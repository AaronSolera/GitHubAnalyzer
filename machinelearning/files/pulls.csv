pull_id,pull_no,title,body
751173883,5512,b'Fixed official builds for Arcade SDK',"b""This PR fixes the official builds for ML.NET's Arcade SDK changes. \r\n\r\nThe failing trusted CI machine DDVSOWINAGE072 has been fixed, more info in this issue: https://github.com/dotnet/core-eng/issues/11513\r\n\r\nLink to the trusted and successful build of these changes: https://devdiv.visualstudio.com/DevDiv/_build/results?buildId=4255993&view=results"""
750098208,5510,b'Disabling AutoFitMaxExperimentTimeTest',"b'The test is sometimes causing CI failures which block PRs.\r\nDisabling it temporally, while the root cause is investigated on #5506 \r\n'"
750087868,5509,b'[Draft] Handle integration tests and nightly build testing',"b'1. To enable running the ""Integration tests"" (formerly known as Functional tests) by using ""build.cmd -integrationTest""\r\n2. Also enabling the nightly build that is triggered everyday at midnight to run the integration tests'"
749362558,5507,b'Fixed some of the memory leaks',b'Added IDisposable to OnnxRuntimeOutputCacher and added using clauses to tests in OnnxConversionTests.'
749165881,5506,b'Debugging occasional AutoFitMaxExperimentTimeTest failures',"b'Debugging occasional AutoFitMaxExperimentTimeTest failures, where sometimes the last model being trained is stopped and its provided exception is not ""Operation was canceled"".'"
747872318,5503,b'Fix NetFX builds by ensuring assembly version is set correctly',"b'Arcade SDK by default sets the version of generated `dll`s to `42.42.42.42`, which breaks some of our unit tests on .Net Frameworks v4.6.1. These failing unit tests are testing backwards compatibility of models by loading them. They are using the `dll`s they came with, which is version `1.0.0.0`. We also generate the same `1.0.0.0` version `dll`s currently, but without this change we make those `dll`s have version `42.42.42.42`.\r\n\r\nCI Build: https://dev.azure.com/dnceng/public/_build/results?buildId=895013&view=results'"
747308715,5502,b'Fix SR anomaly score calculation at beginning',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n#5491 \r\n"""
746829805,5500,b'Testing Arcade',b'\r\n\r\n'
746142442,5499,b'fix CpuMathNative dll not found error for netfx project',b'fix #5495 \r\n\r\n'
745972773,5496,b'Fixes for many of the CI builds.',b'Fixes many of the arcade CI builds. Still need to work on x86 and netfx. '
745343460,5494,b'fix official builds in arcade',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
745150759,5493,b'Arcade Testing',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
745118863,5492,b'Testing Arcade Code Coverage',b'\r\n'
742660045,5488,b'Added Forward Compatibility Error',"b""To resolve #5311. \r\n\r\nIt was suggested we either throw an error or print out a warning if the model is trained with a newer mlnet version than the version reading the model. Given that warnings get logged and a model might still have a silent bug, I'm proposing that we throw an error anytime the model is trained with a newer mlnet version than the one reading the model. \r\n"""
742295988,5485,b'Handle arcade IntegrationTests',b'Handle arcade IntegrationTests\r\n\r\n- [x] Currently working locally on my computer\r\n\r\n- [ ] Checking if it works on CI\r\n\r\n- [ ] Still need to see how to make it work with the NightlyBuild CI.'
739544273,5482,b'Fixing failing Arcade Windows Builds',"b""Fixed the `%20` space error causing Arcade Windows builds to fail, added conditional space variable to be `' '` in Linux/MacOS and `'%20'` on Windows."""
738139020,5479,b'Added Linux & Mac changes for Arcade',"b'This PR contains changes for Linux and Mac Arcade integrations, as well as Arcade benchmark/ performance testing changes.\r\n\r\n'"
738136480,5478,b'Linux & Mac changes for Arcade',"b'This PR contains changes for Linux and Mac Arcade integrations, as well as Arcade benchmark/ performance testing changes.'"
738114834,5477,b'Windows CI working',b'Windows CI working. Mac and Linux will come later.'
736405475,5475,b'Added test key.',b'Added back in the test key to fix the extension issue.'
736350973,5474,b'Fix for #5469',"b""This PR fixes #5469. The issue is coming from the assumption that `ImageResizer` creates a separate `Bitmap`, but when image is already the target dimension `ImageResizer` actually simply returns the source image. Other image methods are likely to dispose of the source image. For example, in this test a getter method get's called twice, and on the second call the source image gets disposed, causing the error. \r\n\r\nA transformer should only be responsible of disposing the objects it creates. One attempt to solve this issue was to keep track of the last Bitmap created to ensure we don't dispose of an object that was not created within  `ImageResizer.` However, the issue encountered with this approach is that the object created by another transformer may be deleted if that transform gets called again. This happens because the source buffers get reused, so image transforms will dispose the previous source image object when they get called again.  \r\n\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageLoader.cs#L238"""
735708463,5472,b'Arcade CI Testing',b'Arcade CI Testing Draft PR'
735179198,5471,b'MaxModels exit criteria for AutoML unit test',b'Update to https://github.com/dotnet/machinelearning/pull/5163.\r\n\r\nUses the internal [`maxModels`](https://github.com/dotnet/machinelearning/blob/e50c4d20012e0d62852f404ae443afca7dad043e/src/Microsoft.ML.AutoML/API/ExperimentSettings.cs#L60) parameter instead of `MaxExperimentTimeInSeconds` for the exit criteria of AutoML. \r\n\r\nThis is to increase the test stability in case the test is run on a slower machine.'
732842412,5468,"b'fix issue 5020, allow ML.NET to load tf model with primitive input and output column'","b'Fix issue 5020, enable tensorflow transformer take primitive type as input column.\r\n\r\n'"
731822738,5467,b'Fixed MacOS daily & nightly builds due to Homebrew bug',"b""Similar to Issue #5457, the nightly ML.NET MacOS builds are failing due to the `openssl` package that is due to be removed from the MacOS images and an outdated standard Homebrew installation on CI's MacOS images, as discussed in the original MacOS-Homebrew GitHub [issue](https://github.com/actions/virtual-environments/issues/1811). This PR adds the fix for this issue.\r\n\r\nIt is said [in this comment](https://github.com/actions/virtual-environments/issues/1811#issuecomment-717348403) that the fix for this issue will be deployed in a few days, until which the changes in this PR will remain on main."""
731603007,5464,b'The `-test` command for windows. Nuget packages',"b""The `-test` command works for windows. CI doesn't work yet as the CI pipeline hasn't been updated. Neither does nightly.\r\n\r\nNuget packages can now be created. Symbols packages are not working yet."""
731089609,5462,b'Add AutoML culture issue test',b'Follow up of #5163 \r\n\r\nHere I add the changes on PR #5163 and a test to actually show that the changes worked correctly. The plan is to merge that other PR and then add this PR for the test.\r\n\r\n'
731013105,5461,b'Debugging Arcade MacOS',"b'Debugging Arcade MacOS runs to see run results on CI, and to see potential differences between local vs CI runs.\r\n'"
730729894,5460,b'Changing LoadRawImages Sample',"b'To resolve issue #5456\r\n\r\nSince the image is raw, what other info should I print to make this sample more useful? '"
729300422,5457,b'Fixed MacOS CI Pipeline builds',"b""This PR adds build workarounds for the recently-failing MacOS builds. As discussed in the main MacOS-Homebrew GitHub [issue](https://github.com/actions/virtual-environments/issues/1811), the `openssl` package that is due to be removed from the MacOS images and an outdated standard Homebrew installation on CI's MacOS images were causing the builds to fail."""
728633113,5455,b'handle exception during GetNextPipeline for AutoML',b'fix part of issue found from #5428 \r\n\r\nhandle exception during GetNextPipeline for AutoML experiment to avoid exception crash the whole AutoML pipeline.\r\n\r\n'
728503780,5454,b'Fix MacOS Pipelines build',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
727741648,5453,b'issue 5336',"b""fix issue #5336 \r\n1. use byte array to create tensor instead of string\r\n2. use Unicode encode instead of UTF8\r\n\r\nThis issue is little bit complicated so please read through below:\r\n\r\nUser want to load a pb model in ML.NET, the input tensor looks like below which is a serialized Example object (a binary buffer, not a text string):\r\n`\r\n      inputs['inputs'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1)\r\n      name: input_example_tensor:0\r\n`\r\n\r\nI find a workable solution is first convert Example object to protobuf encoded byte array using:\r\n`\r\nexample.ToByteArray()\r\n`\r\nthen convert byte array to string (char array) using some sort of reliable encoding (ideally Unicode or Base64 encoding):\r\n`\r\nEncoding.Unicode.GetString(example.ToByteArray())\r\n`\r\nThen ML.NET will convert the string back to byte array with same encoding and pass to tf.net:\r\n`\r\nEncoding.Unicode.GetBytes(((ReadOnlyMemory<char>)(object)data[i]).ToArray());\r\n`\r\n\r\nThe method ML.NET uses to create Tensor is [CastDataAndReturnAsTensor](https://github.com/dotnet/machinelearning/blob/release/1.5.2/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L808), previously we are using [UTF8](https://github.com/dotnet/machinelearning/blob/release/1.5.2/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L832-L838) to decode the string and convert to byte array, UTF8 is not reliable encoding as I described in this [comment](https://github.com/dotnet/machinelearning/issues/5336#issuecomment-714278364) so I would like to change the encoding to Unicode.\r\nAlso, recently Xiaoyun upgrade our TF version in this [PR](https://github.com/dotnet/machinelearning/pull/5404) and changed to use string[] instead of byte[][] to create Tensor, in this case we need to use byte[][] as the input string itself is converted from binary buffer(protobuf encoded). """
726827215,5445,b'Use Timer and ctx.CancelExecution() to fix AutoML max-time experiment bug',"b""Fix #5437 \r\n\r\nThis PR utilizes `Timer` and `ctx.CancelExecution` in AutoML's `Experiment` to listen for and cancel ongoing experiment after given `MaxExperimentTime` has elapsed."""
725990643,5444,b'Improving error message ',b'PR to close #3995 \r\n'
721915897,5439,b'Update OnnxRuntime to 1.5.2',b'Update OnnxRuntime to 1.5.2\r\n\r\n'
721319211,5436,b'[SrCnnEntireAnomalyDetector] Upgrade boundary calculation and expected value calculation',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n#5430 \r\n#5429 \r\n#5441 \r\n\r\nChanges.\r\n1. Check the data range of input data and the output expected values so that they are aligned.\r\n2. Upgrade the boundary unit calculation.\r\n"""
721011426,5435,b'ProduceWordBags Onnx Export Fix ',"b'`ProduceWordBags` Onnx export assumes that the input will be a string of untokenized text. However, in ML.NET the user can choose to tokenize the text before passing it. Even though this is an unnecessary step, since a `WordTokenizer` is added before the `NgramExtraction` transformer, there is no error in ML.NET but there is an error in OnnxRuntime because a double tokenization resulted in more dimensions in Onnx. I have changed the Squeeze transformer to Reshape, so the dimension can remain consistent in this edge case. \r\n\r\n'"
720536960,5433,b'added in DcgTruncationLevel to AutoML api',b'Fixes issue #5425. Adds in DcgTruncation level to the AutoML api to match the normal ML.Net API.'
717003033,5424,b'merge master to arcade branch',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
716997196,5423,b'arcade linux build',b'make arcade linux build pass\r\n\r\n'
716936459,5422,b'Arcade linux',b'1. sync to master to take latest code\r\n2. make arcade build on linux\r\n\r\n'
715031754,5417,b'Fix perf regression in ShuffleRows',"b'RowShufflingTransformer is using ChannelReader incorrectly. It needs to block waiting for items to read and was Thread.Sleeping in order to wait, but not spin the current core. This caused a major perf regression.\r\n\r\nThe fix is to block synchronously correctly - by calling AsTask() on the ValueTask that is returned from the ChannelReader and block on the Task.\r\n\r\nFix #5416\r\n\r\nResults of the added benchmark:\r\n\r\n||      Method |    Mean |    Error |   StdDev | Extra Metric |\r\n|------------|------------:|--------:|---------:|---------:|-------------:|\r\n|master | ShuffleRows | 2.911 s | 0.0379 s | 0.0354 s |            - |\r\n|PR | ShuffleRows | 2.736 ms | 0.0530 ms | 0.0470 ms |            - |\r\n\r\n\r\ncc @jwood803 @ogo-adp @stephentoub '"
711737646,5415,b'Change the _maxCalibrationExamples default on CalibratorUtils',"b'As reported offline, ML.NET yielded different results than TLC when training a PlattCalibrator with the same dataset.\r\n\r\nUpon further investigation, it turns out that it only happened on datasets over 1 million rows, and the reason was that when porting the CalibratorUtils class from TLC, a ""_maxCalibrationExamples = 1000000"" default parameter was added.\r\n\r\nUpon reading through the code (in particular [CalibratorTrainingBase\'s ProcessingTrainingExample](https://github.com/dotnet/machinelearning/blob/4960f9de83351b25874e58d1ca504c9a32aa1112/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1437-L1443)) it turns out that on TLC `TrainCalibrator` was called with `maxRows = 0`, and this made that when training the PlattCalibrator, all the dataset was seen, but only 1M rows where selected randomly to be [added to the DataStore](https://github.com/dotnet/machinelearning/blob/4960f9de83351b25874e58d1ca504c9a32aa1112/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1402-L1417). In contrast, on ML.NET that same method was called with `maxRows = 1M`, and this made that only the first 1M rows were added to the DataStore (instead of randomly selecting them from the complete dataset). This caused bias and undesired results.'"
706692416,5407,b'[Draft] Test Onnx 1.4.0',b'[Draft] Test Onnx 1.4.0\r\n\r\n'
706647770,5406,b'Update to Onnxruntime 1.5.1',"b""Updated to use Onnxruntime 1.5.1, and also added some variables to the Onnx-related tests so it's easier to manually test the onnxruntime GPU prereleases whenever it's necessary."""
705875264,5404,b'update tensorflow.net to 0.20.0',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n# Related issue\r\n#5401 """
702152822,5400,b'Updated branch version',b''
701466963,5399,b'[AutoML]  add SerializedProperties to PipelineNode class.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n# Related issue\r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/792\r\n\r\nThis PR adds `SerializedProperties`, which is a `Dictionary<string, string>` with `PipelineNode`'s property's name as key and **the code to create this property** as value, so that Microsoft.ML.CodeGenerator can directly rely on it to recreate the pipeline. Through this model builder will be able to persist pipeline info in json format so that users will be able to re-add project even after they close model builder. """
700344451,5395,b'Fixes #744 Perf improvement for TopK Accuracy and return all topK in Classification Evaluator',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n\r\n- Improved the perf of the Top K calculation in the ClassificationEvaluator\r\n- Added a new benchmark. Improvements are very small but still present with the tiny data set and only 4 classes. \r\n- outputting AllTopK for K=1..ClassCount always, but left Top k parameter and output of the singular TopK metric to not break compatibility.\r\n\r\nFixes #744"""
693045830,5386,b'Added support for RankingMetrics with CrossValSummaryRunner',"b'Fix #5381 \r\n\r\nPreviously, `AutoFitRankingTest` was never testing `RankingMetrics` with `CrossValSummaryRunner` due to the row limit for cross validation testing, and as the MLSR dataset that `trainDataView` is pulling from is large:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f87a3bbd8adb12934dae0a0060813ce9b7500664/test/Microsoft.ML.AutoML.Tests/AutoFitTests.cs#L123-L141\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/6bae29fc342bf192a36a69484d62db8d6266f8df/src/Microsoft.ML.AutoML/API/ExperimentBase.cs#L109-L130\r\n\r\nAs a result, this lacking of support for `RankingMetrics` with `CrossValSummaryRunner` was not noticed until Issue #5381. This PR adds support for this case, and edits the `RankingMetrics` AutoML unit tests to include testing of `RankingMetrics` with `CrossValSummaryRunner` as well.'"
689703001,5380,b'Added check for paths with wildcards to LoadFromTextFile',"b'Fix #5377 \r\n\r\nAdded validity check for a given path string that may contain wildcards such as ""*"", which result in errors when given to `Directory.Exists`.'"
689460452,5378,"b""Added getter for InputObjectDataView's Data value in documentation""","b""#Fixed #5371 \r\n\r\nAdded getter function to the `private readonly IEnumerable<InputObject> _data` to prevent call to `InputObjectDataView`'s private value."""
689021492,5374,b'Optimize SR Cnn algorithm',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\nChanges.\r\n1. Adjust the expected value for not anomaly points.\r\n2. Add minimum length checks for STL decompose to prevent exceptions. \r\n\r\nAssociated Issues.\r\n#5379 """
688769243,5373,b'Created v1.5.2 relase notes',b'Created v1.5.2 release notes from v1.5.1 release notes. '
684936195,5363,b'add test for model not reload issue',b'add unit test for #5351 \r\n\r\n'
681774277,5354,b'Fixes #5352 issues caused by equality with non-string values for root cause localization ',"b""Fixes #5352 \r\n\r\nComparison between dimension value and aggregated symbol failed or got the incorrect result when their values weren't string. \r\nNeed to support nullable object as the dimension value and aggregated symbol, so we use Object.Equals(a, b) instead of a == b and a.Equals(b).\r\n\r\nBesides, I replace object using Object to align with the data type of dimension and aggregated symbol in this extension."""
680609239,5351,"b'fix issue 5350, check file lock before reload model'","b""fix issue #5350 \r\n\r\nThe issue here is we use a file system watcher to watch model file change and reload the new model file automatically. The problem here is when we try to load the new model file this file is still locked thus cause the reload to fail. \r\nPreviously we are wait for 50 milliseconds before reload the new model file but that fails to work sometimes so here change the strategy to consistently check whether the file can be reload every 50 milliseconds for at most 100 times (which is roughly at total 5 seconds). If we still can't reload new model file after 5 seconds, throw IOException.\r\n\r\n"""
679507967,5349,b'Throw when PCA generates invalid eigenvectors',"b""Fixes https://github.com/microsoft/NimbusML/issues/497\r\n\r\nAs discussed there, the problem is that when PCA generates eigenvectors with NaN values, a cryptic exception is thrown on NimbusML during prediction and not during training. It's thrown during prediction because to do prediction NimbusML saves the model to disk and loads it back, and during deserialization there's a check that prevents loading eigenvectors that contain NaNs.\r\n\r\nIn this PR I'm adding an exception to the constructor of PcaModelParameters so that a more readable exception is thrown during training of either NimbusML or ML.NET, so there's no need to wait until prediction for NimbusML to throw it."""
679456563,5348,b'Added IDisposable to OnnxTransformer and fixed memory leaks',"b""Fixes #5342 \r\nA temp file was being created when the Onnx model was being loaded from within an ML.NET model. This file wasn't being deleted when the session exited because OnnxTransformer didn't support IDisposable. (Also added Dispose calls to OnnxTransformer objects in the tests)\r\n\r\nThanks to the reported bug, this also fixes memory leaks that we would see from OnnxRuntime.dll because the native memory associated with InferenceSession wasn't freed.\r\n"""
678030394,5345,b'AutoML.Net filter infinity value when calculate average score',"b""### Fix issue:\r\n- #5339 \r\n\r\nThis pr fixes #5339 by filtering out the infinity value when [calculating average scores](https://github.com/dotnet/machinelearning/blob/9d3e5452096ac61baf9d2a7ead5a963865fca7d5/src/Microsoft.ML.AutoML/Experiment/Runners/CrossValSummaryRunner.cs#L155) from the results of cross validation runner, so that the average score won't be infinity value in any situation, so that the return value of [GetIndexCloestToAverage](https://github.com/dotnet/machinelearning/blob/37af3f9db86414f4ec5b16a8734c90b498946caa/src/Microsoft.ML.AutoML/Experiment/Runners/CrossValSummaryRunner.cs#L84) will not be -1.\r\n\r\nIn rare case, when all the scores from cross-validation run are infinitive, the average score will be designated to nan. and the return value of [GetIndexCloestToAverage](https://github.com/dotnet/machinelearning/blob/37af3f9db86414f4ec5b16a8734c90b498946caa/src/Microsoft.ML.AutoML/Experiment/Runners/CrossValSummaryRunner.cs#L84) will be 0\r\n\r\nNoted: the +/- infinite value is filtered before calculating average score because of the same reason nan value is filtered. By doing that the evaluation for cross-validation runner might be better than the real situation."""
677944230,5344,b'Integrated guardian SDL tools',b'The guardian tools allow us to run security tools. This PR adds the configuration for those tools into the repo.'
673929369,5338,b'Removed ability to save filters from legacy filter code',"b""Fixes #5335 \r\n\r\nThe offending code in ResultProcessor wasn't being used at all. So I have deleted that.\r\n\r\nAnd as per @yaeldekel the StatefulFilterTransform is a legacy filter from TLC and is not part of the ML.NET public API. It is being used internally in some time series code. But it doesn't need the ability to be saved. \r\n\r\nWe should at some point, upgrade the time series code to use the new CustomMappingTransform and delete the StatefulFilterTransform. \r\n\r\nUntil then I have deleted the SerializableLambdaTransform and the associated functionality in LambdaTransformBase."""
668367592,5332,b'[Reference] Sample on how to solve FxCop errors',"b""This draft PR is meant for reference, and it's not meant to be merged on the main repo, only show case how the workflow will be for working with FxCop issues.\r\n\r\nNotice in the commit history of this PR that FxCop analyzers are enabled first to see the errors they raise, then they're addressed on following commits, and finally the FxCop analyzers are disabled again because they shouldn't be part of a PR solving FxCop issues (enabling FxCop Analyzer on the main repo will only be done after all its issues are addressed, in order to enable us to create single PRs addressing each issue).\r\n\r\nThis PR also contains some tips and tricks by @sharwell about how to deal with the errors that appear when running FxCop."""
668301001,5331,b'Enable FxCop on all projects',"b""This PR enables de FxCop Analyzers on all projects of ML.NET using the `Sdl.Required.Warning.ruleset` recommended to us offline.\r\n\r\n**NOTE:** Right after enabling the FxCop Analyzers (i.e. when syncing with this branch), I've found necessary to Clean, Close, Clean and Rebuild the ML.NET Visual Studio solution to make the changes effective."""
667361943,5329,b'Changed component governance scan type to Register',b''
666660128,5328,b'Replace whitelist terminology to allow list',b''
666653854,5327,b'Added build step for component governance',b'As per security compliance guidelines.'
663435689,5319,b'Aded catch in R^2 calculation for case with few samples',"b'This PR fixes #5306 by adding a catch for the calculation of `R^2` during metric calculation. When there is less than two rows of data used for the calculation of `R^2`, the returned value becomes `-Infinity`, whereas it should be returning `NaN`.\r\n\r\nAn example of this behavior in another ML framework is in scikit-learn, in the following lines:\r\n\r\nhttps://github.com/scikit-learn/scikit-learn/blob/fd237278e895b42abe8d8d09105cbb82dc2cbba7/sklearn/metrics/_regression.py#L587-L590'"
660923423,5313,b'Channels await fix',b'Fix for #5312\r\n\r\nSetting as a draft to add a test.'
659404170,5310,b'RobustScalingNormalizer entrypoint added',"b'When RobustScalingNormalizer was added, PR #5166, the corresponding entrypoints were not created. This PR fixes #5309 by adding in the correct entrypoint for it.'"
655122348,5302,b'Updated version to 1.5.2',b''
655059377,5301,b'Improve VectorTypeAttribute(dims) docs',"b""Addresses #5273 : On the confusion of users about how to use the VectorTypeAttribute.\r\n\r\nAs confirmed offline by @yaeldekel , users currently can't provide a multidimensional array with a `VectorTypeAttribute(dims)` . They should flatten their arrays into 1-D arrays and then use the `VectorTypeAttribute(dims)` to describe the shape ML.NET will use internally.\r\n\r\n**Note:** Originally I was planning on throwing a readable exception if the user added the `VectorTypeAttribute` to a multidimensional array, but some discussion would be needed to decide where to do this (either in `InternalSchemaDefinition.Create`, or somewhere else on `InternalSchemaDefinition` or `SchemaDefinition` itself). Furthermore, I'm thinking that maybe there's a bug on these classes, where if a user adds a custom `DataViewType` (see #3263 ) and adds the attribute of this type to an array, then some unexpected behavior will happen as [`InternalSchemaDefinition.GetMappedType()` ](https://github.com/antoniovs1029/machinelearning/blob/bb13d629000c218136e741b643767cf45ae12fc4/src/Microsoft.ML.Data/DataView/InternalSchemaDefinition.cs#L163) assumes that any array (multidimensional or otherwise) is `isVector = true`, and then elsewhere in the code we assume that if a type `isVector == true` then it _should_ be a `VectorDataViewType`. More discussion and inspection would be needed on this regard and it might, or not, affect the decision of where to throw an exception for multidimensionals array with `VectorTypeAttribute`. And these may be addressed on a separate PR.\r\n\r\nSo, for the time being, and the fact that this might not be a common problem anyway, I think that simply changing slightly the docs is the best option for the next release."""
654621086,5298,b'Added IsotonicCalibrator ONNX Export Support',b'WIP PR to add ONNX export support for the Isotonic Calibrator\r\n\r\nCurrent work remaining is implementing if-then-else conditionals. Intermediate calculations and if-then-else inputs are already implemented.\r\n\r\nI will add tests (first written in this [commit](https://github.com/dotnet/machinelearning/pull/5289/commits/b27d278708beed87d0e7131a58f7fe16abad3f3f)) for validating IsotonicCalibrator with ONNX and merge with upstream once PR #5289 is merged.\r\n\r\n'
654434456,5297,b'Release notes for v1.5.1',b''
653856686,5296,b'Update OnnxTransformer Docs',"b""* Address https://github.com/dotnet/machinelearning/issues/5262#issuecomment-650256576 : Users find it confusing not knowing where to find the info related to the dependencies of Onnx and how to make it work on the GPU. So I think it's best to keep this info in the docs of the `OnnxScoringEstimator` and add a note on every `ApplyOnnxModel()` overload and to `OnnxTransformer` pointing to the Estimator's docs.\r\n\r\n* Address #5293 : About the confusing nature of the `shapeDictionary` parameter. I've updated the docs for this parameter based on the explicit suggestion made by the user.\r\n\r\n* Added a couple of details about how the `gpuDeviceId` and `fallbackToCpu` interact with each other.\r\n\r\n**Note:** As stated in https://github.com/dotnet/machinelearning/issues/5262#issuecomment-650256576 for some reason the published docs for [OnnxTransformer](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.onnx.onnxtransformer?view=ml-dotnet) are outdated, and for some reason it includes info that was deleted on the ML.NET 1.5.0 release (or maybe before that). @natke thinks this is a bug in the tools that generate the published docs, and is seeking for help on this, as this tools are outside of the ML.NET repo itself. In the meantime, we'll try to see if updating this docs on this PR will force the tool to actually generate the correct updated docs.\r\n\r\n"""
652868225,5292,b'Test fix using breastcancel dataset and test cleanup',"b'this PR is part of below PR, we decide to hold the text loader PR but this test fix can be merged separately:\r\nhttps://github.com/dotnet/machinelearning/pull/5275\r\n\r\n2 fixes in this PR:\r\n1. breastcancel dataset don\'t have header, fix tests using this dataset with option hasHeader from true to false\r\n2. we already have dataset breastcancel so stop using hardcoded string ""breast-cancer.txt""\r\n'"
652739656,5291,b'throw exception when call AppendCacheCheckPoint on empty estimator chain',b'issue #4909 \r\n\r\n\r\n\r\n'
652475718,5290,b'Changed default value of RowGroupColumnName from null to GroupId',"b'This is the final pr to fix issue #4749, changes the default value of RowGroupColumnName from null to GroupId.'"
651919403,5289,"b'Added ONNX export support and tests for {FixedPlatt, Naive}CalibratorEstimators'","b'Partial Fix for #5277 \r\nAdded ONNX export support for the Naive calibrator estimator. FixedPlatt calibrator estimator can already be exported as it is deriving from Platt calibrator, which is also already supported.\r\n\r\nAlso added unit tests to check ONNX export for FixedPlatt and Naive calibrator estimators. Specifically, I have consolidated the separate unit tests of calibrators with/without standard date and binary prediction trainers into 1 unit test per calibrator.\r\n\r\nONNX export support for `IsotonicCalibratorEstimator` will come in a separate PR.'"
651825022,5288,b'[Issue4484] Support specifying command timeout while using the database loader',b'fix issue [4484](https://github.com/dotnet/machinelearning/issues/4484)\r\n\r\n-add option to set db command timeout in db loader\r\n-add corresponding test\r\nthis pr partially refers to a hanging [PR](https://github.com/dotnet/machinelearning/pull/4494).\r\n\r\n'
651709754,5287,b'fix test can_reload_model',"b""Fix below test failure by increase wait time:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=716174&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=522d178a-829f-5bff-ccb9-04bea054b64d\r\n\r\nerror message is like:\r\n\r\nX Microsoft.Extensions.ML.FileLoaderTests.can_reload_model [2s 11ms]\r\n  Error Message:\r\n   FileLoader ChangeToken didn't fire before the allotted time.\r\n\r\n\r\nthis failure is tracked at #5266\r\n"""
650436345,5280,b'Properly normalize column names in Utils.GetSampleData() for duplicate cases',"b""Fix #5267 \r\n\r\nThis PR fixes the bug where columns generated from inline data were normalized directly through `Utils.Normalize()`, which only fixes the naming of a given column name, but **does not** take into account duplicate column names that may exist in a dataset.\r\n\r\nPR #5177 introduced a way to fix these duplicate column names by adding the differentiator suffix '_col_x' where 'x' represents the the dataset load order for a given column. In this PR I have separated this generation of distinct and unique column names from `Utils.GenerateClassLabels()` and made it into its own function to `Utils.GenerateColumnNames()`. This is so that this generation of distinct and unique column names can also be used in `Utils.GenerateSampleData`, which before this PR resulted in exceptions. Now, column names from inline data are properly normalized, and duplicate column names are handled.\r\n\r\nThis PR also adds a unit test to test the case of duplicate column names with `Utils.GenerateSampleData`."""
650141899,5279,b'StopWordsRemovingEstimator export to Onnx',"b'- Exporting StopWordsRemovingEstimator/CustomStopWordsRemovingEstimator to Onnx. \r\n- A test which currently fails is the edge case where all the words in the text get removed. While Ml.net produces an empty array, Onnx produces an array of length 1 with the empty string. Suggestions for how handle this case? \r\n\r\nNote: The decision was address the issue mentioned above in another PR. '"
649426349,5275,b'Issue 5051 - ignore duplicate header when load data',"b'address #5051 \r\n1. ignore extra header in line reader of text loader \r\n2. enhance logging\r\n3. corresponding test\r\n4. fix existing text loader test bugs, data file ""breast-cancer.txt"" don\'t have header but many tests use this data file with hasHeader settting to true which is wrong.\r\n'"
648588680,5272,b'remove test data clean up step',"b'see below error during test data clean up stage, try to remove this stage as this might be unnecessary we already fine tune disk usage:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=710808&view=logs&j=f50056e9-8f98-53f0-451e-59b00a9fd1aa&t=c630d711-0b9f-5f2b-2dc5-62892e1fb5ae\r\n\r\n'"
648483511,5269,b'Fix for conditional error in root cause analysis additions',"b'Fix for error in refactoring RCA code. This establishes the same logic in the `OrderDimensions` code as in the previous version, cf. https://github.com/dotnet/machinelearning/blob/1c2469fb8c99afa45531fa9ecca67598291a2288/src/Microsoft.ML.TimeSeries/RootCauseAnalyzer.cs#L460\r\n\r\n\r\n\r\n'"
647891976,5268,b'address build version issue and enhance logging',"b'part of issue #5266\r\n\r\n1. address issue ""error CS7035: The specified version string does not conform to the recommended format - major.minor.build.revision"", one build definition sample of similar issue: https://dev.azure.com/dnceng/public/_build/results?buildId=656357&view=logs&j=28859320-f5de-51e0-1fd2-7bea8c11cf7a&t=ed8fb6c3-76d9-56ef-25a2-06e3456edf43\r\n\r\nThis issue looks like a bug in msbuild versioning. This only happens when the build is crossing 2 days as msbuild versioning is generating versioning file each day so when some project starts to build when the system time is crossing to new day, seems msbuild versioning can\'t handle this case and read empty BuildNumberMajor and BuildNumberMinor sometimes which cause the assembly version number to be a invalid format.\r\n\r\nI can repro this issue by set system time to a time very close to midnight, say 11:58 PM then start build from cmd, there is pretty good chance to repro the build version issue. Since we don\'t have a way to upgrade build tools now I will use default value of BuildNumberMajor and BuildNumberMinor to mitigate this issue.\r\n\r\n2. enhance logging'"
647580293,5265,b'make timeout larger as we are seeing timeouts in CI',"b'we start to seeing timeouts in CI build so make the timeout larger, this is caused by sometimes download tensorflow meta files are slow(takes more than 10 minutes but normally this takes less than 1 minute), also CI tests runs slow than before:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=689649&view=logs&j=dd8eddb6-ecc6-5f65-73e6-df90e5693b94\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706453&view=logs&j=87172896-2df6-55a2-04c3-60b48f00f19f\r\n'"
646544444,5263,b'Enabling Ranking Cross Validation',"b'- Enabled Ranking Cross Validation \r\n- Fixed some syntax errors in the ranking CodeGen generated code\r\n\r\n**Issue**:  Cross Validation is needed in order to integrate the AutoML Ranking Experiment with ModelBuilder. \r\n**Resolves:** #2685 \r\n\r\nUser Scenarios: \r\n- If the user doesn\'t provide a `GroupIdColumnName`, the default becomes ""GroupId"". This is used as the `SamplingKeyColumn` used to split the data. \r\n\r\n- If the user provides both a `GroupIdColumnName` and a `SamplingKeyColumnName`, both most be the same or an exception is thrown. \r\n\r\n**Review**: If the user only provides a `SamplingKeyColumnName`, should we throw an error. Since we use the groupId to split the CV data, the user should not be populating the `SamplingKeyColumnName`. As of right now, an error is only thrown when the `GroupIdColumnName` and a `SamplingKeyColumnName` differ. \r\n'"
646129970,5261,b'Fixed score column name and order bugs in CalibratorTransformer',"b'Fix #4700 \r\n\r\nAs explained in #4700, the column order in which the Score column is given to `PlattCalibratorTransformer` exposes a bug in `CalibratorTransformer` where the name and the location of the score column is hard-coded. This PR fixes this hard-coding, where now the name and order of the score column given to `CalibratorTransformer` can be different than the default values.\r\n\r\nI have also added unit tests to confirm these changes with respect to direct non-standard column name tests and Onnx Conversions.'"
646008734,5260,"b'fix issue 4322, enable lda summary output'",b'fix issue 4322: https://github.com/dotnet/machinelearning/issues/4322\r\n1. output topic summary to model file when OutputTopicWordSummary is set to true\r\n2. open public API from lda transformer to get topic summary\r\n\r\n'
645890659,5259,b'remove unnecessary output from lda native',"b""issue: https://github.com/dotnet/machinelearning/issues/3192\r\n\r\nthese output looks like debug info and don't need output them\r\n"""
645862327,5258,b'Updated AveragedPerceptron default iterations from 1 to 10',"b'Per issue #4749, changes the default AveragePerceptron iteration count from 1 to 10. Also updates all baseline files that were updated as a result.'"
645715124,5257,b'Add two-variable scenario in Tensor shape inference for TensorflowTransform',"b'fix [4364](https://github.com/dotnet/machinelearning/issues/4364)\r\n\r\nThere are a couple of image related scenarios that tensor shape inferencing should handle (tensor usually has shape [W,H,C] or [N,W,H,C] and usually W = H), the first three are covered by current implementation. This PR added the fourth one.\r\n1, [?, ?, C]\r\n2, [?, W, H, C]\r\n3, [N, ?, ?, C]\r\n4, [?, ?, ?, C] (added in this PR)\r\n\r\nThere was another [PR](https://github.com/dotnet/machinelearning/pull/4509) that attempted to resolve this in the past and it considered scenarios like [?, W, ?, C] or [?, ?, H, C] but I am not sure(and never seen) these could be any deep learning scenarios. We can discuss this since I could be wrong and I will add those scenarios if necessary. '"
644511174,5255,"b'Added cross entropy support to validation training, edited metric reporting'","b""Fix #4807 \r\n\r\nIn this PR, I've added cross entropy metric calculation & reporting during validation training in the Image Classification Trainer. Now, validation training can obtain cross entropy values for each epoch during validation training.\r\n\r\nI have attached below screenshots of training and validation metrics with this [repro](https://github.com/dotnet/machinelearning-samples/compare/master...gartangh:validation_metrics).\r\n\r\nBefore (note that learning rate is constant, even when the given `ExponentialLRDecay` is used, and cross entropy during validation is reported as 0):\r\n![before_2](https://user-images.githubusercontent.com/5262061/85540803-455e8680-b5cc-11ea-9928-dab19fd901a6.png)\r\n\r\nAfter:\r\n![_after](https://user-images.githubusercontent.com/5262061/86318215-2ec8b880-bbe6-11ea-86e1-72e77b4ed3a3.png)\r\n\r\nI have also edited `ToString()` to report accuracy and cross entropy for the validation phase as well. Reporting learning rate decay during validation isn't necessary, as no learning rate decay occurs in validation.\r\n\r\nI have also added tests to verify the proper decaying of the cross-entropy rate with this PR.\r\n"""
642841584,5252,b'ignore this',b'testing for PR '
641576086,5249,b'Testing #4309 failure ',b'Do not review \r\n'
641380864,5248,b'Changed default NGram length from 1 to 2.',"b""~~This is part of the work for #4749, other PR's will follow to split the work up. When the default value for NGrams was changed from 1 to 2, we discovered that memory was exploding for FastTree training and was causing test failures in some x86 tests.  This PR changes the the default value for NGramLength from 1 to 2 and also changes FastTree so it handles sparse data better.~~\r\n\r\n~~The main portion of the sparse data change is changing from an array to a dictionary so that memory is only allocated when its needed instead of all up front. When running the previously failing test, it now passes with less memory usage and is actually faster due to less GC running.~~\r\n\r\n~~The slowdown to dense data appears to be very small. Running the benchmark for ranking before the change gives this result:~~\r\n|                                                     Method |    Mean |    Error |   StdDev | Extra Metric |\r\n|----------------------------------------------------------- |--------:|---------:|---------:|-------------:|\r\n| Test_Ranking_MSLRWeb10K_RawNumericFeatures_FastTreeRanking | 1.263 s | 0.0517 s | 0.0595 s |          - |\r\n\r\n~~After the change gives this result:~~\r\n|                                                     Method |    Mean |    Error |   StdDev | Extra Metric |\r\n|----------------------------------------------------------- |--------:|---------:|---------:|-------------:|\r\n| Test_Ranking_MSLRWeb10K_RawNumericFeatures_FastTreeRanking | 1.381 s | 0.0397 s | 0.0457 s |            - |\r\n\r\n~~This is about a 10% slowdown. In return, the memory used is lower. In one example NGram test with NGramLength = 2 the memory before the change was 3.4 GB. After this change was 400 MB.~~\r\n\r\nEdit, leaving in original text for context. After doing more testing and benchmarking, it was discovered the test case was wrong and the FastTree implementation was fine. This pr now just fixes the test case while updating the default NGramLength to 2."""
640777004,5246,b'Enabling custom groupId column in the Ranking AutoML experiment',b'\r\n'
640703745,5245,b'Fix sample tests results preview',"b'Since LoadFeaturizedAdultDataset() has been modified by https://github.com/dotnet/machinelearning/commit/9244e683d85f1c1c16eef4fcd2a5af42d56ac048#diff-eb95ea0c54ebcf8d695d8d73d5849b0cR138, any other sample tests that references LoadFeaturizedAdultDataset() will result in a different score. Change score preview to match.\r\nAlso remove unnecessary spaces.\r\n'"
640695418,5244,b'Fix sample test results ',"b'Since LoadFeaturizedAdultDataset() has been modified by [https://github.com/dotnet/machinelearning/commit/9244e683d85f1c1c16eef4fcd2a5af42d56ac048#diff-eb95ea0c54ebcf8d695d8d73d5849b0cR138](url), any other sample tests that references LoadFeaturizedAdultDataset() will result in a different score. Change score preview to match.\r\n\r\n'"
639850720,5243,b'Changed default NGrams for FeaturizerText from 1 to 2',"b'This fixes #4749. All the other changes in that issue have been done, this was the only one that was left, which will now allow us to close this issue.\r\n\r\n@justinormont can you just verify that is the correct NGramLength to change? Based on the issue, and the other linked issue, this is what I believe is the correct spot. The standard error does go down in the tests with this, which is the expected behavior based on the linked issues.'"
638113689,5239,b'Fix comment in NormalizeRobustScaling',b'Fixes #5238'
637960499,5236,b'Returning multiple dimensions in RCA for anomaly detection',b'This PR adds the ability to return multiple dimensions in Root Cause Analysis for anomaly detection.'
637477786,5234,b'Fixes DateTimeTransformer file path issue for NimbusML',"b'Fixes #5220. This is a regression issue that was resolved before, unless the fix only stayed in the private branch for the featurizers.'"
637324717,5233,b'Adding option for custom groupId column name',b'\r\n'
637252975,5232,b'Improve exception msg by adding column name',"b""For the issue https://github.com/dotnet/machinelearning/issues/5211\r\n\r\nIn this case, when user choose a big dataset and one or more columns have more than expected unique values, the crossvalidate() method throws overflow but it's difficult for users to realize which column in the dataset cause the problem. If we append column name to the overflow message, user can quickly find where goes wrong.\r\n"""
637177506,5231,b'Add DetectSeasonality as a Helper function in TimeSeries ExtensionDialog',"b'We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [X] There\'s a descriptive title that will make sense to other developers some time from now. \r\n- [X] There\'s associated issues. All PR\'s should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n**This PR is part of Feature Request**:  #5230  : Add Seasonality Detection for Time-Series Data\r\n\r\n## Description\r\n\r\nIn time series data, [seasonality](https://en.wikipedia.org/wiki/Seasonality) is the presence of variations that occur at specific regular intervals less than a year, such as weekly, monthly, or quarterly. \r\n\r\nIn this PR, we propose to provide [Seasonality Detection](http://alumni.cs.ucr.edu/~mvlachos/pubs/sdm05.pdf) Support for Time-Series Data based on [fourier analysis](https://en.wikipedia.org/wiki/Fourier_analysis).\r\n\r\n- DetectSeasonality API:\r\n\r\n```\r\n        /// <summary>\r\n        /// Obtain the period by adopting techniques of spectral analysis. which is founded by\r\n        /// the fourier analysis. returns -1 means there\'s no significant period. otherwise, a period\r\n        /// is returned.\r\n        /// </summary>\r\n        /// <param name=""catalog"">The detect seasonality catalog.</param>\r\n        /// <param name=""input"">Input DataView.The data is an instance of <see cref=""Microsoft.ML.IDataView""/>.</param>\r\n        /// <param name=""inputColumnName"">Name of column to process. The column data must be <see cref=""System.Double""/>.</param>\r\n        /// <param name=""seasonalityWindowSize"">An upper bound on the largest relevant seasonality in the input time-series.\r\n        /// When set to -1, use the whole input to fit model, when set to a positive integer, use this number as batch size.\r\n        /// Default value is -1.</param>\r\n        /// <returns>The detected period if seasonality period exists, otherwise return -1.</returns>\r\n        public static int DetectSeasonality(this AnomalyDetectionCatalog catalog, IDataView input, string inputColumnName, int seasonalityWindowSize = -1)\r\n```\r\n\r\nThis PR introduced:\r\n1. `DetectSeasonality` API to `ExtensionDialog` in TimeSeries project\r\n2. Internal class `SeasonalityDetector` that implements the actual logic based on [fourier tranform](https://en.wikipedia.org/wiki/Fast_Fourier_transform)\r\n3. Sample `DetectSeasonality` in `docs/sample/timeseries` folder.\r\n4. Unit Tests in `TimeSeriesDirectApi` file\r\n5. Change `MedianDblAggregator` to be BestFriend and use it in `SeasonalityDetector`\r\n\r\n'"
636702783,5229,b'Use GetRandomFileName when creating random temp folder to avoid conflict',"b'address issue: https://github.com/dotnet/machinelearning/issues/5210\r\n\r\nWe are create random temp folder during model load, sometimes there are file name conflict when load models in multi-threading as the random temp folder name is not seeded.\r\n\r\n'"
636696451,5228,b'Issue 3234: use model schema type instead of class definition schema',b'address issue: https://github.com/dotnet/machinelearning/issues/3234 \r\n\r\n'
636619681,5227,b'Combined methods related to splitting data into one single method. Also fixed related issues.',"b'This PR combines `CreateStratificationColumn` and `EnsureGroupPreservationColumn`, and some code on `GetSplitColumn`, into a new method called `CreateSplitColumn`. This method receives a `samplingKeyColumnName` parameter and _always_ creates a new column named `SplitColumn` based on the `samplingKeyColumn`... the new column is elsewhere in the code used for splitting datasets for Train-Test splits or Cross-Validation Splits, and it\'s _always_ safe to drop the new column as well. **Note**: the `samplingKeyColumn` that `CreateSplitColumn` receives as parameter, or the column it creates, are called `samplingKeyColumn`, `stratificationColumn`, `groupPreservationColumn`, or `splitColumn` (or maybe even `rowGroupColumn` ?) elsewhere in the code or docs, depending on where on the code you\'re / which API you\'re calling (ML.NET\'s TrainTestSplit, CrossValidationSplit, Evaluate or CrossValidate... AutoML, MAML, or NimbusML/Entrypoints). The inconsistency of the naming for this column is a long-standing problem, but since they\'re names used both in public APIs and for historical reasons, I guess there\'s not much we can do now (see #2536, and related issues and PR\'s).\r\n\r\nThis PR also solves multiple issues related with the ""samplingKeyColumn"" when splitting data:\r\n\r\n**Issue**:  When `samplingKeyColumn` is KeyType, dropping the original samplingKeyColumn when calling from entrypoints, makes it impossible to reuse that column\r\n**Solution**: Use a copy column transformer to copy the original column, so that it\'s safe to drop the new column elsewhere without loosing the original column\r\nFixes #5221 : Issue with NimbusML test\r\n\r\n**Issue** : a ""samplingKeyColumn"" is created, but not dropped, when users split data with ML.NET\'s API before training a model with AutoML, causing some problems when reusing the AutoML model\r\n**Solution**: Always drop the new column when calling from ML.NET\'s APIs. Note: to distinguish between the ""samplingKeyColumn"" provided by the user, and the one we internally create, the new column is now called ""SplitColumn"".\r\nFixes #5256\r\nFixes #4048\r\nFixes https://github.com/dotnet/machinelearning-modelbuilder/issues/694\r\n\r\n**Issue**: If the ""samplingKeyColumn"" is float/double type, and includes negative values, or is normalized and outside the (0,1) range, then it might not work as expected.\r\n**Solution**: Use `ensureZeroUntouched = false` in the normalizing estimator, and always normalize if it\'s float/double\r\nFixes https://github.com/dotnet/machinelearning/pull/5227#discussion_r441994977'"
636503402,5226,b'remove unnecessary comments in ONNX.cs',b'Remove unnecessary comments as right now there is no obvious precision difference between ML.NET model and Onnx model\r\n'
635914795,5223,b'fixed Microsoft.MLFeaturizer version in nuget and csproj',"b""Fixes issue #5222 \r\n\r\nWhen I updated the Microsoft.MLFeaturizers version in the csproj file, I didn't do it in the .nuget package. This fixes the version discrepancy and updates them from the preview they were on to the latest full release."""
635287882,5218,b'add threshold for RCA',"b""Update Root Cause Analysis interface.\r\n\r\n\r\n\r\n- [ ] For root cause analysis interface, we added a new parameter called anomalyDeltaThreshold for users to choose. \r\n- [ ] It won't break existing interface if some users are using it.\r\n- [ ] Fixes #5188 .\r\n- [ ] Related PR #4925 \r\n\r\n"""
634993255,5216,b'Updated codegen to support object detection scenario.',"b""Issue: https://github.com/dotnet/machinelearning-modelbuilder/issues/799\r\n\r\nThe previous version of the codegen did not support the new object detection feature. I have added some small changes to templates and some transforms to allow the correct changes for Object Detection Scenario in model builder.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
631412436,5212,b'Filter anomalies according to boundaries under AnomalyAndMargin mode',b'Fixed #5224 .\r\nFilter anomalies according to boundaries under AnomalyAndMargin mode in SrCnnEntireAnomalyDetector.\r\n\r\n'
631072530,5209,b'Removing featurizers now in ML.Net',b'This PR depends on PR #5205. Once that is in all the featurizer functionality that belongs in ML.Net itself will have been added already. We can then remove these 3 standalone transformers as they are now duplicate functionality.'
630373972,5205,b'Added in new MissingValueReplacing method.',"b'Adds in the missing values replacing method of `Mode`. Replaces missing values with the most frequent value in a column. In the case that multiple values have the same count, the first one encountered is the one that is returned.\r\n\r\nThis also moves a test helping method from OnnxConverstionTest.cs into the BaseTestBaseline class so that every test class can use it.'"
629871252,5202,b'Add deseasonality in SrCnnEntireAnomalyDetect',"b'We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There\'s a descriptive title that will make sense to other developers some time from now. \r\n- [x] There\'s associated issues. All PR\'s should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n## Description\r\nIn time series data, [seasonality](https://en.wikipedia.org/wiki/Seasonality) is the presence of variations that occur at specific regular intervals less than a year, such as weekly, monthly, or quarterly. In time series anomaly detection, it is essential to remove the effect of seasonality before detecting anomalies.\r\n\r\nIn this PR, we add the de-seasonality process in SrCnnEntireAnomalyDetect.\r\n* A new SrCnnEntireAnomalyDetect API is introduced.\r\n\r\n```\r\n        /// <summary>\r\n        /// Create <see cref=""SrCnnEntireAnomalyDetector""/>, which detects timeseries anomalies for entire input using SRCNN algorithm.\r\n        /// </summary>\r\n        /// <param name=""catalog"">The AnomalyDetectionCatalog.</param>\r\n        /// <param name=""input"">Input DataView.</param>\r\n        /// <param name=""outputColumnName"">Name of the column resulting from data processing of <paramref name=""inputColumnName""/>.\r\n        /// The column data is a vector of <see cref=""System.Double""/>. The length of this vector varies depending on <paramref name=""options.DetectMode""/>.</param>\r\n        /// <param name=""inputColumnName"">Name of column to process. The column data must be <see cref=""System.Double""/>.</param>\r\n        /// <param name=""options"">Defines the settings of the load operation.</param>\r\n        /// <example>\r\n        /// <format type=""text/markdown"">\r\n        /// <![CDATA[\r\n        /// [!code-csharp[DetectEntireAnomalyBySrCnn](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/TimeSeries/DetectEntireAnomalyBySrCnn.cs)]\r\n        /// ]]>\r\n        /// </format>\r\n        /// </example>\r\n        public static IDataView DetectEntireAnomalyBySrCnn(this AnomalyDetectionCatalog catalog, IDataView input, string outputColumnName, string inputColumnName, SrCnnEntireAnomalyDetectorOptions options)\r\n            => new SrCnnEntireAnomalyDetector(CatalogUtils.GetEnvironment(catalog), input, outputColumnName, inputColumnName, options);\r\n```\r\n\r\nIn the `options` parameter, if `Period` is set to a positive integer, de-seasonality will be enabled before detection. \r\n\r\nThree de-seasonality methods are introduced. \r\n```\r\n    public enum SrCnnDeseasonalityMode\r\n    {\r\n        /// <summary>\r\n        /// In this mode, the stl decompose algorithm is used to de-seasonality.\r\n        /// </summary>\r\n        Stl = 0,\r\n\r\n        /// <summary>\r\n        /// In this mode, the mean value of points in the same position in a period is substracted to de-seasonality.\r\n        /// </summary>\r\n        Mean = 1,\r\n\r\n        /// <summary>\r\n        /// In this mode, the median value of points in the same position in a period is substracted to de-seasonality.\r\n        /// </summary>\r\n        Median = 2\r\n    }\r\n```\r\n\r\nChanges in this PR includes.\r\n1. Add new constructor for `SrCnnEntireAnomalyDetector` class that accepts an options class as parameter.\r\n2. Implement three de-seasonality functions, namely the STL algorithm, the mean method and the median method. The STL algorithm can be referred to at http://www.nniiem.ru/file/news/2016/stl-statistical-model.pdf. The mean/median method substracts the mean/median value of points belong to the same bucket as de-seasonality value.\r\n3. Add unit tests in `TimeSeriesDirectApi` file.'"
629846689,5201,b'Suxi/update',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
629796148,5200,b'Add Seasonality Detection',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
629693692,5198,b'Allow TextLoader to load empty float/double fields as NaN instead of 0',b'Fixes #4132 by implementing a new option on TextLoader that will allow it to impute missing float/doubles as NaN instead of the default `0`.\r\nBuilds on #5154 '
629601154,5197,b'Fixed version format of built packages',"b'Since we are no longer using the pre-release tag, our package versions at the daily build have had an improper version string with two hyphens in a row. This PR fixes that issue. \r\nOur version format is not SemVer 2.0.0 compatible because according SemVer v2, the build metadata has to be separated by +. However this causes build warnings and attempting to fix the warnings causes the msbuild Pack task to not include build number in the package name. \r\nThat issue has to be resolved separately. '"
629599006,5196,b'upgrade tensorflow and tf.net version',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
629575172,5195,b'Add a sample for Onnx conversion',b'\r\n\r\n'
629554295,5194,b'Updated Codegen to support ObjectDetection for ModelBuilder',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
629466054,5192,b'Fixed OnnxTransformer output column mapping.',"b""Our OnnxTransformer has overrides that let you specify a subset of output columns, all the output columns, or let it figure it out from the onnx model. The issue was that if you manually specified either a subset of the columns, or all the columns, and did it in an order different then the onnx model, our transformer would not do the mapping correctly and it would try and access the wrong column. This usually resulted in an error that the types didn't match, but when types matched it just returned wrong data.\r\n\r\nThis PR fixes that issue by doing the correct mapping regardless of the order they are provided in."""
628926763,5189,"b'Issue 4047, improve error message give expected type'",b'address https://github.com/dotnet/machinelearning/issues/4047\r\n\r\n'
628869856,5187,b'Add anomalyDeltaThreshold for RCA',"b""Update Root Cause Analysis interface.\r\n\r\n\r\n\r\n- [ ] For root cause analysis interface, we added a new parameter called anomalyDeltaThreshold for users to choose. \r\n- [ ] It won't break existing interface if some users are using it.\r\n- [ ] Fixes #5188 .\r\n- [ ] Related PR #4925 \r\n\r\n"""
628758301,5186,b'remove unnecessary methods',b'address https://github.com/dotnet/machinelearning/issues/3720\r\n\r\n'
628728725,5185,b'Refactor of OnnxConversionTests.cs',"b'The majority of the tests in OnnxConversionTests.cs do the same thing. Build an ML.Net pipeline, export it to ONNX, and compare the results. This PR refactors the OnnxConversionTests.cs file to use a common method for all the tests that do that same functionality, removing about 400 lines of duplicate code. There were a few tests with functionality not exactly the same, and those were left as is.'"
627611378,5180,b'output memory usage after every test finish',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
627010962,5177,b'Ensured Sanitized Column Names are Unique in AutoML CLI',"b'Fix #3902. This PR ensures that column names that are pulled from datasets and used to generate C# model input are unique. As a result, naming collisions are prevented and are valid C# variables. This is done by adding the column naming-collision fix in `ML.CodeGenerator.Utilities.Utils.GenerateClassLabels`.\r\n\r\nThis naming-collision fix consists of appending the type of the variable to the name of the second duplicate. For example, let us have 3 columns in a sample dataset:\r\n\r\n```csharp\r\nint id;\r\nint Country;\r\nstring country;\r\n```\r\n\r\nThis is represented with `TextLoader.Columns[]` as:\r\n```csharp\r\n\r\nnew TextLoader.Column[]\r\n{\r\n    new TextLoader.Column(){ Name = ""id"", Source = new TextLoader.Range[]{new TextLoader.Range(0) }, DataKind = DataKind.Int32 },\r\n    new TextLoader.Column(){ Name = ""Country"", Source = new TextLoader.Range[]{new TextLoader.Range(1) }, DataKind = DataKind.Int32 },\r\n    new TextLoader.Column(){ Name = ""country"", Source = new TextLoader.Range[]{new TextLoader.Range(2) }, DataKind = DataKind.String },\r\n}\r\n```\r\n\r\nFor `string country` to be a valid class variable, its first letter has to be capitalized, which would result in a naming collision. This PR ensures that this doesn\'t happen, and the generated code becomes:\r\n\r\n```csharp\r\npublic class ModelInput\r\n{\r\n    [ColumnName(""id""), LoadColumn(0)]\r\n    public float Id_col_0 { get; set; }\r\n\r\n\r\n    [ColumnName(""Country""), LoadColumn(1)]\r\n    public float Country_col_1 { get; set; }\r\n\r\n\r\n    [ColumnName(""country""), LoadColumn(2)]\r\n    public string Country_col_2 { get; set; }\r\n}\r\n```\r\n\r\nIn addition, this PR ensures non-unique column names are properly named and differentiated, as shown below:\r\n\r\n```csharp\r\nnew TextLoader.Column[]\r\n{\r\n    new TextLoader.Column(){ Name = ""column1"", Source = new TextLoader.Range[]{new TextLoader.Range(0) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""column1_string"", Source = new TextLoader.Range[]{new TextLoader.Range(1) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""column1_string_1"", Source = new TextLoader.Range[]{new TextLoader.Range(2) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""column1_string_2"", Source = new TextLoader.Range[]{new TextLoader.Range(3) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""Column1"", Source = new TextLoader.Range[]{new TextLoader.Range(4) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""column1_int"", Source = new TextLoader.Range[]{new TextLoader.Range(5) }, DataKind = DataKind.Int32 },\r\n    new TextLoader.Column(){ Name = ""column1_string"", Source = new TextLoader.Range[]{new TextLoader.Range(6) }, DataKind = DataKind.String },\r\n    new TextLoader.Column(){ Name = ""column1"", Source = new TextLoader.Range[]{new TextLoader.Range(7) }, DataKind = DataKind.Int32 }\r\n}\r\n```\r\n```csharp\r\npublic class ModelInput\r\n{\r\n    [ColumnName(""column1""), LoadColumn(0)]\r\n    public string Column1_col_0{get; set;}\r\n\r\n    [ColumnName(""column1_string""), LoadColumn(1)]\r\n    public string Column1__string_col_1{get; set;}\r\n\r\n    [ColumnName(""column1_string_1""), LoadColumn(2)]\r\n    public string Column1_string_1_col_2{get; set;}\r\n\r\n    [ColumnName(""column1_string_2""), LoadColumn(3)]\r\n    public string Column1_string_2_col_3{get; set;}\r\n\r\n    [ColumnName(""Column1""), LoadColumn(4)]\r\n    public string Column1_col_4{get; set;}\r\n\r\n    [ColumnName(""column1_int""), LoadColumn(5)]\r\n    public int Column1_int_col_5{get; set;}\r\n\r\n    [ColumnName(""column1_string""), LoadColumn(6)]\r\n    public string Column1_string_col_6{get; set;}\r\n\r\n    [ColumnName(""column1""), LoadColumn(7)]\r\n    public int Column1_col_7{get; set;}\r\n}\r\n```\r\n\r\nThis PR also adds unit tests to test naming collision scenarios in both `CodeGenTests` and `ConsoleCodeGeneratorTests`.\r\n\r\nIn addition, this PR also cleans up duplicate code with respect to the `ML.CodeGenerator.Utilities.Utils.GenerateClassLabels` function, by linking its duplicate function `ML.CodeGenerator.CodeGenerator.GenerateClassLabels` to the former.'"
626944351,5176,b'Support onnx export with previous OpSet version',b'For Feature request: https://github.com/dotnet/machinelearning/issues/5171\r\n\r\n\r\nSupport exporting to onnx with a lower opset version\r\nupgrade opset version from 11 to 12'
626734289,5175,b'Updated ORT version info for OnnxScoringEstimator',b'Also added additional detail around mandatory inclusion of either the CPU or the GPU nuget of ORT.\r\n'
626225161,5174,b'Support onnx export with previous OpSet version',b'Feature request https://github.com/dotnet/machinelearning/issues/5171\r\n\r\n'
626154744,5173,b'update codegen to make it work with mlnet 1.5 ',b'related issue:\r\nhttps://github.com/dotnet/machinelearning-modelbuilder/issues/777'
625975676,5172,b'Removed unused CodeGen Baseline',"b'The `codegen-out.cs` file was supposed to be used as baseline for some test:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2f7075782764c9dab8f0a04013aaf8b9921d984/test/BaselineOutput/Common/Command/codegen-out.cs\r\n\r\nThe file was introduced in #1654 along with a `CommandCodeGen()` test which used the baseline to test the MAML `codegen` command. That test, along with the CodeGenerationUtils class (which I guess was only used by the codegen command) was deleted in [#1848](https://github.com/dotnet/machinelearning/pull/1848/files/6337f663d841b5709a5567c21809ddbf51327f22#diff-9a5afd195d2538b0a4080d3d5d0059c0), but the baseline was left... so I\'m assuming this was an error, and I\'m simply deleting the baseline file in this PR.\r\n\r\nThere is also another test, `CheckFastTreeParallelInterface()`, which declares `var csOutPath = DeleteOutputPath(outRoot, ""codegen-out.cs"");` but actually never uses the `csOutPath` variable. Also, the test is disabled for some reason that seems unrelated to the `codegen` command. So I\'m simply removing that variable. As I guess it wasn\'t meant to use the baseline I\'m deleting anyway (notice that the baseline got introduced in #1654 as I\'ve mentioned, but the `CheckFastTreeParallelInterface` was introduced in the first commit of the ML.NET repo, and it already had the unused variable).'"
625427806,5169,b'new code coverage',"b'Address code coverage pipeline issue:\r\nError message like: Unable to read beyond the end of the stream.\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=662753&view=logs&j=12b34f85-96db-5b04-05cf-faf2be278867&t=4efaf9f8-7d26-5ca9-4ea8-c01555af0e7d\r\n\r\nThis is known issue from msbuild and coverlet. Coverlet collect and write hits data on process exist, if for some reason process is too slow to close will be killed and we cannot collect coverage result.\r\nhttps://github.com/coverlet-coverage/coverlet/blob/master/Documentation/KnownIssues.md#1-vstest-stops-process-execution-earlydotnet-test\r\n\r\nDue to recommendation from coverlet, change from coverlet.msbuild to coverlet.collector:\r\nhttps://github.com/coverlet-coverage/coverlet/blob/master/Documentation/VSTestIntegration.md\r\n\r\nUpgrade Vs test sdk and modify corresponding configuration.\r\n\r\n'"
625282035,5167,b'Updated version to v1.5.1',b''
625222103,5166,b'Robust Scaler now added to the Normalizer catalog',"b'One of the featurizers that was added in the past was the RobustScalerFeaturizer. After talking with the ML.Net team, it was decided that since this is just a normalizer it makes more sense to have it be part of the existing collection of normalizers that ML.Net already has. This PR adds that functionality. It is the equivalent of the [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html) in pandas. Once this PR goes in, we can remove the original transformer that was added.'"
624304798,5163,b'Auto.ML: Fix issue when parsing float string fails on pl-PL culture set using Regression Experiment',b'Fixes #5162\r\n\r\nFloat parsing fails when culture = `pl-PL` despite the fact that it does not need to parse anything here.\r\nVariable `pset` is in fact `IParameterValue<float>` - it has `float Value` property with correct `float` type which should be used.'
623943896,5160,b'Fixed onnx export for key types other than uint',"b""In PR #5152 @yaeldekel modified the test for onnx export for key types and disabled the test for types other than uint because of a bug in onnx export for those other types. This PR takes the test from @yaeldekel's PR and adds the fix for the onnx export bug.  """
623596875,5154,b'Created DoubleParser.OptionFlags to be used by TextLoader',"b'As mentioned on https://github.com/dotnet/machinelearning/pull/5145#issuecomment-632255971 , PR #5145 opened the possibility of an issue to occur when running, _at the same time_, different cursors coming from different `TextLoaders `with different `DecimalMarkers`, as race conditions could occur. Although [we originally agreed](https://github.com/dotnet/machinelearning/pull/5145#issuecomment-632467994) to accept that fringe scenario, this PR fixes that problem, and adds a test for that scenario.\r\n\r\nThis PR also addresses the general problem, that if we add new options to `TextLoader `that need to affect how we parse Single/Doubles, then there was no direct/thread-safe way to make these options affect how `DoubleParser `works... For example, issue #4132 would require adding a new `TextLoader.Option` ""impute"" that needs to affect how `DoubleParser `works. Other case would be the offline suggestion of also adding a `ThousandsMarker` option to be able to parse `10,332.05` or `10.332,05` into `10332.05` depending on that option.\r\n\r\n### General explanation of the PR\r\nWithout this PR the behavior was that `TextLoader.Parser` would use the singleton `TextLoader.ValueCreatorCache.Instance` to get the delegates to parse the fields loaded from a file. In turn, the `ValueCreatorCache` singleton would have gotten those delegates from the singleton `Conversion.Instance`, whose methods for parsing text to single/doubles would, then, call static methods in `DoubleParser`.\r\n\r\n**I am assuming that the only reason to have both `ValueCreatorCache` and `Conversion `follow the singleton pattern was for performance reasons, so that they didn\'t have to create the delegates every time somewhere in the code their instances were needed**\r\n\r\nWith this PR:\r\n1. I created a new `DoubleParser.OptionFlags` enum that is used by `TextLoader`, and gets propagated through `ValueCreatorCache `up to `Conversion `in order to call the static `DoubleParser `methods with the correct options.\r\n2. I added code to `ValueCreatorCache `and `Conversion `to let them create other instances besides its default instance. Most of the codebase would still use their default instance, so this PR doesn\'t affect performance or behavior there. It\'s only in `TextLoader`, and only in the case when using custom options for `DoubleParser`, that a custom instance of `ValueCreatorCache `and `Conversion `gets created. So then performance would only be somewhat affected when creating those instances for that particular case. To have minimum impact in performance, I also added a `ConcurrentDictionary `to hold the `_customInstances `of `ValueCreatorCache `(i.e. those which were created using non-default `DoubleParser.OptionFlags`)... this way, when using custom options, the custom instance of `ValueCreatorCache `and Conversion would only be created once, and would be reused afterwards.'"
623380398,5153,b'Updated doc comments and renamed public types',"b'@gvashishtha Left a few doc comments on the earlier anomaly and time series PRs. I am addressing them here. The comments I could not address, I have copied them here. \r\nPlease review the changes and help me with the questions. \r\n\r\nSince this is part of the public API, I have also taken the liberty to rename the following types and names:\r\n- Name `AggType` to `AggregateType`\r\n- Name `AggSymbol` to `AggregateSymbol`\r\n- Type `Point` to `TimeSeriesPoint`\r\n\r\nPlease review whether these renames are appropriate. '"
623056332,5152,b'Change back previous version hashing of 8 byte types',"b'In PR #5104 he hashing function of 8 byte numeric types was changed, but there still needs to be an unchanged implementation for old version models.\r\n\r\nIn addition, found a bug in ONNX conversion of hashing of keys that have underlying type different than uint.'"
622845782,5151,b'Added release notes for v1.5 release and updated version info',b''
622841728,5150,b'Adding Ranking AutoML Task',b'Creating a ranking experiment in AutoML - sweeping over predefined parameters for two trainers - FastTreeRanking and LightGBMRanking. \r\n\r\n**ModelBuilder Requests**: \r\n- Concatenate feature columns - done in this PR \r\n- Allow custom groupId column name- will do in another PR\r\n\r\n**Next Steps:** Fully integrate with modelbuilder'
622228315,5149,b'Ensure that the graph is set to be the current graph when scoring with multiple models',b'Address issue: https://github.com/dotnet/machinelearning/issues/4568\r\n\r\n'
622019042,5148,b'support sweeping multiline option in AutoML',b''
621678836,5147,b'Add escapeChar support to TextLoader and added benchmark for TextLoader',"b'Adds feature requested here: https://github.com/dotnet/machinelearning/pull/5125#discussion_r425735487\r\n\r\nAnd also a benchmark for TextLoader, whose results are reported here:\r\nhttps://github.com/dotnet/machinelearning/pull/5147#discussion_r428583991\r\n\r\nThe feature is exposing a new option called escapeChar to the users, which is used to escape quote characters inside quoted fields.\r\n\r\nSo if `escapeChar = \\`, then the second field of the following row:\r\n`1,""this \\"" quote was escaped"",true`\r\n\r\nwill be loaded as\r\n`this "" quote was escaped`\r\n\r\nDefault behavior (which was the behavior even before this PR) is that `escapeChar = ""` since 2 double quotes ("""") has always been used to escape quotes inside quoted fields by ML.NET.'"
621430363,5146,b'Uniform onnx conversion method when using non-default column names',"b'Resolve https://github.com/dotnet/machinelearning/issues/3089\r\n\r\nFix for BinaryClassification, not find any issue with Multi-Classification.\r\nAdd tests for the above scenarios \r\n'"
621419479,5145,b'Added decimal marker option in TextLoader',"b""This PR adds the decimal marker option in TextLoader, so that cultures where a comma is the decimal marker (as in 3,5 = 3.5 * 10^1) can use their appropriate datasets. This also updates `verWrittenCur` as it is now writing `decimalMarker` during serialization as well. In addition, this PR also adds in a unit test to check whether or not a dataset with `','` as its decimal marker is read in and processed correctly.\r\n\r\nFix #4910 \r\n\r\n"""
621152525,5143,b'Updated installation of libomp on Mac trusted CI builds',"b'This PR fixes the error our Mac trusted CI builds were showing with regards to the installation of `libomp` with Homebrew, and mirrors the changes done in #5141.\r\n\r\n'"
620525215,5141,b'Fix libomp installation for MacOS CI Builds',b'Fix the part of installing dependencies on MacOS where libomp is added'
620480348,5140,b'fix build issue',b'make docker update to nightlybuild pipeline and outer loop pipeline as well\r\n\r\n'
619337977,5138,b'Adding support for MurmurHash KeyDataTypes ',"b""ML.NET's behavior is to map zero input values to zero, instead of hashes. \r\n- Adding that behavior to the onnx export and a test. \r\n\r\nTODO:  rebase once other murmurhash PR are merged \r\n\r\n"""
619270991,5137,b'Update Ubuntu build and reenable TextNormalizingOnnxConversionTest() on Linux',"b'This PR updates our Ubuntu CI builds with the correct installation pattern for `libomp-dev`, and the correct updating of its locale setting, which enables us to re-activate the unit test TextNormalizingOnnxConversionTest().'"
619233862,5136,b'Fix Microsoft.ML.DataView references',"b""The assembly in the package references Collections.Immutable, but the nuget package doesn't. This can cause errors if someone just references the Microsoft.ML.DataView package.\r\n\r\nFixing by adding the reference.\r\n\r\nSee the .csproj here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/212081c62855a835e0612887f705a8f87a899624/src/Microsoft.ML.DataView/Microsoft.ML.DataView.csproj#L8-L11"""
618966627,5135,b'Add SrCnn entire API by implementing function',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
618868922,5134,b'Add public generic methods to TextLoader catalog that accept Options objects',"b""The `TextLoaderSaverCatalog` contains 2 overloads of non-generic `CreateTextLoader` and `LoadFromTextFile`; one overload accepts a [given set of a parameters ](https://github.com/dotnet/machinelearning/blob/3da9e1e7a64f3485b811b99eaab05276a310192c/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L51-L58) and the other overload [accepts a TexLoader.Options object](https://github.com/dotnet/machinelearning/blob/3da9e1e7a64f3485b811b99eaab05276a310192c/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L83-L86).\r\n\r\nThe generic methods for `CreateTextLoader<TInput>` and `LoadFromTextFile<TInput>` only [have 1 method](https://github.com/dotnet/machinelearning/blob/3da9e1e7a64f3485b811b99eaab05276a310192c/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L112-L120) that accepts a given set of parameters. So in this PR I add another overload for those 2 methods that also accepts an Options object.\r\n\r\nThe reason to do this is that if we add new parameters to TextLoader (for example, as done in #5125) then they're only accessible through a TextLoader.Options (so without this PR `CreateTextLoader<TInput>` and `LoadFromTextFile<TInput>` won't be able to use the new options). Notice that we can't simply add a new parameter to the existing `CreateTextLoader<TInput>` and `LoadFromTextFile<TInput>` methods, since that is considered a breaking API change, and we can't do those until ML.NET version 2."""
618708640,5133,b'use new meta file from premium storage account',"b""Recently we are seeing couple of download meta file timeout/failure, checked the old blob storage for meta files, it is using Standard configuration and can't upgrade to premium once created.\r\n\r\nCreated new premium storage account as below to see if we get better stability: \r\nhttps://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/00c06639-6ee4-454e-8058-8d8b1703bd87/resourcegroups/ML.NET/providers/Microsoft.Storage/storageAccounts/mlnetresources/overview\r\n\r\n\r\ndifference between Standard vs Premium:\r\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-performance-tiers"""
618676888,5131,"b'disable download meta file by default, only enable on CI'","b'As download meta files sometime hangs, disable download from build stage by default, only enable meta files download at CI\r\n\r\n'"
618500639,5130,b'Error message for non-parsable datasets in AutoML',"b'Fixes: #5129\r\n\r\n> I\'d recommend improving the current error message:\r\n> https://github.com/dotnet/machinelearning/blob/e5a19af589dfb1468cd99628e82f6b49fb125323/src/Microsoft.ML.AutoML/ColumnInference/ColumnInferenceApi.cs#L120-L123\r\n> \r\n> It currently says, `""Unable to split the file provided into multiple, consistent columns.""`, which is rather uninformative and non-actionable.\r\n> \r\n> Perhaps, as I think @briacht is suggesting, have it list the acceptable file formats we can parse: `""Unable to split the file provided into multiple, consistent columns. Readable formats include delimited files such as CSV/TSV. Check for a consistent number of columns and proper escaping and quoting.""`.\r\n> \r\n> This messaging now includes, the problem, and next steps for the user.\r\n> \r\n> I mention delimited as AutoML supports more than CSV/TSV as it tries tab, comma, space, semi-colon as the separator ([src](https://github.com/dotnet/machinelearning/blob/e50c4d20012e0d62852f404ae443afca7dad043e/src/Microsoft.ML.AutoML/ColumnInference/TextFileContents.cs#L40)). If we run into other common separators, we can trivially augment this list. One candidate is the vertical bar `|`.'"
618486604,5128,b'Update TexFileSample to use FileShare.ReadWrite',"b""Associated issue is in Model Builder repo Issue [530](https://github.com/dotnet/machinelearning-modelbuilder/issues/530) (let me know if I need to open one here). \r\n\r\nBasic problem is when .csv training files are open in excel customers cannot train in Model Builder. The root cause is incorrect `FileShare` setting on the FileStream. `FileAccess` specifies how we want to use the file. `FileShare` specifies how we allow other programs to use the file. Even though we're opening files as FileAccess.Read, setting to FileShare.Read means we won't allow other programs to write. This blocks us from reading a file already opened as ReadWrite by Excel. If found [this](https://stackoverflow.com/questions/897796/how-do-i-open-an-already-opened-file-with-a-net-streamreader) stack overflow to have the best explanation. \r\n\r\nI'm not familiar with how the TextLoad code works, so there may be other spots this should be updated. If anyone has advice let me know, or we can proceed with this change and see if other come up later. \r\n"""
618484474,5127,b'Revert code gen',b'Revert CodeGen to take project reference to AutoML'
618107979,5125,b'Enable TextLoader to accept new lines in quoted fields',"b'Fixes https://github.com/dotnet/machinelearning-automl/issues/193\r\n\r\nAddresses these issues (see below):\r\nhttps://github.com/dotnet/machinelearning/issues/4460\r\nhttps://github.com/dotnet/machinelearning-modelbuilder/issues/702\r\n\r\nBased on @LittleLittleCloud \'s PR: \r\nhttps://github.com/dotnet/machinelearning/pull/4584\r\n\r\nThis PR enables TextLoader to load rows which have new line characters inside quoted fields. So, for example, if the input CSV file has:\r\n\r\n```\r\nid,description,animal\r\n11,""this is a\r\nquoted field with\r\nnewlines"",cat\r\n```\r\nthen all of that will actually be loaded into a single row. Previously, if the TextLoader was presented with such a case, it would typically throw exceptions because it wasn\'t able to parse it correctly.\r\n\r\nI took @LittleLittleCloud \'s PR which had most of the work done, and added some corner cases, public interfaces to this feature, and made and ran different tests, addressing the comments on that other PR.\r\n\r\n### Complying with RFC 4180\r\nI was tasked to take care of this issue, while also making the TextLoader compliant with [RFC 4180](https://tools.ietf.org/html/rfc4180) (on CSV format). Turns out the TextLoader already accepted pretty much everything that the RFC states, except for accepting new lines inside quoted fields, which is pretty much the only thing fixed in this PR.\r\n\r\n1. Notice that this means that TextLoader was already able to escape 2 double quotes ("""") inside quoted fields; i.e. `""this is """"an"""" example""` will correctly be loaded as `this is ""an"" example`.\r\n2. When loading CSV files TextLoader also accepts and do other things that the RFC doesn\'t mention. For example, filtering lines that start with ""//"" as if they were comments, or accepting 1 double quote ("") in the middle of a field when allowQuoting is false.\r\n3. It seems to me the only thing that the RFC states and that ML.NET doesn\'t follow, is that the RFC says that spaces should also be considered part of the fields, and not be ignored... but in general ML.NET ignores spaces at [the beginning](https://github.com/dotnet/machinelearning/blob/8e5f7b42cd65660393b3ac59765ae166ee7ea4ad/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderParser.cs#L1095) and [at the end](https://github.com/dotnet/machinelearning/blob/8e5f7b42cd65660393b3ac59765ae166ee7ea4ad/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderParser.cs#L802) of each field, and line.\r\n\r\n### Modelbuilder and AutoML issues\r\nThere are different issues in Modelbuilder and AutoML that were supposed to be caused by TextLoader and I was supposed to fix them on this PR. But after looking into them, it doesn\'t seem that they are caused by the TextLoader. I have opened [this issue](https://github.com/dotnet/machinelearning-modelbuilder/issues/747) in ModelBuilder explaining this in more detail, but in general, for some reason, if the first line (after the header) of a CSV file contains a comma inside a quoted field, then ModelBuilder shows an error saying it can\'t be loaded; it was said that the problem was on TextLoader, but it isn\'t, particularly because TextLoader doesn\'t have any problem escaping commas inside quoted fields.\r\n\r\nSo, regarding issue https://github.com/dotnet/machinelearning-modelbuilder/issues/702\r\n1. ML.NET\'s TextLoader was able to load most of the datasets pointed there, despite the fact that ModelBuilder shows an error message when the user selects them on the GUI.\r\n2. Only some of the jigsaw datasets (such as jigsaw-toxic-comment-train.csv) and the Airbnb datasets included new lines inside quoted fields so they couldn\'t be loaded by ML.NET. This is fixed on this PR.\r\n\r\nRegarding issue https://github.com/dotnet/machinelearning/issues/4460\r\n1. @LittleLittleCloud mentioned that there were problems using InferColumns() with CSV files that contained new lines inside quotes, so this is fixed on this PR and I add a test reproducing that.\r\n2. @LittleLittleCloud also provided a listings.csv dataset, which doesn\'t include new lines inside quotes, and so this PR doesn\'t really affect that. Regarding this dataset, he didn\'t mentioned problems loading it, but that there were some problems with how the InferColumns method worked with double quotes. It looks to me that that dataset is loaded correctly (i.e. scaping """" as expected), so I further discussions would be needed about this to see where\'s the real root cause, as it\'s likely not in TextLoader.\r\n\r\n### Testing this PR\r\nTo test this PR I:\r\n1. Added 2 new tests\r\n2. Ran locally all existing ML.NET tests, using ReadMultilines = true as default. And it all worked as expected. I did this both using 1 thread or multiple threads for the text loader, to check the effect of multithreading.\r\n3. Loaded all the datasets provided by ModelBuilder team successfully in ML.NET.'"
617917257,5124,b'test on OneClassMatrixFactorizationInMemoryDataZeroBaseIndex',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
617805132,5123,b'Use Channel Instead of BufferBlock',b'Updates for #4482.\r\n\r\n@eerhardt I took a shot at a single replacement to make sure it looks good before continuing. Does this look good or am I missing anything?'
617793842,5122,b'enable build step timeout also some code cleanup',b'1. set the build steps to timeout at 20 minutes\r\n2. remove MatrixFactorizationFact\r\n3. remove RetryFact and related class\r\n\r\n'
617262411,5121,b'Updated libmf and corresponding MatrixFactorizationSimpleTrainAndPredict() baselines per build',"b'Fixes #4874 \r\n\r\nThis PR updates the libmf submodule, where its recent changes in libmf [PR #41](https://github.com/cjlin1/libmf/pull/41) and [PR #42](https://github.com/cjlin1/libmf/pull/42) address the shuffling of values in a given matrix. \r\n\r\nThe C++ function `void random_shuffle(_RanIt _First, _RanIt _Last)` is implemented differently on Windows vs. MacOS vs. Linux. This resulted in inconsistent results on MacOS and more-predictable yet still inconsistent results on Linux. As a result, a given matrix factorization problem, even with a constant seed, produced differing MSEs between each run on each system. The libmf codebase has been updated to prevent this, and baseline MSE values in the unit test `MatrixFactorizationSimpleTrainAndPredict()` have been updated to reflect this.'"
617142500,5120,b'move tf meta file download to build stage',"b'recently observe several test fail due to meta file download fail, move download to build stage which has 2 advantage,\r\n1. if download fail, fail fast at build stage\r\n2. we used to download large benchmark data (over 800 MB) and this download is quite stable, try download here\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=637938&view=logs&j=5aa5c7df-492a-5eaf-973a-62b7b0f0ee3b&t=ffdbd604-f3e2-5332-cf61-c8dd00799b47\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=639940&view=logs&j=4e8eb92e-b635-5c96-398c-05943bacd8c5&t=cf6d66af-7fee-5841-f0be-a4bf6642a2ae\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=640227&view=logs&j=c54dae93-d956-5713-8cb2-8e90b1d124e1&t=87b64192-025a-5709-ee76-220b68eba827'"
616311940,5119,b'test os specific tests',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
616279268,5118,b'move nightly build pipeline and outer pipeline back to hosted',b'move nightly build pipeline and outer loop pipeline back to hosted\r\n\r\n'
616277104,5117,b'ensure benchmark dataset is downloaded before using',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
616072768,5114,b'Improve error message when defining custom type for variables',"b""resolve https://github.com/dotnet/machinelearning/issues/4122\r\n\r\nThe unhelpful message stuff is a bit different from the above link's description. ML.NET throws unhelpful message not because the customer uses the wrong type(different from the type defined in onnx), but defining the variable using the same type as OnnxSequenceType. However, the correct type should be IEnumerable<OnnxSequenceType>.\r\n\r\nThis change adds more information to existing exception message and adds a special error message for errors like this when customer carelessly defines a container variable without using container type\r\n\r\n\r\n"""
614980242,5110,b'Disabled BinaryClassifierSymSgdTest for test stability',b'\r\n\r\n'
614426575,5108,b'test move back to host see if still hangs',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
614424101,5107,b'try use other agent pool',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
614309686,5106,b'added in standard conversions from types to ReadOnlyMemory<char>',"b""Currently in the standard transformations we don't support converting types to a string representation. Since all C# types support `ToString()` functionality, this PR adds in standard transformations to type `ReadOnlyMemory<char>` into the `TypeConvertingTransformer`."""
614171721,5104,b'Support more types for HashEstimator',b'-Verified compatibility(change required in ML.NET in this PR) between ORT(https://github.com/microsoft/onnxruntime/pull/3827) and ML.NET\r\n-Some changes made in a couple of 64-bit hash function because the existed implementation is not exactly the same as MurmurHash3_x86_32\r\n-bump to ort1.3 pre-release and fix some test cases\r\n\r\n'
613776008,5103,b'troubleshoot hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
613705654,5102,"b'address TF test download fail, use resource manager with retry download'","b'address below exception on OSX:\r\n\r\nX Microsoft.ML.Scenarios.TensorFlowScenariosTests.TensorFlowTransforCifarEndToEndTest2 [1ms]\r\n  Error Message:\r\n   System.Net.WebException : Device not configured Device not configured\r\n---- System.Net.Http.HttpRequestException : Device not configured\r\n-------- System.Net.Sockets.SocketException : Device not configured\r\n  Stack Trace:\r\n     at System.Net.HttpWebRequest.GetResponse()\r\n   at System.Net.WebClient.GetWebResponse(WebRequest request)\r\n   at System.Net.WebClient.DownloadBits(WebRequest request, Stream writeStream)\r\n   at System.Net.WebClient.DownloadFile(Uri address, String fileName)\r\n   at System.Net.WebClient.DownloadFile(String address, String fileName)\r\n   at Microsoft.ML.Scenarios.TensorFlowScenariosTests.Download(String url, String destDir, String destFileName) \r\n\r\n\r\naccording to below issue and suggestion (The OSX resolve seems more fragile than other implementation), we retry download:\r\nhttps://github.com/dotnet/runtime/issues/30678 '"
613630404,5100,b'pipeline configuration change',b'1. make code coverage timeout to 90 minutes due to frequent timeout at code coverage pipeline\r\n2. move nightly build pipeline to netcore app agent pool as we see disk out of space error\r\n\r\n\r\n\r\n'
613625073,5099,b'disable test that are hanging and failing',"b'Due to some recent CI failing, disable some test to unblock:\r\n\r\nHanging: \r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=632387&view=logs&j=fbb2cc91-8ee3-5485-dfe8-a5681da76491&t=12433ff8-7284-5589-30ac-02bd5974b6ad\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=631965&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&t=4390109a-3c77-5b7c-bf35-d176b654cd3c\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=631033&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=630228&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&s=b15d9194-8f26-5328-b47f-5968c76b37e7\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=628376&view=logs&j=9dffbc46-9322-5a58-fb37-6d66c044e90d&t=11098bf6-eb78-583b-8eab-f14f48444a6b\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=628134&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=dbdc2969-5b98-5c39-1328-31d4a2fdc45e\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=626424&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=620750&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&s=d654deb9-056d-50a2-1717-90c08683d50a\r\n\r\nFail:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=614989&view=logs&j=4b233af4-7b14-5f68-27c6-9c4d7ac87519&t=6e2e87e8-8c33-50e6-544b-c271638494a5'"
613586028,5098,b'Adding OneHotHashEncoding Test',b'Test that uses OneHotEncoding and MurmurHash transformers\r\n\r\n'
613577783,5097,b'Changed Dictionary to ConcurrentDictionary',"b""We are seeing new test failure sporadically with the following call stack:\r\n\r\n```\r\n[xUnit.net 00:00:05.18]     Microsoft.ML.Functional.Tests.Debugging.ViewTrainingOutput [FAIL]\r\n\r\n  X Microsoft.ML.Functional.Tests.Debugging.ViewTrainingOutput [16ms]\r\n  Error Message:\r\n   System.InvalidOperationException : Operations that change non-concurrent collections must have exclusive access. A concurrent update was performed on this collection and corrupted its state. The collection's state is no longer correct.\r\n  Stack Trace:\r\n     at System.Collections.Generic.Dictionary`2.FindEntry(TKey key)\r\n   at System.Collections.Generic.Dictionary`2.ContainsKey(TKey key)\r\n   at Microsoft.ML.Functional.Tests.Debugging.LogWatcher.ObserveEvent(Object sender, LoggingEventArgs e) in /Users/runner/runners/2.166.3/work/1/s/test/Microsoft.ML.Functional.Tests/Debugging.cs:line 204\r\n   at Microsoft.ML.MLContext.ProcessMessage(IMessageSource source, ChannelMessage message) in /Users/runner/runners/2.166.3/work/1/s/src/Microsoft.ML.Data/MLContext.cs:line 135\r\n   at Microsoft.ML.Runtime.HostEnvironmentBase`1.Dispatcher`1.DispatchCore(IMessageSource sender, TMessage message) in /Users/runner/runners/2.166.3/work/1/s/src/Microsoft.ML.Core/Environment/HostEnvironmentBase.cs:line 314\r\n```\r\n\r\nSince the dictionary is being modified by multiple threads, I am changing this to a ConcurrentDictionary.\r\n"""
613037668,5095,b'Suxi/no transformer',"b""This is a tempory PR to review root cause analysis's implemention by using no transformer. Original one is [here](https://github.com/dotnet/machinelearning/pull/4925)\r\n\r\n\r\n- [ ] Fixes #4960 .\r\n\r\n"""
612863000,5094,b'Re-enabled BinaryClassifierSymSgdTest with platform-specific baselines',b'\r\nThis PR re-enables the unit test `BinaryClassifierSymSgdTest()` on MacOS and Linux by adding MacOS and Linux-specific baselines for the test. The test works properly on these builds as the platform-specific baselines are consistent between each run.'
612672218,5091,b'Pass in caught exception to inner exception in LoadTFSession',b'Fixes #4409 \r\n\r\n## Description\r\nPassing in the caught exception as an inner exception to retain stack trace and information.\r\nI was unable to find a suitable place to add a unit test for this feature. Please feel free to instruct me where I will be able to add that if needed.\r\n\r\n'
612246446,5090,b'Adding vector tests for KeyToValue and ValueToKey',b''
611694277,5087,b'Debugging tests disabled on Linux and MacOS builds',"b'Debugging PR for diagnosing tests disabled on Linux and MacOS builds:\r\n\r\nDisabled tests - Disabled build(s):\r\n- `BinaryClassifierSymSgdTest()` - Linux, MacOS\r\n- `TextNormalizingOnnxConversionTest()` - Linux\r\n- `MatrixFactorizationSimpleTrainAndPredict()` - MacOS\r\n\r\nReport:\r\n- `BinaryClassifierSymSgdTest()`\r\n  - Fixed, added new baselines for Linux and MacOS builds with PR #5094 .\r\n  - Test re-disabled on Linux due to varying baselines.\r\n- `MatrixFactorizationSimpleTrainAndPredict()`\r\n  - The baseline on MacOS varies greatly. In 10 consecutive tests, the calculated MSE ranged between 0.586040127051849 to 0.625339146273452. With these results, a tolerance of `Math.Pow(10, -1)` is required.\r\n  - I have been able to reproduce this issue on my own MacOS computer.\r\n  - Issue stems from [here](https://github.com/cjlin1/libmf/blob/e70b9a32f7df32cce961bbbb997da074759a16fe/mf.cpp#L1121).  This random_shuffle libmf function shuffle values with a rand(). With no given seed, it behaved non-deterministically. By commenting out this shuffling, the MSEs on MacOS and Windows are now very close, within 2 decimal digits, and these are consistent.\r\n   - Fixed with PR #5121 \r\n- `TextNormalizingOnnxConversionTest()`\r\n  - Will be fixed when Issue #5093 is fixed.\r\n  - This test fails on the Linux Net CoreApp 2.1 builds on Linux with the following error:\r\n\r\n  - > System.InvalidOperationException : Error initializing model :Microsoft.ML.OnnxRuntime.OnnxRuntimeException: [ErrorCode:RuntimeException] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/nn/string_normalizer.cc:87 onnxruntime::string_normalizer::Locale::Locale(const string&) Failed to construct locale with name:en_US.UTF-8:locale::facet::_S_create_c_locale name not valid:Please, install necessary language-pack-XX and configure locales\r\n\r\n  - The issue being faced here may be different than before, as the error being faced is related to locales. As this test passes on MacOS Net Core App 2.1 and Linux Net Core App 3.1, this may be a Linux Net Core App 2.1 or more specifically Ubuntu Net Core App 2.1 issue.\r\n\r\n  - The ONNX team faced the exact same issue as this, and they have fixed it with [this PR](https://github.com/onnx/backend-scoreboard/pull/19), which installs the appropiate locales in their docker instance.\r\n'"
611465827,5085,b'Update OnnxTransformer Doc XML',b'Update for #4707.\r\n\r\nUpdates the doc XML to use the latest dynamic API.'
611269075,5084,b'Added SciSharp.TensorFlow as a dependency to Microsoft.ML.TensorFlow',"b'Fix #4065. Added package reference to `SciSharp.TensorFlow.Redist` in `Microsoft.ML.TensorFlow`, and removed this package reference from `Microsoft.ML.Tests`, as `Microsoft.ML.Tests` already has a reference to `Microsoft.ML.TensorFlow.`\r\n\r\n`Microsoft.ML.Tensorflow.csproj` did not include a package reference to `SciSharp.TensorFlow.Redist`, which resulted in users needing to manually install this NuGet package, as demonstrated in issue #4065. I confirmed that this fix works [here](https://github.com/dotnet/machinelearning/issues/4065#issuecomment-623009939).'"
611211363,5082,b'Use KeyTypeAttribute from Schema in CreateTextLoader',b'Fixes #2642 \r\n\r\nThis PR reads the KeyTypeAttribute from the schema of the incoming type and sets that on the corresponding column when loading a text file using the CreateTextLoader.\r\n\r\n'
611089133,5081,b'fix x86 crash',b'fixes https://github.com/dotnet/machinelearning/issues/1216.\r\n\r\nTreeEnsembleCombiner has a bug that causing byte array out of range and corrupts heap\r\n\r\n'
610983267,5080,b'Added SQLite database to test loading of datasets in non-Windows builds',"b""Fix #4156 and related to #4175 \r\n\r\nMSSQL databases are not supported on Mac and Linux builds. As such, I've generated an equivalent SQLite database, and re-activated these disabled Iris tests so that these unit tests can run on non-Windows builds and produce equivalent test results.\r\n\r\nReactivated tests on Linux and MacOS list:\r\n\r\n- `IrisLightGbm()`\r\n- `IrisLightGbmWithLoadColumnName()`\r\n- `IrisVectorLightGbm()`\r\n- `IrisVectorLightGbmWithLoadColumnName()`\r\n- `IrisSdcaMaximumEntropy()`"""
610968953,5079,b'ColumnSelectingTransformer now infers ONNX shape',"b""ColumnSelectingTransformer wasn't inferring the ONNX shape during ONNX export. This was causing issues when the shape needed to be known. This PR adds in the shape inference step by removing the skip flag to skip it."""
610613408,5078,b'Test ensemble combiner sum sq',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
610612188,5077,b'Test ensemble combiner scale',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
610607981,5076,b'Test ensemble combiner max abs',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
610605549,5075,b'Test ensemble combiner add scale',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
610603350,5074,b'try replace DotProductDense',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
609396695,5072,b'Test PR to view CI Generated baselines',"b'The purpose of this test PR is to view the benchmarks generated on CI builds, and to verify that the results are exactly the same as the expected benchmarks.\r\n'"
609256989,5071,"b""Fix MatrixFactorization trainer's warning""","b""### Problem to fix\r\nMatrixFactorization's default options will throw a warning msg `Warning: insufficient blocks may slow down the trainingprocess (4*nr_threads^2+1 blocks is suggested)` when running on PC with more than 10 threads.\r\n\r\n### Cause\r\nThe warning msg is from libmf, which will check nr_bin and nr_thread, if nr_bin <= 2* nr_thread, it will show that warning. \r\n\r\nMatrixFactorization uses `max(20, 2*nr_thread)` to initialize nr_bin, when nr_thread < 10, it's fine because nr_bin will be 20, which is greater than 2\\*nr_thread, but if nr_thread is >= 10, nr_bin's value will be 2\\*nr_thread, which is less than 2*nr_thread + 1 and trigger warning.\r\n\r\n### Fix\r\ninitialize nr_bin with 2 * nr_threads + 1. \r\n\r\n### Related issue\r\n#5067 """
608757001,5068,b'Fixed baselines between Debug and Release builds',"b""Most baselines in SingleDebug and SingleRelease test baseline folders are differing in fields that are not actively compared. Remaining baselines are differing in certain log-loss reduction values at the 10^-5'th digit, due to how the Release compiler does not round up or down values. \r\n\r\nThis PR handles such baselines by removing them from SingleDebug and SingleRelease folders, and by adding to Common folder. This PR also removes the checking of SingleDebug and SingleRelease folders in `BaseTestBaseline.GetBaselinePath()`."""
608562065,5066,"b""Update CodeGenerator's console project to netcoreapp3.1""",b'Issues\r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/684\r\n\r\nAnd it also fix this bug\r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/714'
608474995,5064,b'X86 test',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
607946041,5063,b'Added time series and DateTimeTransformer tests that load its input from a file',"b'* Modified a test in TimeSeriesDirectApi.cs to load its input from a file, instead of loading from an enumerable.\r\n* Added 2 tests for DateTimeTransformer to show and test how to load datetime objects from a text file.\r\n\r\n'"
606108479,5060,b'Added logging for when specific configuration baseline is used',"b'Certain unit tests require configuration specific baselines, for when they differ from ""normal"" baselines. A unit test may also use more than one configuration, such as `linux-x64` and `netcoreapp31`. \r\n\r\nThis PR adds logging for each unit test that utilizes a configuration specific baseline. This PR also corrects a small typo.'"
606057417,5059,b'simplify baseline files',"b'many baseline file in SingleDebug and SingleRelease folder are identical, move them to Common folder to avoid duplication\r\n\r\n'"
605941817,5058,b'try put nuget packages to shared folder instead of local to save disk\xe2\x80\xa6',"b""\xe2\x80\xa6 space\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
605927008,5057,b'Fixed X64Fact tests',b'Fixed X64Fact tests with x86 specific baselines added\r\n\r\nCurrently obtaining baselines from x86 builds from CI'
605921473,5056,b'Let ImageLoadingTransformer dispose the last image it loads',"b""Fixes #4126.\r\n\r\nBy investigating issue #4126 I found out that `ImageResizingTransformer `disposed the last input Bitmap object it resized (i.e. _only_ the last image object in the input dataset). When working with in-memory images (i.e. NOT loaded with `ImageLoaderTransformer`) this is inadequate, since the `ImageResizingTransformer `will dispose the last image in the dataset, and the user won't be able to use that image again. Particullarly, issue #4126 happened when running Cross Validation with a pipeline that included applying `ImageResizingTransformer `to in memory images: when scoring the first model during cross validation, the last image of the input dataset got disposed, and when trying to score the second model, the image wasn't there, and a exception was thrown.\r\n\r\nThe only reason I found as to why `ImageResizingTransformer` had this behavior, is because `ImageLoadingTransformer` actually disposes all the images it loads except for the last one ([link](https://github.com/dotnet/machinelearning/blob/919bc8b886a6bc20c5022e8dad00f84bc1248236/src/Microsoft.ML.ImageAnalytics/ImageLoader.cs#L226-L230)). So assuming this is the only reason for `ImageResizingTransformer's `disposer, I simply moved the disposal mechanism of the last image to `ImageLoadingTransformer`.\r\n\r\nI added two tests that used to throw exceptions without the changes on this PR. And I also manually tested with the debugger's profiler that the last image got correctly disposed when using `ImageLoadingTransformer`."""
604583362,5048,b'[LightGBM] fix bug for empty categorical values',b'ping @najeeb-kazmi  and refer to #3659\r\n\r\nFixes #3659'
604444030,5047,b'NetCore3.1 generates different test result issue',"b'Address issues that NetCore 3.1 generates different test result:\r\nhttps://github.com/dotnet/machinelearning/issues/1096\r\nhttps://github.com/dotnet/machinelearning/issues/3856\r\n\r\nThe difference comes from CPUMath using different instruction set:\r\n1. dotnet framework and dotnet core 2.1 uses CpuMathUtils.netstandard that uses SSE instruction set through CPUMath native library;\r\n2. Since dotnet core 2.2, dotnet core has direct support for AVX and SSE hardware Intrinsics so dotnet core 3.1 use AVX or SSE instruction set directly. Dotnet core 3.1 uses CpuMathUtils.netcoreapp that uses AVX, SSE or direct floating point calculation depending on hardward avaibility. \r\n\r\nAVX and SSE generates slightly different result due to nature of floating point math.\r\nUse below issue to track: #5044\r\n\r\nSo in short term we are separating test baseline for netcore 3.1 until we add AVX support at CPUMath native library.\r\n\r\n'"
604377278,5046,b'Removed references to NeuralTreeEvaluator.dll and cleaned up dependent functions',"b'Fixes Issue #1443 \r\n\r\n`NeuralTreeEvaluator.dll` does not exist in the ML.NET repository. As such, it makes sense to clean up functions dependent on this .dll, which was carried from TLC.'"
604355680,5045,b'Added ability to compare configuration specific baselines',b'This PR enables BinaryClassifierSymSgdTest for x86 runs by adding a separate x86 specific baseline. In the process it also adds the ability enable other tests to have configuration specific baselines.\r\n\r\nSome background on why configuration specific baseline is needed here:\r\nThe SymbolicSgd trainers call into native code in SymSgdNative.dll which in turn call into MklImports.dll to compute dot products. The cblas_sdot call in MKL returns different results for identical input on x86 and x64 based on computation history. MklImports.dll is built from the Intel MKL SDK. Trying to fix the MKL across x86 and x64 is is a much bigger work item than we have time for. \r\nIt is more important for us to enable these tests. So I am attempting this fix by providing different baselines for x86 and x64.\r\n\r\n'
604301759,5043,b'move CI windows build to netcore public pool',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
603570970,5041,b'Converted potentially large variables to type long',"b""Fixes #3228\r\n\r\nAs explained in Issue #3228, very large datasets more than 2.14 billion rows of data can cause overflow when, say, the sum of these labels are obtained, **and** if these are stored as ints. This PR converts arrays and matrices for storing labels and features in their respective histograms from type `int` to type `long`. In addition, this PR updates the version of NaiveBayesMulticlassTrainer's Loader to preserve backwards compatibility. """
602360224,5040,b'Fix official build',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
601593889,5039,b'Lag lead operator',b'LagLeadOperator copies values from prior (lag) rows or future (lead) rows.\r\n\r\n'
601525122,5038,b'clarifying parameters on time series',"b""We are excited to review your PR.\r\n\r\nSome context:\r\n\r\nAlso note that, here we are talking about three different parameters:\r\n1.\tseriesLength is the length of the whole timeseries.\r\n2.\ttrainSize is the number of points from the beginning of the series that are used for training.\r\n3.\twindowSize is the size of rolling window during the training of SSA.\r\n\r\nThe first parameter is dictated by the series and even though it\xe2\x80\x99s not used in SSA, it\xe2\x80\x99s not meaningful for the user to \xe2\x80\x9cset\xe2\x80\x9d it arbitrarily. The third parameter is *recommended* to be at least twice as the biggest seasonality in the data that the user care about. The second parameter must be more twice the third parameter. \r\n\r\nSo to summarize we should have:\r\n1.\t2*Seasonality length < windowSize\r\n2.\t2*windowSize < trainSize\r\n3.\ttrainSize < seriesLength\r\n\r\nThe first constraint is recommended while the other two are required.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
601417598,5037,b'Forecasting pivot featurizer',"b'ForecastingPivotFeaturizer takes in columns that are 2D vectors, and ""pivots"" them into single value columns while dropping null values. It currently supports output from LagLeadOperator and RollingWindowFeaturizer.'"
601399919,5036,b'Update package dependency in CodeGenerator',"b'This PR \r\n- make CodeGenerator depends on a release AutoML package instead of project, to avoid the latest change in model load/unload mechanism, which will break ModelBuilder. '"
601281150,5035,b'Rolling Window',b'RollingWindow does rolling window calculations per grain (kinda like a composite unique key by combining multiple columns). It currently provides min/mean/max.'
601245173,5034,b'Short grain dropper',"b'ShortGrainDropper makes sure that each grain combination (kinda like a composite unique key by combining multiple columns) has the specified minimum number of rows. If it does not, then the all the rows corresponding to that grain are dropped.'"
600667294,5031,b'Handle NaN optimization metric in AutoML',"b'Fixes #4663 \r\nFixes #5042\r\n\r\nIn AutoML, `CrossValSummaryRunner` is invoked if the dataset contains less than 15000 rows. It runs 10-fold cross validation on it, and then returns the model from the fold with the best optimization metric. It does this by looking for the index of the model with the best metric in the list of run results, and returning the element at this index.\r\n\r\nIf the metric in all 10 folds is `NaN`, then this index is `-1`, resulting in an `IndexOutOfRangeException`.'"
600629039,5029,b'Dotnetcore3.1 bench1',"b'allow tests to run on dotnet core 3.1:\r\n1. change back to Fact as some tests are passing on dotnet core 3.1\r\n2. change to use lower precision for dotnet core 3.1\r\n3. fix bug in baseline compare, when compare number with allowed precision, space and tab should not affect the result like below case:\r\n\r\nthey should be same if we set digitsOfPrecision = 3 (should remove space and tab which is only for format before compare result):\r\n\r\n![image](https://user-images.githubusercontent.com/55860649/79395608-d6f7ab00-7f2e-11ea-92ea-4af80b9660c8.png)\r\n\r\n'"
600022117,5027,b'Update ForecastBySsa function specifications and add seealso',"b'Fixes #5007\r\n\r\nUpdated XML documentation for `ForecastBySsa`, and added a see-also section for `SsaForecastingEstimator`with `ForecastBySsa`, similar to how it has been done with [SsaSpikeEstimator](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.timeseries.ssaspikedetector?view=ml-dotnet).\r\n'"
599904333,5026,b'fix 2 build issues',b'fix 2 build issues in nightly build pipeline and machinelearing full pipeline:\r\n1. _targetFramework from netcoreapp3.0 to netcoreapp3.1\r\n2. force tls1.2 when connect to https://dotnetcli.azureedge.net as this address only accepts tls 1.2 and 1.3: https://www.ssllabs.com/ssltest/analyze.html?d=dotnetcli.azureedge.net&s=72.21.81.200\r\n\r\n'
599208774,5025,b'trouble shoot test hanging',b'https://dev.azure.com/dnceng/public/_build/results?buildId=599069&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&t=4390109a-3c77-5b7c-bf35-d176b654cd3c\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=599067&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\n'
599200159,5024,b'move ubuntu and centos to agent pool with larger disk space',"b'Ubuntu and CentOS is facing disk space issue, move to agent pool with larger disk space, this pool has 120 machines so should be good for use:\r\n\r\nhttps://helix.dot.net/api/2019-06-17/info/queues\r\n\r\n""Purpose"": ""Build"",\r\n    ""Architecture"": ""AMD64"",\r\n    ""IsAvailable"": true,\r\n    ""IsInternalOnly"": true,\r\n    ""IsOnPremises"": false,\r\n    ""OperatingSystemGroup"": ""linux"",\r\n    ""PreInstalledImage"": null,\r\n    ""PreparedImage"": null,\r\n    ""QueueId"": ""BuildPool.Ubuntu.1604.Amd64.Open"",\r\n    ""QueueDepth"": 0,\r\n    ""ScaleMin"": 0,\r\n    **""ScaleMax"": 120,**\r\n    ""UserList"": ""helix-buildagent-bot"",\r\n    ""WorkspacePath"": ""/datadisks/disk1/workspace""\r\n\r\n'"
599158269,5023,b'Fix SsaForecast bug',"b'remove static field in PolynomialUtils, use local variable instead avoid random test failure\r\n\r\n'"
598659671,5021,b'LoadColumnName support in TextLoader and auto map class members ',b'This pull request resolves #4480.\r\n\r\nThese features were add in this pull request:\r\n* Support of `LoadColumnName` attribute in `TextLoader` class (when loaded file has headers).\r\n* Possibility to ignore a member when using `CreateTextLoader` using the `LoadColumnIgnoreAttribute`\r\n* Feature to map the `TInput` properties/fields name to column of TextLoader (when loaded file has headers)\r\n'
598597880,5019,b'wip - Add Sweepable Pipeline',"b""Allow users to sweep over pre-defined paramaters with similar API of creating/training a pipeline using sweepers defined in `Microsoft.ML.Sweeper`.\r\n\r\nIn the current state, only `RandomSweeper` and `GridSearchSweeper` is provided, and other sweepers like `SMAC`  will be added soon.\r\n\r\nRight now, only one sweepable trainer is allowed in each pipeline, however, we can support multi-trainer easily with a few lines change.\r\n\r\nOne of a sample pipeline here, it uses `RandomSweeper` over a user-defined paramater set and sweeps over 20 times\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2ba9ec6139a8dae455da61442c6f033e44e2766f/test/Microsoft.ML.AutoML.Tests/AutoEstimatorChainTest.cs#L24\r\n\r\nAnd part of it's Output\r\n```\r\nAlpha=0.7001 Lambda=0.11 LearningRate=0.001\r\nRMSE: 3.08841817087814\r\nAlpha=0.7001 Lambda=0.01 LearningRate=0.0709999949\r\nRMSE: 0.88847094121806\r\nAlpha=0.3001 Lambda=0.91 LearningRate=0.021\r\nRMSE: 1.33374709132294\r\n\r\n...\r\n```\r\n\r\n### Why I create this PR\r\nAuto sweeping parameter is quite a useful feature in Automate ML, AutoML.Net supports it internally but those API is not exposed and sweeping value is fixed, moreover, it only supports a few trainers. It will be great if ML.Net has some external API to allow users to sweep over trainer's parameters on the pipeline level. \r\n\r\n### What will be next\r\n- allow sweeping Enum and Int type\r\n- allow user sets up discrete numeric options using `OptionBase` class.\r\n- adding more sweepers (SMAC....)\r\n- ( if I have time ) create a similar API experience with what AutoML.Net has (saying, creating customer experiment based on pipeline, providing CV training and evaluation, and generate CodeGen afterwards)\r\n"""
598436872,5018,b'Support for Categorical features in CalculateFeatureContribution of LightGBM',"b'Fixes #3272\r\n\r\nAs explained [here](https://github.com/dotnet/machinelearning/issues/3272#issuecomment-611849910), `CalculateFeatureContribution` would throw an exception when used on LightGBM models that had `UseCategoricalSplit` enabled, because there was no support to calculate feature contribution for categorical features. Here I add that support, and one test to replicate the original scenario were an exception was thrown.'"
598242659,5017,"b""Fixing build in UNIX systems that don't have en-US as default culture""","b'This Pull Request fixes #5016 as is set the language to en-US for the shell session, fixing the build problem existing in the cultures that uses comma as decimal separator.\r\n\r\n'"
598019039,5015,b'Lag Lead operator',"b'This PR depends on PR #4993, because that PR is not in yet this PR says it is making more changes then it is. The only new changes this pr brings in once that PR goes in is the LagLead operator. So you can only review the LagLeadOperator files and tests and can ignore the others. This branch will be updated when that other PR gets merged.\r\n\r\nLagLeadOperator copies values from prior (lag) rows or future (lead) rows.'"
598018355,5014,b'Forecasting Pivot Featurizer',"b'This PR depends on PR #4993, because that PR is not in yet this PR says it is making more changes then it is. The only new changes this pr brings in once that PR goes in is the ForecastingPivot featurizer. So you can only review the ForecastingPivotFeaturizer files and tests and can ignore the others. This branch will be updated when that other PR gets merged.\r\n\r\nForecastingPivotFeaturizer takes in columns that are 2D vectors, and ""pivots"" them into single value columns while dropping null values. It currently supports output from LagLeadOperator and RollingWindowFeaturizer.'"
598005423,5013,b'MurmurHash Onnx Export',"b""The following data input types are currently not supported by onnxruntime's murmurHash operator: float, double, ulong, long and ordered hashing(vectors). Once added, ml.net will be able to support them as well. """
597167396,5012,b'Avoid propagating some input columns when applying an Onnx model',"b'Fixes #4970 \r\n\r\nAfter discussing this issue with @harishsk we agreed that the way to go is to drop all the input columns that are used as inputs of the onnx model that is applied by an `OnnxTransformer`. I\'ve added the `ColumnSelectingOnnxTestColumnPropagation` where I explain and show more clearly what effects this has on different scenarios.\r\n\r\nSince the `OnnxTransformer` is a `RowToRowTransformerBase`, it can\'t drop columns only add columns. In fact, it seems that there\'s no transformer that do both dropping and adding columns.\r\n\r\nTo solve this, changes needed to be made in `RowToRowTransformerBase `to let `OnnxTransformer `override some methods, so that it can have more control on the output schema. This way the `OnnxTransformer `now creates a `OnnxDataTransform `which in turn uses the same `OnnxTransformer.Mapper `that always existed, but now it also uses a `OnnxTransformer.Bindings` that enable dropping columns while also adding the new columns added by the mapper. This is different from the previous behavior, where the `RowToRowTransformerBase `would return a `RowToRowMapperTransform `which used the typical `ColumnBindings `which only add columns to the input but don\'t drop columns from it.\r\n\r\nNOTE: I have left several ""//MYTODO"" comments with thoughts and questions for myself, which shall be removed before merging this PR. I\'ve also added some comments here on GitHub pointing to the thoughts and questions that I find more important to address first.\r\n'"
596970371,5011,b'fix SsaForecast test',b'PolynomialUtils.FindPolynomialCoefficients is not thread safe. \r\nPolynomialFactor class contains static fields Destination that be override by other threads during test execution. \r\nLock method call to FindPolynomialCoefficients to make it thread safe.\r\n\r\n'
596915339,5010,b'Move agent pool',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
596242034,5008,b'clean nuget package to save disk space',"b'run out of disk space on CI, so clean up nuget packages to save disk space:\r\n1. delete windows and mac os packages for linux\r\n2. delete windows and linux packages for mac os\r\n3.delete linux and mac os packages for windows\r\n\r\n'"
596055190,5006,b'Rolling window',"b'This PR depends on PR #4993, because that PR is not in yet this PR says it is making more changes then it is. The only new changes this pr brings in once that PR goes in is the RollingWindow featurizer. So you can only review the RollingWindow files and tests and can ignore the others. This branch will be updated when that other PR gets merged.\r\n\r\nRollingWindow does rolling window calculations per grain (kinda like a composite unique key by combining multiple columns). It currently provides min/mean/max.'"
596014149,5005,b'Short grain dropper',"b'This PR depends on PR #4993, because that PR is not in yet this PR says it is making more changes then it is. The only _new_ changes this pr brings in once that PR goes in is the Short grain dropper. So you can only review the ShortGrainDropper files and tests and can ignore the others. This branch will be updated when that other PR gets merged.\r\n\r\nShortGrainDropper makes sure that each grain combination (kinda like a composite unique key by combining multiple columns) has the specified minimum number of rows. If it does not, then the all the rows corresponding to that grain are dropped.'"
595585054,5004,b'disable tensorflow tests to save disk space',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
595516660,5003,b'Updated MultiFileSource.Load to fix inconsistent behavior with multiple files',"b'Fixes #4982 \r\n\r\nMultiFileSource\'s `Load` can now accommodate loading from multiple paths. Also added more test cases for the additional features of `MultiFileSource`.\r\n\r\nExample usages:\r\n`textLoader.Load(""Data/*"");`\r\n`textLoader.Load(""DataFolder/.../*"");`\r\n`textLoader.Load(""DataFolder/SubFolder1/*"", ""DataFolder/SubFolder2/*"");`\r\n`textLoader.Load(""DataFolder/SubFolder1/1.csv"", ""DataFolder/SubFolder2/2.csv"");`'"
595334349,5002,b'add projects capability in CodeGenerator',"b'if generated by ModelBuilder, will add \r\n`<ProjectCapability Include=""ModelBuilderGenerated"" />`\r\nelse\r\n`<ProjectCapability Include=""MLNETCLIGenerated"" />`\r\nto .Model and .Console project\r\n\r\n'"
593699160,5000,b'CountFeatureSelectingEstimator no selection support',"b'**Issue**: The GatherElements ONNX operator used by SlotsDroppingTransformer (transformer for CountFeatureSelectingEstimator) has issues when there\'s nothing selected, so mlnet needs to handle this case separately. \r\n\r\n**This PR**\r\n- Fixes the issue mentioned above\r\n- Modifies the estimator\'s test to be more robust\r\n\r\n**Other issues:**\r\n- There\'s no support for string initializing in ONNX, which prevents us from handling the case where no string columns get selected.\r\n- The documentation for CountFeatureSelectingEstimator is ambiguous. It states that it supports input as  ""vector or scalar of numeric, text or key data types"". However, only strings, doubles, and singles are supported. \r\n\r\n'"
593695555,4999,b'fix TestCancellation hanging',"b'fix TestCancellation, this test sometimes hangs like below:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=584913&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&t=4390109a-3c77-5b7c-bf35-d176b654cd3c \r\n\r\n'"
593388106,4998,b'Add SrCnnEntireAnomalyEstimator',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\nSee Issue #5053 for description of this change."""
593010362,4997,b'fix tensorflow test hanging issue',"b'fixed 2 issue of tensorflow tests:\r\n1. fix issue in Resource Manager, use ReadAsync instead of Read to let thread timeout corrently\r\n2. move download ImageSet to constructor of test class to avoid duplicate download for different tests\r\n\r\n'"
592276680,4996,b'add some logs and see if download images cause the hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
592228503,4995,b'Removed WeakReference<IHosts> already cleaned up by GC',"b'Fixes #4914 \r\n\r\nWeakReference<IHost> objects are stored in `_children`. Occasionally Garbage Collector cleans up these WeakReference<IHost>s and change their `target` value to null, but their `WeakReference`s in the `List _children` are never removed. This PR explicity removed those `WeakReference` objects that have null targets.\r\n\r\n`List.RemoveAll()` has a time-complexity of O(n) where n is the number of objects in `List`.'"
592179452,4994,b'Bitmap(file) locks the file.',"b'Fixes #4585 \r\n\r\nConstruct ""new Bitmap(file)"" locks the underlying file for the lifetime of Bitmap. Use workaround suggested https://stackoverflow.com/questions/6576341/open-image-from-file-then-release-lock\r\n\r\n'"
592158198,4993,b'Update Featurizers to latest nuget.',b'This code brings the Featurizers project up to date with the latest code from the native featurizers.\r\nIt also adds support for CentOS7 that was not there originally.'
592140076,4992,b'Remove WeakReference list in PredictionEnginePoolPolicy.',"b'Accesses to this list are not thread-safe because we can be enumerating it on one thread (in Return) while another thread adds to it (in Create).\r\n\r\nThe list is unnecessary because the PredictionEngine will always be ""rooted"". Either it was being held in memory by someone who got the PredictionEngine from the pool, or it is being held by the ObjectPool itself. So it won\'t ever be GC\'d, and the WeakReference is not doing anything.\r\n\r\nAlso, inherit from PooledObjectPolicy instead of IPooledObjectPolicy, so it can take the ""fastPolicy"" path in DefaultObjectPool. (See https://github.com/dotnet/extensions/pull/318).\r\n\r\nFix #4981'"
591555128,4991,b'test tensorflow test hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
591498284,4990,b'trouble shoot ssaforecast',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
591454369,4989,b'Added the assembly name of the custom transform to the model file',"b'Fixes #4965 \r\nRight now when a custom transformer is used, the model file retains the name of the transformer as a string. This is not enough information to re-instantiate the custom transformer when the model is loaded from file. If the assembly containing the custom transformer is not already registered with the component catalog, then the model will fail to load. \r\nTo fix this, I have incremented the model version and am now saving the assembly name of the transform with the model. \r\n'"
591359897,4988,b'enable and disable tests',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
590777775,4985,b'fix benchmark test hanging issue',"b""benchmark test is hanging sometime on dotnet core 3.0 and 3.1 like below:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=568308&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=565081&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=563397&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\n\r\n\r\nthe reason of hanging is explained in comments like below:\r\n        // Don't use BaseTestClass's GetDataPath method instead for benchmark.\r\n        // BaseTestClass's static constructor is not guaranteed to be called before\r\n        // benchmark running (depending on CLR version this has different behaviour).\r\n        // The problem with executing BaseTestClass's static constructor when benchmark\r\n        // is running is it sometime cause process hanging when the constructor trying \r\n        // to load MKL, this is related to below issue:\r\n        // https://github.com/dotnet/machinelearning/issues/1073\r\n"""
590683567,4984,b'Remove March survey link',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
590674449,4983,"b'Remove survey link, clean up README'","b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
589503938,4979,b'try fix benchmark hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
589427250,4978,b'Fixed & Reactivated AutoFitImageClassificationTrainTest hanging by freeing old Tensor objects',"b'`AutoFitImageClassificationTrainTest` is occasionally hanging, even after PR #4939 . The issue here is that Tensor objects saved in `ITransformer model` (now renamed as \'estimatorModel`) are not being automatically freed by C#\'s Garbage Collector, as these Tensor objects are made in TensorFlow\'s C libraries. \r\n\r\n**Edited on 4/9/2020**: This PR makes ExperimentResult and CrossValidationExperimentResult implements IDisposable to free remaining C Tensor objects in memory in a deterministic manner. This method of freeing these objects ensures the user will not face null-reference/use-after-free errors when trying to access the model, as this clean up is done after GC runs.\r\n\r\n**Edited on 4/9/2020**: I confirmed that this fixes the hanging ""out of memory"" and/or ""long running test"" issues by running `AutoFitImageClassificationTrainTest` for 100 iterations, in addition to running all the other unit tests in [this build](https://dev.azure.com/dnceng/public/_build/results?buildId=595447&view=logs&j=9dffbc46-9322-5a58-fb37-6d66c044e90d&t=11098bf6-eb78-583b-8eab-f14f48444a6b). In all of these builds, none of the issues described occur. These builds all time-out because running 100 iterations of `AutoFitImageClassificationTrainTest` takes more than 1 hour.\r\n\r\nI have also reactivated the `AutoFitImageClassificationTrainTest` unit test with this fix.\r\n\r\n**Edit: **'"
588685807,4976,b'Updated constructor of ImageLoadingTransformer to accept empty imageFolder paths',"b'In certain ML.NET/ONNX samples, the provided path for the directory containing images for loading may be empty, and output the following exception:\r\n\r\n> System.ArgumentException: Directory """" does not exist.\r\n\r\nThis PR is so that the provided imageFolder path that is provided to the constructor of `ImageLoadingTransformer` may be null **or empty**.'"
588055996,4974,b'Fixes OneHotEncoding Issue',"b""OneHotEncoding always increases the dimension by one, which is causing issues with Nimbus.\r\nSee: https://github.com/microsoft/NimbusML/issues/472\r\n\r\n- Added shape info to make models more easy to read\r\n- Replaced ReduceSum with Squeeze (makes more sense imo)\r\n- Isolated KeyToVector test to verify several outputKind modes - Skipping OneHotEncodingEstimator.OutputKind.Binary for now, since this mode is not working and it'll require implementation of KeyToBinaryVector """
588019759,4973,b'Disabled AutoFitImageClassificationTrainTest for test stability',"b'Disabled `AutoFitImageClassificationTrainTest `from runs on CI, as it continues to hang on builds.\r\n'"
587899751,4972,b'Simplify CodeGen - phase 2',b'This PR includes the following updates in CodeGen\r\n- switch train and evaluate order in ModelBuilder.cs. linked issue: [Train and Evaluate order](https://github.com/dotnet/machinelearning-modelbuilder/issues/421)\r\n- filter out ignored cols in programs.cs when printing column value to console. linked issue: [Filter out columns that in ignore-col in console output](https://github.com/dotnet/machinelearning-modelbuilder/issues/580)'
587689159,4971,b'[WIP] Avoid propagating some input columns when applying Onnx models',"b'The goal of this PR is to:\r\n1. Fix #4970 regarding `ColumnSelectingTransformer` onnx exported models not working as expected when applying it with ML.NET\r\n2. Avoid propagating the input columns through an `OnnxTransformer`. This is a new requirement that was discussed offline with @harishsk . The idea is that the output schema of the onnxtransformer should contain `only` a column for each output of the onnx model. Until now, since OnnxTransformer is a `RowToRowTransformer`, the input schema was propagated to the output.\r\n\r\nFixing point number 2 would actually fix point number 1, given the way that the onnx export works today for `ColumnSelectingTransformer `(where the dropped columns are removed from the onnx model output inside the onnx graph).\r\n\r\n'"
587342172,4969,b'Skip hanging TensorFlowImageClassificationEarlyStopping on Linux',b'The unit test `TensorFlowImageClassificationEarlyStopping`occasionally hangs on Linux builds. This PR is so that `TensorFlowImageClassificationEarlyStopping` is skipped on these builds.'
587321198,4968,b'upgrade benchmark dotnet package to latest version',"b'As we have upgrade CI run from netcore 3.0 to netcore 3.1, we need also to upgrade benchmark dotnet to latest version which has netcore 3.1 support\r\n\r\n'"
587228816,4967,b'Updated build docs for .NET Core 3.1',"b'Updated Windows and Unix build docs for .NET Core 3.1.\r\n\r\nSome specific things to note:\r\n\r\n- In addition to other platforms, .NET Core 3.1 supports Ubuntu **16.04**+ and macOS 10.13 (High Sierra)\r\n- Visual Studio 2019 Version **16.4 or higher** is needed for .NET Core 3.1.\r\n- /src files always build on both `netstandard2.0 `and `netcoreapp3.1`, and /tests only build on one target framework at a time: `netcoreapp2.1`, `net461 `or `netcoreapp3.1`'"
587180719,4966,"b""Updated OnnxScoringEstimator's documentation""","b""PR #4919 changed the way users should work with the Onnxruntime's nugets, now they should include either Onnxruntime or Onnxruntime.Gpu nuget along the OnnxTransformer one.\r\n\r\nI also updated a couple of other things that weren't right anymore.\r\n\r\nPlease, let me know it I should update the docs anywhere else.\r\n\r\nFixes #4872 """
586583823,4963,b'Fixes multiclass logistic regression',"b'Fixes dimension bug for MulticlassLogisticRegression and SdcaMaximumEntropy in Nimbus (https://github.com/microsoft/NimbusML/issues/473)\r\nUnsqueeze was adding dimension 0 to the label tensor - to get shape (1,#samples), instead of the expected shape (#samples, 1).'"
586517759,4962,b'enable 2 tests',b'these 2 tests not failed on full test set for 30 days so enable them:\r\nMulticlassLRTest\r\nBinaryClassifierLogisticRegressionBinNormTest\r\n\r\nhttps://dev.azure.com/dnceng/public/_test/analytics?definitionId=707&contextType=build\r\n'
585995175,4959,b'Suxi/refine code',b'test'
585686510,4957,b'Fixed path to Procdump files',b'Small bug fix in PowerShell command on the exact location where Procdump files are downloaded. The unzipping of a .zip file with `Expand-Archive` does not make a new folder specifically for the .zip file.'
585478512,4956,b'Created using Colaboratory',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
584754079,4955,b'Updated paths to test/sample datasets to local paths',"b'There are a lot of datasets/sample files that are downloaded from previous commits through ""raw.githubusercontent"" links. Almost all of these datasets are already available locally in the `test/data` directory. This PR edits references to these datasets so that they are no longer downloaded, and instead simply referred to locally.\r\n\r\nAlso added one dataset (`adult.txt`, 3.67 MB) that was downloaded from a ""raw.githubusercontent"" link. This dataset is small enough to be in `test/data` (biggest local dataset in ""test/data"" is `taxi-fare-train.csv` (24.9 MB).'"
584001656,4953,b'test for benchmark test hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
583555577,4951,b'Pin hash in DownloadTensorFlowSentimentModel()',"b'Changes `DownloadTensorFlowSentimentModel()` to download from a specific commit ID instead of master of the dotnet/machinelearning-testdata repo.\r\n\r\nOtherwise older versions of the ML.NET code will break when the remote repo is reorganized, or the files renamed.\r\n\r\nFurther explanation in comment below: https://github.com/dotnet/machinelearning/pull/4951#discussion_r395213145'"
583494501,4950,b'fix race condition for test MulticlassTreeFeaturizedLRTest',"b'method in TreeEnsembleFeaturizerTransform will be called from multi-threading, make variable ""temp"" as local variable to avoid race condition.'"
583379348,4949,b'Add allowBinary Flag to internal columnInference ',"b""Add allowBinary flag to internal columnInference API. to stop parsing label as `Boolean` type when it's not binary experiment."""
583013577,4946,b'Add new mode to get margin for SR anomaly detector',"b"" #4958 We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
580931672,4943,b'Fixed and Added unit tests for EnsureResourceAsync hanging issue',"b'Fixed EnsureResourceAsync by removing the helper function ResourceManagerUtils.CheckValidDownload and by using WebClientResponseUri (an extension of WebClient). Also added unit test for EnsureResourceAsync.\r\n\r\nResourceManagerUtils.EnsureResourceAsync(...) appends the relative URL of a resource to the $MlNetResourcesUrl environment variable (equal to ""https://aka.ms/mlnet-resources/"" by default).\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cdb1e4b38308d9256cbde9e740a14b3bc7d64c2f/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs#L34\r\n\r\nFor example, this occurs in the unit test WordEmbeddingsTest.TestWordEmbeddings(), where `sentimend.emd` is downloaded from https://aka.ms/mlnet-resources/Text/Sswe/sentiment.emd .\r\n\r\nThere is a possibility of this combined URL not correctly pointing to a resource, which is why this CheckValidDownload function exists:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cdb1e4b38308d9256cbde9e740a14b3bc7d64c2f/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs#L168-L184\r\n\r\nThis function was not correctly warning that the HTML of www.microsoft.com was downloaded (instead of an intended data file), as the size of microsoft.com is bigger than 4 kilobytes, and the site should have the sub-strings <head and <body (not <head> and <body>).'"
580904660,4942,b'Fixes KMeans scoring differences between ORT and OnnxRunner',"b""The KMeans ORT score predictions were off because batches were not being handled correctly. \r\nThere is still an issue because Nimbus produces int32 predictions, when they should be uint32, since ML.NET returns key values, but I plan on working on that separately, since it's probably a Nimbus bug. \r\n\r\n"""
580804713,4941,b'Add see also section to TensorFlowEstimator docs',b'Fixes #4932 '
580714924,4940,b'Fix xrefs in the LDSVM trainer docs',b'\r\n'
580137617,4939,b'Added IDisposable support for several classes',b'We have had a lot of instability in the Tensorflow tests. At least one of the issues has to do with memory leaks from ImageClassificationTrainer which holds references to the Tensorflow session and graphs. In order to fix this I have added IDisposable support for several of the classes involved in this scenario and fixed up the tests to call Dispose at the end of the tests.'
579736111,4938,b'Added working version of checking whether file is available for access',"b""Recently AutoFitRegressionTest() and AutoFitBinaryTest() have been failing occasionally on our MachineLearning-Full CI builds with the error:\r\n\r\n> System.IO.IOException : The process cannot access the file 'D:\\a\\1\\s\\bin\\AnyCPU.Debug\\Microsoft.ML.AutoML.Tests\\netcoreapp2.1\\...dataset' because it is being used by another process.\r\n> \r\n> Stack trace\r\n>    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n>    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n>    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n>    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n>    at Microsoft.ML.AutoML.TextFileSample.CreateFromFullFile(String path) in D:\\a\\1\\s\\src\\Microsoft.ML.AutoML\\ColumnInference\\TextFileSample.cs:line 76\r\n>  ...\r\n\r\n(Specific errors for [AutoFitRegressionTest ](https://dev.azure.com/dnceng/public/_build/results?buildId=555337&view=logs&j=dd8eddb6-ecc6-5f65-73e6-df90e5693b94&t=5b4b90b5-382b-59ee-45ec-a64c47991239&l=202)and [AutoFitBinaryTest](https://dev.azure.com/dnceng/public/_build/results?buildId=545476&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=dbdc2969-5b98-5c39-1328-31d4a2fdc45e&l=286) from CI builds)\r\n\r\nThis indicates that the .dataset file that is trying to be reached still has a lock on it, and is not yet ready for accessing. The current method of checking whether this file is ready to be accessed (checking `new FileInfo(dataFile).Length > 0` is not sufficient. \r\n\r\nThe fix below remedies this by obtaining these dataset files from the local `test/data` path, and thereby eliminating the possibility of download locks. This fix also does the same for other datasets that are available locally that were being downloaded from a commit before, so that similar file lock issues for those datasets can be avoided as well."""
579681677,4936,b'Updated version to 1.5.0-preview3',b''
579653089,4935,b'Nightlybuild fix',"b'several issue here:\r\n1. delete useless folder to avoid no disk space\r\n2. add missing dependency for nightly build\r\n3. fix LD_LIBRARY_PATH for CentOS to set proper native reference path\r\n4. increase build time, seems it takes more time now for net core 3.0 to build'"
579469782,4934,b'Improved documentation for LdSvmTrainer',"b'Adds explanation of the algorithm, moves details to remarks, adds references to samples.'"
579104390,4931,b'Added hanging test mem dump feature',b'Added the option to automatically collect memory dumps on hanging and crashing tests through VSTest Tasks and ProcDump.\r\n\r\nAlso added a section in the developer guide explaining the process to collecting memory dumps from CI builds.'
578891508,4930,"b'Debugging hanging tests [Draft, WIP]'",b''
578885494,4929,b'add back lightgbm crash mitigation',"b'we are seeing several crash so there might be more issue there, will remove this mitigation if we root cause and fix other remaining issue within lightgbm test\r\n\r\n\r\n'"
578821017,4928,b'Fix for MulticlassNaiveBayesTrainer export to Onnx',"b""- Adding support for a batch input dimension\r\n- While ML.NET doesn't use this batch dimension, ORT does.  \r\n"""
578394306,4927,b'fix LdaWorkoutEstimatorCore',"b'fix LdaWorkoutEstimatorCore test.\r\n\r\nresetRandomGenerator needs to be true here as multiple compare will be performed later. \r\nIn lda_engine, a queue of samples with size of (num_of_threads - 2) will be created at first, each time a compare is performed the internal status of one sample (random number: rng_) is changed, so if size of queue is smaller the number of compare performed (in local workstation we have 12 cores thus the issue is not reproduced), dirty data will be used again for calculation and cause issue. set resetRandomGenerator to true will reset the random number rng_ every time before lda calculation thus fix the issue.'"
578280343,4925,b'add root cause localization transformer',b'The goal of this pull request is to provide a decision tree based algorithm to localize the root cause of an incident on multi-dimensional time series on a specified timestamp.\r\n\r\n- [ ] Fixes #4960 .\r\n\r\n\r\n'
578260111,4924,b'Tensorflow crash issue',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
577092182,4922,b'Add hasHeader flag in ColumnInference function',"b""### This change will only affect the internal API.\r\n\r\nwhen hasHeader is true, AutoML will use the column name from dataset's header to indicate label/userId/itemId. else, it will use the default column name `col{i}` to indicate those information"""
576588062,4921,b'test LdaWorkoutEstimatorCore',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
575840698,4919,b'Update to Onnxruntime 1.2 and reenable its support for GPU',"b'Update dependencies in ML.NET for Onnxruntime.Managed 1.2 and reenable GPU support.\r\n\r\nFrom now on OnnxTransformer will take a dependency on OnnxRuntime.Managed nuget, instead of OnnxRuntime. And users of ML.NET will have the ability to either use OnnxRuntime nuget (for CPU) or OnnxRuntime.Gpu nuget, depending if they want their onnx models to be applied using cpu or gpu. All of these, according to the changes that were suggested and implemented on https://github.com/microsoft/onnxruntime/issues/2184\r\n\r\nNotice that in # #4416 support for GPU was disabled because of changes in onnxruntime nugets, and in here that same code is reenabled.'"
575808706,4918,b'LightGBM Crash issue',"b'https://github.com/microsoft/LightGBM/issues/2820\r\n\r\nLightGBM has dependency on OpenMP multi-threading library. In our tests we are setting number of threads to be 1 for LightGBM and LightGBM also sets OpenMP to use only 1 thread. While OpenMP is also used by other native libraries and they also tend to set number of threads for OpenMP to use (by default this is number of cores, in our case it is 2 as we are using https://docs.microsoft.com/en-us/azure/virtual-machines/dv2-dsv2-series#dsv2-series). This setting(number of threads) is global in process and cause LightGBM referencing OpenMP from single threads to multi-threads. LightGBM is using number of threads for indexing and thus cause index out of range in native code and crash the process.\r\n\r\nBy this fix, we are not force single threading when run LightGBM related tests thus default behavior is applied and all the libraries use same number of threads for OpenMP.\r\n\r\nIdealy LightGBM better not to rely number of threads to do indexing as this setting is global and likely be override by other library.'"
575066433,4913,"b""Update ConsumeModel.cs to enhance it's performance when being called for multiple times""","b'#### Sample Code\r\n\r\n``` c#\r\n// This file was auto-generated by ML.NET Model Builder. \r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing Microsoft.ML;\r\nusing Test.Model;\r\n\r\nnamespace Test.Model\r\n{\r\n    public class ConsumeModel\r\n    {\r\n        private static Lazy<PredictionEngine<ModelInput, ModelOutput>> PredictionEngine = new Lazy<PredictionEngine<ModelInput, ModelOutput>>(CreatePredictionEngine);\r\n\r\n        // For more info on consuming ML.NET models, visit https://aka.ms/model-builder-consume\r\n        // Method for consuming model in your app\r\n        public static ModelOutput Predict(ModelInput input)\r\n        {\r\n            ModelOutput result = PredictionEngine.Value.Predict(input);\r\n            return result;\r\n        }\r\n\r\n        public static PredictionEngine<ModelInput, ModelOutput> CreatePredictionEngine()\r\n        {\r\n            // Create new MLContext\r\n            MLContext mlContext = new MLContext();\r\n\r\n            // Register LabelMapping\r\n            mlContext.ComponentCatalog.RegisterAssembly(typeof(LabelMapping).Assembly);\r\n\r\n            // Load model & create prediction engine\r\n            string modelPath = @""\\path\\to\\model"";\r\n            ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n            var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n\r\n            return predEngine;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n#### Related Issue\r\n- [Simplify CodeGen](https://app.zenhub.com/workspaces/mlnet-tools-5cde1c97e3106e39e8ae08fc/issues/dotnet/machinelearning-modelbuilder/558)'"
574478910,4908,b'Debugging Test PR',b'Draft PR for general debugging on CI builds.'
574342206,4907,b'Use inline training data in generated Console Project file.',"b'### Code Sample\r\n\r\n``` c#\r\n// This file was auto-generated by ML.NET Model Builder. \r\n\r\nusing System;\r\nusing SampleRecommendation.Model;\r\n\r\nnamespace SampleRecommendation.ConsoleApp\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            // Create single instance of sample data from first line of dataset for model input\r\n            ModelInput sampleData = new ModelInput()\r\n            {\r\n                UserId = 1,\r\n                MovieId = 1,\r\n                Timestamp = 9.649827E+08F,\r\n            };\r\n\r\n            // Make a single prediction on the sample data and print results\r\n            var predictionResult = ConsumeModel.Predict(sampleData);\r\n\r\n            Console.WriteLine(""Using model to make single prediction -- Comparing actual Rating with predicted Rating from sample data...\\n\\n"");\r\n            Console.WriteLine($""userId: {sampleData.UserId}"");\r\n            Console.WriteLine($""movieId: {sampleData.MovieId}"");\r\n            Console.WriteLine($""timestamp: {sampleData.Timestamp}"");\r\n            Console.WriteLine($""\\n\\nActual Rating: {sampleData.Rating} \\nPredicted Rating: {predictionResult.Score}\\n\\n"");\r\n            Console.WriteLine(""=============== End of process, hit any key to finish ==============="");\r\n            Console.ReadKey();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n#### Fix issue\r\n- [Simply CodeGen](https://app.zenhub.com/workspaces/mlnet-tools-5cde1c97e3106e39e8ae08fc/issues/dotnet/machinelearning-modelbuilder/558) ( Item 1 )\r\n'"
573077419,4904,b'Calculate ReduceSum row by row in ONNX model from OneVsAllTrainer',"b""There's a bug with the ONNX models exported from `OneVsAllTrainers` that have `OutputFormula = OutputFormula.Softmax`. (Notice that to the best of my knowledge, only a LightGBM multiclass trainer that had `useSoftmax = true` would have such an `OutputFormula`).\r\n\r\nProblem was that the SoftMax (particularly the `ReduceSum` part of it) would be applied by summing the whole input batch, instead of doing separate sums for each row. This PR fixes that.\r\n\r\nNotice that this error wasn't presented in our tests, since the `OnnxTransformer` which applies the ONNX model, actually process one row at a time, so the batch would always consist of one row. When trying to use this model directly with OnnxRuntime API (without the `OnnxTransformer`), then this problem appeared."""
572537582,4902,b'test benchmark test hanging',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
572317106,4900,b'Added boolean support for KeyToValue and ValueToKey',b'\r\n\r\n'
571782145,4899,"b'Misc doc/sample fixes, improvements, and typos'","b'Misc doc/sample improvements, fixes, and typos.\r\n\r\nFixes #2655 \r\nFixes #3627 \r\nFixes #3927 \r\nFixes #3841 \r\nFixes #4898 \r\nFixes #3407 \r\n\r\nPartially addresses #3891\r\n\r\nRelated #4119 \r\nAnd a few minor fixes.\r\n\r\nMore to come.'"
571739800,4897,b'upgrade hosted mac agent pool to use new version of mac os',"b'current version of mac os will be out of support at March 23, 2020, move to new version:\r\n\r\nhttps://devblogs.microsoft.com/devops/removing-older-images-in-azure-pipelines-hosted-pools/'"
571713642,4896,b'disable test parallelization for ML.Test assembly to avoid crash',"b""In ML.Tests assembly, when some tests run in parallel, there are chance the host process will crash due to below exception: \r\nThe thread tried to read from or write to a virtual address for which it does not have the appropriate access.\r\nUnhandled exception at 0x00007FFA70E7B049 (ntdll.dll) in dotnet.exe.12884.dmp: 0xC0000374: A heap has been corrupted (parameters: 0x00007FFA70EE27F0).\r\n\r\nLooked into this error in detail, they come from LightGBM/OnnxRuntime dll we are referencing, seems like null pointer error during object finalization. \r\n![image](https://user-images.githubusercontent.com/55860649/75403422-8f548b80-58bc-11ea-8444-eb48027567fa.png)\r\n\r\nThese crash issue can be mitigated if we disable test parallelization. At the meantime, I'm contacting LightGBM and OnnxRuntime team to take a deeper look, maybe they should do null pointer check at their end.\r\n\r\nBelow are combination of tests run in parallel likely to cause crash, there maybe more:\r\nLightGBMBinaryEstimatorUnbalanced and BinaryClassificationTrainersOnnxConversionTest\r\nLightGBMRegressorEstimator and BinaryClassificationTrainersOnnxConversionTest\r\nLightGBMBinaryEstimatorUnbalanced and TestSGDBinary\r\nLightGBMBinaryEstimatorUnbalanced and CommandLineOnnxConversionTest\r\nLightGBMBinaryEstimatorCorrectSigmoid and MulticlassConfusionMatrixSlotNames\r\nIrisVectorLightGbmWithLoadColumnName and PlattCalibratorOnnxConversionTest\r\n"""
571590434,4893,b'Debugging hanging AutoFitImageClassificationTrainTest',"b'Will be using this draft PR for general debugging purposes on CI\r\n\r\nNotes:\r\nWindows builds have 7,168 MBs of RAM'"
571125147,4891,b'Fixes to onnx export for text related transforms',b'and MultiClassLogisicRegression\r\n\r\n'
571102380,4890,b'Enabling SavePipeExponentialAverage test',"b'This PR  re-enables the test `SavePipeExponentialAverage`, as the race condition/WaiterWaiter bug was fixed in PR #4829.'"
570931760,4889,b'Added Onnx ValueToKey and KeyToValue support for more int types',b''
570854650,4888,b'Updates NetCoreApp 3.0 builds to NetCoreApp 3.1',b'Fix #4865 . Updates our builds using NetCoreApp 3.0 to NetCoreApp 3.1.'
570828121,4887,b'Fixed bugs in OptionalColumnTransform and ColumnSelecting',b''
570239040,4885,b'Typo corrections',"b'More typo corrections in this repository.\r\nThe typo corrects are almost all in comments, except for one variable which was misspelled.\r\nWe should really pay more attention to avoid misspellings, and perhaps do a periodical check to make sure no new mistakes are made.'"
570205587,4884,b'Light gbm regressor estimator issue',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
570193009,4883,b'WIP: Verifying all CI machines support onnx',b''
570174985,4882,b'Updating onnxruntime version',b'\r\n'
569660027,4881,b'Slightly simplified version of adding KeyToValue for onnx export',"b""This is a variation of @antoniovs1029 's fix. This adds KeyToValueMappingTransformer in only one place. The results are identical between the two. """
569312559,4878,b'Added multiple related fixes to enable automatic addition of KeyToValue',b'This PR includes a number of fixes to enable automatic addition of KeyToValue in the Nimbus codepath. Specifically:\r\n* Fixed BinaryClassfierScorer to support exporting key types\r\n* Fixed PredictedLabelScorerBase to include the right types and shapes in the onnx graph\r\n* Fixed OneVersusAllTrainer to include shape information\r\n* Fixed SaveAsOnnxCommand to include type information in the last Identity node\r\n* Fixed OptionalColumnTransform to have the correct variable names and types. (This one is a preemptive fix. It fixes a crash that happens with the code in the ORT master branch)'
569293979,4877,b'enable 2 tests but skip running from x86',b'TestOldSavingAndLoading and TestDnnImageFeaturizer uses too much memory and not suitable to run on x86 (which has 2 GB memory limit by default).\r\n\r\nRe-enable these 2 tests if memory usage has been optimized.'
569240344,4876,b'Incorporating varying tolerances through VaryingToleranceAttribute',b'In this PR we are adding the ability to have varying tolerances for tests through VaryingToleranceAttribute.\r\n\r\nThe VaryingToleranceAttribute has been added to the following tests:\r\n\r\n- MulticlassLRTest\r\n- BinaryClassifierLogisticRegressionBinNormTest'
569239764,4875,b'Alternate solution for ColumnConcatenatingTransformer',b'- Added test isolating ColumnConcatenatingTransformer '
569157976,4873,b'Disabling TestOldSavingAndLoading() and TestDnnImageFeaturizer()',b'Temporarily disabling 2 ONNX tests: TestOldSavingAndLoading() and TestDnnImageFeaturizer()'
568782497,4869,b'Re-enabling disabled tests due to wrong nrBins value',"b'Fixed case with erroneous SafeTrainingAndModelBuffer.nrBins value, where if _threads = 1, nrBins should also equal 1. This way, when thread count is 1, there is no need to divide the training matrix into multiple blocks as 1 will do fine. As a result, we can re-enable the following disabled tests:\r\n\r\n- MatrixFactorizationSimpleTrainAndPredict\r\n- MulticlassTreeFeaturizedLRTest\r\n- TestOvaMacroWithUncalibratedLearner\r\n- EntryPointPipelineEnsembleGetSummary'"
568694862,4867,b'Fixed up dimensions to create known sized vectors',b'A recent PR (#4783) added support to run inferencing on an onnx model with multiple rows at a time. This made the output schema of OnnxTransformer to have variable size vectors which in turn broke some things in Nimbus. This PR fixes the dimensions back.'
568613409,4866,b'Fix for KeytoValue transformer',"b""Fix a small bug where the source variable name of an ONNX graph was mistakenly always the input variable name, which is not always the case. Other ONNX transformers don't explicitly test for this functionality, so I didn't add a test case. """
568557406,4863,b'enable BinaryClassifierSymSgdTest',"b'enable BinaryClassifierSymSgdTest as this test infected by CNR and fixed in this PR: https://github.com/dotnet/machinelearning/pull/4569\r\n\r\nchecked the full test set pipeline, this test never failed since #4569 is merged so enable this test again.\r\n'"
568042070,4862,b'fix netfx test not running issue',b'related to PR: https://github.com/dotnet/machinelearning/pull/4854\r\n\r\nsetting CopyLocalLockFileAssemblies to false for netfx cause test not running on CI like below:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=528701&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1\r\n\r\nrestrict CopyLocalLockFileAssemblies to false only for netcore 3.0\r\n\r\n'
568000518,4861,b'Fix for ColumnConcatenatingTransformer',"b'Used the Concat operator instead of FeatureVectorizer to avoid conflicting output type errors, since FeatureVectorizer outputs strictly floats, but some trainers expect double outputs. \r\n\r\n'"
567881761,4860,b'fix nightly-build',"b'related to https://github.com/dotnet/machinelearning/pull/4859.\r\n\r\ncentos is building with netcore3.0 not netcore2.1, add targetFramework parameter to distinct that\r\n\r\n\r\n'"
567825309,4859,b'set library path for centos and ubuntu',"b""set library path for centos as well as we are observing below error from NightlyBuild pipeline for CentOS:\r\n\r\nX Microsoft.ML.Functional.Tests.Training.ContinueTrainingSymbolicStochasticGradientDescent [121ms]\r\n  Error Message:\r\n   System.DllNotFoundException : Unable to load shared library 'SymSgdNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libSymSgdNative: cannot open shared object file: No such file or directory\r\n  Stack Trace:\r\n     at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(Int32 totalNumInstances, Int32* instSizes, Int32** instIndices, Single** instValues, Single* labels, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Single* weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, State* state, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(InputDataManager inputDataManager, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Span`1 weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, GCHandle stateGCHandle, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n   at Microsoft.ML.Functional.Tests.Training.ContinueTrainingSymbolicStochasticGradientDescent() in /__w/1/s/test/Microsoft.ML.Functional.Tests/Training.cs:line 420\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=527464&view=logs&j=c83e03a9-ccae-58c2-be03-4a20d31c7f0e&t=c2d1124c-8b3e-5953-2f5c-b9febb7524be\r\n"""
567823330,4858,b'make all tests inherit from BaseTestClass',b'RT\r\n\r\n'
567776109,4857,b'Added slot names support for OnnxTransformer',"b'This PR adds support for persisting the SlotNames annotations of a column during onnx export and reading those back in OnnxTransformer and adding the annotations back to the column when the onnx model is read from disk.\r\n\r\nOnnx natively does not have support for annotations. To work around this, we store some metadata in some unused portions of the graph. As an example, let us say we have an ML.NET model with an output column NGrams that outputs a vector of NGram counts. This column will have an Annotation in ML.NET named SlotNames. When this model is exported to onnx, we create an additional LabelEncoder node and store the SlotNames in the keys_strings attribute of the LabelEncoder.\r\n\r\nThe LabelEncoder is created with an input name of `$""mlnet.{column.Name}.unusedInput""`, an output name of $""mlnet.{column.Name}.unusedOutput"" and a node name of `$""mlnet.{column.Name}.SlotNames""`. (All the actual output columns of the ML.NET model are suffixed with a `"".output""` string)\r\n\r\nThen when OnnxTransformer loads the graph it goes through the list of output nodes and creates output columns for each of them in its output schema. For each column it searches the graph for a node named `$""mlnet.{column.Name}.SlotNames""`. If it finds it, it reads the keys_strings attributes from that node and adds those strings as SlotNames annotation to that column. \r\n\r\nThis SlotNames data should then be available as annotations on the column in both ML.NET and Nimbus.\r\n\r\n\r\n'"
567291206,4855,b'Debugging for SSAForecast',b''
567268035,4854,b'not copy nuget package to build output to save disk space',"b'dotnet core 3.0 build use too much disk space (more than 16GB) and cause build failure on CI, this is  caused by below line of code from build tools (\\Tools\\dotnetcli\\sdk\\3.0.100\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets):\r\n\r\n\r\n<!-- Don\'t copy local for netstandard projects. -->\r\n    <CopyLocalLockFileAssemblies Condition=""\'$(CopyLocalLockFileAssemblies)\' == \'\' and\r\n                                            \'$(TargetFrameworkIdentifier)\' == \'.NETStandard\'"">false</CopyLocalLockFileAssemblies>\r\n\r\n    <!-- Don\'t copy local for netcoreapp projects before 3.0 or non-exe and non-component projects. -->\r\n    <CopyLocalLockFileAssemblies Condition=""\'$(CopyLocalLockFileAssemblies)\' == \'\' and\r\n                                            \'$(TargetFrameworkIdentifier)\' == \'.NETCoreApp\' and\r\n                                            (\'$(_TargetFrameworkVersionWithoutV)\' &lt; \'3.0\' or\r\n                                             (\'$(HasRuntimeOutput)\' != \'true\' and \'$(EnableDynamicLoading)\' != \'true\'))"">false</CopyLocalLockFileAssemblies>\r\n\r\n    <!-- All other project types should copy local. -->\r\n    <CopyLocalLockFileAssemblies Condition=""\'$(CopyLocalLockFileAssemblies)\' == \'\'"">true</CopyLocalLockFileAssemblies>\r\n\r\n\r\nOverride CopyLocalLockFileAssemblies setting to false to save disk space.\r\n\r\nAlso, change windows netcore 3.0 build to use hosted test agent.'"
567215056,4853,b'Fix grammatical typos',b'Fix grammatical typos. Utilized [Visual Studio Spell Checker](https://marketplace.visualstudio.com/items?itemName=EWoodruff.VisualStudioSpellCheckerVS2017andLater) to quickly find and implement typo fixes.'
566103350,4849,b'Fixed output schema of OnnxTransformer',"b'This fixes a long standing issue about Onnx in ML.NET that the output variables of the onnx graph show up as columns with different names in the output schema of OnnxTransformer. After much investigation, it turns out that the output variables in the Onnx graph cannot be fixed because it is not possible to specify in onnx which particular node you want your output variable to be connected to. \r\n\r\nThis fix, adds a known "".output"" suffix to all Onnx models exported from ML.NET. And when reading a model, if the model was exported from ML.NET, it recognizes the suffix, strips it and maps it back to the input column. \r\n\r\nAs a result of fixing this PR also contains updates to the tests and baseline files. \r\n\r\nFixes #2980. Fixes #2981\r\n'"
565635124,4847,b'Crash issue',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
565606269,4846,b'Re-enabling MatrixFactorizationSimpleTrainAndPredict()',b'Re-enabling disabled test MatrixFactorizationSimpleTrainAndPredict(). The test was failing due to tolerance value being too small for Linux builds.'
565591104,4845,b'enable and disable some tests',"b'1. re-enable SavePipeSlidingWindow related test, have a deeper look at these tests and they are also infected by the race condition issue in WatierWaiter that cause data load incomplete. Error look like below: System.InvalidOperationException : Right has more rows at position: 110\r\nhttps://github.com/dotnet/machinelearning/pull/4829\r\n\r\n2. Disable 2 tensorflow related test as we met below error: System.AccessViolationException : Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\r\n\r\n'"
565499652,4844,b'add reference to onnx package in model project',b'We need to have reference to onnx package in .model project in order to load/save onnx model'
565060710,4841,b'Adding KeyToValueTransformers before finishing exporting to ONNX',"b'When NimbusML deals with category Pandas columns, it automatically convert them into `KeyDataViewType` columns when sending the input `IDataView` to ML.NET. On the way back, it convert those columns back to category columns. This is done without using `KeyToValueTransformer` or `ValueToKeyTransformer`, so those transformers aren\'t actually part of the pipeline of the model that\'s used by NimbusML. Another behavior that NimbusML has, is that for some classifiers it actually adds a `KeyToValueTransformer` in the pipeline, but it doesn\'t add a ValueToKeyTransformer at the end, because it relies on its mechanism of converting the output `KeyDataViewType` columns into the original type of columns.\r\n\r\nIn general these behaviors aren\'t a problem, but it causes troubles when exporting models to ONNX. Since the models created by nimbusml don\'t have the appropriate `ValueToKeyTransformers` inside them to map values back from keys, then the generated ONNX models won\'t have the appropriate `LabelEncoders` to do that mapping. \r\n\r\nIn this PR I add a `KeyToValueTransformers` at the end of the `transforms` list that is used by `SaveOnnxCommand`, so that the resulting ONNX model can map values back from the keys, even when the NimbusML pipeline doesn\'t include the transformers to map them back. This is done for two main cases that were identified to affect NimbusML:\r\n1. For NimbusML pipelines that ended in a binary or multiclass classifier, which output a `PredictedLabel` `KeyDataViewType` column.\r\n2. For scenarios where the model doesn\'t touch some input columns which were `KeyDataViewTypes` after NimbusML sent them to ML.NET. In this scenarios, those input columns are expected to be in the output and remained untouched so that NimbusML can automatically map them back. But when using ONNX models generated by NimbusML without the changes in this PR, then the output of this scenario for ONNX are columns that are no longer `KeyDataViewTypes`, and that contain only keys. So for this scenario it is also necessary to add the corresponding `KeyToValueTransformers`. That way the user will get back the values that they\'re expecting, although this conversion wouldn\'t be done by NimbusML itself, but by the added transformers. The columns that were categorical in NimbusML, and then KeyDataViewTypes, and that remained untouched by the pipeline, are called ""pass through"" columns inside the changes of this PR, and in other related discussions.\r\n\r\nThis is thought to be a temporary solution, to unblock Azure AutoML to work with NimbusML. Ideally these transformers would be added in NimbusML pipeline, but currently it\'s not possible to add transforms after predictors in NimbusML, and doing these changes would also need to change how NimbusML converts between IDataView and Pandas DataFrames. So for the time being the solution in here was found to be the best.\r\n\r\nFixes https://github.com/microsoft/NimbusML/issues/431 and https://github.com/microsoft/NimbusML/issues/426'"
565035782,4838,"b'Optimize generic MethodInfo for Func<T1, T2, TResult>'",b'Builds on #4836'
565028450,4837,"b'[WIP, Test Stability] Running on private agent pool'",b'Testing private agent pool MachineLearning Test https://dev.azure.com/dnceng/_settings/agentpools?poolId=80&view=jobs'
565023088,4836,"b'Optimize generic MethodInfo for Func<T, TResult>'",b'Builds on #4588'
564927599,4835,b'Enable MSML_PrivateFieldName for the full solution',b''
564882152,4834,b'WIP: Fixing TextNormalizing test issue with Linux machines',b'\r\n'
564786910,4833,b'Enable MSML_ParameterLocalVarName for the full solution',b''
564369782,4831,b'Added exception for non-existent directory in ImageLoader',"b'Path.GetFullPath(""C://non-Existant) was not throwing an exception. Hence there is a need to explicitly check for the existence of the imageFolder directory. Related to #4429 .  '"
564337674,4830,b'Update vs-threading analyzers to 16.5.132',b''
564334426,4829,b'fix issue in WaiterWaiter caused by race condition',b'1. Fix issue in WaiterWaiter caused by race condition.\r\n2. Re-enable affected tests as below:\r\nEntryPointEvaluateRegression\r\nEntryPointSdcaBinary\r\nEntryPointSDCARegression\r\nEntryPointChainedCrossValMacros\r\nTestCrossValidationMacroWithStratification\r\nTestOvaMacro\r\nTrainAndPredictOnIris\r\nCrossValidationIris\r\nLinearClassifierTest\r\nSavePipeTrainAndScoreFccTransformStr\r\nBinaryClassifierLogisticRegressionNonNegativeTest\r\nInpsectLinearModelParameters\r\nTrainRegressionModel\r\nCustomTransformer\r\nTrainAndPredictIrisModelTest\r\nLightGbmBinaryClassificationOnnxConversionTest'
563951305,4828,b'Add support for combining hashes in vector columns to HashingTransformer',"b'I am making this change so that `CountTargetEncodingEstimator` (see PR #4514 ) can start using `HashingEstimator` instead of `HashJoiningTransform` (see this [comment](https://github.com/dotnet/machinelearning/pull/4514#issuecomment-584502932) in the above PR).\r\n\r\nIn addition to enabling `CountTargetEncodingEstimator` to use it, this will fix a bug when splitting datasets in the [CV command](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Commands/CrossValidationCommand.cs#L335) and in the [train-test/CV APIs](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L522). If a stratification column that is a vector type is specified, currently an exception will be thrown because the `RangeFilter` applied after hashing cannot handle vector columns.'"
563604008,4827,b'Fix off by 1 error with the cats_int64s attribute for the OneHotEncoder ONNX operator',b'\r\n\r\n'
563490675,4826,b'[Test Stability] PR to Test LinearClassifierTest',b'Testing LinearClassifierTest'
562931909,4824,b'Enable OnnxTransformer to accept KeyDataViewTypes as if they were UInt32',"b""Addresses https://github.com/microsoft/NimbusML/issues/426\r\n\r\nAs discussed offline with @harishsk , @ganik and @pieths , the update in here is the best temporary solution to the problem.\r\n\r\nSimply enables OnnxTransformer to accept a `KeyDataViewType` column as input of a model that actually expects an `UInt32` input column. This, because of the way that NimbusML works with Category columns in Pandas' DataFrames, by converting them into `KeyDataViewType` columns in ML.NET, without actually adding KeyToValueTransformers into the pipeline."""
562874656,4823,b'Added Done() call in BaseTestBaseline.Cleanup and added related fixes',"b'This PR is similar to #4817 but standardizes the default value for Slope in PlattCalibrator to -1 instead of 1 since -1 seems to be used everywhere in the code. (If this PR is approved, I will be closing the other PR)'"
562749985,4822,"b""add AutoMLService.Test's sign key to AutoML and CodeGen's assembly.cs""",b'Doing that so AutoMLService.Test can visit internal class inside those two projects.'
561993180,4818,b'Changed Binarizer node to be cast to the type of the predicted label \xe2\x80\xa6',"b""\xe2\x80\xa6column's data type\r\n\r\nIn BinaryClassifierScorer's SaveAsOnnxCore function we were always casting the output of the Binarizer to a bool. But in some cases BinaryClassifierScorer can output a key value (uint) and in this case we should cast the output to a uint. This fix changes the cast to be dependent on the output type of the predicted label. """
561957436,4817,"b""WIP: Make sure Done() is called in cleanup if it hasn't been called""",b'This makes sure call stack is collected for intermediate failures.'
561957117,4816,b'Fixed bug in tensorflow tests due to long paths for working folders',b'TF tests are relying on IClassFixture to carry forward state from test to test. This by default creates excessively long paths that result in file system errors when there is a longer prefix for the source code. I have fixed it to take temp paths with shorter path lengths.'
561956326,4815,b'Fixed bugs in OptionalColumnTransform and added bool support',"b""OptionalColumnTransform didn't have support for boolean initializers. When I went to add that I saw that the TensorProto data was being set incorrectly for a few other data types. I tried to fix that and I had to redo the AddInitializer functionality in OnnxContext and related plumbing in OnnxUtils.cs.\r\nThen when I went to add tests for all the data types that are now supported in OptionalColumnTransform, I realized I needed to simplify the column comparison in OnnxConversionTest. In the process I also added support SByte and Byte in OnnxUtils - CreateNamedValue and fixed up the corresponding tests.\r\n\r\nIn summary:\r\n- Cleaned up OnnxContext's initializer interface\r\n- Cleaned up column comparison functionality on OnnxConversionTest\r\n- Fixed bugs in OptionalColumnTransform's onnx export and added support for boolean initializers\r\n\r\n"""
561922933,4814,b'improve logging for Functional Tests',b'Better logging for FT:\r\n1. add test output logging handler and MessageKindToLog in FT base class\r\n2. move TestLogger to TestFrameworkCommon project as this is more common test project and we might need to use TestLogger in future for FT\r\n'
561899846,4813,b'Fix for NgramTransform',"b'- Casting UInt16 -> Int64  inside NgramTransform, since it may now receive UInt16 keys from TokeningByCharacters\r\n'"
561898450,4812,b'Added in DateTime type support for TimeSeriesImputer',"b'Added in System.DateTime support for the Date column in TimeSeriesImputer.\r\n\r\nInternally it converts it to POSIX time before it sends it to the native implementation, and then converts it back to System.DateTime for the IDataView.\r\n\r\nAlso added more comments and comments for the Enums.\r\n'"
561848195,4811,b'remove build timeout as perf bump',"b""seeing build perf bump like below few builds:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=510766&view=logs&j=4a5328fc-3628-53de-aa0c-9ba4571cae61&t=d953246d-9492-5686-12cd-f07513b595b7\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=510972&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&s=d654deb9-056d-50a2-1717-90c08683d50a\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=510945&view=logs&j=4a5328fc-3628-53de-aa0c-9ba4571cae61&t=d953246d-9492-5686-12cd-f07513b595b7\r\n\r\nthis PR remove build timeout as perf bump\r\n\r\nCan't use hosted agent pool for netcore3.0 due to space limitation:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=512080&view=logs&jobId=4a5328fc-3628-53de-aa0c-9ba4571cae61&j=4a5328fc-3628-53de-aa0c-9ba4571cae61&t=d953246d-9492-5686-12cd-f07513b595b7\r\n\r\n"""
561840191,4810,"b'modify base test class analyzer, allow to extend from ft base test class'","b""We have separate base test class for all functional tests: FunctionalTestBaseClass\r\nThe reason for that is FT is also runned on NightlyBuild pipeline which not take project dependency directly but take ML.NET related Nuget package as dependency and we don't want FT to take dependency from TestFramework."""
561830375,4809,b'Experiment: Switch to multitargeting for tests',b''
561822256,4808,b'Removed extraSettings param in unit test datasets file',"b'Fixes #4742 , quick change to remove the `extraSettings` parameter from unit test datasets in `Datasets.cs`.'"
561360837,4806,b'Add link to February survey',b'Adds a link to ML.NET survey for February\r\n'
561328863,4805,b'TokenizingByCharacters export to Onnx',"b""- Transformer that tokenizes by character and returns the characters (as uint16)\r\n- Since there's not a comparable onnx operator, a label encoder is used to map a string token to it's corresponding character value.  This will unfortunately make the model much larger, since 65535 values have to be saved as a mapping guide for label encoder. """
561320990,4804,b'Fix issue with the onnx export string initializer in OptionalColumnTransform',b''
561282487,4803,b'Implement MSML_RelaxTestNaming suppressor for VSTHRD200',"b""Allow asynchronous test methods to omit the 'Async' suffix."""
561281068,4802,b'Extract IsTestMethod to a shared analyzer helper',b''
561279039,4801,b'Enable RS1026 (Enable concurrent execution)',b''
561278295,4800,b'Enable RS1025 (Configure generated code analysis)',b''
561277741,4799,b'Enable RS1024 (Compare symbols correctly)',b''
561277395,4798,b'Update to Microsoft.CodeAnalysis 3.3.1',b''
561235457,4797,b'Fix for KeyToValue Onnx export ',"b'- Like for ValueToKey,  mapping int64 -> int64 needs casting\r\n- Cast float values back to doubles, when the valuetype is expected to be a double \r\n\r\nThe current KeyToValue test makes it hard to test different value types, so I added KeyToValue to the ValueToKey pipeline, which is more flexible. Comparing the keys checks ValueToKey and comparing the value output checks KeyToValue. If this test is ok, I can remove the current KeyToValue test. Otherwise, I can modify the KeyToValue test to follow a similar format.   '"
561024392,4794,"b'Enable VSTHRD200 (Use ""Async"" suffix for async methods)'",b'This rule relies on a suppression analyzer (#4803) to avoid requiring test methods to be renamed.'
561023816,4793,b'Enable VSTHRD105 (Avoid method overloads that assume TaskScheduler.Current)',b''
561023379,4792,b'Enable VSTHRD103 (Call async methods when in an async method)',b''
561022883,4791,b'Enable VSTHRD100 (Avoid async void methods)',b''
561010856,4790,b'Install threading analyzers',b'Rules with existing violations have been disabled.'
560706894,4787,b'Release notes for v1.5.0-preview2',b''
560603758,4786,b'Fix onnx output name for GcnTransform',b'Fixed typo in GcnTransform SaveAsOnnx(..) where input column name is used instead of output one.'
560528538,4785,"b'Added baselines for the TestDatasets.breastCancerPipeMissing dataset, and their unit tests'","b'Related to Issue #4681 and PR #4695. \r\n\r\nThis PR adds the baseline figures for the `TestDatasets.breastCancerPipeMissing` dataset (which is the  same dataset as `TestDatasets.breastCancerPipe` but without missing values due to the `NAHandle` transformer), and adds these baseline figures to the required tests in `TestPredictors.cs`.\r\n\r\nThe tests that these baselines satisfy are: \r\n\r\n- `LightGBMClassificationTest`, \r\n- `GossLightGBMTest`, \r\n- `DartLightGBMTest`, \r\n- `FastTreeBinaryClassificationTest`, \r\n- `FastTreeHighMinDocsTest`\r\n- `MulticlassNaiveBayes ` \r\n\r\nThese tests are also originally the only unit tests that utilize `TestDatasets.breastCancerPipe`.\r\n\r\nSince the `TestDatasets.breastCancerPipeMissing` dataset does not contain missing `?` values, the change in PR #4695 of allowing `CursOpt.AllFeatures` will not impact the test cases mentioned above.\r\n\r\n**Edit: ** In the last sentence above, I mean that since there are no missing values in `TestDatasets.breastCancerPipeMissing`, these datasets are better suited to test these LightGbm tests as `CursOpt.AllFeatures` combined with the `HandleMissingValues` flag in `LightGbmTrainerBase.cs` introduce multiple modifiers to the case of handling missing values, which this `TestDatasets.breastCancerPipeMissing` dataset is **not** impacted by.'"
560078228,4783,b'Onnx Export change to allow for multiple rows',"b""Changed ONNX export from always exporting the dimensions as 1 to -1. This lets ONNX Runtime determine the dimension when the data is passed to it, allowing for batching to be done if desired. ML.NET doesn't support batching, but this allows the model to be run directly in ORT using batching while still supporting the streaming approach that ML.NET uses."""
560072070,4782,b'fix some Baselinetest and add missing Done()',b'1. add missing baseline file for compare\r\n2. use allow mismatch in certain tests that only intend compare value and return result but not fail test\r\n\r\n'
560012292,4781,b'TextNormalizing export to Onnx ',"b'- can, at the moment, only handle case changing options\r\n\r\n'"
559978194,4780,b'Enable cnr test',b'This is a test to demonstrate correct baselines in #4569 '
559928923,4779,b'Fix incorrect SynchronizationContext use in TestSweeper',b''
559501086,4776,b'build and test failure due to download resource fail',"b'facing build and test failure due to download resource fail:\r\nhttps://microsoft.sharepoint.com/teams/ML.NET/_layouts/OneNote.aspx?id=%2Fteams%2FML.NET%2FSiteAssets%2FML.NET%20Notebook&wd=target%28Tests.one%7C5E713C2E-6DCF-4AA3-9071-69CBBAF48985%2FTest%20Network%20Issue%7CDBE36B97-0518-43C2-8C3F-A7D2A461FBDE%2F%29\r\n\r\n\r\nthis fix including:\r\n1. add retry and delay for resource downloading when run test\r\n2. disable parallel when restore nuget package, this can prevent restore consume too much connections from vm and cause the following download to hanging, restore itself has retry already\r\n3. add retry for download resource from Internet when build, if disable parallel when restore can prevent the network glitch this can possibility be unnecessary\r\n\r\n'"
559437530,4775,b'Add Seed property to MLContext and use as default for data splits',b'Fixes #4752 \r\n\r\nAddresses leftover feedback from #4764 '
559391287,4774,b'Fix NullReferenceException when it comes to Recommendation in AutoML and CodeGenerator',b'add code for handle enum case in CodeGen'
559368196,4772,b'trouble shoot issue',"b'trouble shoot SdcaTrainerBase related issue, take memory dump at failure point:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=505404&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=dbdc2969-5b98-5c39-1328-31d4a2fdc45e'"
559351636,4771,b'set max thread to unlimited to avoid dead lock',"b'Related to: https://github.com/dotnet/machinelearning/issues/4773: \r\nSet max threads to unlimited is mitigation for dead lock issue in xunit tests, we should change the way we are using async code to prevent dead lock in future.\r\n\r\nCollection of test hanging are collected at: https://microsoft.sharepoint.com/teams/ML.NET/_layouts/OneNote.aspx?id=%2Fteams%2FML.NET%2FSiteAssets%2FML.NET%20Notebook&wd=target%28Tests.one%7C5E713C2E-6DCF-4AA3-9071-69CBBAF48985%2FLong%20running%20tests%7C54A981BE-BFF2-4188-9520-7DE3E2DF0EDF%2F%29\r\nonenote:https://microsoft.sharepoint.com/teams/ML.NET/SiteAssets/ML.NET%20Notebook/Tests.one#Long%20running%20tests&section-id={5E713C2E-6DCF-4AA3-9071-69CBBAF48985}&page-id={54A981BE-BFF2-4188-9520-7DE3E2DF0EDF}&end \r\n\r\nRunned 7 builds, no test hanging found.\r\n\r\n'"
559348320,4770,b'try enable test parallel between assembly',b'RT.\r\n\r\n'
558652933,4766,b'Branch to test current state of outer loop builds',b'This is a test branch to test the current state of builds when all test run including the disabled test.'
558602279,4765,b'Enable MSML_SingleVariableDeclaration for the full solution',b''
558456511,4764,b'Data splits to default to MLContext seed when not specified',b'Fixes #4752 '
558444240,4763,b'Fix for ColumnSelecting issue',"b""There was an issue found when there's a transform prior to ColumnSelect that gets rid of the selected input variables in the ONNX graph. \r\n\r\nI modified the existing test to demonstrate this issue.\r\n\r\nA (possibly temporary) fix is to not remove any of the input variables from the ONNX graph. \r\n   \r\n\r\n"""
558434003,4762,b'Enable MSML_TypeParamName for the full solution',b''
558430966,4761,b'add read share to all file read operation',b'address file lock issue in test like below:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=501414&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=502370&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=503598&view=logs&j=9dffbc46-9322-5a58-fb37-6d66c044e90d&t=11098bf6-eb78-583b-8eab-f14f48444a6b\r\n\r\nallow other reader to read file when file is opened by file stream only for read\r\n\r\n'
558388405,4759,b'enlarge cancelTimeout from 5 minutes to 10 minute',b'RT.\r\n\r\nSeeing this build: https://dev.azure.com/dnceng/public/_build/results?buildId=503424&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46\r\n\r\nTest run times out and artifact is not uploaded as cancel timeout exceeds with below message:\r\n##[warning]Agent NetCorePublic-Pool 114 did not respond to a cancelation request with 00:05:00\r\n\r\nset this cancel time to 10 minutes to ensure we upload artifact for investigation\r\n\r\n'
558341394,4758,b'Updating onnx baseline files for regression tests',b''
558337211,4757,b'Disable test parallelization in TimeSeries tests',b'Extracted from #4569'
558336853,4756,b'Update test baseline for TimeSeries tests',b'Extracted from #4569'
558336729,4755,b'Check exception status even if TF_SessionRun throws an exception',b'Extracted from #4569'
558335123,4754,b'Remove incorrectly-coded finalizer in DnnRetrainTransformer',b'Extracted from #4569'
557944784,4753,b'can_reload_model test issue',"b'Increase wait time for can_reload_model test as we are observing some failures recently:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=502691&view=logs&j=5aa5c7df-492a-5eaf-973a-62b7b0f0ee3b&t=ffdbd604-f3e2-5332-cf61-c8dd00799b47\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=502647&view=logs&j=5aa5c7df-492a-5eaf-973a-62b7b0f0ee3b&t=ffdbd604-f3e2-5332-cf61-c8dd00799b47\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=502589&view=logs&j=5aa5c7df-492a-5eaf-973a-62b7b0f0ee3b&t=ffdbd604-f3e2-5332-cf61-c8dd00799b47\r\n\r\ntried several run with this fix, no can_reload_model failed again'"
557873637,4751,b'Add double initializer to the OptionalColumnTransform onnx export.',b''
557862530,4750,b'Added Shuffle=false for all the Sdca related tests',b'See discussion [here](https://github.com/dotnet/machinelearning/pull/4736)\r\n\r\nReviewers please check if any of them need to have to Shuffle=true.'
557825889,4747,b'Can reload model issue',"b'troubleshoot can_reload_model issue, might be caused by deadlock, try loosen max thread number:\r\n\r\nfailure sample:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=500380&view=logs&j=ac97a0ee-ee90-5a55-af17-a5a589fa545f&t=b52ada90-72fa-5cd6-fc24-3dd2e707ecb9\r\n\r\n\r\n'"
557819604,4746,b'Implement MSML_ExtendBaseTestClass (Test classes should be derived from BaseTestClass)',"b'All current violations are excluded from analysis via **.editorconfig**. After this is merged, someone can enable the diagnostic in one project at a time and ensure there are no violations.'"
557775680,4745,b'Double cast to float for some onnx estimators ',b''
557755043,4744,b'add run specific test capability and CrashTestHostProcessorHelper',"b'2 purpose for this PR:\r\n1. add capability of run specific test only on CI by:\r\n   a. set innerLoop to false to certain configuration\r\n   b. set runSpecific to true to certain configuration\r\n   c. add [Trait(""Category"", ""RunSpecificTests"")] to the test methods wish to run\r\n2. add CrashTestHostProcessorHelper to crash process and take memory dump at any place\r\n\r\n'"
557751030,4743,b'Fix issue with missing schema info when saving to ONNX.',b''
557630677,4740,b'Update analyzer test library',b''
557197002,4737,b'fix path in test that not working in linux and mac os',"b""Path in TestAPI is not working in linux and mac os and cause publish to artifacts fails:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=501206&view=logs&j=5aa5c7df-492a-5eaf-973a-62b7b0f0ee3b\r\n\r\nwith error message:\r\n\r\nFail to upload '/home/vsts/work/1/a/AnyCPU.Release/Microsoft.ML.Tests/netcoreapp2.1/TestOutput/..\\Common\\Api/lambda-output.tsv' due to 'The following path is not valid: Ubuntu_x64_NetCoreApp21 R/AnyCPU.Release/Microsoft.ML.Tests/netcoreapp2.1/TestOutput/../Common/Api/lambda-output.tsv. Path segments must contain characters other than period and whitespace.'.\r\n\r\nAfter fix, artifacts upload is success in all platform, below build is with this fix but an on purpose test fail, all builds fails and successfully uploads artifacts:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=501376&view=results"""
557123110,4736,b'Changed all MLContext creation to include a fixed seed',"b'Many tests are creating MLContext without a seed. Since we are seeing a number of random failures, this PR attempts to standardize all MLContext creation to include a fixed seed. \r\n\r\nNote to reviewers: If you know if cases where a fixed seed is not desired, please flag those cases. '"
557080878,4734,b'Changed onnx export to append a .onnx string to column names',"b'Nimbus (and potentially others) need a mechanism to map the variables in the ML.NET output schema to the corresponding output variables in the onnx graph. Since Onnx generates unique names for output variables, this becomes difficult. With this change, we are adopting a simple heuristic that when an ML.NET pipeline is exported to onnx, the column names in the output schema will have a .onnx appended to it. '"
557067699,4733,b'[Test Stability] PR to Test PlattCalibratorOnnxConversionTest',b'PR to Test PlattCalibratorOnnxConversionTest\r\n\r\n--------------------------------------------------------\r\n\r\nPlatforms where it has explicitly caused been involved in a failure so far:\r\n1. Windows_x64_NetCoreApp30 Release_Build\r\n\r\nRate of explicit failure (considering all pipelines and trials):\r\n1/2800'
557036896,4732,b'PR to Test PlattCalibratorOnnxConversionTest',b'PR to Test PlattCalibratorOnnxConversionTest'
556993531,4731,b'Enable the internal code analyzer for test projects',b'Existing rules which report diagnostics are disabled.\r\n\r\nThis is a prerequisite for adding new analyzer rules specifically targeting test code in this repository.'
556852352,4728,b'Added CustomGainsDouble for type consistency without breaking API',b'Fixes #3708 . Added CustomGainsDouble and marked CustomGains as obsolete in evaluator.'
556795388,4727,b'Added instructions on updating core_manifest.json and core_ep-list.tsv',b'Added instructions on updating core_manifest.json and core_ep-list.tsv to the developer guide\r\n'
556644530,4726,b'skip more test',"b'skip below tests as they are crashing, hanging or failing the CI:\r\n\r\nSavePipeSlidingWindowW2L1 \r\nEntryPointSdcaBinary\r\nMulticlassLRTest \r\nAutoFitImageClassificationTrainTest \r\nTensorFlowImageClassification\r\nIrisVectorLightGbmWithLoadColumnName\r\nTensorFlowTransformMNISTConvTrainingTest \r\nTestEstimatorHogwildSGD \r\nPlattCalibratorOnnxConversionTest\r\nTensorFlowImageClassificationEarlyStopping\r\n\r\n\r\n\r\n'"
556585817,4724,b'Test hanging issue',"b""troubleshoot test host process hanging issue, enable long running test support to find the test(s) that are hung and not returning:\r\nhttps://xunit.net/docs/configuration-files#longRunningTestSeconds\r\n\r\ntested in local, if test hangs, xunit will report like below:\r\n[xUnit.net 00:02:13.09] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:02:11\r\n[xUnit.net 00:04:13.10] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:04:11\r\n[xUnit.net 00:06:13.11] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:06:11\r\n[xUnit.net 00:08:13.11] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:08:11\r\n[xUnit.net 00:10:13.12] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:10:11\r\n[xUnit.net 00:12:13.12] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:12:11\r\n[xUnit.net 00:14:13.13] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:14:11\r\n[xUnit.net 00:16:13.13] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:16:11\r\n[xUnit.net 00:18:13.14] Microsoft.ML.Sweeper.Tests: [Long Running Test] 'Microsoft.ML.Sweeper.RunTests.TestSweeper.TestDeterministicSweeperAsyncParallel', Elapsed: 00:18:11\r\n\r\n"""
556579694,4723,b'Fix math rendering for SdcaMaximumEntropyMulticlassTrainer doc',b'Fixes #3938 '
556576994,4722,b'[Test Stability] PR to Test BinaryClassifierSymSgdTest',b'PR to Test BinaryClassifierSymSgdTest'
556565690,4721,b'Clarify model format in TensorFlow model loading sample',b'Fixes #4063'
556563542,4720,b'Fix math rendering in SdcaMaximumEntropyMulticlassTrainer doc',b'Fixes #3938 '
556552832,4718,b'only run spefic test in CI for test',b'Sample PR with ability to only run specific tests on CI.\r\n\r\n'
556551527,4717,b'[Test Stability] PR to test TrainAndPredictOnIris',"b'PR to test ""TrainAndPredictOnIris"" test.\r\n\r\n--------------------\r\n\r\nPlatforms were it\'s caused an error so far:\r\n\r\n1. Windows_x64_NetFx461 Debug_Build'"
556486107,4716,b'Fix failure to capture test failures',"b""Need to verify that this doesn't cause new test failures."""
555894326,4715,b'crash test host process when test fails to take memory dump',b'1. try crash the test host process to take memory dump when test fails\r\n2. enable all test running on CI to investigate'
555544186,4714,b'Updated BinaryLoader & Removed RowIndexName and its functionality',b'Fixes #3707\r\n\r\nRemoved adding column containing the row index as it is no longer necessary and IDataViews have RowIds. Also updated BinaryLoader and its version.'
555161340,4710,b'Draft modification to redirect logs to test output',"b""Currently when running tests the channel output doesn't appear in the test logs. This is a draft change to enable that functionality in order to get better logging to debug tests better.\r\n\r\nThere are two changes here. \r\nThe first is a simple adds a handler for MLContext's Log event and logs the message to test output. The second adds a TextWriter derived class to ConsoleEnvironment that makes ConsoleEnvironment also log to the test console if the code is running a test environment.\r\n\r\nI am putting this PR up for review for two purposes. \r\n\r\nThe first is for general verification of the code and concept. And while the code reviews are in progress I am also using this to try and debug the failure in BinaryClassifierSymSgdTest in the CI builds.\r\n"""
554983812,4706,b'Update cookbook to latest API',b'Fixes #3849 '
554916246,4705,b'Correct KMeans scoring function doc',b'Fixes #4011 '
554854878,4704,b'[Mn] Roadmap update',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
554785554,4702,"b""Disallow bad input types in FeatureSelection estimator's GetOutputSchema method""",b'Related to #4693 .\r\n\r\n'
554761949,4701,b'Changed type of CustomGains to double[] for consistency',b'Fixes #3708 '
554485803,4699,b'Added Onnx Export to PlattCalibratorTransformer',"b'`PlattCalibrator` already had a `SaveAsOnnx` method ([link](https://github.com/dotnet/machinelearning/blob/2267f8d709ad053a5db5867abb396c960173d6ef/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1739)) which was called when saving to Onnx a `PlattCalibrator` through a `CalibratedModelParameter` class (such as in [here](https://github.com/dotnet/machinelearning/blob/2267f8d709ad053a5db5867abb396c960173d6ef/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L391)). This would happen when saving a model produced by a calibrated binary classifier.\r\n\r\nBesides being part of calibrated binary classifiers, a PlattCalibrator can also be used independently, through a `PlattCalibratorTransformer`. So in this PR I add the necessary code so to also make it possible to save as Onnx a model that used a `PlattCalibratorTransformer`.\r\n\r\nI added 2 tests where a PlattCalibratorTransformer is added at the end of the model (in one test it\'s added on top of binary classifiers, in the other test no binary classifiers were used).\r\n\r\nI also fixed a bug in the SaveAsOnnx method of PlattCalibrator. For some reason, it was hardcoded to use ""-0.0000001f"" as the value of the Offset, ignoring the actual offset that the calibrator had. This worked with the existing tests because in them the offset was actually ""0"", but that isn\'t always the case, and so in the tests that I am adding the offset is not 0.'"
554472705,4698,b'Fix for OneVersusAll Multiclass trainer',"b'Also adding tests for OVA with FastForest, LinearSVM, and AveragedPerceptron.'"
554445158,4697,b'Fix #4611 broken xrefs in ExpressionTransformer',b'Re-fix #4611 \r\n\r\n#4647 tried to fix this but some problems remained'
554243517,4696,b'Fix bug in WordBagEstimator when training on empty data',b'Fixes #969 .\r\nRelated to issue #4693 .'
554130086,4695,"b'Updated handling of missing values with LightGBM, and added ability to use (0) as missing value'","b""Fixes #4681 , and also adds the ability to use the numerical value (0) as missing value with LightGBM. In addition, I've also updated the baseline results for LightGbm as it is normal for them to change with `CursOpt.AllFeatures`, and all added a unit test checking that a previously trained LightGBM model with the `CursOpt.Features` flag produces the baselines it did before."""
553892271,4694,b'Remove obsolete code in BinaryClassifierEvaluator',"b""As mentioned in [here](https://github.com/dotnet/machinelearning/pull/4673#discussion_r368178117), the code that I am removing in this PR (methods `SavePrPlots` and `GetCurve` in `BinaryClassifierEvaluator`) makes use of `IRowCursor` and `XYPlot`, which existed back in TLC but doesn't exist in ML.NET. The only reason they don't cause a problem when building ML.NET was because they're wrapped around an `#if !CORECLR` directive."""
553472855,4691,b'Fixes cases of invalid image folder path and input column name',b'Fixes #4429 \r\n\r\nInput column names and image folders can no longer be empty or null.'
553425752,4690,b'Make SVM Light loader create the correct schema in case of indices greater than int.MaxValue',b'Fixes #4689 .'
553348546,4688,b'separate build pipelines',b'1. new outer loop pipeline that runs all tests\r\n2. remove flaky tests from CI\r\n\r\n'
553345588,4687,b'Updated langversion to 8.0',b'Fixes #3786\r\n\r\nWe cannot use 7.3 because Utilities\\ThreadUtils.cs uses static local functions which is available only in 8.0. I also had to set the langVersion to 4.7 for the F# project.\r\n\r\n'
553212201,4685,b'Fix typos in README.md',"b'Copy edited the following:\r\n\r\n- Added serial commas \r\n- Added comma after introductory phrase ""for example""\r\n- Fix typo: in this separated page > in this separate page\r\n- Fix typo and sentence structure under ""ML.NET videos playlist at YouTube"" section\r\n- Fix wording: or alternatively > alternatively \r\n\r\n<hr>\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There\'s a descriptive title that will make sense to other developers some time from now. \r\n- [x] There\'s associated issues. All PR\'s should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n'"
553194291,4684,b'fix reg path when take memory dump',"b'seeing below error from CI, fix the path format:\r\n\r\n""C:\\Windows\\system32\\cmd.exe"" /D /E:ON /V:OFF /S /C ""CALL ""F:\\workspace\\_work\\_temp\\12c42bfd-4cdb-4cfb-ab8c-35ee6b913464.cmd""""\r\nERROR: Invalid key name.\r\nType ""REG ADD /?"" for usage.\r\nERROR: Invalid key name.\r\nType ""REG ADD /?"" for usage.\r\nERROR: Invalid key name.\r\nType ""REG ADD /?"" for usage.\r\nERROR: Invalid key name.\r\nType ""REG ADD /?"" for usage.\r\n\r\n\r\n'"
553103631,4683,b'retry more times on tensorflow test',b'retry more times on tensorflow tests\r\n\r\n'
553078711,4682,b'update Assembly Key in AutoML and CodeGen',"b""Since mlnet and mlnet.test are already moved into modelbuilder's repo, update assembly key in AutoML and CodeGenerator project to allow mlnet to visit internal classes from those two projects\r\n\r\nRelated Issue:\r\n[Update mlnet and mlnet.test assembly key to match modelbuilder's](https://github.com/dotnet/machinelearning-modelbuilder/issues/453)"""
551919388,4676,"b'Add support for stateful custom mappers, and for custom filters.'",b'Fixes #4675 .'
551699185,4674,b'F1-score to return 0.0 instead of NaN',b'Fixes #4664'
551662681,4673,b'Update documentation to stop mentioning interfaces that no longer exist',"b'So some weeks ago I noticed that the documentation under `docs/code` mention several interfaces that currently don\'t exist in ML.NET\'s codebase. They existed back in TLC... and perhaps some of them, if not all of them, actually made it into ML.NET before version 1.0 release... but the case is that they no longer exist, so I just wanted to update them.\r\n\r\nAfter looking into the TLC code, I decided to make the following replacements in the docs:\r\nISchema -> DataViewSchema\r\nIRandom -> System.Random\r\nIRow -> DataViewRow\r\nIRowCursor and ICursor -> DataViewRowCursor\r\nIDataReader -> IDataLoader\r\n\r\n### Side notes\r\n1. **About IRandom**: In TLC it seems that only `SysRandom `and `TauswortheHybrid ` implemented `IRandom`. In ML.NET `IRandom` and `SysRandom` don\'t exist, but `TauswortheHybrid` inherits from System.Random. So I guess it\'s safe to replace `IRandom` for ""System.Random"" in the docs.'"
551228320,4669,b'retry and disable tests to get stable CI',"b'Due to test in private agent pool, these 2 tests seems crashing test host process, try to disable them.\r\n\r\nhttps://dev.azure.com/dnceng/public/_build?definitionId=712&_a=summary\r\n\r\n'"
551131544,4667,b'retry flaky tests',"b'1. new retry fact to retry flaky tests, at most 2 times by default\r\n2. use retry fact to some known flaky tests, below is the list:\r\n\tSsaForecast\r\n\tTensorFlowImageClassificationWithPolynomialLRScheduling\r\n\tTensorFlowImageClassificationDefault\r\n\tTensorFlowImageClassificationBadImages\r\n\tCrossValidationIris\r\n\tTestOvaMacro\r\n\tEntryPointChainedCrossValMacros\r\n\tEntryPointSDCARegression\r\n\tTestOvaMacroWithUncalibratedLearner\r\n\tMulticlassTreeFeaturizedLRTest\r\n\tBinaryClassifierSymSgdTest\r\n\tBinaryClassifierLogisticRegressionBinNormTest\r\n\tTestGAMRegression\r\n\tRegressionTrainersOnnxConversionTest\r\n\tTestGcnNormCommandLine\r\n\tSavePipeSlidingWindow\r\n3. this is only to mitigate flaky tests with retry, not to address test crash or test hanging issues\r\n\r\n'"
551021842,4666,"b'collect crash dump, upload dump and pdb to artifact'",b'1. collect crash dump when test host process crashes\r\n2. upload dump and pdb to artifact for further investigate'
551002160,4665,b'TextLoader now checks for presence of source file with clear error message',"b'Fixed #2461 \r\n\r\nTextLoader now checks whether the given file in path exists. If the file is missing, a clear exception stating that the file is missing is given, instead of stating that some field is missing some unknown attribute.'"
550495092,4662,b'Throw exception in ImageClassificationTrainer when dataset contains only 1 class',b'Throw exception in ImageClassificationTrainer when dataset contains only 1 class\r\n\r\nFixes #4660 \r\n\r\n'
550413875,4661,b'added in support for System.DateTime type for the DateTimeTransformer',b'Added in support to the `DateTimeTransformer` to use columns of `DateTime` type.\r\n\r\nRemoved the thread safe caching as its faster to just query the native code multiple times then to deal with the thread safe cache.'
550375718,4659,b'Testing changing the behavior of baseline Fail function',b'Draft PR to try to get callstacks at the point of failure. '
550131278,4657,b'Use random file name for AutoML experiment folder',b'Address #3803 by using a random file name when creating the AutoML experiment folder.'
549922709,4655,"b""Added documentation regarding TextLoader's hasHeader field""","b""Fixes #3053\r\n\r\nAdded note regarding TextLoader's hasHeader field per @yaeldekel 's suggestion in #3053."""
549920100,4654,"b""Added documentation regarding TextLoader's hasHeader field""","b""Fixes #3053 \r\n\r\nAdded note regarding TextLoader's hasHeader field per @yaeldekel 's suggestion in #3053."""
549886927,4653,b'add log for Ssaforecast test',b'Add logs to investigate SsaForecast test issue.\r\n\r\nOne example is in this build: https://dev.azure.com/dnceng/public/_build/results?buildId=480666&view=logs&j=4b233af4-7b14-5f68-27c6-9c4d7ac87519&t=6e2e87e8-8c33-50e6-544b-c271638494a5\r\n\r\nError message: \r\n[xUnit.net 00:00:02.58]     Microsoft.ML.Tests.TimeSeries.SsaForecast [FAIL]\r\n  X Microsoft.ML.Tests.TimeSeries.SsaForecast [95ms]\r\n  Error Message:\r\n   Assert.Equal() Failure\r\nExpected: 0.1914917 (rounded from 0.191491723060608)\r\nActual:   -8.1287222 (rounded from -8.12872219085693)\r\n  Stack Trace:\r\n     at Microsoft.ML.Tests.TimeSeries.SsaForecast() in /Users/runner/runners/2.163.1/work/1/s/test/Microsoft.ML.TimeSeries.Tests/TimeSeriesDirectApi.cs:line 373\r\n\r\n\r\n'
549871363,4652,b'Fixes None dimension bug',"b'Bug: #4646 \r\n\r\nML.Net considers empty dimensions invalid. However, the ""None"" dimension is valid in OnnxRuntime.  '"
549235264,4650,b'Cancellation in Image Classification (fixes #4632)',"b""Adds support for cancellation to the Image Classification trainer in a similar manner as done in #3062 (and [other PRs](https://github.com/dotnet/machinelearning/pulls?utf8=%E2%9C%93&q=is%3Apr+is%3Aclosed+cancellation++)) by adding cancellation checkpoints to the train method.\r\n\r\nI've tested it by running the sample related to this trainer. Since the other PR's that included checkpoints for cancellation don't include unit tests, I also didn't include any in here.\r\n\r\nFixes #4632 ."""
549102136,4647,b'Fixed xref formatting',b'Fixes #4611 \r\n\r\nUpdated cross-references of ML.Data.ExpressionTransformer and ML.Data.VectorDataViewType to the correct format. \r\n\r\nAB#1667125'
548452044,4645,b'Use a GUID when creating the temp path',"b'Addresses #568.\r\n\r\n@justinormont Not sure if the placement of it is the best, but it should still prevent the collisions.\r\n\r\nEdit: Fixes #568 (added so that issue #568 will close automatically when this PR is successfully merged.)'"
548423479,4644,b'NormalizeMinMax Multicolumn example',"b'Update for #3436 for the NormalizeMinMax transform.\r\n\r\n@sfilipi Took a shot at adding a multicolumn sample. If this is on the right track, I can help with some of the others.'"
548176643,4642,b'Misc misspellings',b'Fix issue #4638 \r\n\r\n'
547690441,4639,"b'Featurizers Nuget fix, DateTimeTransformer path fix'","b'Fix the nuget package to also add in netcoreapp2.1 as a target framework.\r\n\r\nNimbus ML moves the native code DLL from where it is restored to a different location. This was causing issues with finding the data files required for DateTimeTransformer to do holidays correctly. This change makes the DateTimeTransformer look in 2 places for the existence of the data files, the restore location and the current location of the .dll, resolving the issues.'"
546573204,4636,b'Added onnx export for NaiveBayesMulticlassTrainer',b'\r\n'
546545535,4635,b'Using invariance culture when converting to string',b'related Issue:\r\n- [Exception while auto-train with regression task](https://github.com/dotnet/machinelearning-modelbuilder/issues/363)\r\n- #4634 '
546458290,4633,b'Contributing: Fix typos',b'Fixing some typos\r\n\r\n\r\n'
545409476,4631,b'Contributing: Fix typo',b'Fixed some spelling errors.\r\n\r\n'
545406570,4629,b'Contributing: Fix typo',b'specifiy --> specify\r\n'
545394971,4628,b'Fix Typo: an Microsoft > a Microsoft',"b""Fix Typo: an Microsoft internal framework > a Microsoft internal framework\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n"""
545271264,4627,b'Contributing: Fix typo',b'Fixing a typo: bottlenect -->bottleneck\r\n\r\n'
545270654,4626,b'Contributing: fix a typo',b'Fixing a typo Micrsoft --> Microsoft\r\n\r\n'
545223659,4625,b'Test stable cross validation iris',"b'several fluky tests that call stack seems similar, add some debug log to help trouble shoot:\r\n\r\nMicrosoft.ML.Tests.Scenarios.Api.CookbookSamples.CookbookSamplesDynamicApi.CrossValidationIris [48s 317ms] \r\nError Message: \r\nAssert failed: longIdx=32, invariants.Length=32 \r\nExpected: True \r\nActual: False \r\nStack Trace: \r\nat Microsoft.ML.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in F:\\workspace\\_work\\1\\s\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs:line 71 \r\nat Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 781 \r\nat Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 794 \r\nat Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 852 \r\nat Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.StandardTrainers\\Standard\\SdcaBinary.cs:line 574 \r\nat Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.StandardTrainers\\Standard\\StochasticTrainerBase.cs:line 43 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 157 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 77 \r\nat Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 67 \r\nat Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Data\\TrainCatalog.cs:line 104 \r\nat Microsoft.ML.MulticlassClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numberOfFolds, String labelColumnName, String samplingKeyColumnName, Nullable`1 seed) in F:\\workspace\\_work\\1\\s\\src\\Microsoft.ML.Data\\TrainCatalog.cs:line 535 \r\nat Microsoft.ML.Tests.Scenarios.Api.CookbookSamples.CookbookSamplesDynamicApi.CrossValidationOn(String dataPath) in F:\\workspace\\_work\\1\\s\\test\\Microsoft.ML.Tests\\Scenarios\\Api\\CookbookSamples\\CookbookSamplesDynamicApi.cs:line 590 \r\nat Microsoft.ML.Tests.Scenarios.Api.CookbookSamples.CookbookSamplesDynamicApi.CrossValidationIris() in F:\\workspace\\_work\\1\\s\\test\\Microsoft.ML.Tests\\Scenarios\\Api\\CookbookSamples\\CookbookSamplesDynamicApi.cs:line 553 \r\n\r\n\r\nMicrosoft.ML.RunTests.TestEntryPoints.TestOvaMacro [218ms] \r\nError Message: \r\nAssert failed: longIdx=139, invariants.Length=139 \r\nExpected: True \r\nActual: False \r\nStack Trace: \r\nat Microsoft.ML.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in /__w/1/s/test/Microsoft.ML.TestFramework/GlobalBase.cs:line 71 \r\nat Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in /__w/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 781 \r\nat Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in /__w/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 794 \r\nat Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in /__w/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 852 \r\nat Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount) in /__w/1/s/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs:line 574 \r\nat Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in /__w/1/s/src/Microsoft.ML.StandardTrainers/Standard/StochasticTrainerBase.cs:line 43 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.Microsoft.ML.ITrainer<Microsoft.ML.IPredictor>.Train(TrainContext context) in /__w/1/s/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 100 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.Microsoft.ML.ITrainer.Train(TrainContext context) in /__w/1/s/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 168 \r\nat Microsoft.ML.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor, RoleMappedData testData) in /__w/1/s/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 280 \r\nat Microsoft.ML.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in /__w/1/s/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 249 \r\nat Microsoft.ML.EntryPoints.TrainerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in /__w/1/s/src/Microsoft.ML.Data/EntryPoints/InputBase.cs:line 119 \r\nat Microsoft.ML.Trainers.Sdca.TrainBinary(IHostEnvironment env, Options input) in /__w/1/s/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs:line 2488 \r\nStandard Output Messages: \r\nTest TestOvaMacro: aborted: passed \r\n\r\n\r\n\r\n[xUnit.net 00:00:46.41] Microsoft.ML.RunTests.TestEntryPoints.EntryPointChainedCrossValMacros(iteration: 44) [FAIL] \r\n77-th running... \r\nX Microsoft.ML.RunTests.TestEntryPoints.EntryPointChainedCrossValMacros(iteration: 44) [173ms] \r\nError Message: \r\nAssert failed: longIdx=335, invariants.Length=335 \r\nExpected: True \r\nActual: False \r\nStack Trace: \r\nat Microsoft.ML.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in D:\\a\\1\\s\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs:line 71 \r\nat Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 781 \r\nat Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 794 \r\nat Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 852 \r\nat Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardTrainers\\Standard\\SdcaBinary.cs:line 574 \r\nat Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardTrainers\\Standard\\StochasticTrainerBase.cs:line 43 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.Microsoft.ML.ITrainer<Microsoft.ML.IPredictor>.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 100 \r\nat Microsoft.ML.Trainers.TrainerEstimatorBase`2.Microsoft.ML.ITrainer.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 168 \r\nat Microsoft.ML.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor, RoleMappedData testData) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 280 \r\nat Microsoft.ML.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 249 \r\nat Microsoft.ML.EntryPoints.TrainerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 119 \r\nat Microsoft.ML.Trainers.Sdca.TrainBinary(IHostEnvironment env, Options input) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardTrainers\\Standard\\SdcaBinary.cs:line 2488 \r\nStandard Output Messages: \r\nTest EntryPointChainedCrossValMacros: aborted: passed \r\n\r\n\r\n\r\n\r\n'"
545179686,4624,b'remove unnecessary finalizer from imageclassification trainer',b'1. remove unnecessary finalizer from imageclassification trainer\r\n2. simplify conditional check'
545122002,4623,b'TimeSeriesImputer featurizer added',"b""This change adds in the TimeSeriesImputer into the new TimeSeriesImputer project. It is the final of a series of PR's that will go in. The TimeSeriesImputer is implemented in native code, so this is mostly just a wrapper around that with the appropriate entrypoints for NimbusML as well.\r\n\r\nThe TimeSeriesImputer imputes rows and columns based on the time series given. This is the first transformer that imputes rows in ML.NET."""
545121450,4622,b'ToString Featurizer added',"b""This change adds in the ToStringTransformer into the new Featurizers project. It is the fourth of a series of PR's that will go in. The ToStringTransformer is implemented in native code, so this is mostly just a wrapper around that with the appropriate entrypoints for NimbusML as well.\r\n\r\nThe ToStringTransformer converts values into the appropriate string representations.\r\n\r\nThis code is auto generated. The functionality will be migrated into the existing type conversion over the next several weeks and this file will be removed, but its going in as is to unblock other development work."""
545019396,4621,b'Remove unnecessary finalizer',"b'LatentDirichletAllocationTransformer does not directly own any unmanaged resources, so it does not need a finalizer.\r\n'"
544816063,4620,b'Prevent LatentDirichletAllocationTransformer from disposal prior to end of test',"b'Fixes test exceptions which look like this:\r\n\r\n```text\r\n  X Microsoft.ML.RunTests.TestDataPipeNoBaseline.TestLDATransform(iteration: 92) [198ms]\r\n  Error Message:\r\n   System.InvalidOperationException : Splitter/consolidator worker encountered exception while consuming source data\r\n---- System.ObjectDisposedException : Safe handle has been closed\r\n  Stack Trace:\r\n     at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 832\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 1102\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 65\r\n   at Microsoft.ML.RunTests.TestDataPipeNoBaseline.TestLDATransform(Int32 iteration) in D:\\a\\1\\s\\test\\Microsoft.ML.TestFramework\\DataPipe\\TestDataPipe.cs:line 1462\r\n----- Inner Stack Trace -----\r\n   at System.Runtime.InteropServices.SafeHandle.DangerousAddRef(Boolean& success)\r\n   at System.StubHelpers.StubHelpers.SafeHandleAddRef(SafeHandle pHandle, Boolean& success)\r\n   at Microsoft.ML.TextAnalytics.LdaInterface.InitializeBeforeTest(SafeLdaEngineHandle engine)\r\n   at Microsoft.ML.Transforms.Text.LatentDirichletAllocationTransformer.LdaState.Output(VBuffer`1& src, VBuffer`1& dst, Int32 numBurninIter, Boolean reset) in D:\\a\\1\\s\\src\\Microsoft.ML.Transforms\\Text\\LdaTransform.cs:line 470\r\n   at Microsoft.ML.Transforms.Text.LatentDirichletAllocationTransformer.Mapper.<>c__DisplayClass5_0.<GetTopic>b__0(VBuffer`1& dst) in D:\\a\\1\\s\\src\\Microsoft.ML.Transforms\\Text\\LdaTransform.cs:line 612\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill() in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 723\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2() in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 415\r\n```\r\n\r\nThe issue occurred because the finalizer for `LatentDirichletAllocationTransformer` was causing states to get disposed while they were still in use.'"
544382766,4617,b'Contributing: fix a typo',b'## Fixing a typo:\r\n\r\n- Fix typo in the comments of Dispose methods. \r\n\r\n'
544354359,4616,b'Fix documentation of SvmLightLoader',"b'Together with PR #4614, fixes #4610 .'"
544347866,4614,b'Additional changes to ExpressionTransformer',b'This PR addresses the ExpressionTransformer part of issue #4610 and also addresses some left over comments from PR #4548 .'
544317108,4613,b'refine TensorFlowTransformer to avoid early dispose',"b""from build: https://dev.azure.com/dnceng/public/_build/results?buildId=468639&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\nbelow unhandled exception:\r\n\r\n```\r\nUnhandled exception: System.ObjectDisposedException: Cannot access a disposed object.\r\nObject name: 'The ThreadLocal object has been disposed.'.\r\nat System.Threading.ThreadLocal`1.GetValueSlow()\r\nat Tensorflow.Graph.DisposeManagedResources()\r\nat Tensorflow.DisposableObject.internal_dispose(Boolean disposing)\r\nat Tensorflow.DisposableObject.Dispose()\r\nat Microsoft.ML.Transforms.TensorFlowTransformer.Dispose(Boolean disposing) in D:\\a\\1\\s\\src\\Microsoft.ML.TensorFlow\\TensorflowTransform.cs:line 467\r\nat Microsoft.ML.Transforms.TensorFlowTransformer.Finalize() in D:\\a\\1\\s\\src\\Microsoft.ML.TensorFlow\\TensorflowTransform.cs:line 450\r\n```\r\n\r\n\r\n"""
544297345,4612,b'Release notes.',b'Release notes for 1.5.0-preview and 1.4.0.\r\n'
544064717,4609,b'fix mac os Install build dependencies error',"b""error message is:\r\n\r\n==> Installing mono-libgdiplus dependency: python\r\n==> Downloading https://homebrew.bintray.com/bottles/python-3.7.6.high_sierra.bottle.tar.gz\r\n==> Downloading from https://akamai.bintray.com/85/853a5c89053fa747daf1779a515df60648b56968317aa8865dfdd058f1520bad?__gda__=exp=1577751065~hmac=55ee60182c766308e6945cb69742fe63e1a1cff345734c944bb682cf7d3900c8&response-content-disposition=attachment%3Bfilename%3D%22python-3.7.6.high_sierra.bottle.tar.gz%22&response-content-type=application%2Fgzip&requestInfo=U2FsdGVkX1-bggRq2F1shc2wtnvALSz26IT4dCWuBsB4qZLdtxnnxtoGPpDVd7Emi-5FtMSiqaK3ejwg-IICAlAi4pHk9rEOR3laR8WtsVIJyHYdS4tKW0bHAs60S-r3UYAYWwsbbDpf0a7BBxilGg&response-X-Checksum-Sha1=84747f875e642c09a209da71f5e7986d002d6b68&response-X-Checksum-Sha2=853a5c89053fa747daf1779a515df60648b56968317aa8865dfdd058f1520bad\r\n==> Pouring python-3.7.6.high_sierra.bottle.tar.gz\r\nError: The `brew link` step did not complete successfully\r\nThe formula built, but is not symlinked into /usr/local\r\nCould not symlink Frameworks/Python.framework/Headers\r\nTarget /usr/local/Frameworks/Python.framework/Headers\r\nis a symlink belonging to python@2. You can unlink it:\r\n  brew unlink python@2\r\n\r\nTo force the link and overwrite all conflicting files:\r\n  brew link --overwrite python\r\n\r\nTo list all files that would be deleted:\r\n  brew link --overwrite --dry-run python\r\n\r\nPossible conflicting files are:\r\n/usr/local/Frameworks/Python.framework/Headers -> /usr/local/Cellar/python@2/2.7.17/Frameworks/Python.framework/Headers\r\n/usr/local/Frameworks/Python.framework/Python -> /usr/local/Cellar/python@2/2.7.17/Frameworks/Python.framework/Python\r\n/usr/local/Frameworks/Python.framework/Resources -> /usr/local/Cellar/python@2/2.7.17/Frameworks/Python.framework/Resources\r\n/usr/local/Frameworks/Python.framework/Versions/Current -> /usr/local/Cellar/python@2/2.7.17/Frameworks/Python.framework/Versions/Current\r\n==> /usr/local/Cellar/python/3.7.6/bin/python3 -s setup.py --no-user-cfg install --force --verbose --install-scripts=/usr/local/Cellar/python/3.7.6/bin --install-lib=/usr/local/lib/python3.7/site-packages --single-version-externally-managed --record=installed.txt\r\n==> /usr/local/Cellar/python/3.7.6/bin/python3 -s setup.py --no-user-cfg install --force --verbose --install-scripts=/usr/local/Cellar/python/3.7.6/bin --install-lib=/usr/local/lib/python3.7/site-packages --single-version-externally-managed --record=installed.txt\r\n==> /usr/local/Cellar/python/3.7.6/bin/python3 -s setup.py --no-user-cfg install --force --verbose --install-scripts=/usr/local/Cellar/python/3.7.6/bin --install-lib=/usr/local/lib/python3.7/site-packages --single-version-externally-managed --record=installed.txt\r\n==> Caveats\r\nPython has been installed as\r\n  /usr/local/bin/python3\r\n\r\nUnversioned symlinks `python`, `python-config`, `pip` etc. pointing to\r\n`python3`, `python3-config`, `pip3` etc., respectively, have been installed into\r\n  /usr/local/opt/python/libexec/bin\r\n\r\nIf you need Homebrew's Python 2.7 run\r\n  brew install python@2\r\n\r\nYou can install Python packages with\r\n  pip3 install <package>\r\nThey will install into the site-package directory\r\n  /usr/local/lib/python3.7/site-packages\r\n\r\n"""
544052061,4608,b'Fixes #3878. About calling Fit more than once on Multiclass LightGBM trainer.',"b'Fixes #3878, by initializing the values of _`tlcNumClass` and `_numClass` everytime `Fit()` is called on a Multiclass LightGBM trainer. This is done under the assumption that trainers should behave as if they were stateless, and every call to `Fit()` should re-initialize those values.\r\n\r\nAs discussed offline with @yaeldekel , `_tlcNumClass` and `_numClass` hold the same value if there were no NaN labels on the dataset used for training. If there were NaN labels then `_tlcNumClass = _numClass - 1`. Mantaining both fields is necessary, because [here](https://github.com/dotnet/machinelearning/blob/aa5b3be14eeab1160dca2cc08561190141199f4f/src/Microsoft.ML.LightGbm/LightGbmMulticlassTrainer.cs#L219) NaN labels are replaced to be a new class, and then, [here](https://github.com/dotnet/machinelearning/blob/aa5b3be14eeab1160dca2cc08561190141199f4f/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L620), when training the `WrappedLightGbmTraining` it is as if NaN labels were an extra class, but then [here](https://github.com/dotnet/machinelearning/blob/aa5b3be14eeab1160dca2cc08561190141199f4f/src/Microsoft.ML.LightGbm/LightGbmMulticlassTrainer.cs#L185), when creating the Predictors, only `_tlcNumClass` predictors are created. So, for example, if I have a dataset with 3 classes (0-2), but some rows have NaN values on their labels, then NaN values get converted to ""3"", `_numClass` is equal to ""4"" and `WrappedLightGbmTraining` trains as if there were truly 4 classes... but `_tlcNumClass` is equal to ""3"" and when creating the Predictors, only 3 predictors are created (one for each of the original classes ignoring the ""fake NaN class"").\r\n\r\nThe above wasn\'t documented in the code, but after doing some tests it seems that is how it is supposed to behave, and so I added some comments explaining this, as @yaeldekel  and I agree that the above isn\'t really clear directly from reading the code, and the names `_tlcNumClass` and `_numClass` are somewhat obscure.\r\n\r\nI also added a test.'"
542648388,4604,b'Increment build version for 1.5-preview and 0.17-preview release.',b'\r\n'
541926451,4602,b'Only for test - Ssaforecast issue',b'\r\n'
540651772,4598,b'Fixes #4074. About adding a word to French stopwords',"b'Fixes #4074 \r\n\r\nSimply adds the word ""les"" to the French stopwords list.'"
540610936,4597,b'Add Robust Scaler Featurizer',"b""This change adds in the RobustScaler into the new Featurizers project. It is the third of a series of PR's that will go in. The RobustScaler is implemented in native code, so this is mostly just a wrapper around that with the appropriate entrypoints for NimbusML as well.\r\n\r\nThe RobustScaler scales and centers numerical values based on the quantile range specified. \r\n\r\nThis code is auto generated. The functionality will be migrated into the NormalizingTransformer over the next several weeks and this file will be removed, but its going in as is to unblock other development work."""
540527509,4596,b'ONNX Conversion for Hashing Transformer',"b'Here is the draft for Onnx Conversion for Hashing transformer.\r\nPlease not that some test will not pass because onnx only support string and uint for murmur hash3\r\nand also needs to add mask and useOrderedHashing to be compatible with ML.NET\r\nFurther more there is a bug in ORT regarding UTF 8 encoding, (they fixed it in this PR: https://github.com/microsoft/onnxruntime/pull/2697), but I think the next release is in about 2 months\r\n\r\n'"
539949775,4594,b'Add Category Imputer Featurizer',"b'This change adds in the CategoryImputer into the new Featurizers project. It is the second of a series of PR\'s that will go in. The CategoryImputer is implemented in native code, so this is mostly just a wrapper around that with the appropriate entrypoints for NimbusML as well.\r\n\r\nThe CategoryImputer imputes missing values in a column based on the most frequent value seen during training. Due to not having support for nullable types in ML.NET, this only supports Float, Double, and Strings (with empty string being treated as ""missing"").\r\n\r\nThis code is auto generated. The functionality will be migrated into the MissingValueReplacer over the next several weeks and this file will be removed, but its going in as is to unblock other development work.'"
539948182,4593,b'Added onnx export status for all estimators and trainers',"b'In particular, please review OnnxTransform.cs and SSaForecasting.cs.'"
539901173,4592,b'fix System.ArgumentOutOfRangeException issue in CustomStopWordsRemovingTransformer',b'fix issue #4518 \r\n\r\n'
539896101,4591,b'fix System.ArgumentOutOfRangeException issue in CustomStopWordsRemovingTransformer',b'fix issue #4518 '
539857651,4590,b'Added onnx export support for SelectColumns',b'Implemented ability to export ColumnSelectingEstimator to onnx.'
539795685,4588,b'Optimize generic MethodInfo for Func<TResult>',"b""Repeated profiling showed MarshalInvoke as a _heavy_ performance bottleneck. Rather than remove the use of reflection at runtime altogether, this pull request demonstrates a strategy for caching the results of particularly expensive operations. The performance benefits come from two primary changes:\r\n\r\n1. `RuntimeReflectionExtensions.GetMethodInfo(Delegate)` is only called once for a given method\r\n2. `MethodInfo.GetGenericMethodDefinition()` is only called once for a given method\r\n\r\nIn this change, I am also caching the result of `MethodInfo.MakeGenericMethod`. It might not be necessary to cache this result, but it doesn't seem to hurt either.\r\n\r\n\xf0\x9f\x93\x9d This pull request is a demonstration of the process required to fully convert the code from the current pattern to the new pattern. I have only converted `MarshalInvoke<TRet>`; each of the others will need to be converted in a similar fashion."""
539741297,4587,b'Fix PFI issue in binary classification',b'This change adds support for running PFI on binary classification models that do not contain a calibrator. Fixes #4517 .'
539373595,4584,"b""fix TextLoader bug when there's newline between quotes """,b'A quick workaround for this Issue\r\n#4460 \r\nperhaps also this one\r\n#4555 \r\n\r\n'
538785927,4581,b'fix issue-4518',"b'fix issue #4518 , fix System.ArgumentOutOfRangeException in CustomStopWordsRemover\r\n\r\n'"
538739900,4580,b'[Not A Right Way] A quick fix for Recommendation Null Reference bug',b'#4579 '
537833474,4577,b'Added onnx export support for VectorWhitening',b'\r\n'
537772250,4576,b'Fixes #4571. About memory leak when using FeaturizeText.',"b""### Updated first post:\r\nOriginally this PR included different proposals to solve issue #4571 , which are described below. From all of them, proposal 3 was chosen, and now this PR only includes the changes of that Proposal.\r\n\r\n----------------------------------\r\n\r\n### Original first post:\r\nIn this PR I include 3 proposals to solve issue #4571:\r\n1. Modifying NormStr constructor\r\n- OR -\r\n2. Modifying TextNormalizer\r\n- OR -\r\n3. Modifying NormStr.Pool Get Method\r\n\r\n(the proposals are mutually exclusive, in that we are supposed to choose one of those, but I've included the three in this PR so that we can discuss about them, since @harishsk and I are unsure about the overall impact of each one, please let us know your opinion, and if there's anything else I should test)\r\n\r\nFor reference: Offline, @daholste provided me with a dataset which I can't share in here because of privacy reasons. It had 100k rows and 2.5k columns. When featurizing 22 of those columns, he got 22 NormStr Pools which, together, had an inclusive size of 2.25 GB, because many entire rows where held in memory, mainly because of the reason I described in [this comment](https://github.com/dotnet/machinelearning/issues/4571). The text that follows assume experiments based on that dataset, finding n-grams of size 1.\r\n\r\nWhen using Proposal 1 the inclusive size of the NormStr Pools went down from 2.25GB to 22MB. When using Proposal 2 it went down to 30MB. With Proposal 3 it went down to 22MB. With any of the proposals, or without them, the time for fitting was around 40 seconds on my machine.\r\n\r\nAll of the proposals are based in the idea of creating a `ReadOnlyMemory<char>` that doesn't have an `_object` member holding a reference to the string of the whole row.\r\n\r\n### Proposal 1 - Modifying NormStr constructor\r\n[Link to proposal](https://github.com/dotnet/machinelearning/pull/4576#discussion_r357827889)\r\n- Each NormStr has _object that only contains the text that NormStr is representing, and it's saved as a char[]\r\n- With @daholste's dataset 260k NormStrs are created, and each one of those holds a reference to the corresponding char[]\r\n- When fitting with this proposal, this was the Process Memory, notice the oscillations:\r\n![image](https://user-images.githubusercontent.com/38739674/70831324-1a86b080-1da7-11ea-957a-4a4c0675c83d.png)\r\n\r\n@harishsk  and I think the oscillations in memory usage are caused by the strings that are created with this implementation, but that are then garbage collected every once in a while, because no actual reference to them is kept.\r\n- All the references to entire rows were gone\r\n\r\n### Proposal 2 - Modifying Text Normalizer\r\n[Link to proposal](https://github.com/dotnet/machinelearning/pull/4576#discussion_r357827979)\r\n- _In general_, each NormStr has a _object of type string, which holds the content of the entire column where the NormStr was found.\r\n- With the dataset, 260k NormStrs are created, and less than 120k strings are held in memory.\r\n- When fitting with this proposal, this was the Process Memory graph, notice no oscillations:\r\n![image](https://user-images.githubusercontent.com/38739674/70831302-0d69c180-1da7-11ea-8e62-828b482188e9.png)\r\n\r\n- ~~Some references to entire rows were still there (I am still figuring out why). But there were only a few of them, compared to when there was no fix; as it is shown in the decrease in size of the NormStr pools I mentioned (from 2.2GB to 30MB), this proposal is still useful, at least for @daholste case.~~ All the references to strings containing entire rows are gone.\r\n\r\n### Proposal 3 - Modifying NormStr.Pool Get Method\r\n[Link to proposal](https://github.com/dotnet/machinelearning/pull/4576#discussion_r357871260)\r\n- Each NormStr has _object that only contains the text of the string that NormStr is representing\r\n- With the dataset, 260k NormStr were created, each one holding a reference to their corresponding string.\r\n- When fitting with this proposal, this was the Process Memory, notice the oscillations:\r\n![image](https://user-images.githubusercontent.com/38739674/70838311-7a3b8680-1dbc-11ea-91b5-29509bf4f100.png)\r\n- All the references to entire rows were gone"""
537302319,4573,b'Fix FastTree regression samples',b'Fix #4572 \r\n\r\nIncorrect trainers added to `FastTreeRegression` and `FastTreeTweedieRegression` in PR #3948'
537270139,4570,"b'fix issue 4528, use thread safe ConcurrentDictionary instead of Dictionary'",b'fix issue #4528 \r\n\r\n'
537197840,4569,b'Enable Conditional Numerical Reproducibility for tests',b''
536713828,4565,b'Updated baselines',b'* Update CheckEqualityFromPathsCore for clearer output on failure\r\n* Update test outputs now that validation is enabled'
536090016,4564,b'Adding Cyclic LR scheduling for Image Classification API ',b'This PR implements Cyclic Learning rate scheduler. The following paper has more information.\r\nhttps://arxiv.org/abs/1506.01186\r\n\r\nAlso added unit test and integration test for the same.\r\n'
536088250,4563,b'add document for method ChangeModelThreshold',"b'Fixes issue #4527 , add documentation for public method ChnageModelThreshold.\r\n\r\nThis method is introduced in #2969\r\n'"
536053200,4562,b'Added onnx export support for SlotsDroppingTransformer',"b'This work required the use of ConstantOfShape operator from onnx which has an attribute of type Tensor. Most operators have attributes that are of primitive types (int, float, etc). ML.NET Onnx converter coded didnt have support to add attributes of tensor types. \r\nTherefore this PR includes the support for adding tensor type attributes along with the necessary code and tests for SlotsDroppingTransformer. '"
535921255,4561,b'Add IterationDataAttribute',b''
535892862,4560,b'Add netcoreapp3.0 output for SsaForecast test',b''
535073567,4557,b'Add a test handler for AppDomain.UnhandledException',b''
535023372,4556,b'SsaForecast iterations experiment',b''
534605298,4552,b'WIP Log exceptions thrown within finalizers',b'Exceptions thrown from a finalizer will terminate the process.\r\n'
534598675,4551,b'Use std::unique_ptr for samplers_ and likelihood_in_iter_',b'Fixes an access violation in native code if `LdaEngine` is deleted before `samplers_` is initialized.'
534582582,4550,b'Add tests for ParameterSet equality',b'\xf0\x9f\x93\x9d Builds on #4549\r\n\r\nThis change stabilizes test coverage in `ParameterSet.Equals` and `ParameterSet.ContainsParamValue`.'
534580881,4549,b'Add tests for IParameterValue implementations',"b'This change provides deterministic coverage for the implementation of `LongParameterValue`, `FloatParameterValue`, and `StringParameterValue`.\r\n'"
534535423,4548,b'Expression estimator/transformer',b'Fixes #4015 .'
534472994,4547,b'Use std::unique_ptr for objects in LdaEngine',b'Builds on #4546'
534472376,4546,b'Pass by reference when null is not expected',b''
534472100,4545,b'Add Xunit.Combinatorial for test projects',b''
534471315,4544,b'WIP Safe pointers',b'Locally I converted most owned native objects to `std::unique_ptr` and `std::shared_ptr`. This pull request represents a relatively easy-to-review subset of the changes with minimal overall fan-out in the code.\r\n\r\n* Pass by reference when null is not expected (submitted separately as #4546)\r\n* Use `std::unique_ptr` for objects in `LdaEngine` (submitted separately as #4547)\r\n* Use `std::unique_ptr` for `samplers_` and `likelihood_in_iter_`'
534447833,4543,b'Update code coverage integration',b'* Simplifies coverage integration\r\n* Removes the need to define CODECOV_TOKEN during builds'
534340364,4540,b'Increase the code coverage run timeout',b'Most of the code coverage runs are timing out. Increase the timeout to match the value used for non-code-coverage builds.'
534332024,4539,b'Create SafeBoosterHandle and SafeDataSetHandle',b'These safe handles were created based on the crash data in https://dev.azure.com/dnceng/public/_build/results?buildId=449745&view=logs.'
534314921,4538,b'Convert LdaEngine to a SafeHandle',b'This pull request follows the test failure observed in https://dev.azure.com/dnceng/public/_build/results?buildId=449759&view=ms.vss-test-web.build-test-results-tab&runId=14347330&resultId=100770&paneView=debug. Converting this object to a SafeHandle has two primary advantages:\r\n\r\n1. The object will not be disposed while there is an ongoing native call\r\n2. Misuse of the object by trying to pass an invalid instance to a native call will throw an exception at the point of the call'
534302884,4537,b'Enable VSTestBlame to show details for crashes',b''
534297498,4536,b'Update Microsoft.Extensions.* to 3.0.1',"b'The 3.0 release includes a fix to cases where `ChangeToken.OnChange` would not unregister callbacks even when disposed.\r\n\r\nSee aspnet/Extensions#558, aspnet/Extensions#869'"
534294197,4535,b'Prevent exceptions from escaping FileSystemWatcher events',b'Exceptions in the handler of FileSystemWatcher events will terminate the process. This pull request updates the event handler to use a try/catch block that logs the error instead of crashing the process.\r\n\r\nThis fixes one known cause of test process failures.'
534292296,4534,b'Conditionally compile helper code',b'Fixes IDE0051 (Private member is unused) in tests.\r\n'
534291967,4533,b'Onnx conversion theory',b'Use `[Theory]` to break up tests in OnnxConversionTest.\r\n\r\n\xf0\x9f\x93\x9d Builds on #4532 and #4545\r\n\r\n\xf0\x9f\x92\xa1 Recommended review strategy is commit-by-commit. The final commit is easier to review with whitespace-only changes hidden.'
534291627,4532,b'Make test methods public',b'Fixes IDE0051 (Private member is unused)\r\n'
534291193,4531,b'Disable CS0649 in OnnxConversionTest',b'Fixes an IDE0051 warning (Private member is unused).'
534290511,4530,b'Make local functions static where applicable',b''
534290426,4529,b'Avoid running API Compat for design time builds',b'This change prevents the API compat tool from failing design time builds and leaving the IDE project model in a bad state for development.\r\n'
533750579,4526,b'add more log for SsaForecast test',b'1. add more log for SsaForecast test \r\n2. make TimeSeries test class inherent from BaseTestBaseline for logging\r\n\r\n'
533292844,4523,b'Add aka.ms aliases for files downloaded from Azure blobs',b'Fixes #4445 .'
533098218,4522,b'Image classification performance improvements and option to create validation set from train set.',b'This change improves the overall performance of image classification API and tensorflow transform by making the graph runner memory efficient and saving the bottleneck cached values in image classification API in binary format instead of text format.\r\n\r\nThis change also adds the option in Image Classification API to create validation set from train set in the event validation set is not provided by the user. Validation set is used for early stopping.'
532850454,4521,b'DateTimeTransformer featurizer',"b""This change adds in the DateTimeTransformer into the new Featurizers project. It is the first of a series of PR's that will go in. The DateTimeTransformer is implemented in native code, so this is mostly just a wrapper around that with the appropriate entrypoints for NimbusML as well. Since all the new estimator/transformers follow the same patterns, once this one is reviewed and checked in I will create the other PR's."""
531641247,4515,b'Adds PriorTrainer Onnx conversion',"b'\r\n1. Adding Onnx support for PriorTrainer \r\n       To follow the onnx construction pattern of other binary classifiers, this trainer uses the probability to predict labels, instead of score\r\n\r\n'"
531013626,4514,b'Learning with counts (Dracula) transformer',b'Fixes #4016.'
530490802,4512,b'Fixes #4505 Remove reliance on getting product version for model.zip/version.txt from FileVersionInfo and replace with using assembly custom attributes',b'Refer to original issue for further details of the reasons for this change.\r\n\r\nI have used AssemblyInformationalVersionAttribute to match the same behaviour as was introduced with the change to reliance of FileVersionInfo.GetVersionInfo. There is already a test covering -ModelFiles.DetermineNugetVersionFromModel in Microsoft.ML.FunctionalTests.'
529626089,4510,b'add fail retry for failed tests',b'Add MLNETFactAttribute and replace default Fact Attribute:\r\n1. every test case will retry for 3 times at max by default if the test fails\r\n2. log flaky tests to a sql db to better estimate which tests are fail often\r\n3. add default timeout for every tests\r\n4. refine logging\r\n\r\n'
529622803,4509,b'Correct inferring tensor shape for Tensorflow Transform',"b'Fixes #4364 partially.\r\nThe above issue brought into attention that there was a wrong assumption while inferring input tensor shape in TensorflowTransform. It was assumed that for a input node of a graph with unknown dimensions, all the dimensions would be the same, even though that is not true in most cases. For example, the most common tensor shape format for dealing with Image- based models is (batch_size, height, width, channels).\r\nThis change replaces this wrong check with more comprehensive method of inferring the input tensor shape.\r\nMore tests might need to be added for code coverage.  \r\n'"
529531672,4507,b'Fixed onnx export support for WordBagEstimator',b'Fixed a bug in ngram transform and added test for WordBagEstimator'
528450600,4503,b'improve test stability',b'1. add datatime when start/finish tests\r\n2. add timeout for thread waiting to prevent infinite wait\r\n3. fix cancel token cancel twice issue\r\n\r\n'
527485845,4500,b'Reenabling MacOS tests that had an issue with libgdiplus',"b""### Edited First Post:\r\nPR #4492 disabled some tests that threw a `System.DllNotFoundException : Unable to load DLL 'libgdiplus'`, when trying to run them on our MacOS CI Pipeline.\r\n\r\nAs explained below in this thread, the problem was on homebrew's side, and this PR was meant to give a provitional solution for the problem. Nonetheless, this problem has just been fixed on homebrew's side, so now this PR simply reenables those tests.\r\n\r\n-----------------------------\r\n\r\n### Original First Post:\r\nSolves the problem with MacOS Pipeline where certain tests threw a\r\n`System.DllNotFoundException : Unable to load DLL 'libgdiplus': The specified module could not be found`\r\n\r\nThe issue was caused somewhere in homebrew's installation, and one way to solve this issue is to actually make homebrew to build the libgdiplus library after downloading it (instead of downloading a prebuilt version from [https://homebrew.bintray.com/bottles/mono-libgdiplus-6.0.4.high_sierra.bottle.tar.gz](https://homebrew.bintray.com/bottles/mono-libgdiplus-6.0.4.high_sierra.bottle.tar.gz) which is where it gets libgdiplus if homebrew doesn't build it). For some reason that's still unknown to me, this prebuilt version isn't working as expected, and the above exception is thrown."""
527364014,4498,b'[AutoML] CodeGen For AzureAttach',"b'Transformer added:\r\n\r\nExtractPixel\r\nNormalizeMapping\r\nResizeImage\r\nApplyOnnxModel\r\nLabelMapping\r\n\r\nNotify that those are transformers that not exist in AutoML\r\n\r\nMake some refactor a bit in `AzureAttachCodeGenerator` so that it can expand to support Azure Attach smoothly plus more test friendly.\r\n\r\nThese are two E2E test for Azure CodeGen, \r\n[AzureCodeGeneratorTest](https://github.com/LittleLittleCloud/machinelearning/blob/da65aefadd40ea8cd35581a9fb44d1f3bc895096/test/Microsoft.ML.CodeGenerator.Tests/ApprovalTests/ConsoleCodeGeneratorTests.cs#L228)\r\n[AzureImageCodeGeneratorTest](https://github.com/LittleLittleCloud/machinelearning/blob/da65aefadd40ea8cd35581a9fb44d1f3bc895096/test/Microsoft.ML.CodeGenerator.Tests/ApprovalTests/ConsoleCodeGeneratorTests.cs#L193)\r\n\r\n\r\nSee [UCI_Adult](https://github.com/LittleLittleCloud/UCI_Adult) for classification case\r\n\r\nSee [AzureImage](https://github.com/LittleLittleCloud/AzureImage) For Image Classification case\r\n\r\n## Latest update (12/19/2019)\r\n\r\n- add CSharp prefix to interface (ICSharpProjectGenerator, ICSharpSolutionGenerator.... etc)\r\n- remove all partial class, (and IProjectFileGenerator). Create the ProjectFile class directly instead ( class CSharpProjectFile and class CSharpCodeFile) see [this](https://github.com/dotnet/machinelearning/blob/7eb3875ec163354c1d533ed91effa4f25a79aece/src/Microsoft.ML.CodeGenerator/CodeGenerator/CSharp/AzureCodeGenerator/AzureAttachConsoleAppCodeGenerator.cs#L39) for example\r\n- implement `IProjectGenerator` interface to `ICSharpSolutionGenerator` so both Azure CodeGen and local CodeGen will have the same API\r\n'"
527343723,4497,b'wip - CodeGen for Azure Attach Image',b'Transformer added:\r\n- ExtractPixel\r\n- NormalizeMapping\r\n- ResizeImage\r\n- ApplyOnnxModel\r\n\r\nNotify that those are transformers that not exist in AutoML'
526934018,4496,b'Adds mlnet src and test projects from feature branch',b'Adds mlnet src and test projects from features/automl into master branch\r\n\r\n- [x] pack mlnet\r\n\r\ncc: @LittleLittleCloud @eerhardt '
526885975,4495,b'Only for test - disable test parallelization ',b'\r\n\r\n'
526770949,4494,b'Add SQL command timeout option to database loader.',b'Fixes #4484 \r\n\r\nThis change adds a way to specify the SQL command timeout https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqlcommand.commandtimeout?view=netframework-4.8\r\nwhile creating the DatabaseSource.\r\n\r\n'
526282350,4492,b'Disable tests on macOS that depend on GDI+ library.',"b""Disabling bitmap related tests temporarily on macOS to unblock PRs that are stalled because macOS CI images don't seem to have GDI+ or related library."""
526266701,4490,b'Ignore hidden columns in AutoML schema checks of validation data',"b'Closes #4491\r\n\r\nWhen the AutoML API consumes data, it validates schema consistency between the train and validation data.\r\n\r\nThere are two bugs in this logic:\r\n\r\n1. The API asserts that the count of columns in the train and validation data must be equal. This throws an exception if the two data views have the same number of active columns but a different number of hidden columns. This PR updates to assert that the # of active (not hidden) columns in the train and validation data are equal.\r\n\r\n2. If either the train or validation data has a hidden column with a type that differs from an active column of the same name, an exception is thrown. This PR restricts type consistency checks to active columns only.'"
525965178,4489,b'Test MacOS pipeline problem',"b""Do not approve this branch.\r\n\r\nIt's only meant for testing the problems with the MacOS pipeline\r\n"""
524674219,4486,b'Added onnx export support for CopyColumns',b'Fixes #4218 '
524652987,4485,b'Fixes #4385 about calling the Create methods when loading models from disk',"b""Fixes #4385 \r\n\r\nAs concluded in the discussion there, if a class has both a constructor and a create method that matches the parameter types that the `ComponentCatalog `is looking for, then it should use the one which is public. If both are non-public, then it should use the internal one. If both have the same visibility then it should throw an exception.\r\n\r\nFor this to happen, I modified the `ComponentCatalog ` to work as described. I also had to change the visibility of several methods and constructors to work as described. Since, as per @yaeldekel 's instructions, the create method should be called instead of the constructor in all cases, then I did the following:\r\n1. For most classes, the case was that both the conflictive constructor and create method were private, so I simply made the create method internal.\r\n2. For LabelIndicatorTransform and SkipTakeFilter the conflictive constructors and create methods were public, so I made the constructors internal.\r\n3. For the following classes the constructor was internal, and the create method was private. In these cases I made the constructor private, and the create methods internal.\r\n\r\n```\r\nMicrosoft.ML.Trainers.FieldAwareFactorizationMachinePredictionTransformer\r\nMicrosoft.ML.Transforms.TimeSeries.IidChangePointDetector\r\nMicrosoft.ML.Transforms.TimeSeries.IidSpikeDetector\r\nMicrosoft.ML.Transforms.TimeSeries.SrCnnAnomalyDetector\r\nMicrosoft.ML.Transforms.TimeSeries.SsaChangePointDetector\r\nMicrosoft.ML.Transforms.TimeSeries.SsaForecastingTransformer\r\nMicrosoft.ML.Transforms.TimeSeries.SsaSpikeDetector\r\n```"""
523279423,4481,b'Improve key value mapping api docs',"b'We received many comments that the documentation for value to key mapping and the reverse is not clear, including this issue: https://github.com/dotnet/docs/issues/13590.\r\n\r\nThis PR attempts to address those concerns.\r\n\r\nPlease review with a focus in clarity for the user of this API:\r\n- what does this API do?\r\n- when would I use each of the different methods?\r\n- how does this API fit into the larger ML.NET framework?'"
523143103,4479,b'Ensure BufferBlocks are completed and empty in RowShufflingTransformer.',"b""If BufferBlock doesn't get completed and drained of its items, it will have non-completed Tasks. When debugging in VS, this will appear to be a memory leak because VS adds all running Tasks to a static Dictionary, and then removes them when the Task is complete. If the Task doesn't get completed, it won't be removed from the Dictionary - thus it looks like a leak.\r\n\r\nNote there is no leak when the VS Debugger isn't attached because the non-completed Tasks don't get added to the static Dictionary.\r\n\r\nFix #4399"""
522576606,4477,b'Only for test: open system diagnotise log',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
522492190,4476,b'Add Entrypoint for ImageClassification Trainer.',b'This change adds a NimbusML entrypoint to the ImageClassification Trainer. It modifies the ImageLoader transform to add an option to load in-memory images. This change also adds a unit test to test the entrypoint.\r\n\r\n'
522426246,4475,b'Change the dataset used for unit test to fix issue on Linux',b'There is an issue with how some of the images were saved in the dataset\r\nsuch that they were not being read properly on linux. As such accuracy\r\nwas dramatically reduced given the small size of the dataset to begin\r\nwith. Have corrected the images and made a new dataset such that this\r\nissue should now be resolved.\r\n'
522239295,4474,"b""Add Model Builder's GPU version of the AutoMLService to the InternalsVisibleTo.""","b""Add Model Builder's GPU version of the AutoMLService to the InternalsVisibleTo. This allows Model Builder to run AutoML and call into CodeGen.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
521828372,4472,b'Fixed model saving and loading of OneVersusAllTrainer to include SoftMax',"b'When the model parameters from OnVersusAllTrainer are persisted, it currently writes a single bool byte to indicate what type of output formula to use during prediction. If that byte is false, it outputs raw values else it outputs probability values normalized to one. \r\nThe sample code in this bug uses AutoML to request a softmax output. The code currently only checks whether the output type is ImplDist which excludes softmax output.\r\n\r\nThis PR changes the saved model format in a backward compatible way by continuing to write a single byte for output type and continues to use 0 for raw output, 1 for probability normalization but also adds 2 to indicate SoftMax. These values are already in alignment with the OutputFormula enum.\r\n\r\nFixes #4450 \r\nFixes #3647\r\nFixes #4051 '"
521036891,4465,b'CpuMathNative assembly is not getting copied when using packages.config.',"b'When we refactored CpuMath to support netcoreapp3.0, we broke the packages.config support to copy the native assembly. This fixes it again by copying the file from the correct location.\r\n\r\nFix #93\r\n'"
520290269,4463,b'Fixes onnx exports for binary classification trainers',"b""This PR fixes the issues with exporting the following binary classification trainers to onnx:\r\n\r\n- SymbolicSgdLogisticRegression(),\r\n- SgdCalibrated(),\r\n- AveragedPerceptron(),\r\n- FastForest(),\r\n- LinearSvm(),\r\n- SdcaNonCalibrated(),\r\n- SgdNonCalibrated(),\r\n- FastTree(),\r\n- LbfgsLogisticRegression(),\r\n- Trainers.LightGbm(),\r\n- SdcaLogisticRegression(),\r\n\r\n\r\nNote: I couldn't create consistent regression models, even when seeding, so I didn't include baseline comparison on these tests. \r\n"""
520284210,4462,b'Added onnx export support for several multiclass classifiers',b'This PR adds Onnx export support + tests for the following multiclass classifiers:\r\n* LbfgsMaximumEntropyMulticlassTrainer\r\n* LightGbmMulticlassTrainer\r\n* LightGbmMulticlassTrainer with SoftMax\r\n* OneVersusAllTrainer\r\n* SdcaMaximumEntropyMulticlassTrainer\r\n* SdcaNonCalibratedMulticlassTrainer\r\n\r\nThere is a question marked with a REVIEW comment in the PR below. Please comment if you know of a better way to do what is done there. \r\n\r\n'
519580553,4458,b'Fix a flaky Extensions.ML test.',b'Make the reload model tests more resistant to timing changes.'
519537667,4457,b'Retro-fitted changes made to the ML docs repo into ML.NET',b'Retro-fitted changes made to the ML docs repository into ML.NET.\r\n'
519536274,4456,"b'Reduce time taken for first prediction, Fixes #4428'","b'Fixes #4428 \r\nAs reported in the issue, the first prediction takes a lot longer than the subsequent predictions.\r\nThis is due to the tensorflow initialization/graph optimizations happenning on at the time of the first prediction. \r\nIn order to mask the time within the PredictionEngine creation, this change runs the prediction \r\n on the tensorflow graph with a dummy tensor of the same size as an Imagenet image, of zeros. \r\n'"
519424587,4455,b'Added onnx export support for KeyToValueMappingTransformer',b''
519420715,4454,b'Added onnx export support for OptionalColumnTransform ',"b'Optional columns in ML.NET are supported through initializers in Onnx runtime, support for which was added in the v1 release of ORT. This PR adds support for integrating initializers in ML.NET and adding the corresponding OptionalColumnTransform support in ML.NET.'"
519399770,4453,b'Increment stable API version and add new stable packages to the list.',b''
518988708,4451,b'Added onnx export support for WordTokenizingTransformer and NgramExtractingTransformer',b'PR contents:\r\n* Onnx export support for for WordTokenizingTransformer and NgramExtractingTransformer\r\n* Related bug fixes in ValueToKeyMappingTransformer\r\n* Bug fixes for string handling in OnnxUtils.cs\r\n* Related unit tests\r\n'
518887333,4448,b'Fixes onnx exports for regression trainers',b'\r\nThis PR fixes the issues with exporting the following regression trainers to onnx:\r\n- LbfgsPoissonRegression\r\n- FastTreeTweedie\r\n- FastForest\r\n\r\nAnd adds onnx conversion tests for the following regression trainers: \r\n- FastTree\r\n- OnlineGradientDescent\r\n- Ols\r\n- LightGbm\r\n- Sdca'
518695258,4447,b'Modified Tensorflow ImageClassification tests to make them faster',b'1. Added a IClassFixture to create a workspace path only once before all the tests are run.\r\n2. Allow re-use of cached values wherever possible.\r\nSpeed-ups:\r\nBefore Tensorflow Test fixes - Tests took 8.67 minutes on an average.\r\nAfter Tensorflow Test fixes - Tests took 7.33 minutes on an average.\r\nThese are results with Polynomial LR test disabled. We expect better speed ups as we add more tests.\r\n'
518688777,4446,b'Stabilize the LR test',"b'Found issue with how we were using random for our\r\nImageClassificationTrainer. This caused instability in our unit test, as\r\nwe were not able to control the random seed. Modified the code to now\r\nuse the same random object throughout, the trainer, thus allowing us to\r\ncontrol the seed and therefor have predictable output.\r\n'"
518255830,4444,b'nightly build pipeline',"b'new nightly build pipeline:\r\n\r\n1. add new nightly build pipeline project, disable project build from solution\r\n2. add NuGet package version updater project\r\n3. add new Azure nightly build pipeline and template file\r\n4. TestFrameworkCommon project use conditional reference to source code:\r\n    a. when reference from functional test, use project reference\r\n    b. when reference from nightly build test, use package reference\r\n5. process of nightly build pipeline:\r\n    a. get latest NuGet package version from public NuGet feed\r\n    b. update version to .props file\r\n    c. build nightly build project\r\n    d. run nightly build tests, which is functional test for now\r\n    e. output test results\r\n6. a sample test pipeline can be seems here: https://dev.azure.com/dnceng/public/_build?definitionId=644&_a=summary '"
518035830,4443,b'Hash Transform API that takes in advanced options.',b'fixes #4422\r\n\r\nNeeded by a 1P customer.\r\n'
517921979,4439,b'Remove duplicate lines from project file.',b'fixes #4427\r\n'
517453542,4438,"b'Recreate workspace directory when fit() is called, fix documentation, free up unmanaged memory.'",b''
517447238,4437,b'Nightly build pipeline',"b'new nightly build pipeline:\r\n\r\n1. add new nightly build pipeline project, disable project build from solution\r\n2. add NuGet package version updater project\r\n3. add new Azure nightly build pipeline and template file\r\n4. TestFrameworkCommon project use conditional reference to source code:\r\n     a. when reference from functional test, use project reference\r\n     b. when reference from nightly build test, use package reference\r\n5. process of nightly build pipeline:\r\n     a. get latest NuGet package version from public NuGet feed\r\n     b. update version to .props file\r\n     c. build nightly build project\r\n     d. run nightly build tests, which is functional test for now\r\n     e. output test results\r\n6. a sample test pipeline can be seems here: https://dev.azure.com/dnceng/public/_build?definitionId=644&_a=summary\r\n7. have issue in Ubuntu platform, disable for now, will continue investigate and send out update later\r\n\r\n'"
517037972,4436,b'Nightly build pipeline',"b'new nightly build pipeline:\r\n\r\n1. add new nightly build pipeline project, disable project build from solution\r\n2. add NuGet package version updater project\r\n3. add new Azure nightly build pipeline and template file\r\n4. TestFrameworkCommon project use conditional reference to source code:\r\n        a. when reference from functional test, use project reference\r\n        b. when reference from nightly build test, use package reference\r\n5. process of nightly build pipeline:\r\n        a. get latest NuGet package version from public NuGet feed\r\n        b. update version to .props file\r\n        c. build nightly build project\r\n        d. run nightly build tests, which is functional test for now\r\n        e. output test results\r\n6. have issue in Ubuntu platform, disable for now\r\n7. a sample test pipeline can be seems here: https://dev.azure.com/dnceng/public/_build?definitionId=644&_a=summary\r\n\r\n'"
517003700,4435,b'update the CI feed url',"b""While working on https://github.com/dotnet/performance/pull/988 I've realized that readme points to an old CI feed (last update in March)\r\n\r\n/cc @eerhardt """
516338397,4430,b'Do not pass validation set and metrics callback to Image Classification API.',b''
515647305,4424,b'Modified how data is saved to disk',"b'pre-trained meta files are now stored in one location always, this\r\nallows multiple runs to re-use the same meta file without having to\r\nredownload.\r\n\r\nAdditionally added the ability to cleanup the temporary workspace used\r\nto train the model. This should prevent issues of running out of disk\r\nspace when running multiple training session sequentially.\r\n'"
515042844,4421,b'Cleanup: makes Recommendation sample easier to use',"b'This PR makes the Recommendation sample under docs easier to use, by pointing to an existing sample in machinelearning-samples repo:\r\n\r\nUsing the same datasets under [https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation/Data](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation/Data)\r\n\r\nThe model generated using instructions in [here](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation), produces metrics below:\r\n```\r\nMeanAbsoluteError: 0.619940823978848\r\nMeanSquaredError: 0.947787365931922\r\nRootMeanSquaredError: 0.973543715470406\r\nRSquared: 0.43654475860194\r\n```\r\n\r\nWhereas using AutoML for Recommendation task with just 540 seconds training time (as seen in this PR), we can get a little over 100 models generated out of which the best produced has the improved metrics below:\r\n```\r\nMetrics of best model on test data --\r\nMeanAbsoluteError: 0.578644904825423\r\nMeanSquaredError: 0.747918695002957\r\nRootMeanSquaredError: 0.864822926964218\r\nRSquared: 0.555365766640444\r\n```\r\n--- \r\n\r\nAdditionally in this PR I updated the CodeGeneratorTests a bit so that, the code generated in \r\n- CodeGeneratorTests.Recommendation_GenerateConsoleAppProjectContents_VerifyPredictProgram\r\n- CodeGeneratorTests.Recommendation_GenerateConsoleAppProjectContents_VerifyPredictProject\r\n\r\ncan be used to test the model generated from running the Recommendation experiment in the doc\\samples folder.\r\n\r\ncc: @CESARDELATORRE, @eerhardt @LittleLittleCloud '"
514899119,4419,b'Fixes #4418. Removes publishing nugets to private feed and fixes some minor issues in .yml file',b'* Removed task that published nugets to a private feed (fixing issue #4418)\r\n* Removed commented task that used to publish to myget feed (fixing [this comment](https://github.com/dotnet/machinelearning/pull/4406#discussion_r339847771))\r\n* Fixed typo in OPTOUT variable (fixing [this comment](https://github.com/dotnet/machinelearning/pull/4406#discussion_r339847110))'
514883908,4417,b'Added Cyclic LR scheduling',b'Added functionality for added unit tests for Cyclic LR scheduling with the unit and integration tests. Also added unit tests for LsrDecay and Exponential decay.\r\n'
514868848,4416,b'Upgraded OnnxRuntime to v1.0 and Google Protobuf to 3.10.1',b'This PR upgrades the OnnxRuntime to v1.0 and the Google Protobuf version to 3.10.1'
514867575,4415,b'Defaults for ImageClassification API',b'Changed EarlyStopping to run by default with ExponentialLR Decay for learning rate scheduling.\r\nThis combination seems to give most optimal results with a trade-off balance between the accuracy and training time.\r\n'
514763351,4414,b'Bump release version to 1.5.0-preview and preview version to 0.17.0-preview.',b'\r\n\r\n'
514294370,4413,b'Initial featurizers project',"b""This is the initial featurizers PR to split apart PR #4157 and get all the common code into master.\r\nOnce this code goes in, I will create separate PR's for each of the 5 featurizers.\r\n\r\nThis is the common code for the featurizers. Its mostly changes to project files and solution files. Common.cs is for all the shared code for the featurizers. The change in Utils.cs is to allow `Marshal.Invoke` with multiple type parameters. The RowToRowMapperTransform.cs change has it create a new mapper when possible. This helps with thread safety/local caching of the mappers when run in a multi threaded approach."""
514227734,4412,b'Move Microsoft.ML.Vision to stable package.',b''
514128690,4410,b'Modify ImageClassification API to use a workspace for saving data',"b'Originally this API saved data to the same directory as the DLL, this\r\ncould cause issues if the DLL was in a read only path. Instead moving to\r\ndefault to a temporary workspace path which can be defined in the\r\noptions by the user. This will allow all the data to be saved in one\r\npath.\r\n'"
514001912,4408,b'Rename Microsoft.ML.Dnn to Microsoft.ML.Vision and reverse dependency between Microsoft.ML.TensorFlow and Microsoft.ML.Dnn',b'- Refactors Microsoft.ML.TensorFlow and Microsoft.ML.Dnn such that Microsoft.ML.Dnn depends on Microsoft.ML.TensorFlow and not vice-versa and fixes #4305.\r\n\r\n- Renames Microsoft.ML.Dnn nuget and namespace to Microsoft.ML.Vision.\r\n\r\n'
513642400,4407,b'SEAL Homomorphic Encryption support',b''
513623792,4406,b'Fixes #4405 About publishing nugets to public feed',"b'Fixes #4405 about publishing nugets to this public feed:\r\nhttps://dev.azure.com/dnceng/public/_packaging?_a=feed&feed=MachineLearning\r\n\r\nThis will be executed by the AzureDevOps build pipeline whenever a new commit is added to the master branch of this repo. Notice that sometimes there are some problems on the side of Azure DevOps, and it might fail when executing the build pipeline, even in steps that were not modified in this PR, and producing errors that prevent the pipeline to actually publish the nugets to the feed; this unplanned errors already existed before the changes introduced in this PR, and they are somewhat unpredictable. The solution to this is to rerun the build manually until the pipeline succeeds.\r\n\r\nWorked this out following @safern instructions.'"
513598956,4404,b'Dispose the DataViewRowCursor in CountRows.',b'Not disposing this cursor is causing the training file to remain locked even after training is completed.\r\n\r\nFix #4361\r\n\r\n'
513583649,4403,b'Updating the DatabaseLoader to not force vector for single element columns',b'This resolves https://github.com/dotnet/machinelearning-samples/issues/722'
513474821,4402,b'Adding release process documentation to README.md',"b""This PR better documents the release process for ML.NET\r\n\r\n- [ x ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [  ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ x ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ x ] You have included any necessary tests in the same PR.\r\n\r\n"""
513415393,4401,b'Add missing linePragmas to ConsumeModel.tt',b'Fix for publishing symbols during official build.\r\n\r\nThe other 6 tt files in the `src/Microsoft.ML.CodeGenerator/Templates/Console/` folder already set linePragmas to false.\r\n\r\nFixes #4400\r\ncc: @eerhardt '
512919669,4395,b'Integrate Image Classification API in AutoML.',b'- Integrates Image Classification API in AutoML\r\n- Code generation for Image Classification API.\r\n- Unit-tests\r\n- Increases build timeout to 75 minutes.\r\n- Changes Image Classification defaults.\r\n\r\naddressed comments from #4384 \r\n\r\n'
512785698,4393,b'Fixes #4392 Add AddPredictionEnginePool overload for implementation factory',"b'This is an additional overload for `AddPredictionEnginePool` to allow middleware dependencies to be used in a custom `ModelLoader`.  This will allow the following code to be used in `Startup` in a similar manner to the corresponding overloads on `AddSingleton`, `AddScoped` and `AddTransient`:\r\n\r\n```cs\r\nservices.AddPredictionEnginePool<Foo, Bar>(serviceProvider =>\r\n{\r\n    services.AddOptions<PredictionEnginePoolOptions<Foo, Bar>>().Configure(options =>\r\n    {\r\n        options.ModelLoader = new MyModelLoader(serviceProvider.GetService<IMyService>());\r\n    });\r\n    return new PredictionEnginePool<Foo, Bar>();\r\n});\r\n```\r\n\r\nThis fixes issue #4392, and is related to a [answer to a question](https://stackoverflow.com/a/57698799/197591) on Stack Overflow given by @eerhardt.'"
512756423,4391,b'Adding CodeGen piece for MatrixFactorization trainer',b'This PR adds CodeGen piece for MatrixFactorization trainer (For the recommendation task)\r\n\r\ncc: @eerhardt @LittleLittleCloud \r\n\r\nTODO:\r\n- [x] Add MatrixFactorization trainer generator\r\n- [x] Add tests for the trainer generator\r\n- [x] Review other CodeGen tests to find more use cases that can be tested'
512729290,4390,b'Changed LoadImages method that returns raw images bytes to LoadRawImageBytes',b'Changed LoadImages method that returns raw images bytes to LoadRawImageBytes.\r\nThis addresses issue #4313'
512661104,4388,b'Add caching to the DatabaseLoaderTests.',b'The IrisSdcaMaximumEntropy were taking over 1 minute in CI. This change drops it to around 3 seconds.\r\n\r\n'
512267257,4384,b'Integrate Image Classification API in AutoML',b'This change also contains ImageClassification API change to convert the API to ITrainerEstimator as it has not been checked-in yet but it is only temporary and I will remove it before checking this in change into master branch. Code gen changes will come in a different PR.'
512237053,4382,b'Upgraded ProtoBuf and Onnx runtime versions',"b'This commit upgrades Google Protobuf version to 3.9.2 and upgrades ORT to an internal dev version in preparation for the next release.\r\n\r\nThis version is not yet ready for merging to main. When the next version of the Onnx runtime is released the following changes need to be made to the PR before it can be merged. \r\n* Revert the change to Directory.Build.props\r\n* Change the version of ORT to the released version\r\n* Revert the change related to GPU support in OnnxUtils.cs after verifying its support in the released version\r\n\r\nUntil then, please review the remaining changes. '"
512214160,4380,b'Image Classification Sample cleanup',b'Make samples more readable and add comments.\r\n\r\n'
512204677,4379,b'Add Onnx export support for string processing transformers',b'This checkin includes support for WordTokenizingTransformer and NGramExtractingTransformer and also fixes for ValueToKeyMappingTransformer.\r\n\r\nThe fixes are dependent on upgrades to the Onnx runtime and Google Protobuf packages.  This is not ready to be merged until there is a newer public release of the ORT.\r\n'
512185835,4377,b'Delete build files before packaging and increase build timeout',b'This reverts commit c922529e669d1c4dcb4d2bf8157a579b10a60cee and deletes build files before packaging to get rid of out of memory error. It also increases the build timeout to 60 minutes.\r\n'
512054834,4375,b'Move windows build machines to NetCorePublic-Pool.',b'Builds seem to be failing because it runs out of disk space.'
512009306,4374,b'Add SampleBase abstract class. ',b'1. Add SampleBase abstract class.\r\n2. Make GetAbsolutePath() return be true absolute path.\r\n![image](https://user-images.githubusercontent.com/1705364/67499246-5ffbec80-f646-11e9-9614-05fba03c5d56.png)\r\n\r\n![image](https://user-images.githubusercontent.com/1705364/67499225-58d4de80-f646-11e9-886f-93a585038b34.png)\r\n\r\nPlease let me know if you want other Samples to inherit from `SampleBase`.\r\n\r\n'
511841482,4372,b'Make ImageClassification API an ITrainerEstimator and refactor code.',b'In addition to converting ImageClassification API to ITrainerEstimator it also fixes #4276\r\n\r\n'
511625619,4371,b'Fixes onnx exports for binary classification trainers ',b'This draft PR fixes the issues with exporting the following binary classification trainers to onnx: \r\n- FastTree()\r\n- LbfgsLogisticRegression()\r\n- LightGbm()\r\n- SdcaLogisticRegression()\r\n- SgdCalibrated()\r\n- SymbolicSgdLogisticRegression()\r\n'
511459518,4370,b'Created Polynomial Learning Rate scheduler',"b""Created the polynomial learning rate scheduler based upon Tensorflow's\r\nimplementation of polynomial lr scheduler. which can be found\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/train/polynomial_decay\r\n"""
510999572,4368,b'Fix warnings/errors while buliding NuGet packages.',"b'- A new warning that PackageIconUrl is deprecated, and use PackageIcon instead.\r\n- Mkl.Redist has `build/netstandard2.0` assets, but no `lib` or `ref` assets, so this caused a warning. The fix is to put a placeholder file in the `lib/netstandard2.0` folder.\r\n- Microsoft.ML.symbols had a warning that it contains a `build` targets file, but not for the current package name. This was suppressed because we only use the symbols packages for publishing symbols.\r\n\r\n'"
510853092,4365,b'Adds CodeGen to master (from features/automl)',b'- [x] Add src project for CodeGen\r\n- [x] Add test project for CodeGen\r\n- [x] Add packaging for CodeGen\r\n\r\ncc: @eerhardt @LittleLittleCloud '
510361477,4362,b'Redesign DnnCatalog methods API for ease of use and consistency.',"b'Fixes #4307\r\n\r\nInitially the methods in the DnnCatalog took a lot of optional arguments which would confuse users and adding features to the ImageClassification API would require breaking changes in the future.\r\n\r\nTo be consistent with the rest of ML .Net, this change follows the pattern where we have 2 overloads:\r\n1)An overload that takes the required parameters, and optionally the most important/common parameters to a method.\r\n2)An overload that takes an Options object, which contains all the options to the method \r\n\r\nThis changes also removes a couple of unused options for the ImageClassification API, while making RetrainDnnModel internal to enable further testing before releasing.\r\n\r\nWIP to get initial feedback/add necessary tests.'"
510303993,4360,b'Add Code Gen piece for Recommendation task',b'- [x] Adds CodeGen piece for recommendation task\r\n- [x] Cherry-picks changes in https://github.com/dotnet/machinelearning/pull/4246 into features/automl branch\r\n- [x] Cross check mlnet tests build and run fine\r\n- [ ] confirm AutoML project tests build and run fine\r\n\r\ncc: @LittleLittleCloud @eerhardt '
510255896,4358,"b""Fix AutoML's reference to LightGbm""","b'AutoML has a reference to LightGbm, however it is getting the wrong version number in the dependency. Instead of `1.4.0-preview...`, it is getting `0.16.0-preview...`. This is because the casing in the reference is incorrect.\r\n\r\nSince the casing is incorrect, when evaluating the LightGbm project as a reference, its name no longer matches the casing in the `StableProjects` list, so it no longer thinks it is stable, and gets the unstable version.\r\n\r\nThe fix is to fix the casing, and use case-insensitve checks when evaluating IsStableProject.\r\n\r\nFix #4354'"
510183456,4357,b'Fix path related to v10.0 instead v9.0',"b'Fix path related to v10.0 instead v9.0.\r\nv9.0 was coming from NVIDIA documentation but it is not accurate for us.\r\n\r\nIn any case, this fix only applies for folks using C++\r\n\r\n\r\n'"
510123128,4356,b'Mark Microsoft.Extensions.ML as a stable package.',b'Fix #4352'
510096835,4355,b'Added onnx export support for OptionalColumnTransform',"b'This is a draft PR. This PR depends on [an earlier draft PR ](https://github.com/dotnet/machinelearning/pull/4312 )(from harishsk:ngramonnx branch) and cannot be merged until that draft PR is merged. \r\n\r\nOnce again, I publishing this PR as a draft PR early to get some review eyes on it so that both the PRs can be merged when the new version of ORT is released.  \r\n\r\n'"
509319807,4351,b'Add support for Mobilenet v2 in Image Classification transfer learning',"b'The base MobileNetV2 model is from https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet . Checkpoint file used: https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz\r\n\r\nBenchmarked transfer learning on the Cats V/s Dogs dataset at:\r\nhttps://www.microsoft.com/en-us/download/details.aspx?id=54765\r\n\r\nTrained last layer for 10 epochs with 0.0001f learning rate with batch size 32.\r\nFinal accuracy on eval set:\r\n Micro-accuracy: 0.980959936533122,macro-accuracy = 0.980874311779911\r\nComparable Tensorflow acuracy for same task: \r\nhttps://www.tensorflow.org/tutorials/images/transfer_learning#train_the_model'"
509277396,4350,b'Add try catch block to skip bad(failing to read) images',"b'Fixes #4348\r\nWhile computing the bottleneck values, if an image errors out and throws TensorflowException, this change skips the particular image and continues training.\r\n\r\n'"
509248221,4349,b'Added support for resnet50 architecture for image classification',"b'Created a sample to show usage of resnet50 V2.\r\nTested against Tensorflow we can see there is a definitive discrepancy\r\nin accuracy.\r\n\r\nTraining for ~136 epochs (TF uses steps rather than epochs) we are able\r\nto achieve an accuracy of 78.7% in Tensorflow, compared to our accuracy\r\nwhich was 54.6%. This discrepancy can be accounted for due to the way in\r\nwhich TF adjusts the learning rate over time. We have already begun to\r\nmake those changes to our code, and will be added in a separate change.'"
508752289,4347,b'Devproperties',b'@eerhardt I am creating this draft pull request to initiate a discussion about this. \r\n\r\nMichael and I are running into similar issues where we would like to do our daily development against unstable and unreleased nugets from other sources and then merge our daily working branches into master when our dependent nugets are stable. \r\n\r\nThe current approach is to modify Directory.Build.Props and Dependencies.props appropriately and keep those files checked out. \r\n\r\nWhat do you think of optionally importing DevProperties.props from Directory.Build.props which would override those variables? (The DevProperties.props file would never be checked in and would be added to the .gitignore file if you are okay with this approach).\r\n\r\n@michaelgsharp I have verified that this approach works. Let me know if this works for you as well.\r\n'
508707259,4346,"b'Extract TestFrameworkCommon Project, remove dependency of TestFramework from FT'","b'1. Extract TestFrameworkCommon from TestFramework\r\n   a. Extract CommonUtilities method, move some utilities from BaseTestClass to CommonUtilities\r\n   b. Move some test attributes from TestFramework to TestFrameworkCommon\r\n   c. Move TestDataset from TestFramework to TestFrameworkCommon and fix corresponding \r\nreference\r\n   d. Move some schema compare method from TestDataPipeBase to CommonUtilities\r\n   e. TestFrameworkCommon only have public dependency, no internal class dependency\r\n2. Remove dependency of TestFramework from FT\r\n   a. Remove dependency of TestFramework from FT, now FT dependent on TestFrameworkCommon\r\n   b. Remove unnecessary dependency of Maml from FT\r\n3. Remove duplicate CompareVec method, also fix bug in CompareVec method\r\n   a. Remove duplicate CompareVec method from CoreBaseTestClass, TestDataPipeBase and \r\nCopyColumnEstimatorTests, move CompareVec method to CommonUtilities and fix reference\r\n   b. Fix bug in CompareVec method from CoreBaseTestClass class, original line 125 seems problematic. \r\n\r\n'"
508685625,4345,b'Minor updates of the GPU installation guide so it is clearer for users',b'Minor updates of the GPU installation so it is clearer\r\n\r\n'
508585522,4344,b'Update .NET Core SDK to 3.0 GA',b'Updating the SDK to the officially released version.\r\n\r\nI also took this opportunity to update the building docs to be up-to-date.'
508001220,4342,b'Moving the DatabaseLoader support into Microsoft.ML.Data',b'This resolves https://github.com/dotnet/machinelearning/issues/4323'
507743109,4341,b'Update run.cmd',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
507703086,4340,b'Added LearningRateScheduler functionality for Image Classification',b'1. Added LearningRateScheduler abstract class which will be implemented for various learning rate scheduling algorithms. \r\n2.  Has the lastest Tensorflow nuget which allows Gradient Descent Optimizer to use learning rate input as tensor '
507501005,4338,b'Remove TensorFlow.Redist since we no longer use it.',b'\r\n'
507278615,4337,b'Update OnnxRuntime to latest version.',"b'OnnxRuntime supports win-x86, so start running tests on the win-x86 leg.\r\n\r\n'"
506936790,4336,b'Added learning rate scheduling for cifar and options for using resnet_v2_50 model',"b""The following has been added:\r\n1. Added learning rate scheduling for CIFAR-10.\r\n2. Added a custom class called GradientDescentOptimizerTensor that takes learning rate as a tensor. A temporary fix until TF .Net updates their function to take learning rate as tensor.\r\n3. Modied code to take resnet_v2_50 model.\r\n4. Addressed most of Yael's comments from PR #4242."""
506877053,4334,b'Add non-generic IEstimator interface to be more SOLID',"b'This is a fairly trivial change, but makes the `IEstimator` interface comply with SOLID more, particularly interface segregation.  It is useful in that code need only declare a variable of `IEstimator` type (instead of `IEstimator<ITransformer>`) if they wish only to access `GetOutputSchema` which does not require the generic type parameter `TTransformer`.  Or where they only need to cast to an `IEstimator` where the generic is unimportant such as the usage of the null-coalescing operator in the following example: \r\n```cs\r\nIEstimator<ITransformer> pipeline = null;\r\n\r\nforeach (var label in new[] {""Foo1"", ""Foo2""})\r\n{\r\n    var estimator = mlContext.Transforms.CopyColumns(""Label"", label)\r\n        .Append(mlContext.Transforms.Concatenate(""Features"", ""Baz"", ""Bar""))\r\n        .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n    pipeline = pipeline?.Append(estimator) ?? (IEstimator)estimator;\r\n}\r\n```\r\n\r\nAlso fixed a couple of typos in `EstimatorChain` that I noticed.'"
505984007,4324,b'Fix nuget dependency for Dnn',"b'With change to allow users to support GPU, need to remove the dependency\r\non TF redist from nuget. It will now be up to the user to add a\r\ndependency on the correct nuget, such that they can choose to use either\r\nthe GPU or the CPU.\r\n\r\nfixes #4325'"
504922836,4321,b'Addresses #4226 . Fixes problem when loading NormalizerTransformer from disk.',"b'Addresses and actually solves issue #4226 by fixing [the problem with loading a NormalizerTransformer from disk](https://github.com/dotnet/machinelearning/issues/4226#issuecomment-532902543), where the NormalizerTransformer is supposed to work with multidimensional vectors as input.\r\n\r\nAlthough this PR actually fixes that issue, another problem [is described in one comment](https://github.com/dotnet/machinelearning/issues/4226#issuecomment-533772062) of the issue. This other problem is related to Resnet18, and is independent of the problem here fixed. Solving any of these two problems actually solve this issue, but perhaps the issue shall remain open until both problems are fixed.\r\n\r\n### The solution\r\n- I changed the way NormalizerTransformers are saved and loaded, so that it included the information of the dimensions of the vector it has as input. This changes maintain backward compatibility in that it is still possible to load models that were saved with previous binary format . But notice that the original problem described in the issue will persist for models that were saved before the changes made in this PR... it would be necessary to save the model with the updated save method in order to avoid that specific problem when working with multidimensional vectors.\r\n\r\n- I added a 3 test cases: one reproducing a very similar problem as in the original issue, another that tests a simplified version of the original problem, and another that checks that backward compatibility is still maintained.'"
504337044,4315,b'Release notes for 1.4.0-preview2 and 0.16.0-preview2.',b'We have released 1.4.0-preview2 and 0.16.0-preview2 versions of our nugets on nuget.org. These are the release notes.\r\n\r\n'
504279746,4314,b'Use resource manager to download meta files. Fixes #4234',"b'Previously, when the ImageClassification pipeline is run for the first time, the meta graph of the model (ResnetV2101 or InceptionV3) is downloaded, and in the subsequent runs, it is reused. If the run is interrupted while the download is in progress(eg.: by stopping), the protobuff is partially downloaded. This throws an error when this incomplete graph is attempted to be read in the subsequent runs.\r\n\r\nThis changes uses resource manager to download the meta file. Resource Manager downloads the file to a temporary file path(GUID) and then atomically moves the temporary file path to the actual path. Hence once a file path is created it is guaranteed to have all the contents (unless the user or someone goes and manipulates the file)\r\n\r\nFixes #4234'"
504200912,4312,b'Add Onnx export support for string processing transformers',"b'This draft PR adds support for exporting to Onnx, the following transformers. \r\n- NgramTransformer\r\n- ValueToKeyMappingTransformer (upgraded support)\r\n- WordTokenizingTransformer\r\n\r\nThis PR also upgrades the version of Google Protobuf library.\r\n\r\nThis work is not ready for merging because this work relies on a new version of the Onnx runtime due to be released later. I am submitting this PR for review now so that this can be merged soon after the release of the runtime. \r\n\r\nPlease review the changes so that I can iterate on the review comments now, before the public release of the ORT.'"
503765806,4310,b'Modify image classification sample to take in-memory image for prediction.',b'fixes #4153\r\n'
503667463,4308,b'Adding a LoadColumnNameAttribute',b'This resolves https://github.com/dotnet/machinelearning/issues/4195'
503626211,4306,b'Fixes #4292 about using PFI with BPT and CMPB',"b""Fixes #4292 about using PFI with a `BinaryPredictionTransformer<>` and classes derived from `CalibratedModelParametersBase<>`.\r\n\r\n### Approach of the solution\r\nRegarding the 3 problems listed in #4292 the solutions were the following:\r\n1. **To call the correct 'create' method**: as discussed [here](https://github.com/dotnet/machinelearning/pull/4306#discussion_r336139379), I removed the constructor with overload `(IHostEnvironment env, ModelLoadContext ctx)` from the `PMCMP<,> ` class, since its not needed after the changes on this PR. Without that constructor, the 'create' method gets called directly by `CreateInstanceCore` without changing anything else.\r\n2. **To create a `PMCMP` object with the correct parameter types**: I used a similar approach as the one explained in my previous pull request #4262. That is, the calibrator and submodel of the `PMCMP<>` are loaded first, and then they are used to create a generic type at runtime for `PMCMP<>` but now using the correct parameter types.\r\n3. **To create a `BPT<CMPB<>>` object whereas a `PMCMP<>` was loaded**: After trying different approaches that didn't work, and following the suggestions of @eerhardt the best way to fix this was to create a new attribute called `PredictionTransformerLoadTypeAttribute`, that would help the prediction transformer to know what's the correct type to use as a TModel when loading a model from disk. This attribute is applied to the `PMCMP<>` class, and it's used in `PredictionTransformer.cs` to decide the correct type for the BPT.\r\n\r\nAlso, after discussing it with @eerhardt , I also fixed these 3 problems for the classes that inherit from `CalibratedModelParametersBase<,>`; those are: `ValueMapperCalibratedModelParameters<,>`, and `FeatureWeightsCalibratedModelParameters<,>`. Notice that  `SchemaBindableCalibratedModelParameters<,>` also inherits from CMPB<,>, but, as discussed [here](https://github.com/dotnet/machinelearning/pull/4306#issuecomment-545562898), it was decided not to fix it.\r\n\r\n### Changes implemented\r\n* Changes in `PredictionTransformer.cs` and `Calibrator.cs` to implement the approach previously described\r\n* Added a working sample for using PFI with BPT and CMPB while loading a model from disk. This is based entirely in the original sample.\r\n* Added file `CalibratedModelParametersTests.cs ` with tests that the CMPs modified in this PR are now being correctly loaded from disk.\r\n* Changed a couple of tests in `LbfgsTests.cs` that failed because they used casts that now return 'null'. Notice that those casts involved using classes such as `IPredictorProducing ` and `PMCMP `which are internal classes, so a regular user wouldn't have been able to use those casts. They have now been replaced with casts to the public classes  `BPT<CMPB<>>` and `CMPB<>` using the correct type parameters of the model."""
503034214,4301,b'[DO NOT REVIEW][TEMPORARY]',"b'DO NOT REVIEW, JUST A PR TO CREATE ANOTHER PR. WILL CLOSE SOON.'"
502878212,4300,b'Fixes #4299 related to ML.Samples and ML.Samples.GPU sharing the same Program.cs file',"b'A simple change to fix #4299 . Simply added a new Program.cs file to the ML.Samples.GPU, independent of the one in ML.Samples.'"
502871807,4298,b'Fixed documentation for ImageClassificationMetricsCallback to resolve the confusion in issue #4259',b'Fixed documentation for ImageClassificationMetricsCallback function to resolve the confusion in issue #4259\r\n'
502863179,4297,b'Issue 4120',"b'Follow up on Issue #4120 \r\n\r\n1. Use EditorBrowsable attribute to hide the default constructor from intellisense.\r\n2. Use Obsolete(""XX"", false) instead of Obsolete(""XX"", true) to be safe.\r\n'"
502348385,4293,b'Buffer re-use using ArrayPool and a few more checks',b'Added ArrayPool for buffer re-use while reading images in ImageLoader.cs. A few commits for safety checks. \r\nContinuation to my previous commit #4242 \r\n'
502293780,4291,b'Update CodeCov uploader version.',b''
502274691,4290,b'TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException',b'- Added conversion between Tensor to native C# types instead of throwing NotSupportedException\r\n- Fixed proper reading of TF_STRING\r\n- Added overloads that support TF_STRING (string does not meet T generic constraint `unmanaged`'
502267843,4289,"b'Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    '","b'1)Previously, if the images left were not enough to for a batch of batchSize, the batch would not be processed. Fixed to process incomplete batch in training and validation.\r\n2)There was a bug where the batchIndex was not getting reset when the last batch was incomplete(< batchSize). Fixed to reset batchIndex.\r\n3)EarlyStopping was not triggering when validation set is not provided. Fixed.\r\n\r\nfixes #4274 #4286'"
501989702,4279,b'Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release',b'\r\n'
501839858,4278,b'Fix build breaks.',b'Build first broke with #4237 and remained broken until this change.\r\n\r\n'
501709698,4277,b'Added support for running TF based models on GPU in Linux',"b'Modified the GPU samples to take a dependency on both the linux and\r\nwindows TF GPU redist.\r\n\r\nModified the readme content to explain how to use on linux.\r\n\r\nTested on Ubuntu 18.04 with GTX1070, was able to run on the GPU without any issue.\r\n\r\n'"
501195820,4273,b'Add DateTime to DateTime standard conversion.',"b""This fixes an error which is caused by a missing DateTime to DateTime conversion when outputting DateTime columns in NimbusML. NimbusML calls in to `RowCursorUtils.GetGetterAsCore` (indirectly) which tries to find a conversion from DateTime to DateTime and fails with the following error:\r\n\r\n```console\r\nError: *** System.InvalidOperationException: 'No standard conversion from 'DateTime' to 'DateTime'\r\n```\r\n"""
501177421,4272,"b'Issue 4120, add reasonable exception when user try to use OnnxSequenceType attribute without specify sequence type'","b'Fixes #4120 \r\n\r\nThe issue is: when user use OnnxSequenceType attribute directly without specify sequence type like [OnnxSequenceType], user will hit run time exception when try to use it.\r\n\r\nThe ideal way to fix this issue is to remove the default constructor of OnnxSequenceTypeAttribute and user will get compiler error when he/she try to use [OnnxSequenceType]. \r\nBut this can be a break change in Public API. After discuss with @eerhardt and @ericstj , we decide to obsolete the default constructor for now. Then we will remove the default constructor in next major release.\r\n\r\n\r\n\r\n'"
501037711,4270,b'Modified the project to support running of TensorFlow on GPU on Windows.',"b'Removed all dependencies of TensorFlow redist from the source projects,\r\nand instead added the dependency to the Sample project.\r\nCreated separate sample project for GPU examples since gpu tensorflow requires cuda,\r\nwhich may not be available on all machines, so it needs to be a separate\r\nproject.\r\nAdded documentation for setup as there is now some setup requirements to use this API.\r\n\r\nIn testing on the large flowers data set I was able to see a large improvement in speed, from taking ~720 seconds to train to taking ~156 seconds. \r\n\r\nFixes #4269\r\n\r\nAddresses part of the issue in #86 \r\n\r\n'"
500531241,4267,b'Fix the build badge link',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
500440844,4265,"b'PFI entrypoint - Add checks for null Label, Feature, and GroupId columns'","b'Related #4231 #4232 \r\n\r\nCheck whether Label, Feature, and GroupId columns are null.'"
499710603,4262,b'Addresses #3976 about using PFI with a model loaded from disk',"b""With this pull request it is now possible to use PFI with some models loaded from disk. **This is not yet a final solution to the problem**, as described in the last section below.\r\n\r\n### The Problem\r\nAs explained in [this comment](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076) of issue #3976 it was not possible to use PFI with a model loaded from disk, because the last transformer of the loaded model was not of the appropriate type to use it with the `PermutationFeatureImportance `method.\r\n\r\nSpecifically the problem occurred because when loading the last transformer, a 'create' method would be called and it would assign an inappropriate type to the last transformer, making it unusable for PFI. For example, if a model had `RegressionPredictionTransformer<OlsModelParameters>` as last transformer, and it was saved to disk, later on when loading it from disk the last transformer would be of type `RegressionPredictionTransformer<IPredictorProducing<float>>.` This would have happened because the [Create method ](https://github.com/dotnet/machinelearning/blob/bb00e07b30e9626b3578ff1934b86dad0d1d1ce9/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L615) that is called when loading a `RegressionPredictionTransformer ` would always return a `RegressionPredictionTransformer<IPredictorProducing<float>>` regardless of the actual `TModel `that should be loaded. In this case, it would be necessary to load the last transformer as `RegressionPredictionTransformer<OlsModelParameters>` in order to use it with PFI.\r\n\r\nThis was a problem also in the BinaryClassification, MulticlassClassification and Ranking prediction transformers which implemented a similar Create method. All of these classes are used with PFI.\r\n\r\n### The approach of the solution\r\nThe main obstacle was that the appropriate type `TModel` to be used when loading the last transformer couldn't be known at compile time, only at runtime once the last transformer was being loaded.\r\n\r\nSo to solve the problem, it was necessary to load first the internal model (e.g. the `OlsModelParameters `object) in the Create method of the prediction transformer, get its type to be used as `TModel`, make a generic type at runtime for the prediction transformer using the actual `TModel`, and instantiate that type with a constructor that would receive the internal model (previously loaded) to add it to the last transformer; this constructor would then continue to load the prediction transformer.\r\n\r\n### Changes implemented\r\n\r\n- The create method of the prediction transformers (binary, multiclass, ranking and regression) was modified to solve the problem. Different overloads of constructors were created to receive the internal model once it was loaded and then continue loading the prediction transformer.\r\n\r\n- **Samples were added based on the original PFI samples**, but now using a model that is saved and loaded from disk directly in the sample. This is provided for the multiclass, ranking and regression, but NOT for the binary classification case (see the final section below).\r\n\r\n- **Test cases based on the original PFI test cases are also provided**, but now using a model that is saved and loaded from disk directly in the test case. Again, this was done for multiclass, ranking and regression, but not for binary classification.\r\n\r\n- **Changes were made to 2 tests in the `LbfgsTests.cs`** file where PFI is not used, but prediction transformers are loaded from disk. The changes regard casts that were used in the tests, but can no longer be used. For example, `as MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>` was replaced for `as MulticlassPredictionTransformer<MaximumEntropyModelParameters>` in one test. This is done because now the create method returns the appropriate TModel type instead of the `IPredictorProducing<>` type. Notice that it is invalid to cast from `MulticlassPredictionTransformer<MaximumEntropyModelParameters>` to `MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>`... so those tests fail without the changes I made to the tests. Also notice that since `IPredictorProducing<>` is internal, a regular user using a nugget wouldn't be able to do the casts that were done in those tests.\r\n\r\n### Further problems\r\nIn this pull request I provide working samples and tests for regression, multiclass and ranking. Still, I've been unable to provide them for binary classification.\r\n\r\nThe [existing sample for PFI with binary classification](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L27) uses a last transformer of type `BinaryPredictionTransformer<CalibratedModelParameterBase<LinearBinaryModelParameters,PlattCalibrator>>` which is the type necessary to use it in the PFI method. When saving and then loading that model from disk, the last transformer was of type `BinaryPredictionTransformer<IPredictorProducing<float>>`; with the changes I made to the binary transformer, it now loads a last transformer of type `BinaryPredictionTransformer<ParameterMixingCalibratorModelParameters<IPredictorProducing<float>, ICalibrator>>`, which is still not the type necessary to use PFI.\r\n\r\nThe problem is that the [Create method of ParameterMixingCalibratorModelParameters](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) returns a `CalibratedModelParameterBase` object. This is similar to the problem that the prediction transformers had, but there's a key difference in that `ParameterMixingCalibratorModelParameters ` is internal, and its create method returns an object of its public superclass `CalibratedModelParameterBase`. This key difference has stopped me from solving the problem using the same approach used to fix the prediction transformers. Once this pull request is accepted, I will open another issue with this specific use case, explaining it in more detail.\r\n\r\nNonetheless, notice that the problem is not in the `BinaryPredictionTransformer<TModel>` but rather in its `TModel` for this specific case. Having changed the `BinaryPredictionTransformer<TModel>` actually works as expected, in that it no longer returns a fixed `<IPredictorProducing<float>>` as TModel, and so the problem is actually in the `ParameterMixingCalibratorModelParameters `class.\r\n\r\nAlso notice that this is a signal that there might be other generic classes where the Create method returns an object with fixed type parameters that aren't the ones actually being used. This might become a problem for users trying to use PFI with a model that uses one of such classes."""
499687474,4261,b'Fix code coverage yaml file.',b'Code coverage is broke due to an update that is needed in the yml file.'
499573005,4260,b'Tensor extensions',"b""Output tensors from graph are being copied from unamanaged to managed memory and every time a new buffer is created. Performance will be better if we reuse buffer when it's possible.\r\nImprove performance by replacing ToArray method in Tensor class with extension methods: ToScalar, ToSpan and ToArray\r\n\r\n"""
499233840,4255,b'Typo: Retreive -> Retrieve',b''
499119961,4253,b'Image featurization',"b""It's just the same PR of the one on Justin's [repo](https://github.com/justinormont/machinelearning/pull/4)\r\n- [x] Pass image path\r\n- [x] Seperate ImageFeaturizing into four parts\r\n- [x] CodeGen"""
498574293,4247,b'Fix NgramExtractingTransformer GetSlotNames to not allocate a new delegate on every invoke.',b'This was showing up as allocating a huge number of delegates for no reason.\r\n\r\nI removed the delegate all together and just pass the VBuffer in.'
498520195,4246,b'AutoML Add Recommendation Task',"b""What's already be done in this PR\r\n- [x] added `Recommendation` task and experiment in `AutoML`\r\n- [x] added `MatrixFactorization` as `MatrixFactorizationExtension`\r\n- [x] added a new Column Purpose (`LabelFeature`) and it's corresponding TransformerExtension (`LabelCategorical`) so that `AutoML` can construct the pre-process pipeline for `MatrixFactorizationExtension` correctly\r\n- [x] added a new recommendation example (with rating only) in `AutoML.Example`, and you can play with that!\r\n\r\nWhat's need to be done (Feel Free to CRUD)\r\n- [ ] figuring out how to accelerate and properly presenting the training process. Seems that `MatrixFactorization` requires more time to train a round, and the algorithm for sweeping params requires to train many rounds to find out the best parameter. It's time costy and customers might not like that.\r\n- [ ] Corresponding `CodeGen` part\r\n- [x] Test case!\r\n- [x] Better Naming and code style\r\n- [x] Enable support for multiple feature trainers in `AutoML` (it requires some refactor works and shouldn't be done in this PR. But it's important)"""
497293022,4245,b'[Example Only] Anomaly detection example for extending AutoML features to non-experiment types',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis is for issue #4244 as an example.  Not sure the proper way to go about achieving the same result so this is just for discussion."""
497235087,4242,b'Changed Image classification API to accept Image as VBuffer<byte>',"b'Changed Image classification API to accept Image as V Buffer<byte>. Also, added a few optimizations to re-use the buffer for performance gains.\r\nSo we can do the best job, please check:\r\n\r\nfixes #4153\r\n\r\n'"
496578497,4237,b'Adding Early stopping feature in ImageClassification (WIP)',b'Fixes #4236\r\n\r\nModeled after https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n'
496078228,4232,b'Add entrypoint for PFI',b'Fixes #4231 \r\n\r\nEntrypoint is needed to add PFI to NimbusML\r\nmicrosoft/NimbusML#92'
495477157,4229,b'WIP: Homomorphic encryption ',b'PLEASE DO NOT REVIEW. THIS IS NOT CLOSE TO A REVIEW. WE ARE JUST REVIEWING THE CHANGES FROM SEAL TEAM.'
495442166,4228,b'Added categorical value support for PredictedLabel for the Image Classification Transfer Learning example. Addresses Issue #4169',b'Attempt on Issue #4169\r\n\r\n- Added the necessary estimator pipeline for a KeyDataViewType string/value binding\r\n- Changed the Output Column types of the ImageClassificationEstimator and  the Mapper for future compatibility with KeyType composite values\r\n- Added test cases to test features added above\r\n\r\nfixes #4169\r\n\r\n'
494783312,4223,b'Fix memory leak in TensorflowTransform',"b'This PR fixes two memory leaks:\r\n1. After executing the graph, input tensor are not being freed\r\n2. When running multiple pipelines (sessions), graphs are not being freed.\r\n\r\nThis fixes #4134\r\n'"
494446866,4220,b'Adding code generation logic to skip generating properties for ignored columns',"b""Adding code generation logic to skip generating properties for ignored columns in the Input Model. Ignored columns are specified by the code gen caller in the `ColumnInferenceResults.ColumnInformation` that is passed to the CodeGenerator.\r\n\r\n- Adding unit tests to verify that ignored columns do not generate properties.\r\n\r\n**Note - I also verified that this change works as expected with a fully generated project.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/4224"""
494290176,4219,b'Added onnx export support for CopyColumns',b'Fixes #4218 '
493504395,4215,b'Remove unused parameter in BinarySaver.',b'I noticed this parameter is not being used when looking at this code. Removing it to clean it up.\r\n'
493472059,4214,b'fixing scenerio 3 of issue #3995',"b""This fixes the issue #3995 scenario 3 \r\nI'm waiting to see what can be done about scenario 1(desired behavior not decided yet) and 2( can't replicate). Scenario 4 is not part of our code base. \r\n\r\nIn this commit, I have made the error comment more clear and switched the exception from an System.ArgumentOutOfRangeException to System.ArgumentNullException. ArgumentOutOfRangeException are reserved for signaling bad function parameters and thus doesn't make sense to use for signaling a missing column value. \r\n\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
493243192,4212,b'Sanitize OutputName using dots to handle spaces in namespaces and project files',"b""This fixes the issue with generating namespaces and project files with spaces in them.\r\nFixes #3792.\r\n\r\nThe `Utils.Sanitize` method now takes an extra (optional) parameter, `replacement`, which is the char to replace non letters/digits with. Default value: `_`.  \r\nI thought it's better and easier to sanitize the `OutputName` in the settings directly, since it's used in all the places that needs to be changed (namespaces, project files).\r\n\r\nIn order to try it, I used the same command/dataset from the issue, the output is:\r\n- Analyzing Categorical Data\r\n  - Analyzing.Categorical.Data.ConsoleApp\r\n    - Analyzing.Categorical.Data.ConsoleApp.csproj\r\n    - ModelBuilder.cs\r\n    - Program.cs\r\n  - Analyzing.Categorical.Data.Model\r\n    - Analyzing.Categorical.Data.Model.csproj\r\n    - DataModels\r\n      - ConsumeModel.cs\r\n      - ModelInput.cs\r\n      - ModelOutput.cs\r\n    - MLModel.zip\r\n  - logs\r\n  - Analyzing.Categorical.Data.sln\r\n\r\nAnd the base namespace is `Analyzing.Categorical.Data`.\r\n\r\n---\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
493081360,4211,b'Fixes #3992 and corner cases of inputColumnNames on FeaturizeText',"b""Fixes #3992 , where FeaturizeText is used with an options object, but no inputColumnNames is provided, thus expecting the inputColumnName to be defaulted to the outputColumnName.\r\n\r\nIt also covers the corner cases where the user uses FeaturizeText with an options object along with a 'null' or an empty string as inputColumnNames.\r\n\r\nThree different tests are provided to cover those 3 cases. It is verified that the text is featurized correctly and the features are saved in a column with the same name as the input column. They are all based on the TextFeaturizerWithWordFeatureExtractorTest, but without using a PredictionEngine because the output column hides the input column, and thus instead getting the rows of the dataview to verify their values.\r\n\r\nA small fix to the documentation of FeaturizeText is added."""
492481673,4205,b'Upgrade TF.Net version from 0.10.10 to 0.11.3',b'Fixes #4204\r\n\r\nIncludes a few API changes necessary to upgrade TF.Net version.\r\nVerified that ML.Samples  and Tests run.\r\n\r\n'
491434433,4197,b'Fix relation between IsSavedModel and isFrozen in DnnRetrainTransformer.SaveModel',"b""Fix: https://github.com/dotnet/machinelearning/issues/4191\r\n\r\nIsSavedModel returns true when loaded model is an-frozen model \r\nhttps://github.com/dotnet/machinelearning/blob/1503b0aa9cac997cff8b8bc7e2075eb23d61ad81/src/Microsoft.ML.Dnn/DnnUtils.cs#L137-L143\r\n\r\nbut now isFrozen variable is set true in spite of an-frozen model.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3c02da5d75534265223e56aee9c5d2da53ea4b99/src/Microsoft.ML.Dnn/DnnRetrainTransform.cs#L681\r\n\r\n---\r\n\r\nChecks\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
490809421,4194,b'Added onnx export functionality for MissingValueIndicatorTransformer',b'Fixes #4192'
490805334,4193,b'Added onnx export functionality for MissingValueIndicatorTransformer',b'Fixes #4192 '
490764734,4190,b'Svmlight loader and saver',b'Fixes #4014 .'
490566509,4188,b'Added Onnx export functionality to PCATransformer',b'Fixes #4186 '
490566314,4187,b'Modified how DataViewTypes are registered',"b'The DataViewManager registers DataViewTypes to determine how to\r\nrepresent the the data within ML.Net. However, there was a bug in how\r\ntypes were being queried. Types that were being registered via an\r\nAttribute were being added to the manager with only that Attribute.\r\nHowever, when queried from the manager all custom Attributes were being\r\npassed.\r\nTo solve this we need to only pass custom Attributes that are relevant\r\nto the Manager. All Type attributes now inherit from a single\r\nTypeAttribute class such that we can filter custom attributes for\r\nrelevant types.\r\n\r\nFixes #4121\r\n'"
490039346,4179,b'pack CodeGen into mlnet',b''
488770734,4174,b'Using `GetAssembly` to get DLL loaction in ResNet18',b''
488337706,4170,b'Release notes for 1.4.0-preview and 0.16.0-preview.',b'\r\n\r\n'
487937641,4166,b'WIP - Refactor on Code Gen',b'- [x] refactor on `TransformGenerator` derived Class'
487616633,4163,b'Image featurization',b'\r\n'
487363555,4162,b'Fixed typo in ML.NET Cookbook',b'Fixing one small typo\r\n\r\n'
487288045,4161,b'Added onnx export functionality for LpNormNormalizingTransformer',b'Fixes #4159 '
487285402,4160,b'Added export functionality for LpNormNormalizingTransformer',b'Fixes #4159 '
487248604,4158,b'Increment build version for 1.4-preview and 0.16-preview release.',b''
487215039,4157,b'[WIP] Transformers for AutoML',"b""This is still a work in progress, but will be updated and finished over the next several hours. \r\n\r\nIn order for AutoML to take a full dependency on ML.NET, several pieces of functionality need to be added. This PR is the first step in that process adding in 3 new transformers. The actual implementation of the transformers is done in C++. This code is currently in another repo, but will be turned in a Nuget package that ML.Net can take a binary dependency on. The code going into ML.Net is mostly wrapper code dealing with data interop and, since the binary is exposed via C api's with no overloading, code to call the correct methods based on the data type.\r\n\r\nToStringTransformer - Takes in a column and converts it into an appropriate string representation. It currently supports all integer types, float, double, bool, and string. This is fully done, and should be reviewed first.\r\n\r\nCategoryImputer - Fill in missing values with the most common value in the column.  It currently supports all integer types, float, double, bool, and string. 0's are treated as missing for integer types. This is done except for a small piece of the c++ interop.\r\n\r\nDateTimeTransformer - Splits a column into its appropriate date time components (20 columns total are added). Takes a Long that represents seconds since 1970. The c++ interop will be added for this tonight and can be reviewed last.\r\n\r\nUntil we get the binary added as an official dependency, the constructors of the estimator will throw an error if the correct .dll is not found. This allows us to do a private drop for now. The tests will also be disabled currently for that reason."""
487124417,4155,b'Implement ONNX conversion for TypeConverting transform',b'fixes #4004 \r\nTests TBD.'
486645395,4151,b'Image classification preview 2.',"b'This change improves the in-preview image classification API further:\r\n\r\n1. Increases DNN training speed by 10x.\r\n2. Reduced and constant memory footprint.\r\n3. Simplifies the API by not requiring the user to pre-process the image.\r\n4. Introduces callback to provide metrics during training such as accuracy, cross-entropy.\r\n5. Improved image classification sample.\r\n\r\nfixes #4090, #4087, #4084, #4134'"
484992647,4146,b'Builder extension method to reload changes without specifying model name',"b'This is a simple additional overload of the `BuilderExtensions.FromFile` extension methods to allow a file path to be specified and watch for changes _without_ having to specify an empty model name.\r\n\r\nCurrently, an overload is available to just specify the file path which passes `string.Empty` for the model name to another overload.  The only way to specify to watch for changes is to call the overload that accepts a model name and set this to `string.Empty` to replicate the behaviour of aforementioned overload.'"
484665854,4144,b'Added AutoML team reviewers',"b""Added AutoML team reviewers to files owned by AutoML team\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [X ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
484209489,4140,b'Added CODEOWNERS file in the .github/ folder.',"b""Added CODEOWNERS file in the .github/ folder. This allows reviewers to review any changes in the machine learning repository before merging to the master.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
484159859,4139,b'test.',b''
483683457,4138,b'Adding basic support for handling vectors in the database loader.',b'\r\n\r\n'
482051324,4127,b'Full Model Retrain Sample ',b'A sample using the full model retrain API with the MNIST model and data.\r\n\r\n'
481818296,4124,b'[WIP] Convert variable length columns in tree summaries to constant length. (Do not review)',b''
481750529,4123,b'ML.NET home page readme updated with getting started resources',"b'ML.NET home page readme updated with additional getting started resources such as, Sample apps, community sample apps, ML.NET videos playlist at YouTube, Documentation, etc. plus some refactoring of the page so the info is clearer.\r\n\r\nThis is important info to be seen upfront for new .NET users coming to the ML.NET repo.\r\n\r\n'"
481258796,4118,b'Added caching for Training Transfer Learning',b'\r\n1. Added caching for featurized data when Training\r\n2. Added callback parameter for metrics when Training\r\n3. Added ability to buffer custom batch size tensors\r\n4. Added parameter for validation set\r\n'
481173854,4117,b'Rename LabelColumn to LabelColumnName for MutualInformationSelector',"b'To follow existing practice and match all other transforms need to rename LabelColumn to LabelColumnName. Currently in NimbusML parsing logic needs to handle LabelColumn for MI, while for rest of transformers form manifest its LabelColumnName'"
481150441,4116,b'draft',b'online learning'
480927197,4115,b'Update to .NET Core 3.0 preview9',b'.NET Core preview 8 shipped yesterday. We should use it in our CI to ensure ML.NET runs correctly on the latest bits.\r\n'
480415398,4110,b'Load TransformerChain model file in ModelFileUtils',"b'Fixes #4109 \r\n\r\nRelated to microsoft/NimbusML#201\r\n\r\nEnables loading TransformerChain models from entrypoints. This is needed so that models trained in ML.NET can be scored in NimbusML.\r\n\r\nNimbusML models could be loaded and scored in ML.NET, but we never tested it the other way around.\r\n\r\n'"
480400988,4108,b'Update official build and CI to run on macOS 10.13.',"b'The official build is currently broken because it uses macOS 10.12, which is not supported with .NET Core 3.0. I also updated the CI to run on macOS 10.13, since that is supported and our tests are currently running on 10.14.\r\n\r\nAlso update the building instructions to reflect the new requirement to build for .NET Core 3.0.\r\n\r\nSince we are building for .NET Core 3.0, we now require VS 2019 Update 3, which is in preview right now. It can be downloaded from https://visualstudio.microsoft.com/vs/preview/.'"
480307575,4107,b'Updated docs to include PredictedLabel member',b'Fixes #4024 \r\n'
479901701,4104,b'Changed code path to ensure threshold is changed',b'Fixes #4076 '
478919172,4098,b'Fix LogLossReduction (RIG) example values',b'Adjusting LogLossReduction (RIG) example values in code as well.\r\n\r\nFixes #4097'
478730295,4096,b'Enabling building ML.NET for .NET Core 3.0 in the official builds.',b'This allows for the [C# hardware intrinsics code written last summer](https://github.com/dotnet/machinelearning/pulls?q=is%3Apr+author%3Abriancylui) to be used in official builds.\r\n\r\nIt also allows us to take advantage of other new APIs in .NET Core 3.0 in the future.'
478181329,4091,b'Updating DatabaseLoader to support getting column info from a given .NET type.',b'This adds limited support for determining the column info from a .NET type in order to match what TextLoader provides.'
478176064,4088,b'Update the 3.0 SDK to preview7',b''
478082909,4081,b'Added RankingEvaluatorOptions and removed the truncation limit. ',b'Summary of changes:\r\n- Added RankingEvaluatorOptions class to control the output of evaluation\r\n- Removed hard coded truncation limit for the max truncation level\r\n- Added corresponding unit tests and maml tests\r\n\r\nFixes #3993'
478049352,4079,b'[AutoML] Build fix for automl branch',b'\r\n\r\n'
477604326,4073,b'[AutoML] Fix for Exception thrown in cross val when one of the score equals infinity.',b'closes #4072 '
477526262,4071,b'[AutoML] Bump version to ML.NET 1.3.1 in AutoML API and CLI and AutoML package version to 0.15.1',b'Bumping ml.net version to 1.3.1\r\nNeeds to be smoke tested by : @justinormont  Thanks.\r\n'
477505670,4070,b'Changing the database cursor to return default for DBNull',b'This updates the `DatabaseLoaderCursor` to support nullable columns by treating them as `default`.'
477267713,4069,b'Update version to 1.4 and 0.16',b''
477235644,4068,b'Fix packaging of DNN and Tensorflow nuget package.',b'\r\n'
477212058,4067,b'Increment build version.',b'\r\n\r\n'
477168596,4066,b'Preview of Torch support (scoring)',"b'Fixes #4053 \r\n\r\nI follow the API used in TensorFlowTransformer very closely to add support for Torch. We have TorchModel class that can be loaded through mlContext.Model.LoadTorchModel(""pathToModel""). There is then a method on the TorchModel class that produces TorchScoringEstimator and that requires the usual names of input and output columns as well as the shape of the input vector. After calling Fit() on the pipeline we obtain a TorchTransformer that applies the Torch model to data in an IDataView column.\r\n\r\nFor training the only difference will be that instead of providing a path to a pretrained model, a TorchModel class will be created from a TorchSharp.NN.Module class.\r\n\r\nThis PR adds scoring of TorchScript models'"
476785464,4061,b'Release notes for v1.3.0',b'\r\n\r\n'
476541805,4060,b'LDSVM trainer',b'Add an LDSVM trainer.\r\nFixes #4031 .\r\nI will add documentation and samples in the next iterations.'
476419630,4059,b'Update Build certificate/signing.',b'fixes official builds.\r\n\r\n'
476069614,4057,b'Image classification using DNNs and Transfer Learning.',b'- Rewired Microsoft.ML.Tensorflow to use Tensorflow .NET C# bindings.\r\n- Introduces Microsoft.ML.Dnn package that contains transfer learning based image classification API using resnet and inception V3 models. \r\n  - Contains API to retrain a DNN model using tensorflow. \r\n\r\nAll tensorflow tests are passing. The current test failures have to do with ONNX tests that seem to be using a higher version of protobuf since TF.NET also uses protobuf.'
475977171,4056,b'Make Microsoft.ML.Ensemble internals visible to NimbusML DotNetBridge',"b'Fixes #4055 \r\n\r\nRequired for adding Ensemble trainers to NimbusML, which is required by Azure ML.\r\n\r\n'"
475937688,4054,b'WIP: Preview of Torch support',"b'Fixes #4053.\r\n\r\nI follow the API used in `TensorFlowTransformer` very closely to add support for Torch. We have `TorchModel` class that can be loaded through `mlContext.Model.LoadTorchModel(""pathToModel"")`. There is then a method on the `TorchModel` class that produces `TorchScoringEstimator` and that requires the usual names of input and output columns as well as the shape of the input vector. After calling `Fit()` on the pipeline we obtain a `TorchTransformer` that applies the Torch model to data in an `IDataView` column.\r\n\r\nFor training the only difference will be that instead of providing a path to a pretrained model, a `TorchModel` class will be created from a `TorchSharp.NN.Module` class. \r\n\r\nSupport for Torch in ML.NET:\r\n- [x] scoring\r\n- [ ] training '"
475384995,4050,b'Exposing a new DatabaseReader type to track state and allow multi-threaded usage',"b'As per the title, this adds a new abstract `DatabaseReader` class that allows the various database types to more easily track and expose the state required. This allows easy and configurable state tracking and cleanup, '"
473548438,4043,b'[AutoML] Pull out Code Gen as separate library plus some changes in CodeGen',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n### Related Issue\r\n- [[Implement] Code generation improvements](https://github.com/dotnet/machinelearning-modelbuilder/issues/194)\r\n\r\n- [CLI Hand Off](https://github.com/dotnet/machinelearning-modelbuilder/issues/128)\r\n\r\n"""
473108066,4039,b'PCA Anomaly Detection Threshold',b'Fixes #3990 \r\n\r\nIn this PR I change the default threshold for PCA anomaly detection to 0.5 (see the issue for discussion on what that means).\r\n\r\nI also add a method to change the threshold from MlContext in the same spirit as the BinaryClassification ChangeThreshold method.\r\n\r\nI update the samples and add a test for the new method.'
472711097,4037,b'[WIP] Initial draft of tensorflow dnn API for training.',"b'This spec is till in progress, please hold off until WIP tag is removed.'"
471967973,4035,b'Adding the initial prototype of a DatabaseLoader',b'This adds the initial barebones prototype for DatabaseLoader to the Microsot.ML.Experimental project.\r\n\r\n'
470128230,4022,b'Dnn',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
469957216,4021,b'DatabaseLoader specs: Update on NuGet and Class library design',b'Minor update so we are more explicit about the NuGet and Class library design for this feature.\r\n\r\n'
469456502,4013,b'OneVersusAllModelParameters Strongly Typed',"b'Fixes #2467\r\n\r\nWe used to remove all Type information when we constructed our `OneVersusAllModelParameters`. This prevented the users from access the inner model without run-time casting.\r\n\r\nThis PR makes the `OneVersusAllModelParameters` strongly typed, and adds a strongly typed version of the `OneVersusAllTrainer` as it uses the `OneVersusAllModelParameters`. This change is no longer a breaking change to the current public api. \r\n'"
469254231,4012,b'Minor typo fix in regularization documentation',b'Minor typo fix `empricial` -> `empirical`\r\n'
468918945,4010,b'fixes #3992',"b""fixes #3992, when inputColumnNames is not provided, it is set to new[] { outputColumnName }\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
468891021,4009,b'Farewell to the Static API',"b'Fixes #3952.\r\n\r\nIn this PR I 1. remove the static API code and 2. migrate the tests to the C# API (dynamic API) and 3. stop producing the static pipe nugets.\r\n\r\nThe commits are organized logically, which should simplify the review process.'"
468346816,4007,b'Stop LightGbm Warning for Default Metric Input [Issue #3965 Fix]',"b'Issue #3965 reported that a warning, ""LightGBM] [Warning] Unknown parameter metric="" is produced when the default metric is used. This warning came after this [commit](https://github.com/dotnet/machinelearning/pull/3859) which aimed to provide a consistent user experience from an ML.NET implementation of LightGbm with standalone LightGbm. If a user were to set `EvaluationMetric = EvaluateMetricType.Default`, they might expect that this would set the EvaluationMetric to """" and assigned the metric based on the objective as shown in the LightGbm docs. When the correction was made, this warning began to appear when the metric parameter was set to """". which was also being produced in LightGbm alone. The only way to prevent this error would be to not assign a parameter to the metric at all.\r\n\r\nThis warning has not appeared in previous versions of ML.NET and can be prevent by assigning the correct metric based on the objective as was previously done.\r\n\r\nTo prevent this warning, the changes from this [commit](https://github.com/dotnet/machinelearning/pull/3859) were reverted.'"
468340302,4006,b'Cleanuptodate',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
468218125,4002,"b'fixes #3992,  when inputColumnNames is not provided, it is set to new[] { outputColumnName }. and part of #3994(making SlotDroppingTransfomer exposed as public)'","b""fixes #3992 and part of #3994(making SlotDroppingTransfomer exposed as public)\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
468131540,4001,b'Fixing #4000 documentation and code issues',"b'Fixes the documentation/code snippet issues in #4000 \r\n\r\n- Changed `dv` to `dataView` for a more readable variable and aligned style with other variables in snippet.\r\n- Fixed code not using `IrisVectorData` output class\r\n- Fixed code not calling `CreateEnumerable<T>()` from `.Data`\r\n- Fixed some texts referencing variable `arr` (which existed in some previous version of this documentation file, but not anymore\r\n- Fixed minor indentation style in array initialization\r\n'"
466568495,3986,b'Allow user to save PredictorTransform in file and then convert it to \xe2\x80\xa6',"b'\xe2\x80\xa6ONNX via entry point APIs\r\n\r\nFix #3974. The model type in `Microsoft.ML.Model.OnnxConverter.SaveOnnxCommand.Arguments` is `TransformModel` as shown below.\r\n```c#\r\n...\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = ""Comma delimited list of output column names to drop"", ShortName = ""odrop"", SortOrder = 7)]\r\n            public string OutputsToDrop;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = ""Array of output column names to drop"", Name = nameof(OutputsToDrop), SortOrder = 8)]\r\n            public string[] OutputsToDropArray;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = ""Whether we should attempt to load the predictor and attach the scorer to the pipeline if one is present."", ShortName = ""pred"", SortOrder = 9)]\r\n            public bool? LoadPredictor;\r\n\r\n            /// <summary>\r\n            /// Entry point API can save either <see cref=""TransformModel""/> or <see cref=""PredictorModel""/>.\r\n            /// <see cref=""Model""/> is used when the saved model is typed to <see cref=""TransformModel""/>.\r\n            /// </summary>\r\n            [Argument(ArgumentType.Required, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = ""Model that needs to be converted to ONNX format."", SortOrder = 10)]\r\n            public TransformModel Model;\r\n...\r\n```\r\nThus, model typed to `PredictorModel` (created by entry point APIs) won\'t be loaded. To support both of `TransformModel` and `PredictorModel`, we add one extra field (called `PredictiveModel`) in parallel to `Model` and some if-else blocks.'"
466093013,3983,b'TF package size fix',"b'The Tensorflow tar files contain libtensorflow.so, libtensorflow.so.$(MajorVersion) and libtensorflow.so.$(Version). Of these, the first two are symlinked to the third. When these files get copied over to the nuget package, they are copied as files and not as symlinks which causes the package size to almost triple. \r\nThis fix reduces the copied files to only libtensorflow.so and libtensorflow_framework.so.$(MajorVersion).\r\n'"
465931398,3981,b'Update Api Compat after 1.2 release',"b'Fixes #3980 \r\n\r\nI update the package version number for the stable projects and I activate the API Compat tool for Onnx, TimeSeries and TensorFlow packages which became stable in the last release.  \r\n'"
465905104,3979,b'Internalizing Static API code',b'Related to #3952.\r\n\r\nIn this PR I internalize the static API code and do some clean up:\r\n1. Everything in the StaticPipe assembly is made internal\r\n2. The Static API samples have been removed\r\n3. The packaging step does not produce StaticPipe nuget\r\n\r\nNotice that this is the first of a three step process which will end up removing the static API code from the repository.'
465433267,3971,b'[WIP] NO MERGE.',b''
464916277,3968,b'[AutoML] Increment AutoML build version to 0.15.0 for preview.',b'Increment build version to 1.3.0 for release and 0.15.0 for preview. Note there are no release AutoML components at this time.\r\n\r\nThis is to keep in sync w/ the ML.NET versions -- ref: https://github.com/dotnet/machinelearning/pull/3956'
463844700,3963,b'Allow user to overwrite unknown shapes loaded from ONNX model',"b'This PR adds an extra argument to `ApplyOnnxModel` functions.\r\n```c#\r\n        /// <param name=""shapeDictionary"">ONNX shape should be used to over those loaded from <paramref name=""modelFile""/>.</param>\r\n```\r\nIf a key-value pair, (`tensor_name`, `[1, 2, 3]`) exists, the `tensor_name`\'s shape loaded from ONNX model file will be replaced by `[1, 2, 3]`. It\'s allows user to replace unknown shapes in their applications.\r\n\r\nFix #3932.\r\n\r\nWith this PR, FasterRCNN mentioned in #3932 can be run as the example below.\r\n```c#\r\n        private class RcnnInput\r\n        {\r\n            [ColumnName(""image"")]\r\n            [VectorType(3, 224, 224)]\r\n            public float[] Input { get; set; }\r\n        }\r\n\r\n        private class RcnnOutput\r\n        {\r\n            [ColumnName(""6379"")]\r\n            public float[] Boxes { get; set; }\r\n\r\n            [ColumnName(""6381"")]\r\n            public long[] Label { get; set; } \r\n\r\n            [ColumnName(""6383"")]\r\n            public float[] Score { get; set; }\r\n        }\r\n\r\n        static public IEnumerable<float> GenerateRandomVector(int size)\r\n        {\r\n            var rnd = new Random(0);\r\n\r\n            for (int i = 0; i < size; ++i)\r\n                yield return rnd.NextSingle();\r\n        }\r\n\r\n        /// <summary>\r\n        /// A test to check if dynamic shape works.\r\n        /// </summary>\r\n        [OnnxFact]\r\n        public void TestOnnxTransformDynamicShape()\r\n        {\r\n            var modelFile = Path.Combine(Directory.GetCurrentDirectory(), ""fasterRCNN"", ""faster_rcnn_R_50_FPN_1x.onnx"");\r\n\r\n            var dataPoints = new RcnnInput[] {\r\n                new RcnnInput() { Input = GenerateRandomVector(3 * 224 * 224).ToArray(), }\r\n            };\r\n\r\n            var shapeDictionary = new Dictionary<string, int[]>() { { ""image"", new int[] { 3, 224, 224 } } };\r\n\r\n            var dataView = ML.Data.LoadFromEnumerable(dataPoints);\r\n            var transformedDataView = ML.Transforms.ApplyOnnxModel(new[] { ""6379"", ""6381"", ""6383"" }, new[] { ""image"" }, modelFile,\r\n                shapeDictionary: shapeDictionary).Fit(dataView).Transform(dataView);\r\n\r\n            // Convert IDataView to IEnumerable<ZipMapOutput> and then inspect the values.\r\n            var transformedDataPoints = ML.Data.CreateEnumerable<RcnnOutput>(transformedDataView, false).ToList();\r\n\r\n            for (int i = 0; i < transformedDataPoints.Count; ++i)\r\n            {\r\n                Assert.NotNull(transformedDataPoints[i].Boxes);\r\n                Assert.NotNull(transformedDataPoints[i].Label);\r\n                Assert.NotNull(transformedDataPoints[i].Score);\r\n            }\r\n        }\r\n```\r\n'"
463576791,3961,b'[AutoML] Produce AutoML NuGet package in build pipeline',"b'Produce AutoML NuGet package in build pipeline\r\n\r\nCurrently, only the `mlnet` and _symbols_ for `Microsoft.ML.AutoML` are produced. We need to also produce the NuGet for `Microsoft.ML.AutoML`.\r\n\r\nThis reverts the change from https://github.com/dotnet/machinelearning/pull/3656.'"
463549805,3958,b'[AutoML] Bump ML.NET package version to 1.2.0 in AutoML API and CLI; and AutoML package versions to 0.14.0',b'Closes https://github.com/dotnet/machinelearning/issues/3959 and closes https://github.com/dotnet/machinelearning/issues/3960:\r\nBump ML.NET package version to latest 1.2.0 in AutoML API and CLI (including the generated C# code); bump AutoML package versions to 0.14.0 to be consistent with ML.NET preview version'
463429776,3957,b'Increment version for application compatibility.',b'\r\nFixes #3980'
463414699,3956,b'Increment build version to 1.3 for release and 0.15 for preview.',b'\r\n'
463399692,3955,b'Update .gitattributes',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
463371044,3954,b'[AutoML] CLI: Regenerate templated CS files',"b""Regenerate all templated CS files from checked-in TT files. (I unknowingly upgraded CS files to be FXCop / StyleCop compliant in https://github.com/dotnet/machinelearning/pull/3823 . This was unnecessary. I did not modify TT files. I'm reverting my FXCop / StyleCop change to the generated files by regenerating them from the checked-in TT files.)"""
463370443,3953,b'[AutoML] Regenerate CLI templated files',b''
463132839,3951,b'Release notes for 1.2.0 release.',b'\r\n'
463055787,3950,b'Reformatting Featurization of Transform and Misc files in Transform to Width 85',"b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478\r\n*Misc. refers to those files found in the Transform directory but not in another subdirectory"""
463028013,3949,b'Reformatting misc. samples to width 85',"b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478\r\n\r\n*Misc. meaning files not in a specific folder"""
463017863,3948,b'Reformatted Regression samples to width 85',"b'Guidelines followed:\r\n\r\n- 85 characters per line\r\n- Use 4 spaces for indentation\r\n- Dot, open parentheses, and function/variable name on same line\r\n- Math operations on same line\r\n- Don\'t indent comments\r\n- Don\'t break links\r\n- Don\'t break a comment if it represents a print output\r\n- Add an extra line after a break if it does not already exist\r\n- Break before ""$""\r\nFix for Issue #3478'"
462992630,3947,"b'Reformatting Test, Projection and TimeSeries of Transform to Width 85'","b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478"""
462988564,3946,b'Reformatting BinaryClassification samples to width 85',"b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478\r\n"""
462971092,3945,b'Rename forecasting API argument to a better name.',b'\r\n\r\n'
462951609,3944,b'Fix typo in time series forecasting API.',b'\r\n\r\n'
462943876,3943,"b'Reformatting Conversion, FeatureSelection and Image Analytics of Transform to Width 85'","b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478"""
462901961,3942,b'Reformatting MulticlassClassification samples to width 85',"b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478\r\n*There are a couple exceptions to the 85 char. limit that have been approved by Natalie"""
462874548,3941,b'Reformatted Recommendation samples to width 85',"b'Guidelines followed:\r\n\r\n- 85 characters per line\r\n- Use 4 spaces for indentation\r\n- Dot, open parentheses, and function/variable name on same line\r\n- Math operations on same line\r\n- Don\'t indent comments\r\n- Don\'t break links\r\n- Don\'t break a comment if it represents a print output\r\n- Add an extra line after a break if it does not already exist\r\n- Break before ""$""\r\nFix for Issue #3478'"
462853710,3940,b'Add AVX and FMA intrinsics in Factorization Machine',b'Added AVX and FMA C# intrinsics in Microsoft.ML.StandardTrainers for Factorization Machine algorithm  which currently implements C++ SSE code as suggested in #3000 and #3785\r\n\r\n@wschin @eerhardt '
462842449,3939,b'Reformatted Recommendation samples to width 85',"b'Guidelines followed:\r\n\r\n- 85 characters per line\r\n- Use 4 spaces for indentation\r\n- Dot, open parentheses, and function/variable name on same line\r\n- Math operations on same line\r\n- Don\'t indent comments\r\n- Don\'t break links\r\n- Don\'t break a comment if it represents a print output\r\n- Add an extra line after a break if it does not already exist\r\n- Break before ""$""\r\n\r\nFix for Issue #3478'"
462716808,3937,b'Reformatted Recommendation samples to width 85',"b'Guidelines followed:\r\n\r\n85 characters per line\r\nUse 4 spaces for indentation\r\nDot, open parentheses, and function/variable name on same line\r\nMath operations on same line\r\nDon\'t indent comments\r\nDon\'t break links\r\nDon\'t break a comment if it represents a print output\r\nAdd an extra line after a break if it does not already exist\r\nBreak before ""$""\r\nFix for Issue #3478'"
462685942,3936,b'Internalize tensorflow API and sanity check APIs from Microsoft.ML.Tensorflow nuget',b'fixes #3863\r\n\r\n'
461800555,3930,b'Reformatted Ranking samples to width 85',"b'Guidelines followed:\r\n\r\n- 85 characters per line\r\n- Use 4 spaces for indentation\r\n- Dot, open parentheses, and function/variable name on same line\r\n- Math operations on same line\r\n- Don\'t indent comments\r\n- Don\'t break links\r\n- Don\'t break a comment if it represents a print output\r\n- Add an extra line after a break if it does not already exist\r\n- Break before ""$""\r\n\r\nFix for Issue #3478'"
461783729,3929,b'Updated the redistributed version of Tensorflow to 1.14',b'fixes #3962'
461693221,3928,b'OneVersusAllModelParameters Strongly Typed',"b'Fixes #2467\r\n\r\nWe used to remove all Type information when we constructed our `OneVersusAllModelParameters`. This prevented the users from access the inner model without run-time casting.\r\n\r\nThis PR makes the `OneVersusAllModelParameters` strongly typed, as well as the `OneVersusAllTrainer` and the `LightGbmMultiClassTrainer` as they use the `OneVersusAllModelParameters`. This change is a _**breaking**_ change to the current public api. The `LightGbmMultiClassTrainer` model is typed to be `FeatureWeightsCalibratedModelParameters<LightGbmBinaryModelParameters, PlattCalibrator>` as that is what it is hard coded to return on line 190. The `OneVersusAllTrainer` determines the type automatically if you `OneVersusAll` method in the `StandardTrainersCatalog`.\r\n\r\nAs part of this change, the `OneVersusAllTrainer` will no longer auto calibrate the model and you must pass in the model already calibrated if you want it to be calibrated. \r\n\r\nDISCUSSION POINT - Currently the `useProbabilities` flag is still allowed. You must set it to false with a non-calibrated trainer or an error will be thrown. If your trainer is calibrated, you can pass either `true` or `false` and it will either use raw values or calibrated ones accordingly. Do we still want to allow this? Or would it be better to remove the `useProbabilities` flag and have non-calibrated trainers always return  raw results and have calibrated trainers always return calibrated results? This would simplify the call and prevent errors where you forget to set `useProbabilities` to false with a non-calibrated trainer, but would also prevent you from getting raw results from a calibrated trainer.\r\n\r\nSince the `OneVersusAllTrainer` no longer auto calibrates the trainer, the testing files we use for comparison were also updated to reflect that.\r\n\r\nSome calibrators where changed from `internal` scope to `public` scope as we now return them as a type for the user to use.\r\n\r\nThe test for this is just adding a line in the existing `LightGbmMulticlassEstimatorCorrectSigmoid` test showing that casting is not needed to access the internal model.'"
461639932,3925,b'LightGBM Unbalanced Data Argument [Issue #3688 Fix]',b'Fix for issue #3688. LightGBM Multiclass Trainer can now accept unbalanced data parameter as was previously possible in the Binary Trainer. An additional argument was added to the LightGBMBinaryEstimator test.'
461631920,3923,b'Reformatting ModelOperations and DataOperations samples to width 85',"b""Guidelines followed:\r\n-85 characters per line\r\n-Use 4 spaces for indentation\r\n-Dot and open parentheses stay on same line as function\r\n-If not a preexisting line under line that we break, add an extra line after it\r\n-Don't indent comments\r\n-Don't break a comment if it represents output\r\n-Don't break links\r\n-If applicable, break right before $\r\n-Keep math op together\r\n\r\nFix for issue #3478 """
461631919,3922,b'Reformatting TensorFlow and AnomalyDetection samples to width 85',"b'Guidelines followed:\r\n- 85 characters per line\r\n- Use 4 spaces for indentation\r\n- Dot, open parentheses, and function/variable name on same line\r\n- Math operations on same line\r\n- Don\'t indent comments\r\n- Don\'t break links\r\n- Don\'t break a comment if it represents a print output\r\n- Add an extra line after a break if it does not already exist\r\n- Break before ""$""\r\n\r\nFix for Issue #3478 '"
461358533,3918,b'[AutoML] Sweep Trimming of Whitespace in AutoML',"b'Fixes https://github.com/dotnet/machinelearning/issues/3917:\r\n> We should iterate over the options for TrimWhitespace in the TextLoader.\r\n> \r\n> As diagnosed by @daholste, the MSLR-WEB10K dataset ([train](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTrain720kRows.tsv), [validate](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv), [test](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTest240kRows.tsv), [zip](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/MSLR-WEB10K.zip), [README](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/README.md), [LICENSE](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/LICENSE.md)) has an extra tab at the end of each data row, though not the header row. \r\n> \r\n> This causes the AutoML TextLoader to fail w/ the following error: \r\n> ```\r\n> An Error occured during inferring columns\r\n> Unable to split the file provided into multiple, consistent columns.\r\n> Please see the log file for more info.\r\n> Exiting ...\r\n> ```\r\n> \r\n> Work:\r\n> * Have AutoML sweep over the [TrimWhitespace](https://github.com/dotnet/machinelearning/blob/429f8cc7764769fcf8c7f3668cc0a27619ec9531/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1449) option\r\n> * Fix above error message -- spelling of ""occured""'"
461228155,3916,b'Add FixZero for LogMeanVariance normalizer',"b""Fixes #2798.\r\n\r\nThis PR introduces the `FixZero` argument to the `LogMeanVariance` normalizer, a relative tests and a sample.\r\n\r\nIt's still in WIP because I would like to make a breaking change instead of creating an overload with required parameter `FixZero`. As soon as the change is accepted and I set up the API Compat tool to accept the breaking change, I should be able to remove the overloads to the `MLContext` extensions.\r\n"""
461220862,3915,b'Test PR',b'Testing'
461208214,3914,b'Test PR',b'Test\r\n\r\n'
461138308,3912,b'Fix assignment of a variable to itself',b'The **invMap** variable is assigned to itself. Removed it.'
461124868,3911,b'Another Try to Fix Build for Adding ORT Update',b''
461079414,3910,b'Create forecasting prediction engine and conform time series forecasting API to estimator standards.',b'fixes #3862'
460760058,3908,b'Move from phases to jobs and use bring your own cloud pool',"b'This is needed to unblock: https://github.com/dotnet/machinelearning/pull/3881\r\n\r\nBasically the hosted azure devops machines have limited hard drive (25gb) and since tests are executed on the build machine it is running out of space. BYOC pools have 512 gb so that will unblock this scenario.\r\n\r\nHowever I do think, machinelearning repo should move to run tests on helix in the long term.\r\n\r\n**Note:** *this is easier to review if omitting whitespaces from the diff*\r\n\r\ncc: @codemzs @wschin \r\n'"
459402747,3899,b'Fix #3898 (remove crefs to internal methods)',b'A new API docs build and rendering system is being rolled out (Schema Driven Processor). This new build system discovered some invalid cross references in the ML.NET code. This PR fixes those.\r\n\r\n'
459359956,3896,b'Checked in a better fix based on code review',b'Fixes #3893 \r\n\r\nThe earlier fix was clobbering theCMake defaults. @janvorli  suggested a better fix to simply replace the offending flag. This checkin has that fix.'
459091316,3894,b'Fixed build errors resulting from upgrading to VS2019 compilers',"b'Fixes #3893 \r\n\r\nThe default CMAKE_C_FLAG for debug configuration sets /ZI to generate a PDB capable of edit and continue. In the new compilers, this is incompatible with /guard:cf which we set for security reasons. So to fix, we need to go back to a regular pdb generated by the /Zi flag. \r\n\r\nSince this part of the default CMake rules, we need to override the full default set and update only that particular flag.\r\n\r\n\r\n'"
458779277,3892,b'Tree based trainers implement ICanGetSummaryAsIDataView',"b'Fixes #3755.\r\n\r\nNimbusML did not have access to the details on the tree structure.\r\nThis PR implements the `ICanGetSummaryAsIDataView` interface which is used in the `Summarize` entrypoint to pass a summary of the model parameters to NimbusML in the form of an `IDataView`.\r\n\r\nI create a utility method that does the conversion from `RegressionTreeBase` to `IDataView` with special treatment for `QuantileRegressionTrees` which have additional information.\r\n\r\nIn the `IDataView`, each node has its own row and the columns correspond to the fields describing each node. To determine which tree the node belongs to there is a `TreeID` column.'"
457778085,3882,b'[AutoML] bring AutoML API library to master',b'This moves the AutoML API code from a feature branch to master. The CLI will move next.\r\n\r\nCloses https://github.com/dotnet/machinelearning/issues/4008'
457749970,3881,b'ONNXTransform Upgrade to Enable Non-tensor Types',"b'The current ONNXTransform only operates on tensor types. As many ONNX models (especially classifiers) produce Seq<Map<T, float>> where T can be either int or string, we should remove that limitation.\r\n\r\nThis should fix #3900.'"
457740736,3880,b'[WIP] Improve column purpose detection for sparse text datasets',"b'Fixes #3879 by not counting empty text values when calculating the column statistics.\r\n\r\nBackground from #3879:\r\n> AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n> \r\n> This is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n> \r\n> **To fix:** \r\n> We need to detect the column purpose only on the set (non-blank) values.\r\n> \r\n> Recommend subtracting the blank values from `data.Count`:\r\n> https://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n> \r\n> Currently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.\r\n'"
457223476,3875,b'Add bindings for RowImpl in time series SequentialTransformerBase',b'fixes #3874\r\n'
457135941,3873,b'[WIP] Repro for Timeseries  engine exception',b'Repro for Timeseries  engine exception.\r\n@codemzs  pls take a look\r\n\r\nthx'
455509069,3860,b'[AutoML] add task agnostic wrappers for autofit calls',b''
455483823,3859,b'Change default EvaluationMetric for LightGbm trainers to conform to d\xe2\x80\xa6',"b'\xe2\x80\xa6efault metric in standalone LightGbm\r\n\r\nFixes #3822 \r\n\r\nIn ML.NET, the default `EvaluationMetric` for LightGbm is set to `EvaluateMetricType.Error` for multiclass, `EvaluationMetricType.LogLoss` for binary, and so on. This leads to inconsistent behavior from the user\'s perspective: If a user specified `EvaluationMetric = EvaluateMetricType.Default`, the parameter passed to LightGbm would be the empty string """", which is the LightGbm default and means that the metric is selected based on the objective. However, if they do not specify `EvaluationMetric` at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on. \r\n\r\nWe should make the experience for LightGbm in ML.NET consistent with what a user of standalone LightGbm experiences, and not expect them to dig through LightGbm docs and ML.NET docs to find this out.\r\n\r\nThis PR makes the user experience consistent with standalone LightGbm by by changing the default `EvaluationMetric` in ML.NET to `EvaluationMetricType.Default`.\r\n\r\n[LightGbm metric parameters docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric-parameters)'"
455380977,3857,b'Early Draft specs doc for DatabaseLoader in ML.NET',"b""Early Draft specs doc for a `DatabaseLoader` component in ML.NET. \r\nFeel free to provide feedback. This specs document will be evolving significantly since it is in a very early draft state.\r\n\r\nMain objective is to load data into an IDataView from relational databases (such as SQL Server, Azure SQL Database, PostgreSQL, MySQL, Oracle, etc.) in a very easy way, one line of code in most cases by simply specifying the connection string, the database `table/view/sql-sentence` and what database provider/connection type it is using.\r\n\r\nCurrently in ML.NET 1.0 or 1.1 we can only do the following:\r\n\r\n- Load data from files by using `MLContext.Data.LoadFromTextFile()`, etc.\r\n- Load data from an IEnumerable collection with `MLContext.Data.LoadFromEnumerable()`, usually coming from a database, but the developer/user is responsible for how to load/query the database. It is not straightforward such as when reading from a file.\r\n\r\n**High level design goal:**\r\nThe intention of the new component is to make a lot easier to implement _'model training scenarios  pulling/streaming data from large database tables'_ while transparently solving complicated cases such as 'transient errors' in the cloud (database connections broken as a result) when using Azure SQL Database.\r\n"""
454791564,3854,b'CustomGains should allow multiple values in argument attribute.',b'fixes #3710\r\n'
454789414,3853,b'Update roadmap.',b'fixes #2074\r\n\r\n'
454424547,3852,b'Fixes #3207. Prevent usage of KeyType without parameter.',"b""Added an exception to the parameterless constructor for KeyType because it doesn't make sense to use it without a parameter\r\n\r\nWhen KeyType is called without a constructor, the Count member remains uninitialized and when that remains null, it is set to uint.MaxValue which fails the overflow check. \r\n\r\nSince the value that a particular KeyType takes on represents an index into a 1 based vector, it cannot be set to zero by zero by default. It always needs to have a valid max value and that needs to be determined by the use case. Therefore, the best approach is to prevents its usage without the parameter. \r\n\r\nThere seems to be a different but related doc bug that this fix does not address:\r\n\r\nThe documentation for [KeyTypeAttribute](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.keytypeattribute?view=ml-dotnet) says it can be used with uint and ulong.  However, during mapping there is an overflow check performed and an exception is thrown if the value is greater than int.MaxValue - 1. \r\n\r\nThat means, we don't actually support the full range of uint and ulong. \r\n\r\n@codemzs / @artidoro Any thoughts on whether we should fix the docs or remove the overflow check?\r\n\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\nfixes #3207\r\n"""
454374167,3851,b'Add example for applying ONNX model to in-memory images',b'Fix #3562 by adding an sample.'
454315853,3850,b'Bugfix/hardwired sigmoid',b'Fixes #1422 \r\n\r\nFixes the Hardcoded Sigmoid value from -.5 to the value specified during training.\r\n\r\nLet Microsoft.ML.Tests see internals of Microsoft.ML.Standard trainers to access trained model parameters for testing verification.\r\n\r\n'
453651267,3842,"b'Revert ""Publish nugets to temporary myget feed (#3400)""'",b'This reverts commit 0a90bbb49da69765c2ff870078fdabfb20783a58.\r\n\r\nshmoradi myget feed is downgraded to 200MB of space after a month and needs to be replaced with a permanent solution. It was created as a workaround before //build. Disabling it for now to prevent the failure in publishing step.'
453605771,3840,b'Broken docs images for ranking metrics',"b""Fixes two broken links to images at: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.rankingmetrics?view=ml-dotnet-1.1.0.\r\n\r\nThe next doc release will show the fix.\r\n\r\nIssues fixed by this PR:\r\n* Linking to GitHub's webpage for the images, and not the images itself\r\n* Linking to the master branch, which will change overtime, potentially breaking older versions of the docs\r\n\r\nIssues NOT fixed by this PR:\r\n* Linking at all to GitHub -- Do we have a way to have the docs make its own copy of the image? Currently the user's browser will pull the image from GitHub while on docs.microsoft.com. Perhaps this will be fixed when this PR fixes the link?\r\n* NDCG.png has a transparent background; DCG.png one does not \r\n* We may want a check-in test which verifies document image links\r\n\r\nFeel free to push to this PR if you can fix any of the additional above items."""
453293558,3837,b'Bump ONNXRuntime version',"b""Toward #3836. We will have to increase the number of tests to have higher code coverage.\r\n\r\nThose initial failed tests are caused by an incorrect field in ResNet18 ONNX model. Its last layer (AveragePool) should only have 4 integers as `pads` but found 6. To fix this problem, we need to update ML.NET's model blob on azure (under internal TLC subscription)."""
453271903,3835,b'Explain MLContext seed parameter',b'Fixes #3048.\r\n'
453168729,3834,"b'Move Time Series, TensorFlow and OnnxTransform nugets to stable project'",b'fixes #3833\r\n'
452666106,3831,b'Add default and missing value definitions for ML.NET types',"b""Fixes #3443.\r\n\r\nThis PR has two related parts:\r\n\r\n1) Add default and missing values definitions. DataKind page, seems the best place to have all of that information in one place. The documented definitions come from [IsNa region](https://github.com/dotnet/machinelearning/blob/2960b273ee0eda1d3a285a4b46a58a4d6d7b6926/src/Microsoft.ML.Data/Data/Conversion.cs#L739) and [IsDefault region](https://github.com/dotnet/machinelearning/blob/2960b273ee0eda1d3a285a4b46a58a4d6d7b6926/src/Microsoft.ML.Data/Data/Conversion.cs#L749).\r\n\r\n2) Fix the docs of CountFeatureSelectingEstimator to include missing value in addition to default value. Previously, we incorrectly thought only non-default values matter. But digging into [the code](https://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.Transforms/CountFeatureSelection.cs#L433), it's clear that the check is for non-default AND non-missing."""
452270117,3827,b' Add Microsoft.Extensions.ML integration package.',"b'This package makes it easier to use ML.NET with app models that support Microsoft.Extensions - i.e. ASP.NET and Azure Functions.\r\n\r\nSpecifically it contains functionality for:\r\n\r\n- Dependency Injection\r\n- Pooling PredictionEngines\r\n- Reloading models when the file or URI has changed\r\n- Hooking ML.NET logging to Microsoft.Extensions.Logging\r\n\r\nFix #3239\r\n\r\ncc @glennc - Note that the only major change I made to your code was to remove the `IPredictionEnginePoolBuilder` interface in favor of using a simple class instead.\r\n\r\nAfter this is merged to master, we can remove the `features/IntegrationPackage` branch.'"
452254954,3825,b'Update readme.',b'\r\n\r\n'
452253218,3824,b'Update API compat version number to 1.1.0 for stable release packages',b''
452239328,3823,b'[AutoML] Enable style cop rules & resolve errors',b''
452176125,3821,b'Add AutoML as a best friend assembly to Microsoft.ML.Core',b'This resolves https://github.com/dotnet/machinelearning/issues/3813 for AutoML'
452158821,3820,"b'For binary classification, discard cross validation splits where there is not at least one true & one false label in the validation set'","b'For binary classification, discard cross validation splits where there is not at least one true & one false label in the validation set. Otherwise, scoring the dataset crashes because AUC cannot be computed like in https://github.com/dotnet/machinelearning/issues/3800'"
452151777,3819,"b'NativeAssemblyReference Include ""MklProxyNative"" in Samples project.'",b'fixes #3818\r\n\r\n'
451744537,3815,b'Fix the treatment of LightGbm Evaluation Metric parameters in ML.NET \xe2\x80\xa6',"b'\xe2\x80\xa6and make them conform to LightGbm\r\n\r\nFixes #3761 plus some related issues discovered during investigation\r\n\r\n1. There was a bug in LightGbm `EvaluateMetricType` where if a user specified `EvaluateMetricType.Default`, the metric would not get added to the options Dictionary, and `LightGbmWrappedTraining` would throw because of that. \r\n\r\n2. Secondly, `EvaluateMetricType.Default` in LightGbm is supposed to be an empty string """" and LightGbm chooses the default metric according to the problem type when this is specified. This was not present in ML.NET parameter name mappings. `EvaluateMetricType.None` is supposed to be ""None"" in LightGbm but was """" in ML.NET parameter name mappings.\r\n\r\n3. [**Update: REVERTED**] Third, in ML.NET, the default `EvaluationMetric` is set to `EvaluateMetricType.Error` for multiclass, `EvaluationMetricType.LogLoss` for binary, and so on. This leads to inconsistent behavior from the user\'s perspective: If a user specified `EvaluationMetric = EvaluateMetricType.Default`, the parameter passed to LightGbm would be the empty string """" but if they do not specify `EvaluationMetric` at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on.\r\n\r\nThis PR does the following:\r\n- Fixes the bug in (1)\r\n- Addresses (2) by adding all the parameters to the options dictionary with the correct values (i.e. conforming to LightGbm [docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric-parameters)\r\n- [**Update: REVERTED**] Addresses (3) by changing the default `EvaluationMetric` in ML.NET to `EvaluationMetricType.Default`\r\n\r\n\r\n'"
451720642,3814,b'Expose NeedCalibration property of TrainerInfo',b'Closes https://github.com/dotnet/machinelearning/issues/3813'
451712771,3812,b'Tree-based featurization',"b""Fix #2482. Generating features using tree structure has been a popular technique in data mining. This PR exposes this internal-only feature to the public.\r\n\r\nSince I don't have enough time to handle multiple different assignments at the same time, please don't put nit comments and create new issues instead. Thanks a lot."""
451649636,3809,b'Check for number of input columns in concat transform',b'Fixes #3061 \r\n\r\nThe PR makes the following changes:\r\n- Follows Solution A mentioned in the issue\r\n- Added a unit test \r\n\r\n'
451322634,3805,b'Add overload for time series checkpoint API that takes a stream',b'fixes #3804'
451173031,3802,b'Bump master to 1.2 and preview to 0.14.',b'\r\n\r\n'
451171855,3801,b'Release notes for 1.1.0',b'Adds release notes for v1.1.0 release.\r\n\r\n'
450542033,3796,b'Change ensembles trainer to work with ITrainerEstimators instead of ITrainers',b'This is needed for using ensembles with non-default values for the sub-trainers.\r\nFixes #3709 .\r\n'
450467731,3794,b'[AutoML] Cross validation fixes; validate empty training / validation input data',"b""Updates --\r\n- In the AutoML API -- when calling the `Execute` method signature that contains both training & validation data, if validation data is null, route to the `Execute` method that doesn't contain validation data / that splits the data in a train/test or cross-val manner depending on the # of rows.\r\n- Don't crash if some cross val splits have empty train/test data. As long as not all splits have empty train or test data, proceed only using splits w/ non-empty train & test sets. Explicitly throw an exception if all splits either have empty train or test sets.\r\n- Validate input training & validation data (if explicitly provided) are not empty"""
450432101,3793,b'Added samples for loading text',b'Fix #2457 \r\n'
450076677,3789,b'[AutoML] CLI telemetry rev',"b'Add telemetry around:\r\n - Infer Columns\r\n - System Info\r\n - Experiment iteration results\r\n - Overall experiment results\r\n - Application Exit\r\n\r\nAlso, add error logging and duration tracking for events\r\nCloses https://github.com/dotnet/machinelearning-automl/issues/417 by componentizing the instrumentation of the CLI tool'"
450063264,3788,b'Fix TextLoader constructor and add exception message',"b""Fixes #3705.\r\n\r\nIn issue #3705 it appeared that the class defining the data was required to have both get and **set** auto-properties. In `TextLoader` however, we don't use the set property, so I removed that from the conditions.\r\n\r\nSecond, I added an exception message in case no public readable property or field is found in the class defining the data and no dataSample is passed to the constructor.\r\n\r\nI added a related test which tests the various scenarios.\r\n """
449533150,3785,b'Add AVX and FMA intrinsics in Factorization Machine',b'Added AVX and FMA C++ intrinsics in factorizationmachinenative.dll which currently implements C++ SSE code as suggested in #3000.'
448596499,3777,b'[AutoML] Enhance calculated dataset statistics; expose dataset statistics to CLI',b''
448501311,3776,b'[AutoML] Reservoir sample dataset statistics',b'Closes #3778'
448327873,3774,b'Add load names to Platt calibrator',b'The load names of the `PlattCalibratorTrainerFactory` need to match those of the `LoadableClassAttribute`.\r\n'
447896097,3772,b'Fix the user name in LoadableClassAttribute of VectorToImageTransformer',b'Update user name in loadable class attribute to the right name.'
447390298,3768,b'Improve error message for non-vector input to TensorFlowTransform',b'Closes #1542 \r\n\r\nThe behavior is expected. TensorFlow treats all inputs as tensors. A scalar input should simply be loaded as a uni-dimensional tensor.\r\n\r\nThis PR improves the error message for the existing check for non-vector inputs to make this clear and closes the issue.\r\n'
447032608,3763,b'Access indices array for VBuffer in KeyToVector transformer only when resulting vector is sparse.',b'fixes #3757\r\nfixes #1751\r\nfixes #2678'
446852458,3758,b'Upgraded the TensorFlow version from 1.12.0 to 1.13.1',b'Upgraded the TensorFlow version from 1.12.0 to 1.13.1. Cannot upgrade to version 2.0 as it is currently in alpha.'
446566150,3753,b'Minor typos in TextClassification.cs',b'Minor typos. \r\n\r\nFeel free to merge when ready.'
445816778,3746,b'Update nullable value to GetValueOrDefault',b'Update for #2612. Set as WIP to start getting feedback.\r\n\r\n@TomFinley Just let me know if I missed anything.'
445623406,3745,b'Adding samples for data save and load from text and binary files',b'Fixes #3661 \r\n\r\n'
445201612,3742,b'These changes allow for ML.NET to be built from source by VS2019 ',b'Fixes [#3739](https://github.com/dotnet/machinelearning/issues/3739)\r\n\r\n'
445189971,3741,b'Added omp requirement to build on Linux on README',b'Fixes #3740.\r\n\r\nAdds requirement and sample command to build on Linux.\r\n\r\n'
445175647,3738,b'Added sample for WithOnFitDelegate',b'Fixes #3732 '
444760854,3731,b'[AutoML] Fix for Column inference for R4 type column in different cultures ',b'Looks like the column inference is getting wrong in some of the cultures like Deutsch and Finnish . \r\nSo making the parsing InvariantCulture'
444671742,3730,b'[AutoML] Reset the culture info back to its original value in the test case.',b'Reset the culture info back to its original value in the test case so that if the thread is reused else we do not have any side effects. Just to be safe.\r\n'
444180738,3725,b'[AutoML] Fix Internationalization bug in generated project. ',"b'Looks like in Deutsch culture the floats are causing compilation errors in generated project because of the strings that generated floats are culture specific. Need to make them culture invariant.\r\n\r\nExample : 1.1 -> 1,1 (deutsch)\r\ncloses #3677 '"
444179676,3724,b'Added usage example for LogLossPerClass metric for multiclass trainers',b'Fixes #3672 '
444164446,3721,b'Brew install libomp 7.0.0 only.',b'Stop gap fix until #3722 is fixed.'
444097217,3719,b'Adding InternalsVisibleTo to a couple of projects',b'Fixes #3715 \r\n\r\n- Added `Microsoft.ML.Runtime.SequencePrediction` to `Microsoft.ML.StandardTrainers`\r\n- Added `TMSNlearnPrediction` to `Microsoft.ML.Transforms`\r\n\r\n'
443135527,3706,b'Update Readme.md',b'A few minor changes to make the readme a little easier to read and understand.\r\n'
442538143,3700,b'Add option to execute only the last transform in TransformWrapper and have WordBagEstimator return transformer chain',b'fixes #3699'
442449288,3696,b'Sample of using LoadFromEnumerable with a SchemaDefinition',b'I have seen a few asks for how to bypass having to define the size of the vector in the data models. \r\nAdding an example for it. \r\n\r\n'
442433341,3695,b'Fix documentation for LightGbm parameter',b'Fix #3687 \r\n\r\nDocumentation for `MaximumCategoricalSplitPoint`.\r\n\r\n'
442287784,3693,b'Add SrCnn Anomaly Detector',b'Add SRCNN algorithm to TimSeries Anomaly Detection\r\n\r\nfixes #3799'
442041389,3682,b'Replace VectorType with VectorDataViewType in SchemaComprehension document',"b'ref: https://github.com/dotnet/machinelearning/pull/3022\r\n\r\nThe document did not follow the change https://github.com/dotnet/machinelearning/pull/3022 , so replace it.\r\n'"
441466691,3676,b'Fix SoftMax precision by utilizing double in the internal calculations',b'Fixes #3648 \r\n\r\nUses `double` when calculating softmax exponent scores and only cast to `float` at the final step returning the probabilities.\r\n\r\ncc: @rauhs '
440821521,3668,b'Fixes the build badges to show correct status',"b'Fixes https://github.com/dotnet/machinelearning/issues/3650\r\nThe build badges are showing incorrect status, fixing the issue.'"
440808785,3667,b'Fix to the official build (API Compat tool)',"b'PR #3623 breaks the official build because the .Net Core 2.1 runtime is not found.\r\nWe have it locally in the tools directory, so a solution is to make it point to that local installation of the runtime. \r\n\r\nFixes #3666.\r\n\r\n'"
439850957,3658,b'[AutoML] bump version to 0.4.0',b''
439841782,3657,b'[AutoML] undo temp change in build.proj',b''
439833986,3656,b'[AutoML] temp change to get around vsts publish failure',b''
439802435,3655,b'[AutoML] Change wording for CouldNotFinshOnTime message',b''
439734076,3653,b'[AutoML] Cleaner way to exit the main()',"b""We could just return the exit code from main()\r\nInstead of Environment.Exit(exitcode)\r\n\r\nThe reason it wasn't working before was the fact that we were spawning foreground threads.\r\n\r\nIt seems to be the standard.\r\nhttps://github.com/dotnet/cli/blob/21cda4adb6d88d240978e24fcfeb3ebe73f5fdd7/src/dotnet/Program.cs#L30-L83\r\n"""
439730040,3652,b'[AutoML] Cleaner way to exit the process',"b""More cleaner way to exit the main.\r\n\r\nThe reason why return from main wasn't working before was due to the fact that we have spawned foreground threads.\r\n\r\n"""
439719009,3651,b'Adds missing license headers.',"b'In addition to #3645, I wrote a small C# program to open every "".cs"" file in src directory and read the first non-null/empty line and compare it against ""// Licensed to the .NET Foundation under one or more agreements."" and found few more places where license was missing. \r\n\r\n```csharp\r\npublic static class Program\r\n    {\r\n        public static void Main(string[] args) => RunAll(@""E:\\machinelearning\\src"");\r\n\r\n        internal static void RunAll(string sDir)\r\n        {\r\n           foreach (string d in Directory.GetDirectories(sDir))\r\n            {\r\n                foreach (string f in Directory.GetFiles(d))\r\n                {\r\n                    if (Path.GetExtension(f) == "".cs"" || Path.GetExtension(f) == "".tt"")\r\n                    {\r\n                        using (var fileStream = File.OpenRead(f))\r\n                        using (var streamReader = new StreamReader(fileStream, Encoding.UTF8, true))\r\n                        {\r\n                            string line;\r\n                            while ((line = streamReader.ReadLine()) != null)\r\n                            {\r\n                                if(String.IsNullOrEmpty(line))\r\n                                    continue;\r\n\r\n                                if (line !=\r\n                                    @""// Licensed to the .NET Foundation under one or more agreements."")\r\n                                {\r\n                                    Console.WriteLine(f + "" : "" + line);\r\n                                }\r\n\r\n                                break;\r\n\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                RunAll(d);\r\n            }\r\n        }\r\n    }\r\n```'"
439706655,3649,b'[Donet Review] [Just for testing]pascal casing',b'\r\n\r\n'
439451760,3645,b'Adds missing license headers',b'Adding the license header to files that were missing it'
439409847,3644,b'[AutoML] Upgrade ml.net package in generated code',b'Upgrading to 1.0.0 version in generated code. Since soon its gonna be available in nuget.org.'
439366996,3643,"b""[AutoML] InferColumns API that consumes label column index -- only rename label column to 'Label' for headerless files""",b''
439365958,3642,b'[AutoML] step 2 of removing pinned nupkg versions',b''
439364696,3641,b'[AutoML] Early stopping in CLI based on the exploration time',b'Also fixes https://github.com/dotnet/machinelearning-automl/issues/253'
439358491,3640,b'[AutoML] set exploration time default in CLI to half hour',b''
439349272,3639,b'[AutoML] undo pinning ML.NET dependency',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
439208542,3637,b'Update ML.NET version in Extensions.ML',b'Reference the latest ML.NET.'
439192572,3636,b'Merge release into integration',b'Merging `release/1.0` into `features/IntegrationPackage`. This will allow for the Extensions.ML package to be published to myget.\r\n\r\n'
439050299,3635,b'Latex fixes',b'Fixing scoring function documentation for:\r\n\r\n- FieldAwareFactorizationMachineTrainer\r\n- KMeansTrainer\r\n- LbfgsMaximumEntropyMulticlassTrainer\r\n\r\n'
439049118,3634,b'[AutoML] Rename classes in generated project.',b'@asthana86 @CESARDELATORRE @rustd  Have requested this change for //Build.\r\n\r\nSampleObservation -> ModelInput\r\nSamplePrediction -> ModelOutput\r\n\r\nI have changed the classes and internals to reflect this.\r\n\r\n@justinormont  Could you update your CLI once this PR is merged and continue to work with that version. \r\n\r\ncc: @rjoshi @vinodshanbhag '
439036383,3633,b'[AutoML] use Name instead of FullName for telemetry filename hash',"b'minor nit fix, better get it in now'"
439027269,3632,b'[AutoML] Trim the values of column names provided in --ignore-columns in CLI',b'Trim spaces for the values provided to --ignore-columns through CLI'
438998342,3629,b'Adding the CommonPackage.props file to FastTree.',b'The FastTree NuGet package is currently broken on .NET Framework when using packages.config because we are not copying the native files to the output folder.\r\n\r\nFix #3626\r\n\r\nCherry pick #3628 to `release/1.0`.\r\n\r\n'
438995772,3628,b'Adding the CommonPackage.props file to FastTree.',b'The FastTree NuGet package is currently broken on .NET Framework when using packages.config because we are not copying the native files to the output folder.\r\n\r\nFix #3626\r\n'
438987945,3625,b'Download images only when not present on disk and print warning messages when converting unsupported pixel format.',b'fixes #3631\r\nfixes #3638\r\n'
438975403,3624,b'[AutoML] Handling label column names which have space and exception logging',b'* Handling case where label name has spaces.\r\n* Logging unhandled exceptions to debug log.'
438974607,3623,b'API Compat tool in ML.NET',"b'Fixes #3602.\r\n\r\nWe need to ensure that future changes to ML.NET will not break the stable API released in 1.0.0.\r\n\r\nThis PR introduces the [API Compat](https://github.com/dotnet/arcade/tree/e5c20e707876cb9596d1cbcc996f80c25698fdfe/src/Microsoft.DotNet.ApiCompat) tool from dotnet/Arcade. The API Compat tool runs as part of the build process and compares the assemblies with those found in the stable nugets referenced in the `Microsoft.ML.StableAPI` project.\r\n\r\nThe tool is only run for the assemblies which will be part of the stable nugets. Here is a list of those assemblies and the relative nugets:\r\n\r\n| Stable Nuget | Stable Assemblies|\r\n|--|--|\r\n|Microsoft.ML| Microsoft.ML.Core, Microsoft.ML.Data, Microsoft.ML.KMeansClustering, Microsoft.ML.PCA, Microsoft.ML.StandardTrainers, MIcrosoft.ML.Transforms, Microsoft.ML.Analyzer|\r\n|Microsoft.ML.DataView|  Microsoft.ML.DataView|\r\n|Microsoft.ML.CpuMath |  Microsoft.ML.CpuMath|\r\n|Microsoft.ML.FastTree |  Microsoft.ML.FastTree|\r\n|Microsoft.ML.LightGbm |  Microsoft.ML.LightGbm|\r\n|Microsoft.ML.ImageAnalytics |  Microsoft.ML.ImageAnalytics|\r\n|Microsoft.ML.MklComponents |  Microsoft.ML.Mkl.Components|\r\n\r\nNote: the tool does not run on Microsoft.ML.Analyzer as it does not have a public API, so no need to check backwards compatibility.\r\n\r\nStill to do:\r\n- [x] Fix possible bug in API Compat on handling of Attributes.\r\n- [x] ~~Add a build setting to disable the API Compat tool from command line. This will allow people to work on breaking changes.~~ Not needed see comments below.\r\n- [x] Update the version of the ML.NET nugets to 1.0.0 when available\r\n\r\n'"
438972888,3622,b'[AutoML] Handling label column names which have space and exception logging',b'* Handling where label name has spaces.\r\n* Logging unhandled exceptions to debug log. \r\n\r\n'
438893064,3621,b'Updates release with latest changes from master',b'This PR takes the final updates from master and updates the release branch.\r\n\r\n*No Squash*'
438631885,3620,b'[AutoML]  return null instead of null ref crash on Model property accessor',b''
438553456,3619,b'[AutoML] param name change in learners in CLI',b'Recently there has been a change in param name for few learners in ML.NET \r\noptmization --> optimization . Accommodating the change in generated project.'
438514897,3618,b'[AutoML] Fix error handling in CLI. ',b'Looks like there are lost exceptions in CLI due to spawning threads and the reason for doing that is Progress Bar in CLI.\r\n\r\nThings to try in future:\r\n*  Use tasks. (Which has already been tried and had side effects in progress bar animation)\r\n* Get rid of Progress bar code from CLI\r\n\r\nI personally like to remove Progress bar code from CLI and use some existing nuget package in open source community.\r\n\r\nWe are bringing in some new set of problems because of the GUI work in CLI which seems to be a whole new project.\r\n\r\n'
438474170,3617,b'[AutoML] turn off line pragmas in .tt files to play nice with signing',b''
438460678,3616,"b'[AutoML] force a specific ml.net nuget version, fix typo'",b''
438008060,3614,b'Added new configurations and updates Jobnames',b'Changing the job names caused the links on readme page to fail. This updates those links and adds new configuration that we added for fullframework like testing it on ubuntu and full framework'
437993764,3613,"b'Fixed typo of word ""defined""'","b'Updated AucAggregator.cs ComputeWeightedAuc method to fix spelling issue of ""defined"" in message text.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There\'s a descriptive title that will make sense to other developers some time from now. \r\n- [x] There\'s associated issues. All PR\'s should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n'"
437895556,3612,b'Resize image transformer cannot handle images with unknown pixel format.',b'fixes #3611'
437893365,3610,b'[AutoML] take dependency on a specific ml.net version',b''
437890296,3609,b'[AutoML] rename Auto to AutoML in namespace and nuget',"b'sorry for messy commit history, keep forgetting to catch my fork up'"
437867495,3608,b'Cherrypicks into release branch',b'This adds release notes and hotfix for ImageLoader into Release branch'
437814105,3607,b'Disable building NuGet packages other than Microsoft.Extensions.ML.',b'Note this is only for the `features/IntegrationPackage` branch.'
437799119,3606,b'[AutoML]mlnet CLI nupkg creation/signing',b'also cleaned up build yml a bit'
437771734,3605,b'Adds release notes for 1.0',b'Adding release notes for `1.0.0`'
437457843,3601,b'Handle Indexed Pixel Format correctly in Image Resize transform.',b'fixes #3600\r\n'
437447208,3599,b'[AutoML] InferColumns API: Validate all columns specified in column info exist in inferred data view',b'Closes https://github.com/dotnet/machinelearning-automl/issues/348'
437446991,3598,b'[AutoML] InferColumns API: Validate all columns specified in column info exist in inferred data view',b''
437435111,3597,b'[AutoML] AutoML SDK API: validate schema types of input IDataView',b''
437430325,3595,b'Refactoring clustering catalog samples line width to 85',b'Towards #3478.'
437428668,3594,b'Clean SamplesUtils',"b""This PR cleans SampleUtils a bit. Toward #3584.\r\n\r\n- If a function/class is used only in less than two places, we copy them wherever it's used.\r\n- Function/class referenced by nothing is removed.\r\n\r\nCurrently, we can't not remove SamplesUtils entirely because some samples are still using it.\r\n"""
437423840,3593,"b""[AutoML] PipelineSuggester: don't recommend pipelines from first-stage trainers that failed""",b'Closes https://github.com/dotnet/machinelearning-automl/issues/311'
437423544,3592,"b""[AutoML] PipelineSuggester: don't recommend pipelines from first-stage trainers that failed""",b'Closes https://github.com/dotnet/machinelearning-automl/issues/311'
437419183,3591,"b'[AutoML] If first three iterations all fail, short-circuit AutoML experiment'",b'Closes https://github.com/dotnet/machinelearning-automl/issues/341'
437418780,3590,"b'[AutoML] If first three iterations all fail, short-circuit AutoML experiment'",b''
437415497,3588,b'Reformat categorical transform samples.',b'towards #3478\r\n\r\n'
437380363,3586,b'L1-norm and L2-norm regularization doc',b'Fix #3356.\r\n'
437323910,3585,b'Updates release with latest changes from master',b'This PR takes the documentation updates from master and updates the release branch.\r\n\r\n*No Squash*'
437315060,3583,b'Add the correct name to the InitializationAlgorithm enum',"b'The name Yinyang actually refers to the implementation of the algorithm itself, not the initialization of the clusters. The algorithm for cluster initialization either random, kmeans++ or kmeans||\r\n(see the links in the trainer documentation [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.KMeansClustering/KMeansPlusPlusTrainer.cs#L48-L57)).'"
437069538,3581,b'Updates release with latest changes from master',"b""This PR takes the documentation updates from master and updates the release branch.\r\n\r\n~~Don't merge until we finalize a decision on #3558 issue.~~\r\n\r\n*No Squash*"""
437024704,3580,b'Adding the confusion matrix to binary samples.',b'Same change as #3574 because the later is refusing to kick a CI build. Closes #3573 \r\n'
436995228,3579,b'Fix runtime exceptions in samples.',b'Fixes runtime exceptions in samples introduced by PR #3539 \r\n\r\n'
436990561,3578,b'Confusion matrix for multiclass samples',b'Together with #3574 fixes #3573.'
436972276,3577,b'Reference to See Also section for example of usage in all estimators',b'FIxes #3485.\r\n'
436972065,3576,b'Fix broken XREF in XML documentation.',b'\r\n'
436968997,3575,b'Add samples for linear SVM in XML documentation.',b'towards #3527\r\n'
436940782,3574,b'Updating the binary samples to print the confusion matrix together wi\xe2\x80\xa6',b'Addresses part of #3573 adding the confusion matrix to some samples. \r\n\r\n'
436916124,3572,b'Fix incorrect link in ComputeLogisticRegressionStandardDeviation class documentation',b'fixes #3479\r\n'
436911289,3571,b'Fix time series XML again',b'This PR address missed comments in #3546.\r\n'
436898786,3570,b'Text catalog fixes',b'Copy of https://github.com/dotnet/machinelearning/pull/3552\r\n\r\nFixes the typos documented in #3491\r\nChanges ngram -> n-gram\r\n\r\nCreated by me because previous PR got stuck in builds.\r\n'
436898429,3569,b'Improve initialization algorithm documentation for kmeans',b'Fixes #3495.'
436897369,3568,b'Improve SdcaLogisticRegressionBinaryTrainer documentation.',b'fixes  #3501'
436893144,3567,b'[AutoML] Generated project - FastTree nuget package inclusion dynamically',b'Include FastTree package dynamically based on the trainer\r\n\r\nAlso changed the telemetry message to have correct tool name.'
436891374,3566,b'Improve summary for linear model parameters.',b'fixes #3508\r\n'
436873785,3565,b'Towards #3527',b'Addresses the typos documented on #3527\r\n'
436837454,3564,b'Publish nugets to temporary myget feed (#3400)',b'Re-enable myget feed.'
436784930,3563,b'Avoid using hidden classes defined in SampleUtils',b'Fix #3486.\r\n\r\n'
436457978,3561,b'Samples width: they need to be formatted at 85 characters or less.',b'fixes #3478'
436447706,3560,b'Documentation for loss functions',b'Fixes #3480 '
436441157,3559,b'Standardize Key Type annotation.',"b'When referencing key types, use `[Key](xref:Microsoft.ML.Data.KeyDataViewType) type`.\r\n\r\nfixes #3529'"
436434354,3558,b'simplifying and improving the examples',b'Towards #3509: simplifying and adding more description to the FilterRows samples. \r\n\r\n'
436423616,3557,b'Fix broken xrefs across code base.',b'towards #3474\r\n'
436414046,3555,b'Doc fixes for FeatureContributionCalculatingEstimator',b'Fixes #3489 \r\n\r\n- Added link to `FeatureContributionCalculatingTransformer`\r\n- Clarified one of the APIs is for calibrated models\r\n- Added xref links to supported models. \r\n\r\n'
436408102,3554,b'[AutoML] Change the conflicting alias for the command line option',"b'looks like -h is already taken by command line api\'s ""help"" option. So changing header alias to -H instead of -h.'"
436403062,3553,b'Renaming CI legs',b'The previous pr was alwayus using the mac machines with missing dependencies so just creating a new pr to avoid those failures.\r\n\r\n\r\n@eerhardt is it fine to run centos just with netcoreapp3.0 and ubuntu with netcoreapp2.1 ?'
436395347,3552,b'Text catalog fixes',b'Fixes the typos documented in #3491\r\nChanges ngram -> n-gram\r\n\r\n'
436395145,3551,"b""Fix AP's output schema in its XML doc""","b""Fix #3498 and fix #3496 by\r\n\r\n- Add a new I/O file for binary classifier without probability output\r\n- Reference that new file in AP's and LinearSVM's XML docs.\r\n"""
436392076,3550,b'[One Line Change] Fix Kmeans Options Link',"b""Fix #3492 by replacing xref with cref in Kmean's Options. Other places have been fixed by someone.\r\n\r\n"""
436386012,3549,b'Normalization required for Randomized PCA',b'Fixes #3475 '
436373722,3548,b'Fix feature selection catalog XML documentaion',b'Fixes #3547.\r\n\r\n'
436372892,3546,b'Fix Time Series XML Doc',b'Fix #3517 by\r\n\r\n1.  Change Trainer Template to Transformer Template\r\n2.  Decompose scoring paragraph into two files so that Spike Detection and Change Point Detection can reference files independently.\r\n3.  Some minor polishment.\r\n\r\n'
436372694,3545,b'Fix the ApproximatedKernelMappingEstimator XML doc',b'Fixes #3544.\r\n'
436371365,3543,b'Fix Dnn image featurizer and Onnx XML documentation',b'Fixes #3542.'
436369804,3541,b'Fix GcNorm and LpNorm xml doc',b'Fixes #3540\r\nFixes #3502 \r\n'
436359436,3539,b'Cumulative bug bash fixes',b'Fixes #3476 \r\nFixes #3470 \r\nFixes #3487\r\nFixes #3467'
436356628,3538,b'Add bias to documentation of linear classifiers',b'Fixes #3505 .\r\nAlso converts \\boldsymbol to \\textbf in the multiclass linear classifiers.\r\nAlso fixes #3471 .'
436353737,3537,b'TensorFlow fixes',"b'Closing #3481 by rearranging where the explanation lives for the TensorFlow transfomer/estimator, and fixing the links. \r\n\r\n'"
436351053,3536,b'fix doc for the KeyToBinaryVectorMappingEstimator',b'Fixes #3472 \r\n\r\n- Added `Estimator Characteristics` to the `KeyToVectorMappingEstimator` class\r\n\r\n'
436350738,3535,b'Fix FieldAwareFactorizationMachineBinaryTrainer documentation',b'Fixes #3490 .'
436336448,3534,"b""Polish some options' XML document strings""","b""Fix #3507.\r\n\r\nNote that some options don't have API references because they are not used to create trainers. For example, we cannot create SdcaMulticlassTrainerBase because it's a base class."""
436331433,3533,b'Fix some SDCA documentation issues',"b'Fixes #3519, #3513, #3503, #3477.'"
436327175,3532,b'Update to Preview5 of .NET Core 3.0',b'Updating to the latest release version of .NET Core 3.0.\r\n\r\n'
436321252,3530,b'Indicating in which package transforms belong.',b'Towards #3481. The Onnx package transforms were lacking this information. '
436309742,3528,"b""Fixed the documentation issue for 'OneHotHashEncoding' method.""",b'This PR fixes #3506\r\n\r\n'
436141980,3526,b'Fix Issue 3508 - Correct the comment for LinearModelParameterStatistics class',"b""Fixes #3508 \r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
435943833,3525,b'Correct additional nuget required information in LightGBM XML doc.',b'fixes #3468\r\n\r\n'
435943234,3524,b'Word Options missing in link to constructor with options.',b'fixes #3469\r\n\r\n'
435942908,3523,b'Predicted label needs to be of Key Type.',b'fixes #3465\r\n'
435942237,3522,b'Fix samples link in XML documentation.',b'towards #3474'
435937754,3521,b'[One line change] Replace a xref with cref in XML',b'Fix #3511.\r\n\r\n'
435934976,3520,b'Kmean doc minor fixes',"b'Fix #3473, fix #3514, and fix #3494.\r\n\r\n'"
435920338,3516,"b'Bugbash: OVA, Pairwise Coupling, NaiveBayes, and ModelParameters'","b'Fixes #3518 , fixes #3512 , fixes #3515, fixes #3510.'"
435882630,3504,b'[AUTOML] fixed path bug and regression metrics correction',b'Fix the model path bug in generated project:\r\n- When run through dotnet cli the execution context seems to be different and the project is not able to find the model.zip.\r\n\r\nFix the metric in generated project for regression:\r\n- RMS is reported wrong.\r\n@justinormont  already has a PR for this but his PR seems to have test failures so I have included his changes in here. #3459 \r\n\r\ncloses #3459 '
435879724,3500,b'Updates the language used for see also section reference in documenta\xe2\x80\xa6',b'Fixes #3499 \r\n`See the See Also section` is changed to `Check the See Also section`.'
435870901,3497,b'[Fix Latex Code] Use textbr for vectors',"b'`boldsymbol` is ams package, which is not included in the official latex. This PR replaces `boldsymbol` with `textbf`. Hopefully, this can fix the latex rendering of my docs.\r\n\r\n'"
435842629,3484,b'[AutoML] API docs for automl experiment',b'Fixing API docs for automl experiment\r\n'
435816789,3466,"b'Revert ""Publish nugets to temporary myget feed (#3400)""'",b'This reverts commit 0a90bbb49da69765c2ff870078fdabfb20783a58.\r\n'
435809101,3464,b'Disable myget publishing step',b''
435761339,3461,b'Fix referenced filename in XML',b''
435635380,3459,b'[AutoML] CLI CodeGen printing L1 instead of RMS',"b""CodeGen was printing the L1 Error in the RMS field.\r\n\r\n```md\r\n=============== Cross-validating to get model's accuracy metrics ===============\r\n*************************************************************************************************************\r\n*       Metrics for Regression model      \r\n*------------------------------------------------------------------------------------------------------------\r\n*       Average L1 Loss:    298.351 \r\n*       Average L2 Loss:    186688.889  \r\n*       Average RMS:          298.351  \r\n*       Average Loss Function: 186688.889  \r\n*       Average R-squared: 0.687  \r\n*************************************************************************************************************\r\n=============== Training  model ===============\r\n=============== End of training process ===============\r\n=============== Saving the model  ===============\r\nThe model is saved to /private/tmp/blah/openfoodfactsIngredientsToCalories/openfoodfactsIngredientsToCalories.ConsoleApp/bin/Release/netcoreapp2.1/../../../../OpenfoodfactsIngredientsToCalories.Model/MLModel.zip\r\n```\r\nNotice the `298.351` twice.\r\n"""
435630435,3458,b'[AutoML] Add AutoML example code',b''
435611304,3457,b'Updating release with latest changes from master',b'Taking all the changes from master to update 1.0 release branch'
435588722,3456,b'XML documentation for DNN Image Featurizer Transfomer.',b'towards #3204 .\r\n'
435563135,3455,"b'XML docs for Permutation feature importance for Binary, Multi-class and Ranking trainers.'",b'towards  #3204'
435554113,3454,b'XML doc for LpNormalizingEstimator and GlobalContrastNormalizingEstimator',b'Tracked by #3204 .\r\n\r\nThis PR adds xml doc for `LpNormalizingEstimator` and `GlobalContrastNormalizingEstimator`.'
435544034,3453,b'Replace documentation with link',b''
435542999,3452,b'Delete xml doc files.',b'Now that all the documentation has been moved from XML doc files to MD files and are no longer referenced in the code so we should delete these referenced files.\r\n\r\n'
435522400,3451,b'XML for MLContext.Model (root)',b'Most APIs have been covered by Tom already. Just added the one missing one.'
435478398,3449,b'Adding code of conduct definition',b'This is the adopted code of conduct similar to [CoreFX](https://github.com/dotnet/corefx/blob/master/CODE_OF_CONDUCT.md)'
435474877,3448,b'Changing the format of the formula to LaTeX',b'Thanks @wschin for the correction and re-writting the formula in LaTeX\r\n\r\n'
435451814,3447,b'Input Output column md file for regression and ranking.',b'#2522\r\n\r\n'
435432317,3446,b'Refine descriptions of Microsoft.ML classes',b'Update summary description of all Microsoft.ML classes.\r\n'
435334780,3445,b'fixed typo',b'\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n'
435322192,3444,b'XML documentation for Time Series',b'Toward #3204 for time series.\r\n\r\n'
435301296,3442,b'Lda snapping to template',b'towards #3204. LDA\r\n'
435297056,3441,b'Add back Trainer Characteristics table.',b'\r\n'
435283764,3440,b'Update documentation for WordBag',b'towards #3204 '
435253914,3438,b'snapping featurizeText to the template',b'Towards #3204. Snapping featurizeText to the template\r\n\r\n'
435073342,3435,b'Normalizer multicolumn example',b'Adding a sample for the bin normalizer multicolumn extenion. \r\n\r\n'
435060185,3434,b'Cherry-picking - fixing the link (#3406)',b'Cherry-picking #3406 \r\n\r\n'
435036286,3433,b'Documentation for Multiclass SDCA',b'Toward #2522.\r\n\r\n'
435016803,3432,b'XML documentation for Normalizer',b'Tracked in #3204'
435015347,3431,b'XML documentation for LightGBM Ranking trainer.',b'towards #2522\r\n\r\n'
435014167,3430,b'XML documentation for FastTree Ranking trainer.',b'towards #2522\r\n\r\n'
435013075,3429,b'XML documentation for Randomized PCA trainer.',b'towards #2522\r\n\r\n'
435012954,3428,b'XML documentation for transforms',b'Tracked by #3204.\r\n\r\nThis PR adds xml documentation for:\r\n- Concatenate\r\n- Custom mapping\r\n- Drop columns\r\n- Select columns\r\n'
435010969,3427,b'XML documentation for LightGBM multi-class trainer.',b'towards #2522\r\n\r\n'
435009190,3426,b'XML documentation for Prior trainer.',b'towards #2522\r\n\r\n'
435007826,3425,b'XML documentation for GAM binary classifier trainer.',b'towards #2522\r\n\r\n'
435007108,3424,b'Towards #3204 -FeatureSelection',b'Adhering to the #3204 template for the FeatureSelection estimator and transformer. \r\n'
435006814,3423,b'[AutoML] fix vsts build',b' disable steps but keep phases to keep vsts build pipeline happy'
435002121,3422,b'XML documentation for Online Gradient Descent trainer.',b'towards #2522\r\n\r\n'
434998815,3421,b'XML documentation for GAM regression trainer.',b'towards #2522\r\n\r\n'
434993629,3420,b'[AutoML] temporarily disable all but x64 platforms',"b""don't want to do native builds and no way around that with the current VSTS pipeline\r\n\r\n"""
434993030,3419,b'Update xml documentation for ProduceHashedNgrams',b'towards #3204 '
434989214,3418,b'XML documentation for five text related transforms',b'Tracked by #3204.\r\n\r\nThis PR covers:\r\n\r\n- TokenizeCharacters\r\n- NormalizeText \r\n- ExtractWordEmbeddings \r\n- TokenizeWords \r\n- ProduceNgrams\r\n\r\n\r\n'
434988512,3417,b'Towards #3204 - XML Documentation for MLContext.Data transforms',b'Towards #3204\r\n\r\nTransforms covered:\r\n- LoadFromEnumerable\r\n- CreateEnumerable\r\n- BootstrapSample\r\n- Cache\r\n- FilterRowsByColumn\r\n- FilterRowsByKeyColumnFraction\r\n\r\n\r\n'
434979203,3416,"b""[AutoML] bump version to 0.3 since that's the one we're going to ship for build""","b""bump version to 0.3 since that's the one we're going to ship for build"""
434977131,3415,b'Add a doc template to SkipTakeFilter',b'Toward #3204.'
434975330,3414,b'XML documentation for FastTree Tweedie trainer.',b'towards #2522\r\n'
434971597,3413,b'Stopwords remover xml documentation',b'towards https://github.com/dotnet/machinelearning/issues/3204'
434966287,3412,b'XML documentation for FastTree regression trainer.',b'towards #2522\r\n\r\n'
434961226,3411,b'XML documentation for FastForest regression trainer.',b'towards #2522\r\n'
434958676,3410,b'XML documentation for LightGBM regression trainer.',b'towards #2522\r\n\r\n'
434951393,3409,b'Matrix Factorization XML docs',b'Toward #2522 following #3218.\r\n\r\n'
434949716,3408,"b'Check for IEstimator/ITransformer schema consistency, fix bugs uncovered'","b'Fixes #3380.\r\n\r\nThe commits are one first commit where I change the test of estimators, and subsequent commits are where I fix each of the bugs in `IEstimator`/`ITransformer` pairs that were revealed through that stricter test.\r\n\r\nNote that that calibrator change (the last commit at the time of writing), and the `KeyToVector`/`KeyToBinaryVector` change (third commit) result in actual changes to the annotation data produced by the transformers, so could be considered behavioral changes. However I do not anticipate a negative effect.\r\n\r\nSome tests were also changed a little bit to give greater coverage.'"
434933582,3406,b'fixing the link format in ColumnCopying',b'Towards #3204. Converting the link for cref format to xref format. \r\n\r\n'
434924450,3405,b'XML documentation for Ordinary Least Squares trainer.',b'towards #2522'
434919103,3404,b'XML documentation for Poisson Regression trainer.',b'towards #2522\r\n\r\n'
434914547,3403,b'XML documentation for SDCA regression trainer.',b'towards #2522\r\n'
434902479,3402,b'Towards #2522 - RandomizedPcaTrainer documentation',"b'Adding documentation for Randomized PCA, as specified in #2252.'"
434886738,3401,b'Towards #2522 - LinearSvmTrainer documentation',"b'Adding documentation for LinearSVM, as specified in #2252.\r\n'"
434880118,3400,b'Publish nugets to temporary myget feed',"b""feed: \r\nhttps://www.myget.org/F/shmoradi-mlnet2/api/v2/package\r\nhttps://www.myget.org/F/shmoradi-mlnet2/api/v3/index.json\r\nit's empty currently\r\n"""
434685049,3399,b'XML documentation for FastForest binary classification.',b'towards #2522\r\n'
434675272,3398,b'XML documentation for FastTree binary classification.',b'towards #2522'
434659930,3397,b'XML documentation for LightGBM binary classification.',b'towards #2522\r\n\r\n'
434620443,3396,b'XML documentation for Symbolic Stochastic Gradient Descent Trainer.',b'towards #2522\r\n\r\n'
434616527,3395,b'XML documentation for Calibrated and Non Calibrated SDCA Binary Trainers.',b'towards #2522\r\n\r\n'
434614699,3394,"b""Towards #3204 - Conversion's catalog""","b'Polishes the documentation for the conversions catalog, adhering to the template in #3204 \r\n\r\nMarking it as not final until I do a second pass at the changes through CodeFlow. \r\n\r\n'"
434597212,3392,b'Xml documentation for Calibrated and Non Calibrated SGD Trainer.',b'towards #2522\r\n'
434547044,3391,b'Fixed xref links in AveragedPerceptron',b''
434544879,3389,b'Add XML to LBFGS Maximum Entropy Classifier',b'Toward #2522 following #3218.\r\n\r\n'
434535772,3388,b'Towards #3204 - Documentation for MLContext.Transforms.Categorical',b'Documentation for Categorical transforms using template given in #3204 and implemented in #3316.'
434525422,3387,"b'Docs 2nd pass for NaiveBayes, KMeans, OVA, Pairwise and OnnxTransformer'",b'part of #2522 '
434487695,3386,b'Update documentation for MissingValues',b'towards #3204 \r\nMissingValues'
434487345,3385,b'Add LR XML doc',b'Toward #2522 following #3218.\r\n'
434469218,3384,b'Towards #3204 - documentation for FeatureContributionCalculatingEstimator',"b'Adhering to the template in #3204 (comment) for the ColumnCopying estimator extensions, estimator, transformer.'"
434452675,3383,b'[AutoML] publish AutoML package',"b'Add build scripts for AutoML nuget, set version to 0.2, disable building ml.net projects and nuget publishing for them.'"
434437020,3379,b'DataOperations: Replace PREVIEW API usage with proper IDataView based Enumerable API.',b'fixes #3350\r\n\r\n'
434426572,3377,b'Towards #3204 - documentation for ApproximatedKernelMappingEstimator',"b'Adhering to the template in #3204 (comment) for the ApproximatedKernelMapping estimator extensions, estimator, transformer.'"
434416383,3376,b'Update xml documentation for Image estimators',b'towards https://github.com/dotnet/machinelearning/issues/3204\r\n'
434397048,3374,b'FFM XML Doc And Add One Missing Sample File',b'Toward #2522 following #3218. \r\n'
434080430,3373,"b'[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies'",b''
434080076,3372,"b'[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies'",b''
434048893,3371,b'[AutoML] Minor changes to generated project in CLI based on feedback',b'\r\n1) Match the filenames with classes\r\n2) Dynamic generation of nuget packages for generated project\r\n3) nit picks in UI '
434047461,3370,b'Increase Native build warning level  to W3 and fix build warnings',"b'Before, we actually only reported W1 warning level during native build.\r\nNow we warn on L3 warnings\r\nFixed three warnings from downcasting variables. In all cases the downcasting was deemed safe and replaced with ```static_cast<>```\r\nNote that all those warnings were deemed required to fix for compliance criteria.\r\nThis tracks #3370 \r\n\r\n'"
434016423,3368,b'Check size before allocation',b'This PR fixes #3361 by incorporating a minor fix from LIBMF.'
434015508,3367,b'Setting metadata back to defaults for Microsoft.ML.DataView',b'Fixes #3366 '
433999149,3364,b'[AutoML] Rev AutoML public API; add required native references to AutoML projects',b''
433998658,3363,b'[AutoML] Rev AutoML public API; add required native references to AutoML projects',b''
433988148,3362,b'Upgrade matrix factorization samples',b'One more step toward #2522.\r\n'
433945439,3359,b'API reference - Fix placeholder links',b'Fixes #2356 with actual links.'
433873254,3357,"b'Cherry-pick #3310: ""API reference - Updated trainer docs for AveragedPerceptron (#3310)""'","b""* Updated trainer docs for AveragedPerceptron\r\n\r\n* Addressed PR comments\r\n\r\n* Updated xref\r\n\r\n* Added more IO details.\r\n\r\n* Updated nuget statement\r\n\r\n* Fixed formula with latex syntax\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
433638773,3355,b'Fix typos in XML comments in TextLoaderSaverCatalog',b'Closes #3354 '
433635389,3353,b'BinaryClassification Calibrators: Replace Preview API with IDataView based getter API.',b'towards #3350'
433611343,3352,b'Add samples for MLContext.Model (root) and add links to documentation.',b'Towards #1209\r\n\r\n'
433596151,3351,b'[AutoML] Add AutoML XML documentation to all public members; migrate AutoML projects & tests into ML.NET solution; AutoML test fixes',b''
433577799,3349,b'ApplyOnnxModel sample',b'part of #1209 '
433577110,3348,b'CherryPicking #3316 - ColumCopying documentation  ',b'Cherry picking #3316 \r\n\r\n\r\n'
433576785,3347,b'ApplyOnnxModel transform',b'part of #1209 '
433532290,3346,b'test.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
433520461,3345,b'SymSGD documentation',b'Documentation for SymSGD towards #2522 '
433502239,3344,b'Cherry pick Projection documentation and Normalize changes to 1.0',b'Documentation for Projection and Normalize transforms.\r\nOriginal PRs https://github.com/dotnet/machinelearning/pull/3232 and #3244'
433497836,3343,b'Cherry Pick TreeEnsembleModelParameters Docs',b'This PR cherry-picks the changes made in #3339 into the release branch.'
433436814,3341,"b'Cherrypick to release: ""Renamed WhatTheFeature and their abbreviations to FeatureContributionScorer.""'",b'\xe2\x80\xa6.  Note that this breaks model backwards compatibility. (#3252)\r\n\r\nCherrypicks PR #3252 and issue #3255  into release branch\r\n\r\n'
433430119,3339,b'Clarify documentation for GetFeatureWeights in TreeEnsembleModelParameters',"b'This PR clarifies the documentation for `GetFeatureWeights()` in `TreeEnsembleModelParameters`. Since `IHaveFeatureWeights` has become `internal`, the `TreeEnsembleModelParameters` are now the only place where this method is visible, and it is unclear from the API what this returns. This PR adds documentation to specify that the ""weights"" returned are the cumulative split gains for all the trees in the ensemble.\r\n\r\nFixes #1850\r\n'"
433410476,3338,b'Samples template for ranking catalog',b'Tracked under #2522.\r\n\r\nThis PR adds samples for `FastTree` ranking.\r\n\r\nThis PR also rewrites the samples for `LightGbm` ranking using a template file which will make it easier to maintain going forward.'
432811281,3333,b'Update release branch',b'This PR updates the 1.0 release branch with changes from Master branch.'
432802417,3331,b'[AutoML] disable netfx build leg for now',b'will re-enable once I figure out the fix for not building/running mlnet test there'
432800688,3330,b'[AutoML] try to fix mlnet tests on netfx',b''
432797870,3329,"b'fix test cases, remove AppInsights ref from AutoML'","b'Need to figure out how to refer to keys, on TODO list -- just fixed the hardcoded values for now'"
432789856,3328,b'Dispose source image object in image transfomers.',b'fixes #3327\r\n'
432789398,3326,b'code migration from machinelearning-automl to machinelearning repo feature branch take 2',"b'Sorry I squash merged on the first try which is not what I want, gotta keep history. Changes here are:\r\n\r\n- Shuffle code to conform to ml.net folder structure\r\n- Add automl and automl test components to build\r\n- Fix issues so it builds\r\n\r\nNote this does NOT include running tests or publishing nuget packages, that will come in as a separate PR'"
432788696,3325,b'code migration from machinelearning-automl to machinelearning repo feature branch take 2',"b'Shuffle code to conform to ml.net folder structure\r\nAdd automl and automl test components to build\r\nFix issues so it builds\r\nNote this does NOT include running tests or publishing nuget packages, that will come in as a separate PR'"
432783704,3324,b'code migration from machinelearning-automl to machinelearning repo feature branch',"b'- Shuffle code to conform to ml.net folder structure\r\n- Add automl and automl test components to build\r\n- Fix issues so it builds\r\n\r\nNote this does NOT include running tests or publishing nuget packages, that will come in as a separate PR'"
432780856,3322,b'Multiclass Classification Samples Update',b'Tracked under #2522 \r\n\r\nThis PR adds samples for `LbfgsMaximumEntropy` and `SdcaNonCalibrated` trainers.\r\n\r\nThis PR also removes dependency from Samples Utils in other multiclass classification samples and adds .tt files for all multiclass classification samples.\r\n\r\nNotice that this PR does not take care of Naive Bayes as it is in progress in #3246.'
432778196,3321,b'Cherry-pick GAM samples',b'This PR cherry-picks the GAM samples into the Release branch.'
432773511,3319,b'Upgrade all regressors to use TT',b'Part of #2522.\r\n'
432764068,3318,b'Remove debugging code from a Gam Sample',b'PR #3281 was checked in with a few debugging comments. This PR removes them.'
432750685,3317,b'Samples second pass for Clustering Trainer',b'Tracked in #2522.\r\n\r\nThis PR removes the dependency on SampleUtils for clustering trainers samples (KMeans samples).\r\n'
432724776,3316,b'Towards #3204 - ColumCopying documentation ',"b'Adhering to the template in https://github.com/dotnet/machinelearning/issues/3204#issuecomment-481772172 for the ColumnCopying estimator extensions, estimator, transformer. '"
432700922,3315,b'Tom cherry pick',"b'Cherry pick of some of my commits into release/1.0.  Which PRs they correspond to is obvious from the commit descriptions. Only one, the last one, required conflict resolution. I have verified the sample introduced still runs.\r\n\r\nNote also that when I run the test locally, the test `EntryPointLinearPredictorSummary` fails. This appears to have nothing to do with my changes, but it is probably something that shiproom should be aware of. @shauheen , @glebuk .'"
432678282,3314,b'Renaming CI legs to make them more readable and understandable',b''
432666779,3313,b'put product version instead of version ',b'Fixes #3132\r\nmaster PR https://github.com/dotnet/machinelearning/pull/3173'
432658784,3312,b'Add samples in TT for FFM',b'Two samples in for FFM  are added following new sample guideline. Related to #2522.\r\n\r\n'
432653938,3311,b'Binary classification samples update',"b'Tracked in #2522.\r\n\r\nIn this PR I use the templates for binary classification samples to eliminate the dependency on the SamplesUtils and make the samples standalone.\r\n\r\nSome binary classification trainers did not have samples, so I added them.\r\n\r\nNote: This PR does not take care of FFM on which @wschin will be working.\r\n\r\n'"
432557784,3310,b'API reference - Updated trainer docs for AveragedPerceptron',b'This PR applies the template discussed #3218 to AveragedPerceptron. It serves as reference PR for updating the rest of the trainers.\r\n\r\nThe following pages are best-effort (90%) recreation of what these changes will look like. Although some changes will only be visible this PR and checked in and preview site is updated.\r\n\r\nExtension methods:\r\n* [Page-1-overload1](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.standardtrainerscatalog.averagedperceptron?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_StandardTrainersCatalog_AveragedPerceptron_Microsoft_ML_BinaryClassificationCatalog_BinaryClassificationTrainers_System_String_System_String_Microsoft_ML_Trainers_IClassificationLoss_System_Single_System_Boolean_System_Single_System_Int32_)\r\n* [Page-1-overload2](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.standardtrainerscatalog.averagedperceptron?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_StandardTrainersCatalog_AveragedPerceptron_Microsoft_ML_BinaryClassificationCatalog_BinaryClassificationTrainers_Microsoft_ML_Trainers_AveragedPerceptronTrainer_Options_)\r\n\r\n[AveragedPerceptronTrainer](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.averagedperceptrontrainer?view=ml-dotnet&branch=smoke-test-preview)\r\n\r\n[AveragedPerceptronTrainer.Options](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.averagedperceptrontrainer.options?view=ml-dotnet&branch=smoke-test-preview)\r\n'
432370007,3309,b'Standalone app to run all samples to catch run time exceptions.',b'fixes #3308\r\n\r\n'
432369035,3307,b'Rewrite image transform samples and dispose images after use.',b'fixes #3306\r\ntowards #3350'
432333390,3305,b'Fix runtime exception in MapKeyToVectorMultiColumn sample',b'fixes #3304\r\n\r\n'
432321036,3303,b'Cherry-pick bug fixes and samples from master to release/1.0',"b'Cherry pick for the below PRs from master branch, most of these PRs are related to samples and none related to API except for #3172 multi-column mapping API for normalizer estimator and #3291 that makes Prior trainer accept only Boolean type label column to make it consistent with every other binary trainer. I also did speak with @shauheen prior to cherry-picking and he agreed ideally these sample fixes should be in the release.\r\n\r\n#3172 \r\n#3215 \r\n#3212 \r\n#3230 \r\n#3237 \r\n#3257 \r\n#3259 \r\n#3249 \r\n#3267 \r\n#3278 \r\n#3213 \r\n#3285 \r\n#3287 \r\n#3291 \r\n#3295 \r\n\r\n\r\n\r\n'"
432312682,3302,b'Simple IDataView implementation sample.',b'Fixes #3301.'
432304276,3300,"b'Cherry pick sample update (Concate, Select, Drop, Copy)'","b'This PR cherry picks the following commits from the master related to Concatenate, Select, Drop and Copy transforms.\r\n\r\n#3262\r\n#3268\r\n\r\n'"
432239512,3298,b'Disable omp and sse in MF',b'\r\n\r\n'
432228197,3297,b'Try buid LIBMF with OpenMP again',b'Add path to `omp.h` and incorporate a minor fix from LIBMF.\r\n'
432208736,3296,b'Update VectorDataViewType documentation.',"b'Fix of PR #3288. Shauheen had a couple comments that I had addressed and committed locally, but did not get pushed successfully to the branch of that PR... sorry about that @shauheen!'"
432178151,3295,b'Fix runtime exception in prior trainer sample and update the comments.',b'fixes #3294'
432173342,3293,b'Cherry-Pick PFI and FCC Samples',b'This PR cherry-picks PFI and FCC Samples into the release branch.'
432170848,3292,b'Add MF fixes to release branch',b'Cherry-pick the following PRs for fixing MF bugs.\r\n\r\n#3297\r\n#3265\r\n#3227\r\n#3210\r\n#3170\r\n\r\nThey are all bug fixes or docs. No API change.'
432148084,3291,b'Prior trainer should accept label column type of boolean ONLY.',b'fixes #3119'
431933525,3289,b'Update Documents Index README.md',"b""Added reference to ML Cookbook, Roadmap, API Reference Doc, Samples and related Infer.NET and NimbusML Repo Docs\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
431833771,3288,"b'Update IDataView principles, type system documentation.'",b'Towards #3095.'
431789619,3287,b'Fix runtime exception in MapKeyToVector sample.',b'fixes #3286'
431781531,3285,b'Update tt files to have Microsoft.ML prefix for SampleUtils.',b'fixes #3284'
431758292,3282,b'Add a sample for one class matrix factorization',b'Fix #1769.\r\n\r\n'
431754394,3281,b'Extend Gam Samples',b'This PR extends the current GAM samples for regression and adds them for Binary Classification.\r\n\r\nFixes #3280 '
431735631,3278,b'Remove Console.Readline at the end of the samples.',"b'fixes #3279\r\n\r\nThere are two samples that have ReadLine() in the end, presumably to prevent the window from closing but this is not needed because VS prevents the window from closing and also this pattern is inconsistent from rest of the samples.\r\n'"
431639392,3275,"b'Samples for CustomMapping, IndicateMissingValues, ReplaceMissingValues'",b'Cherry pick of #3216.\r\n\r\nNote that this PR removes the strong naming of the samples assembly. I have discussed this offline with @eerhardt. \r\n\r\nhttps://github.com/dotnet/machinelearning/pull/3216#discussion_r273732201'
431244182,3268,"b' Updated CopyColumns, DropColumns and SelectColumns samples.'",b'Related to #1209.\r\n'
431225574,3267,b'Remove Microsoft.ML prefix from namespaces in samples binary.',b'fixes #3266\r\nfixes #3205'
431221151,3265,b'Ensable the uses of SSE and OpenMP in LIBMF',b'Fix #1408 by compiling LIBMF with SSE and OpenMP.\r\n'
431219234,3264,b'Release cherry picks for Conversions samples and removing gplv2 files ',b'Cherry picking the following PRs:\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/3211\r\nhttps://github.com/dotnet/machinelearning/pull/3187\r\nhttps://github.com/dotnet/machinelearning/pull/3223\r\nhttps://github.com/dotnet/machinelearning/pull/3167'
431205203,3263,b'Add DataView Type Register (supporting loading in-memory image and other in-memory custom types)',"b'Fix #3162 by considering image type in our bridge code. Also fix #3723, fix #3369, fix #3274, fix #445, fix #3460, fix #2121, fix #2495, fix #3784.\r\n\r\n'"
431161794,3262,b'Updated sample for Concatenate API.',b'Related to #1209.\r\n\r\n'
431083732,3259,b'Fix SDCA sample runtime exception.',b'fixes #3258'
431061564,3257,b'Fix LightGBM Ranking sample runtime exception.',b'fixes #3256'
430718769,3253,b'Fixing ONNX test',"b'The test pipeline for consuming an ONNX model would fail due to the Score column being named ""Score0"". The ONNX model will rename the output columns by design, therefore a different class with the ColumnName of ""Score0"" is needed. This fixes the test pipeline to address this issue.\r\n\r\nFixes #2981\r\n'"
430704356,3252,b'Renamed WhatTheFeature and their abbreviations  to FeatureContributionScorer.',"b'### Change: \r\nWe need to rename some outdated component names to fit the term review policy.  Specifically we need to rename all instances of WhatTheFeature to the FutureContributionScorer for it and all abbreviations.  The change cleans up the last instances of old name of this feature.\r\n\r\n### Impact:\r\nNote that this change will break model compatibility for all previous versions of models containing FCC scorer.  \r\n\r\n### Workaround:\r\nThe workaround for legacy models exists.  It requires users to open the model ZIP file and manually rename the binary model file identifier string that contains the FCC model from ""WTF SCBI"" to ""FCC SCBI""'"
430703014,3251,b'[WIP] Matrix factorization transformer',"b""In addition to a scorer, matrix factorization also commonly acts like a featurizer. It can map matrix row/column index to its representation. If we factorize matrix `R` into `P^TQ`, then the row index u's latent representation is defined as the u-th column of P. Similarly, the column index v's latent representation is the v-th column of Q. In addition, this transformer can find columns/rows similar to the given row/column by computing the inner products between row/column and all other columns/rows. The following data structure summarizes this transformer's output schema.\r\n```csharp\r\n        private class LatentVectorAndNeighbors\r\n        {\r\n            [VectorType(2)]\r\n            public float[] ColumnLatentVector { get; set; }\r\n\r\n            [VectorType(2)]\r\n            public float[] RowLatentVector { get; set; }\r\n\r\n            [VectorType(1)]\r\n            [KeyType(_oneClassMatrixRowCount)]\r\n            public uint[] SimilarRows { get; set; }\r\n\r\n            [VectorType(1)]\r\n            [KeyType(_oneClassMatrixColumnCount)]\r\n            public uint[] SImilarColumns { get; set; }\r\n        }\r\n```\r\nThis PR fix partially #1795 because we still need another evaluator.\r\n"""
430701461,3250,b'Exposing the confusion matrix',b'Fixes #2009 by exposing the confusion matrix. '
430685773,3249,b'Fix runtime exception in ImageClassification.',b'fixes #3248\r\n\r\n'
430679199,3247,b'Update Permutation Feature Importance Samples',b'This PR updates the samples for `PermutationFeatureImportance` and adds samples for `MulticlassClassification` and `Ranking` tasks.\r\n\r\nFixes #3242 '
430674219,3246,b'Add NaiveBayes sample & docs',b'repros #3226'
430671588,3245,b'[WIP] NaiveBayes sample added',b''
430662559,3244,b'Normalize documentation',b'towards #1209 '
430652379,3241,b'Update Feature Contribution Calculation Samples',b'This PR cleans up the samples for FCC and creates a new one specifically for calibrated learners.\r\n\r\nFixes #3233 '
430651595,3240,b'Cherry pick for samples (Text)',b'This PR cherry picks the following commits from the master related to text transforms.\r\n\r\n#3120\r\n#3123\r\n#3133\r\n#3142\r\n#3156\r\n#3177\r\n#3183\r\n#3191'
430591991,3237,b'Fix DNN Featurizer sample bug.',b'DNN featurizer sample throws an exception because it cannot find the Resnet ONNX model. This PR fixes it.\r\n\r\nfixes  #3236'
430559469,3232,b'Projection documentation',b'Towards #1209 '
430528584,3230,b'Fix bug in ONNX scorer sample.',b'ONNX scorer transformer sample throws an exception today because it cannot find the model file. This PR fixes that.\r\n\r\nfixes #3231'
429963521,3227,b'Polish marshalling of MF model and MF problem and enable 32-bit tests',b'Fix #1441. Also related to some suggestion made in #3210. \r\n\r\n'
429958745,3225,b'Renaming OptimizationTolerance to fix a spelling error. (#3199)',b'* Renaming OptimizationTolerance in LBFGS to fix a spelling bug.\r\n'
429926823,3223,b'remove unused files.',b'Fixes #502 by removing the unused files with gplv2 license. \r\n'
429883843,3222,b'Refactoring related to namespaces and public input/output classes.',b'This PR is related to #3205.\r\n\r\nIt also makes all the inner input/output classes to private.\r\n\r\n'
429875926,3221,"b'Cherry pick for samples {Image, Categorical, FeatureSelection}'",b'This PR cherry picks the following commits from the master branch\r\n\r\n#3165 \r\n#3179 \r\n#3184 \r\n#3208 \r\n\r\n@shauheen @glebuk \r\n'
429874704,3220,b'Add loadable attribute for LinearMulticlassModelParameters',b'Fixes #3209 \r\nPR towards master https://github.com/dotnet/machinelearning/pull/3217'
429842676,3217,b'Add loadable attribute for LinearMulticlassModelParameters',b'fixes #3209.\r\n'
429839482,3216,"b'Samples for CustomMapping, IndicateMissingValues, ReplaceMissingValues'",b'Related to #1209 \r\nFixes #3117 \r\n\r\nMade samples for the multi-column setting of:\r\n\r\n- `ReplaceMissingValues`\r\n- `IndicateMissingValues`\r\n\r\nI also made a sample to save and load the `CustomMapping` estimator.\r\n'
429658946,3215,b'TimeSeriesStatics naming.',b'fixes #3203'
429656590,3214,b'Fix runtime exception in LDA sample.',b'LDA sample throws an exception because the API changed after the sample was written. This PR fixes the sample and ensures output matches that of comments in the sample.'
429653958,3213,b'Time Series samples for stateful prediction engine.',b'fixes #3277\r\n\r\nSeems like PR #2900 removed the stateful prediction samples as part of refactoring and cleanup. Adding these useful samples back as they are used by customers that want to save time series model to disk and reload the model with up to date state that contains last seen values from prediction phase.'
429641271,3212,b'Rename sample methods to Example',"b'Make our samples follow the convention that method name should be called ""Example"", this PR fixes samples that have any other method name.\r\n'"
429599216,3211,b'Key to binary samples for documentation',b'Towards #1209 \r\nThis adds the last batch of samples for the Conversions catalog.\r\nThe samples are KeyToVector and KeyToBinaryVector\r\n\r\n'
429566389,3210,b'Fix marshalling of bool flags in MF',"b'Fix #3003. The marshalled Boolean size from C# to C should be 1 byte, not 4. Also, the change from LIBMF is for supporting quiet option in new implicit-feedback MF.\r\n'"
429531451,3208,b'Fixing namespace for image samples',b'Towards #3205 \r\n\r\n- fixing the Image samples (which were previously updated via #3165)\r\n\r\n'
429036395,3199,b'Renaming OptimizationTolerance to fix a spelling error.',"b'In the `LbfgsTrainerBase`, the `OptmizationTolerance` option was misspelled.\r\n\r\nFixes #3198'"
429019876,3195,b'Update DataViewRow and DataViewRowCursor implementation documentation.',"b'Towards #3095. The XML documentation for the classes themselves, while it could potentially be improved, is actually mostly correct already, unlike the situation for key-types where some information was wrong.'"
429018234,3194,b'Key type documentation.',"b'Towards #3095, specifically w.r.t. key types.'"
428965681,3191,"b"" Created sample for 'LatentDirichletAllocation' API.""",b'Related to #1209.'
428809129,3189,b'Fix NuGet badge on README to show pre-release',"b'Currently, the badge on the README is still showing `v0.11.0`, and not `v1.0.0-preview`.\r\n\r\nUse the `vpre` URL to show pre-release versions on the badge, as specified by\r\n\r\nhttps://shields.io/category/version\r\n'"
428588549,3187,b'Multi column MapKeyToValue and MapValueToKey',b'Towards #1209 more samples for MapKeyToValue and MapValueToKey\r\n'
428507463,3185,b'Improve saving and loading of TextFeaturizingEstimator',b'Fixes #3128.'
428502357,3184,b'Samples for FeatureSelection transform estimators',b'Towards #1209 \r\n\r\nThe PR makes the following changes\r\n\r\n- Adds sample for the `SelectFeaturesBasedOnCount` transform estimator.\r\n- Adds sample for the `SelectFeaturesBasedOnMutualInformation` transform estimator.\r\n- Delete old sample.\r\n\r\n'
428479112,3183,"b""Created samples for 'ProduceWordBags' and 'ProduceHashedWordBags' API.""",b'Related to #1209.\r\n\r\n'
428474581,3182,b'Fix IncludeBuildNumberInPackageVersion for official builds',"b""When doing an official build and setting a AzDO build variable, the variable turns into an environment variable. When MSBuild props/targets files declare a property, if they don't check if the property is already set, the MSBuild props file will override the environment variable. This causes the AzDO build variable to be ignored.\r\n\r\nAdding a check if the IncludeBuildNumberInPackageVersion property is already set before setting it in Directory.Build.props.\r\n\r\nThis is a cherry-pick of #3181 for the `master` branch.\r\n"""
428473929,3181,b'Fix IncludeBuildNumberInPackageVersion for official builds',"b""When doing an official build and setting a AzDO build variable, the variable turns into an environment variable. When MSBuild props/targets files declare a property, if they don't check if the property is already set, the MSBuild props file will override the environment variable. This causes the AzDO build variable to be ignored.\r\n\r\nAdding a check if the IncludeBuildNumberInPackageVersion property is already set before setting it in Directory.Build.props.\r\n"""
428458616,3180,b'Fix a value-mapping bug',b'This PR fixes #3166.\r\n'
428442476,3179,b'Samples for categorical transform estimators',b'Towards #1209 \r\n\r\nThe PR makes the following changes\r\n\r\n- Adds sample for the `OneHotHashEncoding` transform estimator.\r\n- Updated  sample for the `OneHotEncoding` transform estimator.\r\n\r\n'
428425374,3178,b'Cherry pick release notes into release for RC1',b'Adding release notes for RC1 (#3176)\r\n'
428417671,3177,"b""Created samples for 'ProduceNgrams' and 'ProduceHashedNgrams' APIs.""",b'Related to #1209.'
428400256,3176,b'Adding release notes for RC1',b'Adding release notes for v1.0.0-preview'
428362681,3174,b'Cherry-pick for RC1',b'Cherry picking changes into release for RC1\r\n\r\n*No Squash*'
428360252,3173,b'Put product version with git commit into model.zip/version.txt',b'Fixes #3132 '
428339561,3172,b'Multi-column mapping API for normalizer estimators.',b'fixes #3171'
428325402,3170,"b""Fix matrix factorization trainer's doc based on user feedback""","b""This PR fixes #3169 by\r\n- updating key-typed variable's description in matrix factorization trainer's doc, and\r\n- adding one more reference for alg used.\r\n"""
428045564,3167,b'Conversion catalog samples',b'Towards #1209 \r\nAdding and adjusting samples for the Conversions catalog. \r\n\r\n'
427981700,3165,b'Samples and unit test for image-related  transform estimators',"b'Towards #1209\r\n\r\nThe PR makes the following changes\r\n\r\n- Adds unit test and  sample  for the `ConvertToImage` transform estimator.   \r\n\r\n- Fixes the info presented to the user for the 4 existing image samples   {ConvertToGrayscale, LoadImages, ExtractPixels, ResizeImages}\r\n\r\n'"
427970071,3163,b'Adding initial F# example for docs/samples',b'- Adds initial FSharp example for the docs samples. This is the ApplyCustomWordEmbedding. It is an in-memory example that follows the C# example. \r\n- Adds the Microsoft.ML.Samples.FSharp project to hold the FSharp examples\r\n- Adds the FSharp examples directory structure\r\n- Updates the ApplyWordBedding with an code-fsharp tag so that it will link to the correct sample\r\n\r\nReferences #3100\r\n'
427925136,3159,b'Added OneVersusAll and PairwiseCoupling samples.',b'Part of #2522.\r\nAdds a sample for OneVersusAll classification.\r\nAdds a sample for PairwiseCoupling classification.\r\n'
427905494,3158,b'Update release version to 1.0 for release branch',b'This PR updates the version on the release v1.0 branch'
427897987,3157,b'Temporarily disable myget',b'fixes #2244 yet AGAIN!'
427881915,3156,b' Created samples for TokenizeIntoWords and RemoveStopWords APIs.',b'Related to #1209.\r\n'
427150200,3142,"b""Created sample for 'ApplyWordEmbedding' API.""",b'Related to #1209.'
427121986,3140,b'Updating .tt file due to renaming of LbfgsPoissonRegression.',"b'This PR fixes the issue related to renaming done in #3034. Currently, we are finding a way to forcing people to update the .tt file instead of .cs file generated from .tt.\r\n\r\n\r\n'"
427092619,3136,b'Update VBuffer documentation',"b'Towards #3095, specifically about `VBuffer`s. Changes documentation to reflect the changes made by @eerhardt in his refactoring of #1580.'"
426738717,3135,b'Pass weighting value from ProduceWordBags to WordBagEstimator constru\xe2\x80\xa6',b'Fixes #3134'
426724392,3133,b' Created sample for text normalizing API.',b'Related to #1209.\r\n\r\n'
426226464,3124,"b""Add doc string to explain matrix-vector product's SSE code and a test""","b'CpuMath library is not documented, so I add one for its matrix-vector product. Other functions look easier. A new test based on matrix factorization is also added --- we factorize training matrix into two factor matrices and then use CpuMath to compute their product.\r\n\r\nAlso fix #3130 by changing\r\n```csharp\r\n        private static bool Compat(AlignedArray a)\r\n        {\r\n            Contracts.AssertValue(a);\r\n            Contracts.Assert(a.Size > 0);\r\n            return a.CbAlign == Vector128Alignment;\r\n        }\r\n```\r\nto\r\n```csharp\r\n        private static bool Compat(AlignedArray a)\r\n        {\r\n            Contracts.AssertValue(a);\r\n            Contracts.Assert(a.Size > 0);\r\n            return a.CbAlign % Vector128Alignment == 0;\r\n        }\r\n```\r\n'"
426220814,3123,"b"" Created sample for 'TokenizeIntoCharactersAsKeys' API.""",b'Related to #1209.\r\n'
426199619,3122,b'Fix grammar in exception message.',b'fixes #3107'
426172017,3120,"b""Created samples for 'FeaturizeText' API.""",b'Related to #1209.\r\n\r\n'
426162471,3118,b'Move Normalizer extension method from experimental to stable nuget and remove Normalizer generic APIs',b'fixes #3109\r\nfixes #3161\r\n'
426160408,3116,b'Remove generic normalizer estimator catalog methods.',b'fixes #3161'
426149447,3115,b'Support for CNTK',"b'Hello, what is the reason that there is no support for CNTK? I think it\xc2\xb4s easier to support CNTK instead of tensorflow. \r\n\r\n\r\n'"
426130540,3113,b'Baseline test for MultiClassNaiveBayes.',b'fixes #3112'
426063823,3104,b'Fix missing ExampleWeightColumnName in the advanced Options for some trainers',"b'Fixes #2175 \r\n\r\n- Added `ExampleWeightColumnName` in the advanced `Options` for SDCA trainers {Regression, LogisticRegression, MaximumEntropy}\r\n- Added tests\r\n\r\n'"
425690348,3102,b'Add minor doc strings to some internal functions',b'This PR adds some minor doc strings for devs who want to know more about matrix factorization.\r\n\r\n'
425676566,3101,b'Restore OVA ability to preserve key names on predicted label',b'Fixes #3090.\r\nI found usage of slot names _slightly_ confusing. In same time we have `TrainingLabelValues` which should do the trick.\r\n'
425643573,3099,b'Binary LR samples using T4 templates',b'Related to #2522. The *.cs files are auto-generated. Please review the .tt and .ttinclude files.\r\n'
425259733,3091,b'Bump master to 1.1 and 0.13',b'This PR will update master version to 1.1 for stable projects and 0.13 for preview. (Creating as draft PR until 1.0 branch is created - no merge)'
425158710,3088,b'API to return ColumnPairs for a OneToOneTransformer.',b'fixes #3087'
425143498,3086,b'Updating the ApplyOnnxModel transform to meet the API parameter ordering standards',"b'This PR updates the `ApplyOnnxModel` transform to meet the API standards: Moving to `outputColumnName`, `inputColumnName`, `modelFile`.\r\n\r\nFixes #3082 '"
425140985,3085,b'fixing build warnings.',b'The use of the fields in the Hash sample introduced build warnings. \r\nChanging to properties to avoid warnings. \r\n\r\n'
425139874,3084,b'Fixing API call in LoadImages sample',b'The `LoadImages` sample had the wrong API call. This PR fixes it so that the sample runs correctly.\r\n\r\nFixes #3079 '
425125129,3080,b'Move transform catalog extensions into its own file and class in experimental nuget.',b'Transform catalog extension methods are misplaced in MlContextExtensions.cs file. They need to go in a file of its own.\r\n\r\nfixes #3081'
425075954,3078,b'Internalize LpNorm column options.',"b'Small refinement of the PR #2959. I noticed that a few of the `ColumnOptions` classes, including a base class, were still appearing in the public API. Also hide the `IReadOnlyList<...>` to access it through the columns as we do not want to do that per @Ivanidzo4ka.'"
424467598,3074,b'ITrivialEstimator (Approach 1)',b'\r\n\r\n'
424429246,3073,b'Add ML.DataView to the stable projects.',"b'We missed ML.DataView in the stable projects list.\r\n\r\nI also grouped the stable projects in logical groups, and fixed a few minor clean ups as I was in here.'"
424412275,3071,b'TextLoader throws when type is missing LoadColumnAttribute',b'Fixes #3051.\r\n\r\nEdit: This also fixes #2037.'
424388059,3067,b' Added samples for Poisson and OGD regression',b'Related to #2522 \r\n\r\n'
424386533,3066,b'Multicolumn mapping for some estimators',b'Adding multicolumn mapping for some estimators (as per list by @TomFinley and @glebuk):\r\n\r\n- OneHotEncodingEstimator\r\n- TypeConvertingEstimator\r\n- KeyToVectorMappingEstimator\r\n- ValueToKeyMappingEstimator\r\n- OneHotHashEncodingEstimator\r\n- MissingValueEstimator\r\n- FeatureSelectionCatalog.*\r\n- KeyToValueMappingEstiamtor\r\n\r\nLeaving out:\r\n- TextFeaturizingEstimator (probably requires column specific settings most of the time)\r\n- NoramlizingEstiamtor (in experimental nuget)\r\n\r\n\r\nLet me know if I should add more estimators.\r\n\r\nFixes #3068\r\nRelated to #2884 \r\n\r\n'
423999176,3064,b'Add cancellation checkpoint in ValueToKeyMappingTransfomer.',b'fixes #3069\r\n'
423996084,3062,b'Add Cancellation checkpoint in Normalizer transfomer.',b'fixes #3070'
423988794,3059,"b'Updated xml docs for Poisson, OLS, and OGD regression trainers.'",b'Related to #2522 '
423973690,3058,b'CrossValidationSplit in mlContext.Data',b'Just a QoL change.\r\nfixes https://github.com/dotnet/machinelearning/issues/3049\r\n'
423955410,3056,b'Fix bug in TextLoader',b'Fixes #2996. (This PR replaces #3011).'
423953186,3055,b'Rename ImageType to ImageDataViewType',b'Fixes #3050 \r\n\r\n- Renamed ImageType to ImageDataViewType\r\n\r\n'
423924370,3052,b'Expose advanced options for the NormalizingEstimator ',"b'Fixes  #3047 \r\n\r\n- Introduces 5 APIs required to expose advanced options for each of the normalizing estimators in ML.NET {MinMax, MeanVariance, LogMeanVariance, Binning, SupervisedBinning}\r\n- The APIs are added into the Experimental nuget, till  we finalize a  proper design for #2884 \r\n- Added tests'"
423856597,3046,b'Attempt to fix error messages types',"b""fixes https://github.com/dotnet/machinelearning/issues/3045\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/3037\r\n>Error messages are painful - I4, R4 etc. etc. - most people will not know what these are.\r\n\r\nLet's see is it so easy as I think, or I need to change all baseline"""
423764572,3044,b'Remove model saving/loading inconsistencies',b'Fixes #3025.'
423584919,3042,b'Hash sample',b'Towards #1209\r\n\r\nAdding a sample for the Hash extension.\r\nDisabling the compiler check for whether the members of a class are in use.\r\n\r\n'
423583970,3041,b'Data catalog done',b'Towards #1209 \r\n\r\nAdding a sample for the `Hash` extension. \r\nDisabling the compiler check for whether the members of a class are in use. \r\n\r\n'
423522971,3039,b'Add API to get Precision-Recall Curve data',b'fixes #2645'
423404589,3036,b'Added tests for text featurizer options (Part2).',"b'This PR finally fixes #2967. Test created in this PR are for the following parameters in options class\r\n* WordNgramExtractor\r\n* CharNgramExtractor\r\n* Numeric Feature Normalizer (L1, L2, etc).\r\n\r\nThe intend here is to test that TextFeaturizer is instantiated for every parameter in the options class. Here, we are not testing the internal components of TextFeaturizer.'"
423355075,3035,b'Binary FastTree/Forest samples using T4 templates.',b'Related to #2522. The *.cs files are auto-generated. Please review the .tt and .ttinclude files.'
423338377,3034,b'Better names to calibreated linear classification models',"b'Fix #3016 by renaming `LogisticRegressionBinaryTrainer` to `LbfgsLogisticRegressionTrainer`. Note that for multiclass case, we have `LbfgsMaximumEntropyTrainer`. In addition, as [SDCA (aka dual coordinate descent methods) outperforms L-BFGS](https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf) when training logistic regression models, we should not make L-BFGS looks like the default trainer of logistic regression model.\r\n\r\n**[This link](https://github.com/dotnet/machinelearning/issues/3016#issuecomment-476369026) contains our the conclusion of those new names.**\r\n'"
423030948,3033,b'Refactoring of Options for ImagePixelExtractingEstimator',"b'This PR is an example solution for #2884. Once I receive feedback on this, I will continue with the rest of the transforms.\r\n\r\nThe purpose of this PR is twofold:\r\n\r\n- does the ground work to more easily enable the refactoring of `Options`  in other transforms (commit 1)\r\n    - most of the work is in the file ColumnBindingsBase.cs.\r\n    - made `OneToOneColumn` public, removed empty class\r\n    - renamed `Name` and `Source` to `OutputColumnName` and `InputColumnName`\r\n    - added implicit operators to `OneToOneColumn` to simplify the multicolumn mapping scenario\r\n- refactors the `Options` class for `ImagePixelExtractingEstimator` (commit 2)\r\n    - moved immutable `ColumnOptions` to transformer and renamed `ColumnInfo`\r\n    - moved `Options` and `Column` to estimator\r\n    - refactored extension and constructors\r\n\r\nThe third commit fixes tests and entrypoint catalog.\r\n\r\n\r\nNote that with the combination of the implicit operators on `OneToOneColumn` and the constructor taking `OneToOneColumn` in the `Options` class, it is easier to define the multicolumn mapping scenario where the columns don\'t require column specific settings. For an example of the behavior see the test TestImagePixelExtractOptions in ImagesTests.cs:\r\n\r\n```csharp\r\n// options1 and 2 should be exactly the same.\r\nvar options1 = new ImagePixelExtractingEstimator.Options\r\n{\r\n    ColumnOptions = new[]\r\n    {\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = ""outputColumn1"", InputColumnName = ""inputColumn1"" },\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = ""outputColumn2"", InputColumnName = ""inputColumn2"" },\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = ""outputColumn3"", InputColumnName = ""inputColumn3"" }\r\n    }\r\n};\r\nvar options2 = new ImagePixelExtractingEstimator.Options((""outputColumn1"", ""inputColumn1""), (""outputColumn2"", ""inputColumn2""), (""outputColumn3"", ""inputColumn3""));\r\n// options3 has the same OutputColumnName as the previous two.\r\nvar options3 = new ImagePixelExtractingEstimator.Options(""outputColumn1"", ""outputColumn2"", ""outputColumn3"");\r\n\r\n```\r\n'"
423022848,3032,b'Add cancellation checkpoint in logistic regression.',b'fixes #3031\r\n\r\nPlease read the issue before reviewing this PR.'
423022083,3030,b'Polish train catalog (renaming only)',b'Related to #3029 (for StandardTrainersCatalog.cs) but for TrainCatalog.cs.\r\n\r\n- Rename `topK` to `topPredictionCount`\r\n- Rename `k` to `falsePositiveCount`'
423019489,3029,"b""Polish standard trainers' catalog (Just rename some variables)""","b'To fix #2680, we rename several parameters and improve some doc strings.\r\n\r\n'"
423015452,3028,b'Add cancellation signal checkpoints in FastTree.',b'fixes #3027\r\n\r\nPlease read the issue before reviewing this PR.\r\n'
422997963,3026,b'Add cancellation checkpoints in SDCA.',b'fixes #3024\r\n'
422991070,3023,b'Adds the openmp library to the MklRedist nuget package.',b'Adds the openmp library to the MklRedist nuget package.\r\nFixes #3015\r\n\r\n'
422989138,3022,"b'Move KeyType, VectorType and VBuffer to ML.DataView'","b'Fix #2986 \r\n\r\nEasiest to review commit-by-commit. Major changes:\r\n\r\n1. Moved the types into the ML.DataView assembly.\r\n2. Renamed KeyType and VectorType to have `DataViewType` suffixes.\r\n3. VBufferEditor had an ""internal-only"" option that is now public: `maxValuesCapacity`. This was needed so VBufferUtils could operate effectively. If VBufferUtils needs it, chances are someone else will need it.\r\n4. Removed VectorType\'s constructor that takes a `VectorType template`, and replaced it with a new constructor that takes an `ImmutableArray<int> dims`.'"
422984999,3021,b'Data catalog done',b'Towards #1209 \r\n\r\nAdding a sample for TrainTestSplit. \r\nAdding doc strings for the CreateFromeEnumerable\r\nMinor fixes to xml formatting. '
422984304,3020,b'[WIP] Align with code in LightGBM for Categorical features',"b""Potentially fixes https://github.com/dotnet/machinelearning/issues/1625\r\nHonestly have no idea what I'm doing here, so I would appreciate any feedback.\r\n\r\nNeed tests."""
422951696,3019,b'Rename Save API for DataLoader to SaveDataLoader.',b'towards #2991\r\n'
422949235,3018,b'Rename Save API for DataLoader to SaveDataLoader.',b'towards #2991\r\n\r\n'
422944550,3017,b'[WIP] TT Template for managing samples...',"b'As we are going along with making sample standalone, I have been observing that there is a lot of code duplication in the sample. I am proposing to use tt template for managing our samples.\r\n\r\nThe code in this PR shows how to make a template for samples to reduce the copy-paste of common code as well as minimize the code to review every time someone pushes a sample.\r\n\r\nPlease do not merge this PR. I have already tagged it as WIP.\r\n\r\n'"
422864934,3011,b'Fix bug in TextLoader',b'Fixes #2996.'
422745476,3010,b'Updating the FunctionalTests to clearly explain why they are not strong named signed.',b'See https://github.com/dotnet/machinelearning/pull/2858#discussion_r264738643 for an example of why this is necessary.'
422501891,3008,b'MLContext.Model.Load overloads that take file path instead of stream.',b'fixes #2991\r\n\r\n'
422492087,3006,b'Added tests for text featurizer options (Part1).',b'This PR partially address #2967. See the following list. Further tests will be added in the next PR.\r\n\r\nTest created for following parameters in options class\r\n\r\n* StopWordsRemover\r\n* CaseMode\r\n* KeepDiacritics\r\n* KeepPunctuations\r\n* KeepNumbers\r\n'
422445892,2999,b'Added samples for tree regression trainers.',"b'Related to #2522.\r\n\r\nSamples for tree regression trainers: GAM, FastTree, FastForest, FastTreeTweedie.'"
422216588,2995,b'Clean up the SchemaDefinition class',b'Fixes #2978 .'
422065516,2993,b'Include the save file action (.ZIP file) as part of model.SaveFile().',b'fixes #1689'
422063660,2992,b'Fix spelling: normazlize',b''
422060532,2991,b'Add MLContext.Model.Load overload that takes a file path.',b'fixes #2983\r\n'
422030394,2990,b'Fix FeatureColumnName in the public API',b'Fixes #2975\r\n\r\n- also fixes an incorrect parameter name `featureColumn` parameter in ExplanabilityCatalog.cs'
421742554,2988,b'Load a model by path',b'Updates for #2983.\r\n\r\nOpening as draft for any discussion.'
421741781,2987,b'Move IDataView into Microsoft.ML namespace',"b'Fix #2974\r\n\r\nHere\'s the steps I took:\r\n\r\n1. Rename the folders and files for the `src\\Microsoft.Data.DataView` and `pkg\\Microsoft.Data.DataView` to `Microsoft.ML.DataView`.\r\n2. Rename the namespaces in that assembly:\r\n    - IDataView.cs and DataViewSchema.cs move to the `Microsoft.ML` namespace.\r\n    - Everything else in the assembly move to the `Microsoft.ML.Data` namespace.\r\n3. Find all `using Microsoft.Data.DataView;` lines and delete them.\r\n4. Compile, and fix any build errors to add `using Microsoft.ML.Data;` lines.\r\n5. In the Parquet files, there were some full namespace usages that I removed.\r\n6. Find all ""Microsoft.Data"" in the repo, and change as appropriate (it was only docs). \r\n   - there is only 1 place left - which was there before we made this change\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/87ede9ef39c10b8511fc7f14f97d1250bbd2b951/src/Microsoft.ML.Core/ComponentModel/AssemblyLoadingUtils.cs#L121'"
421727275,2985,b'OutputTokens option in FeaturizeText API',b'Fixes #2957\r\n\r\n- the PR follows the proposal https://github.com/dotnet/machinelearning/issues/2957#issuecomment-473568237 to fix the issue\r\n\r\n'
421724812,2984,b'Add functional tests for ONNX scenarios',"b'As laid out in #2498 , we need scenarios to cover the ONNX functionality we want fully supported in V1.\r\n\r\nScenarios:\r\n- I can take an existing ONNX model and get predictions from it (as both final output and as input to downstream pipelines)\r\n- P1: I can export ML.NET models to ONNX (limited to the existing internal functionality) (In Model Files section, but can be fleshed out a bit better with other ONNX tests)\r\n\r\nFixes #2963'"
421703060,2979,b'In-memory & self-contained sample template.',"b""Related to #2726 I created this in-memory and self-contained sample for FastTree. I'll use the final version from this PR as template for the following samples."""
421634248,2976,b'Make Multiclass Linear Trainers Typed Based on Output Model Types.',"b""Multiclass SDCA can train multi-class SVM but it always outputs multi-class logistic regression model. This is not correct because we should not apply softmax to SVM model.\r\n\r\nTo fix #1100, we got the following working items.\r\n- [x] Clean code.\r\n- [x] Create two multi-class linear models.\r\n- [x] Make multiclass SDCA trainers typed.\r\n- [x] Give the two new model classes better.\r\n\r\nFramework changes:\r\n- LogisticRegressionMulticlassClassificationTrainer (renamed to) ---> LbfgsMaximumEntropyTrainer \r\n- MulticlassLogisticRegressionModelParameters (refactorized to) ---> MaximumEntropyModelParameters (for multi-class LR) and LinearMulticlassModelParametersBase (for uncalibrated cases). The two new classes are also derived from LinearMulticlassModelParametersBase. MulticlassLogisticRegressionModelParameters.\r\n- SdcaMulticlassClassificationTrainer (refactorized to) ---> SdcaMulticlassClassificationTrainer and SdcaNonCalibratedMulticlassClassificationTrainer. These two new classes' are derived from SdcaMulticlassClassificationTrainerBase.\r\n\r\nAPI changes:\r\n- (rename, static API) MulticlassLogisticRegression ---> LbfgsMaximumEntropy\r\n- (rename, dynamic API) LogisticRegression ---> LbfgsMaximumEntropy\r\n- (add, static API) SdcaNonCalibrated for multi-class linear models without calibration.\r\n- (add, dynamic API) SdcaNonCalibrated for multi-class linear models without calibration."""
421308588,2973,b'Cleaning TrainCatalog and RecommenderCatalog',b'Fixes #2972.\r\n\r\nIn this PR I clean `TrainCatalog` (commit 1) and `RecommenderCatalog` (commit 2).\r\nThe other commits are simply the adjustments in the code that need to be done to compile. '
421306728,2971,b'Fixed a rendering issue in the TensorFlow doc.',b'There is a rendering issue with TensorFlow documentation where a link appears as code snippet in the doc at the following link. \r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.tensorflowcatalog?view=ml-dotnet\r\n\r\nThis PR fixes it.\r\n\r\n'
421297095,2970,b'Updated xml docs for tree-based trainers.',"b'Updated XML documentation for tree-based trainers (FastTree, FastForest, GAM, etc). Related to #2522.\r\n\r\nSamples to come in a separate PR.\r\n\r\n'"
421292514,2969,b'Configurable Threshold for binary models',b'fixes #2465'
421289748,2968,b'Fixing ModelParameter discrepancies',"b'Fixes #2938 \r\n\r\n- Fixes to the ~7 odd ModelParameter types which were inconsistent  with the  rest of the ModelParameter types\r\n\r\nCouple of notes: \r\n\r\n1.  PR follows naming convention  used by other ModelParameter types in the codebase\r\n    - {AlgoName}(optional){TypeOfTask}ModelParameters\r\n    - {TypeOfTask} is added  only when needed to distinguish between `Binary` , `Regression` or `Multiclass`\r\n\r\n2. ModelParameter types do not use the word `Classification` in the {TypeOfTask} . PR follows that convention.\r\n\r\nEDIT : MulticlassLogisticRegressionModelParameters is being refactored by separate issue #1100 .  SO not fixing that in this PR'"
421285821,2966,b'Clean FeatureContributionCalculation and PermutationFeatureImportance',b'Fixes #2965.\r\n\r\nIn this PR:\r\n1.  I move and rename the extension `MlContext.Model.Explainability.FeatureContributionCalculation` to `MlContext.Transforms.CalculateFeatureContribution`.\r\n\r\n2. I also remove the `MlContext.Model.Explainability` catalog. \r\n\r\n3. Clean up the `FeatureContributionCalculation` extension\r\n\r\n4. Clean up PFI extensions \r\n'
421284905,2964,b'Remove duplicate NormalizeFeatures from FFM trainer',b'Fixes #2958. There are two flags controlling normalization steps right before and in FFM trainer. We decide to disable the former one because FFM has its own built-in normalization for multiple feature columns and the other normalization only works with a single feature column.'
421284175,2962,"b""Made 'StopWordsRemover' in TextFeaturizer configurable again.""",b'This PR addresses the StopWordsRemover issue in https://github.com/dotnet/machinelearning/issues/838\r\n\r\nThis PR make available two options to remove stop words.\r\n1. PredefinedStopWordsRemover: removes stops words using built in technique in ML.NET.\r\n2. UseCustomStopWordsRemover: User provides the list of stop words to remove. Currently `string[]` is exposed to collect that list.\r\n\r\nNo support is added to load stop words from file. I think if we make No.2 take list as `IEnumerable<string>` instead of `string[]` then user can load list on their own. Let me know if reviewers have any thought.'
421271958,2961,b'Enable MyGet uploads again',b'#2240 required to disable the upload. Seems the issue is fixed now.'
421266301,2960,"b'Checking in the samples generated during bug bash for MissingNa, Repl\xe2\x80\xa6'","b'Towards #1209 \r\n\r\nGathering the work of PR: #2814, #2779 and #2773\r\n'"
421259205,2959,b'Hiding of ColumnOptions',"b'First step towards solving issue #2884.\r\n\r\nThe objective of this PR is to internalize the code that uses `ColumnOptions`. \r\nAll the commits are logically ordered.\r\n\r\n1. Internalization of the extensions using `ColumnOptions`\r\n2. Internalization of the `ColumnOptions` living on the estimators\r\n3. Update the extensions to make all the arguments in the `ColumnOptions` available through the extensions\r\n4. Updated the samples when possible, or moved them to the test folder when they contained `ColumnOptions`\r\n5. Other small changes to make the code compile\r\n'"
421171470,2956,b'Updating OVA tests',b'Fix for OVA #2949  went in without updates to tests. This PR updates the tests to work with the new OVA API.\r\n\r\nFixes: #2955 \r\n'
420945143,2953,b'Micro-accuracy for Multiclass Classification tests',b'Fixes #1268'
420768624,2951,b'Separate nuget packaging into Stable and Experimental',"b'- [x] I added `StableProjects` property in a new `StablePackagesInfo.props` file, which has name of stable projects separated by semicolon.\r\n- [x] I set the strategy for having two separate versions by adding another file next to default `BranchInfo.props`, called `BranchInfo.Stable.props`. The files contain version information. Either of the two would be used depending on whether or not a project is listed in `StableProjects` property.\r\n- [x] I tested the assembly versions and nuget package versions using the diff in this PR.\r\n- [x] The conditions could perhaps be simplified more - needs review\r\n\r\nCurrently `BranchInfo.props` generates `0.12.0-preview` for all projects. The Major/Minor/Patch versions to set for stable projects are specified in `BranchInfo.Stable.props` and have identical values to `BranchInfo.props` until we decide to change them in the near future.\r\n\r\nFixes: #2279 \r\ncc: @eerhardt @TomFinley @Ivanidzo4ka @sfilipi @Anipik \r\n'"
420762734,2950,b'Get rid of public tuples',b'fixes #2881'
420760127,2949,b'Allow only binary classifiers in OVA',b'fixes #2920 '
420753999,2948,b'Updating LightGBM Arguments',"b'This PR moves the LightGBM options from an all-in-one class to individual options for the binary, multiclass, regression and ranker trainers. \r\n- Options code that used to live in LightGbmArguments has moved to LightGbmBaseTrainer. Each trainer now has their own respective options class. \r\n- The booster options have changed a bit to hide the IBoosterFactory interface #2559 \r\n\r\n\r\n'"
420740123,2947,b'FeaturizeText: Add instructions to turn off char- or word-gram generation to the tooltip.',b'Adding a note on how to turn off char-grams and word-grams in `FeaturizeText`.\r\n\r\nFixes #2946 '
420648744,2944,b'Scrub text featurizers',b'Last step of #2832.\r\n'
420640802,2942,b'Sort out seed types',b'fixes #2917'
420408498,2939,b'CpuMath Enhancement: Make bound checking of loops in hardware intrinsics more efficient',b'Fixes #835'
420249334,2937,b'Adding Debugging Scenario tests for V1 APIs',"b'As laid out in #2498 , we need scenarios to cover the Debugging functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can see how my data was read in to verify that I specified the schema correctly\r\n- I can see the output at the end of my pipeline to see which columns are available (score, probability, predicted label)\r\n- I can look at intermediate steps of the pipeline to debug my model.   Example: > I were to have the text ""Help I\'m a bug!"" I should be able to see the steps where it is normalized to ""help i\'m a bug"" then tokenized into [""help"", ""i\'m"", ""a"", ""bug""] then mapped into term numbers [203, 25, 3, 511] then projected into the sparse float vector {3:1, 25:1, 203:1, 511:1}, etc. etc.\r\n- (P1) I can access the information needed for understanding the progress of my training (e.g. number of trees trained so far out of how many)\r\n\r\nFixes #2932 '"
420248988,2936,b'Hide more things in Data assembly',b'Fixes #2926. Fixes #1704.'
420248728,2935,b'Added support for inserting batch dimension in inputs in TensorFlow.',"b""This PR fixes #2778.\r\n\r\nIt is difficult to induce shape of the inputs from the data or model when the model accepts input of any shape but internal operators requires the input in particular shape. This is the problem with the inception model available at the following location.\r\n\r\nhttps://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\r\n\r\nThe model takes input data of any shape. There is a convolution layer just after the input which requires 4-D input. The first dimension for Conv2D operation in TensorFlow is the batch dimension. That's causing failure of samples in #2778. The ML.NET input is [224, 244, 3] while convolution layer in the above model requires [-1, 224, 224, 3]. The ultimate solution to this problem is to have reshape transform #765.\r\n\r\nHowever, it will take time implement. To unblock #2778, the temporary solution implemented here is to add a parameter in options class or other public interfaces called \xe2\x80\x9cAddBatchDimensionInput\xe2\x80\x9d. When user set it to true, batch dimension would be added to the inputs otherwise not. \r\n\r\nNOTE: Once we have the `ReshapeTransform`. This change needs to be reverted.\r\n"""
420199102,2931,b'Train FieldAwareFactorizationMachines without providing arguments',b'This PR adds an extension method for `FieldAwareFactorizationMachines` to allow it to be called without providing any arguments by using the default `Feature` column name as the only `Features` column.\r\n\r\nFixes #2927 '
420160170,2930,b'Fix readme sample',b'revert changes done for #2565 in #2887 . The code snippet is working in 0.11. But this is just a snippet and users should check the samples repo for complete samples.'
420141184,2929,b'Move ONNX Transformer into Microsoft.ML.Transforms.Onnx namespace.',b'towards #2751\r\n\r\n'
420073506,2925,b'handle space in the directory path.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n\r\nfixes https://github.com/dotnet/machinelearning/issues/191"""
419868211,2924,b'Added an extension method for saving statically typed model (#1286)',b'Added an extension method for saving statically typed model\r\nFixes #1286'
419793212,2923,b'Logistic Regression NumberOfIterations to MaximumNumberOfIterations',"b""This PR updates `Logistic Regression` (multiclass, regression aka poisson, and multiclass) to specify the `MaximumNumberOfIterations` instead of `NumberOfIterations` as it's a stopping criterion and not necessarily a tuning parameter.\r\n\r\nI also took a look around the codebase, and this is the last change of this sort that will be needed.\r\n\r\nFixes #2922 """
419766655,2921,b'Adding functional tests for all training scenarios',"b'As laid out in #2498 , we need scenarios to cover the Training functionality we want fully supported in V1.\r\n\r\nScenarios\r\n\r\n- I can provide multiple learners and easily compare evaluation metrics between them.\r\n- I can use an initial predictor to update/train the model for some trainers (e.g. linear learners like averaged perceptron). Specifically, start the weights for the model from the existing weights.  \r\n- Metacomponents smartly restrict their use to compatible components.   Example: ""When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.""\r\n- I can use OVA and easily add any binary classifier to it\r\n\r\nFixes #2906 '"
419764027,2919,b'One name for MulticlassClassification',b'Fixes #2623.\r\n\r\nIn this PR I make sure that the case of `Multiclass` is consistent and rename:\r\n- `MultiClass[...]` to `Multiclass[...]`\r\n\r\nWith PR #2903 this solves #2623.'
419748347,2918,b'Scrub text normalizer',"b'Another step toward #2832. This PR is all about renaming with an internalization of `IReadOnlyCollection`,\r\n```\r\n-        public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n+        internal IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n```\r\n\r\n'"
419727543,2916,b'Polish char- and word-level tokenizers & stopword removers',b'Another sub-task of #2832.\r\n\r\n'
419699070,2915,b'Fixing inconsistency in usage of LossFunction',b'fixes #2174\r\nfixes #2594 \r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856'
419692418,2914,b'updating namespaces ',b'Towards #2751\r\n\r\nMicrosoft.ML.LightGBM -> changes to Microsoft.ML.Trainers.LightGBM\r\nMicrosoft.ML.Transforms.FeatureSelection -> moves to Microsoft.ML.Transforms'
419685093,2913,b'Fixing inconsistency in usage of LossFunction',b'fixes #2174\r\nfixes #2594 \r\n\r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856 '
419659231,2911,b'Exposed ngram extraction options in TextFeaturizer',"b'This PR fixes #2802, fixes #2838 and partially addresses #838,.\r\n\r\n\r\n\r\n'"
419653161,2909,b'Make IServerFactory internal',b'fixes #1973\r\nThis concludes the issue 1973. The only remaining issue of same kind is making ISupportBoosterParameterFactory internal and its addressed by #2559'
419649999,2908,b'Fix links in Entrypoints.md after StandardLearners rename.',b''
419626884,2907,b'TrainTestSplit should be inside MLContext.Data',b'fixes #2337'
419602797,2905,b'TrainTestSplit should be inside MLContext.Data',b'fixes #2337'
419583931,2904,b'Hide some duplicate methods',b'fixes #2897'
419298006,2903,b'Fixing names of trainer estimators',b'Fixes #2762 and #2172\r\n\r\n'
419191841,2902,b'Add sample to get data from a SQL database',"b'Sample to help with #2498.\r\n\r\nThis sample using the Entity Framework in-memory data provider to load and read data that can be used to create an ML.NET model.\r\n\r\nHopefully, this is close to what was in mind for the sample. \xf0\x9f\x98\x84'"
419136723,2901,b'Explainability doc',b'Initial draft to add explainability documentation.\r\n\r\nFix for #2438.'
419042077,2900,b'Time series samples and documentation alignment',b'- [x] All overloads have method and parameter documentation according to XML template table below. \r\n- [x] The returned estimator  and its class hierarchy have documentation according to template table below. \r\n- [x] The corresponding options class and its class hierarchy have documentation \r\n- [x]  All overloaded versions have samples \r\n- [x]  Sample names are <API_method>.cs or <API_method>WithOptions.cs. \r\n- [x]  Sample path mirrors the MLContext path. (e.g. MLContext.Transforms.Categorical.OneHotEncoding goes to Dynamic/Transforms/Categorical/OneHotEncoding.cs \r\n- [x]  Sample is included in the API xml documentation.\r\n'
419017008,2899,b'Create model file V1 scenario tests',"b'As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nThis PR adds tests for the following scenarios:\r\n\r\n* I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n* I can use a model file in a completely different process to make predictions\r\n* I can easily figure out which NuGets (and versions) I need to score an ML.NET model\r\n* I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nFixes #2896 '"
419014212,2898,b'Scrub n-gram hashing and n-gram',b'One step closer to #2832. This PR only polishes NgramHashingTransform.\r\n'
418963554,2894,b'Renaming IterationsToRemember to HistorySize for L-BFGS learners.',b'This PR renames the L-BFGS parameter `IterationsToRemember` to `HistorySize` to be more in line with the common nomenclature. (Previously it was `MemorySize`.)\r\n\r\nFixes #2882 '
418952994,2893,b'WIP: Refactoring of ColumnOptions for ImagePixelExtractor',"b'Related to #2884.\r\n\r\nThe change does the following things:\r\n1. Internalizes the immutable class `ColumnInfos` and moves it to the transformer\r\n2. Exposes the previously named `Column` class and renames it `ColumnOptions`\r\n3. Internalizes entrypoint only fields in `ColumnOptions`, renames those that did not match the public API\r\n4. Refactored the constructor so that it takes the new `ColumnOptions` class\r\n\r\n\r\nThe overall behavior of the Estimator/Transformer API is unchanged (besides the use of the new mutable class).\r\nHowever, this change alters the entrypoints API behavior in the following way.\r\nPast behavior:\r\n- Can set column specific options.\r\n- Can set overall options for all columns\r\n- Can set overall options for some column and column specific options for others. \r\n\r\nAfter this change: \r\n- Can set column specific options.\r\n- Can set overall options for all columns\r\n\r\nI would also like to change the name of the input and output columns (in `SourceNameColumnBase`) to something more appropriate than `Name` and `Source`, but since that will touch a lot of files, I would like some feedback on the approach first. '"
418947219,2892,b'Scrubbing online learners',b'fixes #2614'
418925097,2891,b'Scrub word embedding transform',"b'Toward #2832. This PR only contains renaming and internalizes a function,\r\n```\r\n-        public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n+        private IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n```\r\n\r\n'"
418917603,2890,b'Scrub Latent Dirichlet Allocation Transform (Just Renaming)',b'Toward #2832. This PR handles Latent Dirichlet Allocation.\r\n'
418889778,2889,b'Temporarily disable myget',b'fixes #2244  AGAIN!'
418645228,2888,b'More Normalizer Scrubbing',b'Follow up of #2865 so should fix #2928. Some public APIs were missed.\r\n\r\n'
418578227,2887,b'Update Readme to fix code sample',b'fixes #2565 '
418564732,2886,b'Cleaned LightGBM documentation',"b'LightGBM API, trainers, boosters, and options documentation. Part of #2522.\r\nSource of documentation are:\r\n* https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst\r\n* https://lightgbm.readthedocs.io/en/latest/Parameters.html\r\n* ML.NET source code'"
418545439,2885,b'Main namespace types2445',"b'Towards #2445. \r\n\r\nIn the first commit IHost and related moves to Microsoft.ML.Runtime\r\nIDataFile moves to Microsoft.ML.Data\r\nLoss related functionality moves to Microsoft.ML.Trainers. \r\n\r\nThird commit is making it build. \r\nProcedure:\r\nUse VisualStudio Find/Replace all to replace:\r\n1- `using System;`  -> `using System; using Microsoft.ML.Runtime;`\r\n2- `using Microsoft.Data.DataView;`  -> `using Microsoft.Data.DataView; using Microsoft.ML.Runtime;`\r\n3- `using Microsoft.ML.Data;`  -> `using Microsoft.ML.Data; using Microsoft.ML.Runtime;`\r\n\r\nThinking that the above would touch most cs files. \r\nManually spot fixed the references in the .tt files, and the references to loss related changes, and IDataFile changes. \r\n\r\nI used the [format all files](https://marketplace.visualstudio.com/items?itemName=munyabe.FormatAllFiles) vs extension to order/align/remove dead usings. \r\n\r\nthrough spot-checking I noticed that the tool had converted some variables to readonly, and has remove explicit casts in some points, so i .. reviewed all files of the src folder and reverted those two types of changes. So i kept the using changes for 95% of the files, and some white-space fixes in about 5% of the files. \r\n\r\nAll tests passed locally on windows x64'"
418502584,2883,"b'Specify MaxNumberOfIterations for SDCA, K-Means'","b'This PR updates SDCA and K-Means to specify `MaximumNumberOfIterations` rather than `NumberOfIterations` to make the name more precise. Essentially, for these learners, the maximum number of iterations is a worst-case scenario and a last-resort stopping criteria.\r\n\r\nFixes #2871\r\n'"
418483397,2880,b'Update TreeTrainersCatalog to use standard parameter names',b'This PR updates the `TreeTrainerCatalog` to use standard parameter names (e.g. `numTrees` => `numberOfTrees`).\r\n\r\nFixes #2877 \r\n'
418430258,2878,b'Make array values intended to be immutable IReadOnlyList',"b""Just a bit of relatively minor polish of something revealed during review of the public surface. In a handful of places we were returning arrays as values intended to be immutable. As elsewhere where perf isn't critical I've shifted to having the return value be `IReadOnlyList`. We've been doing this elsewhere but evidently missed a handful spots.\r\n\r\nIn an *ideal* world we'd make them actually immutable, as via `System.Collections.Immutable`, as I indeed did one or two places, but for the time being I think it suffices that we just make them read-only (even if the user could technically still muck with them with a cast, I'd consider fixing that problem later to be a non-breaking change in the API).\r\n\r\nI only undertook this review in the Core/Data/Transform assemblies."""
418128219,2876,b'Scrubbing task: rest of transforms',b'Fixes: #2835.\r\n\r\nThis PR does the scrubbing for the following transforms:\r\n\r\n- ReplaceMissingValues\r\n- IndicateMissingValues\r\n- CustomMapping\r\n\r\n'
418092547,2875,b'Scrubbing image transforms',b'Fixes #2833 '
418053060,2874,b'mlnetmkldeps nuget package updates',"b'Related to changes for updating mlnetmkldeps nuget package, issue #2211.\r\n - Updates to the nuspec file\r\n - Updates to the instructions for creating the nuget'"
418034986,2872,b'ImageModels in tensorflow are 4 dimensional.',"b""Fixes https://github.com/dotnet/machinelearning/issues/2778\r\nWell, not exactly fixes, it's more like a hack.\r\nProper solution would be to implement Reshape transform https://github.com/dotnet/machinelearning/issues/765"""
417946748,2869,b'PFI statistics polish',"b'Fixes #2868. Also contributes minorly towards #2445, by making the statistics classes (not the context extension methods) in the `Microsoft.ML.Data` namespace.'"
417626434,2867,b'Updating MKL',"b'- Updating ml.net to use mlnetDep nuget 0.0.0.9. This does a couple of things:\r\n1) Updates ML.Net to use MKL version 2008.3.10\r\n2) Enables OpenMP for MKL\r\n3) Project changes for handling the OpenMP library, note that we only copy this library on windows builds. Both Mac and Linux require this library to be installed.\r\n- Enables OpenMP for SymSGDNative\r\n- NumberOfThreads parameter now set the number of threads to use for SymSGDNative.\r\n\r\nThis related to issue #2211 \r\nfixes https://github.com/dotnet/machinelearning/issues/655'"
417581237,2865,b'Scrub projection transforms',"b'Fix #2831. \r\n\r\nTransforms touched:\r\nRFF, LpNorm, GcNorm, PCA, Whiten, Normalize.'"
417534131,2863,b'Scrubbing schema related transforms',b'Should fix https://github.com/dotnet/machinelearning/issues/2828'
417531477,2862,b'Scrubbing of the key related transforms',"b'Fixes #2829.\r\n\r\nRelated to the scrubbing tasks. I focus on the key related transforms in this PR.\r\n\r\nNote: in most places the following method is used by the estimator to get the the columns. I kept it but made it internal, despite Ivan suggested deleting it.\r\n\r\n```charp\r\ninternal IReadOnlyCollection<KeyToVectorMappingEstimator.ColumnOptions> Columns => _columns.AsReadOnly();\r\n```\r\n\r\nList of transforms:\r\n\r\n- MapKeyToBinaryVector\r\n- MapKeyToBinaryVector\r\n- MapKeyToVector\r\n- MapKeyToValue\r\n- MapValueToKey\r\n- ValueMap\r\n- OneHotEncoding\r\n- Hash\r\n- OneHotHash\r\n'"
417526216,2861,b'Update release for 0.11',b'Updating the 0.11 release'
417501324,2860,b'Adding release notes for v0.11',b'Adding release notes'
417496864,2859,b'Add V1 Introspective Training Tests',b'This PR adds tests to cover the Introspective Training scenarios we want fully supported in V1.\r\n\r\nI can take an existing model file and inspect what transformers were included in the pipeline\t \t \r\nI can inspect the coefficients (weights and bias) of a linear model without much work. Easy to find via auto-complete.\t \t \r\nI can inspect the normalization coefficients of a normalizer in my pipeline without much work. Easy to find via auto-complete.\t \t \t \r\nI can inspect the trees of a boosted decision tree model without much work. Easy to find via auto-complete.\t \t \t \r\nI can inspect the topics after training an LDA transform. Easy to find via auto-complete.\t \t \t \r\nI can inspect a categorical transform and see which feature values map to which key values. Easy to find via auto-complete.\t \t \t \r\nP1: I can access the GAM feature histograms through APIs\r\n\r\nFixes: #2498 '
417488244,2858,b'Add save/load APIs for IDataLoader',b'Fixes #2735.'
417478741,2856,b'Fixing inconsistency in usage of LossFunction',b'fixes #2174\r\nfixes #2594'
417475996,2855,b'Fixed a tensorflow test which was marked as skipped.',"b'This PR fixes a TensorFlow test which was marked skipped. The test got obsolete because it was creating loader from string.\r\n\r\nAlso, fixes reloading of model again in the TensorFlowModel class.\r\n\r\n'"
417460349,2852,b'Scrubbing feature selection',b'fixes https://github.com/dotnet/machinelearning/issues/2830'
417445315,2851,b'Polish early stop rules in fast tree',"b'Fix #2520. The pattern implemented in this PR is\r\n```csharp\r\n        [BestFriend]\r\n        [Argument(ArgumentType.Multiple, HelpText = ""Early stopping rule. (Validation set (/valid) is required.)"", ShortName = ""esr"", NullName = ""<Disable>"")]\r\n        [TGUI(Label = ""Early Stopping Rule"", Description = ""Early stopping rule. (Validation set (/valid) is required.)"")]\r\n        internal IEarlyStoppingCriterionFactory EarlyStoppingRuleFactory;\r\n\r\n        /// <summary>\r\n        /// The underlying state of <see cref=""EarlyStoppingRuleFactory""/> and <see cref=""EarlyStoppingRule""/>.\r\n        /// </summary>\r\n        private EarlyStoppingRuleBase _earlyStoppingRuleBase;\r\n\r\n        /// <summary>\r\n        /// Early stopping rule used to terminate training process once meeting a specified criterion. Possible choices are\r\n        /// <see cref=""EarlyStoppingRuleBase""/>\'s implementations such as <see cref=""TolerantEarlyStoppingRule""/> and <see cref=""GeneralityLossRule""/>.\r\n        /// </summary>\r\n        public EarlyStoppingRuleBase EarlyStoppingRule\r\n        {\r\n            get { return _earlyStoppingRuleBase;  }\r\n            set\r\n            {\r\n                _earlyStoppingRuleBase = value;\r\n                EarlyStoppingRuleFactory = _earlyStoppingRuleBase.BuildFactory();\r\n            }\r\n        }\r\n```\r\nYou can see that `EarlyStoppingRuleFactory` (used in old infra) is exposed to users by adding `EarlyStoppingRule`.\r\n'"
417444223,2850,b'Add API to save/load models with their input schema',"b'Fixes #2735. \r\n\r\nCurrently, this PR adds a public API that saves and load an IDataLoader. Later iterations will add APIs to save/load the schema directly.'"
417414374,2849,b'Remove random trainer and model parameters from the public surface.',b'Fix #2848.'
417283565,2847,b'Add XML doc to the ITrainerEstimator interface',b'Just a quick draft for the XML docs to help fix #2629 '
417080278,2846,b'Remove ConcurrencyFactor from IHostEnvironment',b'Fixes #2051.\r\n\r\nIn this PR I remove `ConcurrencyFactor` from `IHostEnvironment` and interfaces and classes deriving/implementing it. \r\n\r\nI had to skip a `RandomPredictor` as I am not sure how I can require a single threaded behavior without the `ConcurrencyFactor` for this specific trainer. \r\n\r\n'
417071346,2845,b'Update schema comprehension documentation code',b'Fix for #2039'
417071060,2844,b'[One line Fix] Fix a use of text featurizer',b'As title.'
417066229,2843,b'Update to coverlet 2.6.0',b''
417052498,2842,b'Hide more of Microsoft.ML.Data',"b'Towards #1602. When performing what I hope is one of my final reviews of the public surface area of `Microsoft.ML.Data` I saw many ""small"" items, each too petty to warrant separate issues, but that we nonetheless do not want in the public surface. This is in the vein of #2300 and other similar PRs. Special emphasis was placed on making sure we don\'t have abstract protected members visible as part of the public surface, and other such things as this.\r\n\r\nIn my review of the assembly I did not address those types or members I knew were being taken care of through other channels. (E.g., the attribute bearing marker interfaces for `IComponentFactory`, or the calibrator.)'"
417021989,2840,b'Hide SaveTo/LoadFrom from TransformerChain',b'Fixes https://github.com/dotnet/machinelearning/issues/2837'
417013694,2839,b'Remnants from renaming of StratificationColumn',b'Fixes #2536 remnants.'
416560072,2825,b'Scrubbing SDCA learners',b'Fixes #2616 .  Related #2613\r\n\r\n'
416344237,2822,b'Updating the buildtools version to the latest',"b'This PR doesnot change any functionality of any sought.\r\nDuring the netcoreapp3.0 build on ubuntu, few  restore errors are printed.\r\n\r\n```\r\n/git/machinelearning/Tools/crossgen/crossgen.csproj : error NU1202: Package Microsoft.NETCore.App 3.0.0-preview-27324-5 is not compatible with netcoreapp2.0 (.NETCoreApp,Version=v2.0). Package Microsoft.NETCore.App 3.0.0-preview-27324-5 supports: netcoreapp3.0 (.NETCoreApp,Version=v3.0)\r\n/git/machinelearning/Tools/crossgen/crossgen.csproj : error NU1202: Package Microsoft.NETCore.App 3.0.0-preview-27324-5 is not compatible with netcoreapp2.0 (.NETCoreApp,Version=v2.0) / linux-x64. Package Microsoft.NETCore.App 3.0.0-preview-27324-5 supports: netcoreapp3.0 (.NETCoreApp,Version=v3.0)\r\n```\r\n\r\nThese errors doesnot interfere with the build or tests. This PR resolves those errors as well.'"
416309715,2819,"b'Cleaned and fixed public API surface for KMeans, NaiveBayes, OLS.'",b'This is the final PR related to #2620. This PR finally fixes #2620\r\n\r\nThe following learners are addressed in this PR.\r\n\r\n* KMeansPlusPlusTrainer\r\n* MultiClassNaiveBayesTrainer (No sample for NaiveBayes opened issue #2818)\r\n* OlsLinearRegressionTrainer\r\n\r\nthe following tasks were performed in classes related to above learners.\r\n\r\nChecking to make sure that unnecessary public methods/properties be internal.\r\nRenaming parameters according to standard.\r\nCreating/Refactoring samples according to standards.\r\n\r\n'
416194794,2815,b'[Tiny] Use string[] instead of IEnumerable<string> in column names',"b'There are three possible ways to denote input column names, `string[]`, `IEnumerable<string>`, and `params`. I personally like `string[]` because\r\n\r\n- `IEnumerable<string>` is not used elsewhere for the same purpose.\r\n- `params` makes signature less typed and it forces input column names to be the last argument group.\r\n\r\nFix #2801, Fix #2460.\r\n\r\n'"
416189856,2814,b'Add sample for IndicateMissingValues',b''
415945768,2812,b'Message related to missing models improved in DNNImageFeaturizers.',"b'Fixes https://github.com/dotnet/machinelearning/issues/2784\r\n\r\n\r\nNew error msg \r\n```\r\n[28-02-2019 21:12:14 Error] [xUnit.net 00:00:01.96]     Microsoft.ML.Tests.DnnImageFeaturizerTests.OnnxStatic [FAIL]\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]       System.IO.IOException : Model file path C:\\git\\machinelearning\\bin\\AnyCPU.Debug\\Microsoft.ML.OnnxTransformerTest\\netcoreapp2.1\\DnnImageModels1\\ResNetPrepOnnx\\ResNetPreprocess.onnx doesnot exists.\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]       Stack Trace:\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]         C:\\git\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(744,0): at Microsoft.ML.Contracts.CheckIO(IExceptionContext ctx, Boolean f, String msg, Object[] args)\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]         C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxTransform.cs(168,0): at Microsoft.ML.Transforms.OnnxTransformer..ctor(IHostEnvironment env, Options options, Byte[] modelBytes)\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]         C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxTransform.cs(252,0): at Microsoft.ML.Transforms.OnnxTransformer..ctor(IHostEnvironment env, String[] outputColumnNames, String[] inputColumnNames, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu)\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]         C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxTransform.cs(544,0): at Microsoft.ML.Transforms.OnnxScoringEstimator..ctor(IHostEnvironment env, String[] outputColumnNames, String[] inputColumnNames, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu)\r\n[28-02-2019 21:12:14 Informational] [xUnit.net 00:00:01.96]         C:\\git\\machinelearning\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet1\r\n```\r\n\r\n'"
415928781,2811,b'Read and write binary file documentation',"b'Fix for #1767.\r\n\r\n@GalOshri, I took a stab at this. I figured a sample and included snippets in the cookbook would be a good start.'"
415904137,2809,b'correcting path construction when Resnet projets are consumed as a nuget package',b'Fixes https://github.com/dotnet/machinelearning/issues/2785\r\n'
415903032,2808,b'Scrub changes for LightGBM',b'Api clean up for LightGBM. The cleanup includes:\r\n- Changing all abbreviated parameters to full names (i.e. numThreads->NumberOfThreads)\r\n- Updating column parameters to have Name if thats what they represent\r\n(LabelColumn->LabelColumnName).\r\n- Updated baseline files to reflect these changes which are semantical\r\nand should not have any computational difference.\r\n\r\nPart of the fix for #2618 (related to FastTree and GAM in #2617)'
415898219,2807,b'Make accessor of linear coefficients unique to the public',"b'To fix #2763, we plan to hide one accessor in `LinearModelParameters` which is\r\n```csharp\r\nvolid GetFeatureWeights(ref VBuffer<float> weights)\r\n```\r\nand make the its containing interface a best friend.\r\n```csharp\r\ninternal interface IHaveFeatureWeights\r\n```\r\n\r\n'"
415868052,2804,b'One type label policy in trainers',b'This PR fixes #2628 and fixes #2750. fixes https://github.com/dotnet/machinelearning/issues/2810'
415865454,2803,b'Add V1 Scenario tests for data transformation',"b'Fixes #2711 \r\nTowards #2498 \r\n\r\n* Extensible transformation: It should be possible to write simple row-mapping transforms.\r\n  Examples: ""I can add custom steps to my pipeline such as creating a new column that is the addition of two other columns, or easily add cosine similarity, without having to create my own build of ML.NET.\r\n* I can modify settings in the TextFeaturizer to update the number of word-grams and char-grams used along with things like the normalization.\r\n* I can apply normalization to the columns of my data'"
415795587,2800,b'Rename HalLearners assembly and nuget to Microsoft.ML.Mkl.Components.',b'fixes #2756\r\n\r\n'
415785190,2799,b'Adding a sample for the OnnxCatalog.DnnFeaturizeImage extension',b'Adding to #1209 an example for OnnxCatalog.DnnFeaturizeImage\r\n\r\n'
415750225,2797,"b'Refactor cancellation mechanism and make it internal, accessible via experimental nuget.'",b'fixes #2795'
415748146,2796,b'Replace predicate with an IEnumerable<DataViewSchema.Column> for IRowToRowMapper.GetRow and  ISchemaBoundRowMapper.GetRow',"b'Closes #1529 \r\n\r\nNote to reviewers: The first commit does all the replacement work. \r\nThe second commit, has more files on it, because it deals with renaming the col to columnIndex in the other two methods of IDataView (@eerhardt comment on #1529)\r\nThe third commit is me reviewing the first commit, and making sure that GetRow is an explicit implementation everywhere. \r\n\r\nI have had most of the work on this PR done before breaking ISchemaBoundRowMapper deriving from IRowToRowMapper; so I kept the signature change of ISchemaBoundRowMapper.GetRow although that interface is internal. LMK if that is not desirable. '"
415644575,2792,b'Rename Microsoft.ML.StandardLearners',"b""# Summary\r\nI renamed `StandardLearners` to `StandardTrainers`. If I missed something, please let me know \xf0\x9f\x91\x8c \r\nFixes #2786 \r\n\r\n---\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR."""
415594847,2790,b'Quick fix to XML documentation',b'Fix for #2767.'
415381054,2783,b'Add missing KeyType documentation',"b""Fix for #2333.\r\n\r\nHopefully, this is a good start. I'm sure some wording could be updated. :)"""
415378405,2782,b'[Tiny Change] One-line renaming',b'As title.'
415374745,2781,b'Sample for ConvertType transform estimator',b'Towards #1209\r\n\r\n- fix bug in ConvertType   (exception when trying to convert from Bool => Int)\r\n- add sample for ConvertType '
415373425,2780,b'Add an example of random PCA using in-memory data structure',b'As title. It also shows some benefits of using in-memory data described in #2726.\r\n\r\n'
415370385,2779,b'OneHotEncoding sample',b'Sample code for OneHotEncoding'
415366392,2777,b'Correct documentation for MapKeyToVector.',b'fixes #2772\r\n\r\n'
415362631,2775,b'Merge master into release/preview for 0.11',b'This PR merges master into release branch for 0.11'
415360016,2773,b'Sample for ReplaceMissingValues.',b'\r\n'
415349271,2771,b'Docs & samples for SDCA-based trainers',"b'Docs & samples for SDCA binary, multi-class, and regression.\r\nRelated to #2522 '"
415342873,2770,b'Created samples for StochasticGradientDescentNonCalibrated learner.',b'Created samples for StochasticGradientDescentNonCalibrated learner exposed via following methods.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a0edc5c5724ed2895fd0c2fa5c2525d03de13455/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs#L82\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a0edc5c5724ed2895fd0c2fa5c2525d03de13455/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs#L102'
415322621,2766,b'Calibrators catalog introduction',b'should fix https://github.com/dotnet/machinelearning/issues/1871'
415307291,2765,b'Cleaning and Fixing public API for set of learners.',b'This PR partially addressed #2620\r\n\r\nThe following learners are addressed in this PR.\r\n* `MatrixFactorizationTrainer`\r\n* `PriorTrainer`\r\n* `RandomTrainer`\r\n* `SymSgdClassificationTrainer`\r\n\r\nthe following tasks were performed in classes related to above learners.\r\n\r\n* Checking to make sure that unnecessary public methods/properties be `internal`.\r\n* Renaming parameters according to standard.\r\n* Creating/Refactoring samples according to standards.'
415280938,2764,b'Package FastTree.',b'fixes #2752\r\n'
415252280,2761,b'Scrubbing LogisticRegression learners',b'Fixes #2615.  Related #2613\r\n\r\n'
415239891,2759,b'Remove unused fileHandle',"b""fileHandle variable is not used in the code block. The logic for which it was used is deleted and therefore no need for fileHandle variable.\r\n\r\nCode cleanup from PR: https://github.com/dotnet/machinelearning/pull/2568\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
415239826,2758,b'Bump master to 0.12',b'Updating the version on Master to 0.12'
415238150,2757,b'Merge master into release/preview for 0.11',b'This PR merges master into release branch for 0.11'
414976450,2755,"b""transform and trainer namespaces don't need to follow the catalogs""",b'Microsoft.Ml.Transforms.Normalizers\r\nMicrosoft.Ml.Transforms.Categoricals\r\nMicrosoft.Ml.Transforms.Conversions\r\nMicrosoft.Ml.Transforms.Projections\r\n\r\ninto Microsoft.Ml.Transforms\r\n\r\nMicrosoft.ML.Trainers.KMeans\r\nMicrosoft.ML.Trainers.PCA\r\nMicrosoft.ML.Trainers.OnlineLearners\r\nMicrosoft.ML.Trainers.FactorizationMachine\r\n\r\ninto Microsoft.ML.Trainers\r\n\r\nAddresses #2751. \r\n'
414939291,2754,b'Replace Float with float',b'Fix for #1669.'
414902960,2753,b'Scrub Fast Tree Family',"b'This PR fixes #2617 (also fixes #2375, fixes #2857) and is also a part of #2613.\r\n\r\nCleaned items:\r\n\r\n- [x] FastTree.cs\r\n- [x] FastTreeArguments.cs\r\n- [x] Derived fast tree classes\r\n- [x] Gam family'"
414864473,2749,b'Scrubbing PkPd',"b'- Renamed pkpd class to PkPdTrainer\r\n- Renamed pkpd.cs to PkPdTrainer.cs\r\n- Updates to PairwiseCoupling api such as removing abbreviations from parameter names, updating comments and documentation\r\n\r\nCloses #2619'"
414846952,2748,b'Move Learner* input base and Transform* input base out of Entrypoints\xe2\x80\xa6',b'fixes #2582\r\nfixes #2760 '
414840808,2747,b'Expose split gains in tree models',"b""Fix #2658 by adding split gains to tree's public API. \r\n"""
414814181,2745,b'Remove IMultiStreamSource when path (type: string) exists in text loader APIs',"b'Fix bugs introduced in #2710. If `string path` and `IMultiStreamSource dataExample` are present at the same time, we drop `IMultiStreamSource dataExample`.\r\n\r\n'"
414780361,2744,b'Make EarlyStoppingMetric an enum.',b'fixes #2521\r\n\r\n'
414770315,2743,b'Scrubbing OneVsAll',b'- Renamed OVA to OneVsAllTrainer\r\n- Updates to comments and documentation\r\nRelated to #2619'
414762209,2742,b'Respect group id in options for ranking task',b'Fix https://github.com/dotnet/machinelearning/issues/2652'
414754017,2741,b'Internalize Microsoft.ML.Internal.CpuMath.GeneralUtils.',b'fixes #2737\r\n\r\n'
414748153,2740,b'Microsoft.ML.Internal.Internallearn should be hidden/moved/renamed',b'fixes #2714'
414731575,2738,b'Polish GetColumn on IDataView',"b""To fix #2473, we need to\r\n\r\n- [x] Remove IHostEnviroment from GetColumn's argument list. Note that our strategy is using `Constracts`.\r\n- [x] Replace column name with `DataViewSchema.Column` in GetColumn's argument list.\r\n\r\nReview steps:\r\n1. Start with the 2nd iteration because some changes in the 1st iteration got discarded.\r\n2. Removal of IHostEnviroment happens in the 2nd iteration.\r\n3. Uses of `DataViewSchema.Column` are done in the 3rd iteration.\r\n"""
414565468,2733,b'Enable TextFeaturization tests',b'Also update tests to use the `SSWE` model.\r\n\r\nFix for #2668.'
414430411,2731,"b'Rename IDataLoader, IDataReader and IDataReaderEstimator'","b'Fixes #2144.\r\n\r\nAs discussed in the issue, it was agreed that `TextReader`, `BinaryReader` and `IDataReader` were bad names because they overlap with .NET concepts.\r\n\r\nIn this PR I:\r\n1. rename `IDataLoader` to `ILegacyDataLoader` (commit 1).\r\n2. rename `IDataReader` to `IDataLoader` and `IDataReaderEstimator` to `IDataLoaderEstimator` (commit 2).'"
414381392,2730,b'Scrubbing FieldAwareFactorizationMachine learner.',"b'This PR partially addressed https://github.com/dotnet/machinelearning/issues/2620\r\n\r\nIn FieldAwareFactorizationMachine related classes, the following tasks were performed.\r\n* Checking to make sure that unnecessary public methods/properties be `internal`.\r\n* Renaming parameters according to standard.\r\n* Creating/Refactoring samples according to standards.\r\n\r\n\r\n\r\n'"
414380910,2729,b'Adding sample for LightGbm ranking',b'Replacing PR #2704 and #2650 as I messed up commit history there.\r\n\r\nFixes #2530\r\nFixes #776\r\n\r\n* Adds a sample for LightGbm ranking.\r\n* Cleans up namespaces in Microsoft.ML.Samples project.\r\n* Addresses feedback from previous PRs'
414373920,2727,b'Added performance tests for small array input for cpumath functions',"b'I also tried Unrolling the loop for small input. \r\nFor small functions like add, scale unrolling the loop only shows improvement for length 13-15\r\nFor little complex functions like dotproduct , loop is always better than the unrolling scenario.\r\n\r\nThe pr adds the performance tests for small inputs software implementation\r\n'"
414362751,2724,b'More namespace alignment',b'Closes #2326 by : \r\n1- First commit\r\nsubstituting :\r\n\r\nMicrosoft.ML.Trainers.Ensemble.DiversityMeasure\r\nMicrosoft.ML.Trainers.Ensemble.FeatureSelector\r\nMicrosoft.ML.Trainers.Ensemble.SubModelSelector\r\n\r\nwith:\r\nMicrosoft.ML.Trainers.Ensemble\r\n\r\n2 - Second commit:\r\nMicrosoft.ML.FactorizationMachine becomes Microsoft.ML.Trainers.FactorizationMachine\r\nMicrosoft.ML.EntryPoints.JsonUtils becomes Microsoft.ML.EntryPoints\r\n\r\n3- third commit\r\nMicrosoft.ML.ImageAnalytics.EntryPoints becomes Microsoft.ML.ImageAnalytics\r\nMicrosoft.ML.Internal.Calibration becomes Microsoft.Ml.Calibrator\r\n\r\n4- Fourth commit\r\nMicrosoft.ML.StaticPipe.Runtime changes to Microsoft.ML.StaticPipe\r\n\r\neasier to review commit by commit. \r\n\r\nI have used the VS replace all + reordering namespaces through Ctrl+R+G '
414356716,2722,b'Remove and combine Microsoft.ML.UniversalModelFormat.Onnx with Microsoft.ML.Model.OnnxConverter.',b'fixes #2721\r\n\r\n'
414345802,2718,"b""Ensemble to it's own package""",b'fix #2717'
414343258,2716,b'Move ReadFromEnum and CreateEnumerable and add sample',"b'Fixes #2609.\r\n\r\n1. I moved `ReadFromEnumerable` method outside of `ComponentCreation`. I could therefore make the class `ComponentCreation` BestFriend internal, while making the internal methods public. \r\n2. I moved the extension method for `CreateEnumerable` which used to be under `MLContext` to the `Data` extensions where `ReadFromEnumerable` lives. I could therefore make the `CursoringUtils` class internal.\r\n3. I added a sample for `CreateEnumerable` and `ReadFromEnumerable`.\r\n\r\nOnly non trivial changes are in DataViewEnumerable.cs, DataOperationsCatalog.cs, MLContext.cs, TypedCursor.cs, ComponentCreation.cs. The rest are simply adjusting the code to use `mlContext.Data.CreateEnumerable`.'"
414343076,2715,b'Drop Microsoft.ML.Training and replace it with Microsoft.ML.Trainers.',b'fixes #2713\r\n\r\n'
414320247,2712,b'Rename DataView Metadata to Annotations.',"b'I have ensured there is no public API with the word `metadata` in it anymore. The only place this occurs is in the `Microsoft.ML.UniversalModelFormat.Onnx` namespace, which is a different type of ""metadata"".\r\n\r\nThere are still internal/private usages of the term ""metadata"", but this PR is large enough. We can fix those in a subsequent change.\r\n\r\nFix #1843\r\nFix #2297 \r\n'"
414234005,2710,b'Make text loaders consistent',b'Another attempt to fix #2472.\r\n\r\n'
414233798,2709,b'Renaming ColumnInfo to ColumnOptions',"b'Fixes #2554.\r\n\r\nAs discussed in the issue, we decided to rename `ColumnInfo` to `ColumnOptions`.\r\nI used Visual Studio to find and replace instances of `ColumnInfo`. I did an operation of find and replace for each different casing. I also went over the changes to double check.'"
414208070,2707,b'Make DataViewRowId not act like a number.',b'- Remove it from the NumberDataViewType.\r\n- Remove any method/operator that makes it feel like a number.\r\n\r\nWorking towards #2297'
413723002,2706,b'Remove MD5Hasher.',b'fixes #2696\r\n\r\n'
413656877,2705,b'Fixing the project reference in the nuget packages for OnnxTransformer',"b'- Fixes the project reference path for OnnxTransformer.\r\nFound while fixing #689, moved to separate commit.'"
413653324,2704,b'Adding a sample for LightGbm ranking',b'Replacing PR #2650 as I messed up commit history there.\r\n\r\nFixes #2530\r\nFixes #776\r\n\r\n- Adds a sample for LightGbm ranking. \r\n- Cleans up namespaces in Microsoft.ML.Samples project.\r\n- Addresses feedback from first round of #2650. '
413628805,2703,b'Move the builder classes in DataViewSchema',"b""- Move MetadataBuilder to be DataViewSchema.Metadata.Builder.\r\n- Move SchemaBuilder to DataViewSchema.Builder.\r\n- Rename `GetMetadata` and `GetSchema` to `ToMetadata` and `ToSchema`\r\n\r\nWorking towards #2297\r\n\r\nThere are 2 tasks left before that issue can be closed.\r\n\r\n1. Rename 'metadata' to 'annotations' - a very large change.\r\n2. Remove anything from DataViewRowId that makes it seem like a number."""
413618522,2702,b'Make separator char[] everywhere (previous type is char sometime)',"b""Fix #2472. This PR makes all separators a `char[]` instead of `char` in the public area of `TextLoader`. Note that `TextLoader`'s advanced `options` is already using `char[]`.\r\n\r\n"""
413616093,2701,"b'Hide delegates, model parameters constructors and other small things'",b'should fix #1974'
413584335,2700,b'Clean up metrics classes.',b'fixes #2624'
413549529,2698,b'Remove the IFourierDistributionSampler interface',"b'Fixes #2659,\r\nfixes #699.\r\n'"
413519947,2697,"b'Move metrics from percentages to [0,1]'","b'This PR moves the metrics `LogLoss`, `LogLossReduction`, and `NDCG` to be between 0 and 1 instead of 0 and 100 (i.e. from percentage to fraction) to be in line with the community standards.\r\n\r\nFixes #2637 '"
413230656,2695,b'Activate OnnxTransform unit tests for MacOS ',b'OnnxRuntime now supports MacOS runtimes. Activate  OnnxTransform unit tests for MacOS.\r\n\r\n'
413219259,2693,b'Draft version of ML.NET CLI specs with AutoML capabilities',"b'This is a draft version of ML.NET CLI specs to be discussed in the open with the ML.NET community.\r\nIts initial functionality will be based on .NET AutoML (Which will be also part of ML.NET)\r\n\r\nFor further details, read the **MLNET-CLI-Specs.md** document in the PR.\r\n\r\nRelated issues:\r\nhttps://github.com/dotnet/machinelearning/issues/2694\r\nhttps://github.com/dotnet/machinelearning/issues/1203\r\n\r\n\r\n\r\n'"
413218980,2692,b'Fix AnomalyDetection Evaluator returning NaN when there are no anomalies',"b'This PR ensures that an exception is thrown when AUC is calculated with a data consisting of only one class.\r\n\r\nFor anomaly detection, when test data has no anomalies, the returned AUC was NaN because there are no TPs causing the bug mentioned in #2644 \r\n\r\nI added Unit Tests to ensure that the exception is thrown\r\n\r\nNote: for DrAtK, it looked to me that it is returning NaN by design based on these lines of code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/412e1f904c9cd25b80e62bb01390e09360b5b50c/src/Microsoft.ML.Data/Evaluators/AnomalyDetectionEvaluator.cs#L255-L259\r\n\r\nFixes #2644 \r\n\r\n'"
413207683,2691,b'Remove learningRate parameter from RandomForest',b'Removes the learning rate parameter from RandomForest as this parameter was not used\r\nby the base class.\r\n\r\nThis fixes #2237'
413196519,2690,b'Nuget package updates',b'- Removed ResultProcessor and Maml from Microsoft.ML nuget. These are\r\ncurrently not in a nuget package\r\n- Moved Sweeper from Microsoft.ML to Microsoft.ML.Sweep.\r\n- Updated nuget references as there were some other non-related errors\r\nfor ONNX Transformer.\r\n\r\nThis fixes #689'
413168754,2688,b'Added samples & docs for BinaryClassification.StochasticGradientDescent',b'Part of #1257 and #2522.\r\n\r\n* Added samples & docs for BinaryClassification.StochasticGradientDescent\r\n* Bunch of typo fixes'
413154507,2687,b'Update build tools version and use netcoreapp3.0 on ubuntu CI',b'Fixes #2381 \r\n\r\nUpdates the buildtools version to latest and also running tests and building machinelearning repo with netcorepp3.0 on non-windows machine'
413121420,2684,b'Adding defaults for Label and GroupId to Ranking Evaluator',"b'This PR adds default column names for Label and GroupId for the Ranking `Evaluator`, in line with all other Evaluators.\r\n\r\nFixes #2633 '"
413076278,2682,b'Fix the build',"b'Sorry, PR #2580 broke the build. fixing it.'"
413052900,2681,b'IndexOutOfRange Exception in KeyToVector transformer',b'Fixes #2678'
412826276,2676,b'Creating a service patch for fixing issue with .NET 4.6.2',b'cherry picking fix for 4.6.2'
412701209,2675,b'Changed Ranker to Ranking in evaluation related files.',"b""This PR fixes https://github.com/dotnet/machinelearning/issues/2634\r\n\r\nSome of the EntryPoint names got changed. Reviewers' are requested to please verify consequences of changing EntryPoint names.\r\n"""
412699653,2674,b'Mark EntryPoints classes and APIs as internal',b'fixes #2582 #1065 '
412698292,2673,b'Explicit implementation for IsRowToRowMapper and GetRowToRowMapper',b'Fixes #2540.\r\n\r\nAs explained in the issue I make the implementations of two methods of the`ITransformer` interface `IsRowToRowMapper` and `GetRowToRowMapper` explicit.\r\n\r\nIn a previous PR #2431 I made the implementation of `ICanSaveModel.Save` explicit. `Save` is part of `ITransformer` as it derives from `ICanSaveModel`. I found a few instances that have been changed since my last PR in the TimeSeries assembly and that still had a regular implementation for `Save. I made their implementation explicit in this PR as it is very similar in spirit.'
412670101,2672,b'Internalization of TensorFlowUtils.cs and refactored TensorFlowCatalog.',"b'This PR fixes #2552 and also fixes #2572.\r\n\r\nThe discussion in these issues are taken as initial feedback to create this PR. The PR groups all the TensorFlow related operations into TensorFlowCatalog. This catalog now appears as a separate catalog in TransformsCatalog e.g. `ScoreTensorFlowModel` that appeared under `Transforms` catalog as\r\n\r\n``` csharp\r\nmlContext.Transforms.ScoreTensorFlowModel\r\n```\r\nnow appears under `TensorFlow` as \r\n``` csharp\r\nmlContext.Transforms.TensorFlow.ScoreTensorFlowModel\r\n```\r\nHow breaking is this change at this stage?\r\n\r\nAlso, the PR also include following methods in TensorFlow catalog. \r\n``` csharp\r\npublic static DataViewSchema GetModelSchema(this TransformsCatalog.TensorFlowTransforms catalog, string modelLocation)\r\n    => TensorFlowUtils.GetModelSchema(CatalogUtils.GetEnvironment(catalog), modelLocation);\r\n\r\npublic static IEnumerable<(string, string, DataViewType, string[])> GetModelNodes(this TransformsCatalog.TensorFlowTransforms catalog, string modelLocation)\r\n    => TensorFlowUtils.GetModelNodes(CatalogUtils.GetEnvironment(catalog), modelLocation);\r\n\r\npublic static TensorFlowModelInfo LoadTensorFlowModel(this TransformsCatalog.TensorFlowTransforms catalog, string modelLocation)\r\n    => TensorFlowUtils.LoadTensorFlowModel(CatalogUtils.GetEnvironment(catalog), modelLocation);\r\n```\r\nThere is also a suggestion to add these methods into `DataCatalog`. Feedback is requested in this regard.\r\n\r\nCC: @TomFinley, @yaeldekel, @rogancarr, @Ivanidzo4ka \r\n'"
412605340,2667,b'Microsoft.ML.Internal.Internallearn namespace requires certain internalization.',b'fixes #2590'
412598310,2666,"b'typo in comment: ""shoudl"" changed to ""should""'","b""typo in comment: shoudl changed to should\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
412595432,2665,b'Fixing parameters in ML.NET Public API',"b'Fixes #2257, #2660, #2177 \r\n\r\nAlso related to #2680 #2613 \r\n\r\nUsing ApiReview tool, went through the public surface area making the changes (as described in the issue)'"
412592475,2664,b'Upload code coverage files just once with test and prod flags.',"b""Just testing for now as per @sharwell 's recommendation."""
412550745,2661,b'Internalize DataKind',"b""Fix #2583. In general, we don't want to see `DataKind` in any public area. Depending on the actual amount of works required, this PR might first address cases mentioned #2583 and then more PRs will be published later.\r\n\r\n- [x] TextLoader\r\n- [x] TypeConverting\r\n- [x] Rest (DataKind is internal-best-friend now).\r\n\r\nNote that to specify target types in type converters and text loader, we introduce a cleaner version of existing `DataKind`,\r\n```csharp\r\n    public enum DataKind : byte \r\n    { \r\n        SByte = 1, \r\n        Byte = 2, \r\n        Int16 = 3, \r\n        UInt16 = 4, \r\n        Int32 = 5, \r\n        UInt32 = 6, \r\n        Int64 = 7, \r\n        UInt64 = 8, \r\n        Single = 9, \r\n        Double = 10, \r\n        String = 11, \r\n        Boolean = 12, \r\n        TimeSpan = 13, \r\n        DateTime = 14, \r\n        DateTimeOffset = 15, \r\n    }\r\n```\r\nand the existing `DataKind` is renamed as `InternalDataKind`.\r\nOther user-facing changes were made to work with `DataKind`. Command line and entry point are not affected at all."""
412285447,2651,"b'Metadata utils internalization, migration of few useful methods'","b""Fixes #2622 by limiting the public surface area of metadata/annotations conveniences to a few places.\r\n\r\nNote that that migrated methods are not exactly the same as the existing methods in the case of querying whether a key column type exists, since the existing methods predated the schema column type and therefore had some unnecessary parameters. Though I decided to expand it a bit so as to allow checks on whether other types of key values are present. Not sure if that's necessary or helpful.\r\n\r\nAlso internalized the rather innocuous but nonetheless probably unnecessary metadata builder extensions.\r\n\r\nCommits structured incrementally as usual for the small steps."""
412280387,2650,b'Adding a sample for LightGbm Ranking',b'Fixes #2530 \r\nFixes #776\r\n\r\nAdding a sample for LightGbm ranking.'
412217403,2649,b'Hide much of Microsoft.ML.Model namespace.',"b'Fixes #2640. Per usual commits are logically ordered to reflect the natural order in which structures are internalized, etc.'"
412206123,2648,b'Microsoft.ML.Transforms assembly lockdown',b'Fixes #2282.\r\n\r\nThis is a pull request in the assembly public surface lockdown series.\r\nBesides internalization I also added some comments for public members. This is a relatively small PR as we have gone through the Transforms assembly many times already.\r\n\r\nI made the method `CheckInputColumn` in `OneToOneTransformerBase` BestFriend private protected instead of just protected.'
412201203,2647,b'Increase build timeout for code coverage CI.',"b'Recently it seems the code coverage build times have increased, the exact reason is unclear but it could be because of added tests. Since code coverage CI does not interfere with the main CI so its ok to increase the build timeouts for code coverage CI to prevent build failures due to [timeouts.](https://dev.azure.com/dnceng/public/_build/results?buildId=100301)\r\n'"
412195719,2646,b'Adding functional tests for all training and evaluation tasks',"b'This PR adds functional tests for all training and evaluation tasks.\r\n\r\n* I can evaluate a model trained for any of my tasks on test data. The evaluation outputs metrics that are relevant to the task (e.g. AUC, accuracy, P/R, and F1 for binary classification)\r\n* I can get the data that will allow me to plot PR curves (blocked by #2645)\r\n\r\nFixes #2621'"
412183468,2643,b'Remove append calls since they not compatible with 4.6 framework',b'Fixes https://github.com/dotnet/machinelearning/issues/2639\r\nFixes #2566'
412164144,2641,b'Remove value tuples from public TransformCatalog APIs',b'Fixes #2581 .'
412158390,2638,b'Cleaning our attributes classes',b'Fixes: https://github.com/dotnet/machinelearning/issues/2593\r\nFixes: https://github.com/dotnet/machinelearning/issues/2437'
412156336,2636,b'Fixing renmants of argument keyword in public API',b'Fixes #2557\r\n\r\n- Scrubbed the public API surface area using the **ApiReviewer** tool'
412152239,2635,b'Internalize Microsoft.ML.Data Evaluators folder.',b'fixes #2626\r\n'
412149168,2632,b'Internalization of OneToOne and ManyToOne Column classes',b'fixes #2631\r\n\r\n'
412132670,2630,b'Change Default Settings in TextLoader',"b'To fix #2576, this PR makes the default to `sparse-` everywhere including both of command line and public APIs.\r\n\r\n- [x] Make `sparse-` as default\r\n- [x] Make `quote-` as default\r\n- [x] Fix #2452, which is about TextSaver.\r\n\r\n'"
412124052,2625,b'Lockdown Microsoft.ML.Onnx public surface',b'fixes #2273\r\n\r\n**Reduces public API count from 423 to 1.**\r\n\r\n| Before | After |   \r\n|:-:|:-:|\r\n| ![image](https://user-images.githubusercontent.com/1211949/53047287-eff9ee80-3446-11e9-8586-e036e105e515.png) | ![image](https://user-images.githubusercontent.com/1211949/53047232-d6f13d80-3446-11e9-9752-91e413ae9e87.png) |\r\n'
412025833,2611,b'Address PR feedback from #2579',"b""We don't need a TryConvert method, we already have a TryParse, which can be used instead."""
411705797,2608,b'Lockdown Microsoft.ML.Data Dataview folder.',b'fixes #2606\r\n\r\n'
411703012,2607,b'Lockdown Microsoft.ML.Data Data folder',b'fixes #2604\r\n\r\n'
411700333,2605,"b'Hide IPredictor and descendants,'","b'Fixes #2251. Fixes #2592. Fixes #2603.\r\n\r\nMost significant change is internalization of IPredictor, IPredictorProducing, PredictionKind. Deletion of TrainerBase abstract base class, since it is used in few enough places that complicating the type heirarchy was no longer beneficial.\r\n\r\nI changed feature contribution so that it does not descend from `IPredictor` since I think we still might need it (though I made its implementation internal on all implementors). Querying @rogancarr about this though, he may have some thoughts on its current state.\r\n\r\nAlso incidentally found some minor infrastructure that is specific to ITrainer lurking around.'"
411678583,2602,b'Introduce order for pixel extraction',b'Fixes #2492'
411638866,2601,b'Cleanup calibrators',b'Fixes https://github.com/dotnet/machinelearning/issues/2589'
411617645,2600,b'Lockdown TrainerEstimatorBase class.',b'fixes #2599\r\n'
411305306,2595,b'Use custom BlockingQueue to significantly improve F5 perf with SDCA without caching',"b""When the StochasticDualCoordinateAscent trainer is used without AppendCacheCheckpoint, the algorithm makes many, many passes over the input data.  Each of these passes currently results in a LineReader getting created, which in turns spins up a variety of constructs that incur overhead.  That\xe2\x80\x99s something to be addressed in the TextLoader design in general, but the matter is made significantly worse when a debugger is attached because several of the constructs that get spun up are orders of magnitude more expensive when a debugger is involved, namely threads and exceptions.\r\n\r\nI previously put up several PRs to help defray these costs:\r\n- https://github.com/dotnet/machinelearning/pull/2152 has been merged and removed a bunch of threads getting created in this situation\r\n- https://github.com/dotnet/machinelearning/pull/2138 has been merged and removed a bunch of exceptions getting thrown\r\n- https://github.com/dotnet/machinelearning/pull/2579 is still pending and further removes additional exceptions\r\n\r\nThese changes, in particular the first two, helped to take the Iris multi-class classification demo (without using AppendCacheCheckpoint(mlContext)) from appx \xe2\x80\x9cforever\xe2\x80\x9d when the debugger was attached to ~230 seconds on my machine.\r\n\r\nHowever, even after these changes there are still many exceptions getting thrown in this situation.  Whereas those mentioned PRs helped to remove overheads directly incurred by the ML libraries, there\xe2\x80\x99s a significant source of exceptions that\xe2\x80\x99s coming indirectly, via use of BlockingCollection, due to a mismatch between how it\xe2\x80\x99s implemented and how it\xe2\x80\x99s being used in TextLoader in ML.NET.  BlockingCollection was implemented under the assumption that you don\xe2\x80\x99t frequently create and destroy them; as such, its CompleteAdding method was implemented on top of cancellation, such that if CompleteAdding is called while one or more threads are blocked waiting for data to arrive, internally there will be an OperationCanceledException thrown and subsequently eaten by those threads (https://github.com/dotnet/corefx/issues/34602).  When there\xe2\x80\x99s just a few of these, it\xe2\x80\x99s not ideal but also not problematic.  However, ML.NET\xe2\x80\x99s usage in this situation is tipping the scales.  In the Iris multi-class classification demo, for example, when caching isn\xe2\x80\x99t used (e.g. no call to .AppendCacheCheckpoint(mlContext)), tens of thousands of TextLoaders get created, each of which creates a BlockingCollection, and each of which uses CompleteAdding to tear down communication between the single producer reading and publishing lines from the file, and the one or more consumers taking those lines.  The net result is thousands upon thousands of 1st-chance exceptions.  The Iris demo app has a training file with only ~120 lines of data, and yet even after all of the aforementioned PRs, this demo app is incurring on average on my machine on the order of ~60,000 1st-chance exceptions!\r\n\r\nThis results in numbers like the following for the Iris demo:\r\n- With debugger attached: **\xe2\x80\x9cTraining time: 228 seconds\xe2\x80\x9d**\r\n- Without debugger attached:  **\xe2\x80\x9cTraining time: 8 seconds\xe2\x80\x9d**\r\n\r\nThis PR addresses almost all of the remaining exceptions by replacing the usage of BlockingCollection with an alternative implementation that\xe2\x80\x99s not nearly as feature rich but that doesn't rely on cancellation to implement CompleteAdding.  This implementation can be used until either TextLoader is rearchitected to avoid all of these overheads in the first place, or until this implementation issue in BlockingCollection itself is addressed.\r\n\r\nWith this PR in place, the numbers on my machine drop to the following:\r\n- With debugger attached: **\xe2\x80\x9cTraining time: 30 seconds\xe2\x80\x9d**\r\n- Without debugger attached: **\xe2\x80\x9cTraining time: 5 seconds\xe2\x80\x9d**\r\n\r\nThat\xe2\x80\x99s an ~33% improvement when the debugger isn\xe2\x80\x99t attached, but an ~7.5x improvement when the debugger is attached.\r\n\r\ncc: @CESARDELATORRE, @TomFinley, @eerhardt, @asthana86 \r\nContributes to https://github.com/dotnet/machinelearning/issues/2099"""
410985992,2584,b'Adding functional tests for explainability',"b'This PR adds functional tests for Explainability features. Namely, it tests the following scenarios:\r\n\r\n* I can get near-free (local) feature importance for scored examples (Feature Contributions)\r\n* I can view the overall importance of each feature (Permutation Feature Importance, GetFeatureWeights)\r\n* I can train interpretable models (linear model, GAM)\r\n* I can view how much each feature contributed to each prediction for trees and linear models (Feature Contributions)\r\n\r\nFixes #2573 '"
410969048,2580,b'VectorToImageTransform conversion to estimator/transformer',b'This is the remaining work for the public API of Microsoft.ML.ImageAnalytics. \r\nFixes #2269 .'
410965429,2579,b'Remove exception due to supportsSparse:true in ReadFromTextLoader',"b""In the GitHubLabeler sample, for example, there are ~450 InvalidOperationExceptions getting thrown and caught internally, as the implementation tries to parse some text as an int and fails.  There's no need for an exception here; the implementation is already using a TryParse method, which it then turns into an exception and then immediately catches and ignores... we can just cut out the middle man and not throw.\r\n\r\nRelated to https://github.com/dotnet/machinelearning-samples/pull/257\r\nRelated to https://github.com/dotnet/machinelearning/issues/2576"""
410961770,2578,b'[One-line change] Internalize MamlEvaluatorBase',"b'To fix #1976, the last missing piece is hiding \r\n```csharp\r\n    public abstract class MamlEvaluatorBase : IMamlEvaluator\r\n```\r\nbecause we already have\r\n```csharp\r\n    [BestFriend]\r\n    internal abstract partial class EvaluatorBase<TAgg> : IEvaluator\r\n        where TAgg : EvaluatorBase<TAgg>.AggregatorBase\r\n\r\n    [BestFriend]\r\n    internal interface IMamlEvaluator : IEvaluator\r\n\r\n    [BestFriend]\r\n    internal interface IEvaluator\r\n```'"
410958639,2577,b'Replace IPredictor in Fit method to proper model parameters',b'Fixes https://github.com/dotnet/machinelearning/issues/2553'
410919998,2574,b'Respect Marked exception during model loading.',b'address https://github.com/dotnet/machinelearning/issues/2567'
410877016,2569,b'Stop using System.ComponentModel.Composition',"b'Replace our MEF usage, which is only used by custom mapping transforms, with the ComponentCatalog class.\r\n\r\nFix #1595\r\nFix #2422\r\n'"
410862003,2568,b'Removes IHostEnvironment.CreateTempFile',"b""This PR is effectively removing CreateTempFile from IHostEnvironment and moving it to helper class and expects the caller to dispose of the handle safely instead.\r\n\r\nIssue ask was to Remove Dispose from LocalEnvironment. The Dispose would have been useful if the class wanted to Dispose of the file handles created using CreateTempFile which is not expected to be the responsibility of LocalEnvironment (or ConsoleEnvironment) anymore. \r\n\r\nFixes: #1287 \r\ncc: @eerhardt \r\n\r\n\r\n---\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
410566218,2564,b'Make primal stochastic trainer also typed',"b'To fix #2555, we apply idea done in #2506 to another stochastic gradient trainer. Basically, to align this trainer and the whole SDCA family, `StochasticGradientDescentClassificationTrainer` got renamed to\r\n```csharp\r\n    public abstract class SgdBinaryTrainerBase<TModelParameters> :\r\n        LinearTrainerBase<BinaryPredictionTransformer<TModelParameters>, TModelParameters>\r\n        where TModelParameters : class, IPredictorProducing<float>\r\n```\r\nwhich holds common functions used in all derived classes.\r\nThe new class, `SgdBinaryTrainerBase`, branches out into three actual implementations:\r\n- `LegacySgdBinaryTrainer` for command line and entry point BC.\r\n- `SgdNonCalibratedBinaryTrainer` for training `LinearBinaryModelParameters` with any loss which implements `IClassificationLoss`.\r\n- `SgdBinaryTrainer` for training `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>`, which is essentially logistic regression and was the default before this PR.\r\n\r\n'"
410561532,2563,"b'In the public surface area, all occurrences of Argument keyword replaced with Options'","b'Fixes #2557\r\n\r\nFor **public** API surface, all occurrences of *Argument* keyword replaced with *Options*\r\n\r\nSeveral internal classes continue to be called `Arguments`. We can target those post V1.0  since they are not part of public surface area anyway.'"
410545997,2562,b'Update to Microsoft.CodeAnalysis.Testing',b'Fixes #2480\r\n'
410545192,2561,b'Reorder MatrixFactorizationTrainer parameters',"b'Fixes #1826 \r\n\r\nChanged order of parameters to make labelColumn the first parameter. Since the following two parameters after reordering were required, I had to remove the default label name from the labelColumn param.'"
410543472,2560,b'[Donot Review] Mono ci',b'Just testing some stuff on CI'
410540493,2558,b'Lockdown Microsoft.ML.KMeansClustering public surface',b'fixes  #2270 '
410526039,2556,b'Rename Resize Transform to ResizeImages',b'This PR changes the catalog entry for the `ImageResizer` to be `ResizeImages` from `Resize`.\r\n\r\nThis PR also does a quick fix to rename the `LoadImages` sample to `LoadImages` from `LoadImage`.\r\n\r\nFixes #2550 '
410140763,2548,b'[Tiny & Simple Change] Example classes should be static',"b""Polish DYNAMIC examples to fix #2549. This change is inspired by @TomFinley's good comment to #2506 and I sincerely want to address that.\r\n\r\n- Example class should be static\r\n- Example function should be called `Example()`\r\n- Remove redundant `using` statements.\r\n\r\nPlease note that this PR only focuses on dynamic examples' `static` problem. I don't have much bandwidth to take care other cases."""
410106403,2547,b'DataView type rename',b'This covers the first 3 changes proposed in #2297.\r\n\r\n1. We will ensure the class names in the `Microsoft.Data.DataView` package are unique by adding a prefix to any name deemed too general. Add a `DataView` prefix.\r\n2. Add the base type suffix to all types that derive from the current `ColumnType` class.\r\n3. Rename the properties on NumberType to match the type name in `System` namespace.\r\n\r\nThe rest of the proposed changes will come in a separate PR (this one is big enough).'
410094650,2546,b'Added support for String types in TensorFlowTransformer.',b'This PR fixes #2545 \r\n'
410077612,2544,"b'Lockdown Microsoft.ML.OnnxTransform public surface, possibly rename '","b""fixes #2272\r\n\r\nThere isn't anything obvious to lockdown and the only task I see here is the rename suggestion by @TomFinley \r\n"""
410067404,2543,b'Exclude SamplesUtils from ML.NET nuget and make its own nuget',b'fixes #2277\r\n\r\n'
410060271,2541,b'Lockdown Microsoft.ML.StandardLearners public surface',b'fixes #2264\r\n\r\n**Reduces public API count from 529 to 303.**\r\n\r\n| Before | After |   \r\n|:-:|:-:|\r\n|![image](https://user-images.githubusercontent.com/1211949/52752493-e2a4b600-2fa7-11e9-99b6-80a4509d0409.png)|![image](https://user-images.githubusercontent.com/1211949/52752269-0fa49900-2fa7-11e9-8878-8b861ff27eea.png)|\r\n'
410031635,2539,b'Remove OpenInputFile and CreateOutputFile methods from IHostEnvironment',"b""Didn't add new tests since the implementation is just moved from HostEnvironmentBase to HostEnvironmentUtils class.\r\n\r\nOn a separate PR will remove CreateTempFile which still part of IHostEnvironment interface.\r\n\r\nRelated to: #1287\r\ncc: @eerhardt \r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
410010066,2537,"b'Rename CV and TrainTest ""stratification"" parameter'","b'This PR changes the `CrossValidation` and `TrainTest` parameter `StratificationColumn` to be `GroupPreservationColumn` and updates the docstrings to give a clearer explanation.\r\n\r\nFixes #2536 \r\n\r\nSee conversation in #2536 \r\n\r\nRelated to #1204, but that issue might be asking for further coverage.'"
409975049,2532,b'Lockdown Microsoft.ML.EntryPoints public surface',b'Fixes #2265 .'
409941980,2531,b'Hide InitialWeights in OnlineLinear trainers',"b""Fixes https://github.com/dotnet/machinelearning/issues/2519\r\nRelated to https://github.com/dotnet/machinelearning/issues/2527\r\nAlso fixes mess with Weights columns for OnlineLinear trainers. Only LinearSVM uses it, so all other trainers shouldn't accept weight as column"""
409926337,2529,"b'moving IEstimator, ITransformer ,IDataReader,  IDataReaderEstimator, \xe2\x80\xa6'","b'moving IEstimator, ITransformer, IDataReader,  IDataReaderEstimator, SchemaShape from Microsoft.ML.Core.Data to Microsoft.ML. \r\nThose were the only types in Microsoft.ML.Core.Data. \r\n\r\nThe change is mechanical, IMO you can just approve if the above sentence is not controversial. \r\n\r\nTowards #2326. \r\n\r\n\r\n'"
409666355,2528,b'Renaming .Train to .Fit in TrainerEstimators ',"b'Fixes #2527.\r\n\r\nAs further explained in the issue, there were two methods with two different names to train a TrainerEstimator. I renamed one of them so that the additional functionalities come with an overload.\r\n\r\nIn particular the methods `Train(IDataView trainData, IDataView validData)`, and `Train(IDataView trainData, IPredictor initialPredictor)` have been renamed to `Fit(...`.\r\n\r\n'"
409580785,2526,b'Update calibrator estimators to be more suitable.',"b'Fixes #2515, contributes towards #1871 and indirectly towards #2251.\r\n\r\n* Internalize infrastructure only interface ICalibratorTrainer.\r\n* Update calibrator estimators so they are a suitable replacement for calibrator trainers in the public surface, e.g., no longer take IPredictor.\r\n\r\nNote that I did not add a calibrator catalog, since:\r\n\r\n1. I believe @sfilipi already has assigned herself the issue #1871 to do so, and\r\n2. Real reason, I am lazy! \xf0\x9f\x98\x84\r\n\r\nCalibrator estimators now are configured by the score/label/optionally weight column, *except* for the fixed Platt estimator, which only takes score (since it is not trained).\r\n\r\nNote that ultimately the trainer estimator constructors *will* be internal, pending #1871.'"
409576610,2525,b'Fix an initial-value problem caused by unseen row/column',"b""Update LIBMF to have this [fix](https://github.com/cjlin1/libmf/pull/25). The problem is that when the largest row index in the training set doesn't match the number of rows in the specified matrix shape, rows' starting addresses may look like `[ptr_to_first_element_in_row_1, ptr_to_first_element_in_row_8, ptr_to_the_end_of_element_array, nullptr, nullptr]` but the correct value should be `[ptr_to_first_element_in_row_1, ptr_to_first_element_in_row_8, ptr_to_the_end_of_element_array, ptr_to_the_end_of_element_array, ptr_to_the_end_of_element_array]`.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/2488"""
409575973,2524,b'Store environment when creating new catalog entries ',"b'Fixes #2523 \r\n\r\nThe following changes are being made:\r\n\r\n1. Just _store_ the environment passed in , instead of creating subhosts\r\n2. Updated baselines to make tests pass\r\n\r\n'"
409555869,2518,b'Add Functional Tests for Data I/O',b'This PR adds functional tests for Data I/O\r\n\r\n- Reading from IEnumerable\r\n- Writing to IEnumerable\r\n- Writing to and reading from delimited tex files\r\n  - With inferred schema\r\n  - With explicit schema\r\n- Writing to and reading from Binary files\r\n\r\nFixes #2508 '
409555465,2517,b'Documentation for BinaryClassification.AveragedPerceptron (V2)',b'#2483 got messed up with a bad rebase. Recreating the PR here.\r\n\r\nDocs & sample for BinaryClassification.AveragedPerceptron. Related to #1209.'
409483340,2516,b'Adding a new ubuntu CI leg',b'Related To https://github.com/dotnet/machinelearning/issues/2381\r\n\r\nCurrently we are just running the tests on centos linux. A couple of libraries dont run on centos distro but run on ubuntu so we are adding a new ci leg to increase coverafe and run these tests on ubuntu'
409103426,2511,b'Lockdown Microsoft.ML.FastTree public surface',b'fixes #2266 \r\n\r\n**Reduces public API count from 1098 to ~~274~~ 237.**\r\n\r\n| Before | After |   \r\n|:-:|:-:|\r\n| ![image](https://user-images.githubusercontent.com/1211949/52609628-bddb0200-2e32-11e9-9687-212f6d2db92c.png) | ![image](https://user-images.githubusercontent.com/1211949/53034050-4bb47f80-3427-11e9-9036-062312dd02a1.png) ||\r\n\r\n'
409071847,2510,"b'Creation of components through MLContext, internalization, and renaming'","b'Fixes #1798, #1758 \r\n\r\n1. In this PR I internalize the constructors of `DnnImageFeaturizerEstimator`, `PriorTrainer`, and `RandomTrainer`. This required to add catalog extensions for these three trainers. Internalizing these constructor closes issue #1798. \r\n2. I also rename a few instances of `Arguments` to `Options` which closes issue #1758.\r\n3. I internalized some fields across `ITransformers` and `IEstimators`.\r\n4. I also moved the `Options` class in TensorflowTransform to the estimator. '"
409070226,2509,b'Internalize IDataTransform',"b'Hide the unhideable, bestfriend the unfrienable!\r\nfixes https://github.com/dotnet/machinelearning/issues/1995'"
408998651,2507,b'Get rid of value tuples in TrainTest and CrossValidation',b'Fixes #2501'
408996817,2506,b'Typed SDCA binary trainers',"b""Make `SdcaBinaryTrainer` strongly-typed according to the type it produces. The existing `SdcaBinaryTrainer` can produce either calibrated linear model or linear model as mentioned in #2469. To fix #2469, we move common functionalities used in both cases to `SdcaBinaryTrainerBase<T>` where `T` is `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator` for calibrated case and `LinearBinaryModelParameters` otherwise. Top-level APIs are changed accordingly. For dynamic/static APIs, we have 4 SDCA binary trainers for\r\n\r\n1. Calibrated linear model with simple arguments.\r\n2. Calibrated linear model with advanced options.\r\n3. Uncalibrated linear model with simple arguments.\r\n4. Uncalibrated linear model with advanced options.\r\n\r\nIn addition, because we don't like auto-calibration, the output schema in uncalibrated cases should not contain a probability column. This PR also fixes this in the two derived trainer classes' `ComputeSdcaBinaryClassifierSchemaShape`; the only case with a probability column generated is training logistic regression with Sdca. We also have two separated `SdcaCalibratedBinaryTrainer.Options` and `SdcaBinaryTrainer.Options` derived from `BinaryArgumentBase`. Legacy command-line tool and entry points are not affected by having `LegacySdcaBinaryTrainer`.\r\n\r\n"""
408990471,2505,b'Move IModelCombiner to Microsoft.ML.Data and Lockdown Microsoft.ML.Ensemble',"b""We have an implementation of IModelCombiner in Microsoft.ML.FastTree. This PR is to move the interface to Microsoft.ML.Data so that Microsoft.ML.FastTree doesn't need to reference Microsoft.ML.Ensemble.\r\n\r\nThis PR also internalizes most of the classes in Microsoft.ML.Ensemble. Fixes #2268 ."""
408987057,2504,b'Towards 1529: replacing the predicates with an IEnumerable on IRowToRowMapper.GetDependencies',"b'More work towards #1529. \r\n\r\nMarked the pr as still working on it, because there is one test failing: TestAndPredictoOnIris; double-checking the changes on the CompositeRowToRowMapper. \r\n\r\n\r\n\r\n'"
408972600,2503,b'Add validation scenario tests',b'This PR adds a test for training with a validation set.\r\n\r\nFixes #2499'
408931468,2497,b'Lockdown HAL Project',b'Fixes #https://github.com/dotnet/machinelearning/issues/2267'
408724660,2494,b'Update cookbook',b'Update a Cookbook section to switch the parameters for OneHotEncoding for issue #2485.'
408583803,2493,b'Add Light GBM sample',b'Add Light GBM sample as part of #1209.'
408562362,2491,b'Towards 2326: Microsoft.ML.Ensemble and Microsoft.ML.TimeSeries namespace rationalization',b'Organizing the Microsoft.ML.Ensemble and Microsoft.ML.TimeSeries as described in #2326 '
408350055,2483,b'Documentation for BinaryClassification.AveragedPerceptron',b'Docs & sample for BinaryClassification.AveragedPerceptron. Related to #1209.\r\n'
408170085,2481,b'Remove dead code in src/Microsoft.ML.FastTree/Application',"b'As proposed in #2468, this PR removes the unused code under `src/Microsoft.ML.FastTree/Application`. No other changes were made.'"
407987298,2476,b'Lockdown of Microsoft.ML.LightGBM public surface.',b'This PR fixes #2271. Fixes https://github.com/dotnet/machinelearning/issues/2534 fixes #2459\r\n\r\nThe changes included in this PR are as follows.\r\n1. Changed unnecessary `public` items to `internal`.\r\n2. Created samples in the samples project.\r\n3. Referenced the samples as an example in public API exposed through MLContext.\r\n4. Resolved a bug where one of the constructor of `LightGbmMulticlassTrainer` was using `MakeBoolScalarLabel` instead of `MakeU4ScalarColumn`.\r\n\r\n'
407972232,2475,b'TensorFlow: Fixed shape issue where unknown shape will be induced from data.',"b'This PR fixes #2458.\r\n\r\nThe problem addressed in this PR are\r\n1. Input is used to determine the shape. If there is one unknown dimension, it is computed from the input data. If there are several unknown dimension, the value computed from the input is equally distributed among unknown dimension.\r\n2. There is no batch dimension assumption on input now.\r\n3. Output shape are computed as previously done. However, if there are more than one unknown dimensions in the shape, a variable length vector is returned then.\r\n4. Created test to check for different type of shapes can be pass in and out of TF.\r\n'"
407937064,2470,b'Add a project for functional tests without visibility into internals of ML.NET',"b'This PR adds a new project, `Microsoft.ML.Functional.Tests` for adding end-to-end scenario tests for ML.NET. This project does not have visibility into the main library, and is not strongly named, so may not be added.\r\n\r\nTwo tests were also moved from `Microsoft.ML.Tests` into this project:\r\n- `CrossValidation`: Migrated with additional tests\r\n- `ReconfigurablePrediction`: Migrated but marked as `Skip` because Issue #2465 prevents us from completing the scenario.\r\n\r\nFixes #2306 '"
407549075,2453,b'More internalization of non-public Microsoft.ML.Data',"b""Yet another step along #1602, where much miscellaneous internal infrastructure in Microsoft.ML.Data gets hidden, or even in some cases removed. I think this round removed about 600 or so public members or thereabouts. (Though TBH about 500 of that was just due to `IEvaluator` implementations alone).\r\n\r\nSome of the commits are very small (e.g., internalize vector utils is more or less what it sounds like), whereas others are more involved.\r\n\r\nCrucially, prediction transformers are no longer generic on the scorers, and all scorers are internal. This is related to #1995, since scorers were `IDataTransformer` implementors, so this is another place where we're removing things related to this deprecated interface from our public surface.\r\n\r\nI also took the opportunity to do some opportunistic changing of the tests to use more of the public surface area, as opposed to the non-public APIs, especially around text writing. Incidentally filed #2452 as a side effect of that work."""
407519233,2451,b'Internalize and cleanup recommender project',b'fixes #2276'
407503468,2450,b'ValueMappingEstimator documentation update',"b""Adds a type='bullet' tag to the documentation for ValueMappingEstimator so that the bulleted list will render correctly.\r\n\r\nFixes #2447"""
407498159,2449,b'Remove unnecessary JIT workaround',b'Fixes https://github.com/dotnet/machinelearning/issues/1247\r\n'
407486170,2448,b'Updates ml.net reference of LightGBM to version 2.2',"b""- Updates ml.net reference of LightGBM to version 2.2.3 (Fixes #2446)\r\n- Updated the lightgbm parsing code to handle inf, -inf (now checks for\r\ncontains rather than equals).\r\n- Additional updates for handling NaN\r\n- Moved all LightGBM baseline tests from SingleDebug/SingleRelease to\r\nCommon.\r\n- Added Seed parameter to LightGBM arguments to support setting\r\nLightGBM's random seed."""
407443599,2442,b'Towards #2326 - removing some namespaces',"b'Replacing the following namespaces as described in #2326:\r\n\r\nMicrosoft.ML.Internal.Internallearn.ResultProcessor \r\nMicrosoft.ML.Trainers.FastTree.Internal,\r\nMicrosoft.ML.Learners, \r\nMicrosoft.ML.Trainers.SymSGD.'"
407442961,2441,b'Make DataOperations catalog names more precise',"b'This PR adds the word ""Rows"" to names in `DataOperations` catalog where the use may be ambiguous, e.g. between Rows, Columns, and Slots.\r\n\r\nFixes #2440 '"
407431051,2439,b'Allowing SelectColumns to take a bare list of columns',"b'This PR overloads `SelectColumns` so that it can be used with a bare list of columns. The original API is changed to remove `keepHidden`, as this new API has the default behavior.\r\n\r\nThe PR also cleans up the sample, which had mismatches between the actual and expected outputs.\r\n\r\nFixes: #2371 '"
407365927,2436,b'Add Skip and Take filters',"b'This PR adds the Skip and Take filters to the `DataOperations` catalog in `MLContext`, with corresponding samples. It also adds direct constructors for `Skip` and `Take` to the `SkipTakeTransform` in the style of the other filters in ML.NET.\r\n\r\nFixes #2401'"
407364026,2435,b'Typed Calibrated Predictors',"b'There are some [problems ](https://github.com/dotnet/machinelearning/issues/2378)around weekly-typed calibrated predictor, if we want to expose those trained calibrated predictor to users. To expose trained predictor in a type-safe manner, this PR adds two type parameters to `CalibratedPredictorBase`; that is,\r\n```csharp\r\n    /// <summary>\r\n    /// <see cref=""IWeeklyTypedCalibratedPredictor""/> provides a weekly-typed way to access strongly-typed\r\n    /// <see cref=""CalibratedPredictorBase{TSubPredictor, TCalibrator}.SubModelParameters""/> and\r\n    /// <see cref=""CalibratedPredictorBase{TSubPredictor, TCalibrator}.Calibrator""/>.\r\n    /// <see cref=""IWeeklyTypedCalibratedPredictor""/> is commonly used in weekly-typed expressions. The\r\n    /// existence of this interface is just for supporting existing codebase, so we discourage its uses.\r\n    /// </summary>\r\n    [BestFriend]\r\n    internal interface IWeeklyTypedCalibratedPredictor\r\n    {\r\n        IPredictorProducing<float> WeeklyTypedSubModelParameters { get; }\r\n        ICalibrator WeeklyTypedCalibrator { get; }\r\n    }\r\n\r\n    public abstract class CalibratedPredictorBase<TSubModelParameters, TCalibrator> :\r\n        IDistPredictorProducing<float, float>,\r\n        ICanSaveInIniFormat,\r\n        ICanSaveInTextFormat,\r\n        ICanSaveInSourceCode,\r\n        ICanSaveSummary,\r\n        ICanGetSummaryInKeyValuePairs,\r\n        IWeeklyTypedCalibratedPredictor\r\n        where TSubModelParameters : class, IPredictorProducing<float>\r\n        where TCalibrator : class, ICalibrator\r\n    {\r\n        ...\r\n        // Strongly-typed members.\r\n        public TSubModelParameters SubModelParameters { get; }\r\n        public TCalibrator Calibrator { get; }\r\n\r\n        // Type-unsafed accessors of strongly-typed members.\r\n        IPredictorProducing<float> IWeeklyTypedCalibratedPredictor.WeeklyTypedSubModelParameters => SubModelParameters;\r\n        ICalibrator IWeeklyTypedCalibratedPredictor.WeeklyTypedCalibrator => Calibrator\r\n        ...\r\n    }\r\n```\r\nand make changes making the code complied. This PR doesn\'t make every use of `CalibratedPredictorBase` type-safe, because there are some functionalities built upon C# interface.\r\n\r\nFix #2378, Fix #1307.'"
407320745,2434,b'Add analyzer for detecting BestFriend usages on public declarations',"b""As proposed in #2415, the `BestFriend` attribute should never be applied to public declarations. While this is not a problem per se it still introduces unnecessary noise. I implemented a code analyzer that will flag these occurrences as errors whenever a `[BestFriend]` attribute is applied to a:\r\n\r\n1. public class/struct/enum/interface\r\n2. public method/property/field/delegate\r\n3. public constructor\r\n\r\nI didn't implement an automated code fix for this diagnostic as fixing the problem is trivial - either remove the attribute or make the declaration internal. If we still want a code fix to be created I'll gladly take care of that as well.\r\n\r\nFixes #2415."""
407168220,2432,b'Update the parameters description in the summary as described in the issue 2177',"b""Fixes #2177 \r\n\r\nThe description of the parameters have been updated as described by @sfilipi in issue #2177 \r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [X ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ N/A] You have included any necessary tests in the same PR.\r\n\r\n"""
407120560,2431,b'ITransformer derives from ICanSaveModel and explicit implementation for ICanSaveModel',"b'Fixes  #2336.\r\n\r\nThis PR makes `ITransformer` derive from `ICanSaveModel`. The reasons for changing the core `ITransformer/IEstimator/IDataView` API are illustrated in more detail in the issue #2336. But this essentially captures the idea that once trained the model should be savable. \r\nFor this change I moved `ICanSaveModel, ModelSaveContext, ModelLoadContext` and a few related utility files to Microsoft.ML.Core as `ITransformer` lives in that assembly.\r\n\r\nThe second dimension of this change is the explicit implementation of the interface `ICanSaveModel` everywhere. This will make it a requirement to cast the classes to `ICanSaveModel` in order to access the method `Save(ModelSaveContext ctx)` so that it is less visible. I have covered the entire code base with my changes, including some classes that are internal and others that I think should be made internal shortly. This makes my change touch ~140 files. I decided to do so in order to make the way we implement the `ICanSaveModel` interface consistent everywhere.'"
407047712,2429,b'Moved TensorFlow samples to its own directory in Samples project.',"b'This PR addresses following issues\r\n\r\n1. Moved TF sample to `TensorFlow` folder in samples project.\r\n2. Renamed the files to meaningful name.\r\n3. Added a text classification sample.\r\n4. Updated TensorFlow.Redist nuget to latest in samples project.\r\n\r\n@sfilipi, @shmoradims and @rogancarr, let me know if this move can be a problem for any documentation referencing it.\r\n\r\n'"
407045017,2428,b'Minimum Vector size check added',"b'Fixes https://github.com/dotnet/machinelearning/issues/2253\r\n\r\nThe new c# implementation is slower for inputs of smaller size, so adding a size constraint for using these new c# apis\r\n\r\n'"
407029270,2427,b'Adding Shuffle to the catalog',"b'This PR adds `Shuffle` to the catalog, along with a sample. It also marks `RowShufflingTransform` `internal`.\r\n\r\nFixes #342 '"
407013711,2426,b'Make KeyToValueMapping API consistent',"b'Fixes #2376 \r\n\r\nMakes KeyToValueMapping API consistent with the rest by using the `string outputColumnName, string inputColumnName = null` signature in the `MapKeyToValue` method in `ConversionsExtensionsCatalog` and the associated `KeyToValueMappingEstimator` and `KeyToValueMappingTransformer` constructors.'"
406993497,2424,b'Add MissingValueFilter (NAFilter) to the DataOperations catalog',b'This PR adds the `MissingValueFilter` (aka `NAFilter`) to the `DataOperations` catalog along with a sample of its use.\r\n\r\nFixes #2400 '
406933821,2421,b'Update release for 0.10',b'Updating the 0.10 release'
406918852,2419,b'Mechanical rename of Schema to DataSchema.',"b""Mechanical rename of Schema to DataSchema, through VisualStudio's rename. \r\n\r\nCloses #1500\r\nThis is the last item in the list of items for #1500. \r\n\r\n@TomFinley @eerhardt valuable to do this,  at this time?\r\n\r\n"""
406644801,2417,"b'Textloader internalizations, documentation, and Arguments refactoring'","b'Fixes #2046.\r\nRelated to #1798.\r\n\r\nThis PR does the following:\r\n\r\n1. Addresses the problem raised by #2046 by creating a single `Arguments` class from the original two classes `Arguments` and `ArgumentsCore`. The issue suggested the first approach out of two possible ways to do this, which is the one I followed in this PR.\r\n2. Renames `Arguments` to `Options`.\r\n3. Internalizes the constructors and other fields that should not be in the public API.\r\n4. Adds comments for all public fields and methods. \r\n'"
406626311,2416,"b""ValueMapper: added more tests with 'TestEstimatorCore' and fixed a bug in ValueType.""",b'This PR fixes #2412 and #2410.\r\n\r\n1. Added tests to check schema propagation in `ValueMapperEstimator` and `ValueMapperTransformer` with `TestEstimatorCore`.\r\n2. Fixed a bug that was causing an exception when `ValueMapperEstimator.GetOutputSchema` is called; given that ValueType is a vector.\r\n3. Properly returning output schema based on whether the ValueType  is fixed length or variable length vector.\r\n'
406608841,2414,b'Add release notes for ML.NET 0.10',b'Adding release notes for 0.10'
406583570,2411,b'ResNet Tests corrected for netfx',b'Fixes https://github.com/dotnet/machinelearning/issues/2373\r\n\r\nThe behavior of GetExecutingAssembly is different on netFramework. It return a temp path on .netFramework\r\n\r\nThis problem also occurred while enabling tests for netfx.\r\n'
406565003,2409,b'Fix loading type problem for netfx',"b""Fixes https://github.com/dotnet/machinelearning/issues/2104\r\n\r\nA couple of types doesn't get loaded properly by Maml commands on netfx. So we have to register them manually.\r\nWe are doing a similar things for maml commands in our benchmarks.\r\nThese tests fail on netfx and are being enabled in https://github.com/dotnet/machinelearning/pull/2402\r\n"""
406527317,2408,b'Add release notes for ML.NET 0.10',"b'This adds release notes for 0.10.\r\nPlease, review and provide additional topics to be highlighted for 0.10, changes in the current topics or even suggest to remove any topic if it is not relevant enough.\r\n\r\nThanks,'"
406497634,2406,b'Add a sample for the Cache command',b'This PR adds a sample for the Cache command and updates the xml docs for the Cache catalog entry.\r\n\r\nFixes #2399 '
406481989,2405,b'Add samples and update docs for RangeFilter APIs',b'This PR adds a sample for `FilterByColumn` and `FilterByKeyColumnFraction` and updates their docs.\r\n\r\nFixes #2398\r\n'
406469835,2404,b'Begin hiding the IPredictorProducing',"b""Towards but not quite finishing #2251. Why not finish? At issue is that we must resolve #2378 in some fashion (TBD) before we continue, but as it is I think this is a move in the right direction. The public surface using this interface has now been reduced considerably, but of course not quite completely eliminated. So this is *not* a work in progress, but I didn't want to leave such a big change lying around.\r\n\r\nFirst commit internalizes the (less used) `IDistPredictorProducing`, while the second does some but not all of the work of internalizing `IPredictorProducing`."""
406441353,2402,b'Replace ConditionalFact usages with custom facts',"b'As proposed in #1220, this PR replaces all usages of `ConditionalFact` in tests with custom-tailored, environment-specific facts.\r\n\r\nThese specific facts all inherit from a single base `EnvironmentSpecificFactAttribute`. Several of the facts check the same condition (e.g. TensorFlow, Onnx, and X64 - they all simply check for X64 process) but I decided not to merge them - they might check the same thing now but I expect they might branch out later on. I consider the small duplication of code not worth the mental overhead of inheritance or composition here.\r\n\r\nTogether with this I also removed some now-obsolete checking of platform in Onnx-related tests (they were all Windows-only anyway) and removed the old `OnnxFact`.\r\n\r\nFixes #1220.'"
406135079,2395,b'Fix build',b'fix current build after merges'
406127430,2394,b'Creation of components through MLContext and cleanup (text transform)',"b'Towards #1798 , #1758\r\n\r\nThe following transform estimators are being addressed:\r\n- TextFeaturizingEstimator\r\n\r\nNOTE:  \r\n- for fixing the **text transform** API we have to incorporate the  API patterns we followed for fixing the _learner estimators_  +  the patterns we are following for fixing the _transform estimators_ \r\n- This is because the text transform was using a Action<Settings> delegate  (like some of the _learner estimators_).  \r\n\r\nThe changes are as follows :\r\n\r\n1. Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Internalize constructors of estimators and transformers \r\n3. Pass `Options` objects as arguments instead of `Action` delegate \r\n4. Rename `Settings` to `Options` \r\n5. Rename `Options` objects as options (instead of args or advancedSettings used so far)\r\n6. Internalize `Arguments` since the public constructor uses `Options`. Also a few other fields have been made `internal`\r\n \r\n\r\n'"
406115655,2393,b'Creation of components through MLContext and cleanup (text related transforms)',"b'Towards #1798 , #1758, #1760\r\n\r\nThe following transform estimators are being addressed:\r\n- LatentDirichletAllocationEstimator\r\n- WordEmbeddingsExtractingEstimator\r\n- TokenizingByCharactersEstimator\r\n- WordTokenizingEstimator\r\n- WordBagEstimator\r\n- WordHashBagEstimator\r\n- NgramExtractingEstimator\r\n- NgramHashingEstimator\r\n- StopWordsRemovingEstimator\r\n- CustomStopWordsRemovingEstimator\r\n- TextNormalizingEstimator\r\n\r\nThe changes are as follows :\r\n1. Internalize constructors of estimators and transformers #1798\r\n2. Rename `Arguments` -> `Options` #1798\r\n3. Internalize `Options` when they are not used by public constructor. #1758 \r\n4. Rename `Options` objects as `options` (instead of `args` or `advancedSettings` used so far) #1798\r\n5. Move ColumnInfo to the estimators #1760\r\n\r\n'"
406109831,2392,b'Fix naming of Options argument in  TensorFlowTransform API',b'Fixes #2391 \r\n\r\n- Renamed `Options` argument of the TensorFlowTransform API to `options`\r\n\r\n'
406108470,2390,b'Modify API for advanced settings (RandomizedPcaTrainer)',b'Towards #1798 . \r\n+ adds MLContext extension for Anomaly detection Issue #1369\r\n+ fixes #2471 \r\n\r\nThis PR addresses the following algos\r\n\r\n- RandomizedPcaTrainer\r\n\r\nThe following changes have been made:\r\n\r\n- Make constructors internal .\r\n- Rename Arguments to Options\r\n- Rename Options objects as options (instead of args or advancedSettings used so far)\r\n\r\n\r\n'
405989462,2388,b'Support buld using VS2019',"b'CMake shipped with VS does not support VS2019 yet, so run generator for VS 2017. It will still build using VS 2019\r\n\r\nCloses: #1967'"
405953114,2387,b'Adding a catalog entry for the bootstrap sample',b'This PR adds a catalog entry for the bootstrap sample and creates a sample demonstrating its use.\r\n\r\nFixes #2384 '
405940316,2386,b'Fixed output schema produced by ValueMappingEstimator',b'\r\nThis PR fixes #2385.'
405923073,2383,b'Internalize IDataTransform',b'towards #1995 '
405922878,2382,b'MLContext catalog cleanup',"b""End-users will use ML.NET mainly through MLContext. As part of documentation cleanup, I started from MLContext and cleaned up the top level catalogs as follows:\r\n\r\n* Internal catalog constructors: All catalog constructors are made internal, since the user shouldn't be creating those objects.\r\n* `protected internal` for some fields: doc.microsoft includes `protected` fields/methods (like [Host field here](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcontext?view=ml-dotnet#fields)). Since all our catalogs are sealed, I changed some `protected` fields/method to `protected internal` so that they don't get mentioned in the docs at all. \r\n* Xml cleanup: Fixed some incorrect/missing texts along the way.\r\n"""
405918527,2380,b'Add a sample to SelectColumns',b'This is a small PR to address documentation and samples.\r\n- Added a sample to SelectColumns\r\n- Fixes a bug in a sample link for ConcatTransform.\r\n\r\nFixes #2370  '
405846374,2374,b'Lockdown Microsoft.ML.PCA public surface',b'fixes #2275 '
405831582,2372,"b'Image analytics documentation, samples, internalization'","b'Addressing both:\r\n\r\n#1209  in the first commit by adding samples, and documenting the classes and the extensions better. \r\n#1798 in the second commit by:\r\n1- Internalizing constructors of estimators and transformers\r\n2- Keep ColumnInfo and move it to to the estimators #1760\r\n3- Rename Arguments -> Options'"
405800686,2369,b'Address minor comments in #2243',b'This paper continues addressing some small comments left in #2243.\r\n\r\n'
405727166,2368,b'WIP: Making TrivialEstimator an ITransformer',"b'Fixes #2354.\r\n\r\nAs elaborated in the issue, it can be unintuitive to a `.Fit()` step for non trainable estimators/transformers. \r\nIn this PR, I make the base class of most trivial estimators an `ITransformer`.\r\n\r\nNext steps for the PR:\r\n1. Identify the trivial estimators that don\'t implement `TrivialEstimator` and make them derive from that.\r\n2. Consider whether it is worth it to rename the trivial estimators, including ""Transformer"" in their name. Something like ""ActionPerformingTransformerEstimator"".\r\n3. Add some tests.\r\n\r\n\r\n'"
405716585,2367,"b'Creation of components through MLContext and cleanup (Onnx, Tensorflow, SelectColumn, KeytoBinVec, ValueMap)'","b'This PR is part of the work outlined in #1798, and focuses on the GcnNorm, LpNorm, RandomFourier, CustomStopWords, VectorWhiten, PCA transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep ColumnInfo and move it to to the estimators #1760\r\n3. Rename Arguments -> Options\r\n4. Internalize Options only when they are not used by public constructor. For all other cases, retain Options as public #1758 \r\n\r\nThis PR is marked as WIP because I have to figure out how to make the DNN assemblies BestFriends with the ONNX assembly. I need to figure out how to do that.'"
405653036,2366,"b'Creation of components through MLContext and cleanup (GcnNorm, LpNorm, RandomFourier, CustomStopWords, VectorWhiten, PCA)'","b'This PR is part of the work outlined in #1798, and focuses on the GcnNorm, LpNorm, RandomFourier, CustomStopWords, VectorWhiten, PCA transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep ColumnInfo and move it to to the estimators #1760\r\n3. Rename Arguments -> Options\r\n4. Internalize Options only when they are not used by public constructor. For all other cases, retain Options as public #1758\r\n\r\nfixes #2275  \r\n\r\nIf I wrote (not a ITransformer) on the #1798 issue, and this PR number appears on the same line, I renamed the Arguments to Options, and tried to make it internal.'"
405615891,2365,"b'Creation of components through MLContext and cleanup (Convert, DropSlots, FeatureSelection)'","b'This PR is part of the work outlined in #1798, and focuses on the Convert, DropSlots, CountFeatureSelection, MutualInformationFeatureSelection, FeatureContributionCalculationTransform,  PermutationFeatureImportanceTransform, MissingValueDropping, TreeEnsembleFeaturizationTransform transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep ColumnInfo and move it to to the estimators #1760\r\n3. Rename Arguments -> Options\r\n4. Internalize Options only when they are not used by public constructor. For all other cases, retain Options as public #1758\r\n'"
405594181,2364,"b'Creation of components through MLContext and cleanup (OneHotHash, Hash, CopyCol, KeyToVector)'","b'This PR is part of the work outlined in #1798, and focuses on the OneHotHash, Hash, CopyCol, KeyToVector transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep ColumnInfo and move it to to the estimators #1760\r\n3. Rename Arguments -> Options\r\n4. Internalize Options only when they are not used by public constructor. For all other cases, retain Options as public #1758\r\n'"
405588724,2363,"b' Creation of components through MLContext and cleanup (Concat, Normalizer, NA Indicator/Replace) '","b'This PR is part of the work outlined in #1798, and focuses on the Concat, Normalizer, NA Indicator/Replace  transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep ColumnInfo and move it to to the estimators #1760\r\n3. Rename Arguments -> Options\r\n4. Internalize Options only when they are not used by public constructor. For all other cases, retain Options as public #1758\r\n'"
405582489,2362,b'Add ResizingMode.Fill to ImageResizerTransformer',"b'This PR adds a new resizing mode to the `ImageResizerTransformer`. This mode is called `Fill` and when used, the transformer ignores aspect ratio and squeezes/stretches the source image into the target dimensions.\r\n\r\nThe idea for this mode came up in #2022 - when attempting to score a Keras-trained model it turned out that Keras resizes images in a way that ML.NET cannot do on its own. To increase interoperability, the Fill mode was proposed.\r\n\r\nI also included a test for the new mode. This tests uses a specially prepared image, runs the resizing transformation, and then checks whether the result fulfills the specification for the resizing mode.\r\n\r\nFixes #2022\r\n'"
405570040,2360,b'Fix locale-sensitivity for float.Parse calls in CpuMathUtilsUnitTests',"b'As discussed in #2342, the tests in `CpuMathUtilsUnitTests` are culture-sensitive due to `float.Parse` calls which do not specify format providers.\r\n\r\nI updated the calls to be `float.Parse(x, CultureInfo.InvariantCulture)`. Now the tests pass even on my Slovak locale which uses comma (`,`) as a decimal separator.\r\n\r\nFixes #2342 '"
405526616,2359,b'Update OnnxRuntime to 0.2.1',"b'Updating to onnxruntime lib 0.2.1 (containing corrected github hash commit id, to match the release tag)'"
405506595,2357,b'Add a sample for DropColumns',b'This PR adds a sample for DropColumns.\r\n\r\nFixes #2353 '
405499370,2355,b'Enabling the OnnxRuntime disabled tests',b'Related to https://github.com/dotnet/machinelearning/issues/2106\r\n\r\nThese tests were fixed by the above issue but not enabled\r\n\r\n'
405483312,2351,b'Add a sample for copy columns.',"b'This PR adds a sample for copy columns, and moves the SchemaManipulation transform samples under a Transforms/ folder.\r\n\r\nFixes #2350 '"
405475113,2349,b'Added more information and fixed the rendering issue with documenation.',"b'This is a small fix, therefore does not require an issue.\r\n\r\nThis fixes the rendering issue on https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowtransform?view=ml-dotnet\r\n\r\nAlso, added bit of description regarding retraining of the model and whats not possible.'"
405424263,2347,b'Updating the netcoreapp sdk to latest version',b'\r\n'
405388916,2345,b'Handle lightgbm output in different locales properly',b'fixes https://github.com/dotnet/machinelearning/issues/2263'
405385495,2344,b'Lockdown Microsoft.ML.TimeSeries public surface',b'fixes #2281\r\n\r\n**This change reduces TimeSeries public API count from 371 to ~~124~~ ~~58~~ 57.**\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/52497276-834f3c00-2b8a-11e9-8678-23b5043a3040.png)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/52245620-4556cd00-2897-11e9-8d5d-df2d9d75ccd7.png)\r\n\r\n'
405225516,2343,b'Remove XmlIncludes',b'Remove `XmlInclude`s from entry point attributes.\r\n\r\nFixes #2325 \r\n'
405051278,2340,"b'Creation of components through MLContext and cleanup (KeyToValue, ValueToKey, OneHotEncoding)'","b'This PR is part of the work outlined in #1798, and focuses on the KeyToValue, ValueToKey, OneHotEncoding transformers/estimators:\r\n\r\n1. Internalize constructors of estimators and transformers\r\n2. Keep `ColumnInfo`\r\n3. Rename `Arguments` -> `Options`\r\n4. Internalize `Options` only when they are not used by public constructor. For all other cases, retain Options as public\r\n5. Move `ColumnInfo` to the estimators\r\n\r\n\r\nThis is meant to be a test PR. Once we agree on the format, I will be more confident in doing the remaining.'"
405036328,2339,b'Clarify documentation for WordEmbeddings and provide sample.',b'Fixes https://github.com/dotnet/machinelearning/issues/2068'
404978030,2334,b'Internalize ITransformTemplate',b'Towards #1995 '
404931746,2331,"b""Fix fake schema's creation and add a test""",b'Fix #2322 and add a test.\r\n'
404931095,2330,b'Monotone constraint  support for LightGBM',"b'This add the ability to set the monotone_constraints argument for\r\nLightGBM. This is done through the LightGBM Options class via the\r\nMonotoneConstraints member. To handle the monotone constraints, this\r\nadds the ability to specify whether to use a positive constraint or a\r\nnegative constraint along with a range. Multiple ranges can be\r\nspecified.\r\n\r\nThis checkin also includes tests for the parsing of the ranges to\r\nvalidate the expected value that will be passed to LightGBM.\r\n\r\nThis fixes #1651.'"
404924583,2329,b'Internalize IDataSaver interface',b'Towards #1995'
404904644,2327,b'add adult test and train datasets',b'add adult test and train datasets to test/data. They are referenced in the docs but no longer there.\r\n\r\n'
404867763,2324,b'fixing a link in the cookbook',"b'Small fix to the file name, since links are case sensitive. \r\n\r\n'"
404862898,2323,b'Removed Read methods taking string parameters from TextLoader (#1797)',b'Unsure about the naming of `LocalPathReader` but I kept it the same due to the requirement that it be namespaced to `Microsoft.ML` - `DataViewExtensions` already exists and is in the `Microsoft.ML.Data` namespace.\r\n\r\nFixes #1797.'
404618601,2321,b'Bump master to 0.11',b'Updating the version on Master to 0.11'
404617699,2320,b'Merge master into release/preview for 0.10',b'This PR merges master into release branch for 0.10'
404554902,2317,b'Link to the concat transform sample in the catalog',b'Adding a link to the concat sample; adding a bit more explanation in the concat sample.\r\n\r\nFixes #2316 '
404534964,2314,b'Simple fix to make error message more clear',"b""Fixes #966.\r\n\r\nFirst, I further investigated and we don't use short names in error messages.\r\nThe issue #966 was pointing to an internal utility function that calculates the `probit`. The error message was not particularly useful which probably led to this concern.\r\n\r\nIn this PR, I change the error message to make the error a bit more clear and close the issue."""
404513875,2312,b'Lockdown Microsoft.ML.TensorFlow public surface',b'fixes #2280 '
404489044,2309,b'Internalize IDataLoader',b'Towards #https://github.com/dotnet/machinelearning/issues/1995'
404483802,2308,b'Upload coverage files only when all tests pass.',b'Sometimes not all tests pass and coverage files with missing data is uploaded to codecov and this changes the baseline of the master repo and causes all sorts of fluctuations in the coverage report both in PR and on the main page.\r\n'
404473260,2307,b'Update Microsoft.Data.DataView nuget metadata.',b'Fix #2289'
404434004,2304,b'Re-enable push to myget',b'The issue is fixed so we can enable myget push again.\r\n\r\nhttps://github.com/dotnet/core-eng/issues/5070'
404222953,2303,b'Removed python naming conventions from samples - closes #2155',b'Fixes #2155 - C# samples should use C# naming conventions and not python naming conventions. Second PR on this issue because last PR had issues\r\n\r\n'
404125830,2302,b'Added a test showing example of text classification using TensorFlow in ML.Net',b'This PR fixes #2301.\r\n\r\nAlso updated the TensorFlow runtime  from 1.10.0 -> 1.12.0'
404084415,2300,b'Hide much infrastructure in data',"b'Another of many steps towards #1602. Commits logically structured. No overall theme, just lots of hiding of individual components, most notably command line parsing, entry-point declarations, and other such things.'"
404069354,2296,b'Follow up from Extract IDataView feedback',b'@stephentoub left some PR comments on #2220 after it was merged. Addressing those comments here.'
404066674,2295,b'Fix TextLoader version number for KeyType backward compatibility and added new test',"b""Fixes #2294.\r\n\r\nI fixed the version number that's used to recognize and load the old `TextLoader` format.\r\n\r\nI also add a test to check that the code for `TextLoader` is actually backward compatible. I created a pipeline that contains a `TextLoader` that loads a `KeyType` using a version of the code prior the changes to `KeyType` and loaded it with the new code checking for the expected behavior.\r\n\r\n\r\n"""
404033647,2290,b'Exclude files not authored by ML.NET from code coverage',"b""Doesn't make sense to include ONNX ML autogenerated C# to protobuf file generator and Tensorflow sharp files as part of code coverage. \r\n\r\n"""
404014393,2287,b'Fix build break.',"b""My latest change conflicted with @TomFinley's latest change. They both passed separately, but failed together.\r\n\r\nAdding a using statement fixes the build."""
404002654,2285,b'Remove slash from PackagePath',b'fixes #2255'
404000785,2284,b'Creating the MLNetCookBook_StaticApi.md and updating the current cookbook',"b'Creating the MLNetCookBook_StaticApi.md. The document contains the same content and the MLNetCookBook.md, but the sample code uses the static API.\r\n\r\nUpdating the official cookbook to remove the static API samples, and leave just the dynamic API ones.\r\n\r\nFixes: #2210 \r\n'"
403873605,2262,b'Remove ZLib APIs',"b'This code is not being called by ML.NET, and it was not intended to be public API. Removing.\r\n\r\nFix #2249'"
403640465,2261,b'Modify API for advanced settings (LightGBM)',"b'Towards #1798 .\r\n\r\nThis PR addresses the following algos \r\n\r\n- LightGbmRegressorTrainer\r\n- LightGbmBinaryTrainer\r\n- LightGbmRankingTrainer\r\n- LightGbmMulticlassTrainer\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` .  Also a few other fields have been made `internal`\r\n3. Pass Options objects as arguments instead of Action delegate. Also, added  3 fields to `Options`  for API consistency. \r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)\r\n'"
403618906,2259,b'Fix disabled code coverage for src folder.',"b""Seems like #2200 broke code coverage for src folder, hence production coverage is not being generated and even the codecov badge on the main isn't displaying any coverage. \r\n\r\nfixes #2258 \r\n"""
403562970,2256,b'Add a binary logistic sample',"b'Add a binary logistic sample using the adult dataset to update issue #1362 \r\n\r\n@sfilipi Hopefully, this looks good, but just let me know if anything should be changed.'"
403401444,2254,b'Move IDataView to Microsoft.Data.DataView namespace.',b'Renaming the namespace of the IDataView types.\r\n\r\nFollow up to #1860 \r\n\r\nI also added a few copyrights where they were missing.'
403365063,2250,b'Expose schema for prediction engine',"b""towards https://github.com/dotnet/machinelearning/issues/2233\r\nI don't think our current work with metadata is best thing we can offer to the users, but at least this changes can unblock whole possibility to lookup into metadata for prediction engine.\r\n@TomFinley  @CESARDELATORRE """
403347041,2248,b'Enabling the tests to run on netcoreapp3.0 without Intrinsics',b'The 3.0 is supported on ci as well as local environments.\r\n\r\nThe change will enable people to run the tests with netcoreapp3.0 and have the possibility of using the native implementation of cpumath functions\r\n\r\nIt helps to distinguish between the regressions caused by netcoreapp3.0 or new Intrinsics'
403263774,2246,b'Disable publishing to myget',b'Fix #2244\r\n\r\n\r\n\r\n'
403262592,2245,b'No loader on APIs for ValueToKey/OneHotEncoding',"b'Fixes #2231. We should work to scour this more thoroughly once the changes to allow non-public settings objects on `Arguments`/`Settings` classes goes in.\r\n\r\nAlso: I had thought another estimator (stopwords) did not have loader as part of its name as I had thought, but I still fixed the name.'"
403247315,2243,b'Public Interface of RegressionTree and TreeEnsemble',"b'This PR proposes some changes to make RegressionTree and TreeEnsemble not mutable to users. Our strategy is\r\n\r\n1. Create wrapper classes `RegressionTree` and `TreeEnsemble` over their internal relatives. Those wrapper classes are not mutable.\r\n2. Internalize everything (around `InternalRegressionTree` and `InternalTreeEnsemble`) which should not be public.\r\n3. Internalize public constructors such as `FastForestClassificationModelParameters`, `FastForestRegressionModelParameters`, etc.\r\n4. Some cleaning. For example, changing `Float` to `float` and removing unused `using` statements.\r\n\r\nHopefully this will fix #1960.'"
402963382,2241,b'Make sure seed works for stratification column in TrainTest and CrossValidate',b'I hope this is final nail into #1635.\r\nFixes #1635 '
402962982,2239,b'Input output swap',"b'Fixes issue #2064 \r\n\r\n1- Change the order of the parameters from inputColumn, outputColumn to outputColumnName, sourceColumnName. \r\n\r\n2 - Changing the ""source"" parameter name and field in the Columninfo classes, to be ""sourceColumnName"", as suggested.\r\n\r\n3- Changing the ""name"" parameter to ""outputColumnName"" in the:\r\n- estimator extension APIs\r\n- estimator ctors\r\n- column pairs expressed through tuples, because in context it reads better than name.\r\n\r\nNote: in the columnInfo classes i left it to ""name"" because ""outputColumnName"" makes no sense.\r\n\r\n4 - Nit on standardizing the XML comments.\r\n5 - Arranging the order of the parameters to be: outputColumnName, required parameters, nullable sourceColumnName.\r\n6 - fixed some bugs i bumped into. \r\n'"
402936797,2236,b'Add sample for stop words removing.',b'Addresses #1996'
402933005,2235,b'Enhance code coverage bot message.',b''
402924395,2234,b'Adding attribution info for the Iris dataset',b'Adding attribution info for the Iris dataset\r\n'
402862049,2232,b'ValueMapperTransformer: Added support for loading map from file through dataview.',b'This fixes #2162. This is the 2nd part where the support for loading the mapping from file is added.'
402813009,2230,b'Enable test coverage',b'This change works around tonerdo/coverlet#318 to immediately enable correct coverage for test code.'
402791302,2229,"b'Revert ""exclude test folder from codecov.""'",b'Reverts dotnet/machinelearning#2227\r\n\r\nPossibly blocked on tonerdo/coverlet#318 (though I would not personally block on that issue).'
402646345,2228,b'Fix a bug in `ColumnTypeExtensions.SameSizeAndItemType()`',"b""Hi,\r\n\r\nI came across this when looking at the alerts for this project on LGTM.com (full disclosure: I work on the C# analysis there). It appears to have been introduced recently on https://github.com/dotnet/machinelearning/pull/2131.\r\n\r\nYou can see the original alert on LGTM.com here: https://lgtm.com/projects/g/dotnet/machinelearning/alerts/?mode=tree&lang=csharp&ruleFocus=1506097706076\r\n\r\nBest regards,\r\nTom\r\n\r\n(I will leave these bits below unfilled until you've determined whether this is actually a bug fix or not...)\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
402541247,2227,b'exclude test folder from codecov.',b'\r\n\r\n'
402520887,2226,b'hot fix.',"b'Fix master branch, since it broke with changes from @zeahmed.\r\n'"
402515556,2225,b'merge opencover reports into one Cobertura report and upload to codecov.',b'\r\n'
402514629,2224,b'Make changes necessary to build internal repo',b''
402505403,2222,b'ValueMappingEstimator example',b'This provides an example that demonstrates different ways to use the\r\nValueMappingEstimator. This is part of the original change to add the\r\nValueMappingEstimator to the code base and references #754.\r\n'
402501265,2221,b'fix file layout for codecov',b'Maps file layout correctly.\r\n'
402499373,2220,b'Extract IDataView into its own assembly and NuGet package',"b""Moving IDataView and related types into a new library: `Microsoft.Data.DataView`\r\n\r\nFix #1860\r\n\r\nI've split the changes into 3 commits for easy reviewing:\r\n\r\n1. Copy the files out into the new folder with minimal/zero changes\r\n2. Get the new assembly building\r\n3 Get ML.NET building on the new assembly"""
402495204,2219,b'Modify API for advanced settings (FieldAwareFactorizationMachineTrainer)',"b'Towards #1798 .\r\n\r\nThis PR addresses the following algos \r\n\r\n- FieldAwareFactorizationMachineTrainer\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` .  Also a few other fields have been made `internal`\r\n3. Pass Options objects as arguments instead of Action delegate. Also, added  3 fields to `Options`  for API consistency. \r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)'"
402487541,2218,b'change coverage file format to cobertura.',b'Just testing if cobertura works better on codecov.'
402468569,2217,b'Improve exception message and make consistent with ExceptSchemaMismatch',"b'Fixes #2044.\r\n\r\nI make the exception message consistent using `ExceptSchemaMismatch` when possible. \r\nIn particular, as mentioned in the issue #2044, I did it for the base class for TrainerEstimators.\r\n\r\n'"
402455134,2216,b'test.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
402449366,2215,b'code coverage yml fix.',"b'fix file path, since yml seems to take full paths and not relative paths.'"
402448295,2214,b'Adding tests to cover the array checks in the core Utils',b'This PR adds tests to cover the array checks in `Microsoft.ML.Internal.Utilities`.\r\n\r\nFixes #2213 '
402426219,2212,b'Fixing build break',b'Updated the API call for GetRowCursor as this was causing a build break.'
402171345,2209,b'Add reference to any form of API?',"b""Is this the best API reference for this?\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
402027423,2208,b'WIP NEW CC BUILD DEF - TEST',b'Just a test branch to make sure new build def is working\r\n\r\n'
402001340,2206,b'Add visibility for internal projects.',"b""We made constructors internal, and in internal repo I don't have mlcontext all the time. I don't want to create mlcontext, so I would prefer to make learners visible via [InternalVisible]."""
401989061,2205,b'Multiple feature columns in FFM',"b'This PR somehow provides a solution to #2179 regarding FFM via allowing multiple feature column names in advanced trainer arguments.\r\n\r\nStrategy: adding one extra field to `Arguments` of FFM; that filed is\r\n```csharp\r\n            /// <summary>\r\n            /// Extra feature column names. The column named <see cref=""LearnerInputBase.FeatureColumn""/> stores features from the first field.\r\n            /// The i-th string in <see cref=""ExtraFeatureColumns""/> stores the name of the (i+1)-th field\'s feature column.\r\n            /// </summary>\r\n            [Argument(ArgumentType.Multiple, HelpText = ""Extra columns to use for feature vectors. The i-th specified string denotes the column containing features form the (i+1)-th field."" +\r\n                "" Note that the first field is specified by \\""feat\\"" instead of \\""exfeat\\""."",\r\n                ShortName = ""exfeat"", SortOrder = 7)]\r\n            public string[] ExtraFeatureColumns;\r\n```\r\n'"
401981042,2204,b'Modify API for advanced settings (MatrixFactorizationTrainer)',"b'Towards #1798 .\r\n\r\nThis PR addresses the following algos \r\n\r\n- MatrixFactorizationTrainer\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` .  Also a few other fields have been made `internal`\r\n3. Pass Options objects as arguments instead of Action delegate. Also, added  3 fields to `Options`  for API consistency. \r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)\r\n\r\n'"
401964399,2203,b'Removed python naming conventions from C# samples ',b'Fixes #2155 \r\n\r\nRemoved the python naming conventions in `docs/samples/Microsoft.ML.Samples` \r\n'
401898446,2202,b'Remove ColumnType.RawKind Round 3 (and final)',b'Completely removes `ColumnType.RawKind`.\r\n\r\nPart of the work necessary for #1860. \r\n\r\nFix #1533.'
401548621,2200,b'Tests for Sse and Software implementations',b'Fixes https://github.com/dotnet/machinelearning/issues/1156\r\n\r\nThis pr adds tests for sse and software implementation of cpumath functions'
401533234,2199,b'Modify API for advanced settings (GAM learners)',"b'Towards #1798 .\r\n\r\nThis PR addresses the following algos \r\n\r\n- BinaryClassificationGamTrainer\r\n- RegressionGamTrainer\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` \r\n3. Pass Options objects as arguments instead of Action delegate\r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)\r\n\r\n'"
401066646,2195,"b""Remove RowCursor's GetRootCursor/MoveMany/CursorState""","b'Fixes #1532, in particular the last notes about things to remove from cursors.\r\n\r\nAs noted in a reply on the issue, the one thing I gave up on `IsColumnActive` because I realized eventually that it its removal did more harm than good, and it represented a genuine lapse in capability. Some test code started to become impossible to write, and it struck me that some debugging/test scenarios simply could not be served with it, even if in our ""perfectly"" written code it seemed to me that it was never genuinely useful. Debug/test code, its utility becomes very clear. (E.g., one could never write a modestly useful debug proxy object without that method or something like it.)\r\n\r\nThe commits are intended to be structured usefully, as per usual.\r\n\r\n* For `RowCursor.GetRootCursor`, I replaced that functionality with some implementation specific logic in `SynchronizedCursorBase`, since that\'s the only really important place that becomes critical anyway.\r\n* `MoveMany`. Slight inefficiencies on the very sparse samplers and the skip/take filter. That\'s about it.\r\n* `CursorState`. Want to know if the cursor is in a bad state? Check whether `Position` is negative.'"
401051004,2194,b'Automate code coverage report as part of PRs.',"b'fixes #2193.\r\n\r\nAfter this change, every PR will get a code coverage report against master for every commit. It will inform the author the impact of their change on the code coverage. This should hopefully lead to more informed, faster and higher quality code review, in addition, it will hopefully lead to improved code quality.\r\n\r\nCurrently coverage files are generated using coverlet tool and uploaded to codecov.io. For now coverage reports are generated using Windows x64 Debug build but later it will be enabled for all debug legs when coverlet releases a more performant version. '"
400913290,2192,b'[Tiny Change] Internal-best-friend CacheDataView and IRowSeekable',b'Fixes #2028.\r\n'
400881345,2190,b'Made ValueMappingTransformer accept vector as input.',b'This PR address one of the issues in #2162.\r\n\r\n\r\n'
400850559,2189,b'Replace CreateDataView and CreateStreamingDataView with a new one on mlContext.Data',"b""There will be two iterations.\r\n1. The first iteration replaces CreateStreamingDataView with an equivalent one on mlContext.Data.\r\n2. The second iteration replaces CreateDataView with the same one on mlContext.Data.\r\n\r\nTogether with #2182, this fixes #1708, fixes #2025.\r\n\r\nDetailed working items:\r\n- Add\r\n```csharp\r\npublic static IDataView ReadFromEnumerable<TRow>(this DataOperations catalog, IEnumerable<TRow> data, SchemaDefinition schemaDefinition = null) \r\n```\r\n- Because `ReadFromEnumerable` is equivalent to `CreateStreamingDataView`, we remove\r\n```csharp\r\npublic static IDataView CreateStreamingDataView<TRow>(this IHostEnvironment env, IEnumerable<TRow> data, SchemaDefinition schemaDefinition = null) \r\n```\r\n- Replace the uses of `CreateDataView` and `CreateStreamingDataView` with the new `ReadFromEnumerable`.\r\n\r\nI am not sure if `CreateDataView` should be removed too as ML.NET now uses `ReadFromEnumerable` everywhere and caching should be done by calling `Cache`. \r\n[Update] `CreateDataView` is removed because it's equivalent to `DataViewConstructionUtils.CreateFromList`.\r\n"""
400821047,2188,b'Test GAM Public APIs',"b'This PR adds new APIs to GAMs to retrieve all the shape function bins and effects (in addition to the current APIs to get only one shape at a time). This PR also adds tests to cover all the public APIs, including expected behavior for the public constructor.\r\n\r\nFixes #2186 \r\nFixes #2187'"
400517473,2182,b'Get IDataView to C# Path Sorted',b'Fixes partially #1708 (first and second working items).'
400512719,2180,b'WIP Code Coverage',b''
400497571,2178,b'Fix broken build',b'Fixes build broken in #2125 \r\n'
400479529,2176,b'Remove ColumnType.RawKind usages Round 2.',"b'Removes the ""easy"" usages of ColumnType.RawKind.\r\n\r\nPart of the work necessary for #1860 and contributes to #1533.\r\n\r\nThere are still about 38 usages of ColumnType.RawKind left, but they are a little more involved, and needs refactoring. I will fully remove them in the next PR.'"
400423623,2173,b'Filtered operators which have no outputs while getting schema and added test.',b'This PR fixes #2156.\r\n\r\nPlease see the issue for more details and the solution of the bug.\r\n\r\n'
400127875,2170,b'Towards #1798 .',"b'This PR addresses the estimators inside HalLearners:\r\n\r\nTwo public extension methods, one for simple arguments and the other for advanced options\r\nDelete unecessary constructors\r\nPass Options objects as arguments instead of Action delegate\r\nRename Arguments to Options\r\nRename Options objects as options (instead of args or advancedSettings used so far)\r\n\r\n'"
400067493,2169,b'Rename types inside MLContext as Catalogs',b'Fixes #1796 \r\n\r\nRenames `XyzContext` types inside `MLContext` to `XyzCatalog`.\r\n\r\nRenames `DataOperations` to `DataOperationsCatalog`.'
400044019,2168,b'Added a test in disabled mode to show the known issue with loading TF model multiple times.',"b'This PR partially fixes #2156.\r\n\r\nAdded a test to show that ""loading TensorFlow SavedModel multiple times throws exception"" is a know issue.\r\n'"
400032482,2166,b'Add code coverage build def.',b'Adds a new CI leg just for code coverage. The reason for adding a new leg is not let code coverage process affect PR merge. '
399981399,2163,b'Modify API for advanced settings (several learners)',"b'Towards #1798 .\r\n\r\nThis PR addresses the following algos \r\n\r\n- LogisticRegression\r\n- MulticlassLogisticRegression\r\n- PoissonRegression\r\n- AveragedPerceptronTrainer\r\n- LinearSvmTrainer\r\n- OnlineGradientDescentTrainer\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` \r\n3. Pass Options objects as arguments instead of Action delegate\r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)\r\n\r\n'"
399945410,2161,b'Changing LicenseURL to License in Nugets',b'Fixes #2095 \r\n\r\nNuget.org requires updating the metadata to use License instead. This PR changes that.'
399695626,2160,b'Rename FeatureContributionClaculator => FeatureContributionCalculator',b'Addresses Issue #2150 \r\n\r\nA dirty job but someone has to do it :-). As a newbie I thought this might be the best way to start...\r\n\r\nNo new tests but existing tests run OK.\r\n\r\n'
399595235,2158,b'KMeans and Implicit weight cleanup',"b'Towards #1798 \r\n\r\nRenaming Args ->Options, internalizing ctors, and fixing the issue with the weigh column being initialized as Implicit or Explicit. \r\n'"
399594934,2157,b'Support running benchmarks on netfx',b'Fixes https://github.com/dotnet/machinelearning/issues/1945\r\n\r\nThis PR makes changes in order to enable developers to run ML benchmarks against .NetFramework\r\n'
399555462,2153,b'Adding packages to the solution',"b'Does not effect users, however would be nice to have all packages in the solution. Fixes #1168 '"
399494716,2152,b'Reuse threads in ThreadUtils',"b'ThreadUtils.CreateBackgroundThread is being truthful to its name and creating a new thread for every call.  However, even for very simple ML.NET usage, such as the MulticlassClassification_Iris demo app, this method is being called ~110,000 times, resulting in ~110,000 threads getting created and destroyed.  That adds measurable overhead in normal runs, but when the debugger is attached it makes the solution effectively unusable, as every thread creation/destruction is tracked by Visual Studio, leading to significant overheads that make an F5 execution last ""forever"" (== I gave up waiting).\r\n\r\nThe right solution is for the higher-level algorithms and architecture to be better about its need for threads, creating them only when necessary and otherwise relying on the .NET ThreadPool for execution, via either ThreadPool.QueueUserWorkItem or via Task.Run or the like.\r\n\r\nHowever, as an immediate stop-gap that significantly helps the situation, this commit allows the created threads to be reused for a period of time such that not every call ends up creating a new thread.  In my runs:\r\n- The same demo that app that created ~110K threads now creates only ~32.\r\n- With ctrl-F5 (e.g. no debugger attached), it previously took ~13 seconds, and with this change now takes ~6.\r\n- With F5 (debugger attached), execution previously took ""forever"", now takes ~190 seconds (still way too high, but vastly improved).\r\n\r\nThe CreateBackgroundThread method is renamed to StartBackgroundThread, and returns a Task instead of a Thread, such that callers may synchronize with that instead with Thread.Join.  In several cases, this avoids additional threads from being consumed, where callers were blocking a thread pool thread doing a synchronous wait for all tasks, and where now that\'s entirely avoided via Task.WhenAll.  Eventually, more call sites can be fixed as well, as more of the code base is moved to async/await; for now this just handles the obvious ones that don\'t require any significant restructuring.\r\n\r\nContributes to https://github.com/dotnet/machinelearning/issues/2099'"
399172306,2146,b'KeyType Simplification',"b'Fixes #1540.\r\n\r\nIn this PR I remove the Min and Contiguous fields of KeyType. The reason for doing so is elaborated in the issue #1540.\r\n\r\nBefore this PR, a valid range of values for a key could be 1000 to 4000. This was represented by a key with Min 1000 and Count 4001. Having a key that starts at a value that is not 1 only very rarely happened in practice.\r\n\r\nNow by default a valid range will start at 1, up to Count, with 0 being used for missing values.\r\n\r\nAs part of this PR I also removed the Min and Contiguous field of KeyRange (KeyRange serves the purpose of representing a valid range of values for a KeyType). It is useful to note that the max of a KeyRange will be equal to Count - 1 of the associated KeyType.\r\n\r\nAlso fixed the comments and the [documentation ](https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewTypeSystem.md#key-types) on the type system to make sure they reflect the change.'"
399134254,2143,b'Remove ColumnType.RawKind usages Round 1.',b'Remove all usages of RawKind that are outside of ML.Core and ML.Data assemblies. The next round will completely remove ColumnType.RawKind.\r\n\r\nPart of the work necessary for #1860 and contributes to #1533.'
399126527,2142,b'Refactor GAM Predictor to be Public-ly Creatable',"b'This PR refactors the GAM trainer and predictor such that all training information remains in the trainer, and the GAM predictor is for any generic (binned) GAM.\r\n\r\nFixes #1948\r\n\r\n**Update**:  Two small bug fixes included in this PR\r\n1. Fixed a serialization error when reading in GAM models written prior to 0.6. Now we issue a warning with a workaround.\r\n2. Fixed a scoring error for sparse datasets.'"
399097824,2140,b'Remove ISchema in TextLoader.cs and TextLoaderCursor.cs',b'As title. This might be the tail of #1501.'
399077549,2139,b'Remove ISchema in BinaryLoader',b'As title. Parade of #1501 continues today.\r\n'
399066289,2138,b'Avoid using exceptions for control flow in GetBatch',"b""Fixes https://github.com/dotnet/machinelearning/issues/2137\r\nContributes to https://github.com/dotnet/machinelearning/issues/2099\r\n\r\nThis avoids using Take() in GetBatch, instead using TryTake with an infinite timeout, the only difference being whether it expects to eventually get data, and thus whether it throws or returns false when it finds the collection empty and marked for completion. This doesn't fix #2099, but it helps.  These exceptions are largely a side-effect of tons of threads getting created, which is another huge contributor to #2099.\r\n\r\ncc: @TomFinley """
399020074,2136,b'Revert tests changes in tensorflow to unblock builds',"b""I can't find proper way to handle tests right now for case where we load same model twice. So i'm removing that part of test"""
398506488,2135,b'Add a test to make sure example pipeline can run',"b""An [example](https://github.com/dotnet/machinelearning-samples/blob/16acc2f55880808bd34f3465e3eec4571565cb89/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation/MovieRecommendation/Program.cs#L48) built with 0.7 doesn't work anymore because we reorder a function's arguments. Therefore, I'd like add a test for preventing it from happening again."""
398482437,2132,b'Remove ISchema in TreeEnsembleFeaturizer',b'New member of #1501.'
398480598,2131,"b'Remove ""VectorType"" specific members on ColumnType.'",b'Remove the following members from ColumnType:\r\n\r\n- IsVector\r\n- ItemType\r\n- IsKnownSizeVector\r\n- VectorSize\r\n- ValueCount\r\n\r\nPart of the work necessary for #1860 and contributes to #1533.'
398476760,2130,b'Fix bug with order of pixels in the Interleave=true case',b'Fixes #2129.'
398465288,2128,b'Publish test trx files on failure',"b""There are times when the tests fail, but we don't know why. Publish the trx files as well during test failures."""
398404049,2125,b'Rename CreateTextReader to CreateTextLoader',b'Fixes #1690 \r\n\r\nRename `CreateTextReader` to `CreateTextLoader` to conform to the return type:\r\n\r\n```csharp\r\nTextLoader textLoader = mlContext.Data.CreateTextLoader(new TextLoader.Arguments() ...\r\n```'
398398054,2124,b'Make array argument names plural',b'Fixes #2040 \r\n\r\nMakes array argument names plural where they were singular.\r\n\r\nFixes `CmdParser` to check for Attribute name in addition to field Name.\r\n\r\nFixes Entry Points `InputBuilder` to check for both Attribute and Field names.'
398383243,2123,b'Remove ISchema in TensorflowUtils.cs and polish its shape translation',b'As title. Party member of #1501.\r\n\r\n'
398087933,2119,b'Remove ISchema in FCC',b'Again a part of #1501.\r\n\r\n'
398077662,2118,b'swapping the order or arguments on the constructors of the ConversionExtensionsCatalog. Internalizing the constructors.',b'Working towards resolving #2064 by swapping the order or arguments on the constructors of the ConversionExtensions Catalog. Internalizing the constructors.\r\n\r\n'
398070768,2117,b'Adding netfx configurations to the directory.props',"b'This change was missed while adding the new build configuration \r\nThis address the issue @Ivanidzo4ka and others are facing with the sln files i.e ""-netfx"" getting replaces by ""-intrinsics""\r\n\r\n'"
398066225,2116,b'Code coverage support',b'This is a WIP PR that adds code coverage support. This change contains code that generates code coverage files. In the next iteration I will add code to upload code coverage files to CodeCov once I know builds pass and a way to disable code coverage if needed.'
398065880,2115,b'Adds string support for ValueMappingEstimator',b'This adds support for strings to be used for keys and values for the ValueMappingEstimator (as opposed to ReadOnlyMemory<char>).\r\n\r\nThis also converts all tests to use string types as well as adds an\r\nadditional test for string vector values.\r\n\r\nFixes #2114'
398018101,2113,b'Allow NimbusML to access some internals',"b""Added NimbusML's DotNetBridge to ML.Core/Data/Entrypoints. \r\n\r\nThis closes #2062, closes #1957, closes #1958, closes #1959"""
397987439,2112,b'Tensorflow GetModelSchema should support unfrozen models',b'Fix https://github.com/dotnet/machinelearning/issues/2102'
397980813,2111,b'Say good-bye to transpose ISchema',"b""We remove `ITransposeSchema` and move `GetSlotType` to `TransposeSlotTypes` field in `ITransposeDataView`. Several derived classes' `ISchema` members are removed because they are not used at all.\r\n\r\nParty of #1501 continues."""
397689221,2110,"b'fixing the AdultData LoadColumn, and IrisWithAllFeatures class.'","b'Fixing errors regarding data loading,  spotted in the cookbook. \r\n\r\n'"
397646245,2109,b'Added Dry job for benchmarks CI',b'Fixes https://github.com/dotnet/machinelearning/issues/2002\r\n\r\nThis PR will run all the benchmarks in the ci atleast one. This will ensure that the commits have not broken any of the benchmarks'
397637203,2108,b'Added <Link> to CommonPackage.props for native DLLs',b'Fixes #1851 \r\n\r\nI built the nugets locally and tested in a new solution to verify that the issue described in #1851 was resolved.'
397636654,2107,b'Make ScoreMapperSchema and its relatives not ISchema',b'1. Remove ScoreMapperSchema and its relatives entirely\r\n2. Create static functions to generate commonly-used Schema\r\n\r\nThis PR wants to join the march of #1501.\r\n'
397635803,2105,b'Brew update',b'https://github.com/dotnet/machinelearning/issues/2103'
397622709,2101,b'Adding a test to show supported data types in TensorFlowTransform',b'This PR adds addition test to fix #745. \r\n\r\n'
397595819,2098,b'Metadata fixes for the ValueMappingEstimator',b'The ValueMappingEstimator had a couple of issues when using the Values as KeyTypes:\r\n1) The output schema for the Estimator did not contain the KeyType\r\ninformation in the metadata.\r\n2) The reverse lookup of the metadata had the incorrect value.\r\n\r\nThis now sets the correct metadata on the output schema and uses the\r\nvalue data for the reverse lookup. A test was added to confirm the\r\nchanges using the KeyToValueMapping appended to a ValueMappingEstimator\r\nfor the reverse lookup.\r\n\r\nFixes #2086\r\nFixes #2083'
397517673,2093,b'Modify API for advanced settings. (SDCA)',"b'Towards #1798 .\r\n\r\nThis PR addresses only the SDCA agos. For the other remaining components, we will have separate PRs.\r\n\r\nThe following changes have been made:\r\n\r\n1.  Two `public` extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` \r\n3. Pass Options objects as arguments instead of Action delegate\r\n4. Rename Arguments to Options\r\n5. Rename Options objects as options (instead of args or advancedSettings used so far)\r\n6. Added Help text as the XML comment of Options\r\n\r\n'"
397476889,2091,b'remove unnecessary dependency',b'Resolves #2090 by removing the mlnetmkldeps package dependency. '
397236800,2088,b'Replacing TryGetColumnIndex with invocations of GetColumnOrNull ',"b'Work towards #1500 by removing references of TryGetColumnIndex, and replacing them with GetColumnOrNull in a few projects. \r\n\r\n'"
397178584,2085,b'OnnxTransform -- Update to OnnxRuntime 0.2.0',b'Add Linux support for  OnnxTransform.\r\n\r\nFixes #2056\r\nFixes #2106\r\nFixes #2149 '
397159234,2082,b'Using the latest Numeric vector apis',b'- updates the dotnet sdk version 3.0 preview\r\n- modifies the cpumath apis to use new vector256 and vector128 apis\r\n- corrects the software implementation of MatMulTrans\r\n\r\n'
397148034,2081,b'Add Microsoft.ML as a dependency of Microsoft.ML.MatrixFactorization and rename Nuget Microsoft.ML.MatrixFactorization to Microsoft.ML.Recommender',b'Fixes #2077.\r\n\r\n'
397136913,2080,b'Remove NoMetadataSchema and make its relatives not ISchema',b'As title. This PR belongs to #1501.\r\n\r\n'
397052535,2076,b'New ML.NET statically typed pipeline Nuget.',b'Fixes #2072.'
397041239,2073,b'Added AggressiveInlining attribute to hashing and updating the sdk version for netcorapp 3.0',b'Related to https://github.com/dotnet/coreclr/issues/21583\r\n\r\nThere has been a 25 percent improvement in the HashVectorString benchmark. \r\nThe Time reduced from 34.61 to 26.16 for netcoreapp2.1\r\nThe Time reduced from 34.62 to 27 for netcoreapp3.0 preview\r\n\r\nNote - Earlier this test was showing regression(14%) on netcoreapp3.0 but doesnot seem like a  regression now\r\n\r\n'
397026726,2071,b'Remove ISchema in HeaderSchema',b'Another step to the end of ISchema. This PR belongs to #1501.'
396746235,2067,b'Update release for 0.9',b'This updates the release branch for 0.9'
396712891,2066,b'Remove ISchema in UngroupTransform',"b""Remove ISchema in UngroupTransform. It's a part of #1501.\r\n\r\n"""
396696988,2065,b'Change CheckSamePipeline method from private to internal',b'Related to #2036. Missed one method that is needed in the internal repo.\r\n'
396682069,2061,b'Add release notes for ML.NET 0.9',b'This adds release notes for 0.9'
396657997,2060,b'Remove ISchema in GroupTransform',b'Another ISchema implementation is going to leave. This PR is part of #1501.\r\n'
396631608,2059,b'Make TextLoader.ArgumentsCore.Separator internal',"b""Since `TextLoader.ArgumentsCore.Separator` is only used for the command line interface, #2041 aims to make the field internal so that it doesn't show for API users. In order to facilitate this hiding, the `CmdParser.GetArgumentInfo` had to be updated to reflect on both public and private fields of the provided type.\r\n\r\nAt the same time, the API-serving `SeparatorChars` field was renamed to simply `Separators`.\r\n\r\nWork in progress. More fields might be turned `internal`, depending on discussion in the issue.\r\n\r\nFixes #2041"""
396611261,2058,b'MLContext.Data.ReadFromBinary to accept IMultiStreamSource rather than Stream',b'Fixes #2052 '
396594596,2057,"b'Remove ""KeyType"" specific members on ColumnType.'",b'Remove the following members from ColumnType:\r\n\r\n- IsKey\r\n- KeyCount\r\n- KeyCountCore\r\n\r\nPart of the work necessary for #1860 and contributes to #1533.'
396514974,2049,b'Replace MLContext.Log Action<string> delegate with an event',"b""As proposed in #2042, this PR replaces the `Action<string> MLContext.Log` property with an event of the same name.\r\n\r\nI changed the invocation logic slightly as well to guard again possible multithreaded null references. I created a very simple smoke test to help with the refactoring but I don't see much added value in it so I can scrap it when requested.\r\n\r\nFixed #2042"""
396364293,2048,b'Cleanup the statistics usage API',"b""Resolves #2010 by breaking down the existing LinearModelStatistics into two classes: ModelStatistics and LinearParameterModelStatistics. \r\n\r\nThe only reason why the two classes are hierarchical, is backwards compatibility, so we can load either one of them in the Statistics field that exists in [MulticlassLogisticRegressionModelParameters ](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/MulticlassLogisticRegression.cs#L374)and [LinearBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/LinearModelParameters.cs#L410). \r\n\r\nIf we don't want to worry about backwards compatibility, ModelStatistics and LinearParameterModelStatstics, could each be a property in the LinearBinaryModelParameters, the artifact of training LR. As far as MLR, ModelStatistics would replace the current LinearModelStatistics. \r\n\r\n"""
396326925,2047,"b'Modify API for advanced settings. (FastTree,  RandomForest)'","b'Towards #1798 . Also fixes #2019 \r\n\r\nThis PR addresses **only** the  FastTree and RandomForest algos.  For the other remaining components, we will have separate PRs.\r\n\r\nThe following 3 changes have been made:\r\n\r\n1. Two distinct extension methods, one for simple arguments and the other for advanced options\r\n2. Make constructors `internal` \r\n3. Rename `Arguments` to `Options`\r\n4. Pass `Options`  objects as arguments instead of `Action` delegate\r\n5. Added Help text as the XML comment of `Options`\r\n6. Rename `Options` objects  as `options`  (instead of `args` or `advancedSettings` used so far)'"
396294408,2045,b'Open a pull request',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
396235547,2043,b'End of an era - Delete Microsoft.ML.Legacy',b'Deletes Microsoft.ML.Legacy project and related references/files including BatchPredictionEngine.\r\n\r\nreplaces #1971'
396122210,2036,b'Expose internal APIs to components that use them in an internal repo',b'Fixes #2035.'
396117788,2033,b'Remove legacy dependency from TextLoaderTests.cs',"b'Part of the effort described in #1971.\r\n\r\nThis PR removes references to the legacy API from the TextLoaderTests.cs file.\r\nPart of the tests just required substituting to the new textloader, others were substituted by an equivalent json entrypoint graph that was used to run the same pipeline defined in the old api.'"
396113560,2032,b'Remove collectionsdatasource tests.',b'CollectionsDataSource part of legacy api uses StreamingIDataView under the hood which already has coverage from other tests based on code coverage analysis. Remove CollectionsDataSource tests as they use legacy API.'
396112677,2031,b'Hide IDataTransform Create methods',b'Step towards https://github.com/dotnet/machinelearning/issues/1995.\r\nAlso add proper comments for Image transforms.\r\nRemove Create methods in Onnx and Tensorflow (replace them with proper constructors).'
396099432,2030,b'Fix build break',b'Fix to mitigate the build break.\r\n'
396096290,2029,b'Added more documentation and extra CPU path test',"b'Updated XML docs for public estimator methods.\r\nUpdate XML to point to new GPU package\r\nAdded tests for extra CPU paths (gpuDeviceId=null, fallBackToCPU=true)\r\n\r\n'"
396079964,2027,b'Remove Legacy dependency from Microsoft.ML.Benchmarks',"b'Part of the work in PR #1971 \r\n\r\nThis PR removes dependency on Legacy code from Microsoft.ML.Benchmarks.\r\n\r\n`LegacyPredictionEngineBench.cs` was written to mimic `PredictionEngineBench.cs` using Legacy API after the fact, so just deleting it here.\r\n\r\n`StochasticDualCoordinateAscentClassifierBench.cs` is rewritten to use new API and remove all Legacy code.'"
396022011,2024,b'Updating tests in Microsoft.ML.Tests/Scenarios to new API',"b'1. Updated the `ClusteringPrediction` test to use new API\r\n\r\n2. Deleted the following 3 Legacy tests, which were being skipped because of missing data set files \r\n\r\n- `PredictHousePriceModelTest`\r\n- `TrainAndPredictHousePriceModelTest`\r\n- `ReadStrongTypeModelFromStream`\r\n\r\n3. Deleted `test\\Microsoft.ML.TestFramework\\ModelHelper.cs` which had some helper utils for (2)  above\r\n\r\n4. Remove Legacy references from Microsoft.ML.TestFramework.csproj and EnvironmentExtensions.cs\r\n'"
396003756,2023,"b'Remove ColumnType ""Is"" properties (except IsKey and IsVector)'","b'Remove the following properties from ColumnType:\r\n\r\n- IsPrimitive\r\n- IsNumber\r\n- IsText\r\n- IsBool\r\n\r\nAnd move `IsStandardScalar` to an extension method, so it can be left in ML.NET when ColumnType is extracted with IDataView to a separate package.\r\n\r\nI plan on removing `IsKey` and `IsVector` each in their own PR along with the rest of the ""Key"" and ""Vector"" members on ColumnType.\r\n\r\nPart of the work necessary for #1860 '"
395955105,2021,b'Remove Legacy dependency in ML.FSharp.Tests',"b'Part of the effort described in #1971.\r\n\r\nThis PR removes Legacy code in ML.TestFramework and ML.FSharp.Tests, and replaces it with the new Estimator, Transformer API. Specifically, it changes tests that were using ModelHelper.cs (although those tests were skipped anyway as the dataset is missing). It also changes the F# code in the F# smoke tests to use the new API.  \r\n\r\nI checked the code coverage effect of this PR, and it increases the coverage by 0.02% (possibly for deleting test utility code that was not used).\r\n\r\n\r\nEDIT:\r\nWe decided to remove the tests relying on the housing dataset in PR #2024. I am therefore reverting my changes on those tests and letting that PR remove all references to Legacy in the TestFramework DLL.\r\n\r\n'"
395853507,2020,b'Convert CSharpAPI based tests to EntryPoint based test.',"b'Converts [CSharpAPI tests](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Core.Tests/UnitTests/TestCSharpApi.cs) to entrypoints based test. CSharpAPI converts the pipeline to a json graph which is converted by entrypoint infrastructure to MLNET pipeline via entrypoints. This change converts the CSharp based pipeline to Json graph and invokes the graph runner, hence preserving code coverage of entry points infrastructure and ML.NET transforms/trainers, etc.\r\n\r\nCode coverage seems to drop by 0.09%, bulk of it seems to be coming from microsoft.ml.core.tests.dll - 0.55% where TestCSharpAPI.cs file was deleted, followed by microsoft.ml.core.dll - 0.24%, microsoft.ml.maml.dll - 0.13%, microsoft.ml.transforms.dll - 0.02%.\r\n\r\n\r\n'"
395779222,2018,b'Adding a new CI leg for netframework',"b'Fixes https://github.com/dotnet/machinelearning/issues/1933\r\nWe are currently not running or building our tests on netframework.\r\nHowever we are going to support netframework when we release 1.0 , so just adding a new ci leg to consistently build and test stuff on netframework\r\n'"
395773557,2017,"b'Fix CategoricalHashTransform to handle OutputKind ""Key""'","b'fixes #1939.\r\nDuplicate of https://github.com/dotnet/machinelearning/pull/1941, but since Gani is out, I want to finish it.'"
395768044,2015,b'Remove legacy API test that already have coverage and refactor code.',"b""Deleted all tests under test/Microsoft.ML.Tests/Scenarios/PipelineApi and removed SentimentPredictionTests.cs from test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation because these tests already have equivalent tests that use new api under test/Microsoft.ML.Tests/Scenarios/Api/Estimators. \r\n\r\nVerified the code coverage wasn't affected too much, its now at **68.94% vs 68.97%** the difference is in the below dlls:\r\nmicrosoft.ml.data.dll - 0.05%\r\nmicrosoft.ml.entrypoints.dll - 0.18% (expected since legacy api calls into core entrypoints API)\r\nmicrosoft.ml.fasttree.dll - 0.04%\r\nmicrosoft.ml.hallearners.dll - 0.99% (This drop is coming from the removal of SymSGD test, will add one in another PR)\r\nmicrosoft.ml.transforms.dll - 0.06%\r\n\r\n\r\n\r\n\r\n"""
395743777,2013,b'New ONNX converter interface and some tests',"b""This PR create a ONNX converter targeting ITransformer. A full example is added as a test; we train a pipeline (normalize + SDCA) using new APIs, convert the trained model, and call ONNXRuntime to evaluate it. In addition, we recreate existing ONNX conversion tests using new APIs to ensure at least identical test coverage after removing ONNX tests using legacy APIs.\r\n\r\nWorking item summary:\r\n1. Create new ONNX converter interface which is able to handle ITransformer.\r\n2. Remove OnnxTest.cs\r\n3. Recreate ONNX conversions in OnnxTest.cs using new APIs.\r\n4. Add extra end-to-end tests. We train ML.NET model, convert it to ONNX format, and call ONNX runtime to execute it. The results produced by ONNX runtime and ML.NET's original model are checked."""
395741170,2012,b'Fixing typo in FeatureContributionCalculation sample.',b'Fixing typos in FeatureContributionCalculation sample.\r\n\r\n'
395740452,2011,b'Removing Iteration Setup from Benchmarks',"b'Specifying IterationSetup benchmark causes the benchmark to run just only once in an iteration. This is a problem if the benchmarks takes less than 100ms to execute.\r\n\r\nAs it is being executed just once per iteration and number of iterations is 20, no jitting is done on netcore3.0 (requires 30 calls).\r\n\r\nThe possible solutions were to increase the length + increase the warmCount to 30 (this could be a problem for other benchmarks)\r\n\r\nAnother solution is just removing the iterationSetup. In CacheWithSeeker we are not doing anything that is specific to an iteration and we can directly move the code to globalSetup.\r\n\r\nfor CacheWithCursor I moved the implementation to the actual benchmark as the iteration setup itseld was taking a small time. But it will good if we could move the iteration setup to globalSetup. @TomFinley any suggetions will be helpful.\r\n\r\nAlso Earlier this was reported as regression for netcore3.0 but after testing the benchmark with both the solutions, I found there is no regression in this benchmark.\r\n\r\n\r\n\r\n'"
395696706,2008,b'Update tests (using Iris dataset) to use new API',b'- Update a couple of tests (using Iris dataset) to use the new API.\r\n\r\n'
395663870,2007,b'Improve documentation for Feature Contribution Calculation',b'Fixes #1765 and #2016.\r\n\r\nIn this pull request I update the documentation and some parameter names for FCC.\r\n\r\nThere were three aspects mentioned in the issues:\r\n- improving the overall summary\r\n- referencing and documenting the various implementations of FCC\r\n- making the parameters `top` `bottom` more informative in the constructor of FCC.\r\n'
395454916,2005,b'Bump master to 0.10',b'Updating the version on Master to 0.10'
395454253,2004,b'Merge master into release/preview for 0.9',b'This PR merges master into release branch for 0.9'
395412517,2001,b'Make CompositeSchema not an ISchema',"b""Continue removing ISchema one-by-one. It's a part of #1501."""
395406579,2000,"b""WIP [Please don't review] : Arguments, Options""",b'TBD. Please do not review\r\n\r\n1. Rename `Arguments` to `Options`\r\n2. Pass `Options` object instead of `Action` delegate\r\n3. Provide distinct constructors/extension methods.\r\n\r\nFor #1798 '
395402167,1998,"b""Add test for linear svm and polish it's code""",b'Related to https://github.com/dotnet/machinelearning/issues/1984.\r\n'
395202486,1994,"b""Typo fixed: duplicate 'in case of' removed""","b""There was a duplicate 'in case of' in the description of the constructor."""
395035226,1989,b'Use channel info in SymSGD ',b'Fixes #1985 '
395020091,1988,b'Support back compat for ngram hash',b'fixes #1982 '
394559743,1979,b'making GetCoefficientStatistics public',b'Fixes #1977 by making method GetCoefficientStatistics  public. \r\n\r\n'
394514239,1975,b'Initial refactor to swap the predicates for an IEnumerable<Schema.Columns> in the GetRowCursor and GetRowCursorSet',b'Addresses #1529 by swapping the predicates for IEnumerable<Schema.Columns> in the GetRowCursor and GetRowCursorSet\r\n'
394479115,1972,b'[WIP] Jignparm/onnxtransform Linux support',b'Test out OnnxTransform Linux support\r\nFixes #2056'
394343767,1971,b'WIP End of an era - Delete Microsoft.ML.Legacy and related tests.',"b'I still need to remove all those baseline files that are no longer used and then document all the tests that may need to be re-written using the new API such as ONNX converter test and FSharp test. In the end I want to compare how much the code coverage has changed between this change and master. \r\n\r\nCC: @TomFinley, @sfilipi '"
393798939,1966,b'Remove Runtime in namespace from docs folder.',b'fixes #1965'
393795119,1963,b'Sort namespaces as per stylecop rules/.net convention and remove unused namespaces from source files.',"b'Sorts namespaces as per stylecop rules/.net convention and removes unused namespaces from source files. Standardizes namespace to be always sorted as per .NET convention in source files.\r\n\r\nMy impressions after doing this change:\r\n1) There is decent amount of code under IF DEFs that seems dead and should be removed, example: \r\nIn IntArray.cs\r\n#if USE_SINGLE_PRECISION\r\n    using FloatType = System.Single;\r\n#else\r\n    using FloatType = System.Double;\r\n#endif\r\n\r\nUSE_SINGLE_PRECISION is not defined anywhere and FloatType is not at all used anywhere in the file. We should consider opening an issue to do this sort of clean up. There are many such examples.\r\n\r\n2) Consider removing Float and use float directly.   \r\n\r\nCC: @TomFinley \r\n\r\nfixes #1961\r\nfixes #1962'"
393644306,1956,"b'Remove ""Runtime"" from all namespaces.'","b'Partially fixes #1697 by removing ""Runtime"" from all namespaces and that is it, no moving classes to other namespaces.\r\n\r\n'"
393636179,1955,"b'Remove ""Runtime"" from all namespace'","b'Partially fixes #1697 by removing ""Runtime"" from all namespaces and that is it, no moving classes to other namespaces. '"
393624233,1953,b'Add an example for static pipeline with in-memory data and show how to get class probabilities',b'Fixes #1947 and fixes #1881.\r\n\r\n'
393513884,1951,b'Load entry point models',"b""Address https://github.com/dotnet/machinelearning/issues/1104\r\nAs long as NimbusML uses old version ml.net (pre 0.9) I don't have other way around other than this hacky way of loading it.\r\n"""
393247485,1946,b'Throwing exception if the underlying rsp fails with an exception',"b""The benchmarks involving rsps don't fail even when the underlying rsp has thrown an exception\r\n"""
393178826,1944,b'ONNX conversion should throw a better message',b'Fixes #1396. Simply went to all SaveAsOnnx and SaveAsOnnxCore and add throwing mechanism if proper.'
393173452,1941,"b'Fix CategoricalHashTransform to handle OutputKind ""Key""'",b'fixes #1939 '
392884159,1940,"b'Fix CategoricalHashTransform to handle OutputKind ""Key""'",b'fixes #1939 '
392880668,1938,b'Remove IRowCursorConsolidator.',b'Fixes #1867.'
392870513,1937,"b'Remove ""Runtime"" from all namespace reference and move public facing classes used in Samples into Microsoft.ML namespace.'",b'fixes #1697'
392860786,1936,b'Update the demo code because of the `mlContext.Data.CreateTextReader` method is no longer exists in the latest version v0.8.',b'Fixes #1935.\r\n\r\nThere is no `mlContext.Data.CreateTextReader` method in the latest version of ML.NET v0.8.\r\nI Updated  `mlContext.Data.CreateTextReader`  to `TextLoader.CreateReader` so that can give a correct \r\nguidance for the readers.\r\n\r\nPlease check.\r\n'
392855208,1934,b'Loads LightGBM inf/nan properly',b'Follow a suggestion mentioned in #1424 to load inf/nan from trained LightGBM model.\r\n\r\n'
392813362,1932,b'Fix TargetFramework for *.StaticPipe assemblies',b'Fixes #1931 \r\n\r\n'
392782682,1930,b'Move Static API extensions to separate assembly',b'Towards #1695 . Also fixes #1480 \r\n\r\n- Static extensions for TextLoader moved to the Microsoft.ML.StaticPipe assembly\r\n- Static extension related files moved to the Microsoft.ML.StaticPipe assembly\r\n- Moved static extensions for some transforms / learners that were missed in previous PR #1914 \r\n\r\n'
392747119,1929,b'Implement ICanSaveInIniFormat interface for GamPredictor',b'Add support for saving GAM models as ini format. Parity results with maml are included in the tests.\r\n'
392735720,1928,"b'BinaryLoader cursor doesn\'t set state to ""Done""'",b'Fixes #1927 .'
392671503,1926,b'Update PFI tests so they configure sensitive learners to use a single thread.',"b""Fixes #1925 .\r\n\r\nWhile I was at it I also set the number of threads to logistic regression to 1 as a better practice, since even though it's less likely to trigger a failure here, better safe than sorry. As mentioned in the issue since FastTree's results don't depend on number of threads I did not set it there.\r\n\r\nAlso incidentally started using `Assert.Equals(a, b)` instead of `Assert.True(b == a)`, so as to provide slightly more helpful error messages for when test failures happen, but that should not affect the running of the test.\r\n\r\nAs with most spurious test failures, due to the indeterminacy of the effects I am not actually 100% sure this will solve the issue, but it was just one obvious mistake I saw when reviewing the test code, so I figured this might help improve the spurious failures on account of this issue."""
392463692,1924,"b'Replace ColumnInfo usage with Schema.Column, remove ColumnInfo'","b""Fixes #1923. As usual commits are structured in such a way as to make the code approachable. Since the first usage was against `RoleMappedSchema` and that was used in many, *many* places, I'm sorry to say that is probably the biggest change."""
392435842,1922,b'Onnxtransform - api changes for GPU support',b'Fixes #1834 \r\n\r\nAdd CUDA 10.0 GPU execution support\r\n\r\nAdd Linux support\r\n\r\nAdd Mac support\r\n'
392395822,1920,b'PredictionFunction becomes PredictionEngine',"b'Fixes #1761 \r\nFixes #1819 \r\n\r\nRenamed MakePredictionFunction to CreatePredictionEngine, and exposed the schema comprehension parameters to the factory method.\r\n\r\nAdded a method to `mlContext.Model` to create a prediction engine.'"
392370919,1918,b'Load old models with normalizer.',b'- [x] Add issue. Fixes https://github.com/dotnet/machinelearning/issues/1919\r\n- [x] Add test.\r\n'
392353868,1917,b'ISchema is now internal',b'Addresses #1500\r\n\r\nColumnBindingsBase and ISchema are now internal. \r\nSchema and ColumnBindingsBase no longer implement ISchema.\r\n\r\n'
392348787,1914,b'Separate assemblies for static extensions',b'Fixes #1695 \r\n\r\n- Created separate assemblies to host the Static API extensions. Moved the Static API extensions to the appropriate assembly.\r\n- Requires adding [BestFriend] attribute in several places\r\n    \r\n1. Microsoft.ML.StaticPipe\r\n2. Microsoft.ML.LightGBM.StaticPipe\r\n3. Microsoft.ML.TensorFlow.StaticPipe\r\n4. Microsoft.ML.OnnxTransform.StaticPipe\r\n5. Microsoft.ML.HalLearners.StaticPipe\r\n\r\nNOTE: These assemblies are named  corresponding to nuget packages (with the Microsoft.ML prefix)  '
392336144,1910,b'Make IStopWordsRemoverFactory return an IDataTransform',b'Fixes #1909 .'
392275479,1905,b'Fix LDA bug that ignores per-column arguments',b'Fixes #1904 .'
391992011,1902,b'Internalize RoleMappedSchema and implications thereof',"b'Internalization of everything related to role mapped schema, which includes schema-bindable mappers, much of the internal infrasturcture of evaluators, and so forth. As usual the commits are structured in such a way as only one ""group"" of code gets internalized at a time, with only the current last commit internalizing `RoleMappedSchema` itself.'"
391988794,1901,b'Public API for remaining learners',b'Fixes #1703 \r\n\r\nPredictors covered in this PR:\r\n- `EnsemblePredictorBase`\r\n- `EnsembleDistributionPredictor`\r\n- `EnsemblePredictor`\r\n- `EnsembleMultiClassPredictor`\r\n- `GamPredictorBase`\r\n- `BinaryClassificationGamPredictor`\r\n- `RegressionGamPredictor`\r\n- `PcaPredictor`\r\n- `FieldAwareFactorizationmachinePredictor`\r\n- MultiClassLogisticRegressionPredictor`\r\n- `MultiClassNaiveBayesPredictor`\r\n- `OvaPredictor`\r\n- `PkpdPredictor`\r\n- `RandomPredictor`\r\n- `PriorPredictor`\r\n'
391955950,1900,b'Forecasting model framework for time series.',b'This PR introduces forecasting framework/interface for time series. It allows the following:\r\n1. Train forecasting model from an IDataView.\r\n2. Update the model with new observation using an IDataView.\r\n3. Forecast values up to a certain horizon (with confidence intervals).\r\n4. Checkpoint the model to disk.\r\n5. Load a model from disk.\r\n\r\nfixes #929\r\nfixes #3151'
391937986,1898,b'Remove Legacy dependency from Microsoft.ML.EntryPoints project',"b'The TrainTest, CV and OVA macros use the pipeline API. This PR removes the dependency on pipeline API by creating the EntryPointNodes directly.\r\n'"
391933916,1897,b'Fix copyright for Microsoft.ML.TensorFlow.Redist',b'Deleted extra space in copyright\r\n\r\n'
391931229,1896,b'Use seed specified for column in PcaTransform',b'Fixing this elite bug #1337. Fixes #1337.'
391930765,1894,b'Making Schema implement ISchema explicitly',"b'Addresses #1500 \r\n\r\nMade Schema implement ISchema explicitly. Removed all calls to the ISchema inteface when Schema is accessed, with the exception of TryGetColumnIndex, which was made internal.'"
391912276,1893,b'Internalizing MetadataUtils',"b'Contributes to #1500 \r\n\r\nMoved most of MetadataUtils to internal, except some public methods to access common metadata.\r\nRemoved some methods that are now trivial.\r\n'"
391890511,1892,b'Fix hash join transform.',b'Fixes #1891 '
391525280,1889,b'Bruteforce implementation for KNN.',b'All API plumbing for KNN and their dumb implementation.\r\n\r\n- [ ] Add K-D trees.\r\n\r\n- [ ] Add Ball trees.\r\n\r\n- [ ] Figure out what to do during scoring if nothing in radius. (for radius search instead of K neighbors search)\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/1712'
391519677,1888,b'Updated with correct tags for image reference',"b""Updated with correct tags for image. `<a>` to `<image>`\r\n\r\nFixes #1783\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
391516099,1887,b'Remove ISchema in FeatureContributionCalculationTransform',"b""As title. It's a part of #1501. This change is not difficult because the output schema only contains one column, which is per feature contribution."""
391296306,1885,b'Provide seed parameter for TrainTest routine',b'Fixes https://github.com/dotnet/machinelearning/issues/1635'
391284742,1884,"b""[WIP PR won't merge] RE-creating the entry point test in the new API format, because it is\xe2\x80\xa6""","b'This PR has is being used to investigate the failure of the test described in: #1726\r\n\r\nI will not merge it to master, unless i convert this to fixing the issue encountered.'"
391216800,1883,b'Loading the label for binary classfication as BL instead of R4',b'Kmeans Benchmark was broken because Binary classfiers expected the label column to be binary but we were loading it as R4\r\n\r\n'
391010826,1879,b'Bindings in ChooseColumnsByIndexTransform not ISchema',"b'This PR is a part of #1501. We refactorize the `Binding` in `ChooseColumnsByIndexTransform` by making it not an `ISchema` but still maintaining necessary functionalities for connecting input and output. For the functionalities remained, please see the non-private member functions of `Bindings`. Some comments are added for a better readability.'"
390916542,1878,b'Schema based text loader',"b'Initial work to address #561. \r\n\r\nIt moves the current reflection-based logic outside of the legacy project, into the TextLoader catalog, creating an API for it. \r\nDecouples the LoadColumn and Column attributes.\r\n'"
390911635,1877,b'Update instructions for adding to the EntryPoint catalog.',b'Update instructions for adding to the EntryPoint catalog.'
390907360,1876,b'Supervised Bin Normalizer',b'Towards #819 \r\n\r\n- enabled  `NormalizerMode.SupervisedBinning` \r\n- added tests'
390905670,1875,b'Support R4 label for binary trainers',b'fix #1874 '
390896380,1873,b'Fix LightGBM and add test',b'Fixes #1424. The first commit only creates some doc strings created when I felt very struggling when trying to reuse LightGBM facilities in ML.NET.'
390778296,1872,b'Remove ISchema in FakeSchema',"b""`FakeSchema` is not longer an `ISchema` and renamed to `FakeSchemaFactory`. It's a part of #1501."""
390514849,1870,b'Much more core internalization (Phase 3)',"b'Continuuation of #1626 , which as usual continues #1519.\r\n\r\nMost of `Core`, but not all, is now internalized. Most significant remainders include `RoleMappedSchema` and `MetadataUtils`. Some of these had fairly long reaching side effects (most notably, the internalization of `RoleMappedData`).'"
390500063,1869,b'Updated fix for models with negative dimensions',b'Updated the onnxtransform to handle negative dimensions correctly.\r\n\r\n'
390108775,1868,b'Remove ISchema in ColumnBindingsBase',"b""This PR propose a naive way for removing `ISchema` in `ColumnBindingsBase`. It duplicates two utilities functions in the existing `ISchema`.\r\n\r\nDuplicated functions:\r\n```chsarp\r\n        private Delegate GetMetadataGetterDelegate<TValue>(int col, string kind, Delegate del)\r\n        {\r\n            // REVIEW: We are facing a choice here: cache 'value' and get rid of 'schema' reference altogether,\r\n            // or retain the reference but be more memory efficient. This code should not stick around for too long\r\n            // anyway, so let's not sweat too much, and opt for the latter.\r\n            ValueGetter<TValue> getter = (ref TValue value) => ((MetadataGetterDel<TValue>)del)(kind, col, ref value);\r\n            return getter;\r\n        }\r\n```\r\n```csharp\r\n        private Schema MakeOutputSchema()\r\n        {\r\n            var builder = new SchemaBuilder();\r\n            for (int i = 0; i < ColumnCount; ++i)\r\n            {\r\n                var meta = new MetadataBuilder();\r\n                foreach (var kvp in GetMetadataTypes(i))\r\n                {\r\n                    var getter = Utils.MarshalInvoke(GetMetadataGetterDelegate<int>, kvp.Value.RawType, i, kvp.Key);\r\n                    meta.Add(kvp.Key, kvp.Value, getter);\r\n                }\r\n                builder.AddColumn(GetColumnName(i), GetColumnType(i), meta.GetMetadata());\r\n            }\r\n            return builder.GetSchema();\r\n       }\r\n```"""
390014437,1865,b'Public API for Linear Predictors',"b'Fixes #1702 \r\n\r\nRename linear predictors to `XyzModelParameters`, reduce public surface, add a sample, internalize and explicitly implement the following interfaces:\r\n- `IParameterMixer`\r\n- `IParameterMixer<TOutput>`\r\n- `IDistribution<out TResult>`\r\n- `IQuantileDistribution<TResult>`\r\n- `ISampleableDistribution<TResult>`\r\n\r\nI have not renamed the namespaces, after discussion with @TomFinley during the course of fixing #1699. We will revisit namespace rename at a later time.'"
389996200,1864,b'Remove `As` methods on ColumnType.',b'Remove the following methods from ColumnType:\r\n\r\n- AsVector\r\n- AsKey\r\n- AsPrimitive\r\n\r\nMore PRs will be coming in this form. But this seemed like the lowest hanging fruit to start making incremental progress here.\r\n\r\nPart of the work necessary for #1860 \r\n\r\n'
389971813,1863,b'Remove ISchema in MultiClassClassifierScorer.cs',"b""This PR completely remove `ISchema` and its implementation used in `MultiClassClassifierScore`. It's a part of #1501."""
389964474,1862,b'Warn when a graph contains a null output',b'Fixes #315.'
389942259,1861,b'Remove some ISchema',b'This PR is one of the tasks required in #1501. Only simple type-renaming is conducted in this PR.'
389883833,1859,b'Move entrypoints from Microsoft.ML.Legacy to Microsoft.ML.Entrypoints.',b'Move entrypoints from Microsoft.ML.Legacy to Microsoft.ML.Entrypoints.\r\n\r\nWorking towards #1565 \r\n'
389625301,1858,b'renaming uint128 to RowId',b'Fixes #1534 by renaming Uint128 to RowId\r\n'
389521715,1856,b'Enabled feature contributions for GAM trainers',b'* Implemented IFeatureContributionMapper interface for GamPredictorBase to enable FCC for GAM trainers\r\n* Added test'
389517417,1855,b'Added RffBenchmark',b'Adding an end to end to Benchmark for rffTransform and cpumathutils functions like matmul and matmiltran\r\n\r\n'
388752316,1849,b'Add a test for 1259',"b'Closes #1259 by adding the test described in the bug: OVA with the feature column named something other than ""Features"". \r\n\r\nA bit of cleanup on reusing arguments to load the test dataset. '"
388538366,1848,b'Disintegrating Microsoft.ML.Api dispersing its content.',b'Fixes #1707  by moving most of the classes on it to Microsoft.ML.Data or Microsoft.ML.Core. \r\n\r\nLet me know if there is a better place for particular files. \r\n\r\n'
388530007,1847,b'Update of FeatureContributionCalculation to new API',"b'Fixes #1791.\r\n\r\nAs this is a WIP PR, I am still completing the work, but I would really appreciate your feedback on what I have done so far.\r\n\r\nIn this PR:\r\n- [x]  I created a new ITransformer for FeatureContributionCalculation (previously known as WhatTheFeature) by converting previous ISchemaBoundRowMapper to two separate classes: a IRowMapper and a ISchemaBoundMapper.\r\n- [x] I created a new IEstimator that produces the transformer.\r\n- [x] I added tests for the Transformer and Estimator. (Need to add a few more)\r\n- [x] I added MlContext extensions.\r\n- [x] I added documentation, and checks for arguments and types.\r\n\r\nWill do in a separate PR:\r\n- Add static extensions for the estimators.\r\n- I allowed pipelines, and not just IPredictor, to be passed to the IEstimator. \r\n'"
388463357,1846,b'[RIP] ISchema',"b""Fixes #1501. Waiting for #2111 to be merged.\r\n\r\n[Update] This PR will be splitted into small pieces!\r\n\r\n- [x] Replace `ISchema` with `Schema` in all cases without writing extra code\r\n- [x] Remove `ITransposeSchema` because it's a `ISchema`\r\n- [x] Remove the uses of `ISchema` in ColumnBindingsBase\r\n- [x] Remove the uses of `ISchema` in `internal sealed class CompositeSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataView\\CompositeSchema.cs`\r\n- [x] Remove the uses of `ISchema` in `internal sealed class FakeSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\FakeSchema.cs`\r\n- [x] Remove the uses of `ISchema` in `private abstract class NoMetadataSchema : ISchema` in \t`machinelearning\\src\\Microsoft.ML.Data\\DataView\\Transposer.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class Bindings : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Dirty\\ChooseColumnsByIndexTransform.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class Bindings : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoader.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class FeatureContributionSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\FeatureContributionCalculationTransform.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class FeatureNameCollectionSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Depricated\\Instances\\HeaderSchema.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\MultiClassClassifierScorer.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\Binary\\BinaryLoader.cs`\r\n- [x] Remove the uses of `ISchema` in `public abstract class ScoreMapperSchemaBase : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\ScoreMapperSchema.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class GroupSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Transforms\\GroupTransform.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in \t`machinelearning\\src\\Microsoft.ML.Transforms\\UngroupTransform.cs`\r\n- [x] Remove the uses of `ISchema` in `public abstract class SimpleSchemaBase : ISchem` in `machinelearning\\src\\Microsoft.ML.Data\\DataView\\SimpleRow.cs`\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"""
388445125,1845,b'Reverting dead unallignedCode paths',b'Reverting unaligned CodePaths were added in https://github.com/dotnet/machinelearning/pull/1218 and https://github.com/dotnet/machinelearning/pull/1274\r\n\r\nRelated to https://github.com/dotnet/machinelearning/pull/1838\r\n\r\n'
388417893,1844,b'Confidence Intervals for Permutation Feature Importance',"b""This PR adds an optional confidence interval calculation to the `Permutation Feature Importance` evaluator. If the users specifies the number of permutations > 1, then the resulting evaluating metrics will contain the mean and standard deviation.\r\n\r\nFixes #1840\r\n\r\n**Update**: In this PR, I am removing PFI for clustering. It actually doesn't make sense to use clustering metrics with PFI because cluster membership can change during permutations. If we want to look at feature importance for clustering, it'll be better to use a test specific to clustering."""
388365337,1842,b'Prevent DNNImageModels from being downloaded on all machines',b'Moves the check location to prevent download from happening on unnecessary machines during the official build. Fixes #1841 \r\n'
388109478,1838,"b'Revert ""Removed AlignedArray  (#1657)""'","b'This reverts commit 72ec121afe1a889218c750f7bda7ee5093c140b7.\r\nA bug was detected that resulted in non-deterministic calculation, since the\r\nunderlying C++ code was written in a way apparently that required alignment\r\nto produce consistent results, so of course just removing the alignment and\r\ncalling an only slightly modified algorithm compromised determinism, resulting\r\nin test failure for RFF in particular.\r\n\r\nIf we can fix that bug by other means that would be preferable, since removing `AlignedArray` is a desirable outcome. Not if it means nondeterminism though, obviously. \xf0\x9f\x98\x89 '"
388026559,1837,b'Public API for Tree predictors',b'Fix #1701 \r\n\r\nInternalized and explicitly implemented the following interfaces implemented by `FastTreePredictionWrapper`:\r\n- `ICanSaveInIniFormat`\r\n- `ICanSaveInSourceCode`\r\n- `ICanSaveSummary`\r\n- `ICanSaveSummaryInKeyValuePairs`\r\n- `ICanGetSummaryAsIRow`\r\n- `IFeatureContributionMapper`\r\n- `IQuantileValueMapper`\r\n- `IQuantileRegressionPredictor`\r\n- `IValueMapperDist`\r\n\r\nRenamed `FastTreePredictionWrapper` to `TreeEnsembleModelParameters` and descendants to `XYZModelParameters`. Reduced public surface of `TreeEnsembleModelParameters` and descendants.\r\n\r\nAdded public constructors for `TreeEnsembleModelParameters` and descendants.\r\n\r\nAdded a sample showing `FastTreeRegressionModelParameters` operations.'
388023995,1836,b'Test for Metadata Support In DataView Construction',"b'Fixes #1633 \r\n\r\n- Inside the `GetGetterDelegate` we were invoking MarshalInvoke with `GetGetter<int>` .  This does not take into consideration  the generic return type `ValueGetter<TDst>`. Subsequently, the validation inside `MarshalInvokeCheckAndCreate` fails.\r\n\r\n- As part of the fix, we use reflection to invoke the generic `GetGetter<TDst>` with the appropriate type.'"
388021569,1835,b'Row now disposable',"b'Fixes #1824 .\r\n\r\nNote that some internal things that instead operate on top of delegates will still have `Action` disposer delegates, but my expectation is that most of those things are (or should be) disposable.\r\n\r\nThe usual advice about the commits being a useful way to review still apply, though less so than in prior PRs since there are fewer bulk renamings than elsewhere.'"
388018148,1833,b'Provide proper calling conversion for x86 framework',"b'Fixes #1721 \r\nRight now if we call our nuget from .net framework 4.6 x86, we get ugly PInvokeStackImbalance exception.\r\n\r\nI\'ve check and it looks like we build our native libraries in __csdecl conversion which is standard for C and we have \r\n`#define EXPORT_API(ret) extern ""C"" __declspec(dllexport) ret` in our stdafx.h file.\r\nby default PInvoke use WinApi convention which falls down to _stdcall.\r\n\r\nOn x64 platforms and .net core everything works fine, I assume as part of implementation.\r\nFor .net framework 4.6 with x86, it throws exception.\r\n\r\nSo I put implicit calling conversion in all our PInvoke calls, and also made sure we use our stdafx.h in all our native libraries.\r\n\r\nHave no idea how to write test for this tho.'"
387975746,1832,b'Adding support for most learning tasks to PFI',"b'This PR adds support to `Permutation Feature Importance` for `Multiclass Classification`, `Ranking`, and `Clustering`.\r\n\r\nFixes #1771\r\n'"
387954020,1830,b'Deprecate documentation topics migrated to docs.microsoft.com',"b'Deprecate migrated ML.NET Cookbook and ML.NET High-Level topics. These topics will now point to the migrated topics:\r\n* ML.NET Cookbook has been split out and migrated to [the docs.microsoft.com ML.NET How to section](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/).\r\n* ML.NET High-Level topics has been split out and migrated to the [""Basic concepts for model training in ML.NET"" topic at docs.microsoft.com](https://docs.microsoft.com/en-us/dotnet/machine-learning/basic-concepts-model-training-in-mldotnet).\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/1831 '"
387917242,1829,b'Tolerance added for rff tests',b'Fixes #1825\r\n\r\nRff is using the new cpumathalgorithm for matrix multiplication\r\nSo sometimes there is difference in last few decimal places(due to different number of multiplications) from the original baseline so adding tolerance corrects the error.\r\n'
387841330,1828,"b""Allow ML.NET native binaries to work on Windows machines that don't have the VC runtime installed.""",b'This allows ML.NET to run on Windows Nano containers.\r\n\r\nI also ported 2 Unix compile options we are using in core-setup and corefx that were missed when originally creating the ML.NET native build infrastructure.\r\n\r\nFix #1823\r\n'
387482029,1822,b'Make SchemaShape.Column a struct instead of a class',b'Fixes #1706.'
387452782,1821,b'ImagePixelExtractorTransform support for images with no alpha channel',b'Fixes #1820 .'
387160651,1817,b'Cherry-pick for release 0.8',b'Cherry-pick into release for 0.8'
387149514,1816,b'Calibrator estimators',b'Fixes #1622 by creating one CalibratorEstimator per CalibratorTrainer. \r\nIntroduces CalibratorTransforms\r\n\r\n'
387144005,1815,b'Cherry-pick for release 0.8',b'Cherry-pick into release for 0.8'
387138214,1814,b'Cleanup of IRowCursor and related interfaces. IRowCursor/IRow are now classes.',"b'Partial fix for #1532. I say partial because part of what we also wanted to do was clean up some of the things in the interface (now class) that have not proven useful, but, this work is already large to the point where it would be probably unwise to try to make the PR larger.\r\n\r\nI have structured the commits so they are easy to understand, if viewed one by one. The commits with ""Rename"" in the description are *precisely that*, that is, me going to one or more types as described, hitting F2, typing something new, and that becomes my commit. Consider reviewing the other ones -- there is probably not much use in review of the rename ones. (Except perhaps to suggest a better name than `Row`. \xf0\x9f\x98\x9b )'"
387069728,1813,"b'Or converted to add, added tests for negative value of scale'",b'Fixes https://github.com/dotnet/machinelearning/issues/1802\r\n\r\n'
387069584,1812,b'TensorFlowTransform example in Microsoft.ML.Samples',b'Fixes #1715 \r\n\r\n- Adding example for TensorFlowTransform in Microsoft.ML.Samples.\r\n\r\n'
387037452,1811,b'Ngram hashing to estimator',b'Fixes https://github.com/dotnet/machinelearning/issues/1632'
387011778,1810,b'Nadrop',b'Fixes #1809 .\r\n\r\n'
387001738,1808,"b'Fixing incorrect links in XMLDocs for PFI, FCC, GAM'","b'This PR fixes incorrect documentation links in the XML Docs for Permutation Feature Importance, Feature Contributions Calculator, and Generalized Additive Models.\r\n\r\nFixes #1807 '"
386508048,1805,b'Calibrator trainer needs to clear data before retraining',"b'This caused an incorrect calibrator to be trained in OVA and PKPD, since these trainers use the same ICalibratorTrainer to train multiple calibrators.\r\nFixes #1387 .'"
386506053,1804,b'Add test coverage for VBuffer',b'Add unit tests for VBuffer operations.\r\nFixes #1803 .'
386478969,1801,b'Delete IColumn',"b'Fixes #1755.\r\n\r\nAt least initially staged as three commits, where we change some places, change the more difficult and rote places like tests and whatnot, then remove everything.'"
386348176,1793,b'Adding a binary classification PFI Example',"b'This PR adds a binary classification example. I added it to the same file as the regression example, and refactored out the file loading so that the examples focus more on the technique and less on file-loading. I also added a discussion on random fluctuations in PFI values.\r\n\r\nFixes #1766'"
386330600,1792,b'Update the PFI Binary Classification XML Docs',b'This PR updates the Permutation Feature Importance (PFI) for Binary Classification XML docs with the latest version of the documentation. It also fixes one typo in the Regression XML Docs (the name of the class of objects returned).\r\n\r\nFixes #1764 \r\n'
386284789,1788,b'SSA time series samples',b'Samples for SsaChangePointDetectorPrediction and SsaSpikeDetectorPrediction.\r\n\r\n'
385979997,1786,b'Remove IRandom and replace with System.Random.',b'Also make TauswortheHybrid internal/BestFriend.\r\n\r\nFix #1316\r\n'
385973073,1785,b'Add release notes for ML.NET 0.8',b'This adds release notes for ML.NET 0.8.'
385952794,1784,b'Clean up of TextLoader constructor',"b'Fixes #1611.\r\n\r\n1. Hid the constructor of `TextLoader` that takes Arguments, and exposed `HasHeader` and `SeparatorChars` as non-advanced parameters. \r\n2. Made Create methods internal and modified the code accordingly. \r\n3. Added comments for the public facing constructor that was retained.'"
385926412,1782,b'Add LDA example to Microsoft.ML.Samples',b'- Adding a LDA example to Microsoft.ML.Samples . This was a pending comment on #1410 '
385859737,1780,b'Remove auto-cache mechanism',b'Fixes #1604.'
385749720,1779,b'Microsoft.ML.Api - Code cleaned and if else blocks improved',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
385549124,1777,"b'Correcting Documentation, adding asserts and disabling failing ci tests'",b'- Adding Some More Asserts\r\n- Correcting netcoreapp 3.0 documentation\r\n- Disabling\\correcting netcoreapp 3.0 tests \r\n\r\n'
385530466,1775,b'Add fixes to prevent potential build failures due to redist copying',"b'Adds a new build script flag that allows specifying that certain RID agnostic files inside redist should not be built/executed. This is used to prevent the DNNImageFeaturizer models from being copied on each leg causing possible build failures. Instead, the copying only happens on Windows x64. Fixes #1775 '"
385496527,1762,b'Sample for IID spike and changepoint detection using time series stateful prediction engine.',b'Sample for IID spike and changepoint detection using time series stateful prediction engine. Fixes #978'
385450412,1759,b'Remove ISchematized interface from the codebase.',"b'1. Remove ISchematized\r\n2. For any class that requires a Schema, we add a Schema as its field\r\n3. Rename Schema to OutputSchema in IRowToRowMapper\r\n\r\nFixes #1502.'"
385426882,1757,b'Fix bug in ApplyAt in VBufferUtils',"b'When we create the editor, we lose the old values that were in the VBuffer in case it has to be resized.\r\nFixes #1756 .\r\n'"
385264499,1750,b'Bump master to 0.9',b'Bump master branch to 0.9'
385161986,1749,b'Merge master into release/preview for 0.8',b'This PR merges master into release branch for 0.8'
385138831,1748,b'Merge master into release/preview for 0.8',b'This PR merges master into release branch for 0.8'
385063930,1747,b'Extend a test for adding string-array output example',"b'A partial solution to #1746. At least, one can search the code base to find an example of using strings in input and output.'"
385036151,1745,b' Added VarVector static extension for OneHotHashEncoding',b'Fixes #1225'
385004741,1744,b'Fix for DNN Image Featurizer copying models on incremental builds',b'Fixes #1743 \r\n'
384967060,1742,b'Fixes the build break introduced by the DNNImageFeaturizer PR',b'Corrects the location of the package assets download to fix the build break. Fixes #1741 \r\n'
384959984,1740,b'Simplified null check',b'Simplified null check to leaner code.'
384953118,1739,b'Public API for KMeansPredictor',b'Fixes #1699 '
384639013,1735,b'Add Permutation Feature Importance for Binary Classification',"b'This PR adds support for `PermutationFeatureImportance` for binary classifiers, and tests to verify that PFI for binary classification works.\r\n\r\nFixes #1734 '"
384620024,1733,b'Updating the XML Docs for Permutation Feature Importance',"b'This PR updates the XML docs of `PermutationFeatureImportance` to include more details, a reference to the original Breiman paper, and a link to the new sample.\r\n\r\nFixes #1732 '"
384614961,1731,b'Adding XML Documentation for Generalized Additive Models',b'This PR updates the XML Docs for GAMs with more information about the learner and points to the new samples being added to the repository.\r\n\r\nThis also fixes the name of the binary classification trainer.\r\n\r\nFixes #1730 '
384563260,1728,b'Add a sample for Permutation Feature Importance',b'This PR adds a sample for using `PermutationFeatureImportance`.\r\n\r\nThe sample looks at the feature importances for a linear model predicting housing prices with the `HousingRegression` dataset and shows how to interpret the output of `PermutationFeatureImportance` as a measure of global feature importance.\r\n\r\nFixes #1723 '
384557880,1727,b'Stateful Prediction engine for time series.',b'Stateful prediction engine for time series that updates the time series model with new observations at the prediction (anomaly detection) phase and allows for checkpointing the updated model to file stream.\r\n\r\nfixes #1219\r\nReplaces #1618.\r\n'
384539633,1724,b'Make CpuMath not depending on ML.Core again',"b'Fixes #1688.\r\n\r\n`CpuMath` project now includes `Contract.cs` in `ML.Core`. The file `Contract.cs` contains some if-else macros for distinguishing the part for general ML.NET (namespace: `Microsoft.ML`) from the part for `CpuMath`(namespace: `Microsoft.ML.Runtime.Internal.CpuMath.Core`). The `BestFriendAttribute` in `ML.Core` (namespace: Microsoft.ML) and `CpuMath` (namespace: `Microsoft.ML.Runtime.Internal.CpuMath.Core`) follow the same pattern for the same reason. `BestFriendAnalyzer` is also modified to support the two variants of `BestFriend` attributes.\r\n\r\nBesides, we move `PublicKey` into another file, `PublicKey.cs,` to avoid including `AssemblyInfo.cs` twice in CpuMath project.'"
384456255,1722,b'Remove math net numeric',b'Fixes #1720 by removing the std calcs that make use of Math.Net numeric. \r\n\r\n'
384069162,1717,b'Update to use OnnxRuntime library instead of Sonoma',"b'Fixes #1272.\r\nFixes #1228.\r\nFixes #1514\r\n\r\nReplaces the Microsoft.ML.Scoring library with the new Microsoft.ML.OnnxRuntime library.\r\n\r\nUpgraded runtime to Onnx 1.3, with isNan operator.\r\n\r\nDescriptive error messages instead of SEH exception.\r\n\r\nXML documentation for important classes and methods.\r\n\r\nAdds a full end-to-end example for users to start with.\r\n\r\n'"
383667772,1714,b'TensorFlowTransform unit tests should not use Legacy API',b'TensorFlowTransform unit tests should not use Legacy API\r\n\r\nThis PR has the following changes:\r\n- Updated couple of TensorFlow tests to use new API. \r\n- Fix bug in ImagePixelExtractingEstimator.\r\n- Deleted redundant tests using Legacy API.\r\n\r\nCreated a separate issue #1715  to (1)  add mlcontext extension for TFTransform (2)  add TFTransform example to Microsoft.ML.Samples'
383320545,1710,b'Addition of the ValueMappingEstimator and ValueMappingTransform.',b'This will be replacing the TermLookupTransform and provide a way to\r\nspecify the mapping betweeen two values (note this is specified and not\r\ntrained). A user can specify the mapping by providing a keys list and\r\nvalues list that must be equal in size. The Estimator will then generate\r\na 1-1 mapping based on the two lists.\r\n\r\nThe PR references #754 which covers the conversion of Transformer to use\r\nthe new Estimator API.'
383315262,1709,b'Provide methods to train with validation context and initial predictor',b'Tests incoming...\r\nFix #752 '
383292423,1700,b'Adding a new CI leg for netcoreapp 3.0',b'Fixes https://github.com/dotnet/machinelearning/issues/1711\r\n'
382940051,1694,"b'[Do Not Review] :Upgrade to ML.Scoring v 1.2.0, with bug fixes and GPU/CUDA  support'","b'Fixes #1514 \r\nFixes #1228 \r\n\r\nUpgraded runtime to Onnx 1.3, with isNan operator.\r\n\r\nBetter exception handling -- clear error messages instead of generic SEH exception.\r\n\r\nGPU support via CUDA 9.2\r\n\r\nXML documentation\r\n\r\nEnd-to-end example for users to get started.'"
382908812,1692,b'Adding documentation for GAM',b'This PR adds documentation for using the GAM in the Microsoft.ML.Samples project.\r\n\r\nFixes #1645 \r\n\r\nAwaiting PR #1691 \r\n'
382907770,1691,b'Extend GAM models with methods to return model parameters',b'This PR updates `GamPredictorBase` to allow all GAM predictors to return the intercept and copies of the bin and weight arrays.\r\n\r\nFixes #1679'
382820511,1687,b'Remove adult.train and adult.test and modify all unit tests',b'\r\n'
382795373,1686,b'Obsolete API',b'We are planning removing classical APIs defined in Microsoft.ML.Legacy. The commits are organized so please read them one-by-one.\r\n\r\nFixes #1684.'
382752147,1683,"b'Conversion of DropSlots, MutualInformationFeatureSelection, and CountFeatureSelection into estimator and transformers'","b'Ongoing work on converting the transformers to estimators (#754). In this PR I convert DropSlots, MutualInformationFeatureSelection, and CountFeatureSelection into estimator and transformers with relative extensions.\r\n\r\nIn particular: \r\n1. DropSlots is converted to a transformer.\r\n2. MutualInformationFeatureSelection and CountFeatureSelection are converted to estimators.\r\n3. For both estimators, I add static extensions, and dynamic extensions to MLContext.\r\n'"
382551449,1682,"b'adding some trainer extensions on the StandardLearners catalog. Correcting namespace, and names'",b'The last PR addressing #1318. \r\nCloses #1318 '
382536710,1681,b'Spelling corrections',"b""Barge of spelling/grammar corrections I've noted over time. Sailing the high seas, enjoying the sun, occasionally noticing the one, the oddity floating where it aught not be.  """
382479455,1680,b'First round of Schema final polish',b'Contributes to #1500 \r\n\r\nAdded Schema.DetachedColumn for columns that are not bound to schema\r\nMoved Schema to Data namespace\r\n'
382447721,1678,b'Adding binary saving and loading to MLContext.Data',b'Fixes #1627 \r\n\r\n'
382443866,1677,b'Added Feature Contribution Calculation Transform',b'fixes #1644 '
382434490,1676,b'Contracts.Assert statements valid for Debug-Intrinsics',"b'Debuger is currently skipping the Contracts.Assert statements without validating them. for Debug-Intrinsics.\r\n\r\nAfter the change\r\n- If the debugger is attached and the condition is false then the debugger will  break\r\n- If the debugger is not attached, the test will get aborted\r\n'"
382411517,1674,b'Update macOS Prerequisites',b'Updating macOS prerequisites to the latest dependencies\r\n'
382369402,1671,b'WIP: Adding WhatTheFeature Scorer ',b'fixes #1644 '
382326220,1670,b'Fix problem with saving/loading empty vbuffer',b'Fix #1660 '
382046627,1664,b'Enable implicit-feedback recommendation via one-class matrix factorization',"b""This PR updates LIBMF used in ML.NET to the latest [official master](https://github.com/cjlin1/libmf) for adding a parallel coordinate descent method which solves one-class matrix factorization. It's a part of #1408 and the remaining tasks are OpenMP, SSE, and more formulations (current ML.NET treats LIBMF as a library for regression problem so that classification and ranking formulation are not allowed)."""
381901165,1663,b'Move evaluation results to separate classes',"b'Fixes #1280 \r\n\r\nNOTE:\r\n- [x]  Moved results from (Ranking, Multiclass, Regression, Clustering, Binary) evaluators to separte classes under `Evaluators/Metrics` directory.\r\n- [x] Adjusted types in dependent projects classes.\r\n- [x] Build `Release` and `Debug` successful on local :+1:  \r\n '"
381816984,1661,b'Fix problem with saving/loading empty vbuffer ',b'Fix #1660 '
381801982,1659,b'Make CpuMath internal',"b""This PR tries to make `CpuMath` internal, so that it's not going to be exposed to users. It's a part of #1519."""
381792709,1658,b'Enable PermutationFeatureImportance for Regression',"b""This is a PR to enable PermutationFeatureImportance feature for model explainability. It shows how to do PFI for a regression model.\r\n\r\nDiscussion points / open issues:\r\n* Namespace: I'm having some circular dependency issues, so MLContext.Regression.PermutationFeatureImportance() is not fully implemented yet. I've put a comment in there.\r\n* Final name: PermutationFeatureImportance or something else?\r\n* Return type: It used to be IDataView in TLC. I suggest we return List<(string featureName, RegressionEvaluator.Result metricsDelta)> instead.\r\n* Weight Filtering: TLC had weight filtering features by using IPredictorWithFeatureWeights. We can't do this in ML.NET so I removed that option.\r\n* Report file: TLC produces a text report file. I left that option out. \r\n"""
381787388,1657,b'Removed AlignedArray ',b'- Removed Aligned Array from Rff and timeseries. The only place left is FactorAwareFactorization. So I moved it to that namespace so that nobody can use aligned array anymore\r\n- Matmul and MatmulTran modified for any dimension of row and col\r\n- added some more tests for new dimension changes\r\n- corrected the base implementation of MatMulTrans\r\n- added tolerance for some tests for netcoreapp3.0\r\n\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/1018\r\nRelated to https://github.com/dotnet/machinelearning/issues/1096\r\n'
381786530,1656,b'Static extension work for time series.',b'Static extension work for time series.\r\n'
381770927,1655,b'Let me introduce RowToRowTransformerBase!',"b""I need to have base class from which I can derive OneToOneTransformerBase and some-non OneToOne transforms. We currently have ConcatColumns, TensorFlow and Onnx, and i'm working on NGramHash and StopWordRemover."""
381728015,1654,b'Fix CodeGen command and add a unit test',b'Fixes #1643 .\r\n'
381435820,1650,b'Complete VBuffer redesign',b'This completes the redesign work for `VBuffer` by removing `.Values` and `.Indices` public arrays and converts all their usages to the new pattern. This is proposed change (4) in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895.\r\n\r\n> Change the public T[] Values and public int[] Indices to public ReadOnlySpan<T> GetValues() and public ReadOnlySpan<int> GetIndices().\r\n\r\nFixes #608\r\n'
381412208,1647,b'Adding custom mapping to cookbook',b'Added custom mapping example to cookbook'
381400077,1646,b'Stop and custom words remover to estimator',b'Convert stop word remover and custom stop word remover to estimator/transformer.\r\nFix #725 '
381375266,1642,b'Fix GAM default options and values',"b'This PR updates the `TreeTrainerCatalog` entries for `GAMs` to use better choices for default (non-advanced) parameters, and updates the default values for GAMs be those specified in the GAMs `Arguments` class.\r\n\r\nFixes #1630 '"
381372509,1641,b'Fix StopWordRemoverTransform bugs',b'Fixes #1629 .\r\nAlso fix a bug with splitting a comma separated list of stop words into tokens.'
381346952,1638,b'Fix the name for GAMs in the API Catalog',"b'This is a short fix that renames GAM Trainers in the catalog to `GeneralizedAdditiveModels` from `GeneralizedAdditiveMethods` to be consistent with the common nomenclature [1].\r\n\r\n[1] Hastie and Tibshirani are generally considered to have introduced the methodology, for example in Hastie, Trevor and Tibshirani, Robert. (1986), [Generalized Additive Models](https://www.jstor.org/stable/2245459), Statistical Science, Vol. 1, No 3, 297-318.\r\n\r\nFixes #1623 \r\n'"
381333888,1637,b'Remove the uses of CreatePredictionEngine',"b'Fixes #1409. Those tests are full of copy-and-paste, so I also clean them a bit.'"
381065303,1626,b'Movement and Internalization Phase 2',"b'Continuation of the work of #1587, which itself is part of the ongoing work of #1519.\r\n\r\nThe changes are certainly best digested commit by commit, rather than just reviewing the last commit. The commmit descriptions are intended to be informative.\r\n\r\nPlease do not be afraid of the seemingly large line count. Discounting whitespace changes (mostly on account of not using `ConsoleEnvironment` in many places), the number of *actually* changed lines is really more like only 600 additions/900 deletions, as opposed to what git is reporting on my screen as on the order of ~4000 of these.\r\n\r\nIncidentally fixes #1284.'"
380972938,1624,b'Convert MissingValueDroppingTransformer to estimator',b'Convert MissingValueDroppingTransformer to estimator'
380927216,1621,b'Remove lazy parameters for GetRowCount',"b'Fixes #1531. In most cases, the `GetRowCount` is as lazy as before but in some places such as `CacheDataView` in `CacheDataView.cs`, it could need more than O(1) time to wait until the actual number of rows is available.'"
380841808,1620,b'Make Microsoft.ML.Maml a global tool',"b'Updates for #1203 \r\n\r\n@eerhardt Hopefully, I did this somewhat correctly. \xf0\x9f\x98\x84 \t'"
380839892,1619,b'Remove the copyright from the samples files',b'Fixes #1576\r\nRemove the copyright from all docs/Microsoft.Ml.Samples project sources including Program.cs and correct !code-csharp references removing ranges and comments.\r\nLeft Timeseries.cs as is due to #1577 and #1578 and range references to its content.\r\n\r\n'
380818765,1618,b'Prediction engine for time series.',b'Prediction engine for time series that updates the time series transform state at the time of prediction. Next iteration will add more tests.'
380378701,1612,b'Cookbook update for MLContext and custom mapping',b'Added 2 more cookbook samples: debugging and custom mapping.\r\nAdded MLContext to the list of high-level concepts.'
380090801,1607,"b'new names, per 1318 description.'",b'More changes to the #1318 saga. \r\n\r\n'
380061597,1606,b'renaming transforms -> transformers',b'Addresses part of #1318 renaming transforms to transformers. \r\nSome addl cleanup. \r\n\r\n'
380014070,1605,"b'Adding features arg to clustering CV, removing test'","b'Addressing comments in #1584, which was merged before comments could be addressed.\r\n\r\n'"
379892336,1601,b'Schema propagation for custom estimator',b'Fixes #1600 \r\nAdds schema propagation for custom mapping estimator'
379507628,1599,b'Remove parsing perf  bottleneck in WordEmbeddingsTransform',"b'This PR improves the performance of reading large text files and affects two of our most time-consuming benchmarks.\r\n\r\nInfo:\r\n\r\n```ini\r\nBenchmarkDotNet=v0.11.2, OS=Windows 10.0.17134.345 (1803/April2018Update/Redstone4)\r\nIntel Xeon CPU E5-1650 v4 3.60GHz, 1 CPU, 12 logical and 6 physical cores\r\nFrequency=3507503 Hz, Resolution=285.1031 ns, Timer=TSC\r\n.NET Core SDK=3.0.100-alpha1-009697\r\n  [Host]     : .NET Core 2.1.5 (CoreCLR 4.6.26919.02, CoreFX 4.6.26919.02), 64bit RyuJIT\r\n  Job-OXDQNP : .NET Core 2.1.5 (CoreCLR 4.6.26919.02, CoreFX 4.6.26919.02), 64bit RyuJIT\r\n```\r\n\r\nBefore:\r\n\r\n|                                         Method |    Mean |\r\n|----------------------------------------------- |--------:|\r\n| WikiDetox_WordEmbeddings_OVAAveragedPerceptron | 286.7 s |\r\n|                WikiDetox_WordEmbeddings_SDCAMC | 184.1 s |\r\n\r\nAfter:\r\n\r\n|                                         Method |     Mean |\r\n|----------------------------------------------- |---------:|\r\n| WikiDetox_WordEmbeddings_OVAAveragedPerceptron | 169.02 s |\r\n|                WikiDetox_WordEmbeddings_SDCAMC |  65.32 s |\r\n\r\nWhich is two minutes less to read the huge file for both benchmarks which results in a **x3** boost for `WikiDetox_WordEmbeddings_SDCAMC`  and **40%** improvement for `WikiDetox_WordEmbeddings_OVAAveragedPerceptron`\r\n\r\nReading the file was a bottleneck:\r\n\r\n![image](https://user-images.githubusercontent.com/6011991/48314555-83f82680-e5cb-11e8-8948-cc5a22a07c95.png)\r\n\r\nI have applied all possible optimizations and parallelized this operation.\r\n\r\nI am going to post a detailed description on Monday.'"
379454991,1598,b'Increase time out on build to 45',"b""I'm seeing builds getting cancelled at 40 minutes which might have completed otherwise. Increasing timeout to 45 minutes, in #1561 it was suggested we should bump this as well."""
379431139,1597,b'Add README to baseline output folder',"b""Fix for #100.\r\n\r\nTook an initial guess at what the README file would contain, but if there's more that needs to be included, I'll gladly add it. \xf0\x9f\x98\x84 \t"""
379430856,1596,b'Add doc comments',"b""Fix for #1265\r\n\r\nCurrently marked as WIP since I'm sure the doc comment summaries may need to be updated to provide more information. Also, the `netstandard` version of the `CpuMathUtils` will also need to be updated with doc comments."""
379367550,1594,b'Exposing normalizer parameters ',b'Fixes #1616 by exposing the weights of the normalizers. \r\n'
379342440,1593,b'Update Readme.md',b'Update the code snippet'
379337947,1592,b'Convert Ngram transform to estimator/transformer',b''
379322402,1590,b'more transform => transformer renaming',b'Fixes part of #1318 \r\n\r\n'
379061169,1588,b'Renaming transforms to transformers Part 1',b'Addresses part of the third section of #1318 \r\n\r\n'
379056001,1587,b'Movement and Internalization Phase 1',"b""Internalization and sometimes movement of many types. Ongoing work related to #1519 as we try to limit user exposure to internal infrastructure types.\r\n\r\n* Move Sweeper types into Sweeper assembly, out of Core.\r\n* Internalize all command line related infrastructure, including ArgumentAttribute. Move different types into different files.\r\n* Internalize all types in Core's Utils folder.\r\n* Considerable cleanup of TimeSeries abstractions to hide them since they made public some things in Core's Utils.\r\n* Internalize PFA export support.\r\n* Internalize ONNX export support.\r\n* Internalize all the base cursor classes.\r\n* Internalize all ITreeEnsemble and related types.\r\n* Clean up some pointless code.\r\n* Make ModelSave/Load contexts uninstantiable.\r\n\r\nThe commits are mostly structured where I'm removing one sort of thing at a time, so if you want to break it up, just compare adjacent commits. It works pretty well, except sometimes I found I hadn't quite completed the job of a prior commit at a later point and didn't feel like rewriting history, so there is a small amount of pollution.\r\n\r\nThere's no particular reason why I started where I started or stopped where I stopped, except that it's the end of the day."""
379047168,1586,b'Multiple inputs output support for OnnxTransform.',b'Fixes issue #1585.\r\n\r\nThis PR is to add support for Onnx models that have multiple input/outputs. The current version of the transform allows for only single input and single output.\r\n\r\n\r\n'
378983763,1584,b'Adding CrossValidate to ClusteringContext',b'Fixes #1575 '
378959354,1583,b'Moved WhiteningTransform to HalLearners',b'Fixes #721.\r\n\r\nMoved the whitening transform file to HalLearners. Also had to move the corresponding mlcontext extensions.\r\n'
378921485,1582,b'Convert Gcn and LpNorm to estimators',b'Convert gcn and lp norn to estimators'
378869367,1580,b'Introduce VBufferEditor and hide VBuffer.Count',"b'This PR executes on proposed changes (1) and (5) in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895.\r\n\r\n> 1. Keep Length, but hide/private Count\r\n\r\n> 5. The most drastic proposed change is how to actually mutate a VBuffer.\r\n\r\nThis introduces `VBufferEditor`, and uses it in almost all the places where VBuffers are mutated. There are a few stragglers that I will fix in a subsequent PR, but I thought this change was large enough, so I cut it off once I could make `.Count` private.\r\n\r\nWorking towards #608.'"
378753325,1578,b'Split timeseries samples',b'Fix #1577'
378559185,1574,b'More OVA Fixes',b'Bug in OVA. Under the hood we were using LinearSVM as the binary classifier all the time \r\n\r\n'
378542051,1573,b'Fixing typo in ExtractWordEmbeddings',b'Fix #1548 \r\n'
378508339,1571,b'Printing out test scores in training phase for FastTree',"b""The current `FastTree` (defined in `FastTree.cs`) has a nice framework for handling the presence of training, validation, and test sets. This PR exposes this functionality to users by\r\n\r\n1. Extend `MLContext` defined in `TrainContext.cs`\r\n2. Create `Test` (defined in `Test.cs` under `FastTree` project) following what we having been doing for validation set.\r\n3. Make sure that the test data set can be accessed in `FastTree.InitializeTests()` when using `Train` or `TrainTest` commands.\r\n\r\nFixes #1572.\r\n\r\nLet's see an example command of how this works.\r\n\r\nCommand: `machinelearning>dotnet bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.1\\MML.dll train data=breast-cancer.txt loader=text{col=Label:R4:0 col=Features:R4:1-9} valid=breast-cancer.txt test=..\\TLC\\Samples\\breast-cancer.txt tr=frr{tf=1 iter=2} out=model.zip`\r\n\r\nExpected outcome printed on screen:\r\n```\r\nStarting to train ...\r\ntrain.L1=0.291333712794827\r\ntrain.L2=0.483948548949904\r\nvalid.L1=0.291333712794827\r\nvalid.L2=0.483948548949904\r\ntest[0].L1=0.291333712794827\r\ntest[0].L2=0.483948548949904\r\ntrain.L1=0.244367572749215\r\ntrain.L2=0.399588099386731\r\nvalid.L1=0.244367572749215\r\nvalid.L2=0.399588099386731\r\ntest[0].L1=0.244367572749215\r\ntest[0].L2=0.399588099386731\r\n```\r\ntrain*/valid*/test* are scores computed using the specified training/validation/test set."""
378503408,1570,b'Register assemblies in  legacy predictor model',b'fixes #1150'
378496767,1569,b'Added support for caching and filtering',b'Fixes #1568 . Adds caching and range filtering as MLContext extensions'
378472284,1566,b'Add debug asserts',"b'Potential fix for #828 \r\n\r\n@briancylui Is this on the right track to what was needed? Do you think we should do the same to the `AvxIntrinsics` class, as well?'"
378292503,1564,"b'Pass hashBits, invertHash to OneHotHashEncodingEstimator'",b'Fix #1560 '
378155580,1563,b'Moving IModelCombiner to Ensemble and related changes',"b'This is an elaborate series of changes that are, incredibly, actually related and strongly dependent on each other. The end result is positive, but how we got there was kind of a wild ride. Hearken to my tale.\r\n\r\n* Move IModelCombiner out of Core to Ensemble since it clearly belongs there,\r\n  not in Core.\r\n\r\n* Remove dependency of Ensemble on FastTree.\r\n\r\n* Remove learners in Ensemble having defaults of FastTree or indeed any\r\n  learner. (Incidentally: fixes #682.)\r\n\r\n* Rename *FastTree* Ensemble to TreeEnsemble, so as to avoid namespace/type\r\n  collisions with that type and Ensemble namespace.\r\n\r\n* Add dependency of FastTree to Ensemble project so something there can\r\n  implement TreeEnsembleCombiner.\r\n\r\n* Resolve circular dependency of FastTree -> Ensemble -> StandardLearners ->\r\n  Legacy -> FastTree by removing Legacy as dependency of StandardLearners,\r\n  since no project we intend to keep should depend on Legacy.\r\n\r\n* Move Legacy specific infrastructure that somehow was in StandardLearners\r\n  over to Legacy.\r\n\r\n* Fix documentation in StandardLearners that was incorrectly referring to the\r\n  Legacy pipelines and types directly, since in reality they have nothing to\r\n  do with the types in Legacy.'"
378096347,1561,b'Publish test artifacts on timeout and not just failure',"b'Fixes #1556.\r\n\r\nIn this PR I add a condition so that we post test artifacts not just in case of failures, but also in case of timeouts, by using `not(succeeded())` condition.\r\n\r\nI also set the timeout limit for the running the tests to 40 min (this does not include the build time). Still working on the right syntax for the timeout setting.\r\n'"
378083716,1559,b'Update README to add 32 bit support in 0.7',b'Also change .NET Core 2.0 - >2.1 as 2.0 is now out of support.\r\n\r\n'
378078134,1558,b'sample link and xml format  fixes',b'Fixes #1557 by correcting the link and XML format. \r\n'
378064821,1555,b'adding more logging to failures.',"b""Fixes #1477 by adding more logging around the failure on the baselines number comparison. \r\n\r\nLogging on failures looks like this now:\r\n\r\n```\r\nValues to compare are 0.49224 and 0.49223705031518167\r\n\t AllowedVariance: 1E-07\r\n\t delta: 2.9E-06\r\n\t delta2: 2.9E-06\r\n\r\n*** Failure: Output and baseline mismatch at line 3: 'FieldAwareFactorizationMachine\\FieldAwareFactorizationMachine-CV-breast-cancer.txt\r\n```'\r\n"""
378038696,1552,b'Fixes #1550 - Type mismatch in TransformSamples.SampleInfertDataWithFeatures',b'Fixes #1550\r\n\r\nType mismatch in TransformSamples.SampleInfertDataWithFeatures\r\n'
378038636,1551,b'Making RowMapperTransform a template',"b'Making RowMapperTransform a template, avoiding load/save for wrapped transformers containing non-wrapped transformers\r\n\r\n'"
377994073,1547,b'Cherrypick for release 0.7',b'Cherry-pick into release for 0.7'
377989098,1546,b'removing space that is causing the docs CI to fail',b'removing space in the XML that is causing the docs CI to fail\r\n\r\n'
377973621,1545,b'Fix ConvertingTransform bug',b'Fixes #1544 .'
377726645,1543,b'Reduce public surface area of ColumnType and family.',"b'Fixes #1533 .\r\n\r\n* Introduce internals-visible-to on core, and [BestFriend] attributes on key members of ColumnType (see issue #1519) so internally the implementation can use the old conveniences.\r\n\r\n* Make type-specific data available only on the relevant type, for example, Size on VectorType, which replaces all of VectorSize, ValueCount, IsKnownSizeVectorType.\r\n\r\n* All `IsX` and `AsX` should be replaced with `is XType` or `as XType`.\r\n\r\n* Also in the spirit of the above, hide other redundant conveniences.\r\n\r\n* De-emphasize rather entirely DataKind as having anything to do with ColumnType, at least publicly.\r\n\r\n* Validate new public surface by having the tests use it instead of the old way.\r\n\r\n* No more odd `DimCount`/`GetDim` accessors on vector types, instead an `ImmutableArray<int> Dimensions`.\r\n\r\nNote that I was deliberately trying to err on the side of hiding as much as possible, but I believe the set of actual information you can get out of a type is identical. (Up to the presence of `DataKind`, which I am trying to de-emphasize possibly to the point of killing it outright, though not in this PR.)'"
377649240,1538,b'Added dynamic API snippets to cookbook',"b'Added the dynamic API equivalent for all the snippets that were using static API, except for the snippet that uses onFit, which is not supported by dynamic API yet.\r\n'"
377642246,1536,b'Introduce VBuffer GetValues and GetIndices',"b'Use the new methods in place of Count and Values/Indices in as many readonly situations as possible.\r\n\r\nWorking towards #608 \r\n\r\nSee proposed change (4) in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895\r\n\r\nEventually, `Count`, `Values` and `Indices` will be hidden/private on VBuffer and `GetValues()` and `GetIndices()` will be the only way to read these values.'"
377615479,1535,b'Fix TextLoader.Argument (HasHeader=true) for Iris dataset',b'Fixes #1537 \r\n\r\nDropped `HasHeader=true` from  `GetMultiClassPipeline` and `MakeIrisTextLoaderArgs`\r\n'
377554293,1530,b'Make whitening tests work on hosted macs',"b'Fixes #1506.\r\n\r\nThis PR fixes the error encountered when running tests on hosted macs.\r\n\r\nIt turns out that the problem was due to a mismatch in the parameters sizes and values that were passed  to the MKL gemm function during training. In particular, as part of the test, the transform is trained on empty data. An empty array of data was then passed to the MKL gemm function, while the parameters specifying the size of the data were were non 0. This situation was apparently handled for other OS and processors versions, but not on the hosted macs, and was therefore giving an error. \r\n\r\nThe fix that I propose is to initialize zero matrices of the right size instead of training when provided empty data as an input.\r\n\r\nThis PR also deletes a command in the build.proj that was still downloading the wine dataset (found by @vaeksare) when building.'"
377546563,1527,b'Publish build logs in Azure DevOps CI.',b'Fixes #1473 by publishing logs from the build as artifacts in the Azure DevOps pipeline:\r\n\r\n![image](https://user-images.githubusercontent.com/37886197/48021283-045ee900-e0ed-11e8-84a6-63b68ed2f48a.png)\r\n\r\nPublishes the following files:\r\n- msbuild.log\r\n- msbuild.err\r\n- msbuild.wrn\r\n- binclash.log\r\n- init-tools.log\r\n- Microsoft.ML.Predictor.Tests/../TestOutput/*\r\n'
377478618,1526,b'WIP stateful prediction engine for TS.',b'Stateful prediction engine for time series that triggers getters for columns created by time series transform to update the state at prediction time.'
377169341,1524,"b'More trainer extensions, bug fixes and consistency across trainer extensions'","b""Gam trainers placed in the right context, and removing arguments they weren't using from their signatures. \r\nFixes #1521 making the order of the parameters consistent. \r\nAddresses part of #1318 by adding the FastForest extensions. \r\n\r\n"""
377037690,1520,b'Add the `BestFriend` attribute for restricting cross-assembly internal access',b'Fixes #1519 .'
376976979,1518,"b'Debugger preview for data, schema, metadata, VBuffer'","b'Fixes #1242 . Adds debugger previews for data, schema, metadata, VBuffer'"
376957184,1517,b'Add release notes for ML.NET 0.7',b'This adds release notes for ML.NET 0.7'
376955258,1516,b'Examples for Timeseries',b'Added example docs\r\nFix doc strings\r\nfixes #1483 \r\nfixes #1479 '
376905168,1513,"b""Better explanation of Score's initial value""",b'Fixes #1489 so that the example becomes compatible with older C# versions. \r\n\r\n'
376901361,1512,b'Enable calibration in OVA',b'Partial fix for #1387 \r\n\r\n- Calibration was being skipped for OVA. This PR fixes that issue. (Accuracy drop mentioned in #1387 improves from 0.4 to 0.8)\r\n\r\n- Still need to find root cause for not getting expected accuracy (0.98) when using OVA + AveragedPerceptron.'
376865308,1511,b'Fix WordHashBagTransform bug',b'Fixes #1510 .'
376691388,1509,b'Correct spelling of ComputeWeightedAuc',b'Correct spelling from `ComputWeightedAucCore()` to `ComputeWeightedAucCore()`\r\n'
376638192,1507,b'Fix zero based key input from C# classes for matrix factorization',"b""Because of the getter in IDataView created from C# classes doesn't handle key properly, matrix factorization fails whenever there is a zero-based key input. This PR fixes this issue by modifying getter upon [peek](https://github.com/dotnet/machinelearning/blob/d68388a1c9994a5b429b194b64b2b0782834cb78/src/Microsoft.ML.Api/ApiUtils.cs#L53), which doesn't care key type at all. The major fix occurs in `src/Microsoft.ML.Api/DataViewConstructionUtils.cs`.\r\nIn addition, a test based on matrix factorization is made for preventing such an error from happening again in `test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs`.\r\n\r\nIn addition, matrix factorization also got polished. We clean up unnecessary fields and make its comments better.\r\n\r\nFix #1442.\r\n"""
376540461,1505,"b""Don't drop columns that are not specified""",b'Fixes #1504 .'
376471893,1499,b'Always checks label in FFM trainer',"b""Fix #1498. Label column is always needed so we can't ignore this check."""
376437138,1497,b'Fix build error',"b'Fix for #1495 \r\n\r\n@eerhardt This _should_ fix the build. Building in Visual Studio showed the errors and after these changes, the build passed. If I missed anything, just let me know. Thanks!'"
376435664,1496,b'Mark UInt128 and other obvious readonly structs as readonly.',"b""This is a follow-up to #1475. Using the `in` keyword with structs that aren't marked as `readonly` can cause perf issues due to hidden copies being made.\r\n\r\n`UInt128` is used in `ValueMapper` and potentially other places that may use the `in` keyword. Marking it as `readonly`, and while I was here - going through all `struct` declarations and marking the obvious ones as `readonly` as well.\r\n\r\n"""
376279291,1494,"b""Adding another handful transform's extensions""",b'Part of #1318 \r\n\r\nAdds more transform extensions in the catalog. '
376260015,1493,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
376198730,1486,b'Adding third party notice and license to all NuGets',b'Adding the license file and third party notice file in the NuGet. Fixes #1297 '
376162972,1476,"b'Silence kmeans benchmarks, otherwise it treats console output as errors.'",b''
376153228,1475,"b""Convert ValueMapper to use 'in' parameters""","b'ValueMapper takes in a source value, and maps it to a destination value. The source value that is passed ""in"" is current passed by `ref`, which isn\'t correct because we don\'t want ValueMapper implementations to modify this value.\r\nChange ValueMapper (both versions) to use `in` parameters instead.\r\n\r\nThis is a follow-up to #1454 requested in the [PR feedback](https://github.com/dotnet/machinelearning/pull/1454#pullrequestreview-170020651).\r\n\r\nWorking towards #608'"
376136008,1470,b'Bump master to 0.8',b'Bump master to 0.8\r\n'
376130183,1469,b'Merge master into release/preview for 0.7',b'This PR merges master into release branch for 0.7'
376102841,1467,b'Fix unassigned public field',"b'A public field, `MatrixRowIndexColumnType`, is not assigned. Now it will get its value in the constructor.\r\n\r\nFixes #1468.'"
375845094,1465,b'Release/preview test PR',"b""Please don't merge"""
375818887,1464,b'Release/preview test PR',"b""Don't merge"""
375812732,1463,b'Release/preview test PR',"b""Don't merge. Testing release."""
375773712,1462,b'Error Identified with respect to #1454',"b""This implements the 2nd and 3rd steps in the plan outlined in #608 (comment).\r\n\r\nMake VBuffer a readonly struct.\r\nIt was always designed as readonly, we just didn't have the C# capability before now.\r\nIn methods that only actually read values from a VBuffer, change that parameter from ref to in.\r\nThis guarantees that the method won't change the reference, as was always the intention. We just didn't have the C# capability before now.\r\nWorking towards #608\r\n\r\nNote: this doesn't need to make it in for v0.7.\r\n"""
375724347,1461,b'Fix TermLookup bug and enable two unit tests',b'The TryParseKey() method changed to return true in case a numeric value is parsed but is not in the correct range. The TermLookupTransform needs to change accordingly.'
375718641,1460,b'Adding transform extensions',b'Addresses part of #1318  adding xtensions for all text related estimators. \r\n'
375681010,1458,b'Last namespace re-org',b'This is the last namespace move PR :)\r\n\r\nAddresses part of #1318 \r\n'
375654326,1457,b'more namespace move for transforms ',b'Addresses part of #1318 \r\n'
375653972,1456,b'Documentation samples for binary classifiers (Static API)',"b""Addresses #1257.\r\n\r\nAdding documentation samples for binary classifiers when using `Static API`:\r\n\r\n1) `SDCA`\r\n2) `FastTree`\r\n3) `LightGBM`\r\n4) `AveragedPerceptron`\r\n\r\nA couple of points I'd like to mention:\r\n\r\n1) I have used `adult.train` dataset both for training and testing (90/10 split) in the examples (since `adult.test` is not properly formatted).\r\n2) Since we can use for example `FastTree` in both Regression and Classification contexts, I had to rename already added examples from `FastTree.cs` to `FastTreeRegression.cs` and made sure the change is reflected in the docs so the examples point to the correct files."""
375651922,1455,b'Enhancements to online linear trainers to make them stateless.',b'* Factor stateful logic into a separate internal object.\r\n* Remove direct usage of Console.Writeline\r\n* Opportunistic fixes of minor issues.\r\n\r\nFixes #1358 .'
375645379,1454,"b""Mark VBuffer readonly and convert usages to use 'in' instead of 'ref`""","b""This implements the 2nd and 3rd steps in the plan outlined in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895.\r\n\r\n2. Make VBuffer a readonly struct.\r\n    - It was always designed as readonly, we just didn't have the C# capability before now.\r\n3. In methods that only actually read values from a VBuffer, change that parameter from `ref` to `in`.\r\n    - This guarantees that the method won't change the reference, as was always the intention. We just didn't have the C# capability before now.\r\n\r\nWorking towards #608 \r\n\r\nNote: this doesn't need to make it in for `v0.7`."""
375639861,1453,b'namespace moves for more transforms',b'More changes related to #1318 \r\n'
375619129,1452,b'Conversion of Whitening Transform to estimator with pigstensions',b'Ongoing work on converting the transformers to estimators (#754). This PR completes the conversion of the Whitening transform to estimator (previously a TrainedWrapperEstimator).\r\n'
375599717,1450,b'Add doc for MF',b'Add doc for matrix factorization trainer so that users can see what it is. Fixes #1401. '
375347283,1448,b'Adding transform extensions',b'Adding more transform extensions.Addresses part of #1318 '
375272339,1447,b'Add a DNN Image Featurizer Transform Estimator',b'Adds a new estimator for doing pretrained DNN model image featurization as a transform. This estimator calls 2 ONNX transforms in a chain in order to achieve the desired result. The first ONNX model does the preprocessing while the second one is the actual pretrained DNN. A total of 4 DNN models are available:\r\n* AlexNet\r\n* ResNet18\r\n* ResNet50\r\n* ResNet101\r\n\r\nEach model is available through its own project and a related extension method. Building that project automatically downloads the model from a CDN. The model is included with the NuGet package produced by that project when the code is distributed. Fixes #1232\r\n'
375229289,1444,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
375212662,1439,b'Convert to estimator',b'Breaking my convertonite curse and making Convert transform an estimator/transformer'
375174201,1437,b'Fix bug in KeyToVector PFA conversion',b'Fixes #1436 .'
375147057,1434,b'Disabling newly added LightGBM tests for x86',b'Disabling newly added LightGBM tests for x86\r\n\r\nFixes #1435 1435. '
375142319,1433,b'Fix WordTokenize bug',b'WordTokenize transform ignores the per-column term separators argument.\r\nFixes #1431 .\r\n'
375133749,1432,b'Moves dotnet-server shutdown to official build yml file',"b'Fixes #1404 and #1421. \r\n\r\nIn this PR, I move the command of shutting down dotnet processes to the official build yml file. This should solve the problem of tests failing but status report being positive (the error outputs were hidden by the output of shutting down the dotnet-server).\r\n\r\nI also disable two LightGBM test on x86, as LightGBM is not supported on x86.\r\n\r\nI disabled two Matrix Factorization tests on x86. Matrix factorization should work on x86, but the current iteration of the code does not support it. This bug is being tracked as part of #1441.\r\n\r\nI tested manually queuing 5 official builds and they all succeeded: https://devdiv.visualstudio.com/DevDiv/_build?definitionId=8739'"
375116942,1430,b'Fix metadata bug in multi output regression',b'Fixes #1429 .'
375041726,1428,"b'Improved existing Append summaries, clarifying that a new object is created'","b""Fixes #1402 \r\nFollowing the issue suggestion, I updated the existing summaries for Append methods, stating that a new object is created.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
375027506,1427,"b""Corrected typo (mainly it's -> its)""","b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
375022530,1426,b'able to mapper same column names when append',b'Fix #1425'
374754750,1420,"b""Baseline comparisons with tolerance should not exit when values don't match (#218)""","b'Fix #218 \r\ncall Fail() with a detailed error message saying which file and which line the error occurred in, and continue comparing the rest of the files in the unit test.'"
374736378,1418,b'PipeBase<TMessage> implement the Dispose Pattern (#930)',b'Fix #930'
374734332,1417,b'Rename LinearClassificationTrainer to SdcaBinaryTrainer(#1069)',"b'Fix #1069 \r\nRename LinearClassificationTrainer to SdcaBinaryTrainer, like `SdcaMultiClassTrainer`, `SdcaRegressionTrainer`'"
374731583,1416,b'Remove IndentingTextWriter in favor of the existing IndentedTextWriter(#1241)',b'Fix #1241\r\nUse System.CodeDom.Compiler.IndentedTextWriter'
374670215,1415,b'make ConsoleEnvironment internal',b'addresses https://github.com/dotnet/machinelearning/issues/1284'
374656608,1414,"b'Suggest a typo in ""Update ROADMAP.md""'","b""Fixes   suggest to fix a typo.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ x] There's a descriptive title that will make sense to other developers some time from now. \r\n"""
374654679,1413,b'Directory separator char in filenames for model zip',b'Fix #1019\r\n\r\nuse Path.DirectorySeparatorChar in filenames for model zip'
374622348,1412,b'Add Git submodule init to Windows build instructions',b'Submodules must also be initialised in Windows to fetch the necessary dependencies.\r\n\r\nRelated to issue #1399.\r\n\r\n'
374602187,1410,b'Convert LdaTransform to IEstimator/ITransformer API',b'This PR converts LdaTransform to the IEstimator/ITransformer API paradigm (a work item related to #754)\r\n\r\n- LdaTransform is now subclass of OneToOneTransformerBase\r\n- Deleted the previous wrapped version.\r\n- Added pigsty extensions\r\n- Added onFit delegate to return LdaState info to user\r\n\r\nCreated separate issue #1411  for providing a convenient way of providing LDA topic summary info to the user'
374561175,1407,b'Enable statically-typed matrix factorization',"b'As title. One test is added and we also replace `Assert.True` with `Assert.InRange` for another matrix factorization test. Fixes #1395, fixes #1398. Also fixes #1283 by adding [a test](https://github.com/dotnet/machinelearning/pull/1407/commits/235eafe553ee1eb2745537198395b57a4e8ff248) where the expected data structure contains two key-typed variables.'"
374557733,1406,b'Custom mapping transformer',"b'First version of custom estimator, with MEF injection\r\nAlso some minor fixes'"
374555959,1405,b'Rename RefPredicate to InPredicate and change ref to in.',"b""This is laying the foundation for #608. In order to allow `in VBuffer` parameters, we have to change `RefPredicate` to `InPredicate`, because you can't take a `ref` to an `in` parameter.\r\n\r\nWorking towards #608\r\n\r\n"""
374463705,1400,b'Correct Git clone command for Linux building',"b""libmf has been introduced through a Git submodule and submodules need to be initialised before building. Adding the '--recursive' flag performs the needed initialisation.\r\n\r\nFixes #1399.\r\n\r\n\r\n"""
374395639,1394,b'Remove performance regressions discovered in #1194',"b""In #1194 I have analyzed and compared the results of all ML.NET end-to-end benchmarks for .NET Core 2.1 with native library for math and .NET Core 3.0 with managed CpuMath.\r\n\r\nI found 3 quite huge regressions. After some extra profiling I found the reason:\r\n\r\n**Most of the benchmarks use very short arrays, typically with just 4 or 14 floats. For such small arrays, the vectorization makes no sense.** This PR adds a very simple check: if the number of floats is small, don't run the vectorized code.  (/cc @AndyAyersMS this explains no perf boos in ML.NET scenarios after switch to new vectorized code)\r\n\r\n|                             Type |              Method |     Toolchain |         Mean |      StdDev |\r\n|--------------------------------- |-------------------- |-------------- |-------------:|------------:|\r\n| KMeansAndLogisticRegressionBench |    TrainKMeansAndLR | netcoreapp2.1 |   566.601 ms | 168.8636 ms |\r\n| KMeansAndLogisticRegressionBench |    TrainKMeansAndLR | netcoreapp3.0 |   568.968 ms |  92.8586 ms |\r\n|            PredictionEngineBench | MakeIrisPredictions | netcoreapp2.1 |     3.896 ms |   0.0542 ms |\r\n|            PredictionEngineBench | MakeIrisPredictions | netcoreapp3.0 |     3.820 ms |   0.0106 ms |\r\n\r\n\r\nIn 2.1 profiles we have calls to native dll:\r\n\r\n![image](https://user-images.githubusercontent.com/6011991/47570276-11821800-d936-11e8-980d-458d7ea66da0.png)\r\n\r\nBefore my fix the code was calling the new managed CpuMath\r\n\r\n![image](https://user-images.githubusercontent.com/6011991/47570345-3bd3d580-d936-11e8-81c5-e14312960a89.png)\r\n\r\nNow there is no call to CpuMath if the vectors are small (and in most of our scenarios, they are). Moreover, the method gets inlined and we have no `pinvoke` cost compared to 2.1 and native dependency.\r\n\r\n![image](https://user-images.githubusercontent.com/6011991/47570389-57d77700-d936-11e8-9c46-4fa2284734ad.png)\r\n\r\n@danmosemsft I will need to take a look at the way ML.NET devides work into smaller tasks and change something on the upper level to take advantage of the vectorization.\r\n\r\n"""
374367351,1393,b'FastTreeRankingTrainer expose non-advanced args(#1246)',"b'Fix #1246\r\n\r\nadd `numLeaves` , `numTrees`, `minDocumentsInLeafs`, `learningRate`  args'"
374250886,1392,b'Adding training statistics for LR in the HAL learners package.  ',"b'To address #612 maybe we can introduce another LR trainer in the HAL learners package. \r\n\r\nHeresy #1 - it derives from LR making this last one not sealed, and exposing more of its fields.\r\nHeresy #2 - the only thing this learner does differently from LR is to compute the std in the training stats are requested. \r\n\r\nI think afa usability this is more accessible than just having a utility method that takes the LR trainer/predictor and recomputes the stats with std. \r\n\r\nThought?\r\n\r\n@GalOshri @TomFinley @eerhardt \r\n\r\n'"
374198083,1390,b'Kill all dotnet processes after build',"b'Fixes #1357.\r\n\r\nAs explained in more detail in the issue, a process must be leaking during one of the build jobs (the windows one), and is likely not terminating dotnet.exe. Subsequent attempts to clean the repo fail.\r\n\r\nIn this PR I implement the fix that is suggested in the issue: call dotnet build-server shutdown after the build process terminates. \r\n\r\nI manually queued this change 10 times on VSTS, and the error that we were seeing has not appeared again. There 2 other errors that did show up 2 times, but seem to be unrelated to this.\r\n\r\n'"
374179303,1388,b'move regex to right place to reduce test time',b'Fixes #1382 fixes #1348'
374158114,1385,b'Change TryParse* methods to return false instead of throw.',b'Fixes #1374 .'
374150267,1384,"b""Let's not create regex for every function call.""",b'Maybe this would speed up our tests?\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/1382\r\nhttps://github.com/dotnet/machinelearning/issues/1348\r\n'
374129991,1383,b'Update Microsoft.ML.CpuMath.nupkgproj',b'please provide the language used in this script.\r\n\r\n\r\n'
374102502,1381,"b'[Fixes] #1078: ML.Ensemble assembly is not part of any NuGet, hence, \xe2\x80\xa6'","b'[Fixes #1078 : ML.Ensemble assembly is not part of any NuGet, hence, removed it\r\nReplaced Microsoft.ML.Ensemble with Microsoft.ML'"
373812154,1378,b' Insert missing closing-code-block tag (markdown) in CookBook',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
373807778,1377,b'Bug in check for existence of Group field #1372',b'I changed Group for Schema according to @mjmckp  advice in the test.\r\n\r\n'
373796715,1376,b'Fixed issue #1372',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
373757091,1375,b'TryParse methods should not throw',b'Change methods in Conversion.cs to return false in case of failure instead of throwing. Fixes #1374 .'
373753101,1373,b'Update README.md fixed typo',b''
373736257,1371,b'Replaces ChooseColumnsTransform and DropColumnsTransform with SelectColumnsTransform',"b'Replaces ChooseColumnsTransform and DropColumnsTransform with SelectColumnsTransform. \r\n\r\nThese changes include:\r\n* Updates to SelectColumnsTransform to respect ordering when keeping\r\ncolumns. For example, if the input is ABC and CB is selected, the output\r\nwill be CB.\r\n* Updates to code that used Choose or Drop columns, replacing with\r\nSelectColumns.\r\n* Updates to baseline output for tests to pass\r\n* Re-enabled the SavePipeline tests\r\n\r\nThis fixes #1342\r\nThese changes are also related to #754'"
373720809,1370,b'Adding extensions for Hal learners. More namespace re-ogr.',b'Addresses part of #1318: more namespace re-org and catalog extensions. \r\n\r\n'
373672615,1368,b'Add System.Memory as dependency in ML.CpuMath.nupkgproj file',"b""Fixes #1359 \r\n\r\n- add `System.Memory` package reference to `Microsoft.ML.CpuMath.nupkgproj` file . \r\n- remove `System.Runtime.Intrinsics.Experimental` package reference as it's no longer required.\r\n\r\n\r\n"""
373628938,1365,"b""CountFeatureSelection transform doesn't work with text""",b'Fixes #1364 .'
373612304,1361,b'sample for dynamic SDCA binary',b'Addresses part of #1209 by adding a sample for the dynamic SDCA binary classification. \r\n\r\n'
373468473,1355,b'MLContext extension for reader',b'Add extension method in TextLoaderSaverCatalog to create reader\r\n'
373335180,1353,b'Delete EnableDefaultCompileItems conditions',"b""Fix #1351\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
373316937,1352,b'Trainer estimator cleanup for FastTrees and LightGBM',b'1- Adding the GroupId to the TrainerEstimatorBase class. \r\n2- Adding the static xtensions for LightGM Multiclass and Ranking. Fixes #1314 \r\n3- Reorganizing the static and dynamic xtensions for FastTree and LightGBM\r\n\r\nAddresses part of #1318 \r\n\r\n'
373207004,1350,b'Add support for resetting progress channels',b'Fixes #1349 .\r\n'
373192226,1347,b'Moving FastTree from Runtime to Trainers. ',b'Addresses part of #1318 by moving the Runtime.FastTree to Trainers.FastTree\r\n'
373156564,1346,b'Update to latest CookBook and MLHighlevel concepts',b'Update URLs to latest CookBook and MLHighLevel concepts\r\n\r\n\r\n'
373145961,1345,b'Added more details and references',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
373097834,1343,b'Bug Fixes on some paths of the native side',b'Fixes https://github.com/dotnet/machinelearning/issues/1344\r\nThese bugs were not caught by the tests earlier because everything is still sending the stuff as Aligned. The code changes are made to just match with managed side code. no new logic has been added here\r\n\r\ncc @eerhardt  @yaeldekel @tannergooding \r\n'
372972701,1341,b'Fix spelling errors',"b'""enviroment"" should be ""environment""'"
372823492,1340,b'Learners live on Microsoft.ML.Trainers',b'Addresses part of #1318  by moving all the trainers and predictors in Microsoft.ML.Trainers. \r\n\r\nThe rest of the work about xtensions and consistency will come in the next PR. \r\n\r\n'
372724215,1338,b'WIP word remover to estimator',b'Convert stop and custom word remover to estimator land\r\n\r\n'
372499354,1336,"b'add text ""Azure,"" to line 9'","b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
372347090,1334,b'[Fixes] #525: Renamed the NGramNgramExtractor class to a better name',b'Fixes #525 : Updated the following:\r\n1. Renamed the NGramNgramExtractor to NGramNgramText2Vector.\r\n2. Renamed the NgramExtractor to NgramExtractClass.'
372346023,1333,b'Convert PcaTransform to Estimator API',b'This PR is proper conversion of PcaTransform to estimator API (a work item related to #754):\r\n* Overhauled PcaTransfrom to be OneToOneTransformerBase\r\n* Deleted the Wrapped versions\r\n* Extended the unit tests\r\n* Lots of code cleanup/simplifications\r\n'
372343898,1332,b' Added to readability of ISSUE_TEMPLATE.md 7001f81',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
372244179,1330,"b""Evaluation result classes shouldn't be nested under the Evaluator cla\xe2\x80\xa6""","b""\xe2\x80\xa6sses #1280\r\n\r\n1. Moved nested classes Result and CalibratedResult.\r\n2. Refactored to EvaluatorMetrics and BinaryClassificationMetrics\r\n3. Fixes #1280 \r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
372177661,1328,b'Renaming some transforms to follow the estimator naming convention.',"b'Addresses part of #1318 by renaming some transforms to ""actionPerformingEstimator""\r\n'"
372168355,1327,b'Fix merge break',"b'PR #1236  included a change in the signature of the CategoricalEstimator ctor, and it was checked in right after PR #1217 which uses the old signature...'"
372154939,1326,b'WIP: Conversion of Whitening Transform to estimator with pigstensions',b'Ongoing work on converting the transformers to estimators (#754). This PR completes the conversion of the Whitening transform to estimator (previously a TrainedWrapperEstimator).\r\n\r\nThis also fixes #721.'
372151044,1324,b'fix conditional in for loop of GetDependencies()',b'Just a minor unintended one character change in the condition check of a loop in GetDependencies method of CompositeRowToRowMapper.\r\nfixes #1325'
372108021,1321,b'Transforms components docs',"b'Addresses P1 non-Image transforms for #1209. \r\n\r\nAdds samples for Nomalizers, Text, Cocat, Term, KeyToVal\r\n\r\n'"
372085476,1320,b'-0 parsing corrected and digitsofPrecision added',b'Fixes https://github.com/dotnet/machinelearning/issues/1199\r\nworking towards https://github.com/dotnet/machinelearning/issues/1096\r\n\r\nThis PR corrects about 20 tests by providing the precision numbers as well as parsing the -0 correctly for 3 of the tests\r\n\r\n\r\ncc @danmosemsft @eerhardt @shauheen @tannergooding '
371994473,1315,b'Fixed the formatting of the XML documentation for the OnnxConverter.',"b""Fixes #1260 \r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
371798688,1311,b'Fix the formatting of the XML documentation for the OnnxConverter',"b""Issue #1260\r\n----------------\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
371784003,1310,b'Add GC.KeepAlive() for tensor variables',"b""Adding a GC.KeepAlive() to prevent compiler from optimizing and prematurely GC'ing tensors. This is related to issue #1228 \r\n\r\n"""
371780804,1309,b'Introducing PR verification x86 CI build',"b'Fixes #1389.\r\n\r\nThis PR adds a PR verification build for x86. Starting an x86 build is not too difficult, however running tests requires downloading an x86 .NET Core SDK\r\n\r\nMain contributions:\r\n- runs debug and release x86 build \r\n- depending on the argument -buildArch=x86 it will download the .NET Core SDK for x86 or for x64 to be able to run the tests\r\n'"
371729983,1306,b'Introducing official x86 CI build',b'Fixes #1295.\r\n\r\nAdding x86 official build. I tested the official build directly on VSTS and it succeeded. I also created a x86 App locally and tested that the nuget packages published to VSTS by the build worked.\r\n'
371721476,1305,"b'Change IModelCombiner to not be generic, and add unit tests'",b'Fixes #1304. '
371698372,1303,b'Hash estimator/transformer applicable to all numerics and bool',"b'Fixes #1031. Hashes all numeric types, and boolean types. ""Time"" types are omitted, because I don\'t anticipate great desire for them, but they could potentially be more easily added.\r\n\r\nI engaged in some trickery around the JIT\'s handlings of generics and value types in order to maintain efficiency of the previous ""explicit"" implementation. Please see the comment starting line 526 in the last commit (as of the time of writing) for more info.\r\n\r\nThere are to start three commits, that are deliberately structured in a way so as to be useful:\r\n\r\n1. Introduction of benchmarks,\r\n2. Simplification of code,\r\n3. Expanding of types.\r\n\r\nThe benchmarking is somewhat interesting. The variation between different runs of the benchmarks was all over the place with the old code (for some reason), but not on the new code for some reason. I\'m not quite sure why. Anyway these were the first runs from each.\r\n\r\n## Before\r\n\r\n|            Method |        Mean |      Error |     StdDev |\r\n| ----------------- |------------ |----------- |----------- |\r\n|  HashScalarString |  4,738.1 us | 146.250 us | 168.421 us |\r\n|   HashScalarFloat |  1,172.0 us |  30.922 us |  34.370 us |\r\n|  HashScalarDouble |  1,535.2 us |  28.194 us |  26.373 us |\r\n|     HashScalarKey |    965.2 us |  18.733 us |  18.398 us |\r\n|  HashVectorString | 28,295.6 us | 554.444 us | 569.373 us |\r\n|   HashVectorFloat | 10,442.6 us |   6.021 us |   5.338 us |\r\n|  HashVectorDouble | 12,501.8 us | 240.539 us | 267.359 us |\r\n|     HashVectorKey |  9,839.5 us | 270.684 us | 265.848 us |\r\n\r\n## After\r\n\r\n|            Method |        Mean |      Error |     StdDev |\r\n| -----------------:|------------:|-----------:|-----------:|\r\n|  HashScalarString |  4,769.2 us | 125.379 us | 144.387 us |\r\n|   HashScalarFloat |  1,094.3 us |   4.808 us |   3.754 us |\r\n|  HashScalarDouble |  1,529.9 us |  33.315 us |  29.533 us |\r\n|     HashScalarKey |    960.3 us |  17.989 us |  19.248 us |\r\n|  HashVectorString | 28,513.9 us | 520.837 us | 487.191 us |\r\n|   HashVectorFloat |  9,932.0 us | 231.398 us | 257.198 us |\r\n|  HashVectorDouble | 12,264.1 us | 286.483 us | 329.915 us |\r\n|     HashVectorKey |  9,118.8 us | 178.890 us | 167.334 us || \r\n'"
371635536,1301,b'Fix loading of old ConcatTransform models',b'Fixes #1300 .'
371633162,1299,b'Fix null reference exception in InternalSchemaDefinition and add unit tests',"b'Fixes #1298 , and adds some unit tests to test this case.'"
371438119,1296,b'Update CONTRIBUTING.md',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
371328436,1294,b'Convert CharTokenize to estimator',b'Convert CharTokenize to estimator'
371317165,1293,"b""PredictionFunction doesn't reuse output""","b'Fixes #1279 \r\nFixes #1138 \r\n\r\nPredict call no longer reuses the output object.\r\nTo retain the capability for efficient prediction, I added another overload to Predict which takes the output object as a parameter.'"
371316183,1292,b'Use FMA instruction in CpuMath for .NET Core 3',b'Fix https://github.com/dotnet/machinelearning/issues/832\r\n\r\nTest with `..\\..\\Tools\\dotnetcli\\dotnet.exe run -c Release-Intrinsics --allCategories=Fma`\r\n\r\n@eerhardt @tannergooding PTAL'
371315938,1291,"b'ML.NET supports x64 bits, not any 64 bits'","b""I believe our native assemblies are only compiled for x64\r\ne.g. we don't support ARM64\r\nSo, we should say x64, not just 64 bits, right?\r\n\r\n"""
371294227,1290,b'Loading old model files is broken.',"b""Older model files are failing to load due to FpTail checks in the model validation code. These checks weren't happening in the old model loading code, and they now fail on some older models.\r\n\r\nFix this by returning early when it is an older model, and there are no strings. This preserves the old behavior.\r\n\r\nFix #1289\r\n\r\n"""
371265784,1285,b'Convert WordTokenize to estimator',b'Convert WordTokenize to estimator'
371167122,1281,"b'Extension on IDataReader<IMultiStreamSource>, and DataReader<IMultiStreamSource, TShape> to read from one or several file paths, rather than requiring constructing an IMultiStreamSource'","b'Addresses part of  #1090  in this first iteration, by adding a Read extension method taking a string as param, on the IDataReader<IMultiStreamSource>. \r\n\r\nStill looking at how to make so all the derived classes of DataReader<IMultiStreamSource, TShape> can have a Read that takes a string as param. \r\n\r\n'"
371019572,1278,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
370936914,1277,b'Updated ModelHeader.cs to remove TLC references',b'Reference to Issue #1273 \r\n\r\nChanged The exception messages to remove TLC references in them. Added ML.NET reference in place of TLC.\r\n\r\n\r\n\r\n'
370910768,1276,b'Convert TextNormalizer to estimator',b'Convert TextNormalizer to estimator\r\n\r\n'
370882795,1275,b' OnnxTransform freezing - replace  tensor.CopyTo(List<float>) with tensor.CopyTo(float[]).',"b'Fixes #1228.\r\n\r\nReduce the number of data copies of a tensor. Use the Tensor.Copy() method to move contents directly into destination, rather than into a list[T] first, and then destination. \r\n\r\n'"
370768267,1274,b'Same implementation for Sparse Multiplication for aligned and unaligned arrays',b'Working towards https://github.com/dotnet/machinelearning/issues/1018\r\n'
370375288,1270,b'WIP: Introduce ReadOnlyVBuffer and use it all over.',b'This is a prototype of one direction we could take VBuffer - introduce a ReadOnlyVBuffer for methods that are guaranteed not to modify the buffer. That way a caller can safely be assured that the buffer will not be mutated during the method.\r\n\r\nWorking towards #608.'
370374613,1269,"b'Replace DropColumns,KeepColumns and ChooseColumns with SelectColumns'","b'This adds the SelectColumns Transform and Estimator that is replacing\r\nthe DropColumns and ChooseColumns Transforms. With this check-in, Drop\r\nand Choose are still in the code base but will be removed. In order to\r\nsupport loading older models, SelectColumns supports loading in Drop and\r\nChoose transforms. The changes include:\r\n- Implementation of the SelectColumnsTransform,\r\nSelectColumnsDataTransform and SelectColumnsEstimator\r\n- Backward compatibility with Drop and Choose columns by providing\r\nfunctions on SelectColumns that will be called when loading the model.\r\n- Entry point apis for calling select from the command line.\r\n- Additional tests.\r\n\r\nThese changes are related to #754.\r\n\r\n'"
370312760,1266,b'Added Documentation snippets for regressor trainers',"b""Added FastTreeRegression and LightGBM documentation samples to resolve #1256 \r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
370288900,1264,b'Logistic regression for classification problems',"b""Implementation for logistic regression which can be used for classification problems such as sentiment analysis.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
370265407,1263,b'Making MF to be a part of ML.NET',"b'This PR is mainly for porting an internal MF module to ML.NET. Fixes #1262, fixes #763, fixes #1297. A notice file is added for including licenses of external packages.\r\n'"
370254966,1261,b'updating with the info for mlnetmkldeps 0.0.0.7',b'Recording the MKL functions used for the 0.0.0.7 package\r\n'
370018395,1258,b'Fix spelling',b''
369852212,1254,b'Estimators for Timeseries SSA / IID ChangepointDetection and SpikeDetection transforms',"b'* Created Estimators for SSAChangePointDetector, SSASpikeDetector,  IidChangePointDetector, IidSpikeDetector\r\n* Added unit tests '"
369790713,1253,b'ml_hin.md',"b""Some basic point on machine learning translated in hindi..!!\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
369755906,1252,b'ML Context to create them all',"b'Fixes #1098 . \r\nAdds a couple extensions for transforms, and almost all trainers.\r\nAdds text loading and saving, model loading.'"
369744891,1249,b'Export WordEmbeddingsTransform to ONNX',"b'Implements the ability to export the WordEmbeddingsTransform by converting it to an ONNX model, as well as expanding the functionality of some existing structures to allow for more efficient conversion implementation. The detailed conversion strategy can be found in comments inline. Fixes #1248 \r\n\r\nTesting was done through running the model on the same input using ML.NET and Lotus runtime directly using python bindings, producing the same results. The verified ONNX model (run in Lotus to check results) saved in Json format is used as a baseline for the formal tests.\r\n\r\nThe resulting ONNX model looks as follows:\r\n![wordembeddings](https://user-images.githubusercontent.com/42353187/47462992-d0550100-d799-11e8-9267-a206aabd48ba.JPG)\r\n'"
369698942,1243,b'Fix string normalization in tests',"b'Since the `%Source%` path can be a substring of the `%Output%` path, we should replace the larger one first.\r\n\r\nFixes #810\r\n'"
369622038,1240,b'Move build to Hosted macOS and remove unnecessary LightGBM reference.',"b'After updating LightGBM, we can now move build to Hosted macOS.  Also removed unnecessary LightGBM reference in response to comment on #1234.'"
369612590,1238,b'Uncomment the correct code',b'Two very minor changes for fixing #1239:\r\n- Make one comment more clear\r\n- Uncomment the correct line of declaring variable name in ONNX graph\r\n\r\n'
369603296,1236,"b'Fix ResultProcessor bug, LogisticRegression bug and missing value conversion bug'","b""- LogisticRegression doesn't pass the training stats to the predictor: fixes #1205 .\r\n- ResultProcessor has code that doesn't build: fixes #1186 .\r\n- Missing value conversion: fixes #1187 .\r\n- Sweeper needs to load all components into ComponentCatalog: fixes #1188 ."""
369334498,1234,b'Update to version of Lightgbm with no runtime dependency on GCC.',b'Update to version of Lightgbm with no runtime dependency on GCC.\r\n\r\nRequires adding installation of libomp to Mac build phase. (It now has a runtime dependency on the standard OpenMP (libomp) instead of the GCC implementation (libgomp)).\r\n\r\nFixes #1067 and #494.\r\n'
369260354,1230,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
369230433,1229,b'Refactor CpuMathUtils',"b'- Allow it to take Spans instead of arrays.\r\n- Remove redundant overloads\r\n- When multiple spans are accepted, always use an explicit count parameter instead of one being chosen as having the right length.\r\n\r\nWorking towards #608'"
369030470,1227,b'Grammar corrected in README.md',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
368973553,1224,b'exposing the biases for multi-class logistic regression',b'Resolves #1061\r\n'
368873170,1218,b'Common Implemenatation for MatMul and MatMulTran for both aligned and unaligned arrays',"b'Fixes https://github.com/dotnet/machinelearning/issues/1245\r\nFor inputs that are not naturally aligned (the alignment is not a multiple of 4), it does exclusively unaligned loads\r\nFor all other inputs, it will do at most two unaligned loads (one each for any leading/trailing unaligned elements) and all other loads will be aligned.\r\n\r\ncc @tannergooding @eerhardt @danmosemsft @TomFinley '"
368869162,1217,b'Conversion of NAIndicatorTransform to estimator with related pigstensions',b'Ongoing work on converting the transformers to estimators (#754). This PR converts the NA Indicator transform to estimator and adds the relative pigsty extensions. \r\n'
368803504,1213,b'updating_files_with_LinearClassificationTrainer',"b""Fix #1069 \r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
368779593,1212,b'Save Kmeans in ONNX ',b'Address #1211 .  This PR implements a converter for ML.NET Kmeans predictor. Detailed explanation and a visualization of the conversion code is inlined in the source file.\r\n\r\nHere is a Kmeans in ONNX example (ArgMax should be ArgMin though):\r\n![image](https://user-images.githubusercontent.com/3524474/46757244-74a95480-cc7e-11e8-968a-e0fffa4f93b9.png)'
368772398,1210,"b'Adding missing parenthesis, line 91'","b""Adding missing parenthesis in sample code, line 91\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
368446866,1208,b'Turned TensorFlowEstimator into non-trivial estimator and removed shuffling as part of TensorFlowTransform.',b'This PR fixes #1106 and it also fixes #1110.\r\n\r\n- Converted TensorFlowEstimator into non-trivial estimator because of training feature.\r\n- Removed the shuffling of data that was being done internally in TensorFlowTransform (was commented out due to #1106). The idea is to give user more control over the shuffling by allowing them to use the ShuffleTransform in their pipeline explicit. This also reduces the number of parameters in TensorFlowTransform.Argument class. Please see the modified tests for use-cases. \r\n'
368420526,1206,b'Enabling FFM tests',b'Resolves part of #404 \r\n'
368357896,1200,b'Update Load8 with GatherVector256 instruction for .NET Core 3',b'Update Load8 with GatherVector256 instruction for .NET Core 3. Fix https://github.com/dotnet/machinelearning/issues/1195\r\n\r\nBefore the change:\r\n![before](https://user-images.githubusercontent.com/18431130/46692878-3435d200-cbbd-11e8-9123-86fa62cfc6ab.PNG)\r\n\r\nAfter the change:\r\n![after](https://user-images.githubusercontent.com/18431130/46692901-40ba2a80-cbbd-11e8-9037-c561745bdb3e.PNG)\r\n\r\ncc\\ @adamsitnik @eerhardt\r\n\r\n\r\n\r\n'
368248193,1193,b' Enable a QuantileRegression Test & Fix Duplicated Baseline Files',"b'Enable CommandTrainScoreEvaluateQuantileRegression, add the dataset and the necessary baselines.\r\n\r\nThe only baseline changes were of the form that were caused by dotnet/corefx#31847.\r\n\r\nAllow BaseTestBaseline to check Common first.\r\n\r\nA lot of baseline tests have duplicated baselines between debug and release. Allow BaseTestBaseline to check the Common baseline directory for a baseline file first.\r\n\r\nAlso, I cleaned a bunch of dead code from BaseTestBaseline.\r\n\r\nFix #410'"
368054407,1192,b'Snapping average perceptron and OGD to the other constructors.',"b""Addresses part of #910. \r\nWon't close #910 as part of this PR, to deal with the calibration in AP separately. \r\n\r\n"""
368004165,1191,b'Exposed TensorFLow session as TensorFlowModelInfo class',"b'This PR fixes #1157 where loaded `TFSession` is wrapped into `TensorFlowModelInfo` class.\r\nIn addition to that, the `TensorFlowModelInfo` provides following methods to query schema\r\n\r\n- GetModelSchema(): Get all the information in the model as `ISchema` object.\r\n- GetInputSchema(): Get only input related information from the model as `ISchema` object. It is useful for the case when the graph is very large and user cannot locate inputs in such a large graphs.\r\n\r\nPlease see the modified test for more insights.\r\n\r\n'"
367980880,1189,"b'Adding a sample for Vector<T> ConcatWith<T>(this Scalar<T> me, params ScalarOrVector<T>[] others)'",b'Adding a sample to use in the documentation\r\n\r\n'
367931007,1185,b'skipping the MulticlassTreeFeaturizedLRTest on osx debug',"b""This is the main checking hurtle.. I'll log an issue about dealing with it separately. \r\n\r\n"""
367881882,1184,b'sweeping the space of link formats',b'Trying to correct the link format for the sample referenced from the documentation. \r\n'
367874202,1182,b'adding the functions used to build MlNetMklDeps for 0.0.0.6',"b'Added the functions used, the nuspec, and the versions of mkl where the custom binaries got built from. \r\nThis complement #1103 by adding the info about how those packages get built. \r\n\r\nAfter checking this in, will follow with the info about 0.0.0.7'"
367578236,1179,b'General grammar fix',"b""General grammar fix and added the missing word\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
367494778,1178,b'Update LinearClassifierTrainer.cs ',"b""Fix #1069 \r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
367451553,1177,b'Update loops in CpuMath to be more efficient',b'Fixes issue #835 '
367441694,1176,b'renamed LinearClassificationTrainer',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
367432608,1174,b'Spanish Language added.',b'Spanish MX translation added in readme.'
367429816,1173,b'Spanish Language added.',b'Translation to spanish MX added.\r\n\r\n\r\n'
367405834,1172,b'Add successful load checks to ImageLoaderTransform',"b""Check to make sure the loaded image Bitmap is valid, and throw an error if it's not. Fixes #1171 """
367386207,1169,b'Fix TensorFlowScorer duplicate parameter name Model',b'* Fix TensorFlowScorer duplicate parameter name Model\r\n* Add unit test to detect duplicate parameter names in entrypoints\r\nfixes #1039 \r\n\r\nNew unit test detected duplication of parameter names in following components:\r\nData.DataViewReference\r\nModels.CrossValidator\r\nModels.CrossValidationResultsCombiner\r\nModels.PipelineSweeper\r\nModels.PipelineSweeper\r\nModels.SweepResultExtractor\r\nModels.TrainTestEvaluator\r\nTransforms.TwoHeterogeneousModelCombiner\r\nTransforms.ManyHeterogeneousModelCombiner\r\n\r\nI would like to have a separate PRs to fix these entrypoints. The new unit test will prevent further duplication from now on.'
367370330,1167,b'Converted Schema to a class',b'Created a Schema class for eager schema.\r\nConverted existing row mappers to use Schema.\r\n\r\nFixes #764'
367367769,1166,b'WIP: adding a nuget to package the datasets. ',b'The samples that appear in our documentation should have code that the user can copy/pate and execute. \r\nFor that purpose packaging the datasets in a NuGet whose namespace we can reference from the samples. \r\n\r\nAddresses #1137 \r\n\r\n'
367361346,1165,b'Update README.md',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
367199869,1164,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
367076338,1163,b'Changing the namespace where the trainers live',b'Resolves #1162 \r\n'
367069490,1161,b'Remove Done method from IPipe',"b'Two donut people walk into a bar.\r\n""Are we done?"" ask first one.\r\n""No we are not dumb!"" answers second.\r\n\r\nFixes #803.\r\n\r\n@yaeldekel If you think this would slowdown your current project, feel free to block it until you done with it.\r\n'"
367039789,1160,b'Provide action to set Arguments class in SDCA pigstensions',b'fixes https://github.com/dotnet/machinelearning/issues/1121'
367021142,1158,b'WIP enable MTA',"b""I'm just curious what would happen if I turn on AppartmentState in our tests."""
366966946,1155,b'TrainUtils.Train does not have consistent API usage',b'TrainUtils.Train does not have consistent API usage for the calibrator argument (#1023)\r\n\r\nUpdates the API signature for TrainUtils.Train to take in an IComponentFactory<ICalibratorTrainer>.\r\n\r\nFixes #1023'
366875198,1152,b'WIP: Conversion of ensemble trainers to estimators',"b'Ongoing work on converting the trainers to estimators (#754). This PR converts ensemble trainers (RegressionEnsembleTrainer, EnsembleTrainer, and MulticlassDataPartitionEnsembleTrainer).\r\n\r\nStill requires more work on determining the right API for the ensemble trainers. '"
366871698,1151,b'Update README.md',b'Minor addition to README'
366833725,1149,b'Create links to detail sections',b'\r\n'
366679303,1147,b'Remove explicit ComponentCatalog parameter',b'ValidateNodes and EntryPointNode now use the ComponentCatalog\r\nproperty of IHostEnvironment.\r\n\r\nFollowing the conversation with @Ivanidzo4ka at #1135 \r\n\r\n'
366602653,1145,b' Fix MatchNumberWithTolerance to better compare floating-point values',b'This updates `MatchNumberWithTolerance` to better compare floating-point values and enables it on Windows.\r\n\r\nThe previous algorithm was not properly accounting for the distribution of binary floating-point values and would not allow a match for numbers that could have been reasonably considered as equivalent.'
366549418,1143,"b'Improvements to the ""Scale"" SIMD algorithm'","b'For inputs with fewer elements than can fit in the Vector type, it falls back to scalar code.\r\nFor inputs that are not naturally aligned (the alignment is not a multiple of 4), it does exclusively unaligned loads\r\nFor all other inputs, it will do at most two unaligned loads (one each for any leading/trailing unaligned elements) and all other loads will be aligned.\r\n\r\ncc @eerhardt @tannergooding @danmosemsft '"
366537606,1142,b'add .NET Core 3.0 support for the benchmarks',"b'@Anipik works on making the 3.0 test pass, the Benchmark test was failing so here is the fix for it'"
366529435,1141,b'Updating the CopyColumnsEstimator and Transform to use common code (#706)',b'This builds on the Estimator conversion for the CopyColumnsTransform.\r\nThis change is mainly refactoring as common code has moved to base level classes.\r\n\r\nThis change is the following:\r\n       - CopyColumnTransform now derives from OneToOneTransformerBase\r\n       - CopyColumnEstimator now derives from TrivialEstimator\r\n       - CopyColumnTransform::Mapper now derives from MapperBase\r\n       - Removed code that was no longer needed due to these changes\r\n'
366500309,1140,b'General grammar and punctuation fixes in README.md',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
366491704,1139,b'New API overview: added AsDynamic call',"b""The example at the end of the [overview of new ML.NET API](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetHighLevelConcepts.md#prediction-function) doesn't use `AsDynamic`:\r\n```csharp\r\nvar inputData = env.CreateDataView(new InputExample[] { example });\r\nvar outputData = model.Transform(inputData);\r\nvar output = outputData.AsEnumerable<OutputPrediction>(env, reuseRowObject: false).Single();\r\n```\r\n\r\nSo, it looks that the `AsDynamic` call in the cookbook example is not necessary.\r\n"""
366224070,1135,"b""Remove ComponentCatalog from EntryPointGraph's and GraphRunner's constructors""","b'Fixes #1113 .\r\n\r\nThe constructors now use env.ComponentCatalog as their catalog, instead of a catalog being passed as an argument. All call sites were changed accordingly.'"
366201200,1134,b'Conversion of Hogwild SGD to estimator',b'Ongoing work on converting the trainers to estimators (#754). This PR converts Hogwild SGD  (StochasticGradientDescentClassificationTrainer binary classification trainer). \r\n\r\n'
366197167,1132,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
366120094,1127,b'Release/preview',b'#N/A'
366113853,1126,b'Adding prediction benchmarks using legacy LearningPipeline API',"b'Adds the same benchmarks as in `PredictionEngineBench.cs` in #1014 but using the legacy `LearningPipeline` API. We want to post results publicly to show the great speed improvements in single prediction performance that were made just by switching to the new `Estimators` API, followed by further improvements that were made to the new API for prediction performance. \r\n\r\n#1013 \r\n'"
366101960,1125,b'Improve code readability',"b""Remove comment and move code to a new private function with a descriptive name\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
366088589,1123,b'Update Readme',b''
366083095,1122,b'Convert RFF transform to estimators',b'This PR converts RFF transform to IEstimator and add PigstyExtension.'
366001300,1119,b'Cherrypick release notes for 0.6',b'Cherry-pick into release for RC3 0.6'
365967495,1118,b'Update build yaml to use official container functionality',"b'We were using a pre-release Azure DevOps feature to do our Linux builds: `_PREVIEW_VSTS_DOCKER_IMAGE`. This feature is now an official feature, so we should switch to the officially supported functionality.\r\n\r\nI also moved the PR validation Linux queue to use the Azure DevOps hosted Linux machines.'"
365868264,1117,b'Fixed a grammatical error in windows-instructions',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
365752477,1116,b'Release/preview',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
365721913,1115,b'Static pipelines now handle types with PipelineColumn properties.',"b'* Update the internal infrastructure to accomodate these types,\r\n* Update the Roslyn analyzer to accomodate these types.\r\n* Update the tests so that they exercise this capability.\r\n* Opportunistically fix some problems with the Roslyn analyzer\r\n  brought up in this work.\r\n\r\nFixes #1085.'"
365719721,1114,b'Minor updates to 0.6 release notes: ONNX example link and prediction benchmarks',b'This makes the following updates to the 0.6 release notes:\r\n- Add a link to a test showing how the ONNX scoring transform can be used\r\n- Add a link to benchmarks on the improvement in prediction engine performance and correct the speedup noted.'
365689026,1112,"b'Improvements to the ""Sum"" SIMD algorithm'","b'Does some cleanup so that we have a single ""Sum"" algorithm (rather than one for aligned and one for unaligned inputs).\r\n\r\nFor inputs with fewer elements than can fit in the `Vector` type, it falls back to scalar code.\r\nFor inputs that are not naturally aligned (the alignment is not a multiple of 4), it does exclusively unaligned loads\r\nFor all other inputs, it will do at most two unaligned loads (one each for any leading/trailing unaligned elements) and all other loads will be aligned.'"
365688655,1111,b'Conversion of Multi Class Naive Bayes classifier to estimator',b'Ongoing work on converting the trainers to estimators (#754). This PR converts the Multi Class Naive Bayes classification trainer.\r\n'
365624165,1105,b'XML documentation references cs code for examples',b'Addresses  #637 by creating the docs/samples older where we can host the projects for our examples. \r\n\r\nAdded one such example for SDCA regression. '
365278126,1102,b'Add release notes for ML.NET 0.6',b'This adds release notes for ML.NET 0.6.'
365088448,1099,b'Add Onnx and TensorFlow projects to console project',b'fixes https://github.com/dotnet/machinelearning/issues/1081'
365049322,1094,b'Cherrypick to update release for 0.6',b'Cherrypick into release for RC2 0.6'
365039382,1093,b'Document the APIs for examining the topology of a TensorFlow graph',b'This PR adds documentation for two methods:\r\nTensorFlowUtils.GetModelSchema\r\nTensorFlowUtils.GetModelNodes\r\n'
365008887,1091,b'CustomPipelineColumn',b'Fixes https://github.com/dotnet/machinelearning/issues/1043'
364740644,1089,b'Char array for separators in word tokenizer',"b'Fixes #935.\r\n\r\nSwitched the string separator in word tokenizer by a character array. Each character in the array is taken as being a separator, instead of having a comma separated string. \r\n\r\nNeed to add tests.'"
364729436,1088,b'Added training method that accepts initial predictor for Symboli SGD estimator',b'Fixes #1087.\r\n\r\nThis PR restores the ability to train SymbolicSGD estimator starting from the weights of a previously trained predictor.\r\n\r\nI added a  test to demonstrate that it works. '
364725899,1086,b'update ml.scoring library to stable version',b'Bumping up version of dependencies from pre-release to stable\r\n\r\n'
364693722,1084,b'More pigstensions',"b'ongoing work to address #754. \r\nThis PR adds the xtensions for AP, OGD, LR, Multi-LR, and Poisson Regression. '"
364692541,1083,b'Temporary fix for warning issue in KeyToValueTransform',"b""This is a temporary fix for the issue #1059.\r\n\r\nAs outlined by Tom, we suppress the warning temporarily. There will thus be no warning when a the KeyToValueTransform is used with types that don't support missing values (e.g. strings, int, bool).\r\n\r\nThe next steps are also outlined by Tom's comment, and will involve providing a default value to the KeyToValueTranform for missing values, as well as throwing when a missing value is encountered if a default value was not provided. """
364690998,1082,b'Ensure all Microsoft.ML assemblies are loaded by the LearningPipeline API.',"b'This way, all components are registered before the Experiment tries to instantiate them.\r\n\r\nFix #1042\r\n'"
364665423,1080,b'OnnxTransform: Fix 3 bugbash bugs',b'Fixes #1050 #1051 #1053 '
364662553,1079,b'Cumulative changes based on 0.6 bag bash',b'Fixes #1057 \r\nFixes #1044 \r\nFIxes #1056'
364645294,1077,b'Updated documentation for TensorFlowTransform',b'Fixes #1038 \r\n\r\n1. modified sample code\r\n2. fixed links and description text \r\n3. updated doc to mention we now support TF SavedModel format\r\n\r\n'
364614616,1076,b'Add a workaround for the tests hanging while loading MKL.',"b""The workaround is to ensure the MKL library is loaded very early in the test process, so it doesn't cause the deadlock.\r\n\r\nWorkaround #1073\r\n\r\nAnother deadlock also occurs when running TestAutoInference and TestPipelineSweeper in parallel. Marking these tests to not run in parallel anymore.\r\n\r\nWorkaround #1095 \r\n\r\nMoving back to the Azure Hosted VS2017 pool to run the tests now that we've narrowed the deadlocks down."""
364589918,1075,b'Change ML.NET to work with .NET Framework 4.6.1',b'Fixes #1072 .\r\n\r\n'
364587691,1074,b'Finish the sentence in TextLoader static pipeline extension method',"b""Fixes #1046.\r\n\r\nAlso given that the goal is to not have the shape parameters be exclusively value-tuples, I want to get out of the habit of calling them `TTupleShape` but instead `TShape`, which I just opportunistically did while I'm at it.\r\n\r\nI also noticed I had not written anything in the `env` parameter documentation. It's not a terribly helpful statement, but better than leaving it blank as I had."""
364461836,1070,b'Provided the version name for macOS 10.12.',"b""Helps the user to relate to the macOS version faster as some users may know the version name instead of the version ID.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
364310241,1068,b'Ranker train context and FastTree ranking xtensions',"b'ongoing work to address #754 . \r\nThis PR adds the RankerContext, and the FastTree extension for the FastTreeRanker. \r\n\r\nStill not complete because it fails to retrieve the MaxDcg metric. \r\n\r\n'"
364263845,1066,b'Update lightgbm nuget version so that it does not depend on gcc. [WIP]',b'fixes #1067\r\nfixes #494'
364244442,1063,b'Making TensorFlowTransform trainable.',b'This PR addressed #951 where user can retrain TensorFlow models using TensorFlowTransform in ML.Net.\r\n\r\nThe implemented training functionality is an add-on feature on top of current implementation of TensorFlowTransform where model scoring using TensorFlowTransform is untouched.\r\n\r\nCurrent implementation includes\r\n- Retraining of un-frozen model (saved with simple_save method in python).\r\n- Support for batch training\r\n- Serializing retrained model into ML.Net stream\r\n\r\n#### ToDo\r\n- [SOLVED] ~~Serializing retrained model into ML.Net stream. <b>It seems like a big challenge right now because TensorFlow C-API does not support serialization of `TFSession` objects which contains all the retrained parameter.</b>~~\r\n- Turn TensorFlowEstimator from TrivialEstimator to NonTrivialEstimator. This is because TensorFlowTransform now trains model in one of the constructor call where `TrainingArguments` are passed (Will be done as separate PR #1110).\r\n- Think about how we can get ride of data copying during creation of batches.\r\n'
364235811,1058,b'Remove the error tracing when assembly loading fails for Maml.',"b""Also adding our native assemblies to the list to skip, so they aren't attempted to be loaded.\r\n\r\nFix #1034\r\n\r\n"""
364162708,1037,b'Bump master to 0.7',b'\r\n\r\n'
364160336,1036,b'Merge master into release/preview for 0.6',b'This PR merges master into release branch for 0.6'
364156415,1035,b'Use full test name in estimator routine.',"b'Fixes #1064\r\nWe need to use FullTestName variable, otherwise we get name collisions.\r\nhttps://dnceng.visualstudio.com/public/_build/results?buildId=24407&view=ms.vss-test-web.test-result-details here is example how it fails right now.'"
363812714,1033,b'Convert categorical hash to estimator',b'Convert Cathash to estimator'
363782669,1032,"b'Add instructions for building for .NET Core 3.0, and make them work.'","b'Fix #1011 \r\n\r\nThere are a couple manual steps necessary to build for .NET Core 3.0. Adding instructions on how to do it, and changing the build infrastructure so the build actually works.'"
363777482,1030,b'Update our Windows CI leg to use the non-Hosted Windows queue',b'We are getting a random test hang using the hosted Windows queue. Changing to a non-hosted queue so we will be able to debug it if it happens again.\r\n\r\n/cc @shauheen '
363775056,1029,b'Remove DnnAnalyzer from the Microsoft.ML.TensorFlow nuget',b'Fixes #1027 .'
363767206,1028,b'Remove AlignedArray and Aligned Matrix from src and tests',b'Fixes https://github.com/dotnet/machinelearning/issues/1018\r\n\r\ncc @danmosemsft @eerhardt @TomFinley @yaeldekel @shauheen '
363709674,1025,b'Use  TextLoader.Create in unit test TensorFlowTransformCifarSavedModel',"b'Fixes a build break in master cause by  two commits #853 and #970  that went in almost at the same time \r\n\r\n(the two commits work fine by themselves, but there is a dependency between them which caused master to fail)\r\n\r\nThe fix is to use TextLoader.Create instead of env.CreateLoader(""Text..."")\r\n\r\n'"
363704997,1024,b'Updated the building instructions to specify supported VS version',b'Fixes #894.\r\n\r\nWith an old version of VS (15.1) there are build errors. We should specify that our instructions have been verified for VS version 15.8 or higher. \r\n\r\nI specified that we have verified that our project builds with VS version 15.8.0 and higher in the building instructions for windows. I tested that with version 15.8.0 there are no build errors. \r\n'
363678306,1022,b'Merge ModuleCatalog into ComponentCatalog.',b'This completes the ComponentCatalog refactoring work for `v0.6`.  It merges the `ModuleCatalog` and `ComponentCatalog` types into a single type.\r\n\r\nFollow up for #208.\r\n'
363623527,1021,b'Update input arguments in CpuMath files',b'Fix for #824 \r\n\r\nMarked as WIP since this may have more updates to come.\r\n\r\n@briancylui @eerhardt @tannergooding Feel free to let me know if anything already done should be changed.'
363452419,1020,b'LightGbm pigstensions',b'Ongoing work to address #754 \r\nThose are the LightGbm binary and regression extension methods. \r\n\r\n'
363375439,1017,b'Converted PcaTransform into Transformer using TransformerWrapper.',b'This PR implements a work item related to #754.'
363370340,1016,b'replace e.g. with for example',"b""I've noticed in some of the API docs for ML.NET that I was browsing that there is a heavy use of e.g. which is against our style guide rules (https://docs.microsoft.com/en-us/style-guide/a-z-word-list-term-collections/e/eg). So replaced it across the board on the repo. \r\n\r\nOnce this is merged, I can create a separate PR for i.e. which also shouldn't be used."""
363364750,1014,b'Add Benchmark test for PredictionEngine',b'Adds a benchmark test to measure performance of doing many single predictions with PredictionEngine.\r\n\r\nCloses #1013 '
363361545,1012,b'Conversion of Parallel Stochastic Gradient Descent (SymSGD) to estimator',b'Ongoing work on converting the trainers to estimators. This PR converts the Parallel Stochastic Gradient Descent classification trainer (SymSGD).'
363351758,1009,b'Adding the extension methods for FastTree classification and regression',"b'OnGoing work to address #754. \r\n\r\nAdded the extensions to the Binary and Regression context for the respective FastTree trainers. \r\nRanking coming on a separate PR, since it needs a bit more work with the context and elevator changes. \r\n\r\n'"
363342491,1008,b'Move towards being able to build for x86',"b'This is work towards https://github.com/dotnet/machinelearning/issues/97\r\n\r\nIt allows you to build using `build.cmd -buildArch=x86` and, if you manually set the correct testhost, it allows the tests to pass.'"
363330592,1007,b'Rename the static pipeline namespace.',"b'* Microsoft.ML.Data.StaticPipe to Microsoft.ML.StaticPipe.\r\n* Columns now in StaticPipe as opposed to StaticPipe.Runtime.\r\n\r\nThis should fix some of the more obnoxious issues with intellisense involving pipeline columns, just so long as they actually use `Microsoft.ML.StaticPipe` namespace.\r\n\r\nRefinement and iteration of #778.'"
363322105,1005,b'TrainTestSplit function',b'Part of #754\r\nAdded TrainTestSplit function to training contexts.'
363303187,1002,b'Conversion of ordinary least square linear regression (OlsLinearRegression) to estimator',b'Ongoing work on converting the trainers to estimators. This PR converts the ordinary least squares linear regression (OlsLinearRegression).\r\n\r\n\r\n'
363281146,1001,b'Fix the benchmarks',"b""1. Both I and @davidwrighton run today into an issue with NuGet packages restoring.  ML.NET defines the sources in [Directory.Builds.props](https://github.com/dotnet/machinelearning/blob/eb264892e75219b1f191d3c35fcbc636186b8acf/Directory.Build.props#L15-#L18) file, but as suggested by @agocke in https://github.com/dotnet/BenchmarkDotNet/pull/854 BDN ignores those files and needs the classic `nuget.config` file to work. (I know it's not perfect)\r\n2. In #954 I missed the fact that there is no global config. This change sets the `RecommendedConfig` as default and when`[TrainConfig]` is used it overwrites the `RecommendedConfig`.  Few types were missing config (`[Config(typeof(SomeConfig))]`), and they were using the default config from `BenchmarkDotNet`\r\n3. I mentioned how to download external dependencies in the README file"""
363256721,999,b'Add analayzer to nuget',"b'More completion for #778, where I add the code analyzer to the nuget.\r\n\r\nThanks for help from @eerhardt !'"
363179674,998,b'Fix Issue #997',b'Get name from ColumnNameAttribute\r\n'
362831926,996,b'PcaTrainer as estimator',b'Addresses part of #754 \r\n\r\n'
362820849,994,b'Made loop bound checking in hardware intrinsics more efficient',b'Changed style to make loop bound checking more efficient.\r\n\r\nCloses #835'
362816900,993,"b'Extended contexts to regression and multiclass, added FFM pigstension'","b'Part of #754, extends #949.\r\nAdded MulticlassClassification context and RegressionContext, with corresponding Evaluate methods. Also added FFM binary trainer to the context extensions.\r\n'"
362806774,992,b'Fix a conversion bug in KeyToVectorTransform.',"b""This PR addresses #971 and #1010  with the following changes.\r\n\r\n(1) A ReduceSum is missing when Bag+ for merging\r\n    all features' one-hot vectors\r\n(2) Since this conversion depends on the input shape,\r\n    an API is added to retrieve shape of existing\r\n    variables.\r\n(3) Change the starting element of ONNX OneHotEncoder to 0 because the first valid key value (aka 1) gets mapped to 0.\r\n\r\nThis change is verified by the latest runtime. Models used for tests can be produced via\r\n`dotnet bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\MML.dll saveonnx data=TLC\\Samples\\breast-cancer.txt loader=TextLoader{col=Label:R4:0 col=Features:TX:1-2} xf=Term{col=Features} xf=keytovector{col=Features bag+} onnx=k2v.onnx json=k2v.json domain=com.microsoft`\r\nand\r\n`dotnet bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\MML.dll saveonnx data=TLC\\Samples\\breast-cancer.txt loader=TextLoader{col=Label:R4:0 col=Features:TX:1-2} xf=Term{col=Features} xf=keytovector{col=Features bag-} onnx=k2v.onnx json=k2v.json domain=com.microsoft`\r\n\r\n\r\n"""
362806130,991,b'Converted Feature selection transforms in to transformers/estimators.',b'This PR implements a work item related to #754.\r\n\r\nThe following transforms were converted in this PR.\r\n- CountFeatureSelectionTransform\r\n- MutualInformationFeatureSelectionTransform\r\n'
362775354,988,b'NO MERGE: Diagnosing why ComponentCatalog change is deadlocking a test',"b""Trying to reproduce an issue I can't reproduce on my local dev machine."""
362725648,981,b'Add dependency for System.Collections.Immutable in ML.Net nuget.',b'fixes #976\r\n'
362713982,979,b'Converting KMeans++trainer to estimator.',b'Ongoing work to address #754 \r\n\r\n'
362704321,977,b'Port Time Series',"b'Port of time series prediction. \r\n* ExponentialAverage\r\n* IidChangePointDetector\r\n* IidSpikeDetector\r\n* PercentileThresholdTransform\r\n* PValueTransform\r\n* SlidingWindowTransform\r\n* SsaChangePointDetector\r\n* SsaSpikeDetector\r\n\r\nfixes #978, #1092 and #1103 '"
362458430,974,b'undoing test changes',"b'Fixing merge errors on those two files, on the TreeEstimators PR. \r\n\r\n'"
362422753,973,"b'PredictionEngine uses IRowToRowMapper, ITransformer can create IRowToRowMapper'","b'In which we reduce the overhead of calls to `Predict` by avoiding the creation of cursors.\r\n\r\n`PredictionEngine` used to create a ""fake"" data view under the hood, by wrapping a `BatchPredictionEngine`, but only feeding in one item. This was a fairly heavy operation involving spooling up of cursors, including heavy reflection based processing on each row, etc. Now we are able to avoid this by using an existing interface `IRowToRowMapper`.\r\n\r\nThe other major part of the change is, of course, changing transformers so they *can* produce `IRowToRowMapper`, which they previously did not. In most cases this is relatively straightforward since nearly all transformers of interest are using these `IRowToRowMapper` under the hood to support their computation.\r\n\r\n* `IRowToRowMapper` enhancements, unification of some interfaces.\r\n* `ITransformer` has `IRowToRowMapper` accessor.\r\n* `PredictionEngine` now uses `IRowToRowMapper`\r\n\r\nThe effects of this are most dramatic using prediction engines *outside* of the ML.NET v0.1 pipeline API (e.g., using `IEstimator` based pipelines, pre-ML.NET v0.1 API, and so forth). The effect of this is that when predicting, now actual computation dominates the cost, as opposed to reflection based stuff. \xf0\x9f\x98\x84 Due to architectural limitations of pipeline API models, these do not see benefit.\r\n\r\nWill perhaps update with timings later.\r\n\r\nFix #986.'"
362415808,972,b' Converted LdaTransform into Transformer/Estimator.',b'This PR implements a work item related to #754.\r\n\r\nPlease only review LDA related classes. The other text transform changes are being reviewed in #953. I will merge the branches once approved.\r\n\r\nTests are disabled because LdaNative.dll is missing'
362369718,970,b'ComponentCatalog refactor',"b""This executes on the plan outlined in https://github.com/dotnet/machinelearning/issues/208#issuecomment-422136134 copied here for easy reading:\r\n\r\n## New Proposal\r\n\r\n1. We will move `ComponentCatalog` from being a static class to being an instance member on `Environment`. This has been a planned refactoring for ML.NET for a while, but hasn't been funded until now.\r\n2. We will completely remove any implicit scanning for components in `ComponentCatalog` itself. It will have public APIs to register components, but will not do any registering itself - neither by loading assemblies from disk, nor by scanning loaded assemblies.\r\n3. Other subsystems (like the GUI, command-line, Entry Points, and model loading) will be responsible for registering the components they require in the manner they require.\r\n4. During model saving, we will write the `Assembly.FullName` into the model file. We will then register that assembly with the `env.ComponentCatalog` when loading the model.\r\n    - Any model that was saved with a previous version of ML.NET, and loaded using the API, will need to explicitly register the components before loading the model. (Or they will need to save the model again with a current version of ML.NET that will save the assembly names.)\r\n\r\nUnder normal circumstances, API users won't have to explicitly register components with the `ComponentCatalog`. Using the API to train models won't require looking up components from a catalog - you just create .NET objects like normal. Loading a trained model from disk will register the components inside of it by loading the Assembly and scanning it for `LoadableClass` assembly attributes.\r\n\r\nFix #208"""
362346066,967,b'Binary train context with evaluation and SDCA',"b'Fixes #949. In which I provide a working sketch of the context object, for evaluation (both dynamic and otherwise). If we think this is a good idea then we can add more capabilities to it. (Either in this PR or future ones.)'"
362266381,965,b'Allow the creation of ONNX initializers',b'Related issue: #958.\r\nThis PR provides an ability of adding tensors into the `initializer` list of ONNX model. It may help the conversion of neural network based transforms and transforms which can be decomposed into matrix operators (some constant matrices would be saved as initializers).'
362059561,963,"b'enabling scanning the constructors with non-public visibility, and re\xe2\x80\xa6'","b'enabling scanning the constructors with non-public visibility, and reducing the visibility of some of them to avoid confusing the users.\r\n'"
362026208,962,"b'LightGBM,  Tweedie, and GAM trainers converted to tainerEstimators'",b'\r\n\r\n'
361983639,961,"b'Converted LpNorm, GcNorm and Whitening transforms into transformers/estimators\xe2\x80\xa6'",b'This PR fixes #959 \r\n'
361983424,960,b'API overview and samples',"b""Fixes #987 \r\nAdds a document describing high-level API concepts, as well as the 'cookbook' with a variety of samples."""
361956442,957,"b'Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators'","b'Fixes #956.\r\n\r\nConversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.\r\n\r\nWorking on testing the converted classes using TestEstimatorCore. '"
361943367,954,b'different config files for train and predict benchmarks',b'Fixes https://github.com/dotnet/machinelearning/issues/982\r\n- different Config files for train and test\r\n- solves problem of long running time\r\n- train benchmarks contain only one iteration as it gives more idea on how the users will use. (with no warmup iteration)\r\n- predict config is the original version\r\n\r\ncc @danmosemsft @eerhardt @adamsitnik @justinormont \r\n'
361930678,953,b'Converted listed text transforms into transformers/estimators.',b'This PR fixes #950.\r\n\r\nThe following transforms were converted in this PR.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n'
361927915,952,b'Connect Inputs and Outputs Properly and Export CopyColumnTransform to (unofficial) ONNX operator',"b""Related issue: #955 , #968.\r\n1. Add exporter for CopyColumnTransform. It only creates a ONNX node with a `type` field for encoding the transform's C# name.\r\n2. Properly connect inputs and outputs especially when they have the same name in pipeline."""
361861172,947,b'Save ConvertTransform as ONNX Operator and Control the Use of Experimental Features with a Flag',"b'1. Introduce a new argument to SaveOnnx, which is OnnxVersion.\r\n   Two values are currently allowed, ""Latest"" and ""Experimental"".\r\n   Note that ""Latest"" means that the produced ONNX model meets\r\n   the latest ONNX release while ""Experimental"" may produce\r\n   things not officially supported in ONNX.\r\n2. For (1), the interface of saving ONNX is slightly changed. Now,\r\n   CanSaveOnnx requires an OnnxContext as its input argument,\r\n   because if a model can be saved to ONNX depends on the targeted\r\n   ONNX version now.\r\n3. Add exporter for ConvertTransform. It doesn\'t use standard\r\n   ONNX operator.\r\n\r\nRelated issue: #945 '"
361842957,944,b'Hash estimator',b'@Zruty0  you can pick up this one'
361541130,943,b'Update private and constant variable names',"b""Fix for issue #829 \r\n\r\n@briancylui @safern These are the changes I've found so far. Marked as WIP since I'd like to go through once more to make sure I didn't miss anything."""
361527281,942,b'Add OnnxTransform for scoring Onnx 1.2 models - integrates Microsoft.ML.Scoring/Sonoma Library',"b'Fixes issue #695 \r\nFixes issue #892\r\n\r\nThis adds a new transform  for scoring Onnx v1.2 models, leveraging an updated version of the scoring library at the link below.\r\n\r\nhttps://www.nuget.org/packages/Microsoft.ML.Scoring/\r\n\r\n\r\n\r\n'"
361525181,941,b'[WIP] Added Onnx Transform',b'WIP PR for implementing issue #695.'
361517769,940,b'Added the GetColumn functionality to dynamic API',"b'Improves #985 .\r\nAdds a `GetColumn<T>`(""columnName"")` functionality to eagerly extract a column from a data view'"
361516003,939,b'Enabled Multiclass Logistic Regression Tests',b'Related to  https://github.com/dotnet/machinelearning/issues/984'
361505359,937,b'Substituted Wine Quality dataset with machine generated dataset',"b'Fixes #936.\r\nFixes #889.\r\n\r\nI substituted the UCI Wine Quality dataset with a machine generated regression dataset (linear function of a vector input with added Gaussian noise). I had to update the test outputs for all affected tests.\r\n\r\nNote that this is a temporary change, and that we are looking into finding a real dataset to substitute this machine generated one.\r\n'"
361022603,931,b'Transform wrappers and a reference implementation for tokenizers',b''
360679901,928,b'Converted WordEmbeddingsTransform into Estimator.',b'This PR fixes #927 '
360579353,926,b'Fix duplicate transform friendly name',"b""Fix for issue #214 \r\n\r\n@TomFinley I'm not sure if this is the right way to go about it, but I took a shot at it. \xf0\x9f\x98\x84 \r\n"""
360480977,923,b'Renamed TlcEnvironment to Console. Also introduced LocalEnvironment',b''
360477570,922,b'Make Create constructors private and handle that in ComponentCatalog.',b'Fixes #921'
360466607,920,b'Rename Microsoft.ML to Microsoft.ML.Legacy',b'This is a purely mechanical rename.\r\n- `Microsoft.ML` -> `Microsoft.ML.Legacy`\r\n- Moved to `src/Microsoft.ML.Legacy`\r\n- Updated project references and solution'
360411152,917,b'NAReplace estimator',b'Converts NAReplace to estimator\r\n\r\n'
360232597,914,b'TLS Links for Improved Security',b'Changes various HTTP links to HTTPS. Links are checked to ensure the HTTPS serves the same content. Not all HTTP links could be converted.\r\n\r\nCloses #911 \r\n\r\n\r\n\r\n'
360175318,912,b' Field-aware factorization machine to estimator',b'FAFM now extends TrainerEstimatorBase\r\n\r\n\r\n'
360109902,909,b'Fix for trainer estimator metadata propagation',"b'Added tests for metadata propagation on existing trainers, also fixed SDCA to pass metadata correctly.\r\n'"
359693812,901,b'Legacy API namespace rename',b'Fixes #756 .'
359679972,900,"b'Fix bug in pixel extractor transform, and add more unit tests.'","b'Fixes #897 .\r\nThe pixel extractor mixes up the green and blue values in one place, and does the wrong thing with the alpha value in another place.\r\n\r\n'"
359668990,899,b'Categorical estimator',b'Converts Categorical transform to Estimator chain'
359619332,896,b'Transformer for Concat',b'Proper conversion of ConcatTransform'
359261749,890,b'[WIP] Add GPU package of tensorflow',"b""Issue #871\r\n\r\nBest reviewed commit-by-commit.\r\n\r\nThis adds a GPU build package for tensorflow and attempts to use it for tests.\r\n\r\nI'm not certain yet about the mechanism for opting into the GPU build, this was really just a sample to see what we could do."""
359228389,888,b'Added numeric ranking Performance Tests',b'Added benchmarking performance tests for Numeric ranking.\r\n\r\ncc @justinormont @sfilipi @danmosemsft @eerhardt @shauheen \r\n\r\n'
359189638,887,b'Move IComponentFactory from EntryPoints namespace',"b'I chose the same namespace as `ComponentCatalog` is in, which is the root `Microsoft.ML.Runtime` namespace. If we ever move `ComponentCatalog` to a different namespace, we could move this as well.\r\n\r\nI spot checked as many places as I could to remove unnecessary `using Microsoft.ML.Runtime.EntryPoints` statements.\r\n\r\nFix #861 '"
359176721,886,b'Cleanup ComponentCatalog code',b'Format document in VS.\r\nRemove unused method.\r\nUse readonly property declarations.\r\nDrop unnecessary partial keyword.\r\nRemove unnecessary define.\r\n'
358883471,883,"b'Static SDCA Multiclass, and Multiclass Evaluator'",b'Related to #632.'
358877756,882,"b'TensorFlow static extensions, SDCA multiclass static extensions'",b'Code changes to enable end-to-end static pipe training for TF and multiclass'
358857468,881,"b'Concat estimator with pigsty extensions for ConcatWith, AsVector'",b'This is a version of the ConcatEstimator. It is functional but will require future work in future especially w.r.t. its transformer. Related to #632.'
358834243,880,b'WordEmbedding Tests added plus added dimension check for the first row',b'Fixes https://github.com/dotnet/machinelearning/issues/873\r\nRelated PR https://github.com/dotnet/machinelearning/pull/820\r\n\r\nplease review it after 55fb378\r\n\r\ncc @danmosemsft @sfilipi @eerhardt @Ivanidzo4ka @justinormont '
358831841,879,b'Remove CmdParser.GetConsoleWindowWidth.',"b""This method is available on the Console class, thus we don't need to have our own API for it.\r\n\r\nFix #878"""
358829651,877,b'Static extension for one-to-one TensorFlow mapping',b'Added a static extension for a simple TF use case when both single input and single output are vectors of floats of known size.'
358815427,876,b'Conversion of prior and random trainers to estimators',b'Fixes #875.\r\n\r\nConverted prior and random trainers to estimators. \r\nAllowed feature column to be null for both prior and random estimator.\r\n\r\n'
358811865,874,b'Fix typo in nuget Microsoft.ML.TensorFlow.TestModels',b'Fixes #804 \r\n\r\n1. Fix typo in name of nuget package\r\n2. Update version\r\n'
358406510,870,b'Term estimators in static pipeline',"b""Potentially controversial moves:\r\n\r\n* Naming the extension method for `TermEstimator` as `ToKey`, pursuant to #214 discussion. Please consider discussing that there.\r\n* `.tt` file to generate the extension methods. We've previously never used T4, but in this case I felt it was warranted.\r\n\r\nAt the moment, #863 is not yet in, so the `onFit` delegate returns an object with nothing in it. If that goes in prior to when we must finish this work I'll update it, otherwise we'll do it later."""
358332963,869,"b'Static pipeline column indexers, binary/regression evaluators'",b'* Infrastructure for column indexers\r\n* Binary classification and regression evaluators\r\n\r\nFixes #868.'
358306412,867,"b'Add TensorFlow documentation to the main class, and include examples on it. '","b""Fixes #866 \r\nAdds the documentation to the class, and not just the Create method, and changes the visibility of some of the properties that don't need to be user-facing. \r\n\r\nIncludes the examples in the doc.  \r\n\r\n\r\n\r\n"""
358241981,865,b'Ova and Pkpd as estimators',"b'Converting OVA and PKPD to derive from TrainerEstimatorBase. \r\nUpdating the arguments of those Metalinear learners to have the standard Feature, Label, Weights columns. \r\n'"
358237995,864,b'Ported some of the tests from TestCommandMore',b'Related to https://github.com/dotnet/machinelearning/issues/984\r\n- Ported some of the tests from TestCommandMore. Remaining tests contain modules or datasets that are not yet available\r\n\r\ncc @danmosemsft @eerhardt '
358237494,863,b'Replace DV data type system with .NET standard type system.',b'This change replaces DvType system with .NET standard data type system and fixes #673 \r\n\r\n| Old Type | New Type  \r\n|:-:|:-:\r\n| DvInt1 | `sbyte`  \r\n| DvInt2 | `short`  \r\n| DvInt4 | `int`\r\n| DvInt8 | `long`  \r\n| DvBool | `bool`  \r\n| DvDateTime | `DateTime`\r\n| DvDateTimeZone | `DateTimeOffset`  \r\n| DvTimeSpan | `TimeSpan`  \r\n| DvText | `ReadOnlyMemory<char>`  '
358234554,862,b'Create API for extracting information about the nodes in a TensorFlow model',b'This PR addresses issue #791 .\r\nPlease feel free to add feedback or suggestions.'
358229625,860,b'Updated version number of MlNetMklDeps package to 0.0.0.6',"b'Fixes #859.\r\n\r\nI updated the version number of the package MlNetMklDeps in build/Dependencies.props. \r\n\r\nAlthough ML.NET does not officially support x86 at this moment, the new MlNetMklDeps nuget package contains the x86 binaries.\r\n'"
358227691,858,b'KeyToVector estimators',b'Move KeyToVector to estimators land'
358223357,857,b'Handle inputs with unknown shapes in TensorFlow',b'This PR adds support for unknown shapes in the inputs and in the outputs of TensorFlow transform.\r\nCloses #848 .\r\n\r\n'
358222236,856,b'Converted KeyToValue to estimator',"b'Converted KeyToValue to estimator, added Pigsty extensions.'"
358216272,855,b'Tree estimators',b'Ongoing work on converting the trainers to estimators. This PR converts the Tree -type Predictors.  \r\n'
357875036,853,b'Enable TensorFlowTransform to work with pre-trained models that are not frozen',"b""Fixes #784 \r\n\r\n1. Added ability in the TensorFlowTransform to to handle TensorFlow's SavedModel format\r\n2. For doing this, we use a temporary directory for TF SavedModel files. It looks like this is a [ TensorFlow requirement](https://github.com/tensorflow/tensorflow/blob/3be04971716fcaf0c11ad9262e60efa428553e14/tensorflow/c/c_api.h#L1367).  TensorFlow requires the model to be in a directory and doesn't provide a mechanism for loading from some sort of stream/memory representation. \r\n3. The temp directory is created with appropriate ACL's for high-priviledge processes. We take care of deleting the temporary directory \r\n4. Added unit tests."""
357868979,852,b'Remove SubComponent',"b'This change completely removes SubComponent from ML.NET product, and moves it to the test code (since it is so heavily used there).\r\n\r\nThis PR builds on top of #817, so the first commit can be reviewed on that PR.'"
357843267,851,"b""For the GitHub issues classification aspirational example, the 'Area' is not needed as input to Predict(), since it is the label.""","b'Creating a IssueInput class for the github classification pigsty aspirational example, and removing the Area - since it is the label, ad the ID - since it is not used, from the example. Fixes #841'"
357778618,849,"b'Ap, LinearSVM, OGD as estimators'","b'Converting AveragePerceptron, LinearSVM and ODG trainers to estimators. \r\n'"
357672807,846,b'Using sonoma nuget',b''
357647891,845,b'SchemaShape.Column metadata is now SchemaShape not string array',b'Fixes #755 . Existing estimators and static pipeline logic updated to take advantage of the new architecture.'
357550702,843,b'Statically Typed Normalizer Estimators',"b'Related to #632, with normalizers being put into the PiGSTy. This is relatively straightforward.\r\n\r\nOn thing which may not be obvious is the grouping of the mean-var/CDF/log-mean-var/log-CDF normalization functions.\r\n\r\n* In the ""dynamic"" land, mean-var/CDF are grouped, and log-mean-var/log-CDF are grouped.\r\n* In the ""static"" land, mean-var/log-mean-var, and CDF/log-CDF are grouped.\r\n\r\nThe former grouping appeared to have been motivated by the fact that the training procedures resembled each other. However in static typed land, what matters more is what the *result* of that training will be, and in mean-var it is always an affine normalizer, and in CDF (whether log-CDF or not) it is a CDF normalizer. For `onFit` to have a sensible signature I must therefore split it up according to that criteria.\r\n\r\nAlso even though it is not quite efficient now, I feel like exposing the ""guts"" of things might be aided longterm by shifting what we can to use `ImmutableArray<>`. Not sure though.'"
357470082,842,"b""Modified official build yaml file to also push to VSTS's artifacts tab""","b""Fixes #483.\r\n\r\nI based my change on [the old version](https://github.com/dotnet/machinelearning/commit/436700aadf615e7f05a22925476cc441c63a919d#diff-fd7f6e99583f511aa0a2af1c74d32620L148) of the file which pushed to the VSTS feed only. In order to keep pushing to MyGet and also push to VSTS I added a new task to the yaml file. The task is identical to what was found in the old version of the file. \r\n\r\nHowever, I don't know how to test this code and make sure that it works. \r\n\r\n"""
357408774,840,b'TensorFlow estimator',b'Converts TensorFlow transform to estimator/transformer + tests for them'
357081321,837,b'SDCA Regression and BinaryClassification Pigsty extensions',"b'Related to the closed #632 and the API overall. In here I introduce extensions for SDCA regression and binary classification. (No multiclass until I also write extensions for term.)\r\n\r\nThis also includes a sort of general purpose utilities for writing reconcilers for trainers, though, again, only regression, binary classification, and binary classification without probabilities so far.\r\n\r\nAlso a minor change to the linear classification trainer, as it was not identifying that it was producing probabilities sometimes.'"
357028945,825,b'Cherrypick to update release for 0.5',b'Cherrypick into release for 0.5'
357024980,822,b'Fix bounding checking error of SSE SumU intrinsic',"b'Added an ""="" sign to a bound check inside the SSE SumU intrinsic to fix a previous typo and make it consistent with all other intrinsics\' implementations - look forward to green light!\r\n\r\ncc: @eerhardt @tannergooding @safern '"
357024331,821,b'Change bound checking in SSE/AVX intrinsics to avoid pointer overflow',"b'Aims to solve #980\r\n---\r\nSuggested by @ahsonkhan to avoid integer overflow in bound checking inside SSE/AVX intrinsics implementation, i.e. change all `while (pCurrent + 8 OR 4 <= pEnd)` into `while (pEnd - pCurrent >= 8 OR 4)`.\r\n\r\nPerf tests results before and after the change are shown below:\r\n## Before the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |    StdDev |\r\n|----------------------- |------- |---------:|---------:|----------:|\r\n|    AvxPerformanceTests |   SumU | 159.4 us | 1.104 us | 0.9784 us |\r\n| NativePerformanceTests |   SumU | 283.5 us | 5.492 us | 4.8687 us |\r\n|    SsePerformanceTests |   SumU | 281.2 us | 1.472 us | 1.3045 us |\r\n|    AvxPerformanceTests |   AddU | 276.1 us | 3.018 us | 2.520 us |\r\n| NativePerformanceTests |   AddU | 330.1 us | 3.585 us | 3.178 us |\r\n|    SsePerformanceTests |   AddU | 325.6 us | 6.883 us | 7.926 us |\r\n\r\n## After the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |   StdDev |\r\n|----------------------- |------- |---------:|---------:|---------:|\r\n|    AvxPerformanceTests |   SumU | 183.5 us | 3.621 us | 3.023 us |\r\n| NativePerformanceTests |   SumU | 281.6 us | 5.261 us | 4.921 us |\r\n|    SsePerformanceTests |   SumU | 294.1 us | 2.080 us | 1.946 us |\r\n|    AvxPerformanceTests |   AddU | 296.3 us | 5.185 us | 4.850 us |\r\n| NativePerformanceTests |   AddU | 335.1 us | 3.053 us | 2.707 us |\r\n|    SsePerformanceTests |   AddU | 345.0 us | 2.155 us | 1.800 us |\r\n\r\nBoth SSE and AVX implementations are slower by 10-20% after this change.\r\n\r\nIn my opinion, after seeing the perf results, I may not recommend merging this PR.  I may wait until the alternative suggested by @tannergooding in an earlier PR review has been implemented (2nd item under ""Functionality"" in https://github.com/briancylui/machinelearning/issues/2):\r\n``` log\r\nvar remainder = count % elementsPerIteration;\r\nfloat* pEnd = pdst + (count - remainder);\r\nwhile (pDstCurrent < pEnd)\r\n{ \xe2\x80\xa6 }\r\n```\r\n\r\nAnother question I have is: would `pDstCurrent + 8 OR 4` ever have the possibility to result in integer overflow?  According to my knowledge, `pEnd` is initialized as `pDstCurrent + count`, and there are `Contract.Asserts` in the wrapper class to check that `count` does not exceed the original array length.  I\'m not sure, and am open to any PR comments and advice.\r\n\r\ncc: @danmosemsft @eerhardt @tannergooding @ahsonkhan \r\n'"
357023041,820,b'Added Benchmark performance tests for wikidetoxData',b'This PR adds BenchMark tests for AveragePreceptron and LightGBM classifier on wikiDetox Dataset.\r\n\r\n\r\ncc @eerhardt @danmosemsft @sfilipi '
357016535,818,b'remove dot from the file name.',b'fixes #826 '
357014087,817,b'Remove SubComponent usage from ML.PipelineInference.',b'Working towards #585\r\n'
357009721,816,b'Cherrypick to update release for 0.5 - NO MERGE',b'Cherrypick into release for 0.5'
357004212,815,b'Cherrypick to update release for 0.5 - NO MERGE',b'Cherrypick into release for 0.5'
357002744,814,b' Enabled option to get multiple outputs from TF graphs',b'This PR fixes #712.\r\n'
356965893,813,b'Update badges to new definition name',"b'Renamed the build def right after my PR got merged. \r\n\r\n@eerhardt and I chatted offline that the CI name should be something more descriptive, rather than ""public-CI"". So renamed it to MachineLearning-CI.'"
356950539,812,b'Pigsty examples',"b'I will not merge this branch as is, because  its history is polluted from the merge/updates to master. \r\nSending out a PR to get some feedback, while i resolve the history problem. \r\n\r\n\r\n'"
356936320,811,b'Update README badges to point to dnceng',b'cc: @eerhardt @shauheen '
356911003,809,b'Some pigsty examples',b''
356907205,808,b'Add release notes for ML.NET 0.5',b'This adds release notes for ML.NET 0.5.'
356162796,801,b'Text estimator',b'Converting text transform to be an estimator.\r\nDoes not convert individual transformers yet.'
356152804,800,b'Clarified roadmap to mention existence of current text/NLP features',b'Fixes #382 \r\n\r\n- I added a sentence mentioning that text/NLP features already exist and that they will be expanded\r\n- I rephrased the two improvements so that it comes across as an enhancement of current functionalities and not as an addition of completely new features. \r\n\r\n'
356149656,799,b'Renamed variables with more ML.NET specific terminology',b'Fixes #546\r\n\r\n- I renamed variables which included TLC in their name with variables names more ML.NET specific\r\n- I changed the url in code and on aka.ms to redirect to https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet\r\n'
356148910,798,b'Helper methods to save data as text and binary',b''
356138275,797,b'Converted normalizers to be estimators',b'Normalizers (except SupervisedBinning) become estimators.'
356137445,796,b'Normalizers become estimators',b'Changed normalizers to be estimators.'
356128422,795,b'Add Initialize() method to TensorFlow and ImageAnalytics',"b'Fixes #794 .\r\nIn order to use the pipeline API, users will be required to call the Initialize() method in order to load the assemblies that contain the relevant entry points.'"
356105089,793,b'Update buildtools version in preview',b'For dotnet/buildtools#2144 - takes the buildtools change to fix the copyright string.\r\n\r\nCC @weshaggard @eerhardt'
356057190,790,b'Updates to Unit Test cases for the TensorFlowTransform',b'Fixes #779\r\n\r\n(1) address the additional comments on the original TensorFlowTransform PR\r\n\r\n(2) added an additional unit test to verify invalid shapes are being handled correctly\r\n\r\n'
355800763,788,b'Make perf results table of CpuMath hardware intrinsics more informative',b'All style changes aimed at making the perf results table look nicer - no functionality changes.  Look forward to green light!\r\n\r\n\r\ncc: @eerhardt @safern @tannergooding @danmosemsft \r\n'
355693710,783,b'Updates to Unit Test cases for the TensorFlowTransform',b'Fixes #779 \r\n\r\n(1) address the additional comments on the original TensorFlowTransform [PR](https://github.com/dotnet/machinelearning/pull/704)\r\n\r\n(2) added an additional unit test to verify invalid shapes are being handled correctly \r\n\r\n\r\n'
355689598,782,b'Bump the master branch to 0.6',b'Setting the master to 0.6'
355629352,778,b'Static typed Estimator/Transformer/Data',"b""Fixes #632. The first version of the statically typed parallels to `IEstimator`, `ITransformer`, `IDataView`. Stub for the library's analyzer."""
355588928,777,b'Including Wikipedia citations',b'Including the missing citations and organizing previous citation so we are more consistent inside the Readme.\r\n\r\n\r\nSolving the issue #697 '
355423058,775,b'Merge master into release/preview for 0.5',b'This PR merges master into release branch for 0.5'
355404178,774,b'Fix netcoreapp3.0 errors in AVX intrinsics',b'This is a small PR that fixes an error made while making changes in a previous PR - nothing fancy!  Look forward to green light.\r\n\r\ncc: @safern @eerhardt @tannergooding'
355399692,773,b'Misc SubComponent removals',"b'Removing SubComponent usages in:\r\n\r\n* ML.Maml\r\n* ComponentCreation extension methods\r\n\r\nAfter this change the only places that use SubComponents are:\r\n\r\n1. CmdParser.cs, SubComponent.cs, and ComponentCatalog.cs (which will be the last things to be removed).\r\n2. PipelineInference (which the whole project will be removed from this repo with #689)\r\n3. EntryPoint code gen (which should no longer apply since there are no more usages of SubComponents in the API)\r\n4. Tests\r\n\r\nWorking towards #585'"
355385749,771,b'Attribution of images in test/data/images',"b' Fixes #697\r\n\r\n- I added the attribution for the images located in the test/data/images folder. \r\n- I used the citation format indicated in wikipedia\'s ""[best practices for attributions](https://wiki.creativecommons.org/wiki/Best_practices_for_attribution#This_is_an_ideal_attribution)"" \r\n\r\nNote: I used the same readme that provides citations for the datasets located in test/data and separated it in two parts. I think it makes more sense to keep the citations for the data and images in the folder in a single file.\r\n'"
355335284,768,b'Ported some Sweeper tests',b'Fixes https://github.com/dotnet/machinelearning/issues/786\r\n\r\n- I have ported some sweeper tests\r\n- Changed the tests from mstest into Xunit\r\n- Disable LowDiscrepancyRandomSweeper tests as the class is not yet ported\r\n- skipped NelderMeadSweeper tests as not able to load this ldrandpl class\r\n- reformatted some tests to use theory\r\n\r\ncc @eerhardt @Ivanidzo4ka @danmosemsft '
355285073,767,b'Update buildtools to 3.0.0-preview1-03129-01',b'This new version has a fix for the Copyright header.\r\n\r\nFix #766\r\n\r\nNOTE: The `init-tools` changes are direct copies from `dotnet/corefx/master`.\r\n\r\nFYI - @shauheen '
354885162,759,b'Term transformer implementation',b'implementation for #754 '
354811158,757,b'Add test for parquet loader.',b'fixes #760 '
354504731,753,b'Image transforms become Estimators',b'Converted the following transforms to Estimators:\r\n- ImageLoader\r\n- ImageResizer\r\n- ImagePixelExtractor\r\n- ImageGrayscale\r\n\r\nFixes #707 '
354454183,750,b'IDV test for DvTypes',b'This test ensures IDV file generated using DvTypes is parsed by the new type system that does not contain DvTypes.'
354267611,743,b'Fixes for General Additive Models',"b'This PR addresses a number of issues with the `General Additive Model` (`GAM`) trainer. In particular, it addresses the issues with the `GAM Classifier` not fitting nor producing a probability, and adds support for validation pruning, summary text, and centering of the feature effects around a mean response (e.g. intercept).\r\n\r\nAdditionally, the PR addresses some minor issues in the codebase, like `GAMs` using copy-and-paste versions of `FastTree` code, unnecessarily `public` attributes, unused arguments, and splits the `BinaryClassifier` and `Regressor` into separate files.\r\n\r\nThe changes are as follows:\r\n1. Centered the response and added an intercept term; fixed corresponding issues with table lookups, sparse calculations, and exports. (#739)\r\n2. Added in a validation set and pruning based on the validation set, producing a final pruned graph at the end. (#740)\r\n  a. Switched to using `ScoreTrackers` to keep track of scores during boosted\r\n  b. Save boost iterations as individual graphs (n_features x n_iterations x n_boosts) for pruning.\r\n3. Fixed `GAM Classifier` to use a small learning rate (#741)\r\n  Updated the `FastTreeBinaryClassification` logistic loss gradient to take the `sigmoid` parameter as input: `GAM Binary Classifier` now uses unity; `FastTree Binary Classifier` uses the same default of `2*learning rate` (no change). Optionally, we can plumb this to the FastTree arguments if we show an experimental gain; We can also experiment to see if the `sigmoid` parameter gives gains for GAMs (i.e. by slowing learning even more).\r\n7. Added calibration to the `GamClassifier` to produce probabilities (#738).\r\n  This meant changing the various interfaces.\r\n8. Refactored `GAMRegressor` and `GAMClassifier` into their own files.\r\n  The one file for all GAM trainers had gotten a bit long, and this change is consistent with ML.NET tradition.\r\n9. Added tests to verify train loss and validation metrics (e.g. same value is produced by boosting and the lookup table).\r\n10. Added a Summary to the `GAMPredictor` to produce training statistics and the feature table (#742).\r\n11. Rewrote the core split finding routine to use the same code as FastTree to rely on FastTree unit tests\r\n  The `GAM` routines used a copy-and-paste of internal `FastTree` components. To fight entropy, these were refactored to use the same central calculation, such that it is verified and validated by the `FastTree` unit and end-to-end tests.\r\n12. Removed unused arguments.\r\n13. Allowed for weighted samples.\r\n\r\nFixes #738 \r\nFixes #739 \r\nFixes #740 \r\nFixes #741 \r\nFixes #742 \r\n'"
354177683,735,b'Support for custom metrics reported in the Benchmarks',"b'This PR enables two things: \r\n\r\n1. executing every benchmark in an isolated process\r\n2. reporting custom metrics per benchmark\r\n\r\nWhy should we run every benchmark in a separate process?\r\n\r\n1. Because most of ML.NET benchmarks allocate a lot of memory which affect GC Generation sizes and affects final results (GC is self-tuning if we run all the benchmarks in the same process GC won\'t be able to find a solution that is great for all of the benchmarks)\r\n2. Most of the ML.NET can have potential side effects. Example: running train benchmark after running predict benchmark in the same process can possibly affect the results. With new process per benchmark, we always start at the same place and have repeatable results.\r\n\r\nResults when running all the benchmarks in the same process:\r\n\r\n|                                          Type |              Method |         Mean |       Error |      StdDev |       Gen 0 |      Gen 1 |     Gen 2 |   Allocated |\r\n|---------------------------------------------- |-------------------- |-------------:|------------:|------------:|------------:|-----------:|----------:|------------:|\r\n|              KMeansAndLogisticRegressionBench |    TrainKMeansAndLR | 2,134.265 ms | 164.3370 ms | 189.2507 ms |  16000.0000 |  9000.0000 | 3000.0000 | 49949.23 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |      TrainSentiment | 2,130.503 ms |  24.8173 ms |  23.2141 ms | 122000.0000 | 35000.0000 | 5000.0000 | 759772.8 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |           TrainIris |   834.229 ms | 254.5284 ms | 293.1152 ms |   6000.0000 |  1000.0000 |         - | 12173.28 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |         PredictIris |     2.472 ms |   0.1202 ms |   0.1384 ms |     35.1563 |    15.6250 |    3.9063 |   123.24 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf1 |     2.712 ms |   0.3276 ms |   0.3773 ms |     35.1563 |    15.6250 |    3.9063 |    123.2 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf2 |     2.370 ms |   0.1334 ms |   0.1482 ms |     35.1563 |    15.6250 |    3.9063 |   123.31 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf5 |     2.492 ms |   0.1678 ms |   0.1865 ms |     35.1563 |    15.6250 |    3.9063 |   123.61 KB |\r\n\r\nWhen running every benchmark in a dedicated process:\r\n\r\n|                                          Type |              Method |         Mean |       Error |      StdDev |       Gen 0 |      Gen 1 |     Gen 2 |    Allocated |\r\n|---------------------------------------------- |-------------------- |-------------:|------------:|------------:|------------:|-----------:|----------:|-------------:|\r\n|              KMeansAndLogisticRegressionBench |    TrainKMeansAndLR | 1,968.326 ms |  84.3827 ms |  97.1753 ms |  16000.0000 |  9000.0000 | 3000.0000 |  50027.36 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |           TrainIris |   604.496 ms | 238.4849 ms | 274.6396 ms |  59000.0000 |  1000.0000 |         - |   76697.5 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |      TrainSentiment | 1,829.670 ms |  10.9792 ms |  10.2699 ms | 123000.0000 | 35000.0000 | 6000.0000 | 759758.03 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |         PredictIris |     1.895 ms |   0.0132 ms |   0.0111 ms |     35.1563 |    15.6250 |    3.9063 |    121.87 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf1 |     1.941 ms |   0.0145 ms |   0.0121 ms |     35.1563 |    15.6250 |    3.9063 |    119.94 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf2 |     1.960 ms |   0.0676 ms |   0.0751 ms |     35.1563 |    15.6250 |    3.9063 |    121.94 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf5 |     1.870 ms |   0.0043 ms |   0.0036 ms |     37.1094 |    17.5781 |    3.9063 |    120.35 KB |\r\n\r\nTo run every benchmark in a standalone, dedicated process BenchmarkDotNet needs to be able to create, build and run new executable.\r\n\r\nSo far it was not possible out of the box due to MSBuild limitation. When `Microsoft.ML.Benchmarks` references native assembly and the auto-generated BenchmarkDotNet project references `Microsoft.ML.Benchmarks` the native dependencies are not copied to the output folder of the auto-generated project with benchmarks. This is why I had to implement `ProjectGenerator` which does that for us.\r\n\r\n@eerhardt we had a conversation about making it possible for BenchmarkDotNet to compile ML.NET stuff a long time ago and the blocker was the native dependency.\r\n\r\nThe other thing are custom metrics. BenchmarkDotNet does not support it out of the box, I had to implement it. How it works:\r\n\r\n1.  If given type wants to report custom metrics it has to derive from `WithExtraMetrics` and implement `IEnumerable<Metric> GetMetrics()` method\r\n2. `WithExtraMetrics` after running the benchmarks prints the custom metrics to console in child process\r\n3. `ExtraMetricColumn` parses the output in parent process.\r\n\r\nSample results:\r\n\r\n|                                          Type |              Method |        Extra Metric |\r\n|---------------------------------------------- |-------------------- |--------------------:|\r\n|              KMeansAndLogisticRegressionBench |    TrainKMeansAndLR |                   - |\r\n| StochasticDualCoordinateAscentClassifierBench |           TrainIris |                   - |\r\n| StochasticDualCoordinateAscentClassifierBench |      TrainSentiment |                   - |\r\n| StochasticDualCoordinateAscentClassifierBench |         PredictIris | AccuracyMacro: 0.98 |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf1 | AccuracyMacro: 0.98 |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf2 | AccuracyMacro: 0.98 |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf5 | AccuracyMacro: 0.98 |\r\n\r\nOther changes: so far the benchmarks were using `currentAssemblyLocation.Directory.Parent.Parent.Parent.Parent.FullName` to get the path to folder with input files. I believe it\'s better to reference them as links in `csproj` and ""copy to output directory if newer"". This solution is cleaner and more futureproof.\r\n\r\n/cc @eerhardt @danmosemsft @briancylui @KrzysztofCwalina  '"
354132651,734,b'Convert ML.Sweeper usages of SubComponent to IComponentFactory.',"b""Moving all the SubComponent usages in the ML.Sweeper assembly to use IComponentFactory.\r\n\r\nNote: I logged https://github.com/dotnet/machinelearning/issues/733 for the NelderMeadSweeper, which was using another component that doesn't appear to be in the `dotnet/machinelearning` repo.\r\n\r\nWorking towards #585"""
354061823,731,b'Update LightGBM nuget version to support .NET framework and add start_iteration parameter to BoosterSaveModelToString()',b'fixes #494 \r\n\r\n'
354041535,730,b'update wikipedia detox line 83 - Add missing quote',b'Fixes a missing quote.\r\nIt solves this warning \r\n![image](https://user-images.githubusercontent.com/6944598/44622308-6947c880-a88c-11e8-9083-8a39c44d69f9.png)\r\n\r\nwhen you train your model from [sentiment-analysis example](https://docs.microsoft.com/es-es/dotnet/machine-learning/tutorials/sentiment-analysis)\r\n'
353908324,729,b'Convert ML.Data usages of SubComponent to IComponentFactory.',"b'With this change, all the usages of SubComponent from our main API assemblies are now removed.\r\n\r\nThe usages that are left are all under:\r\n\r\n1. ComponentCatalog/CmdParser/SubComponent.cs and one line in ComponentCreation.cs\r\n2. ML.PipelineInference\r\n3. ML.ResultProcessor\r\n4. ML.Sweeper\r\n5. ML.Maml\r\n6. EntryPoints CodeGen\r\n7. Tests\r\n\r\nWorking towards #585 \r\n\r\n\r\n'"
353865712,728,b'Made IRowMapper take IRow for metadata',b'Fixes #719 '
353854481,727,b'Move macOS CI legs to VSTS',b'cc: @eerhardt @danmosemsft '
353587247,724,b'Benchmarks created by @yaeldekel',"b'I took the benchmarks created by @yaeldekel, solved merge conflict run them and changed the config a little bit to run just one warmup iteration. \r\n\r\n\r\n@davidwrighton to run all the benchmarks you need to pass `*` as the filer:\r\n\r\n        dotnet run -c Release -- -f * --join\r\n\r\nSample results:\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.11.0, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Xeon CPU E5-1650 v4 3.60GHz (Max: 2.90GHz), 1 CPU, 12 logical and 6 physical cores\r\n.NET Core SDK=2.1.301\r\n  [Host] : .NET Core 2.1.1 (CoreCLR 4.6.26606.02, CoreFX 4.6.26606.05), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain  MaxIterationCount=20  WarmupCount=1  \r\n\r\n```\r\n|                                          Type |              Method |         Mean |       Error |      StdDev | AccuracyMacro |       Gen 0 |      Gen 1 |     Gen 2 |   Allocated |\r\n|---------------------------------------------- |-------------------- |-------------:|------------:|------------:|--------------:|------------:|-----------:|----------:|------------:|\r\n|              KMeansAndLogisticRegressionBench |    TrainKMeansAndLR | 2,134.265 ms | 164.3370 ms | 189.2507 ms |          0,98 |  16000.0000 |  9000.0000 | 3000.0000 | 49949.23 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |      TrainSentiment | 2,130.503 ms |  24.8173 ms |  23.2141 ms |          0,98 | 122000.0000 | 35000.0000 | 5000.0000 | 759772.8 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |           TrainIris |   834.229 ms | 254.5284 ms | 293.1152 ms |          0,98 |   6000.0000 |  1000.0000 |         - | 12173.28 KB |\r\n| StochasticDualCoordinateAscentClassifierBench |         PredictIris |     2.472 ms |   0.1202 ms |   0.1384 ms |          0,98 |     35.1563 |    15.6250 |    3.9063 |   123.24 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf1 |     2.712 ms |   0.3276 ms |   0.3773 ms |          0,98 |     35.1563 |    15.6250 |    3.9063 |    123.2 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf2 |     2.370 ms |   0.1334 ms |   0.1482 ms |          0,98 |     35.1563 |    15.6250 |    3.9063 |   123.31 KB |\r\n| StochasticDualCoordinateAscentClassifierBench | PredictIrisBatchOf5 |     2.492 ms |   0.1678 ms |   0.1865 ms |          0,98 |     35.1563 |    15.6250 |    3.9063 |   123.61 KB |\r\n\r\n'"
353535995,723,b'Turn TextLoader into a data reader',b'Fixes #718 '
353510298,722,b'Add new benchmarks to test\\Microsoft.ML.Benchmarks',"b""Submitting @yaeldekel's new benchmarks via this PR.\r\n\r\n- Added a new benchmark for KMeans and Logistic Regression (LR) under `test\\Microsoft.ML.Benchmarks`\r\n- Added a new sentiment test inside the existing SDCA benchmark\r\n\r\ncc: @yaeldekel @eerhardt """
353492937,720,b'Create a redist package for tensorflowCreate a nuget package that red\xe2\x80\xa6',b'Fixes https://github.com/dotnet/machinelearning/issues/713\r\n\r\nCreate a nuget package that redistributes the TensorFlow C-API.\r\n\r\nThis is a straight up repack of the bits published on tensorflow.org.  I made sure to apply the TensorFlow license to this package and not sign it with our authenticate certificates.\r\n\r\nThis is part 1 of the TF packaging.  Once @abgoswam merges #704 I plan to refactor that into its own package and depend on this (as well as update the tests to use the binaries from this redist project).  I can either do that as a separate PR or as part of this.'
353133987,716,b'SDCA trainers become Estimators',b'Converted the SDCA family to Estimators'
352745900,706,b'Implementing copy column estimator',b'+ @Zruty0 '
352741604,705,b'Replace DvText with .NET Standard type.',b'fixes #673 '
352713186,704,b'TensorFlowMapper transform for scoring Tensorflow models in ML.NET',"b""Fixes #696, #748 #714 \r\n\r\nThis PR creates a new transform 'TensorFlowMapper' for scoring Tensorflow models in ML.NET.\r\n\r\n\r\n\r\n"""
352602524,703,b'Few benchmark fixes',b'1. I added README.md so everyone can find out how to run the benchmarks\r\n2. I fixed a bug in the benchmarks where it was returning a lazy-executed `IEnumerable<T>` without the actual execution. So instead of 16 nanoseconds we now have 2.3 milisecond ;)\r\n3. I updated BenchmarkDotNet to latest version to get advantage of performance improvements and new features.\r\n4. I have changed the configuration to run not 3 (`Job.Short`) but up to 20 iterations (BenchmarkDotNet implements a heuristic based on standard error and runs the benchmarks until they are not stable). 3 iterations is simply not enough to get trustworthy results.\r\n\r\n/cc @danmosemsft @KrzysztofCwalina '
352327477,701,b'Add package tags',"b'Fix https://github.com/dotnet/machinelearning/issues/484\r\n\r\nAdd some tags to the nuget package to help us appear more prominently when searching for ""ML.NET""\r\n\r\nWe can also add a custom title (see first commit) which apparently helps, but it is probably not a good idea, since as @eerhardt pointed out, one might expect to be able to add `<PackageReference Include=""ML.NET"" />` if the title is `ML.NET`, but not the package ID.\r\n'"
352317120,700,b' Replace all ML.Transforms SubComponent usages with IComponentFactory.',"b'Working towards #585\r\n\r\nPlease ignore the first commit, it is being proposed separately as #698. I am using these new constructors in this PR, so I needed to include it.  If you have any comments regarding it directly, please put them on #698.\r\n\r\nThere are 2 ""hacks"" in this PR that I\'m not proud of:\r\n\r\n1. `LearnerFeatureSelectionTransform` depends on `SDCA`, but `ML.Transforms` doesn\'t have a reference to `ML.StandardLearners`. I wasn\'t sure how to proceed here (add the dependency, or move some code around).  For now I continued to use Dependency Injection to create the component. Please give me your opinion on what the best approach forward would be.\r\n\r\n2. `RffTransform` has an undesirable coupling to which kind of MatrixGenerator it is using (gaussian or not). Previously, it was using the ComponentCatalog to determine which type of MatrixGenerator it was working with before actually creating it. However, I can no longer do that without actually creating the generator, so I needed to make a ""dummy"" instance. I spoke with @yaeldekel, and we decided this was ""OK"" for now, since it typically only used with a small number of columns (i.e. 1). I\'ve logged #699 for this.'"
352308659,698,b'Add convenience constructors for TextLoader.',b'Creating a TextLoader and specifying its arguments manually is too verbose. We should add a few constructor overloads to make it easier.\r\n\r\nThis work item is related to the new API proposal #371'
351880144,693,"b'Replace DvDateTimeZone, DvDateTime, DvTimeSpan with .NET standard types.'",b'fixes #673 '
351859667,692,b'Replace DvBool with .NET standard type.',b'fixes #673 '
351777552,691,b'Port all relevant AVX hardware intrinsics C# APIs from SIMD native algorithms',"b""### What's new:\r\n1. Implemented all relevant AVX intrinsics, sharing the same software fallbacks previously implemented in `CpuMathUtils`\r\n2. Implemented unit tests in a way compatible with both AVX and SSE alignments, and both netcoreapp and netstandard\r\n2. Implemented separate performance tests for AVX and SSE intrinsics, except for those that accept `AlignedArray` as an argument\r\n3. Performance test results for all applicable AVX intrinsics are updated in https://github.com/briancylui/machinelearning/issues/1\r\n4. **Note:** This time, most AVX intrinsics with the `U` suffix are implemented from scratch and do not yet have support from [native code](https://github.com/dotnet/machinelearning/blob/b51d9f9060acfcbe84405ce37f9c045654573ee0/src/Native/CpuMathNative/Avx.cpp), which only contains their counterparts with the `X` suffix.\r\n\r\n\r\n### Description from https://github.com/dotnet/machinelearning/pull/668:\r\n1. Implemented all remaining active SSE intrinsics, including their software fallbacks and passing unit tests\r\n2. Implemented the performance tests of all remaining active SSE intrinsics, except for those that accept `AlignedArray` as an argument\r\n3. Performance test results for all applicable, active SSE intrinsics are updated in https://github.com/briancylui/machinelearning/issues/1\r\n\r\n### Description from https://github.com/dotnet/machinelearning/pull/562:\r\n- with unit tests and performance tests for two target frameworks: .NET Core App 3.0 and .NET Standard 2.0.\r\n- .NET Core App 3.0 gets the new C# hardware intrinsics APIs, while .NET Standard 2.0 gets the original native SIMD algorithms.\r\n- Several things have made this multi-targeting feature possible.\r\n   1. The new CpuMathUtils class that contains the new APIs is implemented as a partial class with method definitions split into two separate files (src\\Microsoft.ML.CpuMath\\CpuMathUtils.[target].cs), only one of which is compiled based on the target framework.\r\n   2. The Microsoft.ML.CpuMath.csproj file makes the switching decision to compile the right files based on the target framework.\r\n\r\n### Structure:\r\n1. All new hardware intrinsics APIs are contained in src\\Microsoft.ML.CpuMath.\r\n2. Unit tests for the two target frameworks live in test\\Microsoft.ML.CpuMath.UnitTests.[target], and contain the same content except for the target framework in .csproj.\r\n3. Performance tests live in test\\Microsoft.ML.CpuMath.PerformanceTests.\r\n\r\n### Changes to users:\r\n1. Originally, users call intrinsics APIs via the SseUtils class in src\\Microsoft.ML.CpuMath\\Sse.cs, but now they call them via the new CpuMathUtils class, which will handle switching between SSE and AVX in the future.\r\n2. CpuMathUtils methods and SseUtils methods share the same signature, but CpuMathUtils methods additionally call a new helper class (SseIntrinsics) for C# implementations of SSE operations.\r\n\r\n### Future follow-up for `CpuMath` enhancement\r\n1. Suggestions on `CpuMath` enhancement in this PR scheduled for future follow-ups have been compiled into an issue page (https://github.com/briancylui/machinelearning/issues/2).\r\n\r\ncc: @eerhardt @safern @tannergooding @danmosemsft """
351762242,690,b'Move to netcoreapp2.1',"b'Since .NET Core 2.0 is [getting to the end of its lifetime](https://blogs.msdn.microsoft.com/dotnet/2018/06/20/net-core-2-0-will-reach-end-of-life-on-september-1-2018/), we should upgrade our tests and build infrastructure to .NET Core 2.1.\r\n\r\nFYI - @TomFinley @codemzs @Ivanidzo4ka @Zruty0 '"
351674145,688,b'API scenarios implementation with Estimators',b'First version of a couple scenarios over Estimators'
351668715,687,b'API scenarios implemented with Estimators API',b'Added some Estimators-based scenarios and stopgap implementations of necessary components'
351625936,686,b'Simplified if-expression',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
351316661,684,b'HashTransform to handle Floats and Doubles',b'closes issue #679 '
351064227,683,b'Replace DvInt* with .NET standard data types. WIP',"b'This change also removes missing value handling for sbyte, short, int and long because default of these values is a null and that does not fit well with sparse vector architecture where default for missing values is a zero. fixes #673 '"
350992242,681,b' Replace SubComponent with IComponentFactory in ML.Ensemble',"b""The next round of SubComponent removal. Now the ML.Ensemble project is SubComponent free.\r\n\r\nWorking towards #585\r\n\r\nNote: I had to move the Argument class's fields down to the concrete class because of the way we handle `SignatureType`. You can use a generic type in an attribute.  However, this allowed me to remove the `TSig` type on the base classes, which is nice since the signature Type shouldn't be in the public API."""
350200569,677,b'Introduce examples for pipeline api.',b'examples for #584\r\n\r\n'
349674104,672,b'Change SseUtils call sites to call CpuMathUtils instead',"b'After all active SSE intrinsics have been implemented and tested for correctness and speed, this PR asks to make all external `SseUtils` call sites call `CpuMathUtils` instead.  This would allow us to obtain a baseline performance of C# hardware intrinsics APIs in a future PR.\r\n\r\ncc: @safern @danmosemsft @eerhardt @tannergooding '"
349324749,671,b' Move Scorers and Calibrators to use IComponentFactory.',"b""Also, PartitionedFileLoader is now SubComponent-free.\r\n\r\nThis is the next round of SubComponent removal from our public API.  I've removed all `Scorer` and `Calibrator` usages of SubComponent.\r\n\r\n@Ivanidzo4ka - I still need to update this so CmdParser doesn't throw an exception.  I'll do that when I'm back in the office. I wanted to send this out now to get eyes on it while I'm out."""
348979642,670,b'WIP Introduce I*PredictionKind*TrainerFactory and propagate them ',"b""Fixes #669.\r\n\r\nNeed to kill all LoadableClasses attributes, and figure out why command line parser throw assert.\r\n\r\n@eerhardt  this is related to comment in your PR regarding subcomponents, and I just don't want you to do same job since this is about 90% complete."""
348907770,668,b'Port all active C# hardware intrinsics APIs for SSE from SIMD native algorithms',"b""### What's new:\r\n1. Implemented all remaining active SSE intrinsics, including their software fallbacks and passing unit tests\r\n2. Implemented the performance tests of all remaining active SSE intrinsics, except for those that accept `AlignedArray` as an argument\r\n3. Performance test results for all applicable, active SSE intrinsics are updated in https://github.com/briancylui/machinelearning/issues/1\r\n\r\n### Description from https://github.com/dotnet/machinelearning/pull/562:\r\n- with unit tests and performance tests for two target frameworks: .NET Core App 3.0 and .NET Standard 2.0.\r\n- .NET Core App 3.0 gets the new C# hardware intrinsics APIs, while .NET Standard 2.0 gets the original native SIMD algorithms.\r\n- Several things have made this multi-targeting feature possible.\r\n   1. The new CpuMathUtils class that contains the new APIs is implemented as a partial class with method definitions split into two separate files (src\\Microsoft.ML.CpuMath\\CpuMathUtils.[target].cs), only one of which is compiled based on the target framework.\r\n   2. The Microsoft.ML.CpuMath.csproj file makes the switching decision to compile the right files based on the target framework.\r\n\r\n### Structure:\r\n1. All new hardware intrinsics APIs are contained in src\\Microsoft.ML.CpuMath.\r\n2. Unit tests for the two target frameworks live in test\\Microsoft.ML.CpuMath.UnitTests.[target], and contain the same content except for the target framework in .csproj.\r\n3. Performance tests live in test\\Microsoft.ML.CpuMath.PerformanceTests.\r\n\r\n### Changes to users:\r\n1. Originally, users call intrinsics APIs via the SseUtils class in src\\Microsoft.ML.CpuMath\\Sse.cs, but now they call them via the new CpuMathUtils class, which will handle switching between SSE and AVX in the future.\r\n2. CpuMathUtils methods and SseUtils methods share the same signature, but CpuMathUtils methods additionally call a new helper class (SseIntrinsics) for C# implementations of SSE operations.\r\n\r\n### Future follow-up for `CpuMath` enhancement\r\n1. Suggestions on `CpuMath` enhancement in this PR scheduled for future follow-ups have been compiled into an issue page (https://github.com/briancylui/machinelearning/issues/2).\r\n\r\n### List of new SSE intrinisics implemented\r\n\xe2\x80\xa2\tMatMulA\r\n\xe2\x80\xa2\tMatMulTranA\r\n\xe2\x80\xa2\tMatMulPA\r\n\xe2\x80\xa2\tMatMulTranPA\r\n\xe2\x80\xa2\tSdcaL1UpdateU\r\n\xe2\x80\xa2\tSdcaL1UpdateSU\r\n\xe2\x80\xa2\tAddScaleCopyU\r\n\xe2\x80\xa2\tSumU\r\n\xe2\x80\xa2\tAddScalarU\r\n\xe2\x80\xa2\tSumSqDiffU\r\n\xe2\x80\xa2\tSumAbsDiffU\r\n\xe2\x80\xa2\tMaxAbsDiffU\r\n\xe2\x80\xa2\tMaxAbsU\r\n\xe2\x80\xa2\tScaleSrcU\r\n\xe2\x80\xa2\tScaleAddU\r\n\xe2\x80\xa2\tZeroItemsU\r\n\xe2\x80\xa2\tZeroMatrixItemsCoreU\r\n\r\ncc: @eerhardt @tannergooding @safern @danmosemsft """
348849406,667,b'Add sigmoid to lightgbm parameter list and change default to 1.',b'fixes #654 \r\n\r\n'
348727104,665,b'Documentation fixes for the issues in #664',b'Linked Microsoft.ML.SymSgdBinaryClassifier to its documentation. \r\nFixes the missing type in the list element of the FastTree documentation. \r\nIndented examples. \r\n'
348522576,662,b'Add reference to ImageAnalytics nuget so image transforms are packaged.',b'Add reference to ImageAnalytics nuget so image transforms/learners are packaged.\r\n\r\nFixes #661 \r\n\r\n\r\n'
348385143,660,b'Add method AddEntryPoint to class Experiment to add custom entrypoints.',"b'Fixes #659, all entrypoints in class Experiment are stored in _jsonNodes. The method AddSerialize can appends a new node not necessarily defined in Microsoft.ML.\r\n\r\n\r\n'"
348345674,658,b'[WIP] Including Thread Id in the path to avoid collisions',b'This pull request it is to try to solve the problem at #568 \r\n\r\nWhat we did was add the Thread ID in the extracted entity this might result in one entity being added more than once in case there are multi thread working int the solution. Would be good to validate that but I was unsure on how to do it. Another solution would be just to not include anything in case the file it is being extracted already. \r\n\r\nWhat it is the desired behavior for this library would be subjected to how it works if someone from the team could help in understanding that I would be grateful.'
348128489,656,b'Add release notes for ML.NET 0.4',b'This adds release notes for ML.NET 0.4. \r\n\r\nNote that some of the documentation links are not available yet. They will start working after the official release.\r\n'
348098009,653,b'API scenarios implemented with low-level functions',b'examples for #584 '
347972660,652,b'Fix test output during CI.',"b""When tests run in CI, we are not displaying the test output to the console. So if a test fails, and for some reason the .trx file isn't parsed correctly, it is impossible to see what test failed and why.\r\n\r\nThe test output isn't being displayed because of https://github.com/Microsoft/vstest/issues/1503.\r\n\r\nTo work around the vstest bug, split CI builds into 2 separate MSBuild invocations: one to do the build (which is multi-proc) and another to run the tests (which doesn't need MSBuild node reuse).\r\n\r\n"""
347946870,651,b'fixed a spelling from adressing to addressing.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nfixed #650.\r\n\r\n"""
347798420,647,b'Pass MKL version to CMAKE from MSBUILD.',b'fixes #648 '
347558335,646,b'[Part 1] Added comments/description to convenience constructors for a set of transform',b'This PR partially addresses #524.\r\n\r\nInformative comments/description is added to convenience constructors of transforms so that comments/description appear in the intellisense for users.\r\n\r\nDescription/Comments are obtained from relevant `doc.xml` file and added to C# summary comments section using `<include>` tag. If  `doc.xml` does not contain the required information it is directly added to C# summary comments.\r\n\r\nFollowing is list of transforms covered in this PR.\r\n\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n'
347516565,645,b'Bump the master branch to 0.5',"b'Now that we have branched for 0.4, we need to bump the master branch to the next version.\r\n'"
347516249,644,b'Merge master into release/preview for 0.4',"b'This is a merge of the master branch.  It is basically a straight ""accept master"" on any conflict.\r\n\r\n'"
347432074,643,b'Fix official build failure',"b""Now that the HalLearners nuget package doesn't have a PackageReference to MlNetMklDeps, the MlNetMklDeps package is no longer getting restored during the official build. Since HalLearners needs the license file from MlNetMklDeps, it is failing to build the nuget package.\r\n\r\nThe fix is to restore all project before building the packages."""
347270264,641,b'Make model path mandatory in export to ONNX.',b'fixes #423 \r\n\r\n'
347222797,640,b'Support for read-only properties',"b""Suggestion how to fix #631 \r\nThis would let user pass partially visible properties, but in same time, use will have to mark some of them if he don't want them to be exposed."""
347221914,639,"b""API 'getting started' examples""","b""These examples currently do not compile, they depend on both Estimators and static type checks, but let's at least agree that we can all stand behind them in terms of simplicity.\r\n\r\nDo not merge, this is a discussion-only PR."""
347141692,636,b'Change the linux official build queue from test to production.',"b'We were using a ""test"" build queue because of some limitations with the build lab.  Those limitations are now fixed, so we can start using the ""production"" build queue again.\r\n'"
347138582,635,b'Copy native assemblies for packages.config',"b'Whenever we have native assemblies in our nuget packages, we need to have special build logic in order for it to work on packages.config.\r\n\r\nWe already had that logic for Microsoft.ML, but were missing it for CpuMath and HalLearners.\r\n\r\nFix #633'"
347131475,634,b'package mkl lib with hal learners.',b'fixes #638 \r\n'
346847604,629,b'Merge master into release/preview branch for v0.4',b'This PR is cumulatively merging master into release branch in preparation for v0.4 release.'
346817676,628,b'Fixes in documentation for wordembedding',"b'Better example, and replace html encoding to xml encoding\r\n'"
346789518,627,b'Merge master into release/preview branch for v0.4',b'This PR is cumulatively merging master into release branch in preparation for v0.4 release.'
346746546,626,b'Fix official build',"b""Our official build is broken because we introduced a new dependency when building native code.\r\n\r\nPreviously, when we built native code, we didn't need to restore NuGet packages. But with #624 we now have a dependency from our native C++ code to the MklImports NuGet package. And our build fails if the package hasn't been restored.\r\n\r\nThe fix is to make `BuildNative` dependent on `RestorePackages`."""
346669988,625,b'Docs formatting',b'Incorporating the changes the content developing team made to the ml.net doc repo: https://github.com/dotnet/ml-api-docs\r\n\r\n'
346571686,624,b'Port SymSGD trainer',b'This change adds parallel SGD trainer but disables its multi-threading capabilities because of the lack of OpenMP support by the Clang compiler on linux and macOS build systems and MKL library. It also Supersedes PR #556 by squashing all the commits in one and rebasing with master.\r\n\r\nfixes #623 \r\n'
346427167,622,b'Initial replacement of SubComponent with IComponentFactory',"b'This is the first round of code changes necessary in order to remove SubComponent and instead use IComponentFactory.\r\n\r\nThis change removes SubComponent from the following public APIs:\r\n\r\n* `CompositeDataLoader`\r\n    * In order to completely remove it here, I needed to also remove it in some of the DataCommand classes as well - since they were calling methods on CompositeDataLoader that used SubComponent.\r\n* `Ova` and `Pkpd`\r\n* `TermTransform`\r\n\r\nWorking towards #585 \r\n'"
346392942,621,b'Remove agent.os demands on windows ci',"b""All the machines in this pool are guaranteed to be Windows_NT and now that the pool was made big enough not all of them define an agent.os property, so if they don't have one it will only use the machines that define that only. So in order to have more machines available and make CI faster, let's remove that statement and bump parallel to 4.\r\n\r\nThis was causing Windows builds to be slow and not ran in parallel.\r\n\r\ncc: @chcosta @eerhardt \r\n\r\n"""
346356802,620,"b'Overrides forObject.Equals(Object o), GetHashCode() for ... '","b'Closes #547\r\nAdded overrides for Object.Equals(Object o), GetHashCode() for VectorType, KeyType and ImageType\r\n\r\n'"
346184347,616,b'Allow use of property-based row classes in ML.NET',"b'This is WIP to address \r\n* https://github.com/dotnet/machinelearning/issues/254 - ""Support ColumnAttribute on properties and not just fields"" and \r\n* https://github.com/dotnet/machinelearning/issues/180 - ""F# Records not compatible with ML .NET""\r\n\r\nIt builds on #600 and you can see the added diff between #600 and this PR [here](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-fe2d4189320f83b77c7f4f5dca8bb5d8R132)\r\n\r\nCopying comment from [here](https://github.com/dotnet/machinelearning/issues/254#issuecomment-409215137):\r\n\r\n> This would allow the use of [ColumnNameAttribute and friends](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-46f68725db753df8e54db621da51265cR17) on both public fields (as today) and public properties that have getters/setters.\r\n> \r\n> I\'ve tested that allows an F# record definition to be successfully used, e.g. [this test](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-fe2d4189320f83b77c7f4f5dca8bb5d8R132) now passes in that branch.  It would also allow C# classes that just use attributed public get/set properties to be used, many tests for that pattern would need to be added (e.g. covering the vector, channel and other cases)\r\n> \r\n> It would be a change in spec because existing C# classes that use public fields _plus_ some additional get/set properties may now have their get/set properties considered part of the schema, when they weren\'t before.  I suppose this may mean the user has to add some NoColumn attributes on to these properties.  \r\n> \r\n> We could theoretically adjust the spec to be ""if there are non-zero public fields, then use public fields.  Otherwise, see if there are public get/set properties"", but right now I\'ve used the rule ""combine the public fields and public get/set properties"" as that seems more natural and allows gradual transition of field-based types to property-based types.\r\n> \r\n> I believe this would address @terrajobst\'s concerns about the use of public fields, at least in the core schema model.  There are other uses of GetFields() and field-reflection in the component model/catalog parameterization system which I haven\'t attempted to address.\r\n\r\n'"
345987429,614,b'Added convenience constructors for ScoreTransform and TrainAndScoreTransform.',b'This PR fixes #606.\r\n\r\n'
345967030,611,b'Splitting OLS to a separate package called AdditionalLearners',"b""@eerhardt  pointed out on PR #594 that OLS would not work on the ML.Net package, because the main ML.Net package doesn't reference the MlNetMklDeps package. \r\n\r\nTaking his suggestion and splitting OLS into a separate nuget package. """
345936206,610,b'support validation and incremental trainers',"b""Our internal test shows what some trainers stop properly handle validation datasets and continue training.\r\nThus I'm trying to set proper flags in Info, although, it feels like this flags are useless, but what do I know."""
345883775,607,b'Repeated: Port SIMD algorithms for SSE to managed code',"b'- with unit tests and performance tests for two target frameworks: .NET Core App 3.0 and .NET Standard 2.0.\r\n- .NET Core App 3.0 gets the new C# hardware intrinsics APIs, while .NET Standard 2.0 gets the original native SIMD algorithms.\r\n- Several things have made this multi-targeting feature possible.\r\n   1. The new `CpuMathUtils` class that contains the new APIs is implemented as a partial class with method definitions split into two separate files (`src\\Microsoft.ML.CpuMath\\CpuMathUtils.[target].cs`), only one of which is compiled based on the target framework.\r\n   2. The `Microsoft.ML.CpuMath.csproj` file makes the switching decision to compile the right files based on the target framework.\r\n\r\n### Structure:\r\n1. All new hardware intrinsics APIs are contained in `src\\Microsoft.ML.CpuMath`.\r\n2. Unit tests for the two target frameworks live in `test\\Microsoft.ML.CpuMath.UnitTests.[target]`, and contain the same content except for the target framework in `.csproj`.\r\n3. Performance tests live in `test\\Microsoft.ML.CpuMath.PerformanceTests`.\r\n\r\n### Changes to users:\r\n1. Originally, users call intrinsics APIs via the `SseUtils` class in `src\\Microsoft.ML.CpuMath\\Sse.cs`, but now they call them via the new `CpuMathUtils` class, which will handle switching between SSE and AVX in the future.\r\n2. `CpuMathUtils` methods and `SseUtils` methods share the same signature, but `CpuMathUtils` methods additionally call a new helper class (`SseIntrinsics`) for C# implementations of SSE operations.\r\n\r\n## New pull request:\r\n1. Created this new pull request since the build definition has been changed since the last pull request.  This PR also includes a response to the last PR in the latest commit.\r\n2. Suggestions on `CpuMath` enhancement from the last PR have been compiled into an issue page [here](https://github.com/briancylui/machinelearning/issues/2).'"
345753576,600,b'Smoke test for F#',"b'This addresses the first part of #540, i.e. adding an initial smoke test for ML.NET and F#\r\n\r\nSubmitting now to check that CI passes ok, will then iterate.\r\n\r\n\r\n'"
345516673,597,b'Add needed param to warning for L2 in SDCA',b'Closes #596\r\n\r\n'
345401790,594,b'adding a dependency to the MlNetMklDeps package',"b'Introducing the entry point for Ols, and enabling its test\r\nAdding documentation  for Ols\r\n\r\nResolves #497 \r\n\r\n'"
345290453,592,"b'Fixes #591: typos, adding the type attribute to lists, and moving the name attribute for some examples'","b'Testing the documentation in the doc.microsoft.com staging environment, i noticed a few typos, unescaped apostrophes, and missing xml tag attributes. \r\n\r\nFixes #591: typos, adding the type to lists, and fixing the name attribute in OGD and Poisson\r\n\r\n\r\n\r\n\r\n'"
345138981,587,b'Fix creation of dataviews inferred with .NET types with sparse vectors',"b""Fixes #586. `DataViewConstructionUtils`'s methods to create dataviews over .NET types will now have correctly inferred getters in the case of sparse vectors."""
344149093,579,b'Sweep Range of L2RegularizerWeight in AveragedPerceptron',b'Fixes #567 \r\n\r\n'
344129936,578,"b'Adding the MlNetMklDeps package, adding the entry point, tests and docs for OLS.'",b'MKL package has been published'
343821858,575,b'Pass fold index to cross validation metrics.',b'Fixes #570\r\n\r\n'
343799130,574,b'Fix Linux CI to actually run inside a docker container',b'Current CI was not running under a docker container. Use a different approach using a vsts variable to run under the container.\r\n\r\ncc: @eerhardt @Ivanidzo4ka \r\n\r\n'
343736053,572,b'Schema comprehension doc',b'Added a document that describe typed schema comprehension.\r\n\r\nFixes #554 \r\n'
343253617,566,b'Move Windows and Linux CI to VSTS',b'cc: @eerhardt \r\n\r\n'
343186556,565,b'Add build steps to  test it works fine',b'Changes CI system to use VSTS\r\n\r\n'
343000052,562,b'Port C# key hardware intrinsics APIs for SSE from SIMD native algorithms',"b'- with unit tests and performance tests for two target frameworks: .NET Core App 3.0 and .NET Standard 2.0.\r\n- .NET Core App 3.0 gets the new C# hardware intrinsics APIs, while .NET Standard 2.0 gets the original native SIMD algorithms.\r\n- Several things have made this multi-targeting feature possible.\r\n   1. The new CpuMathUtils class that contains the new APIs is implemented as a partial class with method definitions split into two separate files (src\\Microsoft.ML.CpuMath\\CpuMathUtils.[target].cs), only one of which is compiled based on the target framework.\r\n   2. The Microsoft.ML.CpuMath.csproj file makes the switching decision to compile the right files based on the target framework.\r\n\r\n### Structure:\r\n1. All new hardware intrinsics APIs are contained in src\\Microsoft.ML.CpuMath.\r\n2. Unit tests for the two target frameworks live in test\\Microsoft.ML.CpuMath.UnitTests.[target], and contain the same content except for the target framework in .csproj.\r\n3. Performance tests live in test\\Microsoft.ML.CpuMath.PerformanceTests.\r\n\r\n### Changes to users:\r\n1. Originally, users call intrinsics APIs via the SseUtils class in src\\Microsoft.ML.CpuMath\\Sse.cs, but now they call them via the new CpuMathUtils class, which will handle switching between SSE and AVX in the future.\r\n2. CpuMathUtils methods and SseUtils methods share the same signature, but CpuMathUtils methods additionally call a new helper class (SseIntrinsics) for C# implementations of SSE operations.\r\n\r\n### Future follow-up for `CpuMath` enhancement\r\n1. Suggestions on `CpuMath` enhancement in this PR scheduled for future follow-ups have been compiled into an issue page [here](https://github.com/briancylui/machinelearning/issues/2).\r\n'"
342605196,557,"b'Initial code analyzer for Microsoft.ML, use limited StyleCop'","b'Fixes #553.\r\n\r\nSome WIP items:\r\n- [x] Fix issue with `new` declarations on members not being properly handled by accessibility modifier check.\r\n- [x] Enable checking in all source projects, not just `Microsoft.ML.Core`. (Done only there for now just to validate approach.)\r\n\r\nAdds code analysis initially for correct usage of common Contracts.Except/Check patterns, naming conventions, variable usage and initializations, access modifiers, and other idioms used throughout the Microsoft.ML codebase. Enables analysis on Microsoft.ML projects. Uses existing StyleCop analyzer rules for these where appropriate.'"
342556761,556,b'Port SymSGD',b'This change adds parallel SGD trainer.\r\nfixes #623 '
342549622,555,"b""Don't fail in case of const field in Collection source and extended support for type conversion""",b'Fixes  #537.\r\nAdds support for multiple basic C# types to convert Dataview <-> collection.\r\n'
342139971,550,b'Ensure ONNX export is compatible with Windows RS5',b'fixes #549 by testing ONNX models on Windows RS5 machine.'
342119690,548,b'Fixed the TextTransform bug where chargrams where being computed differently when using with/without word tokenizer.',"b'This PR fixes #530. The cause of the problem was `word tokenizer` being applied before `char tokenizer` causing scalar valued text (e.g. `This is a cat`) to become vector (e.g. <This, is, a, cat>). \r\n\r\nPreviously, char tokenizer treated every vector item as separate text item (e.g. computing chargrams on each item by placing start and end markers `<STX>token<ETX>` instead of taking `This is a cat` as single text item).\r\n\r\nThe fix is in CharTokenizeTransform. The CharTokenizeTransform can take either a scalar or vector column as input. The processing of chargrams are done as follows.\r\n\r\n- If the input column is a scalar with text type then chargrams are computed by prepending `<STX>` and appending `<ETX>` characters at the start and at the end of the text respectively.  For example, if the input is `This is a cat` then chargrams will be computed on `<STX>This is a cat<ETX>`.\r\n\r\n- If the input column is a vector with text type (it could be a result of concatenation of several text columns together or application of word tokenizer before char tokenizer) then chargrams will be computed by prepending `<STX>` and appending `<ETX>` characters at start and at the end of the vector respectively. Also, <US> characters are inserted after every item in the vector. For example, if the input is `<This, is, a, cat>` then chargrams will be computed on `<STX>This<US>is<US>a<US>cat<ETX>`.\r\n\r\n- To be backward compatible, CharTokenizerTransform version was bumped up and the support for loading models saved with previous version is added.\r\n\r\nMoving forward, the chargrams will be computed as follows\r\n\r\n- if `stop word removal` is request, chargrams will be computed after `StopwordRemovalTransform` is applied e.g. `<STX>This<US>is<US>a<US>cat<ETX>`.\r\n- otherwise, raw text after text normalization will be used for chargram computing e.g. `This is a cat`.\r\n\r\n'"
342076074,545,b'word embedding transform',b'I heard word embedding can be nice thing for Text classification\r\n- [x] Create issue\r\n- [x] Put legal attributes for fastText files\r\n- [x] Put legal attributes for GloVe files\r\n\r\n(edited by @justinormont to fix model type names) \r\ncloses #615 '
341951176,542,b' Allow CpuMath to reference C# Hardware Intrinsics APIs.',"b""Need to multi-target CpuMath for netstandard and netcoreapp3.0.  Also, since we are going to move CpuMath into its own NuGet package, remove the dependency from CpuMath to the ML.Core project.\r\n\r\nAdd a build parameter to enable building against .NET Core 3.0's Runtime Intrinsics APIs.\r\n\r\nFix #534 """
341571989,539,b'PipelineSweeperMacro for Multi-Class Classification',b'Fixes #538\r\n\r\n- The PipelineSweeper currently only supports AUC as the optimization metric.  Trying to optimize on any other metric throws an exception.\r\n- Need to fix the way metrics are handled by the PipelineSweeper Macro.\r\n- Added a test case for MultiClass classification using the PipelineSweeper.\r\n\r\n'
341087165,529,b'Adding documentation about the rest of the classes involved on generating the CSharpAPI',"b'Resolves #389 \r\nAdded more documentation and examples about mostly transforms components. (A few learners as well.)\r\n\r\nThe documentation for the classes involved in generating the entry points lives in the doc.xml documents, since it needs to be referenced from two locations, for the most part, and since the CSharpApi is auto-generated. \r\n\r\n'"
341041086,528,b'Image support',b'address #489 \r\nneed create issue about IDataView datatype extensibility.\r\n'
341032515,527,b'Fix TrainAndPredictIrisModelUsingDirectInstantiationTest',b'Fixes #526 .\r\n\r\nThe test `TrainAndPredictIrisModelUsingDirectInstantiationTest` now has analogous changes to the `TrainAndPredictIrisModelTest` test.'
340486297,522,"b'Conversion of ITrainer.Train returns predictor, accepts +TrainContext'","b'Fixes #509.\r\n\r\n* `ITrainer.Train` returns a predictor. There is no `CreatePredictor` method on the interface.\r\n\r\n* `ITrainer.Train` always accepts a `TrainContext`. Dataset type is no longer a generic parameter. This context object replaces the functionality previously offered by the combination of `ITrainer`, `IValidatingTrainer`, `IIncrementalTrainer`, and `IIncrementalValidatingTrainer`, which is now captured in one `ITrainer.Train` method with differently configured contexts.\r\n\r\n* All trainers updated to these two new idioms. Many trainers correspondingly improved to no longer be stateful objects. (The exceptions are those that are just too far gone to be done with less than herculean effort at refactoring them to no longer use instance fields for their computation, most notably, LBFGS and FastTree based trainers.)\r\n\r\n* Utility code meant to deal with the complexity of the aforementioned `IT/IVT/IIT/IIVT` idiom reduced considerably.\r\n\r\n* Opportunistic improvements to `ITrainer` implementors where observed.'"
339993621,520,b'[Part 3] Added convenience constructors for set of transforms.',b'This PR fixes #518. The convenience constructors were added for following transforms.\r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs'
339877803,516,b'Fix quotes on json',"b""Fixes issue #507.\r\n\r\nDidn't see any impacted tests for this, but going to see about adding one."""
339677302,514,b'Remove Extra Code Comments and unused InternalStreams project',"b""Fixes #513\r\n\r\nThis is the first go-around at finding extra commented code sitting around. I'll circle back on more when I have a chance.\r\n"""
339547248,510,"b'XML strings for the documentation should live outside of the src code, in xml files. '","b'Resolves #477  by moving the strings with the XML remarks, examples etc into a separate XML file. \r\nNow the actual classes and their C# Api counterparts share the path to the XML node that contains the documentation and the respective example. \r\n\r\nOn this PR, there are only two examples that are separate from the rest of the descriptive xml: the LogisticRegressionBinaryClassifier and LogisticRegressionClassifier, to give an idea of the infrastructure. \r\n\r\nThe rest of the examples are coming in the next PR, together with the rest of the documentation. \r\n\r\n'"
339284398,505,"b'Update Onnx Convert documentation, limited to ONNX-ML target platforms'","b""This PR is just updating the documentation/comments for the ML.NET Convert/export to ONNX.\r\nThe ML.NET export/convert feature uses ONNX-ML (not the regular ONNX specification). \r\nCurrently, the only target platform supported by ONNX-ML is Windows ML.\r\nThe current comments in the documentation have examples mentioning Apple CoreML and TensorFlow, which are currently not supported by ONNX-ML. \r\nThis PR is simply fixing the comments/documentation.\r\n\r\nFurther details on ONNX and ONNX-ML:\r\nONNX is not a single specification but two different variations of the standard. The neural-network-only (DNN) ONNX variant recognizes only tensors as input and output types, while ONNX-ML is a classical Machine Learning variant. \r\nONNX-ML is part of the ONNX standard that provides functionality for classic ML and pipelines. It is a superset of core ONNX.\r\nFrameworks like Caffe2 and CNTK will not support ONNX-ML since they are focused on DNN. \r\n\r\nApple CoreML and other ONNX backends might support ONNX-ML in the future, but they currently don't, so our example should not mention Apple CoreML and TensorFlow as sample target platforms to use after exporting the ONNX file. At least, not yet.\r\n\r\n\r\n"""
338698075,499,b'Validate XML comments in test sources during builds',"b'* CS1573, CS1591, and CS1712 are disabled in test code (documentation is not required)\r\n* Other documentation warnings are enabled (documentation, when included, must be syntactically and semantically correct)\r\n* Fixes cases where comments were incorrect in the current code\r\n\r\nRelated to #434\r\n\r\n\xe2\x9a\xa0\xef\xb8\x8f ~~Please do not rewrite/rebase/squash this pull request during the merge.~~ Edit: relaxing this request for this pull request. \xe2\x9a\xa0\xef\xb8\x8f '"
338618669,496,b'Role mapped improvements',"b'Fixes #445.\r\n\r\n* Generally, favors creating `RoleMappedSchema`/`RoleMappedData` by actual constructors, since that\'s how objects are generally created.\r\n* Concentrated the actual globally useful ""conveniences"" inside the classes themselves, rather than in completely undiscoverable `Utils` classes.\r\n* Got rid of the `Create` and `CreateOpt` idiom that required that we declare every creation method *twice* in favor of a simpler `bool` parameter on the constructors.\r\n* Added documentation.'"
338413394,492,b'Add options to enable use of GPU with LightGBM',b'Note: requires a [build of LightGBM with GPU support](https://github.com/Microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version).  Addresses #500'
338102214,491,b'Added convenience constructors for set of transforms.',b'This PR fixes #487.\r\n\r\nConvenience constructors are added for the following transforms. \r\n\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n'
338061231,490,b'Removed `data` solution-folder from solution files.',"b""As mentioned in #475, files in `data` solution-folder currently are not presented in repository, so it's probably worth to remove them.\r\n"""
338012530,488,b'Hide argument object in ensemble multivoting',b'fixes #443 \r\n'
337997566,486,"b""Reverted 'new' modifier to be first in statement.""","b""This is a small fix left over from PR 478. Following [C# documentation](https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2010/435f1dw2(v%3dvs.100)), placing 'new' modifier to be first in the statement."""
337976972,485,b'Issue 434: Fixed imprecise `cref`s in XML Docs',"b""This fixes a couple of dangling `cref` in the XML Docs. This commit doesn't contain functional changes to the code.\r\n\r\nIssue:\r\n  This closes #434"""
337701078,479,b'Cherrypick to update release for V0.3',b'Cherrypick into release for v0.3'
337698392,478,b'Remove all spaces in the end of lines',"b""It's nice to not have spaces in the end of lines"""
337684413,476,b'Add release notes for ML.NET 0.3',b'This adds release notes for ML.NET 0.3'
337647069,472,b'ParquetLoader - Save Schema to context to support loading the model without files.',b'This changes address issue #471 \r\n\r\nThe Schema is added to the model context when saving. The context model can then be properly loaded without the need of additional files in order to inspect the schema. A file is still required on initial construction and an error will be thrown if a RowCursor is created without a file.\r\n\r\n'
337606890,468,b'Added tests for new API where components(Loaders/Transforms/Learners) are directly instantiated.',b'This PR addressed #424. \r\n\r\nTwo scenario tests were added to show how to directly instantiate ML.NET components instead of using Pipeline API. The test may not look elegant at first instance but they will help us shape the new API.\r\n\r\nThis work is inline with new API proposal #371.\r\n\r\n'
337591952,467,b'Fix a bug with group Id column in CV macro and add NameColumn argument to CV and TrainTest macros',"b'This PR fixes bug #456, and also introduces a NameColumn argument to the TrainTest and CV macros, to enable the evaluator to use it in the per-instance results.\r\nFixes #456 \r\nFixes #466 \r\n'"
337358659,464,b'Light LDA doc ',b'issue #458'
337246711,463,b'Fixed all typos in word `Transform`.',"b'Hey guys!\r\n\r\nWanna trying to contribute and do some helpful work! What is my first small trophy \xe2\x80\x94 typo in `ILearningPipelineStep` comment, which, as I found, is presented in other places in code.\r\n'"
337193292,462,b'Isolate ONNX implementations in separate DLL',"b'Fixes #162.\r\n\r\nPreviously, the ONNX infrastructure and implementations (including refs to protobuf) were in a central DLL. This gave us a dependency on a separate somewhat large project (protobuf), that was only of interest to people saving ONNX models.\r\n\r\nBy having the components save themselves through abstract classes rather than actual instantiable classes (`OnnxContext` became an abstract class with a hidden `OnnxContextImpl` implementation, `NodeProto` and `OnnxUtils` became the `OnnxNode` abstract class with, likewise, a hidden implementation), there is no need for any ""direct"" dependency on protobuf.\r\n\r\nAll implementation classes become internal classes of the `Microsoft.ML.Onnx` project. (This was previously called `Microsoft.ML.UniversalFormat` due to historical reasons that no longer make sense.) The only public classes in that project are the entry-points and commands inside `SaveOnnxCommand.cs`, which instantiate actual implementors of those interfaces, then pass to ONNX savable components.\r\n\r\nAlso, I opportunistically improved documentation on those public interfaces (though even with docs the interfaces would scarcely make sense to someone unfamiliar with ONNX), and improved the code.'"
337177740,461,b'Fix column purpose for PipelineSweeperMacro',"b'Fixes #460 \r\n\r\n- Adding arguments to the PipelineSweeperMacro.  Users will be able to specify the columns for a particular purpose.  \r\n- Updating the methods in the PurposeInference and TransformInference classes to pass the user provided column purposes as optional arguments.\r\n- Added unit tests for the sweeping engines we have currently (Defaults, Rocket, UniformRandom)\r\n\r\n\r\n'"
337143012,455,b'Xml docs for trainers and a minor infrastructure changes',"b'Addresses: #388 \r\n\r\nThis PR adds an EntryPointInfo attribute that will contain the XML documentation to append to the summary: ""Description"", ""References"", ""See also"" sections. \r\nIt also modifies the C# generation code to append the content of this new attribute to the summary. '"
337128266,454,b'Set culture to culture invariant in LightGBM',b'fixes #440 \r\n'
336826321,452,b'Update documentation for LightGBM and add missing binary references to console app.',b'fixes #450 \r\nfixes #451 '
336825011,449,b'WIP humble attemtp to setup vector size for data in runtime.',"b""I don't have any intent of checking this in in current state.\r\nDoesn't contain proper xml comments/ code cleaning.\r\nMain purpose of this PR is to gain feedback regarding mechanism of specifying vector sizes for type.\r\n"""
336819879,448,b'Add clarity to documentation on ColumnConcatenator',"b'Several of the [sample projects](https://github.com/dotnet/machinelearning-samples/) use more than 2 source columns in the column concatenator. In order to clarify, I updated all locations of the phrase ""Concatenates two columns of the same item type."" to be ""Concatenates two or more columns of the same item type.""\r\n\r\n'"
336778768,447,b'Add more documentation for ova',b'Provides more clear documentation for OneVersusAll learner.\r\nFixes #453 '
336719293,446,b'Normalization API helpers',"b'In which I introduce some helpers for normalization, and generally try to clean up the code-base. Addresses #433 . Hopefully will be used in #424, though I\'ve changed the code here to use some of it where it made sense.\r\n\r\n* The `Microsoft.ML.Data` transform had a ""hidden"" dependency on `Microsoft.ML.Transform` project via dependency injection, for its existing ""helper"" for normalization (the console-app centric version). This has been resolved and replaced with direct instantiation. It required moving the normalizer files, however.\r\n\r\n* Introduction of helpers on `NormalizeTransform` for API-centric operations. (Not necessarily useful directly for console-application/GUI usage.)\r\n\r\n* Some documentation changes on `RoleMappedSchema` and `RoleMappedData`, though more non-cosmetic changes I\'d expected would come with #445 .'"
336386335,444,b'Remove MML.DLL from Microsoft.ML nuget. (#439)',b'cherrypick into v0.3 to fix nuget'
336364273,442,b'small fixes in ensembles',"b'small code polishing related to #443\r\nmostly pacify robotom, and breaks diversity measure into separate interfaces (otherwise regression and binary have same interface and show off in gui/ code)\r\nalso put proper friendly name for weighted average combiner\r\n'"
336358607,441,b'Reverse integrate commit  fb8cf0b from master',b'Remove MML.DLL from Microsoft.ML nuget. (#439)'
336348295,439,b'Remove MML.DLL from Microsoft.ML nuget.',b'fixes #438 \r\n'
336335195,437,b'Fix bug #435.',"b'When combining per-instance data views, key columns with text key values should be handled only once.\r\nFixes #435 .'"
336290066,431,b'Build fix - removing the BOM from the CMakeLists.txt file (#430)',b'Cherrypick internal build fix into release\r\n\r\n'
336269704,430,b'Build fix - removing the BOM from the CMakeLists.txt file',"b'Remove the BOM from the CMakeLists.txt file, since it is breaking the build in vsts. \r\n\r\n'"
336153611,428,b'Fix iris.txt dataset and modify Iris Classification tests accordingly',"b'Related to issue #400.\r\n\r\n1) Reordered column values in `iris.txt` (headers stay the same), so the previously `Petal width` values are actually `Sepal length` values; other columns shifted to the right.\r\n\r\n2) Tests `TrainAndPredictIrisModelTest` and `TrainAndPredictIrisModelWithStringLabelTest` are modified accordingly so that the values that test the prediction are also reordered to be more realistic (same way the dataset is modified).\r\n\r\n3)  Model class `IrisDataWithStringLabel` fields reordered to match `iris.data` dataset.\r\n\r\nThe fix for the samples repo that uses the same dataset will follow.\r\n\r\n\r\n\r\n'"
336081120,427,b'Bump master to v0.4',"b'With release/preview branch updated for v0.3, bump the master branch to start building v0.4 assets.'"
336075646,426,b'Merge master into release/preview branch for v0.3',b'This PR is cumulatively merging master into release branch in preparation for v0.3 release.'
336054598,425,"b'removing extraneous character that broke the linux build, and with it the unnecessary cmake version requirement'","b'The cmake file for the FactorizationMachineNative folder contained a character in the first line, that was causing the build to fail. \r\n\r\nDeleting that, and deleting the first line, which was requiring a version of cmake higher than 3.2. \r\n\r\nThere are no issues with this PR, as this is to fix the Linux build. \r\n\r\n\r\n\r\n'"
336013620,422,b'Enable macOS tests for LightGBM.',b'fixes #417 by enabling tests on macOS that were disabled because openmp dependency was not present in the CI machines.\r\n\r\n'
335941246,419,b'ONNX API documentation.',b'fixes #418 by adding XML documentation for converting ML.NET models to ONNX.\r\n'
335638112,413,b'Revert to using native code for FastTree ranking gradient',"b'Corrects an unintentional ""typo"" in `FastTreeRanking.cs` where I had previously mistakenly put in `USE_FASTTREENATIVE2` instead of `USE_FASTTREENATIVE`. Fixes #412 .'"
335619610,411,"b'unify tests into one folder, modify framework to support different configurations and OS'","b""Fixes #410 also can help address #404 in case if it's impossible to resolve difference on platform level.\r\n\r\n"""
335591911,408,b'WIP: Fixed column name\\order in iris dataset',b'per issue #400 \r\nFixed the iris dataset'
335525797,405,b'Added convenience constructor for set of transforms (#380).',b'This PR fixes #380.\r\n\r\nAdded convenience constructor (or create method) for following set of transforms\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n'
335435490,402,b'[WIP] Add Debugger display attribute',"b""Proposed fix for #194.\r\n\r\nUpdated the `CSharpAPIGenerator` file to include the `DebuggerDisplay` attribute.\r\n\r\nMarked as WIP since I'm sure this would need to be improved.\r\n\r\n"""
335017929,397,b'Create a shorter temp file name for model loading.',b'Fixes #396\r\n'
335011922,394,b'EvaluatorUtils to handle label column of type key without text key values',"b'If the label column is a key converted from something other than text, \r\nFixes #395 '"
334959553,393,b'Adding xml style documentation for trainers',"b""Adding xml style documentation for trainers, to improve what's currently on docs.microsoft.com. \r\n\r\nAdresses #388 \r\n"""
334771594,392,b'LightGBM ',b'LightGBM integration. This change adds API for LightGBM binary and multiclass classifier.\r\n\r\nfixes #391 \r\n'
334255079,386,b'Link to an example on using converting ML.NET model to ONNX.',b'fixes #387 \r\n'
334221807,385,b'Fix CV macro to output the warnings data view properly.',b'Fixes #384 .'
334156657,383,b'Adding Factorization Machines ',b'Adding FactorizationMachines and a test for it. \r\nAddresses #381 \r\n\r\n'
333872000,379,b'Bring ensembles into codebase',b'Address #378'
333870349,377,b'Adding LDA Transform',b'issue #373 '
333440735,372,b'Update fast tree argument help text',b'Proposed update for issue #223.'
333367907,370,b'Move the NuGet package build files into a TFM specific directory.',"b""When installing Microsoft.ML on an unsupported framework (like net452), it is currently getting installed successfully. However, users should be getting an error stating that net452 is not supported by this package.\r\n\r\nThe cause is the build files exist for any TFM, which NuGet interprets as this package supports any TFM. Moving the build files to be consistent with the 'lib' folder support.\r\n\r\nFix #357"""
333350671,369,b'`Stream` subclasses now have `Close` call `base.Close` to ensure disposal.',b'Fixes #367.\r\n\r\nAlso while I was at it C# 7.x-ified the file.'
333254627,368,b'Return distinct array of ParameterSet when ProposeSweep is called',"b'This is associated with #215 \r\n\r\nThe ProposeSweep method built a List<ParameterSet> to return, I have changed this to a HashSet<ParameterSet> so that duplicates could not be added. I have also ensured that ParameterSet implements GetHashCode so that equality is calculated properly\r\n\r\nTests have been added to the solution. \r\n\r\nThanks to @Nepomuceno for working on this with me and this could be seen as a duplicate of #365 \r\n'"
332962253,365,b'Propose sweep',b'This pr it is to solve #215 \r\n\r\nThis guarantees that ProposeSweeps will generate just distinct values. Also there were tests created to guarantee that this is the case.\r\n\r\nThanks to @ross-p-smith that also wored in this pr.\r\n\r\n'
332859834,364,b'Combine multiple tree ensemble models into a single tree ensemble',"b'Create a single tree ensemble, by dividing the leaf outputs by the number of ensembles being combined, and multiplying by the calibration parameter if it exists.'"
332537019,363,b'add pipelineitem for Ova',b'Address #34.\r\nThis PR add wrapper on top of OVA to make it pipeline friendly.'
332465037,362,b'Removing non source files from solution',b'According to the discussion on the issue #322 I am proposing removing all non source files from the solution file in order to keep consistency and to keep the solution clean.\r\n'
332453998,361,b'Correcting error messages according to the instructions on ',b'#258 \r\n\r\nCorrecting error messages to reflect the issues page. '
332374252,359,b'Update error messages to point to GitHub issues instead of support group',"b'Fix for issue #258 by replacing `tlcsupp` with a link to https://aka.ms/MLNetIssue.\r\n\r\nDue to my lacking git skills, some commits from #358 got in, but I believe that can get cleaned up if/when it gets merged.'"
332350860,358,b'[WIP] Update ProposeSweeps to have unique entries',"b""Proposed fix for issue #215.\r\n\r\nUpdated the `ProposeSweeps` virtual and override methods to not add to the collection if it already exists to prevent duplicates.\r\n\r\nPut this as a work in progress PR since I'm sure I'll need some guidance as to if this solution is even a good one and how it can be further improved.\r\n\r\nIf anything else is needed, I'll be glad to update this PR."""
332197383,356,b'Use HideEnumValueAttribute for both manifest and C# API generation.',"b'Fixes #341, so that `HideEnumValueAttribute` is used not only in command line help usage but also the other late binding scheme depending on arguments, entry-points. This PR will also allow a more natural solution to #293 to be engineered.'"
332076809,355,b'Add link to samples',b''
331752651,351,b'Remove reference and dependency on System.ValueTuple',b'address #350 '
331484059,348,b'Minor formatting in CollectionDataSourceTests.cs',b'Corrects misplaced spaces in CollectionDataSourceTests.cs'
331043393,344,b'enabled developer naming their column same as valid v\xe2\x80\xa6',b'fiexed for #318\xef\xbc\x8cenabled developer naming their column same as valid variable name'
330811369,339,b'fix namespace issue in CSharpGenerator and some refactoring',b'address #202 #345'
330789524,338,b'Create CalibratedPredictor instead of SchemaBindableCalibratedPredictor',"b'Whenever the predictor implements IValueMapper, we create a calibrated predictor that implements IValueMapperDist. If the predictor is not an IValueMapper, we create SchemaBindableCalibratedPredictor.\r\nFixes #337 .'"
330736894,335,b'Remove unexisting project from solution',b'Address #334 '
330471837,330,b'Added more details to the NumTrees argument in FastTree ',"b""This PR fixes issue #223. Added more specificity to the NumTrees (number of trees) argument's help text within the FastTree class.\r\n"""
330437371,327,"b""Enabled '_' in the field/column name in input type. """,b'This PR fixes issue #318 \r\n\r\n\r\n'
330077268,324,"b""Using named-tuple in OneToOneTransforms' constructor to make API more readable.""",b'This is a partial fix to #274 without breaking anything.\r\n\r\n- Using named-tuple in the constructor instead of unnamed-tuple.\r\n- Renamed the parameters of methods.'
330014412,320,b'Include all categorical split points in feature gain map and clean up regression tree predictor for categorical splits.',b'fixes #319 '
329655997,316,b'Add Cluster evaluator',b'Address #312 '
329620778,310,b'OVA should respect normalization in underlying learner',b'Address #300 '
329546783,304,b'update sample in README.MD with 0.2 features.',b'\r\n\r\n'
329461592,303,b'Update release notes link to use aka.ms. (#294)',b'Our release notes link is broken because the `Documentation` was renamed to `docs`. Fix this for the future to use a redirection link.\r\n\r\nPorting #294 to `release/preview`.\r\n\r\n'
329268980,301,b'Add release notes for ML.NET 0.2',b'This adds release notes for ML.NET 0.2.'
329218478,297,b'Remove stale line of code from test.',b''
329197694,296,b'Fixed typo in the method summary',b'\r\n\r\n'
329172808,295,"b'Adding documentation about entry points, and entry points graphs: EntryPoints.md and GraphRunner.md'","b'Adding the EntryPoints.md and the GraphRunner.md files. \r\nEntryPoints.md introduces the entry points, the entry points manifests and classes that are associated with them. \r\nGraphRunner.md introduces and describes the entry points graph structure. \r\n\r\nAddresses #390 \r\n\r\n'"
329150249,294,b'Update release notes link to use aka.ms.',b'Our release notes link is broken because the `Documentation` was renamed to `docs`. Fix this for the future to use a redirection link.\r\n\r\nI will also port this change to the release branch so it gets updated in v0.2.'
329138747,293,b'Corrected norwegian bokmal stopwords and removed nynorsk words',"b""Went through:\r\nhttps://raw.githubusercontent.com/ecrmnn/norwegian-stop-words/master/dist/stop-words.txt\r\nhttps://raw.githubusercontent.com/crodas/TextRank/master/lib/TextRank/Stopword/norwegian-stopwords.txt\r\nhttps://raw.githubusercontent.com/Alir3z4/stop-words/master/norwegian.txt\r\nhttps://raw.githubusercontent.com/helgeu/machinelearning/master/src/Microsoft.ML.Transforms/Text/StopWords/Norwegian_Bokmal.txt\r\nhttp://snowball.tartarus.org/algorithms/norwegian/stop.txt\r\n\r\nto collect and correct the Norwegian stopwords.\r\n\r\nRemoved new norse (nynorsk) Version too.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ x] You have included any necessary tests in the same PR.\r\n\r\n"""
329124088,291,b'Get the cross validation macro to work with non-default column names',"b'When the label/weight/group Id column has a non-default name, we need to know how to pass that name to the evaluator in the CV macro.\r\nFixes #292 .'"
328686906,289,b'ML.NET-242: FastTreeRanking per-iteration loss metrics are empty',"b'When training a FastTreeRanker using the `testFrequency` parameter, it is expected that NDCG is printed every testFrequency iterations. However, instead of NDCG, only empty strings are printed.\r\n\r\nThe root cause was that the `MaxDCG` property of the dataset was never calculated, so the NDCG calculation is aborted, leaving an empty string as a result.\r\n\r\nThis PR fixes the problem by computing the `MaxDCG` for the dataset when the Tests are defined (so that if the tests are not defined, the `MaxDCG` will never be calculated). Here, the `truncationLevel` of the `MaxDCG` calculation is hardcoded to 10, which is a nice round number, and within the range of the `DiscountMap` (11).\r\n\r\nFixes #242'"
328663134,287,"b'Fix a DllImport issue for frameworks that do not add the "".dll"" suffix automatically'","b'In some cases, the "".dll"" suffix is not added, causing the DllImportAttribute to not find the dll on Linux machines.\r\n'"
328636397,286,b'disable ols',"b""Address #234  #241 \r\nSince we currently can't have way to use MKL library I disable entry point for OLS, so you can't add it for experiment, but code still in place."""
328593083,284,b'add append function to pipeline',b'address #7 '
328335805,280,b'Fix SupportedMetric.ByName() method',"b'This is a fix for Issue #279, where the PipelineInference/AutoInference.cs/SupportedMetric.ByName() no longer functions since changes were made to metric names. This is a simple issue with a simple fix (using the values of the SupportedMetrics names rather than the name of the fields).'"
328281251,278,b'add missing subcomponents to sweepers',b'another step to sync files between repo\r\n\r\n'
328278419,277,b'Random seed and concurrency for tests',"b'#9,#135, #249  related '"
328248008,276,b'Pulling metric names directly from evaluators',"b'This PR changes PipelinwSweeperSupportedMetrics to pull the metric names directly from evaluators, rather than defining them there. This will help reduce duplication and avoid error when/if metric names are changed in the code base. This PR will resolve issue #272 .\r\n\r\nAlso includes some reformatting of InputBuilder.cs courtesy of ctrl+k+d.'"
328231809,275,b'Preparation for syncing sources with internal repo',b'I need to make class partial to define constructor in separate file for other un-introduced sweepers.\r\n+ few constructors which we use in internal code.\r\n\r\n'
328043427,273,b'disable test that fails intermittently.',b''
327913504,271,b'Code cleanup',b'Just trying to please some old grumpy robot.\r\n\r\n'
327889232,270,b'RocketEngine fix for selecting top learners',"b'Fixes #262, changing the way the top K learners are selected. Now uses a LINQ statement for streamlined code. \r\n\r\nAlso adds the full namespace path to the Newtonsoft.Json.Formatting object, to avoid confusion with an object that exists in the Microsoft.ML namespace.\r\n\r\n'"
327870262,269,b'Bump master to v0.3',"b""Now that we've branched for v0.2, bump the master branch to start building v0.3 assets.\r\n"""
327870018,268,b'Keeping data loader in the pipeline while saving model.',b'This PR fixes issue #216.\r\n\r\n\r\n\r\n'
327815769,266,b'Remove references to ILAsmVersion.txt from build script',b'As per comment: https://github.com/dotnet/machinelearning/pull/247#discussion_r191779972'
327621818,264,b'Remove taxi-fare datasets',b''
327471526,263,b'Move ZBaselines => test/BaselineOutput  and Samples/UCI => test/data',"b""fixed #4 \r\n\r\nMove ZBaseline to test/BaselineOutput\r\nMove Samples/UCI to test/data\r\n\r\nFix the relevant path's in the unit tests.\r\n\r\n"""
327404423,260,b'Cleanup SentimentPredictionTests',b'make it more readable\r\n\r\n\r\n'
327088293,255,b'Enables FastTreeBinaryClassificationCategoricalSplitTest and  BinaryClassifierTesterThresholdingTest',"b'Test Being Enabled - BinaryClassifierTesterThresholdingTest, FastTreeBinaryClassificationCategoricalSplitTest\r\n\r\n\r\n\r\nZbaselines used by BinaryClassifierTesterThresholdingTest are already present. The slight difference in numbers is due to change in underlying framework\r\n\r\n\r\n\r\n**FastTreeBinaryClassificationCategoricalSplitTest**\r\n\r\nLearners Used :-  FastTreeClassfier, FastTreeWithCategoricalClassfier, FastTreeClassfierDisk, FastTreeWithCategoricalClassfierDisk\r\n\r\nDatasets Used:-  adultOnlyCat, adult\r\n\r\nFiles BreakDown For FastTreeBinaryClassificationCategoricalSplitTest  :- 40 release files , 40 debug files\r\nEach Learner needs 10 files (5 For each datasets) The 5 files are *.txt, .out.txt, .rp.txt, *.ini, summary.txt\r\n\r\nNote :- Release files are exactly same as Debug files\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs'"
327081305,253,b'LinearClassifierTest And PAVCalibratorPerceptronTest being Enabled',"b'Test Being Enabled -  LinearClassifierTest, PAV Calibrator\r\nModels Used in this test:-  binarySdca, binarySdcaL1, binarySdcaSmoothedHinge, binarySgd, binarySgdHinge\r\n\r\nFiles BreakDown :- 30 release files , 30 debug files (Linear Classifier Test),\r\n6 Release Files 6 Debug files (Average Perceptron Pav Calibrator test)\r\n\r\nEach Predictors needs 6 files i.e .txt, rp.txt and out.txt. These files are generated in 2 modes i.e TrainTest and CV. and we match all 6 files.\r\n\r\nNote ;- Debug and Release Files are same \r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs'"
327061451,252,b'Remove Lotus references.',b'fixes #19 '
326898460,248,b'Export to ONNX and cross-platform command-line tool to script ML.NET training and inference',b'fixes #108 \r\nfixes #125  \r\n\r\n'
326820234,247,b'Fixes build error when path contains space on Linux',"b'Fixes #191 (for Linux)\r\n\r\nSimilar to the problem on Windows, the paths used in the build scripts needed proper quoting.\r\n'"
326381194,240,"b'Change ""Documentation"" folder to ""docs""'",b'Add small fix in Microsof.ML.sln\r\nrename Documentation to docs\r\n'
326322567,239,b'Scores to Label mapping',b'fixes #158 \r\n'
326259568,238,b'Update samples',b''
326228579,236,b'introduce IUnsupervisedLearningWithWeights',b'address #225 '
326041724,233,b'Enables Calibrators Tests for Linear Svm',b'Related to #78 \r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs\r\n\r\n'
326036930,232,b'Enables NoCalibratorLinearSvmTest',b'Related to #78\r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs'
326029166,231,b'Enables RandomCalibratorPerceptronTest',b'Related to https://github.com/dotnet/machinelearning/pull/78 \r\nRelated to https://github.com/dotnet/machinelearning/pull/229\r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs \r\n'
326025737,230,b'Enables PAVCalibratorPerceptronTest',b'Related to https://github.com/dotnet/machinelearning/pull/78 \r\nRelated to https://github.com/dotnet/machinelearning/pull/229\r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\nReview From https://github.com/dotnet/machinelearning/commit/f7587de84da10eb11bbe00c2321dab4b0eb9f954 as first three commits are already in other PR\r\n\r\nMerge After #229 \r\n\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs \r\n\r\n'
326022135,229,b'Enabled DefaultCalibratorPerceptronTest',b'Related to https://github.com/dotnet/machinelearning/pull/78 \r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs '
326011438,228,b'Enables FastTreeHighMinDocsTest',b'Related to https://github.com/dotnet/machinelearning/pull/78 \r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs '
326002861,227,b'Enabling FastTreeBinaryClassificationNoOpGroupIdTest',b'Related to https://github.com/dotnet/machinelearning/pull/78 \r\n\r\nTest is enabled and corresponding Zbaseline files are added\r\n\r\n\r\ncc @shauheen @Ivanidzo4ka @eerhardt @danmosemsft @codemzs '
325952109,224,b'Dedicated column attributes added to input type fields',b'This PR addresses the issue #127. Also added relevant tests to cover the change.\r\n\r\nThe following column attributes were added.\r\n\r\n- NameColumnAttribute\r\n\r\n- GroupColumnAttribute\r\n\r\n- WeightColumnAttribute\r\n\r\n- FeaturesColumnAttribute\r\n\r\n- LabelColumnAttribute\r\n'
325910965,222,b'Add examples for clustering',b'Address #205 '
325879136,221,b'Remove label requirement for PCA anomaly detector entry point.',b'Fixes #220 . PCA trainer should not require a label column.'
325874167,219,b'Prevent annoying error in VSmac',"b'Work around https://github.com/mono/monodevelop/issues/3859, which causes an annoying popup when opening certain SDK-style projects that lack a `TargetFramework` in VSmac.\r\n\r\n'"
325768733,213,"b""CV macro with stratification column doesn't work""","b""The stratification column is being hashed to too many hash bits, and the RangeFilter that does the stratified split can't do the split. We reduce number of hash bits in stratification column so that the RangeFilter can split the data.\r\nFixes #182 ."""
325615462,212,b'Cross Validation and TrainTest',b'Introduces Cross Validation and Train-Test evaluators. and fixes #6 fixes #251  '
325488109,207,b'Combine the fold metrics into one data view in CV macro.',b'The CV macro currently outputs arrays of data views for the different kinds of metrics. This change\r\nadds an entry point at the end of CV macro that combines them into one data view for each metric kind.\r\nCloses #209 .'
325149503,198,b'Added samples: GitHubLabeler and GettingStarted',b'- Iris sample\r\n- Sentiment Analysis sample\r\n- TaxiFare sample\r\n- GitHub issues classification sample'
325107708,197,"b""Don't create parallel cursor if we have only one element in dataview""",b'related to #179 \r\n'
325046386,196,b'Fixes build errors on Windows when project path contains spaces',b'Fixes #191 \r\n\r\nThe problem seemed to be that `%~dp0` was used in the batch scripts without proper quoting.\r\n'
324993025,193,b'Update Fork',"b""This pull request was accidently created. I have closed it. Don't know if there is a way to delete it.\r\n\r\n"""
324566864,190,b'WIP Test',b'fixes #189 \r\n\r\n'
324494752,187,b'Compile CpuMathNative and FastTreeNative with charset=utf-8 on Windows',"b""Fix issue #186. Cmake default settings for the charset is MultiByte, Unicode is recommended on Windows.\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n\r\n"""
324231396,185,b'GetSummaryDataView() implementation for Pca and Linear Predictors',"b'GetSummaryDataView() implementation for Pca and Linear Predictors.\r\nUnit tests are coming, this are just initial changes for review\r\nissue #167 '"
324138517,183,b'handle boolean type in construction utils.',b'Address #156 \r\n'
323830465,178,b'Handle case where there are no input transforms',"b'Pipeline with no data transforms will throw an exception on the line below, as `input.TransformModels` has length zero.\r\n'"
323823930,177,b'Fixed RandomUtils.NextFloat() extension methods',"b'Fixing #166 \r\n\r\nRemoved two NextFloat() extension methods from RandomUtils and renamed NextSingle() to NextFloat()\r\nCurrently, NextFloat() is used everywhere instead of NextSingle().\r\n\r\nActually, for some implementation NextFloat() actually calls NextSingle() internally. Let me know if NextSingle() needs to be preserved.\r\n'"
323785630,176,b'fIx NextSigned method',b'Address #169 issue'
323759658,173,b'Migration of first `IDataView` docs',"b'Migration of some existing internal documentation, rephrased in some places to be more appropriate in context (hopefully successfully). Related to #160, though this PR would be just part of addressing the issue of moving over internal docs.'"
323743571,172,"b""no need to add combiner if you don't have transforms.""",b'Address #171 issue\r\n\r\n'
323705206,170,b'switch housing dataset to wine',b'This commit replaces housing dataset to wine dataset which we download during build from external source\r\n\r\n'
323413247,165,b'Support NuGet packages.config',"b""Copy our native assemblies using MSBuild when a consumer is using NuGet packages.config, since NuGet doesn't do this automatically.\r\n\r\nAlso, add an error when a consumer isn't targeting x64 to tell them ML.NET only supports x64.\r\n\r\nFix #93\r\n\r\n\r\n"""
323039864,155,b'Publishing nuget packages to myget feed.',b'- Also - set the symbols expiration days default based on feedback from the .NET core-eng team.\r\n  - See https://github.com/dotnet/core-eng/issues/2951 and https://github.com/dotnet/core-eng/issues/3382\r\n\r\nFixes #11'
323020656,154,b'Prevent learning pipeline from adding null transform model to the pipeline',b'fixes #153 '
322966024,152,b'Adding support for training metrics in PipelineSweeperMacro + new graph variable outputs',"b'Adding support for training metrics in PipelineSweeperMacro and needed support files. Also includes new output information in PipelineSweeperMacro output graph to make consumption of returned pipelines easier. Addresses issues #148,  #150, and #151.'"
322932510,148,b'AutoML graph output changes and training metrics exposure',"b'Adds training metrics to TrainTest macro, and exposes additonal variables on the output of PipelineSweeperMacro to allow easy use of sweep result graphs.\r\n\r\n'"
322891485,147,b'Remove special case for Logistic Regression in MacroUtils.cs',"b'We had a special case for LR in MacroUtils since its entry point name didn\'t match the pattern of the other classifiers (of ending with either ""Classifier"" or ""BinaryClassifier""). Now that this is fixed, we can remove this special case.\r\n'"
322880516,146,b'Fix build break',"b""The previous 2 changes conflicted.  Resovling the break that happened between them.\r\n\r\nI'll merge once green to get the build unblocked again.\r\n\r\n/cc @TomFinley @glebuk @shauheen """
322877951,145,b'Add Parquet symbols nuget package.',b'Add symbols package for ML.Parquet package.\r\nPut common NuGet package logic in props file.\r\n\r\nFix #144\r\n'
322722354,142,b'Code generate TextLoader API and enhance it with convenience API.',"b""*Code generate support for IDataLoader \r\n*Make TextLoader API code generated so that it's at functional parity with the text loader in the ML.Net infrastructure.\r\n*Move TextLoader API under Microsoft.ML.Data namespace\r\n*Add convenience TextLoader API.\r\n*Add error checking for invalid loader arguments such as ordinal, column names.\r\n*Update baselines.\r\n*Update samples with new loader API and backward compatibility with old loader API.\r\n\r\n[*ADDRESS COMMENTS FROM PR# 38*](https://github.com/dotnet/machinelearning/pull/38)\r\nfixes #15 """
322618701,139,b'Fix entry point name for Logistic Regression (LogisticRegressor is misleading)',"b""This PR fixes #114. \r\n\r\nWe currently have LogisticRegressor and BinaryLogisticRegressor entry points, which are misleading (make logistic regression seem like it is used for regression) and don't match the other learners. These are renamed to LogisticRegressionClassifier and LogisticRegressionBinaryClassifier respectively.\r\n\r\nI have not tried modifying entry points before, so please let me know if something is missing. Here is what I did:\r\n\r\n1. Update the entry point names in the learners (binary and multiclass LR)\r\n2. Regenerate CSharpAPI.cs\r\n3. Update TestCSharpAPI.cs and TestEntryPoints.cs\r\n4. Update core_ep-list.tsv and core_manifest.json to reflect the new names\r\n5. Update remaining references to the old names\r\n\r\nThis is a breaking change to the Logistic Regression C# APIs. \r\n\r\n"""
322464504,136,"b'just a mere concept for seed, threads and logging'","b'this is just a concept of how we can not expose IHostEnviroment to pipeline, and still have seed, concurrency and logging available.\r\n#135 \r\n'"
322411057,134,"b""Removed '#' from the header row in Iris.txt.""","b""Fixing a typo in data file Iris.txt where there is a '#' in front of the header row. '#' causes the row to be ignored by TextLoader.\r\n\r\nAlso, updated the relevant test.\r\n\r\nI don't think it was deliberate. Please update me if it was?\r\n\r\n"""
322402441,133,b'Replaced calls to DateTime.Now with DateTime.UtcNow to be locale agnostic',"b'The codebase now uses DateTime.UtcNow, instead of DateTime.Now, to be locale agnostic.\r\nFixes #110 '"
322373196,131,"b'Fix a bug in Tree leaf featurizer entry point, and add a test for it.'","b""The tree leaf featurizer entry point doesn't pass the correct data to the scorer it creates - it should pass the transformed data, but instead it passes the input data.\r\nFixes #130 """
322304237,129,b'Fixes #128',"b""Make a 'not supported field type' exception more readable, so the developer could figure out why he can't load the data. This should make learning curve smoother for an incoming developer\r\n\r\n"""
322129196,122,b'FastTree: Instantiate feature map for disk transpose and make Generalized Additive Models predictor resilient when feature map is not available.',b'\r\n\r\n'
322126666,121,"b'Fixed exception: ""InvalidOperationException: Source column \'Label\' is required but not found.""'",b'This PR fixes issue #117 \r\n\r\nAdded a test to cover the issue. Please see issue #117 for more details.\r\n\r\n'
322100370,120,b'Added Block Size Checks for ParquetLoader',"b'Fixes #118\r\nOriginally [PR#12](https://github.com/dotnet/machinelearning/pull/12)\r\n\r\nIn order to enable shuffling for both the {rows in a block} and {blocks}, both sizes have to (1) be smaller than int.MaxValue, and (2) fit in an int array, making the upper limit for both {rows in a block} and {number of blocks} around 300M. If either value throws an exception when assigned, the library will suggest adjusting the block size as a potential fix.\r\n\r\nAlso changed the default block size to 1M to minimize the chance of OutOfMemory and Overflow exceptions happening in the first place, and addressed comments in original PR. \r\n\r\n'"
322044575,115,b'Update NuGet packages to fill out all metadata.',"b'Also, a minor build change (move property ordering) to fix SourceLink with our packages.\r\n\r\nFix #43\r\nFix #103'"
322035883,113,b'Update MacroUtils to map trainer kinds to the correct suffix of trainer entry point names',"b'Closes #112 .\r\n\r\nEntry points for binary classifiers end with ""BinaryClassifier"", for regressors end with ""Regressor"", etc. Update the mapping in MacroUtils to enable finding the entry points of trainers for a specific task.'"
321984918,111,b'Decimal separator different in different windows language pack',"b'Fixes https://github.com/dotnet/machinelearning/issues/74\r\n\r\nThe decimal separators are different for different language packs eg "","" is a decimal separator for spanish. the output written to these files will include comma instead of decimal as in our zbaseline files.\r\nThe problem could be avoided by improving our number regular expression to use decimal separator dynamically which will allow us to pick these values as numbers and match them as numbers rather than strings\r\n\r\n@veikkoeeva can you please test this pr on your machine. I currently dont have access to the non-english windows\r\n\r\ncc @eerhardt @danmosemsft @codemzs \r\n'"
321918783,109,b'Fixes data invariant format problems',b'The tests do not pass on machines that have different formatting than English language. The error happens since the results are written in different than expected format.\r\n\r\nFixes #74\r\n'
321754643,106,b'CollectionDataSource (train on top of memory collection instead of loading data from file)',b'First iteration which allows user to create IDataview on top of IList or Enumerable and infrastructure to add it in pipeline.\r\naddress #10 issue\r\n\r\n'
321746809,105,b'Issue #104: Update the build tools to 2.1.200',b'Issues:\r\n  This closes #104'
321671285,102,"b""Update code generator to handle generic types and types with multiple '+' signs in them.""",b'The C# code generator needs to be able to handle types that are nested inside generic classes. It should also handle types that are nested in nested classes.'
321653766,99,b'publish symbols enabled',b'We disabled the publishing of the symbols because we didnt wanted to upload them before the release.\r\nThis PR changes the property of uploading symbols from false to true.\r\nI started a build in the build definations where we can see the log output of publishing the symbols.\r\n\r\ncc @eerhardt @safern '
321603903,95,b'Bump version number to 0.2.',"b""We've shipped 0.1.0, we should start producing higher versions now.\r\n\r\nFix #85\r\n\r\n"""
321577786,94,b'Fix reversed hyperparameters in Scenarios Tests.',b'Closes #25.\r\n'
321461800,90,b'Expand on NuGet installation',b'only readme changes\r\n'
321456642,87,"b'Change ""Documentation"" folder to ""docs""'","b'In order to add consistency would like to change ""Documentation"" to ""Docs"" and fix all links in .MD files and .sln. '"
321352517,84,b'Minor comment fixes.',"b""Minor comment fixes (typos and references non-existent files) in the Native code.  \r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
321211492,79,b'Fixes link to sentiment analysis example.',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n"""
321206076,78,b'Enabling Tests that consume Zbaseline files.',"b'.txt, -rp.txt and -out.txt are copied from the TLC project and values are edited in their last decimal places to match the results.\r\n\r\n.ini files are copied from the output folder as i was not able to find them in TLC project.\r\n\r\nSome Datasets are also added to the repo which were required by these tests.\r\n\r\nThe remaining tests are not enabled because they fail due to some other error and not because zbaselines or datasets are not present.\r\n\r\nUpdate :- \r\nThe repo already contains zbaselines for the test being enabled\r\n\r\n\r\ncc @eerhardt @danmosemsft @codemzs '"
321154191,76,b'Fix broken link to sentiment prediction scenario source code.',"b""Current link points to an unexisting file (Scenario3_SentimentPrediction.cs), so I used the most probable sample file. \r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [o] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
321151371,75,b'fix filename for sentiment analysis',"b""We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
321069279,71,b'Fix link to example file in readme.md',b'This fixes an issue introduced by PR#52\r\nUpdates the path to a sentiment sample file in README.MD'
321028675,65,b'TextLoader exception message missing parameter name #33',"b'Corrects the TextLoader constructor to pass the correct parameter name, and include it in the error message.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/33'"
320992539,62,b'Added Microsoft.ML.Benchmarks Project',"b'Added first demo benchmark. We should update it later to something more representative. \r\nThis is the first step in resolving #20\r\n\r\nTo run the benchmark:\r\n1. Build Release\r\n2. Open command window in tests\\Microsoft.ML.Benchmarks folder\r\n    - if you want to measure hardware counters (not yet enabled), open admin console.\r\n3. dotnet run -c Release Microsoft.ML.Benchmarks.csproj\r\n4. Select benchmark to run from the menu\r\n\r\nNote: currently, LearningPipeline logs to the windows console by default, which impacts the performance run. You can minimize the overhead by minimizing the console window while it runs the test.\r\n\r\nHere is the output from the run:\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.16299.431 (1709/FallCreatorsUpdate/Redstone3)\r\nIntel Core i7-6700 CPU 3.40GHz (Skylake), 1 CPU, 8 logical and 4 physical cores\r\nFrequency=3328124 Hz, Resolution=300.4696 ns, Timer=TSC\r\n.NET Core SDK=2.1.300-rc1-008662\r\n  [Host] : .NET Core 2.0.7 (CoreCLR 4.6.26328.01, CoreFX 4.6.26403.03), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain  LaunchCount=1  TargetCount=3  \r\nWarmupCount=3  \r\n\r\n```\r\n|              Method |              Mean |             Error |            StdDev | AccuracyMacro |     Gen 0 |    Gen 1 |   Gen 2 |  Allocated |\r\n|-------------------- |------------------:|------------------:|------------------:|--------------:|----------:|---------:|--------:|-----------:|\r\n|           TrainIris | 215,636,477.31 ns | 39,847,380.894 ns | 2,251,450.9146 ns |          0.98 | 8000.0000 | 250.0000 | 62.5000 | 11797870 B |\r\n|         PredictIris |   1,027,876.15 ns |    393,249.160 ns |    22,219.3068 ns |          0.98 |   27.3438 |  13.6719 |  1.9531 |    90408 B |\r\n| PredictIrisBatchOf1 |          12.53 ns |          2.905 ns |         0.1641 ns |          0.98 |    0.0171 |        - |       - |       72 B |\r\n| PredictIrisBatchOf2 |          12.83 ns |          4.585 ns |         0.2590 ns |          0.98 |    0.0171 |        - |       - |       72 B |\r\n| PredictIrisBatchOf5 |          14.04 ns |          2.643 ns |         0.1493 ns |          0.98 |    0.0171 |        - |       - |       72 B |\r\n'"
320989158,61,b'Add PartitionedFileLoader',b'Introduce a new IDataLoader to handle partitioned file sets.\r\n\r\nFixes #60\r\n\r\nNote: All tests pass but the CSharpApiGenerator is putting an improper namespace on the Struct fields. Sending out PR to review the actual code since this CSharpApi failure will need to be addressed separately.\r\n\r\n'
320972312,59,b'[Src] Fixed typo: files in Microsoft.ML namespace',"b""- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
320968837,58,b'Correcting docs for building in Linux',b'This PR updates the unix instructions for building this repo on Linux.\r\n\r\nAs prerequisite we need to use clang-3.9 in order to build machinelearning repo on Linux.\r\n\r\ncc: @eerhardt @danmosemsft @safern \r\nRelated to: #57'
320963752,55,b'[Docs] Fixed typo: ROADMAP.md',"b""- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n"""
320941886,54,b'Update license to match CELA guidance',b'addressed CELA review comments'
320924161,52,b'Refactored scenario tests (issue #32)',"b'Fixing issue #32 in this PR.\r\n\r\nRenamed top5Scenario class to ScenariosTests.\r\nRemoved ""scenario_"" from file names.\r\n\r\n'"
320921392,50,b'Comments added to LearningPipeline class to make Intellisense more helpful.',b'Fixing issue #31 in this PR.'
320901628,48,b'Add Build Status to README',b'Adding build status badges and links to the README.\r\n\r\n'
320876009,46,b'Add push trigger to netci.groovy',b'This trigger will run on every commit and will allow a build status link to add to our README.'
320860059,45,b'Update dataset',b'This clarifies the license for the datasets and also adds the taxi fare dataset.\r\n\r\n/cc @aditidugar '
320858796,44,b'Issue #41: Fix the link to the Gitter chat in README.md',b'This changes the link to gitter from pointing to `https://gitter.im/dotnet/corefx` to point to `https://gitter.im/dotnet/mlnet`.\r\n\r\nIssues:\r\n  This closes #41'
320857561,42,b'Adjust gitter link to go to new mlnet room',b''
320675677,40,b'Update README.md',b'Enlarge readme including prerequisites.\r\n\r\nHappy to change anything.\r\n\r\n'
320622811,38,b'Code generate TextLoader API and make it backward compatible with existing TextLoader API.',"b""*Code generate support for IDataLoader\r\n*Make TextLoader API code generated so that it's at functional parity with the text loader in the ML.Net infrastructure.\r\n*Move TextLoader API under Microsoft.ML.Data namespace\r\n*Make TextLoader API backward compatible. \r\n*Add error checking for invalid loader arguments such as ordinal, column names.\r\n*Update baselines.\r\n*Update samples with new loader API and backward compatibility with old loader API."""
320619234,37,b'Add release notes for ML.NET 0.1',b'This adds the release notes for ML.NET 0.1.\r\n\r\nThis fixes #36 .'
320540411,35,b'Update contribution guide and issue/PR templates',b'This is a first draft of the issue/PR template and updates to contribution guide.\r\n'
320462419,30,b'Add ML.NET Roadmap',b'Resolves issue #27\r\nChanges\r\n* Adds roadmap\r\n* Adds folders for markdown docs\r\n* fixes a bug in readme to point to correct license file'
320461668,29,b'Refectored scenario tests (issue #32)',b'Fixing issue #32 in this PR.'
320455917,17,b'switch housing dataset to wine',b'This commit replaces housing dataset to wine dataset which we download during build from external source'
320452408,13,b'Comments added to LearningPipeline class to make Intellisense more helpful.',b'Fixing issue #31 in this PR.'
320445912,12,b'Added block size exception',"b'Added exceptions in two known points of failure as detailed below:\r\n1. ParquetLoader will fail on OutOfMemoryException when trying to create an enumeration sequence array that is too big. \r\n2. If the numbers of rows in a block or number of blocks is greater than int.MaxValue, Overflow exception will be thrown. Ideally, we would use longs to keep track instead, but this is restricted due to point 1.\r\n\r\nAlso fixed a cast error.\r\n'"
320376829,2,b'Fixed the syntax of cited example.',b''
320346061,1,b'Get a working build',b'* Set missing executable bits on `.sh` files.\r\n* Skip tests that depend on a a dataset that cannot currently be included in the repo.'
