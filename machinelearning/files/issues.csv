issue_id,issue_no,title,body
750996581,5511,"b'Unable to split the file provided into multiple, consistent columns. (.tsv)'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1.402\r\n\r\n### Issue\r\n\r\n- **What did you do?** I was trying to use ML.NET to create a support desk application.\r\n- **What happened?** Once I pressed ""start training"" this error came:\r\n`   Unable to split the file provided into multiple, consistent columns.\r\nat Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns, Boolean hasHeader)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.InferColumns(MLContext context, AutoMLServiceParamater config, ColumnInformation columnInformation)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 112`\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\nLogs:\r\nat Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns, Boolean hasHeader)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.InferColumns(MLContext context, AutoMLServiceParamater config, ColumnInformation columnInformation)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 112\r\nTSV file:\r\nID\tQuestion Category\r\n1\tMy printer isn\'t working.\tPrinter\r\n1\tPrinter\tPrinter\r\n2\tI can\'t turn on my computer.\tComputer\r\n3\tI would like to book a chromebook.\tChromebooks\r\n1\tMy printer won\'t print.\tPrinter\r\n1\tMy printer isn\'t working.\tPrinter\r\n1\tI can\'t print\tPrinter\r\n2\tMy computer isn\'t working\tComputer\r\n2\tMy computer isn\'t turning on\tComputer\r\n2\tComputer\tComputer\r\n2\tMy computer is malfunctioning.\tComputer\r\n3\tChromebooks\tChromebooks\r\n3\tI would like a chromebook.\tChromebooks\r\n3\tHow can I book a chromebook?\tChromebooks\r\n3\tMy chromebook isn\'t charging.\r\n\r\n(before you ask, the tabs are formatted correctly in VS)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.'"
749499104,5508,b'Failed to deploy ML image classification model with aspnetcore webapi:',"b'### System information\r\n\r\n- **OS version/distro**: WINDOWS SERVER 2019 \r\n- **.NET Version (eg., dotnet --info)**:  dotnetcore 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have trained image classification using ML.Net and integrated model to aspnetcore webapi.\r\n- **What happened?**\r\nWebApi worked fine on my local development machine. But it failed to work when i deploy webapi to the server IIS.\r\nwindows showed error:\r\n**Windows cannot access the file  for one of the following reasons: there is a problem with the network connection, the disk that the file is stored on, or the storage drivers installed on this computer; or the disk is missing. Windows closed the program IIS Worker Process because of this error.\r\n\r\nProgram: IIS Worker Process\r\nFile: \r\n\r\nThe error value is listed in the Additional Data section.\r\nUser Action\r\n1. Open the file again. This situation might be a temporary problem that corrects itself when the program runs again.\r\n2. If the file still cannot be accessed and\r\n\t- It is on the network, your network administrator should verify that there is not a problem with the network and that the server can be contacted.\r\n\t- It is on a removable disk, for example, a floppy disk or CD-ROM, verify that the disk is fully inserted into the computer.\r\n3. Check and repair the file system by running CHKDSK. To run CHKDSK, click Start, click Run, type CMD, and then click OK. At the command prompt, type CHKDSK /F, and then press ENTER.\r\n4. If the problem persists, restore the file from a backup copy.\r\n5. Determine whether other files on the same disk can be opened. If not, the disk might be damaged. If it is a hard disk, contact your administrator or computer hardware vendor for further assistance.\r\n\r\nAdditional Data\r\nError value: 00000000\r\nDisk type: 0**\r\n**Faulting application name: w3wp.exe, version: 10.0.17763.1, time stamp: 0xcfdb13d8\r\nFaulting module name: tensorflow.DLL, version: 0.0.0.0, time stamp: 0x5f77815a\r\nException code: 0xc000001d\r\nFault offset: 0x00000000003aec32\r\nFaulting process id: 0x3410\r\nFaulting application start time: 0x01d6c230bdc0bf5c\r\nFaulting application path: c:\\windows\\system32\\inetsrv\\w3wp.exe\r\nFaulting module path: C:\\inetpub\\wwwroot\\runtimes\\win-x64\\native\\tensorflow.DLL\r\nReport Id: 003ff975-a029-4989-96e6-cca406a8b89d\r\nFaulting package full name: \r\nFaulting package-relative application ID: **\r\n- **What did you expect?**\r\nWebApi and ML.net should have same behavior on local machine and remote server.\r\n\r\n### Source code / logs\r\n\r\n[proj.txt](https://github.com/dotnet/machinelearning/files/5588449/proj.txt)\r\n\r\n[file1.txt](https://github.com/dotnet/machinelearning/files/5588455/file1.txt)\r\n[startup.txt](https://github.com/dotnet/machinelearning/files/5588458/startup.txt)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
748030663,5505,b'Import tensorflow model from keras generated one',"b'### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**: 5 \r\n\r\n### Issue\r\n\r\n- **What did you do?** Tried to create in keras a simple NN(7 inputs, 10 outputs), freeze the model and import it in ML.Net\r\n- **What happened?** Exception\r\n- **What did you expect?** To be successfully imported \r\n\r\n### Source code / logs\r\n\r\nHi all,\r\nI created a simple neural net using keras in python, and wanted to export it to ML.Net. First try was to save it in ""tf"" format, but as i saw, ML.Net needs a frozen model. So i tried to freeze it using this approach: [https://hellobird.tistory.com/399](https://hellobird.tistory.com/399), i have generated the .pb file, but when i try to **mlContext.Model.LoadTensorFlowModel(pathToModel);** an ** Tensorflow.TensorflowException: \'Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\' exception is thrown \r\n**\r\n\r\n\r\nThe python code is this attached \r\n\r\n[test.txt](https://github.com/dotnet/machinelearning/files/5577780/test.txt)\r\nand the pb file(I changed it\'s extension so i could upload):\r\n[model.txt](https://github.com/dotnet/machinelearning/files/5577783/model.txt)\r\n\r\n\r\n\r\nI saved the pb, i imported it to VS and the c# code:\r\n\r\n` \r\n  \r\n             var mlContext = new MLContext();\r\n            \r\n            var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(pathToModel);\r\n            \r\n            var pipeline = mlContext.Transforms.Concatenate(""Features"",\r\n                    new[] { ""Bathrooms"", ""SqftLiving"", ""SqftLot"", ""Floors"", ""YearBuild"", ""YearRenovated"", ""Price"" })\r\n                .Append(tensorFlowModel.ScoreTensorFlowModel(""Prediction/Softmax"", ""Features""))\r\n                .Append(mlContext.Transforms.CopyColumns(""Scores"", ""Prediction/Softmax""));\r\n\r\n\r\n            var dataView = mlContext.Data.LoadFromEnumerable(Enumerable.Empty<House>(), tensorFlowModel.GetModelSchema());\r\n            var transformer = pipeline.Fit(dataView);`\r\n\r\nBut on the second line i got that error.\r\n\r\nIs there any known issue about this or any sample code that shows how to export a model from python in ML.Net that works?\r\n\r\nThanks ^_^ \r\n\r\n\r\nL.E: Found the problem. It seems it needs the whole path(including the file name, not only the folder)'"
747997199,5504,b'Is it possible to do continuous/incremental learning in ML.net? [question]',"b'I was unsure if I should ask here or on Stack Overflow.  \r\n(SO have less than 400 questions with the `ml.net`-tag, so I doubt there is a critical mass of people who bother to to follow the tag)\r\n\r\n**TL;DR:**  \r\n> Is it possible to do small incremental changes to a trained model?\r\n\r\n**Scenario**  \r\nWhere I work, we have an AI/ML/DL product called Semine, which does classification of invoices for accounting purposes, e.g. detecting what ""accounting code"" a specific invoice line is. We had a brilliant Ph.D. in statistics consult with us and write an optimized algorithm for our needs. I\'d love to describe it in details but I\'m not contractually allowed to divulge trade secrets, but in general: When an invoice is ""posted"", the relevant values are added to the pile of data which is used by the algorithm. Then there is an ""incremental learning"" on that action, and not a complete re-train of the entire model; Having to retrain an entire model a few thousand times per day would not be financially responsible.\r\n\r\n**Question**  \r\nIs there a way to do this type on learning in ML.net? Just a tweak, based on a small change to the underlying data? `#AskingForAFriend` \xf0\x9f\x98\x86 \r\n\r\n**My efforts**  \r\nHaving googled, (even with Bing \xf0\x9f\x98\x86 ), it\'s evident that there are a lot of questions about this, but no clear answers or examples. So a definitive ""yes/no"" on the question of if it is possible, and if it will be possible\r\n\r\nThank you for your time!'"
747121141,5501,b'Absorb Accord.net as a whole or in parts',"b'[Accord.net](https://github.com/accord-net/framework), (An ML library for .net), has been archived, and will no longer be maintained. The maintainer has done so partly because of ML.net deprecating Accord as a ML framework for .net. (and apparently also because of nasty researchers making fun of people using C# for Machine Learning)\r\n\r\nThe ML.net -team should absorb it, (fork it into dotnet, and move the components piece-by-piece into ML.net), because there are a lot of great stuff there that could really benefit ML.net\'s future, that now is just adrift, without new releases or active development.\r\n\r\nIt would be a shame for it all to go to ""waste"" or fall into obscurity'"
746095573,5498,"b'Survey: Repo contribution experience, Fall 2020'","b'We normally focus on how to improve the product, but we\xe2\x80\x99re also turning our focus to improving the open source project. Periodically we are running a survey to collect feedback on your experience working with our repos. We did one back in May, and as its been about 6 months, its about time for another. We\xe2\x80\x99ve created a survey to better understand your individual experience of participating and contributing in this project.\r\n\r\nWe would appreciate your feedback so we can work to address shortcomings and missed opportunities. If you don\xe2\x80\x99t supply contact details, then responses will be anonymous.\r\n\r\n[Survey](https://www.surveymonkey.com/r/92RLF7R?Source=dotnet/machinelearning)\r\n\r\nThank you for your time!'"
746035055,5497,b'Are ML .Net models deterministic?',"b'Some models are inherently stochastic, others are deterministic. Are ML .Net models deterministic? In other words, given the same input, will an ML .Net model always return the same output/prediction? If so, to how many decimal places is this prediction deterministic?'"
745686066,5495,"b""Unable to load DLL 'CpuMathNative': The specified module could not be found""","b""salam all\r\nI face this problem when I use Microsoft.ML to create clustering \r\nI hope to help me \r\nSystem.DllNotFoundException: 'Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)'\r\nthank you \r\n![image](https://user-images.githubusercontent.com/34779906/99539707-39c68e80-29b7-11eb-8e28-88fdf3eed323.png)\r\n"""
745080896,5491,b'Unable to detect anomaly in data that appears anomalous',"b'### System information\r\n\r\n- **OS version/distro**: \r\n- **.NET Version (eg., dotnet --info)**: \r\n![image](https://user-images.githubusercontent.com/69877427/99447299-0828c700-28d4-11eb-8663-c0f165631be9.png)\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempted to detect anomalies on time series data\r\n\r\n- **What happened?**\r\nNo anomalies were detected\r\n![image](https://user-images.githubusercontent.com/69877427/99441627-fee82c00-28cc-11eb-8b2c-069f0cca148e.png)\r\n![image](https://user-images.githubusercontent.com/69877427/99446948-edeee900-28d3-11eb-90f0-d177e1e02e4a.png)\r\n\r\n\r\n- **What did you expect?**\r\nAn anomaly on either the 1st or 2nd data point\r\n\r\n### Source code / logs\r\n[no_anomalies_detected_data.zip](https://github.com/dotnet/machinelearning/files/5556169/no_anomalies_detected_data.zip)\r\n\r\nSensitivity=100, SeasonalPeriodForAnomalyDetection=-1 (we set it to 0 when it is < 0), Threshold=0.1\r\n![image](https://user-images.githubusercontent.com/69877427/99440684-c431c400-28cb-11eb-90c5-dcc1d9dccb2f.png)\r\n\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
743345395,5490,b'AutoML: How to remove/ignore columns returned by InferColumns API',"b'### System information\r\n\r\n- Windows 10 Pro 10.0.19041\r\n- .NET 5.0 \r\n- Microsoft.ML.AutoML 0.17.2\r\n\r\n### Issue\r\n\r\n- I want to be able to inference columns loaded from a .csv file but then remove/ignore select columns from AutoML experiment.  My attempt to remove these columns in columnInformation does not appear to work as all columns loaded are used.\r\n- I don\'t necessarily want to remove the columns from the IDataView rather I just want to exclude them from the experiment.  How can this be accomplished?\r\n- In the attached exhibits I show part of the IDataView schema with the columns (3) I want to remove/ignore and the columnInformation properties after attempting to remove them.\r\n![IDataView Schema](https://user-images.githubusercontent.com/8396992/99196430-50bc7500-275a-11eb-8d0e-279fec1e4df5.png)\r\n![columnInformation properties](https://user-images.githubusercontent.com/8396992/99196431-53b76580-275a-11eb-9b16-d59fe836766c.png)\r\n\r\n### Source code / logs\r\n```\r\n    ...\r\n    MLContext mlContext = new MLContext();\r\n\r\n    // Infer columns in the dataset with AutoML\r\n    var columnInference = InferColumns(mlContext);\r\n\r\n    // Load data from files using inferred columns\r\n    LoadData(mlContext, columnInference);\r\n\r\n    // Run an AutoML experiment on the dataset\r\n    var experimentResult = RunAutoMLExperiment(mlContext, columnInference);\r\n    ...\r\n\r\n    private static void LoadData(MLContext mlContext, ColumnInferenceResults columnInference)\r\n    {\r\n        TextLoader textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n        TrainDataView = textLoader.Load(TrainDataPath);\r\n    }\r\n\r\n    private static ExperimentResult<BinaryClassificationMetrics> RunAutoMLExperiment(MLContext mlContext, ColumnInferenceResults columnInference)\r\n    {\r\n       // Customize column information returned by InferColumns API\r\n       ColumnInformation columnInformation = columnInference.ColumnInformation;\r\n       columnInformation.CategoricalColumnNames.Remove(""rUpDn"");\r\n       columnInformation.NumericColumnNames.Remove(""rDE_MaxProf"");\r\n       columnInformation.TextColumnNames.Remove(""rD_LKDateTime"");\r\n\r\n       // invoke after each model it produces and evaluates.\r\n       var progressHandler = new Progress<RunDetail<BinaryClassificationMetrics>>();\r\n\r\n       // Initialize a cancellation token source to stop the experiment.\r\n       var cts = new CancellationTokenSource();\r\n\r\n       // Create experiment settings\r\n       var experimentSettings = CreateExperimentSettings(mlContext, cts);\r\n\r\n       // Run AutoML regression experiment\r\n       var experiment = mlContext.Auto().CreateBinaryClassificationExperiment(experimentSettings);\r\n       ExperimentResult<BinaryClassificationMetrics> experimentResult = experiment.Execute(TrainDataView, columnInformation, null, progressHandler: progressHandler);\r\n\r\n       // Print top models found by AutoML\r\n       PrintTopModels(experimentResult);\r\n\r\n       return experimentResult;\r\n   }\r\n    private static BinaryExperimentSettings CreateExperimentSettings(MLContext mlContext, CancellationTokenSource cts)\r\n    {\r\n        var experimentSettings = new BinaryExperimentSettings();\r\n        experimentSettings.MaxExperimentTimeInSeconds = 3600;\r\n        experimentSettings.CancellationToken = cts.Token;\r\n\r\n        // Set the metric that AutoML will try to optimize over the course of the experiment.\r\n        //experimentSettings.OptimizingMetric = RegressionMetric.RootMeanSquaredError;\r\n        experimentSettings.OptimizingMetric = BinaryClassificationMetric.Accuracy;\r\n\r\n        // Set the cache directory to null.\r\n        // This will cause all models produced by AutoML to be kept in memory \r\n        // instead of written to disk after each run, as AutoML is training.\r\n         // (Please note: for an experiment on a large dataset, opting to keep all \r\n        // models trained by AutoML in memory could cause your system to run out \r\n        // of memory.)\r\n        experimentSettings.CacheDirectory = null;\r\n\r\n         // Clear trainers and add LightGbm\r\n         //experimentSettings.Trainers.Clear();\r\n         //experimentSettings.Trainers.Add(BinaryClassificationTrainer.LightGbm);\r\n\r\n         return experimentSettings;\r\n     }\r\n\r\n```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
743222117,5489,b'Could not load file from Consume Model even after changing to sdk-style',"b'**Versions**\r\nMicrosoft.ML - Version=""1.5.0-preview2"". \r\nVisual Studio 2019\r\nTarget Framework: Class Library ( .NET Framework 4.7)\r\n\r\n**Bug description**\r\n""Could not load file"" error thrown from ""ModelOperationsCatalog.Load()"".\r\n\r\n**Steps to Reproduce**\r\n1. Follow the steps here: https://dotnet.microsoft.com/learn/ml-dotnet/get-started-tutorial/create\r\n2. Include the auto generated ""MLModel.zip"" into the project file as an ""Embedded Resource"".\r\n3. Read the ""MLModel.zip"" into Stream and pass that in into the mlContext.Model.Load(theMLModelZipStream, null)""\r\n`string resourceName = ""IfcPluginML.Model.MLModel.zip"";`\r\n`Stream modelFile = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName)`\r\n`ITransformer mlModel = mlContext.Model.Load(modelFile , out var modelInputSchema);`\r\n4. Compile into .dll and run.\r\n5. Error is thrown.\r\n\r\n**Expected Experience**\r\nFile is read successfully.\r\n\r\n**Actual Experience**\r\nCould not read file:\r\n\r\n![image](https://user-images.githubusercontent.com/37243889/99022804-46ee1280-259e-11eb-8cec-e32c3663096d.png)\r\n\r\nI have checked that the \r\n`Stream modelFile = GetEmbeddedResourceStream(resourceName);  // returns ""System.IO.UnmanagedMemoryStream""`\r\nso it is definitely not null.\r\n\r\nPutting the full file path produces the same error too:\r\n`string modelPath = @""C:\\Users\\User\\AppData\\Local\\Temp\\MLVSTools\\IfcPluginML\\IfcPluginML.Model\\MLModel.zip"";`\r\n`ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);`\r\n\r\n**Additional Context**\r\nI have referenced this post: https://github.com/dotnet/machinelearning-modelbuilder/issues/274\r\nHowever, even after changing the target framework of ProjectNameML.Model.csproj to an sdk style:\r\n![image](https://user-images.githubusercontent.com/37243889/99023420-8ec16980-259f-11eb-8899-35699780ca2f.png)\r\nThe error persists.\r\n\r\nHow my software works:\r\n1. There is a main project (Class Library .NET Framework 4.7).\r\n2. The main project calls `ConsumeModel.Predict(input);`\r\n3. ConsumeModel throws the error.\r\n\r\n**It works when:**\r\n1. The auto generated Program.cs in ProjectNameML.ConsoleApp (.NET Core 3.1) is ran.\r\n2. Program.cs calls `ConsumeModel.Predict(input);`\r\n3. Runs perfectly.\r\n\r\nThanks for your help \xf0\x9f\x92\xaf \r\n'"
742568481,5487,b'Help to consume simple linear integration TensorFlow model needed',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.19041 64 Bit\r\n- **.NET Version (eg., dotnet --info)**: Version:   5.0.100\r\n\r\n### Issue\r\n  Please help me by providing the solution that I can solve this problem. \r\n- **What did you do?**\r\nI created a simple Python script in Jupyter Notebook for the data set consisting of 8 rows. Successfuly trained and evaluated the model and then exported it. The model can be loaded but I cannot configure the pipeline to make prediction. \r\n- **What happened?**\r\nNow I try to consume the model with ML.NET Console dotnet core 3.1 application.\r\n- **What did you expect?**\r\nCannot consume the model, because not able to create the proper pipeline. \r\nCannot access the properties in GetModelShema as in the microsoft tutorial, because they dont exist. (how can I define them in my model (""Features""m ""Prediction/Softmax"")) that they are labeled and recognized?\r\n\r\n### Source code / logs\r\n[project&jupyter_notebook.zip](https://github.com/dotnet/machinelearning/files/5537990/project.jupyter_notebook.zip)'"
742390574,5486,b'Load Tensorflow model from stream',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Enterprise 64 bits\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Question\r\n\r\nIs there a way to load a Tensorflow model from a memory stream instead of a filepath? Currently the only way I managed to load a TF model is by calling:\r\n`public static TensorFlowModel LoadTensorFlowModel(this ModelOperationsCatalog catalog, string modelLocation);`\r\n\r\nHowever, if I want to load a ML.NET trained model, I can do it by calling:\r\n`public ITransformer Load(string filePath, out DataViewSchema inputSchema);`\r\nor\r\n`public ITransformer Load(Stream stream, out DataViewSchema inputSchema);`\r\n\r\nI am looking for a method like the latter one but for TF models. Does anybody know if something like that is already implemented? How could I load a TF model without the need of having the .pb file in disk?\r\nWill such a method be implemented in a future release?\r\n\r\nThanks for your help,\r\nCarlos.\r\n\r\n\r\n'"
741839600,5484,b'Use custom Onnx model in place of Onnx model found on Object Detection sample',"b'I have a digit detection model in custom vision and it is detecting digit Very good at cloud https://www.customvision.ai/.\r\nAfter i export it local (onnx) and i checked with ml.net\r\nour accuracy decrease and it does not recognize object . in most images .\r\nnote : my objects are small , character size like ocr,\r\nplease help me.'"
740531627,5483,b'How to use neural network in ML.NET?',b'Is there any concept in ML.NET to imply the NN?\r\n\r\n\r\n'
738884655,5481,b'TimeSeries forecasting not work well ',"b'I use the following data format for time series forecasting.The data is on the half-hour dimension,and the forecasted column is `NextTimeCount`. \r\n\r\nUse data from the past 24 hours or more to predict the next hour data.\r\nNo matter how adjust the `windowSize` paramter, there is no good result.\r\n```\r\nYear,Time,RealCount,DropCount,TurnOnRate,ServiceRate,ProductRate,UsageRate,ShareRate,AHT,RealManCount,NextTimeCount,PreTimeCount,Month,Day,TotalCount,DayOfWeek\r\n2020,0,130,4,0.97,0.96,0.72,0.96,0.75,3.97,26,116,0,9,1,134,2\r\n2020,30,115,1,0.99,0.98,0.76,0.97,0.78,4.7,26,96,134,9,1,116,2\r\n2020,60,84,12,0.86,0.85,0.7,0.95,0.74,3.83,15,61,116,9,1,96,2\r\n2020,90,61,0,1,1,0.67,0.94,0.71,4.34,15,57,96,9,1,61,2\r\n2020,120,53,4,0.92,0.92,0.81,0.96,0.85,4.63,10,54,61,9,1,57,2\r\n```\r\nEven the predictions in the [example](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/Forecasting-Sales)  are not very accurate,The prediction number is only half of regression model.\r\n![image](https://user-images.githubusercontent.com/6649024/98509295-eb6d0d80-229b-11eb-9931-b6a6df3d0483.png)\r\n\r\nAny suggestion?'"
738440404,5480,"b""Suddenly unable to load DLL 'CpuMathNative' on F#""","b'### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.401\r\n Commit:    5b6f5e5005\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19041\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.401\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.7\r\n  Commit:  fcfdef8d6b\r\n\r\n.NET Core SDKs installed:\r\n  2.1.801 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.802 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.401 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.402 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.102 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.401 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n - Microsoft.ML 1.5.2\r\n - Microsoft.ML.FastTree 1.5.2\r\n - Microsoft.ML.Mkl.Components 1.5.2\r\n - Newtonsoft.Json 12.0.3\r\n - System.Threading.Channels 4.7.1\r\n - System.Memory 4.5.4\r\n - System.CodeDom 4.7.0\r\n - System.Reflection.Emit.Lightweight 4.7.0\r\n - Microsoft.ML.CpuMath 1.5.2\r\n - Microsoft.ML.DataView 1.5.2\r\n - Microsoft.ML.Mkl.Redist 1.5.2\r\n - System.Collections.Immutable 1.7.1\r\n - System.Reflection.Emit.ILGeneration 4.7.0\r\n - System.Threading.Tasks.Extensions 4.5.4\r\n - System.Runtime.CompilerServices.Unsafe 4.7.1\r\n - System.Buffers 4.5.1\r\n - System.Numerics.Vectors 4.5.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI tried to run a trainer `context.BinaryClassification.Trainers.SdcaLogisticRegression`. \r\n- **What happened?**\r\nWith the exact same code, on the exact same machine without any changes, first it ran without problems, then, suddenly I get:\r\n\r\n> Unable to load DLL \'CpuMathNative\' or one of its dependencies\r\n\r\nI am absolutely sure that before I was able to use that trainer. \r\nI am absolutely sure that I did this using netstanderd2.0\r\nI also tried setting to netcoreapp3.1 and net72, with the same error.\r\n\r\nI DID NOT EVEN RESTART BUT THIS HAPPENED WHILE WORKING!!\r\n\r\nThis is weird???\r\n\r\n- **What did you expect?**\r\n\r\nTo be able to continue to run the same code on the same machine.\r\n\r\n### Source code / logs\r\n\r\n**Note** The below code DID RUN \r\n\r\n```fsharp\r\nopen Microsoft.ML\r\nopen Microsoft.ML.Data\r\n\r\nlet printDataMetrics (trainData : Data seq) (testData : Data seq) =\r\n    printfn ""*       Metrics for train and test data      "" \r\n    printfn ""*-----------------------------------------------------------""\r\n    printfn ""*       Model trained with %i records"" (trainData |> Seq.length)\r\n    printfn ""*       Containing %i deaths"" (trainData |> Seq.filter (fun d -> d.Death) |> Seq.length)\r\n    printfn ""*       Model tested with %i records"" (testData |> Seq.length)\r\n    printfn ""*       Containing %i deaths"" (testData |> Seq.filter (fun d -> d.Death) |> Seq.length)\r\n    printfn """"\r\n    \r\n\r\nlet printCalibratedMetrics (metrics : CalibratedBinaryClassificationMetrics) =\r\n    printfn ""*       Metrics for binary classification model      "" \r\n    printfn ""*-----------------------------------------------------------""\r\n    printfn ""*       Accuracy: %.3f"" metrics.Accuracy\r\n    printfn ""*       Area Under Roc Curve: %.3f"" metrics.AreaUnderRocCurve\r\n    printfn ""*       Area Under PrecisionRecall Curve: %.3f"" metrics.AreaUnderPrecisionRecallCurve\r\n    printfn ""*       F1 Score: %.3f"" metrics.F1Score\r\n    printfn ""*       LogLoss: %.3f"" metrics.LogLoss\r\n    printfn ""*       LogLoss Reduction: %.3f"" metrics.LogLossReduction\r\n    printfn ""*       Positive Precision: %.3f"" metrics.PositivePrecision\r\n    printfn ""*       Positive Recall: %.3f"" metrics.PositiveRecall\r\n    printfn ""*       Negative Precision: %.3f"" metrics.NegativePrecision\r\n    printfn ""*       Negative Recall: %.3f"" metrics.NegativeRecall\r\n\r\nlet printNonCalibratedMetrics (metrics : BinaryClassificationMetrics) =\r\n    \r\n    printfn ""*       Metrics for binary classification model      "" \r\n    printfn ""*-----------------------------------------------------------""\r\n    printfn ""*       Accuracy: %.3f"" metrics.Accuracy\r\n    printfn ""*       Area Under Roc Curve: %.3f"" metrics.AreaUnderRocCurve\r\n    printfn ""*       Area Under PrecisionRecall Curve: %.3f"" metrics.AreaUnderPrecisionRecallCurve\r\n    printfn ""*       F1 Score: %.3f"" metrics.F1Score\r\n    printfn ""*       Positive Precision: %.3f"" metrics.PositivePrecision\r\n    printfn ""*       Positive Recall: %.3f"" metrics.PositiveRecall\r\n    printfn ""*       Negative Precision: %.3f"" metrics.NegativePrecision\r\n    printfn ""*       Negative Recall: %.3f"" metrics.NegativeRecall\r\n\r\n// Calculate the model using the training data,\r\n// and test data for the metrics. Include the features\r\n// (Data column names) that has to be included in the model.\r\nlet calculate trainData testData features =\r\n    let context = MLContext()\r\n\r\n    let trainView = context.Data.LoadFromEnumerable trainData\r\n    let testView = context.Data.LoadFromEnumerable testData\r\n    \r\n    let pipeline =\r\n        let features = features |> Seq.toArray\r\n        EstimatorChain()\r\n            .Append(context.Transforms.Concatenate(""Features"", features))\r\n            .Append(context.BinaryClassification.Trainers.SdcaLogisticRegression(""Death"", ""Features""))\r\n\r\n    let trained = pipeline.Fit(trainView)\r\n\r\n    let predicted = trained.Transform(testView)\r\n\r\n    let metrics = \r\n        //context.BinaryClassification.EvaluateNonCalibrated(data=predicted, labelColumnName=""Death"", scoreColumnName=""Score"")\r\n        context.BinaryClassification.Evaluate(data=predicted, labelColumnName=""Death"", scoreColumnName=""Score"")\r\n\r\n\r\n    printDataMetrics trainData testData\r\n    metrics\r\n    |> printCalibratedMetrics\r\n\r\n```'"
736795562,5476,b'Use runtime /dynamic created class object in prediction engine.',"b'### System information\r\n\r\n- **OS version/distro**:\r\nwindows 7\r\n- **.NET Version (eg., dotnet --info)**: \r\n>  .NET 4.6.1 ML.NET 1.5.2\r\n### Issue\r\n\r\n- **What did you do?**\r\nUse runtime /dynamic created class object in prediction engine.\r\n\r\nI want to predict different value, so I have created 25+ model\r\nUsing those models, I predict different values.\r\nBut each time I need to create class object with data and pass it to prediction engine to predict data \r\nSo, every time I need to change in code. So, I take approach to create class object on run time/ Dynamic with data and pass it to prediction engine but it will generate exception. Colum name not found in schema\r\n\r\n\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
735932441,5473,b'Is it possible to convert a ml.net model (.zip) to ONNX or tensorflow model?',"b""### System information\r\n\r\n- **Win 10 10.0.19041**:\r\n- **.NET Version 3.1.402**: \r\n\r\n### Issue\r\n\r\nIs it possible to convert a ml.net model (.zip) to ONNX or tensorflow model? I've found various APIs but they were either removed or I didn't know how to make them work.\r\n"""
733837804,5470,b'No multinomial logistic regression algorithm',"b""I didn't find multinomial logistic regression algorithm. Is it with a different name?\r\n\r\nMultinomial logistic regression is used to predict probabilities for more than two classes.\r\n\r\n"""
733080581,5469,b'ResizeImages() raise System.ArgumentException when resizing image already at correct size',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10, 10.0.19041\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1.403\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDoing inference on an image, with `ResizeImages()` part of the pipeline. The processed image is already at the correct size (1300x1300, i.e. no resizing needed). Also occurs with different pipeline/images when image already at `ResizeImages()` output size.\r\n\r\n- **What happened?**\r\nProgram raised an exception: `System.ArgumentException: \'Parameter is not valid.\'`\r\n(No exception for other images, and for same image with a different size).\r\n\r\n- **What did you expect?**\r\nNo exception.\r\n\r\n### Source code / logs\r\n```csharp\r\n// Define scoring pipeline\r\nvar pipeline = mlContext.Transforms.ResizeImages(inputColumnName: ""bitmap"", outputColumnName: ""image"",\r\n                                             imageWidth: 1300, imageHeight: 1300,\r\n                                             resizing: ResizingKind.IsoPad)\r\n                            .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""image"", scaleImage: 1f / 255f))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(inputColumnNames: new[] { ""image"" },\r\n                                                                        outputColumnNames: new[] { ""boxes"", ""labels"", ""scores"", ""masks"" },\r\n                                                                        modelFile: modelLocation));\r\n// Fit on empty list to obtain input data schema\r\nvar model = pipeline.Fit(mlContext.Data.LoadFromEnumerable(new List<InputBitmapData>()));\r\n\r\n// Create prediction engine\r\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<InputBitmapData, OutputPrediction>(model);\r\n\r\nusing (var bitmap = new Bitmap(Image.FromFile(imagePath)))\r\n{\r\n      var prediction = predictionEngine.Predict(new InputBitmapData() { Image = bitmap }); // <- error raised\r\n}\r\n\r\n```\r\n\r\n```\r\nSystem.ArgumentException\r\n  HResult=0x80070057\r\n  Message=Parameter is not valid.\r\n  Source=System.Drawing.Common\r\n  StackTrace:\r\n   at System.Drawing.Image.get_Height()\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.NamedOnnxValueGetterVec`1.GetNamedOnnxValue()\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, String[] activeOutputColNames, OnnxRuntimeOutputCacher outputCache)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass12_0`1.<MakeTensorGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n```\r\n\r\nGuess: the problem might come from here:\r\nhttps://github.com/dotnet/machinelearning/blob/a9ab7fc530ba9a2a519aaca70862ee67f42bf712/src/Microsoft.ML.ImageAnalytics/ImageResizer.cs#L301-L305'"
731805648,5466,"b""Trying to implement YoloV4 in ML.NET but running into some trouble (I'm quite new to all of this)""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 20H2\r\n- **.NET Version (eg., dotnet --info)**: 3.1.9\r\n\r\n### Introduction\r\n\r\nI\'m currently trying to use the YoloV4 model inside ML.NET but whenever I try to put an image through the model I get very strange results from the model. (It mainly finds backpacks, handbags, some apples and some other unexpected results). The image I\'m using:\r\n![dog](https://user-images.githubusercontent.com/2350015/97497833-66185d80-196b-11eb-8c96-ce7ed676cbd6.jpg)\r\n\r\nI created a repository to reproduce my issue as well:\r\nhttps://github.com/devedse/DeveMLNetTest\r\n\r\nDisclaimer: I\'m quite new to all of this :smile:\r\n\r\n### Steps I\'ve taken\r\n\r\nI first wanted to obtain a pre-trained model which I was sure worked so I did the following steps:\r\n1. Cloned: https://github.com/Tianxiaomo/pytorch-YOLOv4\r\n1. Installed requirements + pytorch + cuda etc.\r\n1. Downloaded the Yolov4_epoch1.pth model and put it in `checkpoints\\Yolov4_epoch1.pth`\r\n1. Ran `demo_pytorch2onnx.py` with debug enabled.\r\n\r\nWhen you do this you can step through the code where the output from the model is parsed (this shows the labels for all boxes with a confidence higher then 0.6):\r\n![image](https://user-images.githubusercontent.com/2350015/97498111-e212a580-196b-11eb-83b3-013f905eec5e.png)\r\n\r\nWhen we look up these labels, we can see that (all +1 since it\'s a 0-index array):\r\n```\r\n1: bicycle\r\n8: truck\r\n16: dog\r\n```\r\n\r\nSo the results in Python seem to be correct. This python script first converts the model to an ONNX model and then uses that model to do the inference.\r\n\r\nWhen I now start using the model inside C# though and try to parse through the results in exactly the same way I find completely different results:\r\n![image](https://user-images.githubusercontent.com/2350015/97498763-0622b680-196d-11eb-91b9-bb02374e7e39.png)\r\n\r\nCould it be that the model is somehow creating garbage data?\r\n\r\nAnyway, here\'s the code that I\'m \r\n\r\nMLContext:\r\n```\r\nvar pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""image"", imageFolder: """", inputColumnName: nameof(ImageNetData.ImagePath))\r\n                .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""image"", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: ""image""))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""input"", inputColumnName: ""image""))\r\n                .Append(mlContext.Transforms.ApplyOnnxModel(\r\n                    modelFile: modelLocation,\r\n                    outputColumnNames: new[] { ""boxes"", ""confs"" },\r\n                    inputColumnNames: new[] { ""input"" }\r\n                    ));\r\n```\r\n\r\nCode to parse model output:\r\n```\r\npublic IList<YoloBoundingBox> ParseOutputs(float[] boxes, float[] confs, float threshold = .6F)\r\n{\r\n\tvar boxesUnflattened = new List<BoundingBoxDimensions>();\r\n\tfor (int i = 0; i < boxes.Length; i += 4)\r\n\t{\r\n\t\tboxesUnflattened.Add(new BoundingBoxDimensions()\r\n\t\t{\r\n\t\t\tX = boxes[i],\r\n\t\t\tY = boxes[i + 1],\r\n\t\t\tWidth = boxes[i + 2] - boxes[i],\r\n\t\t\tHeight = boxes[i + 3] - boxes[i + 1],\r\n\t\t\tOriginalStuff = boxes.Skip(i).Take(4).ToArray()\r\n\t\t});\r\n\t}\r\n\r\n\tvar confsUnflattened = new List<float[]>();\r\n\tfor (int i = 0; i < confs.Length; i += 80)\r\n\t{\r\n\t\tconfsUnflattened.Add(confs.Skip(i).Take(80).ToArray());\r\n\t}\r\n\r\n\tvar maxConfidencePerBox = confsUnflattened.Select(t => t.Select((n, i) => (Number: n, Index: i)).Max()).ToList();\r\n\tvar boxesNumbered = boxesUnflattened.Select((b, i) => (Box: b, Index: i)).ToList();\r\n\r\n\tvar boxesIndexWhichHaveHighConfidence = maxConfidencePerBox.Where(t => t.Number > threshold).ToList();\r\n\tvar allBoxesThemselvesWithHighConfidence = boxesIndexWhichHaveHighConfidence.Join(boxesNumbered, t => t.Index, t => t.Index, (l, r) => (Box: r, Conf: l)).ToList();\r\n\r\n\r\n\tConsole.WriteLine(""I would expect a bike, dog and car here"");\r\n\tConsole.WriteLine(""Instead we got:"");\r\n\r\n\tforeach (var b in allBoxesThemselvesWithHighConfidence)\r\n\t{\r\n\t\tvar startString = $""{b.Conf.Number}: {labels[b.Conf.Index]}"";\r\n\t\tConsole.WriteLine($""{startString.PadRight(30, \' \')}({string.Join("","", b.Box.Box.OriginalStuff)})"");\r\n\t}\r\n\r\n\tthrow new InvalidOperationException(""Everything below this doesn\'t work anyway"");\r\n```\r\n\r\nCan someone give me some hints / ideas on why I could be running into this issue?\r\n\r\nAlso feel free to clone the repo and press F5. It should simply build / run.\r\nhttps://github.com/devedse/DeveMLNetTest'"
731667035,5465,b'Bayesian Optimization with Gaussian Processes',"b'Are there any implementations of aforementioned methods with ""same process space"" interface to C# by Microsoft or Microsoft sponsored project or similar? Basically I am interested in anything solid/more or less ready to be used ""out of the box"". Tree-based regression under the hood will also work.'"
731400231,5463,b'How to read all data from output shapes of a node?',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version**: \r\n.net Core 3.1\r\n- **ML.NET Version**:\r\nML.NET 1.5.2 \r\n- **Further packages**:\r\nSciSharp.TensorFlow.Redist 2.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nWith my ML.NET code I load an existing TensorFlow Model for object detection and run it. It\'s an own pretrained model and there is no further training in my code. The execution of the model works fine. The model provides several result information: coordinates, confidences, class ids, number of found objects\r\n- **What happened?**\r\nWhen I try to read data after inference I only get coordinates.\r\n- **What did you expect?**\r\nGetting all data of node.\r\n\r\n### Source code / logs\r\nThe special thing about the model is the shape of output node. In all examples I saw so far, it was always e.g. a list of floats. In this specific model the shape are several lists containing the data.\r\n\r\nWhen I have a look at the output node of the model with Netron it looks like this\r\n![image](https://user-images.githubusercontent.com/8576966/97433888-7ce49300-191e-11eb-9500-207614a7130d.png)\r\n\r\nMy colleagues, consuming the model with python, just call it with something like\r\n`coords, confidence, class_ids,  nums  = model( input_image)`\r\nand receive the results. \r\n\r\nSo far I defined my result class as\r\n```C#\r\npublic class ImagePrediction\r\n{\r\n    [ColumnName(""StatefulPartitionedCall"")]\r\n    public float[] Coordinates;\r\n}\r\n```\r\nso it makes sense that only the first list is available as result.\r\n\r\nUnfortunately I have no idea what I have do change to get all provided information in ML.NET\r\n\r\nRest of execution code is quite the same like classification sample with a TensorFlow model.\r\n\r\nI uploaded model and code to a repository. Since I am not allowed to make the model public, it is a private repo. Please let me know when someone wants to have a deeper look in code/model.\r\n\r\nI appreciate any ideas what I can try or even if it is possible/supported at all.\r\n\r\nThanks and regards'"
730164397,5459,b'Make TextLoader infer column information from a CSV file header',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1\r\n\r\n### Issue\r\n\r\nI couldn't find the channel to submit a request so I apologise if this isnt the right place.\r\n\r\nI have a web portal that customers upload csv files to train and predict using multiclass-classification algo. However, ML.NET requires a concrete class for the Input Model with properties hard coded to the columns of the csv. \r\n\r\nCould you enhance the LoadFromText method so that it can accept an argument for the label header name and then just read the features from the headers of the rest of the csv file without having to create a class? This way nothing is hard coded and it can work with any csv file that my customers upload.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
729845023,5458,b'Error while loading yolov4 model ',"b'![Screenshot from 2020-10-27 00-56-53](https://user-images.githubusercontent.com/29913676/97219090-84594e80-17ef-11eb-923e-7e9dfda0d3f7.png)\r\nI am new to this. I have experience with Python but with this, I have no idea. Please help. What is this error indicating?'"
728773405,5456,b'Doc: Example for LoadRawImageBytes does not contain a call to LoadRawImageBytes',"b'\r\nThe example shown in the documentation of the LoadRawImageBytes method does not contain a single reference to this method. I think an example calling this method would be more helpful.\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 935b3cba-8385-d7b1-0d1c-92ce1e5b6bef\r\n* Version Independent ID: f4c01ba9-1f3e-03fa-48ea-1a62a13e11b4\r\n* Content: [ImageEstimatorsCatalog.LoadRawImageBytes(TransformsCatalog, String, String, String) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.imageestimatorscatalog.loadrawimagebytes?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/ImageEstimatorsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ImageEstimatorsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
727671075,5452,"b""BinaryClassification.Trainer  produces System.ArgumentOutOfRangeException: 'Not large enough to hold these values. Parameter Name: destinantion""","b'### System information\r\n\r\n- **OS version/distro**: win 10 \r\n- **.NET Version (eg., dotnet --info)**: 3.3\r\n\r\n### Issue\r\n\r\n- **What did you do?** i\'m running my c# script , which takes the two(training and validation ) plain files containing  more than 10 000 features in each of files.\r\n- **What happened?**  the script string ""var model = pipeline.Fit( trainingData, validationData);""   produced: System.ArgumentOutOfRangeException: \'Not large enough to hold these values. Parameter\'s name: destinantion\r\n- **What did you expect?** I expect  you to see the ecnlosed code ""mlnet.txt"" and the zipped source data which i use for training and validation.\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[source_data.zip](https://github.com/dotnet/machinelearning/files/5425302/source_data.zip)\r\n\r\n[mlnet.txt](https://github.com/dotnet/machinelearning/files/5425306/mlnet.txt)\r\n'"
727538486,5451,b'Parameter mapping betbeen python Booster model and ML.Trainers.LightGbm.GradientBooster object',"b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 3.1.3\r\n\r\n### Issue\r\n\r\n- **What did you do?** I trained a model within python LGBM API via Byessian optimization\r\n- **What happened?** I\'ve received from the optimization a model file with the defined parameters. I want to train this optimized model within the ML.NET environment. The obstacle is: a confusion, that I can\'t make confindent matching between  parameters presented on the page https://lightgbm.readthedocs.io/en/latest/Parameters.html  and the properties of  the  ML.Trainers.LightGbm.GradientBooster object:\r\n \r\n                    FeatureFraction  \r\n                    L1Regularization  \r\n                    L2Regularization  \r\n                    MaximumTreeDepth \r\n                    MinimumChildWeight \r\n                    MinimumSplitGain  \r\n                    SubsampleFraction   \r\n                    SubsampleFrequency \r\n \r\n- **What did you expect?** So below is presented my matching between python parameters and GradientBooster object, I want you to verify whether my matching is correct , and point out how is the ""SubsampleFraction "" named in python parameters.\r\n\r\n### Source code / logs\r\n\r\n            var options = new LightGbmBinaryTrainer.Options\r\n            {\r\n                Booster = new Microsoft.ML.Trainers.LightGbm.GradientBooster.Options   \r\n                {\r\n                    FeatureFraction = 0.855937, //   -- > feature_fraction \r\n                    L1Regularization = 0.973817, // ---> lambda_l1 \r\n                    L2Regularization = 2.27,    // ---> lambda_l2\r\n                    MaximumTreeDepth = 8, //   -- > max_depth \r\n                    MinimumChildWeight = 17.9015, //    -- > min_sum_hessian_in_leaf \r\n                    MinimumSplitGain = 0.076047,  //    -- >  min_gain_to_split\r\n                    SubsampleFraction =1,  // ???? can\'t determine the analoguos within https://lightgbm.readthedocs.io/en/latest/Parameters.html \r\n                    SubsampleFrequency = 10, //     -- > bagging_fraction\r\n                }\r\n            };\r\n\r\nThe criterion of the successful answer is: \r\nThe two models give the same classification probabilities  trained in python and with GradientBooster object. Wen you present me the correct matching of the parameters, i run the two models, and check the output difference. \r\nThank you!'"
727336968,5450,b'how to use FastTextWikipedia300D',"b'Hi if I wanted to use a pre-trained file, for example Wiki word vectors by fasttext is it possible? and how?'"
727317860,5449,"b""Unable to load DLL 'tensorflow' or one of its dependencies""","b""### System information\r\n\r\n- **OS version/distro**: Azure windows app service\r\n- **.NET Version (eg., dotnet --info)**:  3.1 \r\n- **ASP.NET Version (eg., dotnet --info)**:  3.1.7\r\n#### Packages\r\n- Microsoft.ML                          1.5.2\r\n- Microsoft.ML.ImageAnalytics 1.5.2\r\n- Microsoft.ML.Vision               1.5.2\r\n- Microsoft.ML.TensorFlow        1.5.2\r\n\r\n- SciSharp.TensorFlow.Redist     2.3.0\r\n- TensorFlow.NET                       0.21.0\r\n\r\n### Issue\r\nI create a web application with ML.Net. Everything works on my local machine,  But the Azure server catch the error when I debugged on app service.\r\n\r\n`System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()`\r\n\r\n- **What did you do?**\r\nDeploy a web application with ML.NET to azure.\r\n- **What happened?**\r\nSystem.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies\r\n- **What did you expect?**\r\nThe program can run the same as local.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
726983837,5447,"b""System.InvalidOperationException: 'LightGBM Error, code is -1 (LightGbm 3.0.0)""","b""- Tested on Windows 10 and Server 2019:\r\n- .NET 4.7: \r\n- Microsoft.ML (1.5.2) \r\n- Microsoft.ML.LightGbm (1.5.2)\r\n- LightGbm (3.0.0)\r\n\r\n**Issue**\r\nIt crashes in this line \r\n\r\n- var model = pipeline.Fit(trainData);\r\n\r\n- I get this error: System.InvalidOperationException: 'LightGBM Error, code is -1, error message is 'Unknown importance type: only support split=0 and gain=1'.'\r\n\r\nThis error can be reproduced by an example. I just used the example in docs.microsoft.com and able to reproduce it.\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet\r\n\r\nI created a console app and you can access it from the link below:\r\n\r\nhttps://drive.google.com/drive/folders/1-wc04CM75-IGoxjRAniDuhqI-zrHTWwM?usp=sharing\r\n\r\nI talked to the LightGBM team and they mentioned this issue exists in .Net code and not theirs. This is the third time this issue has been reported (#5431 and #5382) and each time it has been closed without any resolution."""
726911615,5446,b'Multidimensional Vectors causing AutoML to throw null reference exception',"b""### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 3.1.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to use a 2 dimensional float array as a vector\r\n- **What happened?**\r\nGot a null reference exception when trying to run an experiment\r\n- **What did you expect?**\r\nTh experiment to run\r\n\r\nThe documentation seems to indicate my setup is correct: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.vectortypeattribute.-ctor?view=ml-dotnet#Microsoft_ML_Data_VectorTypeAttribute__ctor_System_Int32___\r\n\r\nTo fix my multidimension vector problem, I've tried:\r\n* Adding/Removing the float[,] initializers in InputData\r\n* Specifying the exact size with [VectorType(3,60)]\r\n* Leaving the [VectorType] attribute off altogether and using autoschema to set it.\r\n* Leaving the [VectorType] attribute off altogether and not using autoschema to let ML.net figure it out on its own\r\n* Adding just [VectorType()], although the docs say that is for single dimension arrays.\r\n\r\n### Source code / logs\r\n\r\nHere is a minimal reproduction of the issue:\r\n```\r\nclass Program\r\n{\r\n    static void Main(string[] args)\r\n    {\r\n        var mlContext = new MLContext();\r\n\r\n        // create schema for multidimensional vector\r\n        var autoSchema = SchemaDefinition.Create(typeof(InputData));\r\n        var col = autoSchema[1];\r\n        col.ColumnType = new VectorDataViewType(NumberDataViewType.Single, 3, 60);\r\n\r\n        // fabricate some data\r\n        var trainingData = new List<InputData>();\r\n        var inputData = new InputData();\r\n        inputData.MultiDimensional = new float[20,20];\r\n        for (int i = 0; i < inputData.MultiDimensional.GetUpperBound(0); i++)\r\n        {\r\n            for (int j = 0; j < inputData.MultiDimensional.GetUpperBound(1); j++)\r\n            {\r\n                inputData.MultiDimensional[i,j] = 5; // doesn't matter\r\n            }\r\n        }\r\n        trainingData.Add(inputData);\r\n\r\n        // setup a data view\r\n        IDataView trainingDataView = mlContext.Data.LoadFromEnumerable<InputData>(trainingData, autoSchema);\r\n\r\n        // preview it (goes BOOM)\r\n        var preview = trainingDataView.Preview();\r\n\r\n        // run the experiment\r\n        var settings = new BinaryExperimentSettings();\r\n        settings.MaxExperimentTimeInSeconds = 60;\r\n        ExperimentResult<BinaryClassificationMetrics> experimentResult = mlContext.Auto()\r\n            .CreateBinaryClassificationExperiment(settings)\r\n            .Execute(trainingDataView);\r\n    }\r\n}\r\n\r\npublic class InputData\r\n{\r\n    public bool Label { get; set; }\r\n    public float[,] MultiDimensional { get; set; }\r\n}\r\n```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
725064176,5443,b'NoColumn Attribute not recognized by TextLoaderSaverCatalog.LoadFromTextFile Method',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10/ Home\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.101\r\n Commit:    b377529961\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19041\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.101\\\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to run the following code to load my training data out of a CSV file.  I\'ve been using the AutoML CLI to this point to generate my models, and thought I\'d take crack at doing it via my .NET code.  The `ModelInput` class has been working at runtime to load my metrics into, and pass to the model trained using the CLI, for predictions, even with the extra columns in the class.\r\n\r\n```csharp\r\nMLContext mlContext = new MLContext();\r\nIDataView trainDataView = mlContext.Data.LoadFromTextFile<ModelInput>(""data/data.csv"", hasHeader: true);\r\n```\r\n- **What happened?**\r\nGet error:\r\n```\r\nSystem.InvalidOperationException: Property \'Change_Tomorrow\' is missing the LoadColumnAttribute attribute\r\n   at Microsoft.ML.Data.TextLoader.CreateTextLoader[TInput](IHostEnvironment host, Options options, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.Data.TextLoader.CreateTextLoader[TInput](IHostEnvironment host, Boolean hasHeader, Char separator, Boolean allowQuoting, Boolean supportSparse, Boolean trimWhitespace, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.TextLoaderSaverCatalog.LoadFromTextFile[TInput](DataOperationsCatalog catalog, String path, Char separatorChar, Boolean hasHeader, Boolean allowQuoting, Boolean trimWhitespace, Boolean allowSparse)\r\n```\r\n- **What did you expect?**\r\nData to be loaded from my csv file into an IDataView\r\n\r\n### Source code / logs\r\n- **ModelInput Class**\r\nThis is a trimmed down version of my ModelInput class.  Note that the ""Index(0)"" attribute and the ""Ignore"" attribute come from the ""CsvHelper"" Nuget package, as I use this ModelInput class for both writing to Csv, and for input for model predictions.\r\n```csharp\r\n    public class ModelInput\r\n    {\r\n        [ColumnName(""Country""), LoadColumn(0), Index(0)]\r\n        public string Country { get; set; }\r\n        [Ignore, NoColumn]\r\n        public float Change_Tomorrow { get; set; }\r\n        [Ignore, NoColumn]\r\n        public DateTime DateTomorrow { get; set; }\r\n    }\r\n```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
723792084,5442,b'Incompatible package sign on Ml 1.5.2 in Visual Studio',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro 1909 Build: 18363.1139\r\n- **.NET Version (eg., dotnet --info)**: 3.1.401\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated new core console project and added `ML.Net` version `1.5.2` nuget package.\r\n- **What happened?**\r\nI'm seeing yellow incompatible package sign on package in dependency tree. Although everything works just fine.\r\n- **What did you expect?**\r\nObviously, it shouldn't show this sign.\r\n### Source code / logs\r\n\r\n![image](https://user-images.githubusercontent.com/16499626/96347709-fb3e6b00-10bc-11eb-9878-c8d13dd781ca.png)\r\n\r\n"""
722707804,5441,b'Anomaly detection returns scores of infinite value',"b'\r\n\r\n### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**: built from guinao:yuyi/dev/new_boundary\r\n![image](https://user-images.githubusercontent.com/69877427/96190993-085e2d00-0ef8-11eb-9dac-eee1845063d5.png)\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRun anomaly detection\r\n\r\n- **What happened?**\r\nAnomalies were detected, but some of the scores returned were infinite. Looks like there might be a regression in how AD scores are calculated.\r\n![image](https://user-images.githubusercontent.com/69877427/96190093-802b5800-0ef6-11eb-8280-f38934fdd78a.png)\r\n\r\n- **What did you expect?**\r\nResults to return scores that are not infinite\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nAnomaly detector options\r\n![image](https://user-images.githubusercontent.com/69877427/96190860-c46b2800-0ef7-11eb-8af8-e0c09a254788.png)\r\n\r\nDLLs used\r\n[dlls.zip](https://github.com/dotnet/machinelearning/files/5388145/dlls.zip)\r\n\r\nCSV\r\n[csv](https://github.com/dotnet/machinelearning/files/5388216/covid.zip)\r\n'"
721836234,5438,b'Discuss - Image classification in AutoML.Net',"b""### What's the problem\r\nCurrently, Image classification in automl.net is brutal. By meaning brutal, it's because of the way automl.net run cross-validation on ImageClassification trainer: It's ten times longer than using ImageClassification API directly, with little difference. Here are some statistics.\r\n\r\nThe weather report is a dataset which includes around 1K images, the training time for using ImageClassification trainer directly is about 6 mins on `Xeon W 2133` CPU, using resnet_v2_50_299, the time using AutoML.Net to train on the same dataset is astonishingly 60 minutes. However, the result is quite similar: Macro accuracy from using ImageClassification API is 96.07%, and from AutoML.Net is 96.29%. \r\n\r\nWhy the difference in the time is huge while the difference in evaluation result is small? It's because AutoML.Net runs a cross-validation check on a small dataset. (FYI small is defined as a dataset with less than 15000 rows). And the default fold number for cross-validation is 10, which means AutoML.Net will run the same trail for ten times with different dataset, and return the average evaluation metric and the model with evaluation closest to that metric. On the other hand, if I use a larger dataset with over 15000 pictures, the training time should be similar because AutoML.Net will use a train-validation split instead of cross-validation to run a single trail.\r\n\r\nIs CV really necessary for image classification, especially when AutoML.Net only uses one trainer and the hyper-parameter tuning for that trainer is disabled? To answer this, let's first look back on what's CV's pro and cons, and why AutoML.Net uses CV. The pros of using CV is 1) it reduces the variance of the validation score, so less bias in evaluation result 2) it helps reduce the overfitting problem. The con is it's time-costy. In most of the case, CV is necessary for AutoML.Net because AutoML's smart sweeper relies on the validation score of each trail to perform SMBO algo, a less bias evaluation result helps produce better model. Moreover, the final evaluation metrics summary will be more objective because of CV. The time-costy problem still exists, but that's not a big one in normal cases because most of AutoML.Net trails only uses a rather short time to complete, and it's worthwhile to use the extra time in exchange for better result.\r\n\r\nHowever, when it comes to image classification, the pros of running cross-validation disappear and the cons of CV becomes even more serious. As I mentioned above, there's only one trainer and no hyper-parameter tuning is available for that trainer, so a less bias validation score doesn't help sweeper to produce a better model. What makes things worse is the time for a single trail for image classification is much longer than a normal trail because of ImageClassification trainer. The only pros for using CV in image classification cases is left to be a more objective evaluation score in the summary, but is that really worthwhile enough with the cost of 10-time longer training time?\r\n\r\nMy answer is no, at least not for model builder users, where Azure training is available at hand. They can accept a lousy but faster (actually not too lousy, the model is the same, only evaluation score might be biased because of high variance) instead of better (not too better, see above) but much slower local training.\r\n\r\n### What we need to change\r\nWe have two ways to make image classification having a better experience in AutoML.Net, both training performance and training time.  The first way is simple but with less improvement: simply disable CV in image classification, or at least make it a flag in the MultiClassificationExperiment option so the user can disable it. The second way is more of an AutoML-style solution: Use DNN featurizers along with traditional multiclassification trainers, The single trail time will be shorter, and it provides more space for its smart sweeper to tune over the hyper-parameter to find out the best combination.\r\n\r\n"""
721354512,5437,b'Auto train pipeline Bug',"b'### System information\r\n\r\n- **OS version/distro**: Windows server 2012r2 - windows 10\r\n- **.NET Version**: .net core 3.1\r\n- **Ml.net Version**: Last Stable Version.\r\n\r\n### Issue\r\n\r\n- **What did you do?**: Set a auto Training pipeline using API, set a long MaxExperimentTimeInSeconds (For example 600) for small dataset.\r\n- **What happened?**: Program hanged without any response.\r\n- **What did you expect?**: the program should stop training after 600 seconds. and show me the result.\r\n- **Am I Tested it with shorter time?**: Yes! I Tested it with 120Seconds and 100 Seconds. Its work currectly!\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar experimentSettings = new MulticlassExperimentSettings()\r\n            {\r\n                MaxExperimentTimeInSeconds = 600,\r\n                CacheDirectory = new DirectoryInfo(""cache""),\r\n                CacheBeforeTrainer = CacheBeforeTrainer.Auto,\r\n                OptimizingMetric = MulticlassClassificationMetric.MicroAccuracy,\r\n            };\r\n```\r\n\r\n            var experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);\r\n\r\n            var crossValidationExperimentResult = experiment.Execute(\r\n                trainData: mappedInputData,\r\n                labelColumnName: ""Label"",\r\n                progressHandler: new Progress<RunDetail<MulticlassClassificationMetrics>>()\r\n            );\r\n\r\n![toplearn](https://user-images.githubusercontent.com/36773254/95979375-68859e00-0e28-11eb-95d9-3c44f742709d.png)'"
720807403,5434,b'Models build with SDCA trainers and seeded ML context are getting different values for accuracy  ',"b'### System information\r\n\r\n- **Windows 10**:\r\n- **.NET 5 RC1 & RC2**: \r\n\r\n### Issue\r\n\r\n- **I build a model using a MLContext with seed parameter set and I use SDCAMaximumEntropy or SDCANonCalibrated**\r\n- **The accuracy fluctuates with every build**\r\n- **I expect the accuracy to be the same. If I\'m using other trainers like LighGbm, the accuracy is consistent, the same with every build.**\r\n\r\n### Source code / logs\r\nYou can find the notebook here: https://github.com/dcostea/SmartFireAlarm/blob/master/SmartFireAlarm/Jupyter/sample.ipynb\r\nI have extracted here the code:\r\n```\r\n#r ""nuget:Microsoft.ML,1.5.2""\r\n#r ""nuget:Microsoft.ML.LightGBM,1.5.2""\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Trainers.LightGbm;\r\nusing Microsoft.ML.Data;\r\n\r\nMLContext mlContext = new MLContext(seed: 123);\r\n\r\nconst string TRAIN_DATASET_PATH = ""./sensors_data_train.csv"";\r\nIDataView trainingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n    path: TRAIN_DATASET_PATH,\r\n    hasHeader: true,\r\n    separatorChar: \',\');\r\n\r\nconst string TEST_DATASET_PATH = ""./sensors_data_test.csv"";\r\nIDataView testingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n    path: TEST_DATASET_PATH,\r\n    hasHeader: true,\r\n    separatorChar: \',\');\r\n\r\nvar featureColumns = new string[] { ""Temperature"", ""Luminosity"", ""Infrared"", ""Distance"" };\r\n\r\nvar trainingPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", featureColumns))\r\n    .Append(mlContext.MulticlassClassification.Trainers.SDCAMaximumEntropy(""Label"", ""Features""))\r\n    .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nvar model = trainingPipeline.Fit(trainingData);\r\n\r\nvar predictions = model.Transform(testingData);\r\nvar metrics = mlContext.MulticlassClassification.Evaluate(predictions, ""Label"", ""Score"", ""PredictedLabel"");\r\n```\r\n'"
720200029,5432,b'Webhosting of models and high memory consumption',"b'We have a web application that hosts a trained model to enable users for prediction scenarios.\r\nThe solution is based on the *ImageClassificationModelTraining.Solution*  in the *machinelearning-samples* repo. \r\nThe training was done by following code (just a snippet for a case that it is important):\r\n\r\n```csharp\r\n            var pipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(options: hyperParams)\r\n            .Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: ""PredictedLabel"",\r\n                                                                      inputColumnName: ""PredictedLabel""));\r\n\r\n            // Apply 5-fold cross validation\r\n            var cvResults = mlContext.MulticlassClassification.CrossValidate(cvDataView, pipeline, numberOfFolds: numOfFolds, labelColumnName: ""LabelAsKey"", seed: 8881);\r\n\r\n            // Get best Model which is on the first place\r\n            var topModel = cvResults[0].Model;\r\n\r\n            //Show the performance metrics for the multi-class classification            \r\n            var metrics = mlContext.MulticlassClassification.Evaluate(cvResults[0].ScoredHoldOutSet, labelColumnName: ""LabelAsKey"", predictedLabelColumnName: ""PredictedLabel"");\r\n ``` \r\n\r\nTo make this working, we have loaded a pool of Prediction Engine instances, which will be assigned to incoming requests. Following code shows how instances are created on startup.\r\n\r\n```csharp\r\n       private List<PredictionEngine<TSrc, TDest>> LoadPool(string modelFullPathName)\r\n        {\r\n            List<PredictionEngine<TSrc, TDest>> engines = new List<PredictionEngine<TSrc, TDest>>();\r\n\r\n            for (int i = 0; i < config.PoolSize; i++)\r\n            {\r\n                var mlnetModel = mlContext.Model.Load(modelFullPathName, out _);//ModelInfo.ServerFilePath\r\n                var predictionEngine = mlContext.Model.CreatePredictionEngine<TSrc, TDest>(mlnetModel);\r\n                engines.Add(predictionEngine);\r\n            }\r\n\r\n            return engines;\r\n        }\r\n```\r\nThis part works fine. As next, we have measured how much RAM the application will need when deployed to the *AppService* (or anything else). We figured out that the memory consumption of trained model is extremely high.\r\nFollowing diagram shows the behaviour of the prediction engine. First, we load a set of prediction engines (in this example 6 instances) by using the code shown above.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/95859723-53910800-0d5f-11eb-8758-917ba4499a15.png)\r\n\r\nAfter loading some space in RAM is consumed. However on the first *Predict* invoke of the particular instance of the prediction engine, there is a peak of 1.5-2.0 GB. After the peak, the memory consumption gets stable again.\r\n\r\nThe issue with the peak is that, when it happens, it causes the AppService health feature sometimes to restart the service. Ok, it is not nice, but it can be fixed by using higher AppService offering. However, it would be good to know where does the peak comes from for the case that it can get higher than 2GB.\r\n\r\nAnother negative observation is the high memory consumption of the single instance of the prediction engine. Following diagram shows the consumption in dependence on the number of instances of the prediction engine.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/95860311-2bee6f80-0d60-11eb-9c23-3fe86514b31a.png)\r\n\r\nThe blue line shows the consumption after the load of the predication engine and the green one shows consumption of the prediction engine instances after the ```Predict``` method has been invoked on each of them.\r\n\r\nThe dotted line is the memory consumption as calculated by the formel shown in the diagram. The issue with behaviour is that the consumption of the single prediction engine instance is approx. **600MB**, which is too much. We could easily calculate here how much would cost the App Service with just 100 concurrent users. It is too much for this scenario.\r\n\r\nWe can understand and agree that training is a heavy scenario and might require a lot of memory and CPU resources. However trained models must be more lightweight.\r\n\r\n### System information\r\n\r\n- **Windows 10**:\r\n- **  DotNet 3.1.402**: \r\n\r\n'"
719875778,5431,"b""System.InvalidOperationException: 'LightGBM Error, code is -1""","b""- Tested on Windows 10 and Server 2019:\r\n- .NET 4.7: \r\n- Microsoft.ML (1.5.2) \r\n- LightGbm (3.0.0)\r\n\r\n**Issue**\r\nIt crashes in this line \r\n\r\n- var model = pipeline.Fit(trainData);\r\n\r\n- I get this error: System.InvalidOperationException: 'LightGBM Error, code is -1, error message is 'Unknown importance type: only support split=0 and gain=1'.'\r\n\r\nThis error can be reproduced by an example. I just used the example in docs.microsoft.com and able to reproduce it.\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet\r\n\r\nI created a console app and you can access it from the link below:\r\n\r\nhttps://drive.google.com/drive/folders/1-wc04CM75-IGoxjRAniDuhqI-zrHTWwM?usp=sharing\r\n\r\nI talked to the LightGBM team and they mentioned this issue exists in .Net code and not theirs."""
719613909,5430,b'The expected value calculation does not have knowledge of the data range of the series',"b'### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**:  ML.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDetected anomalies on dataset with only non-negative values and saw a negative expected value range.\r\n\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/69877427/95783099-f7a68080-0c85-11eb-97a7-414329c36faf.png)\r\n\r\n- **What did you expect?**\r\nThe expected value range to be non-negative.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nCsv and email correspondence \r\n[covid19_deaths.zip](https://github.com/dotnet/machinelearning/files/5367173/covid19_deaths.zip)\r\n\r\n\r\nThe options set for anomaly detection:\r\nvar options = new SrCnnEntireAnomalyDetectorOptions()\r\n            {\r\n                Threshold = 0.05,\r\n                BatchSize = -1, // not set, so we are using the default, is that -1?\r\n                Sensitivity = 75.0,\r\n                DetectMode = SrCnnDetectMode.AnomalyAndMargin,\r\n                Period = -1,\r\n                DeseasonalityMode = SrCnnDeseasonalityMode.Median // the period is -1, so I assume deseasonalize is not applied?\r\n            };\r\n\r\n\r\n'"
719613873,5429,b'Cannot detect anomalies on percent of grand total ',"b'### System information\r\n\r\n- **OS version/distro**:.Net 4.8\r\n- **.NET Version (eg., dotnet --info)**:  ML.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDetect anomalies on the percent of grand total of a value that returned multiple anomalies.\r\n\r\n- **What happened?**\r\nNo anomalies were returned\r\n![image](https://user-images.githubusercontent.com/69877427/95783665-2ffa8e80-0c87-11eb-9e77-b910cc88e095.png)\r\n![image](https://user-images.githubusercontent.com/69877427/95783686-3983f680-0c87-11eb-91d3-2514fc1fbe25.png)\r\n\r\n\r\n- **What did you expect?**\r\nTo see anomalies at the same points in time as in the original value,\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nCsvs, gif, and email correspondence\r\n[percent of grand total.zip](https://github.com/dotnet/machinelearning/files/5367178/percent.of.grand.total.zip)\r\n\r\n'"
719359145,5428,"b'""Input string was not in a correct format."" exception when executing experiment with ML.AutoML'","b""\r\n\r\n### System information\r\n\r\n- Microsoft Windows 7 Professional, Version\t6.1.7601 Service Pack 1 Build 7601\r\n- .Net Core 3.1\r\n- Microsoft.ML.AutoML 0.17.2\r\n\r\n### Issue\r\n\r\n- I am executing an experiment with ML.AutoML, using the data from test2.csv\r\n-  I constantly have a parsing exception on experiment.Execute(data, labelProperty.Name),\r\nno matter what label I'm choosing, or if I'm loading the data directly from the file or I'm reading and parsing it myself.\r\n\r\n\r\n\r\n at System.Number.ThrowOverflowOrFormatException(ParsingStatus status, TypeCode type)\r\n   at Microsoft.ML.AutoML.SweeperProbabilityUtils.ParameterSetAsFloatArray(IValueGenerator[] sweepParams, ParameterSet ps, Boolean expandCategoricals)\r\n   at Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerAllowList)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.ExecuteCrossValSummary(IDataView[] trainDatasets, ColumnInformation columnInfo, IDataView[] validationDatasets, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, String labelColumnName, String samplingKeyColumn, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at MLPoc.Services.LoadDataService.TrainDataAndCreateModel(List`1 properties, DynamicTypeProperty labelProperty, List`1 lineValues) in C:\\DevITPAzurePatricia\\Ikosoft\\MLPoc\\Services\\LoadDataService.cs:line 81\r\n\r\n\r\n### Source code / logs\r\n[code.zip](https://github.com/dotnet/machinelearning/files/5365217/code.zip)\r\n"""
719249606,5427,b'object detection on local ML',"b'there is object detect ml on Azure\xef\xbc\x8c I want to do that on local, anyone can give me some advice or demo?\r\n\r\nthanks a  lot.'"
718428900,5426,b'Exception while inferencing ML.NET ONNX model that uses TextFeatures',"b'[###](url) System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?\r\n     Trained a Fast tree model on text data.\r\n     Saved the trained model to ONNX format\r\n     Load the ONNX model and run Prediction\r\n- **What happened?\r\n      Prediction code threw an exception and application crashed.\r\n- **What did you expect?**\r\n      Prediction code to return score and predict label.\r\nSample code is attached\r\n[MLNetONNXSample.zip](https://github.com/dotnet/machinelearning/files/5357598/MLNetONNXSample.zip)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
717765883,5425,b'Add DcgTruncationLevel to Ranking AutoML API',"b'When performing Ranking in AutoML, it will always return back a length of 3 in the DCG and nDCG metrics. However, when using the Evaluate method for Ranking, it has a property in the `RankingEvaluatorOptions` to specify the DcgTruncationLevel.\r\n\r\n```csharp\r\nvar rankingEvaluatorOptions = new RankingEvaluatorOptions { DcgTruncationLevel = 10 };\r\n```\r\n\r\nThis was noticed when adding the Ranking AutoML sample in [this comment](https://github.com/dotnet/machinelearning-samples/pull/852#discussion_r498425201)'"
716552710,5421,b'Options for running ML.NET in Hyper-V',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 64-bit in Hyper-V\r\n- **.NET Version (eg., dotnet --info)**: 4.8/Standard 2.0\r\n\r\n### Issue\r\n\r\nI have an application utilizing ML.NET image classification that works excellent on Windows 10 desktop, but does not load when run in a Hyper-V virtual machine.\r\n\r\nThe execution stops during initialization and 4 inner-exceptions-deep is the error:\r\n\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nUnable to load DLL 'tensorflow': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n\r\nI have read other postings online that this might have to do with the lack of GPU capabilities in the default Hyper-V video driver.  Does anyone have any workarounds or solutions for this?\r\n"""
716374400,5420,"b""System.ArgumentOutOfRangeException: 'Features column 'Feature' not found (Parameter 'schema')'""","b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1\r\n- ML.NET 1.5.2\r\n\r\n### Issue\r\n\r\nI\'m having a problem when training a model. I have a range of HTTP requests and I want to be able to identify is the request is coming from a bot or not. To train this I have a range of these:\r\n\r\n```csharp\r\npublic class Request\r\n{\r\n    public string Url { get; set; }\r\n    public string UserAgent { get; set; }\r\n    public bool IsBot { get; set; }\r\n}\r\n```\r\n\r\nAnd a prediction class like this:\r\n\r\n```csharp\r\npublic class IsBotPrediction\r\n{\r\n    [ColumnName(""PredictedLabel"")]\r\n    public bool Prediction { get; set; }\r\n    public float Score { get; set; }\r\n}\r\n```\r\n\r\nJust for this example, I have created a list of hardcoded data:\r\n\r\n```csharp\r\nvar trainingData = new List<Request>\r\n{\r\n    new Request { Url = ""/wp-admin"", UserAgent = ""a bot"", IsBot = true },\r\n    new Request { Url = ""/backoffice"", UserAgent = ""a bot"", IsBot = true },\r\n    new Request { Url = ""/hack"", UserAgent = ""a bot"", IsBot = true },\r\n    new Request { Url = ""/login"", UserAgent = ""a bot"", IsBot = false },\r\n    new Request { Url = ""/dashboard"", UserAgent = ""a bot"", IsBot = false },\r\n    new Request { Url = ""/humans.txt"", UserAgent = ""a bot"", IsBot = false },\r\n    new Request { Url = ""/admin"", UserAgent = ""a bot"", IsBot = true },\r\n};\r\n```\r\n\r\nTo train a model I\'m using the following code:\r\n\r\n```csharp\r\nIDataView mlData = mlContext.Data.LoadFromEnumerable(trainingData);\r\n\r\nvar dataPrepPipeline = mlContext\r\n    .Transforms\r\n    .Text\r\n    .FeaturizeText(""UrlF"", ""Url"")\r\n    .Append(mlContext.Transforms.Text.FeaturizeText(""UserAgentF"", ""UserAgent""))\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", ""UrlF"", ""UserAgentF""))\r\n    .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""))\r\n    .AppendCacheCheckpoint(mlContext);\r\nvar prepPipeline = dataPrepPipeline.Fit(mlData);\r\n\r\nvar trainer = mlContext\r\n    .BinaryClassification\r\n    .Trainers\r\n    .AveragedPerceptron(labelColumnName: ""IsBot"", numberOfIterations: 10, featureColumnName: ""Features"");\r\n\r\nvar preprocessedData = prepPipeline.Transform(mlData);\r\n\r\nITransformer trainedModel = trainer.Fit(preprocessedData);\r\n```\r\n\r\nThe trained model seems to be a success. But when I try to create a prediction engine:\r\n\r\n```csharp\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<Request, IsBotPrediction>(trainedModel);\r\n```\r\n\r\nI get the following exception:\r\n\r\n> System.ArgumentOutOfRangeException: \'Features column \'Feature\' not found (Parameter \'schema\')\'\r\n\r\nCan you please help me figure out what this means?'"
716138735,5419,b'Local GPU training fails with Image Classification scenario using Model Builder',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 2004\r\n- **.NET Version (eg., dotnet --info)**: 5.0.100-rc.1.20452.10\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried using ML.NET Model Builder with my GTX 1070 to run an image classification scenario.\r\n\r\n- **What happened?**\r\nVRAM spikes to 99% usage, then exceptions are printed in the logs and the training fails.\r\n\r\n- **What did you expect?**\r\nTraining to succeed.\r\n\r\n### Source code / logs\r\n[log.txt](https://github.com/dotnet/machinelearning/files/5337885/log.txt)\r\n'"
715893719,5418,"b""if all iterations are completed, I don't want to wait until the train-time reaches 0""","b'### System information\r\n\r\n- **Windows 10.0.19041**:\r\n- **.NET Core 3.1.402**: \r\n\r\n### Issue\r\n- **What did you do?**\r\nWith each command I need to specificy the train time. e.g.\r\n`mlnet regression --dataset ""Step2.csv"" --label-col ""Position"" --has-header true --train-time 3600 --cache on`\r\n- **What happened?**\r\nI noticed that there are max 70 iterations. If all the iterations are completed before the train-time ends, I have to wait untill it counts till 0 before it outputs the best iteration & generates the example code.\r\n- **What did you expect?**\r\nIf the max amount of iterations have been completed, the training should stop. There is no need to wait until the countdown goes to 0 while being idle.\r\n'"
713511415,5416,b'ShuffleRows is broken (again) in 1.5.2',"b""### System information\r\n\r\n- **OS version/distro**: Windows Server 2016\r\n- **.NET Version (eg., dotnet --info)**: .NET 4.8\r\n\r\n### Issue\r\n\r\nMy training tasks times exploded when going from 1.4 to 1.5.2 (from seconds to tens of hours). The culprit is ShuffleRows which is now extremely slow.\r\n\r\nShuffleRows was already broken in previous release (see issue #5312). The fix for that issue (#5313) is broken too in my opinion. It contains a line with a Thread.Sleep(1) to wait for async completion. This is a no go ... First the Sleep should not be there. And second, sleeping 1ms is dependent on timer resolution which is in general 15ms, so a wait will be in most cases 15ms. As my learning tasks read millions of datarows, this can not work and learning time explode to the point of being unusable. \r\n\r\nTo confirm that Thread.Sleep(1) is the culprit, I changed the timer resolution to 1ms on my server and learning time improved greatly but are still very far from the times I got with version 1.4. The fix for #5312 needs to be redone properly (sorry for being a bit harsh).\r\n\r\nSo ShuffleRows needs a fix, as I suspect this bug will impact many users. I'm not an async specialist so I can't fix the code myself.\r\n\r\n"""
711463242,5414,b'Can predictions be bounded?',b'**Describe Bug**\r\nPredicted values are outside of expected range. Is there a way to bound the predictions? Or set to a minimum value?\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nGenerate regression model using CLI and play with inputs\r\n'
711030632,5413,"b""retinanet-bbox/regression_submodel/pyramid_regression_1/Relu:0_nchwc' Status Message: Input channels C is not equal to kernel channels * group. C: 40 kernel channels: 256 group: 1""","b""### System information\r\n\r\n- windows8\r\n- .net core3.1\r\n\r\n### Issue\r\n\r\nI got a this issue \r\n\r\nbut I don't understand what it means ....\r\n\r\nhow can I change my code ? \r\n\r\nrelu is set by keras so I don't understand \r\n### Source code / logs\r\n\r\nretinanet-bbox/regression_submodel/pyramid_regression_1/Relu:0_nchwc' Status Message: Input channels C is not equal to kernel channels * group. C: 40 kernel channels: 256 group: 1\r\n"""
710396750,5412,b'Issue with Graph.def invalid for a tensorflow model',"b'Windows 10 latest\r\n.NET Core 3.1\r\n\r\nOpening savedmodel tensorflow pb file gives invalid Graph.def message.\r\n\r\nThe pb file is possible to open and view with this site:\r\nhttps://lutzroeder.github.io/netron/\r\n\r\nIt warns about huge model and it is huge with a complex network.\r\n\r\nWhen opening the file in ML.NET:\r\nLoadTensorFlowModel(<path>)  I get the message.\r\n\r\nI have opened another pb file ok so my environment is setup ok by this.\r\n\r\nI would like to get more info about what is wrong with the model file, to verify it before it is opened.\r\n\r\nIs there a verification tool or specification that could be matched to check the pb file, Thanks?\r\n'"
709087481,5411,b'DetectEntireAnomalyBySrCnn should not deseasonalize if given seasonal period = -1. Instead we see an error',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**:  1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nPassed seasonality period -1 into DetectEntireAnomalyBySrCnn\r\n\r\n- **What happened?**\r\nAn error was thrown\r\n\r\n- **What did you expect?**\r\nNo error, just for deseasonalizing to be skipped\r\n\r\n### Source code / logs\r\n![image](https://user-images.githubusercontent.com/69877427/94292232-88a0fc00-ff11-11ea-8c12-51557613e5a7.png)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
708562742,5410,b'SrCnnEntireAnomalyDetectorOptions should support Non-seasonal cases',"b""### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**: Ml.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Try to apply detect anomaly\r\n- **What happened?** We expect to use the SrCnnEntireAnomalyDetectorOptions for non-seasonal data, yet it gives an assertion that period cannot be negative. Shouldn't we gracefully ignore deseasonalize if period < 0?\r\n\r\n- **What did you expect?**  SrCnnEntireAnomalyDetectorOptions should support Non-seasonal cases\r\n\r\n### Source code / logs\r\n\r\nWe expect to use the SrCnnEntireAnomalyDetectorOptions for non-seasonal data, yet it gives an assertion that period cannot be negative. **Shouldn't we gracefully ignore deseasonalize if period < 0?** \r\n\r\n```\r\n       seasonalPeriod = mlContext.AnomalyDetection.DetectSeasonality(..)\r\n            var anomalyDetectorOptions = new SrCnnEntireAnomalyDetectorOptions()\r\n            {\r\n                DetectMode = detectMode,\r\n                Threshold = adjustThreshold,\r\n                Sensitivity = this.inputMetadata.Sensitivity,\r\n                Period =seasonalPeriod < 0  ? 0 : seasonalPeriod,\r\n            };\r\n```\r\n"""
706801803,5409,"b""It's happened at EstimatorChain.fit at asp.net web site with .net 4.7 and 4.8. The code works fine at Visual Studio 2019 with IIS express.""","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
706719927,5408,b'Ranking AutoML Sample',b'The [ML\xe2\x80\xa4NET samples repo](https://github.com/dotnet/machinelearning-samples) could use a ranking AutoML sample.\r\n\r\nCurrently there are AutoML samples for:\r\n* [Binary Classification sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/BinaryClassification_AutoML)\r\n* [MultiClass Classification sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/MulticlassClassification_AutoML)\r\n* [Regression sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/Regression_AutoML)\r\n* [Advanced experiment sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/AdvancedExperiment_AutoML)\r\n\r\nThese existing demos are missing how to use ranking in AutoML\xe2\x80\xa4NET.\r\n\r\nI would recommend basing on the [existing ranking sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/Ranking_Web) and converting it to an AutoML sample.'
706070373,5405,b'CustomMapping causes problem when used inside an Autodesk plugin',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  .NET framework 4.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI use [Normalize CustomMapping](https://github.com/dotnet/machinelearning-samples/blob/master/samples/modelbuilder/ImageClassification_Azure_LandUse/LandUseML.Model/NormalizeMapping.cs) for ONNX model \r\nWithout the mapping, everything works fine and it stills worked in development environment. The model, the way I load the model are the same.\r\n\r\n- **What happened?**\r\nWhen I load my application as a plugin for another application (with all of needed libraries), they always ask for missing library although they have been added (exact version). New libraries are asked each time but all of them are releated to ML.NET (Microsoft.ML.Transforms, System.Memory for eg.). I wonder if CustomMapping causes incompatibility in library version. \r\n- **What did you expect?**\r\nI can load library without errors.\r\n### Source code / logs\r\nThe code is basically the same as tutorial but I will show here for validation\r\n```\r\nMLContext mlContext = new MLContext();\r\nvar data = mlContext.Data.LoadFromEnumerable(new List<ImageData>());\r\nvar pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""image"", imageFolder: """", inputColumnName: nameof(ImageData.ImagePath))\r\n                    .Append(mlContext.Transforms.ResizeImages(outputColumnName: ModelSettings.ModelInput, imageWidth: ImageResNetSettings.imageWidth, imageHeight: ImageResNetSettings.imageHeight, inputColumnName: ""image""))\r\n                    .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ModelSettings.ModelInput))\r\n                    .Append(mlContext.Transforms.CustomMapping(new NormalizeMapping().GetMapping(), contractName: nameof(NormalizeMapping)))\r\n                    .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: modelLocation, outputColumnNames: new[] { ModelSettings.ModelOutput }, inputColumnNames: new[] { ModelSettings.ModelInput }));\r\nvar model = pipeline.Fit(data);\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(NormalizeMapping).Assembly);\r\nmlContext.Model.Save(model, data.Schema, _outputModelFilePath);\r\n```\r\n\r\n```Uri uri = new Uri(modelLocation, UriKind.Relative);\r\nStreamResourceInfo info = Application.GetResourceStream(uri);                  \r\ntrainedModel = mlContext.Model.Load(info.Stream, out DataViewSchema modelSchema);\r\n```\r\n'"
705720023,5403,b'System.Collections.Immutable  not found in .Net Framework 4.8 and ML.NET 1.5.1/1.5.2',"b'### System information\r\n\r\nWindows 10 Enterprise: Build:,19041.508\r\n\r\nMicrosoft Visual Studio Professional 2019, Version 16.7.3\r\nVisualStudio.16.Release/16.7.3+30503.244\r\nMicrosoft .NET Framework, Version 4.8.04084\r\n\r\n### Packages\r\n\r\n```\r\n<packages>\r\n  <package id=""Google.Protobuf"" version=""4.0.0-rc2"" targetFramework=""net48"" />\r\n  <package id=""LightGBM"" version=""3.0.0"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML.CpuMath"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML.DataView"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML.FastTree"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML.LightGbm"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Microsoft.ML.TensorFlow"" version=""1.5.1"" targetFramework=""net48"" />\r\n  <package id=""Newtonsoft.Json"" version=""12.0.3"" targetFramework=""net48"" />\r\n  <package id=""NumSharp"" version=""0.20.5"" targetFramework=""net48"" />\r\n  <package id=""NumSharp.Lite"" version=""0.1.8"" targetFramework=""net48"" />\r\n  <package id=""Protobuf.Text"" version=""0.4.0"" targetFramework=""net48"" />\r\n  <package id=""System.Buffers"" version=""4.5.1"" targetFramework=""net48"" />\r\n  <package id=""System.CodeDom"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Collections.Immutable"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.IO.FileSystem.AccessControl"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Memory"" version=""4.5.4"" targetFramework=""net48"" />\r\n  <package id=""System.Numerics.Vectors"" version=""4.6.0-preview5.19224.8"" targetFramework=""net48"" />\r\n  <package id=""System.Reflection.Emit.Lightweight"" version=""4.7.0"" targetFramework=""net48"" />\r\n  <package id=""System.Runtime.CompilerServices.Unsafe"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Security.AccessControl"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Security.Principal.Windows"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Threading.Channels"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Threading.Tasks.Dataflow"" version=""5.0.0-preview.8.20407.11"" targetFramework=""net48"" />\r\n  <package id=""System.Threading.Tasks.Extensions"" version=""4.5.4"" targetFramework=""net48"" />\r\n  <package id=""TensorFlow.NET"" version=""0.20.0-preview4"" targetFramework=""net48"" />\r\n</packages>\r\n```\r\n\r\n### Issue\r\n\r\nAfter upgrading to prerelease ML.NET 1.5.1, I am now getting the following error:\r\n\r\n```\r\nSystem.IO.FileLoadException: Could not load file or assembly \'System.Collections.Immutable, Version=1.2.3.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a\' or one of its dependencies. The located assembly\'s manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\r\nFile name: \'System.Collections.Immutable, Version=1.2.3.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a\'\r\n```\r\n\r\n\r\nAny help will be greatly appreciated.\r\n\r\nCharles\r\n'"
704892710,5402,b'Model generated by Object Detection does not work with Windows.AI.MachineLearning libraries',"b""Hi Team! Is this ML.NET's issue or WinML team's problem? Happy to close it here and open it there if it's the case.\r\n\r\n### System information\r\n\r\n- **Windows 10 / 19041.329*:\r\n- **UWP**: \r\n\r\n### Issue\r\n\r\n- **I tried to use the ONNX model created by ML.NET Object Detection (Azure ML)**\r\n- **I gave me an error**\r\n- **It must have worked fine**\r\n\r\n### Source code / logs\r\n\r\nHere's the issue I get; I have tried using last 3 builds and it works well with other ONNX models. \r\n\r\n![image](https://user-images.githubusercontent.com/16351038/93669522-30649700-fad8-11ea-9efa-1bb75339ffad.png)\r\n\r\n"""
704607241,5401,b'Upgrade TensorFlow to 2.3 / Tensorflow.NET to 0.20',"b""Hello,\r\nI'm opening this issue for our discussion around migrating our implementation of Image Classification to TF.NET 0.20. It's release is imminent and wanted to have a public place for the discussion.\r\n\r\nCheers,\r\nJake """
700895060,5397,"b""Can't use GPU""","b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- I tried to run the ""DeepLearning_ImageClassification_Training"" solution from the samples, the ImageClassification.Train project. Everything worked fine as expected. Then I tried to use the my GPU (Nvidia Quadro P400) to run it again. I did : \r\n     -> uninstalled the ""SciSharp.TensorFlow.Redist Nuget"" Package and installed the ""Windows-GPU"" one.\r\n     -> Installed CUDA V10 (cuda_10.0.130_411.31_win10) and Cudnn (cudnn-10.0-windows10-x64-v7.6.4.38) and put the cudnn dll in the CUDA bin folder.\r\n\r\n- The project still run correctly but does not use the Nvidia GPU at all and use the CPU.\r\n\r\n\r\n### Source code / logs\r\n\r\nLiterally this project : https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_Training/ImageClassification.Train\r\n\r\n\r\nThanks for your help ! :) '"
700216175,5394,b'SVM IndexOutOfRangeException',"b'### System information\r\n\r\n- CentOS 7.x(kernel 3.10.0-514.26.2.el7.x86_64)\r\n- .net core 2.1\r\n\r\n### Issue\r\n\r\ni use SVM to impl a classifier to test a short input text is AD. recently it throw Exception occasionally (both ML.NET 1.2 and 1.5.1).\r\n\r\n### Source code / logs\r\n\r\n```\r\nException:System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Internal.Utilities.Utils.CopyTo[T](List`1 src, Span`1 dst, Nullable`1 count)\r\n   at Microsoft.ML.Transforms.Text.WordTokenizingTransformer.Mapper.<>c__DisplayClass8_0.<MakeGetterOne>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer.BoundTermMap.Base`1.<>c__DisplayClass3_0.<GetMappingGetter>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.Text.NgramExtractingTransformer.Mapper.<>c__DisplayClass11_0.<MakeGetter>b__2(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.LpNormNormalizingTransformer.Mapper.<>c__DisplayClass8_0.<MakeGetter>b__5(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass20_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass19_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, DataViewRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Data.BinaryClassifierScorer.<>c__DisplayClass15_0.<GetPredictedLabelGetter>b__0(Single& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass10_0`1.<CreateDirectSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n```\r\n'"
699288573,5393,b'Error In Blazor When Creating Prediction Engine',"b'I have a problem with Blazor. I tried to do what\'s said in the documentation about loading existing model from remote source. (https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/save-load-machine-learning-models-ml-net)\r\n\r\nThis is what I came up with:\r\n\r\n```\r\n@page ""/analyzer""\r\n@inject HttpClient _client\r\n<h1>Analyzer</h1>\r\n\r\n<input class=""form-control"" @bind:event=""oninput"" @bind=""InputText""/>\r\n\r\n@if (InputText != null)\r\n{\r\n    <h1>@InputText</h1>\r\n}\r\n\r\n@code {\r\n    private string _inputText, mlPrediction;\r\n    DataViewSchema modelSchema;\r\n    MLContext mlContext = new MLContext();\r\n    public string InputText\r\n    {\r\n        get\r\n        {\r\n            return _inputText;\r\n        }\r\n        set\r\n        {\r\n            _inputText = value;\r\n            GetPrediction();\r\n        }\r\n    }\r\n    private PredictionEngine<ModelInput, ModelOutput> _predictionEngine;\r\n    protected override async Task OnInitializedAsync()\r\n    {\r\n        Stream modelFile = await _client.GetStreamAsync(""<MODEL.ZIP ENDPOINT>"");\r\n        ITransformer trainedModel = mlContext.Model.Load(modelFile, out modelSchema);\r\n        _predictionEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(trainedModel);\r\n    }\r\n    private void GetPrediction()\r\n    {\r\n        ModelInput mlInput = new ModelInput();\r\n        mlInput.Sentiment = InputText;\r\n        ModelOutput mlOutput = _predictionEngine.Predict(mlInput);\r\n        mlPrediction = mlOutput.Prediction;\r\n    }\r\n}\r\n```\r\n\r\nWhen I initialize the page, there was an error, and the only thing I understood is there is an error in line 32:\r\n`_predictionEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(trainedModel);`\r\n\r\nHere\'s the error message:\r\n```\r\nMicrosoft.AspNetCore.Components.WebAssembly.Rendering.WebAssemblyRenderer[100]\r\n      Unhandled exception rendering component: Exception has been thrown by the target of an invocation.\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.IO.FileNotFoundException: Could not load the file \'Microsoft.ML.Transforms, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\'.\r\n  at (wrapper managed-to-native) System.Reflection.RuntimeMethodInfo.InternalInvoke(System.Reflection.RuntimeMethodInfo,object,object[],System.Exception&)\r\n  at System.Reflection.RuntimeMethodInfo.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) <0x296c470 + 0x000ce> in <filename unknown>:0 \r\n   --- End of inner exception stack trace ---\r\n  at (wrapper managed-to-native) System.Reflection.RuntimeMethodInfo.InternalInvoke(System.Reflection.RuntimeMethodInfo,object,object[],System.Exception&)\r\n  at System.Reflection.RuntimeMethodInfo.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) <0x296c470 + 0x000ce> in <filename unknown>:0 \r\n   --- End of inner exception stack trace ---\r\n  at (wrapper managed-to-native) System.Reflection.RuntimeMethodInfo.InternalInvoke(System.Reflection.RuntimeMethodInfo,object,object[],System.Exception&)\r\n  at System.Reflection.RuntimeMethodInfo.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) <0x296c470 + 0x000ce> in <filename unknown>:0 \r\n   --- End of inner exception stack trace ---\r\n  at System.Reflection.RuntimeMethodInfo.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) <0x296c470 + 0x000f6> in <filename unknown>:0 \r\n  at System.Reflection.MethodBase.Invoke (System.Object obj, System.Object[] parameters) <0x296bd98 + 0x00014> in <filename unknown>:0 \r\n  at Microsoft.ML.Runtime.ComponentCatalog+LoadableClassInfo.CreateInstanceCore (System.Object[] ctorArgs) <0x545e428 + 0x000dc> in <filename unknown>:0 \r\n  at Microsoft.ML.Runtime.ComponentCatalog+LoadableClassInfo.CreateInstance (Microsoft.ML.Runtime.IHostEnvironment env, System.Object args, System.Object[] extra) <0x545e070 + 0x000c4> in <filename unknown>:0 \r\n  at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes] (Microsoft.ML.Runtime.IHostEnvironment env, System.Type signatureType, TRes& result, System.String name, System.String options, System.Object[] extra) <0x545d848 + 0x001c8> in <filename unknown>:0 \r\n  at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, System.String name, System.String options, System.Object[] extra) <0x545d488 + 0x00018> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, System.Object[] extra) <0x5365f30 + 0x00068> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, Microsoft.ML.RepositoryReader rep, Microsoft.ML.Repository+Entry ent, System.String dir, System.Object[] extra) <0x535cb38 + 0x00068> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, Microsoft.ML.RepositoryReader rep, Microsoft.ML.Repository+Entry ent, System.String dir, System.Object[] extra) <0x535c980 + 0x00038> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, Microsoft.ML.RepositoryReader rep, System.String dir, System.Object[] extra) <0x5351628 + 0x00064> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig] (Microsoft.ML.Runtime.IHostEnvironment env, TRes& result, Microsoft.ML.RepositoryReader rep, System.String dir, System.Object[] extra) <0x5351438 + 0x00034> in <filename unknown>:0 \r\n  at Microsoft.ML.ModelOperationsCatalog.Load (System.IO.Stream stream, Microsoft.ML.DataViewSchema& inputSchema) <0x5243828 + 0x000a0> in <filename unknown>:0 \r\n  at Deployments.Pages.SentimentAnalyzer2.OnInitializedAsync () [0x00096] in <PROJECTDIRECTORY>\\Pages\\SentimentAnalyzer2.razor:32 \r\n  at Microsoft.AspNetCore.Components.ComponentBase.RunInitAndSetParametersAsync () <0x2ecb9b0 + 0x0013a> in <filename unknown>:0 \r\n  at Microsoft.AspNetCore.Components.RenderTree.Renderer.GetErrorHandledTask (System.Threading.Tasks.Task taskToHandle) <0x31219d8 + 0x000b6> in <filename unknown>:0\r\n```\r\n\r\nIt seems like the real problem is: `System.IO.FileNotFoundException: Could not load the file \'Microsoft.ML.Transforms, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\'.`\r\n\r\nWhat workaround can I do to fix this?\r\n\r\nI tried getting the model from a cloud host and from wwwroot using GetStreamAsync. Both of their errors has to do with that line.'"
697528817,5391,b'please help me',"b'### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n- **The program runtime class is not created,Can I use a dynamic collection to build a DataView.**\r\n\r\n### Source code / logs\r\n```C#\r\nvar values = ConvertJson.DeserializeObject<List<Dictionary<string,string>>>(str);\r\nMLContext mlContext = new MLContext();\r\nvar builder = new DataViewSchema.Builder();\r\nbuilder.AddColumn(""Id"", TextDataViewType.Instance);\r\nbuilder.AddColumn(columns[1], NumberDataViewType.Int32);\r\nbuilder.AddColumn(columns[0], NumberDataViewType.Single);\r\nvar schema = builder.ToSchema();\r\nIDataView dataView = mlContext.Data.LoadFromEnumerable<Dictionary<string, string>>(values, schema);\r\n```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
694532943,5390,b'Implement different algorithms ',"b'Hi,\r\n\r\nI am student and looking to implement different algorithms regarding forecast to better understand the workings of it and later use them. Following are the algorithms: \r\n\r\n1. Linear Regression\r\n2. Ensemble methods (Random Forest Regression)\r\n3. XGBoost\r\n4. Long Short-Term Memory (artificial recurrent neural network)\r\n5. ARIMA Time Series Forecasting\r\n\r\nIs there any document or guidelines that can help me get started. \r\n\r\nThanks,\r\nAttiqe\r\n'"
694260267,5389,b'I need documentation translated to Chinese',b'\r\n[i need chinese]\r\n\r\n\r\n---\r\n#### \xe6\x96\x87\xe6\xa1\xa3\xe8\xaf\xa6\xe7\xbb\x86\xe4\xbf\xa1\xe6\x81\xaf\r\n\r\n\xe2\x9a\xa0 *\xe8\xaf\xb7\xe5\x8b\xbf\xe7\xbc\x96\xe8\xbe\x91\xe6\xad\xa4\xe9\x83\xa8\xe5\x88\x86\xe3\x80\x82 docs.microsoft.com \xe2\x9e\x9f GitHub \xe9\x97\xae\xe9\xa2\x98\xe9\x93\xbe\xe6\x8e\xa5\xe5\xbf\x85\xe9\xa1\xbb\xe5\x85\xb7\xe6\x9c\x89\xe6\xad\xa4\xe9\x83\xa8\xe5\x88\x86\xe3\x80\x82*\r\n\r\n* ID: ee2a2142-6919-89ca-2345-4d03b85dbb62\r\n* Version Independent ID: 33b41463-b4f4-68e6-3cd2-237177c396fa\r\n* Content: [Microsoft.ML.Transforms.Onnx Namespace](https://docs.microsoft.com/zh-cn/dotnet/api/microsoft.ml.transforms.onnx?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/ns-Microsoft.ML.Transforms.Onnx.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/ns-Microsoft.ML.Transforms.Onnx.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'
693584297,5388,b'Typo - anMicrosoft',"b'https://github.com/dotnet/machinelearning/blob/5370692f6d1e6f1f686596d530032b4226dc9e80/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L66\r\n\r\nTypo:\r\ndata: The enumerable data containing type TRow to convert to anMicrosoft.ML.IDataView .\r\n\r\nShould be:\r\ndata: The enumerable data containing type TRow to convert to an Microsoft.ML.IDataView.\r\n\r\n<img width=""625"" alt=""Screen Shot 2020-09-04 at 4 22 45 PM"" src=""https://user-images.githubusercontent.com/378671/92282080-f33eb900-eeca-11ea-87aa-c4d00817aaaa.png"">\r\n'"
693178229,5387,b'Image preprocessing in pipeline results in different prediction value then manual preprocessing',"b'### System information\r\n\r\n- **OS version/distro**:\r\n      Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n      .net Core 3.1\r\n- **ML.NET Version (eg., dotnet --info)**: \r\n      ML.NET 1.5.1\r\n### Issue\r\n\r\n- **What did you do?**\r\nWith my ML.NET code I load an existing TensorFlow Model for image classification and execute it for a single image. This I do in two different ways where the difference is how I generate the input data for the prediction.\r\nV1: Load bitmap with ""normal"" C# code and manually create the float array that is used for prediction directly.\r\nV2: Use ML.NET pipeline for preprocessing (Load image, resize, extract pixels) before it goes into prediction.\r\n\r\n- **What happened?**\r\nThe two variants result in different prediction values.\r\n\r\n- **What did you expect?**\r\nThe same prediction result for both variants.\r\n\r\n### Source code / logs\r\n\r\nThe model uses an image in float representation as input (image count, image height, image width, image channels)\r\n`Vector<Single, 275, 384, 3>`\r\nand returns as result a list of probabilities.\r\n\r\nThe test bitmap is a grayscale image with the same size like expected from the model (384x275).\r\n\r\nWhen the model is executed with python code following preprocessing is performed (load image, copy channel to generate a ""RGB"" image, extend the required 4th dimension)\r\n```\r\nimg = plt.imread(path_image)\r\nimg = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\r\nimg = np.expand_dims(img, axis=0)\r\n```\r\nWhen prediction is executed the best match is ~27,71%.\r\n\r\nThe same workflow I implemented with ML.NET. The classify method simply writes the results in console window.\r\n```\r\nvar image = new Bitmap(_predictSingleImagePath);\r\nvar floatImage = VerySlowBitmapTo1dFloatArrayConverter(image);\r\n\r\nMLContext mlContextV1 = new MLContext();\r\nITransformer modelV1 = GenerateModelV1(mlContextV1);\r\nClassifySingleImageV1(mlContextV1, modelV1, floatImage);\r\n```\r\n\r\nFor preprocessing I extract pixel values in a very easy way and ""convert and copy"" them to my 1d float representation of the image.\r\n```\r\nprivate static float[] VerySlowBitmapTo1dFloatArrayConverter(Bitmap image)\r\n{\r\n    List<float> floatImage = new List<float>();\r\n\r\n    for (int row = 0; row < image.Height; ++row)\r\n    {\r\n        for (int column = 0; column < image.Width; ++column)\r\n        {\r\n             var pixelValues = image.GetPixel(column, row);\r\n             floatImage.Add(pixelValues.R / 255.0f);\r\n             floatImage.Add(pixelValues.G / 255.0f);\r\n             floatImage.Add(pixelValues.B / 255.0f);\r\n        }\r\n    }\r\n\r\n    return floatImage.ToArray();\r\n }\r\n```\r\n\r\nAfter loading the model I create a pipeline that just contains the execution of the model.\r\n```\r\npublic static ITransformer GenerateModelV1(MLContext mlContext)\r\n{\r\n    IDataView trainingData = mlContext.Data.LoadFromEnumerable(new List<ImageDataV1>());\r\n           \r\n    var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(_TensorFlowModel);\r\n           \r\n    IEstimator<ITransformer> pipeline = tensorFlowModel.ScoreTensorFlowModel(outputColumnNames: new[] { ""StatefulPartitionedCall"" }, inputColumnNames: new[] { ""serving_default_input_4"" }, addBatchDimensionInput: false);\r\n                                            \r\n    ITransformer model = pipeline.Fit(trainingData);\r\n\r\n    return model;\r\n}\r\n```\r\n\r\nFinally I perform a prediction and write the result to console.\r\n```\r\npublic static void ClassifySingleImageV1(MLContext mlContext, ITransformer model, float[] image)\r\n{\r\n    var imageData = new ImageDataV1()\r\n    {\r\n        Image = image\r\n    };\r\n\r\n    var predictor = mlContext.Model.CreatePredictionEngine<ImageDataV1, ImagePrediction>(model);\r\n    var prediction = predictor.Predict(imageData);\r\n\r\n    Console.WriteLine($""Image predicted with score: {prediction.Scores.Max()} "");\r\n\r\n    foreach(var score in prediction.Scores)\r\n    {\r\n        Console.WriteLine(score.ToString());\r\n    }\r\n}\r\n\r\npublic class ImageDataV1\r\n{\r\n    [LoadColumn(0), ColumnName(""serving_default_input_4""), VectorType(316800)]\r\n    public float[] Image;\r\n}\r\n\r\npublic class ImagePrediction\r\n{\r\n    [ColumnName(""StatefulPartitionedCall"")]\r\n    public float[] Scores;\r\n}\r\n```\r\nWith this code I get as best match the value 0,27709773, so ~27,71% like the python version.\r\n\r\n\r\n\r\nSo far so good. Now I make the same but instead of the manual image handling I use pipeline methods.\r\n\r\nSame workflow, just with different method calls.\r\n```\r\nMLContext mlContextV2 = new MLContext();\r\nITransformer modelV2 = GenerateModelV2(mlContextV2);\r\nClassifySingleImageV2(mlContextV1, modelV2);\r\n```\r\nAlso model execution is quite the same.\r\n```\r\npublic static void ClassifySingleImageV2(MLContext mlContext, ITransformer model)\r\n{\r\n    var imageData = new ImageDataV2()\r\n    {\r\n        ImagePath = _predictSingleImagePath\r\n    };\r\n\r\n    var predictor = mlContext.Model.CreatePredictionEngine<ImageDataV2, ImagePrediction>(model);\r\n    var prediction = predictor.Predict(imageData);\r\n\r\n    Console.WriteLine($""Image: {Path.GetFileName(imageData.ImagePath)} predicted with score: {prediction.Scores.Max()} "");\r\n\r\n    foreach (var score in prediction.Scores)\r\n    {\r\n        Console.WriteLine(score.ToString());\r\n    }\r\n}\r\n```\r\nThe difference is the used pipeline.\r\nI load the image from the given path.\r\nThen I ""resize"" the image the get a ""known-size image"".\r\nFinal preprocessing step is to get float values from the bitmap.\r\n```\r\npublic static ITransformer GenerateModelV2(MLContext mlContext)\r\n{\r\n    IDataView trainingData = mlContext.Data.LoadFromEnumerable(new List<ImageDataV2>());\r\n\r\n    var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(_TensorFlowModel);\r\n\r\n    IEstimator<ITransformer> pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""serving_default_input_4"", imageFolder: _imagesFolder, inputColumnName: nameof(ImageDataV2.ImagePath));\r\n    pipeline = pipeline.Append(mlContext.Transforms.ResizeImages(outputColumnName: ""serving_default_input_4"", imageWidth: ImageSettings.ImageWidth, imageHeight: ImageSettings.ImageHeight, inputColumnName: ""serving_default_input_4""));\r\n    pipeline = pipeline.Append(mlContext.Transforms.ExtractPixels(\r\n                                                        outputColumnName: ""serving_default_input_4"",\r\n                                                        inputColumnName: ""serving_default_input_4"",\r\n                                                        interleavePixelColors: false,\r\n                                                        offsetImage: 0,\r\n                                                        colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Rgb,\r\n                                                        orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB,\r\n                                                        scaleImage: 1,\r\n                                                        outputAsFloatArray: true));\r\n    pipeline = pipeline.Append(tensorFlowModel.ScoreTensorFlowModel(outputColumnNames: new[] { ""StatefulPartitionedCall"" }, inputColumnNames: new[] { ""serving_default_input_4"" }, addBatchDimensionInput: false));                   \r\n                    \r\n    ITransformer model = pipeline.Fit(trainingData);\r\n\r\n    return model;\r\n}\r\n\r\npublic class ImagePrediction\r\n{\r\n    [ColumnName(""StatefulPartitionedCall"")]\r\n    public float[] Scores;\r\n}\r\n\r\npublic class ImageDataV2\r\n{\r\n    [LoadColumn(0)]\r\n    public string ImagePath;\r\n}\r\n```\r\nWith this pipeline I get a best match of ~49,79%. Quite different from the other implementation. I played a little bit with parameters but was not even close to 27%.\r\n\r\nSome suggestion what I\'m doing wrong in preprocessing part of the pipeline?\r\n\r\nI searched for information how I can check the interim results from the pipeline to further trace down the difference. Unforunately I didn\'t find something that helps me (only things about schemas). Does anybody know some useful documentation/tutorial regarding that topic?\r\n\r\nThanks and regards'"
692940167,5385,b'Using OnnxTransformer throws TypeInitializationException',"b'This issue is a duplicate of https://github.com/dotnet/machinelearning/issues/5262 which was closed until further feedback was provided. Feedback was provided but haven\'t received any activity. I don\'t know how to notify properly to get it reopened. IMO, the best course of action is to reopen that issue and close this. Sorry for any inconvenience.\r\n\r\n### System information\r\n\r\n- **OS version/distro**: Windows 7\r\n- **.NET Version (eg., dotnet --info)**: core 3.1\r\n\r\n### Issue\r\nWhen trying to use OnnxTransformer, the native libraries aren\'t loaded properly. I can see them under bin\\Debug\\netcoreapp3.1\\runtimes\\(platform)\\native.\r\nIf I use package version 1.4.0 of OnnxTransformer, without installing the runtime myself, it works.\r\nI couldn\'t find any docs regarding the requirement to install the runtime manually (I figured it out by browsing all over the place, but not through docs really). I suppose this should be clear when you\'re not using the onnxruntime package explicitly, but rather the higher level API of OnnxTransformer?\r\n\r\nOn a separate note: Is it sufficient to install the GPU natives and use the `fallbackToCpu` flag of `ApplyOnnxModel` to be able to run inferencing on both CPU and GPU? I\'m having a hard time finding this documented.\r\n\r\n- **What did you do?**\r\nInstalled `Microsoft.ML.OnnxTransformer` 1.5.0 and `Microsoft.ML.OnnxRuntime` 1.3.0 and used `ApplyOnnxModel` in a pipeline.\r\n\r\n- **What happened?**\r\nCalling `ApplyOnnxModel` throws `System.TypeInitializationException`.\r\n\r\n- **What did you expect?**\r\nThat my ONNX model can be used.\r\n\r\n### Source code / logs\r\nInner exception message:\r\n\r\n""Unable to load DLL \'onnxruntime\' or one of its dependencies: The specified module could not be found. (0x8007007E)""\r\n'"
691555762,5384,b'States that TextFeaturizingEstimator handles TF-IDF',"b'\r\n[Enter feedback here]\r\nNot seeing any reference to how to set TF, IDF or TF-IDF options. Are you sure TextFeaturizingEstimator actually uses that algorithm?\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: deeb31e0-6843-e9ae-e6ad-028c4ec9121b\r\n* Version Independent ID: bf1e4b11-7652-7da4-4791-aa2d9488971c\r\n* Content: [TextFeaturizingEstimator Class (Microsoft.ML.Transforms.Text)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.text.textfeaturizingestimator?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms.Text/TextFeaturizingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms.Text/TextFeaturizingEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
691266607,5383,b'Question about predictor output: Score and PredictedLabel columns',"b""Using the linear svm algorithm in ML.NET I am trying to get the probability that a prediction is in a certain class. However, probability is never outputted and according to this GitHub issue (https://github.com/dotnet/machinelearning/issues/376#issuecomment-399282699), a regression SVM doesn't output probability.\r\n\r\nIs there something I am missing or is getting the probability of a linear svm prediction possible in ML.Net?\r\n"""
690797243,5382,b'LightGbm System.InvalidOperationException after the latest update',"b'### System information\r\n\r\n- Win10/x64\r\n- .Net 4.8\r\n\r\n### Issue\r\n\r\n- It crashes in this line var model = pipeline.Fit(trainData); \r\n- I get this error: System.InvalidOperationException: \'LightGBM Error, code is -1, error message is \'Unknown importance type: only support split=0 and gain=1\'.\'\r\n\r\nWith the previous version everything worked fine and nothing was modified in my source code since it worked.\r\n\r\nThis is my gbm setting \r\n.Append(mlContext.Regression.Trainers.LightGbm(""PercentPredict"", ""Features"",null,null,null,null,200));\r\n\r\n'"
690022657,5381,"b'AutoML Ranking Error: ""RankingMetrics Not Implemented""'","b'When running the Ranking AutoML experiment on [this data](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTrain720kRows.tsv) from the Ranking sample, I seem to get a `Metric Microsoft.ML.Data.RankingMetrics not implemented` error during the `Execute` method.\r\n\r\nI\'m probably doing something wrong but I\'m not sure what I\'m missing.\r\n\r\n```csharp\r\nvar context = new MLContext();\r\n\r\nvar data = context.Data.LoadFromTextFile<RankingData>(""./ranking.tsv"", separatorChar: \'\\t\');\r\n\r\nvar settings = new RankingExperimentSettings\r\n{\r\n      MaxExperimentTimeInSeconds = 300,\r\n      OptimizingMetric = RankingMetric.Ndcg\r\n};\r\n\r\nvar experiment = context.Auto().CreateRankingExperiment(settings);\r\n\r\nvar results = experiment.Execute(data);\r\n```\r\n\r\nHere\'s the [full code](https://github.com/jwood803/MLNetExamples/blob/master/MLNetExamples/AutoMLRanking/Program.cs), if needed.'"
689561257,5379,b'[AnomalyDetection] confidence bound should include non-anomaly points',"b'### System information\r\n\r\n- **OS version/distro**: ML.Net 1.5.1\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nWe use the API `DetectEntireAnomalyBySrCnn`\r\n\r\n- **What happened?**\r\n\r\nWe see some points are outside of the confidence bound yet not detected as anomalies. This is a bit confusing on why these points are not anomalies.\r\n\r\n![image](https://user-images.githubusercontent.com/3010893/91775351-b8bddf00-eb9f-11ea-9bad-c2ab02d08601.png)\r\n\r\n- **What did you expect?**\r\n\r\nThe non-anomaly points should be included in the confidence bound.\r\n\r\n### Source code / logs\r\n\r\nPR: #5374 \r\n\r\nProposed change: Adjust the confidence bound so that it includes the non-anomaly points\r\n![image](https://user-images.githubusercontent.com/3010893/91775507-10f4e100-eba0-11ea-86e1-621b1f5dafd9.png)\r\n\r\n\r\n'"
689283644,5377,"b'LoadFromTextFile<ModelInput>(""./data/*"") - System.ArgumentOutOfRangeException: File does not exist at path'","b'### System information\r\n\r\n- **OS version/distro**:macOS 10.15.6\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET SDK (reflecting any global.json):\r\n Version:   5.0.100-preview.8.20417.9\r\n Commit:    fc62663a35\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.15\r\n OS Platform: Darwin\r\n RID:         osx.10.15-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/5.0.100-preview.8.20417.9/\r\n\r\nHost (useful for support):\r\n  Version: 5.0.0-preview.8.20407.11\r\n  Commit:  bf456654f9\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFollow this instruction: https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/load-data-ml-net#load-from-files-in-a-single-directory\r\n- **What happened?**\r\n`Unhandled exception. System.ArgumentOutOfRangeException: File does not exist at path: ./data/* (Parameter \'path\')`\r\n- **What did you expect?**\r\nI expected to load the files from the directory.\r\n\r\n### Source code / logs\r\n```c#\r\nvar mlContext = new MLContext();\r\n\r\nvar loader = mlContext.Data.CreateTextLoader<ModelInput>();\r\n\r\n//THIS WORK\r\nvar d = loader.Load(""./data/*"");\r\n\r\n//THIS DOESN\'T\r\nvar data = mlContext.Data.LoadFromTextFile<ModelInput>(""./data/*"");\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
689178366,5376,"b'ApplyOnnxModel with parameter ONNX model as byte[] is missing, why?'","b'Hi, \r\n\r\nin ONNX Runtime exists possibility to create session from byte array like this. \r\n**public InferenceSession(byte[] model);**\r\nWhy is such a possibility missing in ML.Net OnnxCatalog.ApplyOnnxModel method.\r\nApplyOnnxModel allows only:\r\n**ApplyOnnxModel ( ... string modelFile ...)**\r\nI think it would make definitely sense. Becouse it would allow loading onnx model direct from database and not only from file system.\r\nIs this planed for the future release? Or is there any workaround or some reason why is it not implemented?\r\nI would be happy for any comments. '"
689077007,5375,"b""Error NETSDK1032: The RuntimeIdentifier platform 'browser-wasm' and the PlatformTarget 'x64' must be compatible""","b'---\r\n**Issue moved from dotnet/runtime#41556**\r\n- Please respond to @andersson09.\r\n\r\n---\r\n\r\n_From @andersson09 on Saturday, August 29, 2020 6:14:29 PM_\r\n\r\n<!--This is just a template - feel free to delete any and all of it and replace as appropriate.-->\r\n\r\n### Description\r\n\r\nI want to run **Microsoft.ML 1.5.1** in Blazor. When running the application (dotnet run) I get:\r\n""Microsoft.ML currently supports \'x64\' and \'x86\' processor architectures. Please ensure your application is targeting \'x64\' or \'x86\'"". \r\n\r\nIf I add <PlatformTarget>x64</PlatformTarget> to csproj to fix the above issue I receive:\r\n""Error NETSDK1032: The RuntimeIdentifier platform \'browser-wasm\' and the PlatformTarget \'x64\' must be compatible.""\r\n\r\n<!--\r\n* Please share a clear and concise description of the problem.\r\n* Include minimal steps to reproduce the problem if possible. E.g.: the smallest possible code snippet; or a small repo to clone, with steps to run it.\r\n* What behavior are you seeing, and what behavior would you expect?\r\n  -->\r\n\r\n### Configuration\r\n\r\n5.0.100-preview.8.20417.9\r\nWindows 10\r\n\r\n<!--\r\n* Which version of .NET is the code running on?\r\n* What OS and version, and what distro if applicable?\r\n* What is the architecture (x64, x86, ARM, ARM64)?\r\n* Do you know whether it is specific to that configuration?\r\n  -->\r\n\r\n### Regression?\r\n\r\nThis used to work fine with Blazor 3.2.1. \r\n\r\n<!--\r\n* Did this work in a previous build or release of .NET Core, or from .NET Framework? If you can try a previous release or build to find out, that can help us narrow down the problem. If you don\'t know, that\'s OK.\r\n  -->\r\n\r\n### Other information\r\n\r\n<!--\r\n* Please include any relevant stack traces or error messages. If possible please include text as text rather than images (so it shows up in searches).\r\n* If you have an idea where the problem might lie, let us know that here. Please include any pointers to code, relevant changes, or related issues you know of.\r\n* Do you know of any workarounds?\r\n  -->\r\n'"
688744357,5372,b'[Proposal] Create Keras Neural Network Like API in C# (Create Survey First)',"b""In the Last ML.NET Community Standup, we discussed the possibility of having a Keras Like API in C#. [(YouTube Talk Link) ](https://youtu.be/2gjMrZ9XbRQ?t=3339)\r\n\r\nThe goal is to have similar native C# API that can also take advantage of GPU and also being independent of Tensorflow Binding for DotNet for better performance scenarios.\r\n\r\nKeras is simple and easy to use, Keras API in Python looks like this\r\n```python\r\nnetwork = models.Sequential()\r\nnetwork.add(layers.Dense(784, activation='relu', input_shape=(28 * 28,)))\r\nnetwork.add(layers.Dense(784, activation='relu', input_shape=(28 * 28,)))\r\nnetwork.add(layers.Dense(10, activation='softmax'))\r\nnetwork.compile(optimizer='adam',\r\n                loss='categorical_crossentropy',\r\n                metrics=['accuracy'])\r\n```\r\n\r\n\r\nMost of us are aware of the community bindings and libraries like Tensorflow.Net etc to name a few but for high-performance scenarios, these libraries seem to struggle (i guess mainly due to Interop Cost)\r\n\r\nIn my case, with Unity Engine using  MLAgent which also depend on TF(Tensorflow).\r\nNow in Unity for vision-based experiments ie. with convolutional NN based problems, Unity struggles a bit because each frame of the game they need to send pixel data to TF, which is performance costly, now if we had a similar good implementation of Neural Network in C#,  Unity can also get performance improvements around 2 to 4 times (maybe), at least in iteration times.\r\n\r\n### I request ML.NET  Team to create a survey regarding this, so we can share our challenges and use cases and necessity to have a Keras like API.\r\n\r\nThank You."""
688640817,5371,b'Cursor class attempts to access an private class member',"b'\r\n[Enter feedback here]\r\nThe Cursor class that is showed in the code preview attempts to access the private member ""parent._data"" from it\'s constructor.\r\n```\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: cebd0074-01d3-d048-305a-cfea8b4083de\r\n* Version Independent ID: 7f1aaf72-e345-e334-6237-d92abd3aa6d3\r\n* Content: [IDataView Interface (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/IDataView.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/IDataView.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
688361399,5370,"b'PredictionEnginePool uses ObjectPool which is not supported on .Net Framework 4.6.2, can we get PredictionEnginePool support for .Net Framework 4.6.2 '","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
688233225,5369,b'Enable access to preloaded data in primitive data types',"b""I have been using the Accord.Net framework for some time and would like to run it side-by-side with ML.NET in my application. In my application the data exists in memory as a 2D array ```double[,]```. Headings are kept as a separate 1D string array. It would be easy enough to convert to a jagged array or to a .NET DataTable (which I do in various instances for Accord). \r\n\r\nHowever, there does not appear to be any easy way to load the data to ML.NET this way. I've looked at ```mlContext.Data.LoadFromEnumerable``` but it appears that is looking for objects not raw data. It would be massively inefficient to convert the raw data to this approach.\r\n\r\nI'm a newbie to ML.NET so if I'm missing something, my apologies. \r\n\r\n\r\n"""
687543949,5368,b'Fix API reference snippets',"b""The API reference repository doesn't have issues turned on, so I think it might be suitable here, especially that the broken snippet references used to exist in this repository, but now they don't (or moved somewhere that I can't find).\r\n\r\nSee https://github.com/dotnet/ml-api-docs/pull/142 for details.\r\n\r\ncc: @luisquintanilla """
687530449,5367,"b""Method not found: 'Tensorflow.Tensor Tensorflow.tensorflow.truncated_normal(Int32[], Single, Single, Tensorflow.TF_DataType, System.Nullable`1<Int32>, System.String)'.""","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version 2019 (eg., dotnet --info)**: \r\n-**.Net Framework 4.8\r\n \r\n### Issue\r\ni am not able to Train a Model using C# with MulticlassClassification.Trainers.ImageClassification iam getting below error message\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\n  var options = new ImageClassificationTrainer.Options()\r\n            {\r\n                FeatureColumnName = ""Image"",\r\n                LabelColumnName = ""Label"",\r\n\r\n                Arch = ImageClassificationTrainer.Architecture.ResnetV2101,\r\n                Epoch = 50,\r\n                BatchSize = 10,\r\n                LearningRate = 0.01f,\r\n                MetricsCallback = (metrics) => Console.WriteLine(metrics),\r\n                ValidationSet = testDataset,\r\n                 EarlyStoppingCriteria = new ImageClassificationTrainer.EarlyStopping(minDelta: 0.001f, patience: 20, metric: ImageClassificationTrainer.EarlyStoppingMetric.Loss)\r\n            };\r\n \r\n            var pipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(options)\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: ""PredictedLabel"", inputColumnName: ""PredictedLabel""));\r\n\r\n            var trainedModel = pipeline.Fit(trainDataset);\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n*****************************************************Error  StackTrace****************************************************\r\nSystem.MissingMethodException\r\n  HResult=0x80131513\r\n  Message=Method not found: \'Tensorflow.Tensor Tensorflow.tensorflow.truncated_normal(Int32[], Single, Single, Tensorflow.TF_DataType, System.Nullable`1<Int32>, System.String)\'.\r\n  Source=Microsoft.ML.Vision\r\n  StackTrace:\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.<>c__DisplayClass64_1.<AddFinalRetrainOps>b__4(NameScope <p0>)\r\n   at Tensorflow.Binding.tf_with[T](T py, Action`1 action)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.<>c__DisplayClass64_0.<AddFinalRetrainOps>b__1(NameScope scope)\r\n   at Tensorflow.Binding.tf_with[T](T py, Action`1 action)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.AddFinalRetrainOps(Int32 classCount, String labelColumn, String scoreColumnName, Tensor bottleneckTensor, Boolean isTraining, Boolean useLearningRateScheduler, Single learningRate)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.AddTransferLearningLayer(String labelColumn, String scoreColumnName, Single learningRate, Boolean useLearningRateScheduling, Int32 classCount)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at VWS.ML.API.VWSTrainObjectDetectionAdvancedOptions.CreateImagepipeline() in G:\\Automation\\3.Projects\\VS 2017\\Utility\\VWSMLStudio\\VWS.ML.API\\VWSImageClassification.cs:line 377\r\n   at VWS.ML.API.VWSImageClassification.TrainData(IDataView loadImageData1, String GetInputPath, String GetModelPath, String FeatureColumnName, String ScoreColumnName, String PredictedLabelColumnName, String LabelColumnName) in G:\\Automation\\3.Projects\\VS 2017\\Utility\\VWSMLStudio\\VWS.ML.API\\VWSImageClassification.cs:line 702\r\n   at ConsoleML.Program.Main(String[] args) in G:\\Automation\\3.Projects\\VS 2017\\Utility\\VWSMLStudio\\ConsoleML\\Program.cs:line 20\r\n\r\n\r\n'"
687430294,5366,b'Issue when providing custom gains to LightGbmRanking',"b'### System information\r\n\r\n- **OS version/distro**: Not sure, running on AML Compute.\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nI am using the command line interface to train a LightGbmRanking model using a pre-defined set of custom gains. Full command is:\r\n_dotnet /mlnet/MML.dll TrainTest tr=LightGBMRanking{iter=500 customGains=""0,82,189,435,1000""} loader=TextLoader{col=SessionGuid:TX:0 col=Features:R4:5-47 col=Label:R4:225} xf=HashTransform{col=GroupId:SessionGuid} data=inputs/train.tsv test=inputs/test.tsv out=outputs/model.zip dout=outputs/pred.tsv\r\nmaml.exe TrainTest test=inputs/test.tsv tr=LightGBMRanking{iter=500 customGains=""0,82,189,435,1000""} dout=outputs/pred.tsv loader=TextLoader{col=SessionGuid:TX:0 col=Features:R4:5-47 col=Label:R4:225} data=inputs/train.tsv out=outputs/model.zip xf=HashTransform{col=GroupId:SessionGuid}_\r\n\r\n- **What happened?**\r\nCommand fails suggesting my custom gains are invalid. Full output:\r\n_\'0,82,189,435,1000\' is not a valid value for the \'customGains\' command line option\r\nUsage For \'LightGBMRanking\':\r\ncustomGains=<int>\r\n     An array of gains associated to each relevance label. Default value:\'0, 3,\r\n     7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095\' (short form gains)\r\nsigmoid=<double>\r\n     Parameter for the sigmoid function. Default value:\'0.5\'\r\nevaluationMetric=[None|Default|MeanAveragedPrecision|NormalizedDiscountedCumulativeGain]\r\n     Evaluation metrics. Default value:\'NormalizedDiscountedCumulativeGain\'\r\n     (short form em)\r\nnumberOfIterations=<int>\r\n     Number of iterations. Default value:\'100\' (short form iter)\r\nlearningRate=<double>\r\n     Shrinkage rate for trees, used to prevent over-fitting. Range: (0,1].\r\n     (short form lr)\r\nnumberOfLeaves=<int>\r\n     Maximum leaves for trees. (short form nl)\r\nminimumExampleCountPerLeaf=<int>\r\n     Minimum number of instances needed in a child. (short form mil)\r\nmaximumBinCountPerFeature=<int>\r\n     Maximum number of bucket bin for features. Default value:\'255\' (short form\r\n     mb)\r\nbooster=<name>{<options>}\r\n     Which booster to use, can be gbtree, gblinear or dart. gbtree and dart use\r\n     tree based model while gblinear uses linear function. Default value:\'gbdt\'\r\nverbose=[+|-]\r\n     Verbose Default value:\'-\' (short form v)\r\nsilent=[+|-]\r\n     Printing running messages. Default value:\'+\'\r\nnumberOfThreads=<int>\r\n     Number of parallel threads used to run LightGBM. (short form nt)\r\nearlyStoppingRound=<int>\r\n     Rounds of early stopping, 0 will disable it. Default value:\'0\' (short form\r\n     es)\r\nuseCategoricalSplit=[+|-]\r\n     Enable categorical split or not. (short form cat)\r\nhandleMissingValue=[+|-]\r\n     Enable special handling of missing value or not. Default value:\'+\' (short\r\n     form hmv)\r\nuseZeroAsMissingValue=[+|-]\r\n     Enable usage of zero (0) as missing value. Default value:\'-\' (short form\r\n     uzam)\r\nminimumExampleCountPerGroup=<int>\r\n     Minimum number of instances per categorical group. Default value:\'100\'\r\n     (short form mdpg)\r\nmaximumCategoricalSplitPointCount=<int>\r\n     Max number of categorical thresholds. Default value:\'32\' (short form\r\n     maxcat)\r\ncategoricalSmoothing=<double>\r\n     Lapalace smooth term in categorical feature spilt. Avoid the bias of small\r\n     categories. Default value:\'10\'\r\nl2CategoricalRegularization=<double>\r\n     L2 Regularization for categorical split. Default value:\'10\'\r\nseed=<int>\r\n     Sets the random seed for LightGBM to use.\r\nparallelTrainer=<name>{<options>}\r\n     Parallel LightGBM Learning Algorithm Default value:\'Single\' (short form\r\n     parag)\r\n@<file>\r\n     Read response file for more options\r\nError log has been saved to \'/tmp/TLC/Error_20200826_065457_be780834-d247-476d-bb18-e336a332d1eb.log\'. Please refer to https://aka.ms/MLNetIssue if you need assistance._\r\n- **What did you expect?**\r\nCustom gains provided are a list of integers, as suggested in the input. Not clear on what is the expected input pattern here beyond that.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
686202441,5365,b'Add re-training support for MatrixFactorization.',"b'When my dataset is large, retraining will take a lot of time.Is there any way add new training data to improve the model, not retrain all the data.'"
685321623,5364,"b'ML.Net - The first dimension of paddings must be the rank of inputs[4,2] [1,1,320,320,3]'","b'System information\r\nOS version/distro: Windows 10 Pro\r\n.NET Version (eg., dotnet --info): dotnet framework 4.7\r\nIssue :\r\nWe are working on how to consume the tensorflow model in .Net using ML.NET. We are using below tutorial as reference :\r\n\r\nTutorial Link : https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification\r\n\r\nWe tested with model that is used in the Tutorial and it worked fine. But, when we replace tutorial model with our tensorflow model (object detection model which we have exported from Azure Custom Vision), it is throwing an Exception saying -TensorflowException: The first dimension of paddings must be the rank of inputs[4,2] [1,1,320,320,3] [[{{node conv1/pad_size}}]]\r\nThe same custom vision model works fine when consumed in Python code.\r\n\r\nSource code / logs\r\nDetails:\r\n\r\nProject Name : TransferLearningTF\r\nClass name : program.cs\r\nMethod Name : GenerateModel\r\n\r\nCode :\r\n\r\n  IEstimator<ITransformer> pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""image_tensor"", imageFolder: _imagesFolder, inputColumnName: nameof(ImageData.ImagePath))\r\n                .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""image_tensor"", imageWidth: InceptionSettings.ImageWidth, imageHeight: InceptionSettings.ImageHeight, inputColumnName: ""image_tensor""))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""image_tensor""))\r\n                .Append(mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel)\r\n                .ScoreTensorFlowModel(outputColumnNames: new[] { ""detected_boxes"", ""detected_scores"", ""detected_classes"" }, inputColumnNames: new[] { ""image_tensor"" }, addBatchDimensionInput: true))            \r\n                .AppendCacheCheckpoint(mlContext);\r\n\t\t\t\t\r\n\t\t\tIDataView trainingData = mlContext.Data.LoadFromTextFile<ImageData>(path: _trainTagsTsv, hasHeader: false);\r\n            ITransformer model = pipeline.Fit(trainingData);\r\n            IDataView testData = mlContext.Data.LoadFromTextFile<ImageData>(path: _testTagsTsv, hasHeader: false);\r\n            IDataView predictions = model.Transform(testData);\r\n            IEnumerable<ImagePrediction> imagePredictionData = mlContext.Data.CreateEnumerable<ImagePrediction>(predictions, true);\r\n\r\nException Details :\r\n\r\nTensorflowException: The first dimension of paddings must be the rank of inputs[4,2] [1,1,320,320,3]\r\n                [[{{node conv1/pad_size}}]]\r\n\r\n'"
684630916,5362,"b'Automl.net version 0.17.1, training a Binary Classification model returns misleading quality metrics'","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nThe AutoMl Api, stops after one iteration when training a Binary Classification, and the best run model score is set to 1. Therefore, the quality metric always set to prefect values which are misleading. \r\n\r\n- **What happened?**\r\n\r\n// Deugging the source code, I can see  if model is perfect, break\r\nif (_metricsAgent.IsModelPerfect(suggestedPipelineRunDetail.Score))\r\n{\r\n   break;\r\n}\r\n\r\nsuggestedPipelineRunDetail. The score is always 1\r\n\r\n\r\nTrainer                                            Accuracy      AUC    AUPRC  F1-score  Duration\r\n1    AveragedPerceptronBinary        1.0000   1.0000   1.0000    1.0000       0.5\r\n\r\n- **What did you expect?**\r\n\r\n if you run with ML.Net for the same training dataset:\r\n\r\nAccuracy       AUC            F1-Score       Positive Precision  Positive Recall     Negative Precision  Negative Recall\r\n52.26%         52.86%         0.82%          1.00                0.00                0.52                100.00%\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
684106075,5361,b'Second time prediction using PredictionEngine in ML.Net throws SEHException in Azure Function deployed to Cloud. Works fine locally.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 64 bit\r\n- **.NET Version (eg., dotnet --info)**: \r\nC:\\Users\\praghuvanshi>dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.401\r\n Commit:    5b6f5e5005\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19041\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.401\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.7\r\n  Commit:  fcfdef8d6b\r\n\r\n.NET Core SDKs installed:\r\n  3.1.401 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.21 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.21 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.21 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI am working on a sample image classification problem of classifying dog and cat. I have used AutoML for Image Classification with 10 images each of cat and dog and generated the model(MLModel.zip~93MB) and c# code. ... I have been successful in loading the model in a function app locally and it works flawlessly giving the predictions properly. Source code attached.\r\n\r\nSteps: \r\n- Create Image Classification project using AutoML-Model Builder\r\n- Generate Model(MLModel.zip) and C# Code\r\n- Use MLModel.zip in Azure function\r\n- Run it locally - Works fine\r\n- Publish to Azure Function(Cloud) - Function App(Windows)\r\n- \'tensorflow\' DllNotFound exception is thrown\r\n- Change \'Deployment Mode\' to \'Self-Contained\' and Target Runtime to \'win-x64\'. Also change Platform Settings from 32-bit to 64-bit in Azure Function setting in portal.\r\n- Hit API from REST Client(Postman) : Classification is done successfuly\r\n- Hit API second time or consecutively - SSHException is thrown at PredictionEngine.Predict() method.\r\n\r\n**What happened?**\r\n- Deploying the same function over Azure Function(Cloud) gave DllNotFound exception for tensorflow dll during loading of the model. \r\n- Referred https://developers.de/2019/10/25/hosting-ml-net-in-appservice/ and changed Target Runtime to x64. Tensorflow dll not found error disappeared. \r\n- Hit Function API through Postman first time after above change and it was successful with proper prediction.\r\n- However, when API is hit second or consecutively, SSHException is thrown during prediction using PredictionEngine. \r\n\r\n**What did you expect?**\r\n- No exception at predictionEngine.Predict() while executing in Azure Function(cloud)\r\n- A similar issue reported over SO https://stackoverflow.com/questions/62947625/ml-net-tensorflow-image-clasification-crashes-with-sehexception-when-run-in-azur but there is no solution yet.\r\n- References\r\n - https://github.com/SciSharp/TensorFlow.NET/issues/485\r\n- https://github.com/dotnet/machinelearning/issues/4112\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n**Source Code:** Attached zip file : src.zip\r\n**Azure Function Project:** TestImageClassificationFunctionApp\r\n**Steps, call stack, snippets, logs:** ./testimageclassification/**Readme.md**\r\n**Diagnostic logs:** ./testimageclassification/diagnosis/\r\n\r\n**Exception:** System.Runtime.InteropServices.SEHException\r\n**FailedMethod:** Tensorflow.c_api.TF_SessionRun\r\n\r\n```powershell\r\nSystem.Runtime.InteropServices.SEHException:\r\n   at Tensorflow.c_api.TF_SessionRun (TensorFlow.NET, Version=0.11.8.1, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils+Runner.Run (Microsoft.ML.TensorFlow, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters+Classifier.Score (Microsoft.ML.Vision, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters+<>c__DisplayClass22_0`2.<Microsoft.ML.Data.IValueMapper.GetMapper>b__0 (Microsoft.ML.Vision, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition (Microsoft.ML.Data, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Data.MulticlassClassificationScorer+<>c__DisplayClass16_0.<GetPredictedLabelGetter>b__0 (Microsoft.ML.Data, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Transforms.KeyToValueMappingTransformer+Mapper+KeyToValueMap`2+<>c__DisplayClass8_0.<GetMappingGetter>b__0 (Microsoft.ML.Data, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase+<>c__DisplayClass9_0`2.<CreateConvertingActionSetter>b__0 (Microsoft.ML.Data, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase.FillValues (Microsoft.ML.Data, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51)\r\n   at TestImageClassificationFunctionApp.ClassifyImage+<Run>d__0.MoveNext (TestImageClassificationFunctionApp, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null)\r\n```\r\n\r\n**Azure Function *.csproj **\r\n```poweshell\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n  <PropertyGroup>\r\n    <TargetFramework>netcoreapp3.1</TargetFramework>\r\n    <AzureFunctionsVersion>v3</AzureFunctionsVersion>\r\n    <UserSecretsId>xxxxx-xxxx-xxxxx-xxxxxx</UserSecretsId>\r\n    <Platforms>AnyCPU;x64</Platforms>\r\n  </PropertyGroup>\r\n  <ItemGroup>\r\n    <PackageReference Include=""Azure.Storage.Blobs"" Version=""12.5.1"" />\r\n    <PackageReference Include=""Microsoft.Azure.WebJobs.Extensions.Storage"" Version=""3.0.10"" />\r\n    <PackageReference Include=""Microsoft.ML"" Version=""1.5.1"" />\r\n    <PackageReference Include=""Microsoft.ML.ImageAnalytics"" Version=""1.5.1"" />\r\n    <PackageReference Include=""Microsoft.ML.Vision"" Version=""1.5.1"" />\r\n    <PackageReference Include=""Microsoft.NET.Sdk.Functions"" Version=""3.0.7"" />\r\n    <PackageReference Include=""SciSharp.TensorFlow.Redist"" Version=""2.1.0"" />\r\n  </ItemGroup>\r\n  <ItemGroup>\r\n    <None Update=""host.json"">\r\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\r\n    </None>\r\n    <None Update=""local.settings.json"">\r\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\r\n      <CopyToPublishDirectory>Never</CopyToPublishDirectory>\r\n    </None>\r\n  </ItemGroup>\r\n</Project>\r\n```\r\n\r\nLet me know in case any more information is required.\r\n\r\n[src.zip](https://github.com/dotnet/machinelearning/files/5113449/src.zip)\r\n'"
684003763,5360,"b'How to load python-trained LGB model file into  LightGbmBinaryTrainer  object, and use the trained model inside c#?'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 \r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI\'ve trained a LGB-model from the python  lightgbm package.\r\n\r\n- **What happened?**\r\nI\'ve obtained:\r\n  model-file -  ""model.txt""\r\n  file of model-parameters:  ""predict.conf"" \r\n- **What did you expect?**\r\nI expect to somehow to create a LightGbmBinaryTrainer  object   based on the two files:\r\n   ""model.txt"" and ""predict.conf"" \r\n\r\nI don\'t want to run ""./lightgbm""  config=predict.conf from c# each time in order to obtain the new prediciton inside the *.txt file.\r\nI want to apply the created model inside the c# environment and get the prediction inside the c# and not to load it from the txt file.\r\n### Source code / logs\r\n\r\nThe contents of the ""model.txt"":\r\ntree\r\nversion=v3\r\nnum_class=1\r\nnum_tree_per_iteration=1\r\nlabel_index=0\r\nmax_feature_idx=10307\r\nobjective=binary sigmoid:1\r\nfeature_names=Column_0 Column_1 Column_2 Column_3 Column_4\r\n\r\nThe contents of the ""predict.conf"" \r\ntask = predict \r\n\r\ndata = sharp_preds_string.csv\r\n\r\ninput_model =model.txt\r\n\r\noutput_result=  LightGBM_predict_result.txt\r\n\r\n\r\n\r\n\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
683978432,5359,b'How to feed frames from live video to a trained ONNX model',"b'using System.Drawing classes I am able to read a .MP4 file and receive frames from it and store them as Bitmap,\r\nthis process is happening on a separate thread, simultaneously on another thread I want to feed this Bitmap data to my loaded pretrained .onnx model.\r\nI am not able to find any documentation or support on how to achieve this.\r\n\r\nAny suggestions will be helpful, thanks in advance'"
683903102,5358,b'Support for FHE and SMPC',"b""Are there any plans or support for the following?\r\n\r\n- Full Homomorphic Encryption (FHE)\r\n- Secure Multi Party Computing (SMPC)\r\n\r\nThere seemed to have been some effort on FHE in the past, but unsuccessful:\r\n[SEAL Homomorphic Encryption support](https://github.com/dotnet/machinelearning/pull/4407)\r\n[WIP: Homomorphic encryption](https://github.com/dotnet/machinelearning/pull/4229)\r\n\r\nWith the above becoming popular in other ML frameworks (PySyft, Azure Encrypted Inference, XayNet, etc), it would be good to look into the above areas again. There doesn't seem to be anything similar for .Net (C# or F# for that matter)."""
683795650,5357,"b""ML.NET 1.0.0.0 cannont read component 'HashTransform' of the model, because the model is too new.""","b'### System information\r\n\r\n- **OS:** Windows 10\r\n- **Microsoft.Net Framework:** 4.7.2 \r\n- **Model Builder:** 16.1.1.2041102\r\n- **Visual Studio:** 16.6.3\r\n- **ML.NET (Nuget packages installed):** tried 1.5.1 and 1.5.0\r\n\r\n### Issue\r\n\r\n- I have a **working** ML.Net app built with .Net framework 4.7, that consumes a model generated with Model Builder. It was working really well until I generated a new model file with an extra ""feature"". \r\n1. Re-Trained ML.NET model.\r\n2. Generated the Model file and Input/output classes\r\n3. Copied the ModelInput, ModelOutput and ModelConsume code to my application. \r\n4. Build and run.\r\n\r\n- When I try to load the model it throws an exception **""ML.NET 1.0.0.0 cannont read component \'HashTransform\' of the model, because the model is too new.""**. Refer to exception details below.\r\n\r\n**Note** that the *cannont* is not my typo, thats how the message shows.\r\n\r\n- Given that I updated the model files and the code files required it should work well. If I change the model file and load the old zip model it works well.\r\n\r\n### Source code / logs\r\n\r\n`ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var modelInputSchema);`\r\n\r\nThe line above throws the following exception:\r\n\r\n**Message:** Cause: ML.NET 1.0.0.0 cannont read component \'HashTransform\' of the model, because the model is too new.\r\nSuggestion: Make sure the model is trained with ML.NET 1.0.0.0 or older.\r\nDebug details: Maximum expected version 65540, got 65538.\r\n**Source:** Microsoft.ML.Core\r\n**Stack trace:**    at Microsoft.ML.ModelHeader.CheckVersionInfo(ModelHeader& header, VersionInfo ver)\r\n   at Microsoft.ML.ModelLoadContext.CheckAtModel(VersionInfo ver)\r\n   at Microsoft.ML.Transforms.HashingTransformer.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n\r\n### Notes\r\nI really don\'t know what could have changed. Maybe Model builder auto updated (auto update is enabled on this extension)??? I really did not change anything related to ML.Net versions.\r\n\r\nThings I already tried:\r\n- Changed version of the nuget package for ML.Net (1.5.1 and 1.5.0) - no luck.\r\n- Reinstalled model builder - no luck.\r\n- Re-trained the same model (without the extra feature/column) - No luck.\r\n- If I run the console app that is generated when I click generate code, that app is able to run. I suspect its because its .Net Core 3.1.\r\n\r\nThank you!'"
682990322,5356,b'The first example is misleading.',b'This line of code is simply not working.\r\nvar linearPredictor = model.LastTransformer;\r\nThere is no LastTransformer property. \r\n\r\nCan someone post a working example?\r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\r\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\r\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_BinaryClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_)\r\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'
682406193,5355,b'how to retrain the image classify model incrementally?',"b'\r\n### System information\r\n- **OS version/distro**:Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**: .netcore 3.1 console\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI want to retrain the image classify model incrementally\r\n- **What happened?**\r\nwhen i predict it  after my second training, it report an error,as below\r\n\r\n![error](https://user-images.githubusercontent.com/40555417/90717625-9942ce80-e2e2-11ea-9ab1-25084386f459.png)\r\n\r\n- **What did you expect?**\r\nafter my retraining model ,it can works well\r\n\r\n### Source code / logs\r\n```csharp\r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Drawing;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers;\r\nnamespace Test\r\n{\r\n  public class ContinueGraphTrainingTest\r\n    {\r\n        private static readonly string PrePath = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, ""train"");\r\n        private static readonly string TrainModelPath2 = Path.Combine(PrePath, ""data2.zip"");\r\n        private static readonly string PreDataPath = Path.Combine(PrePath, ""preData.zip"");\r\n        private static readonly string DataModelPath = Path.Combine(PrePath, ""data.zip"");\r\n        private static readonly string InceptionPb = Path.Combine(PrePath, ""tensorflow_inception_graph.pb"");\r\n        private static readonly string FirstScanDir = Path.Combine(PrePath, ""TrainImage1"");\r\n        private static readonly string SecondScanDir = Path.Combine(PrePath, ""TrainImage2"");\r\n        private static readonly string PredictImgs = Path.Combine(PrePath, ""PredictImgs/111.png"");\r\n        private static readonly MLContext MlContext = new MLContext(1);\r\n\r\n        public static void SaveRetrainModel()\r\n        {\r\n\r\n            List<ImageData> list1 = new List<ImageData>();\r\n            ScanPic(list1, FirstScanDir);\r\n            var fulldata1 = MlContext.Data.LoadFromEnumerable(list1);\r\n            var trainTestData1 = MlContext.Data.TrainTestSplit(fulldata1);\r\n            var trainingDataView1 = trainTestData1.TrainSet;\r\n\r\n            var pipeline = MlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                .Append(MlContext.Transforms.ResizeImages(outputColumnName: ""input"", imageWidth: ImageSettings.ImageWidth, imageHeight: ImageSettings.ImageHeight, inputColumnName: ""Image""))\r\n                .Append(MlContext.Transforms.ExtractPixels(outputColumnName: ""input"", interleavePixelColors: ImageSettings.ChannelsLast, offsetImage: ImageSettings.Mean))\r\n                .Append(MlContext.Model.LoadTensorFlowModel(InceptionPb).ScoreTensorFlowModel(outputColumnNames: new[] { ""softmax2_pre_activation"" }, inputColumnNames: new[] { ""input"" }, addBatchDimensionInput: true))\r\n                .AppendCacheCheckpoint(MlContext);\r\n\r\n            var trainingPipeline = pipeline.Append(MlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: ""Label"", featureColumnName: ""softmax2_pre_activation""));\r\n\r\n            var dataPiple = trainingPipeline.Append(MlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabelValue"", ""PredictedLabel""));\r\n\r\n            var preDataTransform = trainingPipeline.Fit(trainingDataView1);\r\n            MlContext.Model.Save(preDataTransform, trainingDataView1.Schema, PreDataPath);\r\n\r\n            ITransformer dataTransform = dataPiple.Fit(trainingDataView1);\r\n            MlContext.Model.Save(dataTransform, trainingDataView1.Schema, DataModelPath);\r\n\r\n            PredictScore();\r\n\r\n        }\r\n\r\n        public static void SecondTrainAndPredit()\r\n        {\r\n            var list2 = new List<ImageData>();\r\n            ScanPic(list2, SecondScanDir);\r\n            var fulldata2 = MlContext.Data.LoadFromEnumerable(list2);\r\n            var trainTestData2 = MlContext.Data.TrainTestSplit(fulldata2);\r\n            var trainingDataView2 = trainTestData2.TrainSet;\r\n\r\n\r\n            var preDataModel = MlContext.Model.Load(PreDataPath, out DataViewSchema modelInputSchema2);\r\n            var originalModelParameters = (preDataModel as TransformerChain<ITransformer>)?.LastTransformer as MulticlassPredictionTransformer<MaximumEntropyModelParameters>;\r\n\r\n            ITransformer dataPrepPipeline = MlContext.Model.Load(DataModelPath, out var dataPrepPipelineSchema);\r\n            IDataView newDataForm = dataPrepPipeline.Transform(trainingDataView2);\r\n            var _keyToValueModel = MlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: ""Label"", featureColumnName: ""softmax2_pre_activation"").Fit(newDataForm, originalModelParameters.Model);\r\n\r\n            MlContext.Model.Save(_keyToValueModel, trainingDataView2.Schema, TrainModelPath2);\r\n\r\n            PredictScore(TrainModelPath2);\r\n        }\r\n\r\n        public static void PredictScore(string dataModelPath = """")\r\n        {\r\n            if (string.IsNullOrEmpty(dataModelPath))\r\n            {\r\n                dataModelPath = DataModelPath;\r\n            }\r\n            var loadedModel = MlContext.Model.Load(dataModelPath, out var modelInputSchema);\r\n            var predictor = MlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(loadedModel);\r\n            var imageData = new ImageData() { Image = (Bitmap)Image.FromFile(PredictImgs) };\r\n            var result = predictor.Predict(imageData);\r\n            Console.WriteLine(result.Score.Max());\r\n        }\r\n\r\n        private static void ScanPic(List<ImageData> list, string directory)\r\n        {\r\n            var files = Directory.GetFiles(directory, ""*.*"", SearchOption.AllDirectories);\r\n            StringBuilder imgTags = new StringBuilder();\r\n            foreach (var filePath in files)\r\n            {\r\n                if (!filePath.EndsWith("".jpg"") && !filePath.EndsWith("".png""))\r\n                {\r\n                    continue;\r\n                }\r\n                var deviceModel = Directory.GetParent(filePath).Name;\r\n                string imgPath = $""{deviceModel}/{Path.GetFileName(filePath)}"";\r\n                imgTags.AppendLine($""{imgPath}\\t{deviceModel}"");\r\n                list.Add(new ImageData()\r\n                {\r\n\r\n\r\n\r\n                    Label = deviceModel,\r\n                    Image = (Bitmap)Image.FromFile(filePath)\r\n                });\r\n            }\r\n        }\r\n    }\r\n\r\npublic class ImagePrediction\r\n    {\r\n        public float[] Score;\r\n\r\n        public string PredictedLabelValue;\r\n    }\r\n\r\n public class ImageData\r\n    {\r\n        //[LoadColumn(0)]\r\n        //public string ImagePath;\r\n        [ImageType(227, 227)]\r\n        [LoadColumn(0)]\r\n        public Bitmap Image;\r\n\r\n        [LoadColumn(1)]\r\n        public string Label;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n[train.zip](https://github.com/dotnet/machinelearning/files/5100711/train.zip)\r\n\r\nand file ""tensorflow_inception_graph.pb"" is too big to upload\r\n'"
681653494,5353,b'Is recognition supported on .NET Framework\xef\xbc\x9f',"b'### System information\r\n\r\n- **OS version/distro**:Windows\r\n- **.NET Version (eg., dotnet --info)**: .NET Framework 4.7.2\r\n\r\n### Issue\r\n\r\n- **I am new to ML.NET. I noted ML.NET can run on .NET Framework and I curious about if recognition also be supported on .NET Framework or not?**\r\n\r\n\r\n'"
681434454,5352,b'LocalizeRootCause does not return any root causes when RootCauseLocalizationInput includes dimensions with values of type long',"b'### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**: ML.Net 1.5.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI called LocalizeRootCause with a RootCauseLocalizationInput that included an aggregation symbol and dimension values of type long.\r\n\r\n- **What happened?**\r\nI got no root cause results. I get results when the dimension values are strings.\r\n\r\n\r\n- **What did you expect?**\r\nI expected to get some results based on earlier prototypes using this dataset.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n\r\n**Repro:** [RCARepro.zip](https://github.com/dotnet/machinelearning/files/5093350/RCARepro.zip)\r\n\r\n#### Below I have two different RootCauseLocalizationInputs as json strings\r\n\r\n**Returned no results**\r\n```\r\nprivate static string jsonT =\r\n@""{\r\n\t""""AnomalyTimestamp"""": """"1998-02-02T00:00:00"""",\r\n\t""""AnomalyDimension"""": {\r\n\t\t""""[__Sandbox.Customers.ContactTitle__]"""": -1\r\n\t},\r\n\t""""Slices"""": [\r\n\t\t{\r\n\t\t\t""""TimeStamp"""": """"1998-02-02T00:00:00"""",\r\n\t\t\t""""Points"""": [\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 16387.5,\r\n\t\t\t\t\t""""ExpectedValue"""": 2187.2416694295504,\r\n\t\t\t\t\t""""IsAnomaly"""": true,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""": 54\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": 14200.25833057045\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 723.15,\r\n\t\t\t\t\t""""ExpectedValue"""": 800.1415610472596,\r\n\t\t\t\t\t""""IsAnomaly"""": false,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""": 34\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": -76.99156104725967\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 17110.65,\r\n\t\t\t\t\t""""ExpectedValue"""": 2193.535,\r\n\t\t\t\t\t""""IsAnomaly"""": true,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""":-1\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": 14917.115000000002\r\n\t\t\t\t}\r\n\t\t\t]\r\n\t\t}\r\n\t],\r\n\t""""AggregateType"""": 0,\r\n\t""""AggregateSymbol"""": -1\r\n}"";\r\n```\r\n\r\n\r\n**Returned results**\r\n```\r\nprivate static string jsonString =\r\n\r\n@""{\r\n\t""""AnomalyTimestamp"""": """"1998-02-02T00:00:00"""",\r\n\t""""AnomalyDimension"""": {\r\n\t\t""""[__Sandbox.Customers.ContactTitle__]"""": """"-1""""\r\n\t},\r\n\t""""Slices"""": [\r\n\t\t{\r\n\t\t\t""""TimeStamp"""": """"1998-02-02T00:00:00"""",\r\n\t\t\t""""Points"""": [\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 16387.5,\r\n\t\t\t\t\t""""ExpectedValue"""": 2187.2416694295504,\r\n\t\t\t\t\t""""IsAnomaly"""": true,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""": """"54""""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": 14200.25833057045\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 723.15,\r\n\t\t\t\t\t""""ExpectedValue"""": 800.1415610472596,\r\n\t\t\t\t\t""""IsAnomaly"""": false,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""": """"34""""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": -76.99156104725967\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""""Value"""": 17110.65,\r\n\t\t\t\t\t""""ExpectedValue"""": 2193.535,\r\n\t\t\t\t\t""""IsAnomaly"""": true,\r\n\t\t\t\t\t""""Dimension"""": {\r\n\t\t\t\t\t\t""""[__Sandbox.Customers.ContactTitle__]"""":""""-1""""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""""Delta"""": 14917.115000000002\r\n\t\t\t\t}\r\n\t\t\t]\r\n\t\t}\r\n\t],\r\n\t""""AggregateType"""": 0,\r\n\t""""AggregateSymbol"""": """"-1""""\r\n}"";\r\n\r\n```\r\n```\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext(0);\r\n\r\n            var rcaInputString = JsonConvert.DeserializeObject<RootCauseLocalizationInput>(jsonString);\r\n            var rcaInputLong = JsonConvert.DeserializeObject<RootCauseLocalizationInput>(jsonLong);\r\n\r\n            // one root cause item returned\r\n            var rcaString = mlContext.AnomalyDetection.LocalizeRootCause(rcaInputString).Items.OrderByDescending(e => e.Score).ToList();\r\n\r\n            // no root cause items returned\r\n            var rcaLong = mlContext.AnomalyDetection.LocalizeRootCause(rcaInputLong).Items.OrderByDescending(e => e.Score).ToList();\r\n        }\r\n```\r\n'"
679633476,5350,b'ML Model is not reloaded if prediction was made before',"b'### System information\r\n\r\n- **OS version/distro**:  Windows 10 Pro, version 2004, OS Build: 19041.450\r\n- **.NET Version (eg., dotnet --info)**: 3.1.302\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n     After new record is available, I add it to training data and retrain model.\r\n\r\n- **What happened?**\r\n\r\n     New model was generated, but not reloaded in app.\r\n\r\n- **What did you expect?**\r\n\r\n     Reloaded model and better (expected) prediction\r\n\r\n### Source code / logs\r\n\r\nI use this code to add prediction engine pool:\r\n\r\n```\r\nservices.AddPredictionEnginePool<SentimentData, SentimentPrediction>()\r\n                  .FromFile(\r\n                  modelName: Constants.ModelName,\r\n                  filePath: Constants.ModelFileName,\r\n                  watchForChanges: true);\r\n```\r\n![image](https://user-images.githubusercontent.com/46314872/90320515-140e9100-df53-11ea-8392-f1f66364887b.png)\r\n\r\nSample project: https://github.com/alexandermujirishvili/DotnetMLWatchForChanges\r\n'"
679344999,5347,b'Feature request: Add support for saving/loading IDataView to/from csv/tsv directly and other pandas-like functionalities',"b'This will be a useful feature when using ML.Net to build pipeline in jupyter notebook, especially in data preprocessing steps.\r\n\r\nOther useful functions can be\r\n- IDataView.description -> similar to DataFrame.description, which prints summary information of current dataset.\r\n- IDataView.Head(n) -> print first n rows in nice table format\r\n- IDataView[ColumnName] -> get the column of ColumnName\r\n\r\n'"
679109446,5346,b'ML.Net CustomMapping with ONNX Model',"b'### System information\r\n\r\n- **Win10\r\n- ** .Net Core 3.1 \r\n\r\n### Issue\r\n\r\nI do not know how to define output_column with sequence in CustomMapping.\r\n![Output_ONNX](https://user-images.githubusercontent.com/10833738/90246362-ca2f8900-de34-11ea-8f76-25b6c1f09414.PNG)\r\nFor output_label  it is simple Int64[] . But for output_probabilities I have no idea.\r\nI have tried in my InputClass \r\n`IEnumerable<IDictionary<Int64, float>> output_probability { get; set; } `\r\nor\r\n`OnnxSequenceType output_probability { get; set; } `\r\n\r\nBut witout success. \r\n\r\nHier ist fully functional sample. With dataset and onnx model.\r\n[TestCustomMapping.zip](https://github.com/dotnet/machinelearning/files/5074415/TestCustomMapping.zip)\r\nOr here is code :\r\n\r\n### Source code\r\n\r\n`using Microsoft.ML;\r\nusing Microsoft.ML.Transforms.Onnx;\r\nusing System;\r\nusing System.Collections.Generic;\r\n\r\nnamespace TestCustomMapping\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n            var data = new List<InputDataLinear>() { new InputDataLinear() { day = 3, hour = 4, temperature = 15.4F, vibration = 5.6F, name = ""Machine 1"", worker = ""Hans"", Fehler = true } };\r\n            var dataView = mlContext.Data.LoadFromEnumerable<InputDataLinear>(data);\r\n\r\n            // Define the operation code.\r\n            Action<InputRow, OutputRow> mapping = (input, output) => {                \r\n                output.PredictedLabelSingle = input.output_label[0];\r\n                output.ProbabilitySingle = 0/*input.output_probability*/;\r\n            };\r\n\r\n            var pipeline = mlContext.Transforms.ApplyOnnxModel(modelFile: @""../../../Model/model2.onnx"", inputColumnNames: new string[] { ""day"", ""hour"", ""name"", ""worker"", ""temperature"", ""vibration"" },\r\n                    outputColumnNames: new[] { ""output_label"", ""output_probability""});\r\n\r\n            IDataView predictions = pipeline.Fit(dataView).Transform(dataView);\r\n\r\n            IDataView predictions2 = mlContext.Transforms.CustomMapping(mapping, null).Fit(predictions).Transform(predictions);\r\n   \r\n            var metrics = mlContext.BinaryClassification.Evaluate(predictions2, labelColumnName: ""Fehler"", scoreColumnName: ""ScoreSingle"", probabilityColumnName: ""ProbabilitySingle"", predictedLabelColumnName: ""PredictedLabelSingle"");            \r\n        }\r\n    }\r\n\r\n    public class InputRow\r\n    {\r\n        //public IEnumerable<IDictionary<Int64, float>> output_probability { get; set; }\r\n        public IEnumerable<IDictionary<Int64, float>> output_probability { get; set; }\r\n\r\n        public Int64[] output_label { get; set; }\r\n\r\n    }\r\n\r\n    public class OutputRow\r\n    {\r\n        public float ScoreSingle { get; set; }\r\n\r\n        public float ProbabilitySingle { get; set; }\r\n\r\n        public bool PredictedLabelSingle { get; set; }\r\n\r\n    }\r\n\r\n    class InputDataLinear \r\n    {\r\n        public float day { get; set; }\r\n\r\n        public float hour { get; set; }\r\n\r\n        public float temperature { get; set; }\r\n\r\n        public float vibration { get; set; }\r\n\r\n        public string name { get; set; }\r\n\r\n        public string worker { get; set; }\r\n\r\n        public bool Fehler { get; set; }\r\n\r\n    }\r\n}\r\n`\r\n\r\n\r\n'"
677618310,5343,b'ONNX Model Evaluation in ML.Net not working',"b'### System information\r\n\r\n- Win10\r\n- .NET Core 3.1\r\n\r\n### How can I evaluate ONNX Model in ML.Net\r\nI am loading already trained ONNX Model with ApplyOnnxModel then produce predictions based on my data(IDataView) and afterward I am going to evaluate the results with mlContext.BinaryClassification.Evaluate. That does not work. Becouse he expects scoreColumn as single float and not float[]. But ONNX Model returns always results in Vector<Single, -1, 1>. \r\nOn evaluating I got exception: \r\n\r\n> System.ArgumentOutOfRangeException\r\nSchema mismatch for score column \'Score\': expected Single, got Vector<Single, 1, 1> (Parameter \'schema\')\r\n\r\nAs you can see in the following model. Output Parameter are vectors float32[-1,1] but BinaryClassification.Evaluate expect single float. Is there any workaround. Or it is not possible to evaluate ONNX Model with ML.Net.\r\n\r\n[model.zip](https://github.com/dotnet/machinelearning/files/5062377/model.zip)\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar pipeline = mlContext.Transforms.ApplyOnnxModel(modelFile: this.ModelFile, inputColumnNames: new string[] { ""day"",""hour"",""name"",""worker"",""temperature"",""vibration""},\r\n                    outputColumnNames: new[] { ""Probability.output"", ""PredictedLabel.output"",""Score.output"" });\r\n\r\nIDataView predictions = model.Transform(dataView);\r\nvar metrics = mlContext.BinaryClassification.Evaluate(predictions, labelColumnName: labelColumnName, scoreColumnName: ""Score"", probabilityColumnName: ""Probability"", predictedLabelColumnName: ""PredictedLabel"");\r\n```'"
677545163,5342,b'Load ONNX model creates temp file',"b""### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: .NET framework 4\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nLoad model saved by ML.NET, the base model is in ONNX format\r\n- **What happened?**\r\nEverytime I load the model, a new onnx model file is created in %temp% folder and it is not deleted after releasing model object or after exiting the application. File path: %temp%\\7bf1a39c-b65c-4874-927b-2bacbbf57b15\\model.onnx\r\nI tried to delete the file when the model was predicting but there is no error or exception and the result is the same.  \r\n- **What did you expect?**\r\nThis file should be deleted or better not be created since it exposes our model to the user consumes too much user's memory.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
676413342,5341,"b""Image classification can't run on CPU that doesn't support AVX instruction""","b'### System information\r\n\r\n- **OS version/distro**: Window10\r\n- **.NET Version (eg., dotnet --info)**:  3.1.302\r\n\r\n### Issue\r\n\r\nWe have a few users from Model Builder report on image classification failure because of loading error.\r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/915\r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/920\r\n\r\nAfter some investigation, I think it is because their CPU is too old and doesn\'t support AVX instruction, which is used to build tensorflow after v1.6. **But I\'m not too sure about it, and that conclusion need double check**.\r\n\r\nIn the meanwhile, it would be great if we can catch the instruction not support error from exception thrown by mlnet. Right now the error message is ""Tensorflow exception triggered while loading model"", which is not really helpful in debugging. Is it possible to have a new exception, or a specific error message to highlight the avx not support exception?\r\n\r\n'"
676165493,5340,b'How to re-train onnx model in ml.net',"b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n\r\n\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 3.1\r\n\r\n### Issue\r\n\r\nHi I am trying to re-train model saved in onnx format. I can inference this model with onnxruntime in .net but retraining without success. What I am doing wrong? Is this in .net possible? Here is my model:[logres_scikit_pipeline.zip](https://github.com/dotnet/machinelearning/files/5051258/logres_scikit_pipeline.zip)\r\n\r\n### Source code\r\n`\r\nvar MODEL_PATH = @""..\\..\\..\\Model\\logres_scikit_pipeline.onnx"";\r\n                \r\n                var pipeline = mlContext.Transforms.ApplyOnnxModel(modelFile: MODEL_PATH, inputColumnNames: inputColumnNames,\r\n                    outputColumnNames: new[] { ""output_probability"", ""output_label"" });\r\n\r\n                var model = pipeline.Fit(newData);\r\n              \r\n                using (var stream = File.Create(MODEL_PATH))\r\n                {\r\n                    mlContext.Model.ConvertToOnnx(model, newData, stream);\r\n                }\r\n`\r\n\r\n> On ConvertToOnnx, I got following Exception: The targeted pipeline can not be fully converted into a well-defined ONNX model. Please check if all steps in that pipeline are convertible to ONNX and all necessary variables are not dropped (via command line arguments).'"
674625047,5339,"b""AutoML.Net: CrossValSummaryRunner can't handle all-infinity metrics value.""","b""CrossValSummaryRunner picks up the best model and score from cross validation in the following logic:\r\n- get results from all validation runs\r\n- if all run succeed, get the index of model with best score as return model, if all run's score is NaN or Infinity, uses the first model\r\n- if all run succeed, get the score which is closest to the average score as return training score, if average score is NaN, use the first score (**BUG**)\r\n\r\nThe possible place that causes the bug is sometimes the average score can be Infinity, in which case the following function will return -1 and causes an index out of error exception\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/37af3f9db86414f4ec5b16a8734c90b498946caa/src/Microsoft.ML.AutoML/Experiment/Runners/CrossValSummaryRunner.cs#L84\r\n\r\n### Related issue\r\n(The label column for this user's dataset is all empty, which is the root cause for this error) \r\n- https://github.com/dotnet/machinelearning-modelbuilder/issues/929"""
673245637,5337,b'ONNX model performs wrongly and Normalization for Image',"b'### System information\r\n\r\n- **OS version/distro**: Window \r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n I use pre-trained ONNX in my application\r\n- **What happened?** \r\nThe ONNX model performs worse in ML.NET than in other platforms (pytorch, tensorflow) in term of accuracy. They give the same results for some images while some are not. I think the problem might be on the preprocessing stage. In Pytorch, I have normalization step while I cannot produce the same method in ML.NET.\r\nI tried NormalizeMeanVariance and NormalizeMinMax but the result is all 0 so I wonder if they are applicable for image.\r\n- **What did you expect?** \r\nNormalization for image or allowing custom preprocessing transform. I would love to have sample for this problem. Actually it would be nice to have document about how to map Tensorflow, Pytorch functions to ML.NET functions.\r\n\r\n### Source code / logs\r\nML.NET code which can produce some good results:\r\n```\r\nvar pipeline = mlContext.Transforms\r\n                .LoadImages(\r\n                    outputColumnName: ""image_object"",\r\n                    imageFolder: null,\r\n                    inputColumnName: nameof(ImageData.ImagePath))\r\n            .Append(mlContext.Transforms.ResizeImages(\r\n                outputColumnName: ""image_object_resized"",\r\n                imageWidth: ImageSettings.imageWidth,\r\n                imageHeight: ImageSettings.imageHeight,\r\n                inputColumnName: ""image_object""\r\n               ))\r\n            .Append(mlContext.Transforms.ExtractPixels(\r\n                outputColumnName: ""image_object_scale"",\r\n                inputColumnName: ""image_object_resized"",\r\n                offsetImage:117,\r\n                scaleImage:1/255f))\r\n.Append(mlContext.Transforms.ApplyOnnxModel(modelFile: _modelFilePath, outputColumnName: ModelSettings.outputTensorName, inputColumnName:  ModelSettings.inputTensorName));\r\n```\r\n\r\n**ML.NET normalize code:**\r\n```\r\nvar pipeline = mlContext.Transforms\r\n                .LoadImages(\r\n                    outputColumnName: ""image_object"",\r\n                    imageFolder: null,\r\n                    inputColumnName: nameof(ImageData.ImagePath))\r\n            .Append(mlContext.Transforms.ResizeImages(\r\n                outputColumnName: ""image_object_resized"",\r\n                imageWidth: ImageSettings.imageWidth,\r\n                imageHeight: ImageSettings.imageHeight,\r\n                inputColumnName: ""image_object""\r\n               ))\r\n            .Append(mlContext.Transforms.ExtractPixels(\r\n                outputColumnName: ""image_object_scale"",\r\n                inputColumnName: ""image_object_resized""))\r\n            .Append(mlContext.Transforms.NormalizeLogMeanVariance(inputColumnName: ""image_object_scale"", outputColumnName: ""image_normalized"", fixZero:true));\r\n\r\n            var normalizeTransform = pipeline.Fit(dataView);\r\n            var transformedData = normalizeTransform.Transform(dataView);\r\n            var column = transformedData.GetColumn<float[]>(""image_normalized"").ToArray();\r\n            foreach (var row in column)\r\n                    Console.WriteLine(string.Join("", "", row.Select(x => x.ToString())));\r\n```\r\n\r\n**Pytorch transformation:**\r\n```data_transforms = transforms.Compose([\r\ntransforms.Resize(224),\r\ntransforms.ToTensor(),\r\ntransforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\r\n])```'"
671940805,5336,b'Passing serialized TensorFlow Example to TF Serving SavedModel',"b'### System information\r\n\r\n- **OS version/distro**: macOS 10.15\r\n- **.NET Version (eg., dotnet --info)**: 3.1.301\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n  I would like to use the PredictionEnginePool (eventually) in combination with a pretrained Tensorflow Model that I exported using the [Estimator.export_saved_model](https://www.tensorflow.org/guide/saved_model?hl=en#savedmodels_from_estimators) function in combination with [`build_parsing_serving_input_receiver_fn`](https://www.tensorflow.org/api_docs/python/tf/estimator/export/build_parsing_serving_input_receiver_fn).\r\n\r\n  Specifically, I went through this tutorial: https://www.tensorflow.org/tfx/tutorials/transform/census. Below, you can find the Tensorflow Serving signature definition according to `saved_model_cli`. \r\n\r\n- **What happened?**\r\n  The `input_example_tensor` input expects a serialized [Example](https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/core/example/example.proto) message (a binary buffer, not a text string). This does not work using the ML.NET library because it [re-encodes the data](https://github.com/dotnet/machinelearning/blob/release/1.5.1/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L837) that I\'m providing as the model input.\r\n- **What did you expect?**\r\n  There should be the option in ML.NET to pass raw binary data as a TFString to the model (maybe as a `byte[]` or `ReadOnlyMemory<byte>`?).\r\n\r\n### Source code / logs\r\nSaved model signature:\r\n```bash\r\n$ saved_model_cli show --dir ./my_saved_model --tag_set serve --signature_def serving_default\r\nThe given SavedModel SignatureDef contains the following input(s):\r\n  inputs[\'inputs\'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1)\r\n      name: input_example_tensor:0\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs[\'classes\'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1, 2)\r\n      name: head/Tile:0\r\n  outputs[\'scores\'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 2)\r\n      name: head/predictions/probabilities:0\r\nMethod name is: tensorflow/serving/classify\r\n```\r\n\r\nMy code:\r\n```csharp\r\nclass ModelInput {\r\n    [ColumnName(""input_example_tensor""), VectorType(1)]\r\n    public string[] InputExampleTensor { get; set; }\r\n}\r\nclass ModelPrediction {\r\n    [ColumnName(""head/Tile:0""), VectorType(2)]\r\n    public string[] Classes { get; set; }\r\n\r\n    [ColumnName(""head/predictions/probabilities:0""), VectorType(2)]\r\n    public float[] Prediction { get; set; }\r\n}\r\n\r\nvar mlContext = new MLContext();\r\n\r\nvar pipeline = mlContext.Model.LoadTensorFlowModel(""my_saved_model"")\r\n    .ScoreTensorFlowModel(\r\n        outputColumnNames: new[] { ""head/Tile:0"", ""head/predictions/probabilities:0"" },\r\n        inputColumnNames: new[] { ""input_example_tensor"" }\r\n    );\r\n\r\n// Train the model\r\n// Since we are simply using a pre-trained TensorFlow model,\r\n// we can ""train"" it against an empty dataset\r\nvar emptyTrainingSet = mlContext.Data.LoadFromEnumerable(new List<ModelInput>());\r\nvar mlModel = pipeline.Fit(emptyTrainingSet);\r\nvar engine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelPrediction>(mlModel);\r\n\r\n// Example is a Protobuf-Class, generated from example.proto\r\nvar example = new Example();\r\n// filling the example with features omitted\r\n\r\nvar input = new ModelInput {\r\n    InputExampleTensor = new[] { new string(example.ToByteArray().Select(x => (char)x).ToArray()) }\r\n};\r\n\r\nvar prediction = engine.Predict(input);\r\n```\r\n\r\nWhich fails with:\r\n```\r\nW tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at example_parsing_ops.cc:92 : Invalid argument: Could not parse example input, value: \'<omitted binary data>\'\r\n```'"
670008383,5335,b'SerializationBinder must be set for BinaryFormatter',b'https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ResultProcessor/ResultProcessor.cs#L1150-L1151\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/SerializableLambdaTransform.cs#L135\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/SerializableLambdaTransform.cs#L142\r\n\r\nPlease see tracking bug for more details:\r\nhttps://devdiv.visualstudio.com/DevDiv/_workitems/edit/1110054'
669978515,5334,b'Reenabling Analyzers rules',"b""Running the FxCop analyzers with the `Sdl.Required.Warning.ruleset` as done on #5331 raises some errors. Please note that ML.NET already had a ruleset defined on [Source.ruleset](https://github.com/dotnet/machinelearning/blob/dd318d89ca6e97a46ce84ae37f091b69dc6ebca5/src/Source.ruleset#L1-L3) but it turns out that since the FxCop analyzers weren't installed before, several of those rules were _never_ actually enforced. After installing the FxCop most of the errors detected come from this preexisting ruleset, but they're not to be considered security-related since they aren't part of the Sdl ruleset.\r\n\r\n### Rules related to security\r\n- [x] CA2301 - Raised on a couple of places of ML.NET. This is actually the only error coming from the Sdl ruleset.\r\n- [ ] CA2100 - This doesn't come from the Sdl ruleset (it comes from the preexisting ruleset) but seems to be security related.\r\n\r\n### Rules not related to security\r\nThe other error codes thrown by the analyzers are the following. As per @sharwell recommendation, it might just be best to disable all of these, but it might also be preferable to address and solve some of them in order to reenable the rules. PR #5331 disables all of this, until they might be addressed in the future.\r\n\r\n**Rules we might want to address after disabling:**\r\n- [ ] CA1060\r\n- [ ] CA1065\r\n- [ ] CA2002\r\n- [ ] CA2101\r\n- [ ] CA2231\r\n\r\n**Rules we might simply want to disable and not address:**\r\n- [ ] CA1001\r\n- [ ] CA1033\r\n- [ ] CA1063\r\n- [ ] CA2213\r\n- [ ] CA2214\r\n\r\n"""
669008003,5333,b'Image Classification Infinite Training Loop',"b'### System information\r\n\r\n- Windows 10 Enterprise\r\n- .NET 4.7.03190\r\n- Visual Studio Professional 2019 16.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am attempting to run training for image classification for the first time with about 5000 images in 5 sub-folders for tagging as required. My pc does not have a real GPU if that matters, the training uses my CPU cores at 100% during the ""bottleneck"" phase.\r\n\r\n- **What happened?**\r\nThe training runs through a loop that repeats over and over. The loop repeated over 12 times in the longest run over 3 hours before I cancelled it. I will attach the output log. I tried making a new solution entirely and got the same behavior. I tried reducing the training set to 2000 images in 2 sub-folders but that had the same behavior.\r\n\r\n- **What did you expect?**\r\nI expected the training to complete after one loop through the images, since this is what the documentation seems to say.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[image classifier log](https://github.com/dotnet/machinelearning/files/5002843/image.classifier.log)\r\n'"
667988521,5330,b'ML.NET Is unable to export model in Text format as MAML used to do',"b""I was using TLC/MAML to create my LR model and would then export it to a text file which would show the weights and the bias value. Our subsequent pipeline consumes this file.\r\nWe are trying to switch over to ML.NET and are noticing that it doesn't have an option to export the same format.\r\nCan we please get this functionality?\r\n\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
666339046,5326,b'[Documentation] LpNormNormalizingEstimator equations display as plain text',"b""\r\nEquations don't seem to work as intended in the documentation. I assume this isn't meant to be how it's displayed:\r\n\r\n![image](https://user-images.githubusercontent.com/3247357/88553903-b951db80-d01d-11ea-89fc-e32a4a5ac3fd.png)\r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 71dcdd76-b41e-d01e-3a03-e26415d0339a\r\n* Version Independent ID: 1b166fb2-85e0-0378-a467-d84d7435f491\r\n* Content: [LpNormNormalizingEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.lpnormnormalizingestimator?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/LpNormNormalizingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/LpNormNormalizingEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**"""
665762853,5325,b'Pause the Training process?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .Net Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nHello!\r\nQuestion - Can I with ML.net  stop training process, save results to the disk and resume process of training later?\r\nTask - Multiclass classification\r\nTrainer - ImageClassificationTrainer\r\n'"
665632649,5324,"b'Transform Vector<Byte> to Vector<width,height,3>'","b""### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Creating pipeline for image loading \r\n- **What happened?**  'Schema mismatch for input column 'Data': expected Vector<Byte, 45, 45, 3>, got Vector<Byte> \r\n- **What did you expect?** i don't , i want to known - how covert Vector's\r\n\r\n### Source code / logs\r\n\r\nHow to Convert Vectors?\r\n"""
664736428,5323,"b"": 'Schema mismatch for input column 'data': expected Vector<Byte, 45, 45, 3>, got Vector<Byte> '""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 64\r\n- **.NET Version (eg., dotnet --info)**:  Net Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** :  Try to load images from folder as byte [], then load data into Bitmap and then  createEnumareable\r\n- **What happened?** : Error  Type \'System.Drawing.Bitmap\' is not yet supported.   in ConvertToImage\r\n- **What did you expect?** Expect to make array of abjects with Bitmap field\r\n\r\n### Source code / logs\r\ni Have class:\r\npublic class MyImage\r\n    {\r\n        public string Label { get; set; }\r\n        public string path { get; set; }\r\n        [VectorType(45, 45, 3)]\r\n        public byte[] data { get; set; }\r\n        [ImageType(3, 4)]\r\n        public Bitmap im { get; set; }\r\n    }\r\n\r\nand the code:\r\n\r\n```\r\nMLContext ml = new MLContext();\r\n string folder = @""here my path to folder with images"";\r\n\r\n// Simple function to load images and populate MyImage class (Label and path properties)\r\n IEnumerable<MyImage> images = LoadImagesFromDirectory3(folder: folder, useFolderNameAsLabel: true);\r\n IDataView data = ml.Data.LoadFromEnumerable<MyImage>(images);\r\n IDataView data2 = ml.Transforms.LoadRawImageBytes(""data"", folder, ""path"")\r\n                                    .Fit(data).Transform(data);\r\n \r\n // And here i want to from data2 make data3 ( with im field)\r\n// but here i get error:\'Schema mismatch for input column \'data\': expected Vector<Byte, 45, 45, 3>, got Vector<Byte> \'\r\n  IDataView data3 = ml.Transforms.ConvertToImage(45, 45, ""im"", ""data"")\r\n                                     .Fit(data2).Transform(data2);\r\n  // And now i want to convert from data3 of type IDataView to List<MyImage>\r\n  // And here\r\n  IEnumerable<MyImage> res=ml.Data.CreateEnumerable<MyImage>(data3, false)\r\n // and after that, i want to save images to the disk\r\n```\r\n`\r\n\r\nPlease help.\r\nWhat i do wrong?'"
664709250,5322,b'ML.Net Invalid GraphDef - Object Detection Model',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: dotnet framework 4.7\r\n\r\n### Issue\r\n\r\nWe are working on how to consume the tensorflow model in .Net using ML.NET. We are using below tutorial as reference :\r\n\r\nTutorial Link : https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification\r\n\r\nWe tested with model that is used in the Tutorial and it worked fine. But, when we replace tutorial model with our tensorflow model (object detection model which we have exported from Azure Custom Vision), it is throwing an Exception saying \xe2\x80\x98Invalid GraphDef\xe2\x80\x99, while loading the tensor flow model. The same custom vision model works fine when consumed in Python code.\r\n\r\n### Source code / logs\r\n\r\nDetails:\r\n\r\nProject Name : TransferLearningTF \r\nClass name : program.cs \r\nMethod Name : GenerateModel \r\n\r\nCode : \r\nIEstimator<ITransformer> pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""input"", imageFolder: _imagesFolder, inputColumnName: nameof(ImageData.ImagePath))\r\n                                                                                              .Append(mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel)\r\n                                                                                                                .ScoreTensorFlowModel(outputColumnNames: new[] { ""softmax2_pre_activation"" }, inputColumnNames: new[] { ""input"" }, addBatchDimensionInput: true))\r\n\r\nException Details : \r\n\r\nException Message : Tensorflow exception triggered while loading model\r\nSource : Microsoft.ML.TensorFlow\r\nStacktrace :  \r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.GetSession(IHostEnvironment env, String modelPath, Boolean metaGraph)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTensorFlowModel(IHostEnvironment env, String modelPath)\r\n   at Microsoft.ML.TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog catalog, String modelLocation)\r\n   at PredictionModel.Program.GenerateModel(MLContext mlContext) in D:\\Cognitive-Samples-VideoFrameAnalysis-master\\Windows\\PredictionModel\\Program.cs:line 35\r\n   at PredictionModel.Program.Main(String[] args) in D:\\Cognitive-Samples-VideoFrameAnalysis-master\\Windows\\PredictionModel\\Program.cs:line 22\r\n\r\nInner Exception:\r\n\r\nException  Message  : Invalid GraphDef\r\nSource :  TensorFlow.NET\r\nStack trace : \r\n   at Tensorflow.Status.Check(Boolean throwException)\r\n   at Tensorflow.Graph.Import(Byte[] bytes, String prefix)\r\n   at Tensorflow.Graph.Import(String file_path, String prefix)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n\r\n'"
664584785,5321,"b""System.ArgumentException: Destination is too short. (Parameter 'destination')""","b""### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\nVersion: 3.1.301\r\nCommit: 7feb845744\r\n\r\n \r\n\r\nRuntime Environment:\r\n\r\nOS Name: Windows\r\n\r\nOS Version: 10.0.14393\r\n\r\nOS Platform: Windows\r\n\r\nRID: win10-x86\r\n\r\nBase Path: D:\\Program Files (x86)\\dotnet\\sdk\\3.1.301\\\r\n\r\n \r\n\r\nHost (useful for support):\r\n\r\nVersion: 3.1.5\r\n\r\nCommit: 65cd789777\r\n\r\n \r\n\r\n.NET Core SDKs installed:\r\n\r\n1.1.14 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n2.1.514 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n2.1.515 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n2.2.109 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n3.1.202 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n3.1.301 [D:\\Program Files (x86)\\dotnet\\sdk]\r\n\r\n \r\n\r\n.NET Core runtimes installed:\r\n\r\nMicrosoft.AspNetCore.All 2.1.17 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n\r\nMicrosoft.AspNetCore.All 2.1.19 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n\r\nMicrosoft.AspNetCore.All 2.2.8 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n\r\nMicrosoft.AspNetCore.App 2.1.17 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.AspNetCore.App 2.1.19 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.AspNetCore.App 2.2.8 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.AspNetCore.App 3.0.3 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.AspNetCore.App 3.1.3 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.AspNetCore.App 3.1.5 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n\r\nMicrosoft.NETCore.App 1.0.16 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 1.1.13 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 2.0.9 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 2.1.19 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 2.2.8 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 3.0.3 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nMicrosoft.NETCore.App 3.1.5 [D:\\Program Files (x86)\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\n- We have implemented a service using ML.Net to analyze email messages.  In certain cases, when sending a request to analyze we get the following error, which results in a 400 status reply from our service.  When trying the same payload a couple of minutes later we get a correct 200 reply without error.\r\nWe would expect that ML always returns the same result when provided with the same payload?\r\n\r\nSystem.ArgumentException: Destination is too short. (Parameter 'destination')\r\n   at Microsoft.ML.Data.BufferBuilder`1.GetResult(VBuffer`1& buffer)\r\n   at Microsoft.ML.Transforms.Text.NgramExtractingTransformer.Mapper.<>c__DisplayClass10_0.<MakeGetter>b__2(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.LpNormNormalizingTransformer.Mapper.<>c__DisplayClass8_0.<MakeGetter>b__5(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass18_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, DataViewRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Data.MulticlassClassificationScorer.<>c__DisplayClass16_0.<GetPredictedLabelGetter>b__0(UInt32& dst)\r\n   at Microsoft.ML.Transforms.KeyToValueMappingTransformer.Mapper.KeyToValueMap`2.<>c__DisplayClass8_0.<GetMappingGetter>b__0(TValue& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass9_0`2.<CreateConvertingActionSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at sar.svc.ml.alex.business.services.MailPredictionService.GetIntents(Mail mail) in D:\\a\\1\\s\\sar.svc.ml.alex.business\\services\\MailPredictionService.cs:line 26\r\n\r\n\r\n```csharp      \r\npublic Dictionary<string, float> GetIntents(Mail mail)\r\n        {\r\n            if (mail == null)\r\n            {\r\n                throw new ArgumentNullException(nameof(mail));\r\n            }\r\n\r\n            var prediction = predictionEngine.Engine.Predict(mail);\r\n\r\n            return BuildIntents(predictionEngine.Engine.OutputSchema, prediction.Score);\r\n        }\r\n```"""
663994500,5320,b'The input string was not formatted correctly',"b'Model Builder Error\r\n\r\nVisual studio 2019 last version\r\nML.NET last version\r\nwindows 8.1 x64\r\ninput data: https://yadi.sk/d/dOH4eg9ojMV4gA\r\nTraining stops after this log line:\r\n`|63   OlsRegression                         0,0000          5,55       428,48    20,70      55,0         63      |`\r\n\r\ntrace:\r\n```\r\n\xd0\xb2 System.Number.ParseSingle(String value, NumberStyles options, NumberFormatInfo numfmt)\r\n   \xd0\xb2 Microsoft.ML.AutoML.SweeperProbabilityUtils.ParameterSetAsFloatArray(IValueGenerator[] sweepParams, ParameterSet ps, Boolean expandCategoricals)\r\n   \xd0\xb2 Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   \xd0\xb2 Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   \xd0\xb2 Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   \xd0\xb2 Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerWhitelist)\r\n   \xd0\xb2 Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   \xd0\xb2 Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   \xd0\xb2 Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   \xd0\xb2 Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment`3.<>c__DisplayClass21_0.<ExecuteAsync>b__5() \xd0\xb2 /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Experiments/AutoMLExperiment.cs:\xd1\x81\xd1\x82\xd1\x80\xd0\xbe\xd0\xba\xd0\xb0 81\r\n   \xd0\xb2 System.Threading.Tasks.Task`1.InnerInvoke()\r\n   \xd0\xb2 System.Threading.Tasks.Task.Execute()\r\n--- \xd0\x9a\xd0\xbe\xd0\xbd\xd0\xb5\xd1\x86 \xd1\x82\xd1\x80\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd1\x80\xd0\xbe\xd0\xb2\xd0\xba\xd0\xb0 \xd1\x81\xd1\x82\xd0\xb5\xd0\xba\xd0\xb0 \xd0\xb8\xd0\xb7 \xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd1\x8b\xd0\xb4\xd1\x83\xd1\x89\xd0\xb5\xd0\xb3\xd0\xbe \xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbe\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f, \xd0\xb3\xd0\xb4\xd0\xb5 \xd0\xb2\xd0\xbe\xd0\xb7\xd0\xbd\xd0\xb8\xd0\xba\xd0\xbb\xd0\xbe \xd0\xb8\xd1\x81\xd0\xba\xd0\xbb\xd1\x8e\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 ---\r\n   \xd0\xb2 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   \xd0\xb2 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   \xd0\xb2 Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment`3.<ExecuteAsync>d__21.MoveNext() \xd0\xb2 /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Experiments/AutoMLExperiment.cs:\xd1\x81\xd1\x82\xd1\x80\xd0\xbe\xd0\xba\xd0\xb0 108\r\n--- \xd0\x9a\xd0\xbe\xd0\xbd\xd0\xb5\xd1\x86 \xd1\x82\xd1\x80\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd1\x80\xd0\xbe\xd0\xb2\xd0\xba\xd0\xb0 \xd1\x81\xd1\x82\xd0\xb5\xd0\xba\xd0\xb0 \xd0\xb8\xd0\xb7 \xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd1\x8b\xd0\xb4\xd1\x83\xd1\x89\xd0\xb5\xd0\xb3\xd0\xbe \xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbe\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f, \xd0\xb3\xd0\xb4\xd0\xb5 \xd0\xb2\xd0\xbe\xd0\xb7\xd0\xbd\xd0\xb8\xd0\xba\xd0\xbb\xd0\xbe \xd0\xb8\xd1\x81\xd0\xba\xd0\xbb\xd1\x8e\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 ---\r\n   \xd0\xb2 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   \xd0\xb2 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   \xd0\xb2 Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__30.MoveNext() \xd0\xb2 /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:\xd1\x81\xd1\x82\xd1\x80\xd0\xbe\xd0\xba\xd0\xb0 147\r\n```'"
663385377,5318,b'Transformers and AutoML',"b'### System information\r\n\r\n- Microsoft Visual Studio Professional 2019, Version 16.6.4\r\n- ML.NET 1.5.1\r\n\r\n### Issue\r\n\r\n- I am trying to do data preparation with AutoML.\r\nI have run my code with, and without, the ""NormalizeMeanVariance"" transform, and I\'m getting a much poorer result with the transform. I must be doing something wrong because applying this transform should not produce poorer results.\r\n\r\nHere is a snapshot of my results:\r\n![transform](https://user-images.githubusercontent.com/1317234/88118539-a7ca8880-cb72-11ea-8b27-4c1ff13607d7.png)\r\n\r\n### Reproducible solution files:\r\nThe complete reproducible solution can be downloaded from: https://github.com/CBrauer/Transform-and-AutoML\r\n\r\n\r\n### Here is the main code of the solution.\r\n\r\n```\r\nusing System;\r\nusing System.Diagnostics;\r\nusing System.Linq;\r\n\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.AutoML;\r\nusing Microsoft.ML.Data;\r\n\r\nusing MLLibrary;\r\n\r\nnamespace BottleRocketClassify {\r\n\r\n  internal static class Program {\r\n    public const string trainedModelPath = ""../../../MLModel.zip"";\r\n\r\n    #region PrintMetrics\r\n    #region BinaryExperimentProgressHandler\r\n    #region Head\r\n\r\n    public static class ModelBuilder {\r\n      public static void Run() {\r\n        var mlContext = new MLContext(seed: 1);\r\n\r\n        var trainDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n          path: @""H:/HedgeTools/Datasets/rocket-train-classify.csv"",\r\n          // path: @""../../../rocket-train-classify.csv"",\r\n          hasHeader: true,\r\n          separatorChar: \',\');\r\n\r\n        Head(trainDataView, 5);\r\n\r\n        var validDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n          path: @""H:/HedgeTools/Datasets/rocket-valid-classify.csv"",\r\n          hasHeader: true,\r\n          separatorChar: \',\');\r\n\r\n        var pipeline = mlContext.Transforms.NormalizeMeanVariance(""BoxRatio"")\r\n                                .Append(mlContext.Transforms.NormalizeMeanVariance(""Thrust""))\r\n                                .Append(mlContext.Transforms.NormalizeMeanVariance(""Acceleration""))\r\n                                .Append(mlContext.Transforms.NormalizeMeanVariance(""Velocity""))\r\n                                .Append(mlContext.Transforms.NormalizeMeanVariance(""vwapGain""))\r\n                                .Append(mlContext.Transforms.NormalizeMeanVariance(""OnBalRun""))\r\n                                .AppendCacheCheckpoint(mlContext);\r\n\r\n        var model = pipeline.Fit(trainDataView);\r\n        var transformedTrainDataView = model.Transform(trainDataView);\r\n        Head(transformedTrainDataView, 5);\r\n\r\n        var optimizingMetrics = new BinaryClassificationMetric[4];\r\n        optimizingMetrics[0] = BinaryClassificationMetric.F1Score;\r\n        optimizingMetrics[1] = BinaryClassificationMetric.AreaUnderRocCurve;\r\n        optimizingMetrics[2] = BinaryClassificationMetric.AreaUnderPrecisionRecallCurve;\r\n        optimizingMetrics[3] = BinaryClassificationMetric.PositiveRecall;\r\n\r\n        var trainers = new BinaryClassificationTrainer[1];\r\n        trainers[0] = BinaryClassificationTrainer.FastTree; \r\n     // trainers[1] = BinaryClassificationTrainer.LightGbm;\r\n\r\n        var bestMetric = 0.0;\r\n        foreach (var trainer in trainers) {\r\n          foreach (var optimizingMetric in optimizingMetrics) {\r\n            var sw = Stopwatch.StartNew();\r\n\r\n            var settings = new BinaryExperimentSettings {\r\n              MaxExperimentTimeInSeconds = 1 * 60 * 60,\r\n              OptimizingMetric = optimizingMetric,\r\n              CacheDirectory = null\r\n            };\r\n            settings.Trainers.Clear();\r\n            settings.Trainers.Add(trainer);\r\n\r\n            Console.WriteLine(""\\n_____________________________________________________________________________\\n"" +\r\n                              ""Running AutoML binary classification experimeent using: "" +\r\n                              trainer + "", "" + optimizingMetric);\r\n\r\n            var experimentResult = mlContext.Auto()\r\n                                            .CreateBinaryClassificationExperiment(settings)\r\n                                            .Execute(trainData: transformedTrainDataView,\r\n           //                               .Execute(trainData: trainDataView,\r\n                                                     validDataView,\r\n                                                     labelColumnName: ""Altitude"",\r\n                                                     progressHandler: new BinaryExperimentProgressHandler());\r\n\r\n            var bestRun = experimentResult.BestRun;\r\n\r\n            Console.WriteLine(""Total models produced.... {0}"", experimentResult.RunDetails.Count());\r\n            var validDataViewWithBestScore = bestRun.Model.Transform(validDataView);\r\n            var validMetrics = mlContext.BinaryClassification.\r\n                                         EvaluateNonCalibrated(data: validDataViewWithBestScore,\r\n                                                               labelColumnName: ""Altitude"");\r\n            // Console.WriteLine(""\\nMetrics using validation dataset:"");\r\n            // PrintMetrics(validMetrics);\r\n\r\n            var crossValidationResults = mlContext.BinaryClassification\r\n                                                  .CrossValidateNonCalibrated(validDataView,\r\n                                                                              bestRun.Estimator,\r\n                                                                              numberOfFolds: 10,\r\n                                                                              labelColumnName:   ""Altitude""); \r\n                                                                \r\n            var metricsInMultipleFolds = crossValidationResults.Select(r => r.Metrics);\r\n\r\n            var AccuracyValues = metricsInMultipleFolds.Select(m => m.Accuracy);\r\n            var accuracyValues = AccuracyValues as double[] ?? AccuracyValues.ToArray();\r\n            var AccuracyAverage = accuracyValues.Average();\r\n\r\n            var F1Values = metricsInMultipleFolds.Select(m => m.F1Score);\r\n            var f1Values = F1Values as double[] ?? F1Values.ToArray();\r\n            var F1Average = f1Values.Average();\r\n\r\n            var AUCValues = metricsInMultipleFolds.Select(m => m.AreaUnderRocCurve);\r\n            var aucValues = AUCValues as double[] ?? AUCValues.ToArray();\r\n            var AUCAverage = aucValues.Average();\r\n\r\n            var AUCPRCValues = metricsInMultipleFolds.Select(m => m.AreaUnderPrecisionRecallCurve);\r\n            var aucPRCValues = AUCPRCValues as double[] ?? AUCPRCValues.ToArray();\r\n            var AUCPRCAverage = aucPRCValues.Average();\r\n\r\n            var sumOfSquaresOfDifferences = accuracyValues.Select(val => (val - AccuracyAverage) * (val - AccuracyAverage)).Sum();\r\n            var AccuraciesStdDeviation = Math.Sqrt(sumOfSquaresOfDifferences / (accuracyValues.Length - 1));\r\n            var confidenceInterval95 = 1.96 * AccuraciesStdDeviation / Math.Sqrt((accuracyValues.Length - 1));\r\n            var AccuraciesConfidenceInterval95 = confidenceInterval95;\r\n\r\n            Console.WriteLine(""CrossValidation Metrics using the validation dataset:"");\r\n            Console.WriteLine(""  trainer......................... {0}"", bestRun.TrainerName);\r\n            Console.WriteLine(""  optimizingMetric................ {0}"", optimizingMetric);\r\n            Console.WriteLine(""  AccuracyAverage................. {0}"", AccuracyAverage);\r\n            Console.WriteLine(""  F1Average....................... {0}"", F1Average);\r\n            Console.WriteLine(""  AUCAverage...................... {0}"", AUCAverage);\r\n            Console.WriteLine(""  AUCPRCAverage................... {0}"", AUCPRCAverage);\r\n            Console.WriteLine(\r\n              ""  Cross Validation, AUC........... {0:f4}, Standard deviation: {1:f4}, Confidence Interval 95%: {2:f4}"",\r\n              AccuracyAverage, AccuraciesStdDeviation, AccuraciesConfidenceInterval95);\r\n\r\n            if (AccuracyAverage > bestMetric) {\r\n              bestMetric = AccuracyAverage;\r\n              var bestTrainer = bestRun.TrainerName;\r\n              var bestOptimizingMetric = optimizingMetric.ToString();\r\n              Console.WriteLine(""\\n  Best model\'s trainer............... {0}"", bestTrainer);\r\n              Console.WriteLine(""Best model\'s optimizingMetric........ {0}"", bestOptimizingMetric);\r\n              Console.WriteLine(""Best model\'s AccuracyAverage......... {0}"", AccuracyAverage);\r\n              Console.WriteLine(""Best model\'s F1Average............... {0}"", F1Average);\r\n              Console.WriteLine(""Best model\'s AUCAverage.............. {0}"", AUCAverage);\r\n              Console.WriteLine(""Best model\'s AUCPRCAverage........... {0}"", AUCPRCAverage);\r\n\r\n              var mlModel = bestRun.Model;\r\n              mlContext.Model.Save(mlModel, trainDataView.Schema, trainedModelPath);\r\n              Console.WriteLine(""The model is saved."");\r\n\r\n              Console.WriteLine(""\\n_____________________________________________________________________________"");\r\n              var savedModel = mlContext.Model.Load(trainedModelPath, out _);\r\n              var validDataViewWithBestScore2 = savedModel.Transform(validDataView);\r\n              var validMetrics2 = mlContext.BinaryClassification.EvaluateNonCalibrated(data: validDataViewWithBestScore2,\r\n                                                                                       labelColumnName: ""Altitude"");\r\n              Console.WriteLine(""\\nConfusion Matrix from saved model using the validation dataset:\\n{0}"",\r\n                                validMetrics2.ConfusionMatrix.GetFormattedConfusionTable());\r\n            }\r\n            sw.Stop();\r\n            var ts = sw.Elapsed;\r\n            Console.WriteLine((""Experiment time: {0:00}:{1:00}:{2:00}"", ts.Hours, ts.Minutes, ts.Seconds));\r\n          }\r\n        }\r\n        Console.WriteLine(""Done."");\r\n      }\r\n    }\r\n\r\n    private static void Main() {\r\n      ModelBuilder.Run();\r\n\r\n      var testDataset = @""H:/HedgeTools/Datasets/rocket-test-classify.csv"";\r\n      Verify.Model(trainedModelPath, testDataset);\r\n      Console.WriteLine(""Done."");\r\n      Console.ReadKey();\r\n    }\r\n  }\r\n}\r\n\r\n\r\n\r\n```\r\n\r\nAny suggestions or help will be greatly appreciated.\r\nCharles\r\n'"
663354166,5317,b'Solicitud de gu\xc3\xada para re-entrenar un modelo ya entrenado',"b'### System information\r\nNA\r\n### Issue\r\n\r\nEstoy logrando con \xc3\xa9xito incluir y utilizar el c\xc3\xb3digo de uso para mi modelo con el ML builder.\r\n\r\nBusco por cargar un modelo ya entrenado, y volverlo a entrenar con un  adicional conjunto de datos (a fin que el aprendizaje de mi modelo sea escalable sobre lo que ya hab\xc3\xada aprendido).\r\n\r\nEl c\xc3\xb3digo generado por el ML builder,  cargar el modelo y entrena uno NUEVO para el conjunto de datos nuevo, remplazando el que ya exist\xc3\xada, esto no me permite continuar ""aprendiendo"" sobre mi modelo previamente entrenado.\r\n\r\nLas documentaciones que encuentro me dirigen al anterior workflow.\r\n\r\nPueden por favor indicarme alguna gu\xc3\xada para implementar el work flow deseado:\r\nCargar modelo local ya entrenado.\r\nllamar al entrenador para que entre m\xc3\xa1s el modelo con nuevos datos.\r\nevaluar y guardar localmente el modelo.\r\n\r\nMuchas Gracias!\r\n \r\n\r\n\r\n '"
663225973,5316,"b""Unable to load DLL 'MklImports' or one of its dependencies: The specified module could not be found. (0x8007007E)""","b""### System information\r\n\r\n- **Windows server 2019 IIS / Docker Windows Container**:\r\n- **.NET Version 3.1.3**: \r\n\r\n**Project references**\r\nMicrosoft.ML 1.5.0 - 1.5.1 \r\nMicrosoft.ML.TimeSeries 1.5.0 - 1.5.1\r\nMicrosoft.ML.Mkl.Components 1.5.0 - 1.5.1 \r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n I was trying to train the model in a .NET standard 2.0 library\r\n\r\n ITransformer trainedModel = dataProcessPipeline.Fit(trainingDataView);\r\n\r\nIt doesn't work on IIS production environment (VM on Azure)  as well in a Docker Windows Container used from my development machine.\r\n\r\nI've performed several attempts in order to solve the  issue, including manual installation of the Intel Math Kernel Library through the installer.   \r\n\r\n- **What happened?**\r\n Dll not found exception\r\n\r\n- **What did you expect?**\r\n\r\nIt should work fine like on my development environment (IIS Express).\r\n\r\n### Source code / logs\r\n\r\nUnable to load DLL 'MklImports' or one of its dependencies: The specified module could not be found. (0x8007007E)    at Microsoft.ML.Transforms.TimeSeries.EigenUtils.Dsytrd(Layout matrixLayout, Uplo uplo, Int32 n, Double[] a, Int32 lda, Double[] d, Double[] e, Double[] tau)\r\n   at Microsoft.ML.Transforms.TimeSeries.EigenUtils.MklSymmetricEigenDecomposition(Single[] input, Int32 size, Single[]& eigenValues, Single[]& eigenVectors)\r\n   at Microsoft.ML.Transforms.TimeSeries.TrajectoryMatrix.ComputeSvd(Single[]& singularValues, Single[]& leftSingularvectors)\r\n   at Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModelerInternal.TrainCore(Single[] dataArray, Int32 originalSeriesLength)\r\n   at Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModelerInternal.Train(RoleMappedData data)\r\n   at Microsoft.ML.Transforms.TimeSeries.SsaForecastingEstimator.Fit(IDataView input)\r\n\r\n"""
662794188,5315,b'Load native LightGBM exported text file',"b""### Issue\r\n\r\n- I would like to be able to load a LightGBM model exported from the native library in text format directly in ML.NET LightGBM implementation.\r\n\r\nI noticed there are bindings to the save method here https://github.com/dotnet/machinelearning/blob/8631afaaaa60daa1bda734dc79d92433591f7917/src/Microsoft.ML.LightGbm/WrappedLightGbmInterface.cs#L190, but couldn't find a way to load the text file\r\n\r\n"""
661228371,5314,b'My confusion trying to use EAST text detector model with the ML.net',"b'### System information\r\n\r\n- **OS version/distro:Windows 10**:\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nHi, well I am trying to use a the EAST text detector model with the ML.net\r\nfrom here:\r\n\r\nhttps://www.kaggle.com/yelmurat/frozen-east-text-detection\r\n\r\nhowever I don\'t know if I am doing it the right way. (I only began using ML.net last month) First I tried using\r\nOpenCV with this example:\r\n\r\nhttps://github.com/opencv/opencv/blob/master/samples/dnn/text_detection.cpp\r\n\r\nIt runs fine everything is Ok, but when I tried to do the same with ML.net...\r\n\r\n- **What happened?**\r\nThe problem is that I dont understand how ML.net handle the input data, and the output data. I had an idea. I run other examples, but I couldn\'t find something similar.\r\n\r\n- **What did you expect?**\r\nI was expecting to have the same or at least similar results like those from OpenCV example.\r\n\r\n### Source code / logs\r\n\r\nFirst I define this\r\n\r\n`       static readonly string _assetsPath = Path.Combine(Environment.CurrentDirectory, ""assets"");\r\n        static readonly string _imagesFolder = Path.Combine(_assetsPath, ""imagesText"");      \r\n        static readonly string _predictSingleImage = Path.Combine(_imagesFolder, ""page10.jpg"");\r\n        static readonly string _inceptionTensorFlowModel = Path.Combine(_assetsPath, ""models"",""frozen_east_text_detection.pb"");\r\n\r\n        private const int imageHeight = 3104;// 576;  It should be multiple by 32\r\n        private const int imageWidth  = 2304; //576;  It should be multiple by 32\r\n        private const int numChannels = 3;\r\n        private const int inputSize = imageHeight * imageWidth * numChannels;`\r\n\r\n\r\nthen I load the TensorFlow model and saved as ML.net model\r\n\r\n`using var modelX = mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel);\r\n            var schema = modelX.GetModelSchema();\r\n            var inputchema = modelX.GetInputSchema();\r\n            var pipelineX = modelX.ScoreTensorFlowModel(\r\n                outputColumnNames: new[] { ""feature_fusion/Conv_7/Sigmoid"", ""feature_fusion/concat_3"" }, nameof(OutputScores.output) },\r\n                 inputColumnNames: new[] { ""input_images"" }, addBatchDimensionInput: false); }, addBatchDimensionInput: true);\r\n            List<TensorData> list = new List<TensorData>();\r\n            list.Add(new TensorData() { input = null });\r\n            IEnumerable<TensorData> enumerableData = list;\r\n            var dv = mlContext.Data.LoadFromEnumerable<TensorData>(list);//TensorData\r\n            ITransformer model = pipelineX.Fit(dv);\r\n            Directory.CreateDirectory(""Model"");\r\n            mlContext.Model.Save(model, inputchema, ""trainedModelEAST3.zip"");`\r\n\r\n\r\nAt this point everything seems to work, but here is my problem with the outputs\r\n\r\nIn OpenCV I load an Image and use this\r\n`cv::dnn::blobFromImage(frame, blob, 1.0, cv::Size(inpWidth, inpHeight), cv::Scalar(123.68, 116.78, 103.94), true, false);    \r\n`\r\nand only using this\r\n\r\n`    detector.setInput(blob);\r\n    tickMeter.start();\r\n    detector.forward(outs, outNames);\r\n    tickMeter.stop();\r\n\r\n    cv::Mat scores = outs[0];\r\n    cv::Mat geometry = outs[1];`\r\n\r\nIt\'s almost done, my inputs are clear, and my outputs too. But ML.net you need to create a class to hold the sample tensor data. So I did that\r\n\r\n` public class TensorData\r\n        {\r\n            [VectorType(imageHeight, imageWidth, numChannels)]\r\n            [ColumnName(""input_images"")]\r\n            public float[] input { get; set; }\r\n\r\n\r\n            [ColumnName(""ImagePath"")]\r\n            public string imageP { get; set; }\r\n            [ColumnName(""Name"")]\r\n            public string imageN { get; set; }\r\n        }`\r\n\r\nThis is where my confusion began because I know that my input for this model should be like this\r\n\r\n![inputs](https://user-images.githubusercontent.com/60855616/87887590-965b7200-c9f4-11ea-9d17-4bc627ea8792.png)\r\n\r\nusing this seems to work\r\n\r\n`            [VectorType(imageHeight, imageWidth, numChannels)]\r\n            [ColumnName(""input_images"")]\r\n            public float[] input { get; set; }`\r\n\r\nBut for my outputs and how to pass and image to the model I only guessing.  so using the information about the model\'s output that I find using Netron:\r\n\r\nThis is the ""scores""\r\n![outputs1](https://user-images.githubusercontent.com/60855616/87887712-71b3ca00-c9f5-11ea-8a6d-237261c1feb3.png)\r\n \r\nand this is the ""geometry"" (the box that show you where is a word in the image) \r\n![outputs2](https://user-images.githubusercontent.com/60855616/87887726-aa53a380-c9f5-11ea-8c80-8ee082c2159d.png)\r\n\r\nI create the class \r\n\r\n`        class OutputScores\r\n        {\r\n            [ColumnName(""feature_fusion/concat_3"")]\r\n            public float[] output { get; set; }\r\n\r\n            [ColumnName(""feature_fusion/Conv_7/Sigmoid"")]\r\n            public float[] output2 { get; set; }\r\n\r\n        }`\r\n\r\nwhite all that I tried to use the predict engine like this using an image (""jpg""):\r\n\r\n`            Bitmap bitmapImage = (Bitmap)Image.FromFile(_predictSingleImage);\r\n\r\n            float[] a = new float[(bitmapImage.Height * bitmapImage.Width) * 3];\r\n            Color[] c = new Color[bitmapImage.Height * bitmapImage.Width];\r\n            for (int i = 0; i < bitmapImage.Height * bitmapImage.Width; i++)\r\n            {\r\n                int row = i / bitmapImage.Width;\r\n                int col = i % bitmapImage.Width;\r\n                var pixel = bitmapImage.GetPixel(col, row);\r\n\r\n                c[i] = pixel;\r\n                //a[i + 0] = pixel.ToArgb();\r\n                a[i * 3 + 0] = pixel.R;\r\n                a[i * 3 + 1] = pixel.G;\r\n                a[i * 3 + 2] = pixel.B;\r\n            }\r\n            var aux = c.ToArray();\r\n\r\n            TensorData imageTensorData = new TensorData()\r\n            {\r\n                input = a.ToArray()\r\n            };\r\n\r\n\r\n            PredictionEngine<TensorData, OutputScores> _predictionEngineX;\r\n            var loadedModelX = mlContex.Model.Load(""trainedModelEAST3.zip"", out _);\r\n            _predictionEngineX = mlContex.Model.CreatePredictionEngine<TensorData, OutputScores>(loadedModelX);\r\n            var predictionX = _predictionEngineX.Predict(imageTensorData);\r\n            `\r\n\r\nthat gave this results:\r\n\r\nFor the ""geometry""\r\n-\t\toutput\t{float[2234880]}\tfloat[]\r\n\t\t[0]\t164.553131\tfloat\r\n\t\t[1]\t108.803284\tfloat\r\n\t\t[2]\t88.53912\t        float\r\n\t\t[3]\t157.4754\t        float\r\n\t\t[4]\t-0.00642232737\tfloat\r\n\t\t[5]\t121.783844\tfloat\r\n\t\t[6]\t93.6575\t        float\r\n\t\t[7]\t89.14729\t        float\r\n\t\t[8]\t149.1378\t        float\r\n\t\t[9]\t0.003307178\tfloat\r\n\t\t[10]\t143.044312\tfloat\r\n\t\t[11]\t92.95393\t        float\r\n\t\t[12]\t93.75145\t        float\r\n\t\t[13]\t136.486084\tfloat\r\n\t\t[14]\t-0.00365050742\tfloat\r\n\t\t[15]\t150.783173\tfloat\r\n\t\t[16]\t105.081482\tfloat\r\n\t\t[17]\t104.515717\tfloat\r\n\t\t[18]\t138.529785\tfloat\r\n\t\t[19]\t0.00163079088\tfloat\r\n\t\t[20]\t155.030853\tfloat\r\n\r\n\r\nFor the scores:\r\n-\t\toutput2\t{float[446976]}\tfloat[]\r\n\t\t[0]\t5.96046448E-08\tfloat\r\n\t\t[1]\t2.38418579E-07\tfloat\r\n\t\t[2]\t2.38418579E-07\tfloat\r\n\t\t[3]\t4.76837158E-07\tfloat\r\n\t\t[4]\t2.682209E-07\t        float\r\n\t\t[5]\t1.49011612E-07\tfloat\r\n\t\t[6]\t3.27825546E-07\tfloat\r\n\t\t[7]\t5.662441E-07\t        float\r\n\t\t[8]\t3.27825546E-07\tfloat\r\n\t\t[9]\t5.066395E-07\t        float\r\n\t\t[10]\t1.10268593E-06\tfloat\r\n\t\t[11]\t1.10268593E-06\tfloat\r\n\t\t[12]\t1.22189522E-06\tfloat\r\n\t\t[13]\t1.10268593E-06\tfloat\r\n\t\t[14]\t6.854534E-07\t        float\r\n\t\t[15]\t4.76837158E-07\tfloat\r\n\t\t[16]\t2.682209E-07\t        float\r\n\t\t[17]\t2.682209E-07\t        float\r\n\t\t[18]\t1.49011612E-07\tfloat\r\n\t\t[19]\t2.38418579E-07\tfloat\r\n\t\t[20]\t1.49011612E-07\tfloat\r\n\r\nWell that is how far I went. Could some one tell me If I implemented the loading of Image correctly or not.  My end goal is to have the same or similar result as in OpenCV \r\n\r\nthis are the packages I am using:\r\n\r\n![Packages](https://user-images.githubusercontent.com/60855616/87889195-63b67700-c9fe-11ea-8b9b-198e6513bbc3.png)\r\n\r\nand yes I tried this to create a pipeline:\r\n\r\n`var imagesDataFile = @""..\\..\\DNN_ML_CUDA_01\\assets\\imagesText\\"";\r\n\r\n\r\n            var data = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = new[]\r\n                {\r\n                        new TextLoader.Column(""ImagePath"", DataKind.String, 0),\r\n                        new TextLoader.Column(""Name"", DataKind.String, 1),\r\n                        new TextLoader.Column(""input_images"", DataKind.Single , 2),\r\n                }\r\n            }).Load(imagesDataFile);\r\n\r\n            var imagesFolder = Path.GetDirectoryName(imagesDataFile);\r\n            // Image loading pipeline. \r\n            var pipelineI = mlContext.Transforms.LoadImages(""ImageObject"",\r\n                imagesFolder, ""ImagePath"")\r\n                .Append(mlContext.Transforms.ResizeImages(""ImageObjectResized"",\r\n                    inputColumnName: ""ImageObject"", imageWidth: imageWidth, imageHeight: imageHeight))\r\n                .Append(mlContext.Transforms.ExtractPixels(""Pixels"",\r\n                    ""ImageObjectResized""))\r\n                .Append(mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel)\r\n                              .ScoreTensorFlowModel(\r\n                                     outputColumnNames: new[] { ""feature_fusion/Conv_7/Sigmoid"", ""feature_fusion/concat_3"" },\r\n                                     inputColumnNames: new[] { ""input_images"" },\r\n                                     addBatchDimensionInput: false))\r\n                ;\r\n\r\n            List<TensorData> list = new List<TensorData>();\r\n            list.Add(new TensorData() { input = null });\r\n            IEnumerable<TensorData> enumerableData = list;\r\n            var dvv = mlContext.Data.LoadFromEnumerable<TensorData>(list);//TensorData\r\n\r\n            var model = pipelineI.Fit(dvv);\r\n\r\n\r\n            using var modelX = mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel);\r\n            var testeschema1 = modelX.GetInputSchema();\r\n\r\n            Directory.CreateDirectory(""Model"");\r\n            mlContext.Model.Save(model, testeschema1, ""trainedModelEAST3.zip"");\r\n`\r\nIt gave me the same results\r\n\r\nfor reference these are the websites that I use for this project:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.imageestimatorscatalog.loadimages?view=ml-dotnet\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-do-i-train-my-model-on-categorical-data\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.imageestimatorscatalog.extractpixels?view=ml-dotnet\r\n\r\nhttps://devblogs.microsoft.com/cesardelatorre/run-with-ml-net-c-code-a-tensorflow-model-exported-from-azure-cognitive-services-custom-vision/\r\n\r\nhttps://www.pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/\r\n\r\nhttps://devblogs.microsoft.com/cesardelatorre/training-image-classification-recognition-models-based-on-deep-learning-transfer-learning-with-ml-net/\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowmodel.scoretensorflowmodel?view=ml-dotnet\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/5286\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow\r\n\r\nIf somebody could show me an example, of guide me or anything that would be great.'"
660740597,5312,b'Async operation has not completed error',"b""It seems some scenarios cause this error after looking at this [StackOverflow question](https://stackoverflow.com/questions/62976568/system-invalidoperationexception-the-asynchronous-operation-has-not-completed).\r\n\r\n```\r\nat System.Threading.Channels.AsyncOperation.ThrowIncompleteOperationException() at System.Threading.Channels.AsyncOperation1.GetResult(Int16 token)   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore()\r\n```\r\n\r\nThis seems to be caused by a change I added in #5123. \r\n\r\nTagging @eerhardt @harishsk for visibility. I'll work on a fix for this."""
659786637,5311,b'throw a more useful error if a user loads a newer model than is supported by the current ML\xe2\x80\xa4NET version',b'follow up improvement for below issue: \r\nhttps://github.com/dotnet/machinelearning/issues/5303 \r\n'
658646323,5309,"b'Entrypoints for RobustScaler, ToString removed'","b'ML.NET 1.5.1 breaking changes for NimbusML.\r\nEntrypoints RobustScaler, ToString and CategoryImputer removed.\r\nThe PR was #5209 \r\nNimbusML can do changes for CategoryImputer to use ReplaceMissingValues entrypoint\r\nWe need to expose TypeConvertingTransformer  and NormalizingEstimator as entrypoints\r\n'"
657943987,5308,"b""Unable to load DLL 'FastTreeNative' in Azure Function ""","b""### System information\r\n\r\n- **OS version/distro**: win10 (10.0.19041 Build 19041)\r\n- **.NET Version (eg., dotnet --info)**: .net core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nML.net 1.5.1\r\n- **What happened?**\r\nIt is no issue to run sample code in console app, but it's repeatedly reporting below error when run CreateModel() from a testing azure function:\r\n=============== Training  model ===============\r\n[7/16/2020 7:41:11 AM] Executed 'NormalizeFunction' (Failed, Id=64d8e39f-5a8b-40e9-b335-3cf2cbf4ce45)\r\n[7/16/2020 7:41:11 AM] System.Private.CoreLib: Exception while executing function: NormalizeFunction. System.Private.CoreLib: One or more errors occurred. (Unable to load DLL 'FastTreeNative' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)). Microsoft.ML.FastTree: Unable to load DLL 'FastTreeNative' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E).\r\n- **What did you expect?**\r\nIt should run without exception as it did in console app\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
657106630,5307,b'how to work 2 inputs to loading ONNX model by ML.NET',"b'### Question\r\nI built a ONNX model with 2 inputs in python.\r\nONNX with 2 inputs works in python.\r\nBut I can\'t find any sample code in ML.NET with multiple inputs.\r\nCould you tell me how to build pipline with two inputs in ML.NET ?\r\n\r\n## ONNX Infomation ##\r\n[INPUTNAME]\r\n   input_1 [\'None\', 224, 224, 3]\r\n   input_2 [\'None\', 18]\r\n[OUTPUTNAME]\r\n   dense_3 [\'None\', 5]\r\n\r\n### Source code \r\n##################################################\r\n# ML.NET\r\n##################################################\r\npipeline=imageLoader.Append(imageResizer).Append(pixelExtractor).Append(onnxEstimator);\r\nmodel = pipeline.Fit(data);\r\n* The size of imageResizer is [224,224,3] \r\n\r\n\r\n\r\n##################################################\r\n# Python (2 inputs onnx works)\r\n##################################################\r\n## Prediction Process ##\r\n   x1 = x1.astype(np.float16)\r\n   x2 = x2.astype(np.float16)\r\n   predict = SESS.run([""dense_3""],{""input_1"":x1,""input_2"":x2})[0]'"
656468317,5306,b'Index out of range exception in execute',"b'### System information\r\n\r\nwindows 10 version 1803\r\nNET Version (3.1.300): \r\nAutoML version : 0.17.1\r\n(also tested on version 0.14.0)\r\n### Issue\r\n\r\nI am trying to use AutoML for the first time. but I get IndexOutOfRangeException on execute method call.\r\n\r\n### Source code / logs\r\nstatic void Main(string[] args)\r\n\t\t{\r\n\t\t\tMLContext mlContext = new MLContext();\r\n\t\t\tIDataView trainDataView = mlContext.Data.LoadFromTextFile<ModelInput>(""input.csv"", hasHeader: true);\r\n\t\t\tvar experimentSettings = new RegressionExperimentSettings();\r\n\t\t\texperimentSettings.MaxExperimentTimeInSeconds = 100;\r\n\t\t\tRegressionExperiment experiment = mlContext.Auto().CreateRegressionExperiment(experimentSettings);\r\n\t\t\tExperimentResult<RegressionMetrics> experimentResult = experiment.Execute(trainDataView, ""Withdrawal"");\r\n\t\t\tRegressionMetrics metrics = experimentResult.BestRun.ValidationMetrics;\r\n\t\t\tConsole.WriteLine($""R-Squared: {metrics.RSquared:0.##}"");\r\n\t\t\tConsole.WriteLine($""Root Mean Squared Error: {metrics.RootMeanSquaredError:0.##}"");\r\n\t\t}\r\n\r\nError:\r\n\r\nUnhandled exception. System.ArgumentOutOfRangeException: Index was out of range. Must be non-negative and less than the size of the collection. (Parameter \'index\')\r\n   at Microsoft.ML.AutoML.CrossValSummaryRunner`1.Run(SuggestedPipeline pipeline, DirectoryInfo modelDirectory, Int32 iterationNum)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.ExecuteCrossValSummary(IDataView[] trainDatasets, ColumnInformation columnInfo, IDataView[] validationDatasets, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, String labelColumnName, String samplingKeyColumn, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at FunWithMlnet.Program.Main(String[] args) in C:\\Users\\User\\source\\repos\\FunWithWithdrawalsData\\FunWithMlnet\\Program.cs:line 18'"
655621175,5305,b'Length of memory (691200) must match product of dimensions (3).',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: netcoreapp3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I loaded an ONNX model to ML.NET and tried to run it.\r\n- **What happened?** I am getting this exception when trying to do a prediction: ""Length of memory (691200) must match product of dimensions (3)""\r\n- **What did you expect?** Prediction \r\n\r\n### Source code / logs\r\n\r\nFull error message:\r\n`System.ArgumentException: \'Length of memory (691200) must match product of dimensions (3).\'`\r\n\r\nPipeline that I am using:\r\n`            var pipeline = _mlContext.Transforms\r\n                .ResizeImages(\r\n                    outputColumnName: ""resized_image"",\r\n                    imageWidth: 640,\r\n                    imageHeight: 360,\r\n                    inputColumnName: ""image"")\r\n                .Append(_mlContext.Transforms\r\n                    .ExtractPixels(\r\n                        outputColumnName: ModelConfigParameters.InputColumns.First(),\r\n                        outputAsFloatArray: false,\r\n                        colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Rgb,\r\n                        orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB,\r\n                        interleavePixelColors: false,\r\n                        inputColumnName: ""resized_image""))\r\n                .Append(_mlContext.Transforms\r\n                    .ApplyOnnxModel(\r\n                        modelFile: onnxModelPath,\r\n                        outputColumnNames: ModelConfigParameters.OutputColumns,\r\n                        inputColumnNames: ModelConfigParameters.InputColumns));`\r\n\r\n\r\nInput object to the pipeline:\r\n```\r\npublic class InputImage\r\n{\r\n    [ImageType(width: 640, height: 360)]\r\n    [ColumnName(""image"")]\r\n    public Bitmap Image { get; set; }\r\n\r\n}\r\n```\r\n\r\nOutput object (predictions):\r\n```\r\npublic class OutputPredictions\r\n{\r\n    [ColumnName(""detection_scores:0"")]\r\n    public float[] DetectionScores;\r\n\r\n    [ColumnName(""detection_boxes:0"")]\r\n    public float[] DetectionBoxes;\r\n\r\n    [ColumnName(""detection_classes:0"")]\r\n    public float[] DetectionClasses;\r\n\r\n    [ColumnName(""num_detections:0"")]\r\n    public float[] NumDetections;\r\n}\r\n```\r\n\r\n\r\n\r\nThe code that fails on the last line:\r\n```\r\n        var imgPath = @""some/path/to/image.png"";\r\n        var img = (Bitmap)Image.FromFile(imgPath);\r\n        var inputData = new InputImage() { Image = img };\r\n\r\n        var emptyData = _mlContext.Data.LoadFromEnumerable(new List<InputImage>());\r\n        var model = pipeline.Fit(emptyData);\r\n\r\n        var prediction = _mlContext.Model.CreatePredictionEngine<InputImage, OutputPredictions>(model).Predict(inputData);\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\nWhen I inspect pipeline using the var preview = pipeline.Preview(emptyData); I get this scheme:\r\n![img1_scheme](https://user-images.githubusercontent.com/5252663/87278343-80c1e600-c4e4-11ea-8daf-f2cc4ef0eef2.png)\r\n\r\n\r\n\r\nand the input and output of the ONNX model is following:\r\n\r\n![img2_inout](https://user-images.githubusercontent.com/5252663/87278357-8dded500-c4e4-11ea-8f79-2526764ec316.png)\r\n\r\n'"
655296361,5304,"b'Error al llamar ""ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);""             '","b'### System information\r\n\r\n- **OS Microsoft Win 10\r\n- **.NET Version 2019: \r\n\r\n\r\n- **What did you do?**\r\nEstoy generando c\xc3\xb3digo con ML.builder.  De hecho he logrado generar y ejecutar con exito un par de modelos donde el modelo propuesto por ML.Builder fue un fasttree.\r\nPara este nuevo set de datos el modelo generado el  el  ML.Builder fue el OlsRegression . Fue agregado el c\xc3\xb3digo al proyecto.  \r\nHe a actualizado las librerias incluidas a la version 1.0.0 , pues me lo pidi\xc3\xb3 igual que los casos anteriores.\r\n\r\nEstoy cargando con exito los datos en el ModelInput\r\nEstoy llamando a ConsumeModel.Predict ... dando el problema t\xc3\xa9cnico mencionado  en la llamada\r\n\r\nITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n            .\r\nde la clase consumeModel.\r\n\r\nHe vuelto a iniciar de cero, para descartar que por alguna X raz\xc3\xb3n el  modelo .zip estuviese corrupto, PERO tengo el mismo resultado.\r\n\r\n- **What happened?**\r\n\r\n- **What did you expect?**\r\naclaro ya he generado  y utilizado otros modelos, los cuales suelen funcionar luego de hacer las actualizaciones a las librer\xc3\xadas y los amarres de c\xc3\xb3digo respectivos.  Pero  en este caso ... persiste el  error, en vez de poder hacer UNA prediccion \r\n\r\n### Source code / logs\r\n\r\n### System.InvalidOperationException\r\n  HResult=0x80131509\r\n  Mensaje = Error during class instantiation\r\n  Origen = Microsoft.ML.Core\r\n  Seguimiento de la pila:\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\r\n   at PaLanteML.Model.ConsumeModel.CreatePredictionEngine() in D:\\Toni\\Soluciones\\PaLante\\PaLanteML.Model\\ConsumeModel.cs:line 31\r\n   at System.Lazy`1.CreateValue()\r\n\r\nEsta excepci\xc3\xb3n se gener\xc3\xb3 originalmente en esta pila de llamadas:\r\n    [C\xc3\xb3digo externo]\r\n\r\nExcepci\xc3\xb3n interna 1:\r\nTargetInvocationException: Se produjo una excepci\xc3\xb3n en el destino de la invocaci\xc3\xb3n.\r\n\r\nExcepci\xc3\xb3n interna 2:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nExcepci\xc3\xb3n interna 3:\r\nTargetInvocationException: Se produjo una excepci\xc3\xb3n en el destino de la invocaci\xc3\xb3n.\r\n\r\nExcepci\xc3\xb3n interna 4:\r\nFormatException: Uno de los elementos identificados tiene un formato no v\xc3\xa1lido.\r\n\r\n'"
655177865,5303,b'Not being able to generate code from model on ML.NET CLI',"b""### System information\r\n\r\n- **OS version/distro**: Running over Azure Machine Learning compute cluster, not completely sure on the OS behind it.\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.0, I believe.\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCLI command performed: _saveModel in=inputs/model.zip code=outputs/code.cs_\r\n\r\n- **What happened?**\r\nI've got the following error message:\r\n_Error during class instantiation\r\nOne of the identified items was in an invalid format._\r\n\r\n- **What did you expect?**\r\nTo have the model code generated.\r\n\r\n### Source code / logs\r\nThe library generated a log file, but since I was running over a dynamically generated Azure Machine Learning compute cluster, I was not able to retrieve it."""
654938281,5299,"b""Unable to load shared library 'CpuMathNative' or one of its dependencies.""","b""### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan the following command from a published AML experiment pipeline:\r\n`maml.exe TrainTest test=inputs/test.tsv tr=LogisticRegression scorer=BinaryClassifierScorer eval=BinaryClassifierEvaluator norm=No cache=+ dout=outputs/pred.tsv loader=TextLoader{col=Name:TX:3 col=Features:R4:4-222 col=Label:R4:0 header=+} data=inputs/train.tsv out=outputs/model.zip seed=137`\r\n\r\n- **What happened?**\r\n```\r\n(1) Unexpected exception: One or more errors occurred. (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory) (Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libCpuMathNative: cannot open shared object file: No such file or directory), 'System.AggregateException'\r\n   at System.Threading.Tasks.TaskReplicator.Run[TState](ReplicatableUserAction`1 action, ParallelOptions options, Boolean stopOnFirstFailure)\r\n   at System.Threading.Tasks.Parallel.ForWorker[TLocal](Int32 fromInclusive, Int32 toExclusive, ParallelOptions parallelOptions, Action`1 body, Action`2 bodyWithState, Func`4 bodyWithLocal, Func`1 localInit, Action`1 localFinally)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.Tasks.Parallel.ThrowSingleCancellationExceptionOrOtherException(ICollection exceptions, CancellationToken cancelToken, Exception otherException)\r\n   at System.Threading.Tasks.Parallel.ForWorker[TLocal](Int32 fromInclusive, Int32 toExclusive, ParallelOptions parallelOptions, Action`1 body, Action`2 bodyWithState, Func`4 bodyWithLocal, Func`1 localInit, Action`1 localFinally)\r\n   at System.Threading.Tasks.Parallel.For(Int32 fromInclusive, Int32 toExclusive, Action`1 body)\r\n   at Microsoft.ML.Trainers.LbfgsTrainerBase`3.DifferentiableFunctionMultithreaded(VBuffer`1& xDense, VBuffer`1& gradient, IProgressChannel pch) in /machinelearning/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs:line 698\r\n   at Microsoft.ML.Trainers.LbfgsTrainerBase`3.DifferentiableFunction(VBuffer`1& x, VBuffer`1& gradient, IProgressChannelProvider progress) in /machinelearning/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs:line 641\r\n   at Microsoft.ML.Numeric.L1Optimizer.L1OptimizerState.EvalCore(VBuffer`1& input, VBuffer`1& gradient, IProgressChannelProvider progress) in /machinelearning/src/Microsoft.ML.StandardTrainers/Optimizer/L1Optimizer.cs:line 119\r\n   at Microsoft.ML.Numeric.Optimizer.OptimizerState.Init() in /machinelearning/src/Microsoft.ML.StandardTrainers/Optimizer/Optimizer.cs:line 241\r\n   at Microsoft.ML.Numeric.L1Optimizer.MakeState(IChannel ch, IProgressChannelProvider progress, DifferentiableFunction function, VBuffer`1& initial) in /machinelearning/src/Microsoft.ML.StandardTrainers/Optimizer/L1Optimizer.cs:line 59\r\n   at Microsoft.ML.Numeric.Optimizer.Minimize(DifferentiableFunction function, VBuffer`1& initial, ITerminationCriterion term, VBuffer`1& result, Single& optimum) in /machinelearning/src/Microsoft.ML.StandardTrainers/Optimizer/Optimizer.cs:line 611\r\n   at Microsoft.ML.Trainers.LbfgsTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data) in /machinelearning/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs:line 573\r\n   at Microsoft.ML.Trainers.LbfgsTrainerBase`3.TrainModelCore(TrainContext context) in /machinelearning/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs:line 433\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Microsoft.ML.ITrainer<Microsoft.ML.IPredictor>.Train(TrainContext context) in /machinelearning/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 100\r\n   at Microsoft.ML.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor, RoleMappedData testData) in /machinelearning/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 280\r\n   at Microsoft.ML.Data.TrainTestCommand.RunCore(IChannel ch, String cmd) in /machinelearning/src/Microsoft.ML.Data/Commands/TrainTestCommand.cs:line 186\r\n   at Microsoft.ML.Data.TrainTestCommand.Run() in /machinelearning/src/Microsoft.ML.Data/Commands/TrainTestCommand.cs:line 108\r\n   at Microsoft.ML.Tools.Maml.MainCore(IHostEnvironment env, String args, Boolean alwaysPrintStacktrace) in /machinelearning/src/Microsoft.ML.Maml/MAML.cs:line 142\r\n```\r\n\r\n- **What did you expect?**\r\nWe expect a trained model, not this error. \r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\nDocker file: \r\n```\r\nFROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS builder\r\n\r\nRUN apt-get update \r\nRUN apt-get install -y git cmake clang-3.9 libomp-dev\r\nRUN git clone https://github.com/dotnet/machinelearning.git\r\n\r\nRUN cd /machinelearning &&\\\r\n    git submodule update --init &&\\\r\n    bash build.sh -release\r\n\r\n\r\nRUN mkdir /mlnet_ &&\\\r\n    dotnet publish -c Release --no-build  machinelearning/src/Microsoft.ML.Console --output mlnet_ --self-contained false\r\n\r\nRUN mkdir /mlnet &&\\\r\n    cp -RL /mlnet_/* /mlnet/\r\n\r\n# RUN cp -r /mlnet /mlnet_all\r\n\r\nRUN rm -rf /mlnet/runtimes/osx-x64 &&\\\r\n    rm -rf /mlnet/runtimes/win &&\\\r\n    rm -rf /mlnet/runtimes/win-x64 &&\\\r\n    rm -rf /mlnet/runtimes/win-x86\r\n\r\n\r\n\r\nFROM mcr.microsoft.com/azureml/o16n-sample-user-base/ubuntu-miniconda\r\n\r\nRUN apt-get update &&\\\r\n    apt-get install -y apt-transport-https fuse\r\n\r\nRUN wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > microsoft.asc.gpg\r\nRUN mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/\r\nRUN chown root:root /etc/apt/trusted.gpg.d/microsoft.asc.gpg\r\n\r\nRUN wget -q https://packages.microsoft.com/config/debian/10/prod.list\r\nRUN mv prod.list /etc/apt/sources.list.d/microsoft-prod.list\r\nRUN chown root:root /etc/apt/sources.list.d/microsoft-prod.list\r\n\r\nRUN apt-get update &&\\\r\n    apt-get install -y dotnet-runtime-2.1\r\n\r\nCOPY --from=builder /mlnet /mlnet/.\r\n\r\nRUN ldconfig -n /mlnet\r\nENV LD_LIBRARY_PATH=/mlnet/runtimes/linux-x64/native:/mlnet/runtimes/unix/lib/netcoreapp2.0:$LD_LIBRARY_PATH\r\n```"""
653124819,5294,"b'""Could not find operation"" Error When Scoring a Tensorflow Model'","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10 1909 Build \r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.400-preview-015178\r\n Commit:    60cb58d3b1\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.400-preview-015178\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.2\r\n  Commit:  916b5cba26\r\n\r\n.NET Core SDKs installed:\r\n  3.0.100-preview8-013656 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.400-preview-015178 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.App 3.0.0-preview8.19405.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.DesktopUI.App 3.0.0-alpha-26921-3 [C:\\Program Files\\dotnet\\shared\\Microsoft.DesktopUI.App]\r\n  Microsoft.NETCore.App 3.0.0-preview8-28405-07 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0-preview8-28405-07 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempted to load and score a Tensorflow model.\r\n\r\n- **What happened?**\r\nWhen running it gave a \'Could not find operation ""input"" inside graph ""grap-key-1/"".\' error.\r\n\r\n### Source code / logs\r\nUsed [this Colab notebook](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb) locally and added the `model.save(""mnist-model.h5"", save_format=""h5"")` line to save the model to a local file.\r\n\r\nThe model as shown in Netron:\r\n![image](https://user-images.githubusercontent.com/1578160/86899782-719ffa00-c0d8-11ea-9d9d-1363c88daaaa.png)\r\n\r\nUsed the below ML.NET code to load and score the model:\r\n\r\n```csharp\r\npublic class DigitInput\r\n{\r\n    public float[] DigitData { get; set; }\r\n}\r\n\r\nvar context = new MLContext();\r\n\r\nvar emptyData = new List<DigitInput>();\r\n\r\nvar data = context.Data.LoadFromEnumerable(emptyData);\r\n\r\nvar pipeline = context.Model.LoadTensorFlowModel(""./mnist-model.h5"")\r\n  .ScoreTensorFlowModel(new[] { ""dense_1"" }, new[] { ""input"" }, addBatchDimensionInput: true)\r\n  .Append(context.MulticlassClassification.Trainers.LbfgsMaximumEntropy(""LabelKey"", ""dense_1""))\r\n  .Append(context.Transforms.Conversion.MapKeyToValue(""PredictedLabelValue"", ""PredictedLabel""));\r\n\r\npipeline.Fit(data);\r\n```\r\n\r\nI\'m sure I\'m missing something but not sure what that is. \xf0\x9f\x98\x84 '"
653098668,5293,b'Opaque disruptive handling of variable axes of ONNX-models',"b'**### System information**\r\n- Win 10, 1903\r\n- .NET 4.7.2\r\n\r\n**### Issue**\r\nremark: I do have a functional workaround solution, but it requires quite some nasty additional code and probably is a bit slower than optimal.\r\n\r\nThe main point of critique here concerns the OnnxTransform class.\r\n\r\n**What did you do?**\r\nTried to do inference with an ONNX-model for sequence labeling with two variable input axes (batch and sequence).\r\n\r\nThe whole input (3 dimensions: batch, sequence, features) were put into one big float[]. Still not sure whether this is really the correct way. All attempts to use multidimensional input fields failed.\r\n\r\n**What happened?**\r\nAs stated in source code (OnnxTransform.MakeRowMapper(...), see below), dimensions of variable input axes were set to 1, resulting in incorrect batches and sequences of size 1 each, regardless of specified DataView.\r\n\r\nThere is no explicit hint leading to the dimensionality reduction, however. The problem is documented, but that\'s in a private method. You only get an exception when feeding your whole sequence (as stated as one big float[]), because due to the dimension reduction the set up model expects length 1 * 1 * FeatureLength, and the input vector gets is large for that. At least that exception tells you that the product of the dimensions is relevant.\r\n\r\nThe workaround consists of setting up the ""model"" for each sequence by using the ApplyOnnxModel-overload with the input size dictionary ""shapesDictionary"". The documentation for that overload method is a bit cryptic, though (see below). It does allow to override the reduction to 1 of the variable axes (and only for those!) by using the values in the dictionary, but I learned that from the source code, not from the documentation.\r\n\r\nThe DataView has to be reset for each sequence, too, of course, to contain the specific sequence length.\r\n\r\nTook unnecessarily long to find the source of the problem and the workaround solution.\r\n\r\n**What did you expect?**\r\nBest case: Full support for variable input dimensions, which should extend to the DataView and the model.\r\n\r\n2nd best: Even for my chosen workaround of adjusting everything for each sequence to contain specific sequence length, the model-row-mapper should infer the correct dimensions instead of reducing them to 1 (there IS a todo comment for that). Fortunately, the time for the resets still make the workaround kind of usable. (although at batch size 1, so far, for more padding will probably be necessary, the effect of which remains to be checked)\r\n\r\nAt least: Output some kind of hint that the reduction takes place, at least in the public documentation for ApplyOnnxModel(...) or with further information in the exception when the sizes don\'t fit.\r\n\r\n\r\n### Source code / logs\r\nFrom OnnxTransform.cs:\r\n\r\n```\r\n        private protected override IRowMapper MakeRowMapper(DataViewSchema inputSchema) => new Mapper(this, inputSchema);\r\n\r\n        /// <summary>\r\n        /// This design assumes that all unknown dimensions are 1s. It also convert scalar shape [] in ONNX to [1].\r\n        /// [TODO] We should infer the unknown shape from input data instead of forcing them to be 1.\r\n        /// </summary>\r\n        private static IEnumerable<int> AdjustDimensions(OnnxShape shape)\r\n        {\r\n            if (shape.Count > 0)\r\n            {\r\n                return shape.Select(x => (x <= 0) ? 1 : x);\r\n            }\r\n            return new[] { 1 };\r\n        }\r\n```\r\n\r\nFrom OnnxCatalog.ApplyOnnxModel(...) not too helpful documentation:\r\n```\r\n        /// <param name=""shapeDictionary"">ONNX shape should be used to over those loaded from <paramref name=""modelFile""/>.</param>\r\n```\r\nsuggestion:\r\n```\r\n        /// <param name=""shapeDictionary"">Variable dimension sizes as stated in the loaded <paramref name=""modelFile""/> are replaced by dimension sizes from this dictionary. All dimensions, also nonvariable, have to be given, though. For keys use names as stated in the ONNX model, e.g. ""input""</param>\r\n```'"
651371898,5286,"b""Input shape mismatch: Input 'image_tensor' has shape (-1, -1, -1, 3), but input data is of length 2160000.'""","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI created my own TensorFlow object detection model and tried to load it in a C# console application.\r\n- **What happened?**\r\nWhen I tried to create a model by using pipeline.fit I get this error System.ArgumentOutOfRangeException: \xe2\x80\x9dSystem.InvalidOperationException: \'Input shape mismatch: Input \'image_tensor\' has shape (-1, -1, -1, 3), but input data is of length 2160000.\'\r\n\r\n- **What did you expect?**\r\nI would have been able to create the model and continue to create the prediction engine and test my TensorFlow.\r\n\r\n### Source code / logs\r\n\r\nHere is how I am loading the pipeline\r\n\r\nvar pipeline = mlContext.Transforms\r\n                .LoadImages(""image_tensor"", @""E:\\output_original_image"", nameof(ImageData.ImagePath))\r\n                .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""image_tensor"", imageWidth: 1200, imageHeight: 600, inputColumnName: ""image_tensor""))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""image_tensor"", interleavePixelColors: true, outputAsFloatArray: false))\r\n                .Append(mlContext.Model.LoadTensorFlowModel(modelLocation)\r\n              .ScoreTensorFlowModel(outputColumnNames: new[] { ""detection_boxes"", ""detection_classes"", ""detection_scores"", ""num_detections"" }, inputColumnNames: new[] { ""image_tensor"" }, addBatchDimensionInput: true));\r\n\r\n\r\n\r\n\r\nWhen I try to load the model inPython like so it works just fine.\r\n\r\nimage_tensor = detection_graph.get_tensor_by_name(\'image_tensor:0\')\r\ndetection_boxes = detection_graph.get_tensor_by_name(\'detection_boxes:0\')\r\ndetection_scores = detection_graph.get_tensor_by_name(\'detection_scores:0\')\r\ndetection_classes = detection_graph.get_tensor_by_name(\'detection_classes:0\')\r\nnum_detections = detection_graph.get_tensor_by_name(\'num_detections:0\')\r\n\r\n\r\nimage = cv2.imread(PATH_TO_IMAGE)\r\nimage_expanded = np.expand_dims(image, axis=0)\r\n\r\nprint(""going to run the model now"")\r\n\r\n(boxes, scores, classes, num) = sess.run(\r\n    [detection_boxes, detection_scores, detection_classes, num_detections],\r\n    feed_dict={image_tensor: image_expanded})\r\nAny ideas on how to find the input column that ML.NET wants?\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.'"
651127529,5285,"b""System.MissingMethodException: 'Method not found: 'System.Threading.Tasks.Task`1<ResourceDownloadResults> ""","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Framework 4.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to train a model with InceptionV3\r\n- **What happened?**\r\nCrashed with MissingMethod\r\n- **What did you expect?**\r\nExpected no errors\r\n\r\n### Source code / logs\r\n\r\n            var options = new ImageClassificationTrainer.Options()\r\n            {\r\n                FeatureColumnName = ""Image"",\r\n                LabelColumnName = ""LabelAsKey"",\r\n                Arch = ImageClassificationTrainer.Architecture.InceptionV3,\r\n                Epoch = 50,       //100\r\n                BatchSize = 10,\r\n                LearningRate = 0.01f,\r\n                MetricsCallback = (metrics) => Console.WriteLine(metrics),\r\n                ValidationSet = testDataView\r\n            };\r\n\r\n\r\nSystem.MissingMethodException: \'Method not found: \'System.Threading.Tasks.Task`1 ResourceDownloadResults Microsoft.ML.Internal.Utilities.ResourceManagerUtils.EnsureResource(Microsoft.ML.Runtime.IHostEnvironment, Microsoft.ML.Runtime.IChannel, System.String, System.String, System.String, Int32)\'.\'\r\n\r\n\r\nHello, I was tring to train a model with ImageClassificationTrainer and tried to user InceptionV3 in .NetFramework4.7 and it gave me MissingMethodException. \r\nTried the same code in .NetCore 3.1 and the problem wasn\'t there \r\nIs there a fast WA or a Fix for this kind of problem? Can someone advise?'"
651016624,5284,b'ML.NET CLI support for F#',"b'### System information\r\n\r\n- **OS version/distro**: `Microsoft Windows [Version 10.0.19041.329]`\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.301\r\n Commit:    7feb845744\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19041\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.301\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.5\r\n  Commit:  65cd789777\r\n\r\n.NET Core SDKs installed:\r\n  3.1.301 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.App 3.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 3.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n```\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to generate F# project using mlnet CLI tool.\r\n- **What happened?**\r\nNo such option, only C# projects.\r\n- **What did you expect?**\r\nAn option to generate F# code.\r\n\r\n### Source code / logs\r\n```\r\nmlnet --version\r\n16.1.1+acd4a98c2ef0dd6575de234c00ddc4f48d1d4f75\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
650751508,5283,b'Averaged Perceptron in MultiClass classification',"b'Hi,\r\n\r\nI am trying to use the AveragedPerceptron trainer in a multiclass scenario with labeled columns like ""1"", ""2"" or ""3"", but I only found an example in a binary classification problem, which is not what I want.\r\n\r\nIs there a document mentioned AveragedPerceptron in Multiclass problem? \r\nOr how can I approach it?\r\n\r\nI originally used the ModelBuilder to training my multiclass data, and I got an AveragedPerceptron model. Now, I want to customize the training process.\r\n\r\nThanks\r\n\r\n'"
650497540,5281,b'Request : Apply Lemma / stemming in FeaturizeText options ',"b'Hi\r\nFirst Thank you for all the work done, i know that FeaturizeText apply NLP preprocessing like skipword with a specifique language : \r\n![image](https://user-images.githubusercontent.com/16559628/86459192-bddcea00-bd26-11ea-8274-d3ad23a55eeb.png)\r\n\r\nBut is there a way to apply lemma / stemming in this function ? \r\n'"
650129012,5278,b'Usabilla Feedback: User is facing dependency issue',"b""@v-mepa commented on [Tue Jun 30 2020](https://github.com/dotnet/machinelearning-modelbuilder/issues/874)\n\n**User Comment:** There is a dependency problem with Microsoft.ML and Microsoft.ML.DataView needing System.Collections.Immutable 1.2.3.0. Not sure how System.Collections.Immutable 1.7 (newest version) got in the packages directory but I can't change it to the old version so can please update Microsoft.ML.DataView and Microsoft.ML to use any version higher than 1.2.3.0?\r\n**URL:** https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet\r\n**OS:** MacOSX\r\n**Browser:** Safari 13.1\r\n**Device:** Desktop\r\n\r\n![image](https://user-images.githubusercontent.com/42360097/86171588-cbe5fd00-bad1-11ea-82ae-caddb4d5e322.png)\r\n\n\n"""
650115290,5277,"b'No ONNX model export support for {FixedPlatt, Isotonic, Naive}CalibratorEstimator(s)'","b'For tracking purposes. The following CalibratorEstimators do not have ONNX model conversion support:\r\n- `FixedPlattCalibratorEstimator`\r\n- `IsotonicCalibratorEstimator`\r\n- `NaiveCalibratorEstimator`\r\n\r\n`PlattCalibratorEstimator` does have ONNX export support. This issue will be closed when the remaining calibrator estimators have ONNX export support, and are being tested for ONNX conversion in the manner below as `PlattCalibratorEstimator` is being tested: \r\nhttps://github.com/dotnet/machinelearning/blob/81357ba85f1410d81f92e8b1e0632e41a0f10b02/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L265-L300\r\n'"
650024649,5276,b'Request: Support Image segmentation',"b'Is there, or will there be a way to use ML.net for object instance segmentation in an image? Or do I have to use tensorflow wrapper directly for that?'"
649092041,5274,b'[TimeSeries Explanation] Score is NaN',"b'### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**: ML.Net 1.5.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**  Invoke `var prediction = this.mlContext.AnomalyDetection.LocalizeRootCause(input);`\r\n- **What happened?** `rootCauseItem.Score = double.NaN`\r\n- **What did you expect?** Should return a meaningful score (either 0 or 1)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n```\r\nstring jsonString = """"{\\""AnomalyTimestamp\\"":\\""1997-05-19T00:00:00\\"",\\""AnomalyDimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""\\""},\\""Slices\\"":[{\\""TimeStamp\\"":\\""1997-05-19T00:00:00\\"",\\""Points\\"":[{\\""Value\\"":8995.35,\\""ExpectedValue\\"":-120.28187410606782,\\""IsAnomaly\\"":true,\\""Dimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""Beverages\\""},\\""Delta\\"":9115.6318741060677},{\\""Value\\"":1282.02,\\""ExpectedValue\\"":1374.808978001977,\\""IsAnomaly\\"":false,\\""Dimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""Condiments\\""},\\""Delta\\"":-92.788978001977057},{\\""Value\\"":1686.7,\\""ExpectedValue\\"":2014.8946291211198,\\""IsAnomaly\\"":false,\\""Dimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""Confections\\""},\\""Delta\\"":-328.19462912111976},{\\""Value\\"":174.15,\\""ExpectedValue\\"":215.02809847811903,\\""IsAnomaly\\"":false,\\""Dimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""Dairy Products\\""},\\""Delta\\"":-40.878098478119028},{\\""Value\\"":12138.22,\\""ExpectedValue\\"":9066.203,\\""IsAnomaly\\"":true,\\""Dimension\\"":{\\""__Sandbox.Categories.CategoryName__\\"":\\""\\""},\\""Delta\\\r\n"":3072.017}]}],\\""AggregateType\\"":0,\\""AggregateSymbol\\"":\\""\\""}""\r\n"";\r\nvar input = JsonConvert.DeserializeObject<RootCauseLocalizationInput>(jsonString); // using Newtonsoft.Json\r\nvar prediction = this.mlContext.AnomalyDetection.LocalizeRootCause(input);\r\n```\r\nThe input is like:\r\n```\r\n{\r\n\t""AnomalyTimestamp"": ""1997-05-19T00:00:00"",\r\n\t""AnomalyDimension"": {\r\n\t\t""__Sandbox.Categories.CategoryName__"": """"\r\n\t},\r\n\t""Slices"": [\r\n\t\t{\r\n\t\t\t""TimeStamp"": ""1997-05-19T00:00:00"",\r\n\t\t\t""Points"": [\r\n\t\t\t\t{\r\n\t\t\t\t\t""Value"": 8995.35,\r\n\t\t\t\t\t""ExpectedValue"": -120.28187410606782,\r\n\t\t\t\t\t""IsAnomaly"": true,\r\n\t\t\t\t\t""Dimension"": {\r\n\t\t\t\t\t\t""__Sandbox.Categories.CategoryName__"": ""Beverages""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""Delta"": 9115.631874106068\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""Value"": 1282.02,\r\n\t\t\t\t\t""ExpectedValue"": 1374.808978001977,\r\n\t\t\t\t\t""IsAnomaly"": false,\r\n\t\t\t\t\t""Dimension"": {\r\n\t\t\t\t\t\t""__Sandbox.Categories.CategoryName__"": ""Condiments""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""Delta"": -92.78897800197706\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""Value"": 1686.7,\r\n\t\t\t\t\t""ExpectedValue"": 2014.8946291211199,\r\n\t\t\t\t\t""IsAnomaly"": false,\r\n\t\t\t\t\t""Dimension"": {\r\n\t\t\t\t\t\t""__Sandbox.Categories.CategoryName__"": ""Confections""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""Delta"": -328.19462912111978\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""Value"": 174.15,\r\n\t\t\t\t\t""ExpectedValue"": 215.02809847811904,\r\n\t\t\t\t\t""IsAnomaly"": false,\r\n\t\t\t\t\t""Dimension"": {\r\n\t\t\t\t\t\t""__Sandbox.Categories.CategoryName__"": ""Dairy Products""\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""Delta"": -40.87809847811903\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\t""Value"": 12138.22,\r\n\t\t\t\t\t""ExpectedValue"": 9066.203,\r\n\t\t\t\t\t""IsAnomaly"": true,\r\n\t\t\t\t\t""Dimension"": {\r\n\t\t\t\t\t\t""__Sandbox.Categories.CategoryName__"": """"\r\n\t\t\t\t\t},\r\n\t\t\t\t\t""Delta"": 3072.017\r\n\t\t\t\t}\r\n\t\t\t]\r\n\t\t}\r\n\t],\r\n\t""AggregateType"": 0,\r\n\t""AggregateSymbol"": """"\r\n}\r\n```\r\nAnd the output:\r\n\r\n```\r\n{\r\n\t""Items"": [\r\n\t\t{\r\n\t\t\t""Score"": ""NaN"",\r\n\t\t\t""Path"": [\r\n\t\t\t\t""__Sandbox.Categories.CategoryName__""\r\n\t\t\t],\r\n\t\t\t""Dimension"": {\r\n\t\t\t\t""__Sandbox.Categories.CategoryName__"": ""Beverages""\r\n\t\t\t},\r\n\t\t\t""Direction"": 0\r\n\t\t}\r\n\t]\r\n}\r\n```\r\n\r\n'"
648948335,5273,b'Error on prediction with LSTM Model in ONNX Format in ML.Net',"b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1, Microsoft.ML 1.5.0, Microsoft.ML.OnnxRuntime 1.3.0, Microsoft.ML.OnnxTransformer 1.5.0\r\n\r\n### Issue\r\nI would like to predict Values with my LSTM Model in ONNX Format. I am struggling on data input for my ONNX Model in my ML.NET project. When I run my code, I get an Exception: _System.NullReferenceException: \'Object reference not set to an instance of an object.\'_ on prediction. The input data is just dummy. I am trying to find out, how to input data in form (None,3,7) as expected from LSTM Model. LSTM Model ist attached. Can someone help me, what I am doing wrong?\r\nWhy I get exception or how to deliver data for my ONNX Model. \r\n\r\n```C#\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.Data.SqlClient;\r\n\r\nnamespace InQu.ML.Test.ONNX.FehlerAbsch\xc3\xa4tzungLSTM\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext();\r\n            \r\n            var x = new InputData[] { \r\n                        new InputData() { X = new float[,] { { 1, 2, 3, 4, 5, 6, 7 }, { 1, 2, 3, 4, 5, 6, 7 }, { 1, 2, 3, 4, 5, 6, 7 } } }                       \r\n                    };\r\n\r\n            IDataView dataView = mlContext.Data.LoadFromEnumerable<InputData>(x);\r\n\r\n            var pipeline = mlContext.Transforms.ApplyOnnxModel(modelFile: @"".\\scikit-learn\\AbschatzungFehlerLSTM.onnx"", \r\n                            inputColumnNames: new[] { ""input_layer"",  }, \r\n                            outputColumnNames: new[] { ""dense_3"" });\r\n\r\n            var model = pipeline.Fit(dataView);\r\n            \r\n            var predEngine = mlContext.Model.CreatePredictionEngine<InputData, OutputData>(model);\r\n\r\n            OutputData prediction = new OutputData() { y = new float[0] };\r\n            predEngine.Predict(x[0], ref prediction);\r\n        }\r\n    }\r\n\r\n    public class InputData\r\n    {\r\n        [ColumnName(""input_layer"")]\r\n        [VectorType(3,7)]\r\n        public float[,] X { get; set; }        \r\n    }\r\n\r\n    public class OutputData\r\n    {\r\n        [ColumnName(""dense_3"")]\r\n        [VectorType(1)]\r\n        public float[] y { get; set; }\r\n    }\r\n}\r\n\r\n```\r\n'"
648582534,5271,b'ConvertToOnnx options to exclude the data generation pipeline',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCalling `mlContext.Model.ConvertToOnnx(model, colSelTrainingData2, fs);`\r\n\r\nOf which `model ` involved data transformations pipeline like encoding, concatenating and column manipulation.\r\n\r\n- **What happened?**\r\n\r\nAll the data transformation pipeline is included in the final ONNX model, which I do not want. \r\n\r\n- **What did you expect?**\r\n\r\nI want the model to tramsformed into an ONNX model where the InputColumn is the InputColumn that is fit to the model, excluding all the data transformations pipeline like encoding, concatenating and column manipulation before fitted to the model.\r\n\r\n### Source code / logs\r\n'"
648578397,5270,b'CreateEnumerable from key column',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to create Enumerable from IDataView which contains Column with Type Key<UInt32, 0-1059>, into a uint type.\r\n- **What happened?**\r\nEncountered error:\r\n""Can\'t bind the IDataView column \'ImpressionIdKey\' of type \'Key<UInt32, 0-1059>\' to field or property \'ImpressionIdKey\' of type \'System.UInt32\'.""\r\n- **What did you expect?**\r\nI want to be able to export key value in its uint format as enumerable\r\n\r\n### Source code / logs\r\n\r\n```\r\n        var a = mlContext.Data.CreateEnumerable<ProcessedData>(\r\n            colSelTrainingData, reuseRowObject: false);\r\n\r\n...\r\n\r\n        private class ProcessedData\r\n        {\r\n            public float[] Feature { get; set; }\r\n\r\n            public float BackProClick { get; set; }\r\n\r\n            public uint ImpressionIdKey { get; set; }\r\n        }\r\n```\r\n'"
647696050,5267,"b""Property names generated in AutoML's GenerateSampleData() differ from those generated by GenerateClassLabels()""","b'As @LittleLittleCloud noted in [this comment](https://github.com/dotnet/machinelearning/pull/5177#discussion_r446314964) in PR #5177 for fixing Issue #3902, columns generated from inline data are currently named in the following way:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/33f5f32a71cbe6f7a8fb03d75fbdb091d15b8fe8/src/Microsoft.ML.CodeGenerator/Utils.cs#L49-L68\r\n\r\nThis method of directly using `Utils.Normalize` is different from using `GenerateClassLabels` instead to obtain normalized and sanitized column names. `GenerateClassLabels` can accommodate conflicting/duplicate column names, whereas in `GenerateSampleData()` this situation results in exceptions.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/33f5f32a71cbe6f7a8fb03d75fbdb091d15b8fe8/src/Microsoft.ML.CodeGenerator/Utils.cs#L246-L318\r\n\r\nTo-do:\r\n\r\n- Ensure `GenerateSampleData()` can accomodate conflicting/duplicate column names by using `Utils.GenerateClassLabels()`.'"
647594596,5266,b'recent CI failure',"b'we are start seeing some ci failure recently:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=709641&view=results\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706523&view=results\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706453&view=results\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=699015&view=results\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=689649&view=results\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=656357&view=results\r\n\r\nthere are several issues here:\r\n1. error CS7035: The specified version string does not conform to the recommended format - major.minor.build.revision\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=656357&view=results\r\n\r\nthis also happens on local randomly\r\n\r\n2. fatal: unable to access \'https://github.com/mongodb/homebrew-brew/\': Failed to connect to github.com port 443: Operation timed out\r\n\r\nError: Fetching /usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew failed!\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=709641&view=logs&j=4b233af4-7b14-5f68-27c6-9c4d7ac87519&t=6c4d0d4f-93f4-59fe-bb3a-eecc956920fe\r\n\r\nlooks like random failure related to github authentication\r\n\r\n3. SavePipePValue failure, new random failure\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706523&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=522d178a-829f-5bff-ccb9-04bea054b64d\r\n\r\n4. benchmark failure, new random failure\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706453&view=logs&j=4b233af4-7b14-5f68-27c6-9c4d7ac87519&t=c45ec5f3-1036-5f06-ba3b-dc6ad6175c22\r\n\r\n[xUnit.net 00:02:08.63]     Microsoft.ML.Benchmarks.Tests.BenchmarksTest.BenchmarksProjectIsNotBroken(type: typeof(Microsoft.ML.Benchmarks.StochasticDualCoordinateAscentClassifierBench)) [FAIL]\r\n// ***** BenchmarkRunner: Start   *****\r\n// ***** Found 2 benchmark(s) in total *****\r\n// ***** Building 1 exe(s) in Parallel: Start   *****\r\n  X Microsoft.ML.Benchmarks.Tests.BenchmarksTest.BenchmarksProjectIsNotBroken(type: typeof(Microsoft.ML.Benchmarks.StochasticDualCoordinateAscentClassifierBench)) [1m 8s]\r\n  Error Message:\r\n   All reports should have at least one ""ExecuteResult"" with ""FoundExecutable"" = true and at least one ""Data"" item\r\nExpected: True\r\nActual:   False\r\n  Stack Trace:\r\n     at Microsoft.ML.Benchmarks.Tests.BenchmarksTest.BenchmarksProjectIsNotBroken(Type type) in /Users/runner/runners/2.170.1/work/1/s/test/Microsoft.ML.Benchmarks.Tests/BenchmarksTest.cs:line 69\r\n\r\n5. some timeouts failure\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=689649&view=logs&j=dd8eddb6-ecc6-5f65-73e6-df90e5693b94\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=706453&view=logs&j=87172896-2df6-55a2-04c3-60b48f00f19f\r\n\r\n6. TestCancellation hanging again\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=699015&view=logs&j=9d6f93fc-7103-540d-abb9-b79bad552b0d&t=febb8f43-1f98-59b4-5544-6955325789bd\r\n\r\n7. Microsoft.Extensions.ML.FileLoaderTests.can_reload_model: FileLoader ChangeToken didn\'t fire before the allotted time.\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=716174&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=522d178a-829f-5bff-ccb9-04bea054b64d'"
647414442,5264,"b'Using ""nameof"" in ""outputColumnName"" of ""MapKeyToValue""'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n- **What did you do?**\r\nAdapted the Iris as a canary model for our company internal ML platform based on ML.Net.\r\n\r\n- **What happened?**\r\nUsing to `nameof(IrisModelOutput.Species)`  select the output column name doesn\'t work.\r\n\r\n```cs\r\npublic class IrisModelOutput\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public string Species { get; set; }\r\n\r\n        public float[] Score { get; set; }\r\n    }\r\n```\r\n\r\nIf the prediction result DTO `Species` is annotated with `[ColumnName(""PredictedLabel"")]` if gives an error; if it isn\'t annotated, it comes empty in the prediction.\r\n\r\n- **What did you expect?**\r\nThat the predicted species is mapped back to `Species`.\r\n\r\n### Source code / logs\r\nIn this pipeline\'s `MapKeyToValue` doesn\'t work as expected:\r\n```cs\r\nPipeline = MlContext.Transforms.Concatenate(outputColumnName: ""Features"", inputColumnNames: new[]\r\n                {\r\n                    nameof(IrisModelInput.SepalLength),\r\n                    nameof(IrisModelInput.SepalWidth),\r\n                    nameof(IrisModelInput.PetalLength),\r\n                    nameof(IrisModelInput.PetalWidth)\r\n                })\r\n                .Append(MlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""Label"", inputColumnName: nameof(IrisModelInput.Species)))\r\n                .Append(MlContext.MulticlassClassification.Trainers.SdcaNonCalibrated(labelColumnName: ""Label"", featureColumnName: ""Features""))\r\n                .Append(MlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: nameof(IrisModelOutput.Species), inputColumnName: ""Label""));\r\n```\r\nBut using the following alternative sintaxis for the last append works correctly:\r\n```csharp\r\n.Append(MlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n```'"
646240897,5262,b'Using OnnxTransformer throws TypeInitializationException',"b'### System information\r\n\r\n- **OS version/distro**: Windows 7\r\n- **.NET Version (eg., dotnet --info)**: core 3.1\r\n\r\n### Issue\r\nWhen trying to use OnnxTransformer, the native libraries aren\'t loaded properly. I can see them under bin\\Debug\\netcoreapp3.1\\runtimes\\(platform)\\native.\r\nIf I use package version 1.4.0 of OnnxTransformer, without installing the runtime myself, it works.\r\nI couldn\'t find any docs regarding the requirement to install the runtime manually (I figured it out by browsing all over the place, but not through docs really). I suppose this should be clear when you\'re not using the onnxruntime package explicitly, but rather the higher level API of OnnxTransformer?\r\n\r\nOn a separate note: Is it sufficient to install the GPU natives and use the `fallbackToCpu` flag of `ApplyOnnxModel` to be able to run inferencing on both CPU and GPU? I\'m having a hard time finding this documented.\r\n\r\n- **What did you do?**\r\nInstalled `Microsoft.ML.OnnxTransformer` 1.5.0 and `Microsoft.ML.OnnxRuntime` 1.3.0 and used `ApplyOnnxModel` in a pipeline.\r\n\r\n- **What happened?**\r\nCalling `ApplyOnnxModel` throws `System.TypeInitializationException`.\r\n\r\n- **What did you expect?**\r\nThat my ONNX model can be used.\r\n\r\n### Source code / logs\r\nInner exception message:\r\n\r\n""Unable to load DLL \'onnxruntime\' or one of its dependencies: The specified module could not be found. (0x8007007E)""\r\n'"
645470923,5256,"b""AutoML Exception: System.ArgumentOutOfRangeException: 'Could not find input column 'SamplingKeyColumn' (Parameter 'inputSchema')'""","b'Hi, I get an exception on prediction with AutoML. \r\nBefore you run the Problem you need to reference two NuGet Packages Microsoft.ML and Microsoft.ML.AutoML\r\nHere ist the complete code to reproduce the error. Run in VS2019:\r\n\r\n```C#\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.AutoML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers.FastTree;\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing static Microsoft.ML.DataOperationsCatalog;\r\n\r\nnamespace AutoML\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n\r\n            var examples = GenerateData(100);\r\n\r\n            var dataview = mlContext.Data.LoadFromEnumerable(examples);\r\n\r\n            TrainTestData trainTestSplit = mlContext.Data.TrainTestSplit(dataview, testFraction: 0.1, samplingKeyColumnName: null);\r\n            IDataView trainingData = trainTestSplit.TrainSet;\r\n            IDataView testData = trainTestSplit.TestSet;\r\n\r\n            ITransformer model = TrainRegresionAutoML(trainingData);\r\n            ReportOnFeatureImportance(mlContext, model, dataview);            \r\n\r\n            OutputData prediction = PredictRegresinAutoML<InputData,OutputData>(model, new InputData(){A = 6, B = 6});          \r\n        }\r\n\r\n        static ITransformer TrainRegresionAutoML(IDataView trainData)\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n\r\n            var settings = new RegressionExperimentSettings\r\n            {\r\n                MaxExperimentTimeInSeconds = 10, // In Second\r\n                OptimizingMetric = RegressionMetric.RSquared,\r\n                CacheDirectory = null\r\n            };\r\n\r\n            var experiment = mlContext.Auto().CreateRegressionExperiment(settings);\r\n            \r\n            var model = experiment.Execute(trainData);            \r\n\r\n\r\n            return model.BestRun.Model;\r\n        }\r\n\r\n        private static void ReportOnFeatureImportance(MLContext context, ITransformer model, IDataView data)\r\n        {            \r\n            // Need to cast from the ITransformer interface to gain access to the LastTransformer property.\r\n            var typedModel = (TransformerChain<IPredictionTransformer<object>>)model;\r\n            var modelParams = typedModel.LastTransformer.Model as FastTreeRegressionModelParameters;\r\n            var weights = new VBuffer<float>();\r\n            modelParams.GetFeatureWeights(ref weights);            \r\n        }\r\n\r\n        static TDst PredictRegresinAutoML<TSrc, TDst>(ITransformer model, TSrc inputData) \r\n            where TSrc : class\r\n            where TDst : class, new()\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n\r\n            var predictor = mlContext.Model.CreatePredictionEngine<TSrc, TDst>(model);\r\n            return predictor.Predict(inputData);\r\n        }      \r\n\r\n        private static IEnumerable<InputData> GenerateData(int count,\r\n            int seed = 0)\r\n\r\n        {\r\n            for (int i = 0; i < count; i++)\r\n            {\r\n                for (int ii = 0; ii < count; ii++)\r\n                {\r\n                    yield return new InputData\r\n                    {\r\n                        A = i,\r\n                        B = ii,\r\n                        Value = i * ii\r\n                    };\r\n                }\r\n            }\r\n        }       \r\n    }\r\n\r\n    public class InputData\r\n    {     \r\n        public float A { get; set; }\r\n        \r\n        public float B { get; set; }\r\n\r\n        [ColumnName(""Label"")]\r\n        public float Value { get; set; }\r\n    }\r\n\r\n    public class OutputData\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public float Result;\r\n    }\r\n\r\n    public class FeatureImportance\r\n    {\r\n        public string Name { get; set; }\r\n\r\n        public double RSquaredMean { get; set; }\r\n\r\n        public double CorrelationCoefficient { get; set; }\r\n    }\r\n}\r\n```'"
644194064,5254,"b'DnnFeaturizeImage for Resnet18 should return Vector<Single, 512> instead of Vector<Single, 1, 512, 1, 1>'",b'related to issue: https://github.com/dotnet/machinelearning/issues/4226\r\n'
643067639,5253,b'Exporting Custom Vision models no longer work',"b'### System information\r\n\r\n- **OS version/distro**:\r\n\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n.net framework 4.8\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDownloaded new exported model and replaced old one\r\n\r\n\r\n- **What happened?**\r\nGot exception """"Model variable data, expects Float[-1,3,416,416,], but binding was attempted with an incompatible type Image[544x480].\'""""\r\n\r\n""\'The binding is incomplete or does not match the input/output description.""\r\n\r\n- **What did you expect?**\r\n\r\nExpect: Model working\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nI would attach the models but cannot do so in this ticket \r\n\r\nStack overflow post (not from me) that has the same issue, so this is not only by me. \r\nhttps://stackoverflow.com/questions/62486386/custom-vision-onnx-models-stopped-working-with-windows-10-ml\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
640799263,5247,b'PermutationFeatureImportance not working with AutoML API',"b'### System information\r\n\r\n- Windows 10 Pro, build 18363\r\n- Visual Studio 2019 Professional\r\n- C# Console Application, in .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- Using the AutoML API to generate ML multiclassification model from large network datasets stored in CSV file. The model produced by the API provides accurate prediction, with reasonable results in the following metrics: MicroAccuracy, MacroAccuracy, LogLoss & LogLossReduction. Trying to get metrics on what feature selection was implemented by the API is proving impossible however. \r\n\r\n- Following all direction & [documentation ](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/explain-machine-learning-model-permutation-feature-importance-ml-net#explain-the-model-with-permutation-feature-importance-pfi) on implementing the PermutationFeatureImportance method has no success. It is possible to extract the pipeline from the AutoML BestRun model, and putting together the list of features in the custom class type it is using is not a problem either. However, there would appear to be no LastTransformer attribute for the BestRun model produced by the API. According to the official documentation on how to execute the PFI method on multiclass model, this is one of the main hurdles. \r\n\r\n- Attempting to follow the specific Multiclassification PFI [documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_MulticlassClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_) more exact, and defining a new pipeline with single multiclassification algorithm still throws an error. This is not ideal, as the new pipeline definition with single multiclassification algorithm does not necessarily match that used by the AutoML API\'s model, which is the model the PFI metrics are needed for.\r\n\r\n\r\n### Source code / logs\r\n\r\n**Example code following Multiclassification PFI Implementation from [ML.Net Documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_MulticlassClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_), using pipeline extracted from AutoML bestRun Model:** \r\n```\r\n//PFI code attempting to extract and use pipeline from AutoML bestRun model\r\n            var featureColumns =\r\n                new string[] { ""Unnamed0"",""FlowID"",""SourceIP"",""SourcePort"",""DestinationIP"",""DestinationPort"",""Protocol"",""Timestamp"",""FlowDuration"",""TotalFwdPackets"",""TotalBackwardPackets"",""TotalLengthofFwdPackets"",""TotalLengthofBwdPackets"",""FwdPacketLengthMax"",""FwdPacketLengthMin"",""FwdPacketLengthMean"",""FwdPacketLengthStd"",""BwdPacketLengthMax"",""BwdPacketLengthMin"",""BwdPacketLengthMean"",""BwdPacketLengthStd"",""FlowBytes"",""FlowPackets"",""FlowIATMean"",""FlowIATStd"",""FlowIATMax"",""FlowIATMin"",""FwdIATTotal"",""FwdIATMean"",""FwdIATStd"",""FwdIATMax"",""FwdIATMin"",""BwdIATTotal"",""BwdIATMean"",""BwdIATStd"",""BwdIATMax"",""BwdIATMin"",""FwdPSHFlags"",""BwdPSHFlags"",""FwdURGFlags"",""BwdURGFlags"",""FwdHeaderLength"",""BwdHeaderLength"",""FwdPackets"",""BwdPackets"",""MinPacketLength"",""MaxPacketLength"",""PacketLengthMean"",""PacketLengthStd"",""PacketLengthVariance"",""FINFlagCount"",""SYNFlagCount"",""RSTFlagCount"",""PSHFlagCount"",""ACKFlagCount"",""URGFlagCount"",""CWEFlagCount"",""ECEFlagCount"",""DownUpRatio"",""AveragePacketSize"",""AvgFwdSegmentSize"",""AvgBwdSegmentSize"",""FwdHeaderLength1"",""FwdAvgBytesBulk"",""FwdAvgPacketsBulk"",""FwdAvgBulkRate"",""BwdAvgBytesBulk"",""BwdAvgPacketsBulk"",""BwdAvgBulkRate"",""SubflowFwdPackets"",""SubflowFwdBytes"",""SubflowBwdPackets"",""SubflowBwdBytes"",""Init_Win_bytes_forward"",""Init_Win_bytes_backward"",""act_data_pkt_fwd"",""min_seg_size_forward"",""ActiveMean"",""ActiveStd"",""ActiveMax"",""ActiveMin"",""IdleMean"",""IdleStd"",""IdleMax"",""IdleMin"",""SimillarHTTP"",""Inbound"" };\r\n\r\n            // Fit the pipeline to the data.\r\n            var PFI_model = bestRun.Estimator.Fit(trainDataView);\r\n\r\n            // Transform the dataset.\r\n            var transformedData = PFI_model.Transform(trainDataView);\r\n\r\n            // Extract the predictor.\r\n            var linearPredictor = PFI_model.LastTransformer;\r\n\r\n            // Compute the permutation metrics for the linear model using the\r\n            // normalized data.\r\n            var permutationMetrics = mlContext.MulticlassClassification\r\n                .PermutationFeatureImportance(linearPredictor, transformedData,\r\n                permutationCount: 30);\r\n\r\n            // Now let\'s look at which features are most important to the model\r\n            // overall. Get the feature indices sorted by their impact on\r\n            // microaccuracy.\r\n            var sortedIndices = permutationMetrics\r\n                .Select((metrics, index) => new { index, metrics.MicroAccuracy })\r\n                .OrderByDescending(feature => Math.Abs(feature.MicroAccuracy.Mean))\r\n                .Select(feature => feature.index);\r\n\r\n            Console.WriteLine(""Feature\\tChange in MicroAccuracy\\t95% Confidence in ""\r\n                + ""the Mean Change in MicroAccuracy"");\r\n\r\n            var microAccuracy = permutationMetrics.Select(x => x.MicroAccuracy)\r\n                .ToArray();\r\n\r\n            foreach (int i in sortedIndices)\r\n            {\r\n                Console.WriteLine(""{0}\\t{1:G4}\\t{2:G4}"",\r\n                    featureColumns[i],\r\n                    microAccuracy[i].Mean,\r\n                    1.96 * microAccuracy[i].StandardError);\r\n            }\r\n```\r\nError Produced: _Severity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tCS1061\t\'ITransformer\' does not contain a definition for \'LastTransformer\' and no accessible extension method \'LastTransformer\' accepting a first argument of type \'ITransformer\' could be found (are you missing a using directive or an assembly reference?)_\r\n\r\n\r\n**Example code also following Multiclassification PFI Implementation from [ML.Net Documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_MulticlassClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_), using a newly created pipeline and single multiclassification algorithm:** \r\n```\r\n//PFI code with new pipeline using single multiclassification algorithm\r\n            var featureColumns =\r\n                new string[] { ""Unnamed0"",""FlowID"",""SourceIP"",""SourcePort"",""DestinationIP"",""DestinationPort"",""Protocol"",""Timestamp"",""FlowDuration"",""TotalFwdPackets"",""TotalBackwardPackets"",""TotalLengthofFwdPackets"",""TotalLengthofBwdPackets"",""FwdPacketLengthMax"",""FwdPacketLengthMin"",""FwdPacketLengthMean"",""FwdPacketLengthStd"",""BwdPacketLengthMax"",""BwdPacketLengthMin"",""BwdPacketLengthMean"",""BwdPacketLengthStd"",""FlowBytes"",""FlowPackets"",""FlowIATMean"",""FlowIATStd"",""FlowIATMax"",""FlowIATMin"",""FwdIATTotal"",""FwdIATMean"",""FwdIATStd"",""FwdIATMax"",""FwdIATMin"",""BwdIATTotal"",""BwdIATMean"",""BwdIATStd"",""BwdIATMax"",""BwdIATMin"",""FwdPSHFlags"",""BwdPSHFlags"",""FwdURGFlags"",""BwdURGFlags"",""FwdHeaderLength"",""BwdHeaderLength"",""FwdPackets"",""BwdPackets"",""MinPacketLength"",""MaxPacketLength"",""PacketLengthMean"",""PacketLengthStd"",""PacketLengthVariance"",""FINFlagCount"",""SYNFlagCount"",""RSTFlagCount"",""PSHFlagCount"",""ACKFlagCount"",""URGFlagCount"",""CWEFlagCount"",""ECEFlagCount"",""DownUpRatio"",""AveragePacketSize"",""AvgFwdSegmentSize"",""AvgBwdSegmentSize"",""FwdHeaderLength1"",""FwdAvgBytesBulk"",""FwdAvgPacketsBulk"",""FwdAvgBulkRate"",""BwdAvgBytesBulk"",""BwdAvgPacketsBulk"",""BwdAvgBulkRate"",""SubflowFwdPackets"",""SubflowFwdBytes"",""SubflowBwdPackets"",""SubflowBwdBytes"",""Init_Win_bytes_forward"",""Init_Win_bytes_backward"",""act_data_pkt_fwd"",""min_seg_size_forward"",""ActiveMean"",""ActiveStd"",""ActiveMax"",""ActiveMin"",""IdleMean"",""IdleStd"",""IdleMax"",""IdleMin"",""SimillarHTTP"",""Inbound"" };\r\n\r\n            var pipeline = mlContext.Transforms\r\n                .Concatenate(""Features"", featureColumns)\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(""Label""))\r\n                .Append(mlContext.Transforms.NormalizeMinMax(""Features""))\r\n                .Append(mlContext.MulticlassClassification.Trainers\r\n                .SdcaMaximumEntropy());\r\n\r\n            // Fit the pipeline to the data.\r\n            var PFI_model = pipeline.Fit(trainDataView);\r\n\r\n            // Transform the dataset.\r\n            var transformedData = PFI_model.Transform(trainDataView);\r\n\r\n            // Extract the predictor.\r\n            var linearPredictor = PFI_model.LastTransformer;\r\n\r\n            // Compute the permutation metrics for the linear model using the\r\n            // normalized data.\r\n            var permutationMetrics = mlContext.MulticlassClassification\r\n                .PermutationFeatureImportance(linearPredictor, transformedData,\r\n                permutationCount: 30);\r\n\r\n            // Now let\'s look at which features are most important to the model\r\n            // overall. Get the feature indices sorted by their impact on\r\n            // microaccuracy.\r\n            var sortedIndices = permutationMetrics\r\n                .Select((metrics, index) => new { index, metrics.MicroAccuracy })\r\n                .OrderByDescending(feature => Math.Abs(feature.MicroAccuracy.Mean))\r\n                .Select(feature => feature.index);\r\n\r\n            Console.WriteLine(""Feature\\tChange in MicroAccuracy\\t95% Confidence in ""\r\n                + ""the Mean Change in MicroAccuracy"");\r\n\r\n            var microAccuracy = permutationMetrics.Select(x => x.MicroAccuracy)\r\n                .ToArray();\r\n\r\n            foreach (int i in sortedIndices)\r\n            {\r\n                Console.WriteLine(""{0}\\t{1:G4}\\t{2:G4}"",\r\n                    featureColumns[i],\r\n                    microAccuracy[i].Mean,\r\n                    1.96 * microAccuracy[i].StandardError);\r\n            }\r\n```\r\nCode builds but also fails at PFI_model definition: _System.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  Message=Schema mismatch for input column \'Features\': expected vector or scalar of Single or Double, got Vector<String> \r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Transforms.NormalizingEstimator.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)_'"
639304492,5242,b'TensorFlowTransformCifar test crash',b'Test crash: https://dev.azure.com/dnceng/public/_build/results?buildId=684811&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=b03e2d69-ce1a-5899-6643-e9b6085777b9&s=d654deb9-056d-50a2-1717-90c08683d50a\r\n\r\nerror message: \r\nThe active Test Run was aborted because the host process exited unexpectedly while executing following test(s):\r\nMicrosoft.ML.Scenarios.TensorFlowScenariosTests.TensorFlowTransformCifar\r\n\r\n'
638338576,5241,b'Missing method exception NumSharp.Shape TensorFlow.TensorShape.op_implicit on fit',"b'System information\r\n\r\nWindows 10 pro/18362.836:\r\n.NET 4.7.2:\r\n\r\nIssue\r\n\r\nGot error \xe2\x80\x9cMissing method exception NumSharp.Shape TensorFlow.TensorShape.op_implicit\xe2\x80\x9d on fit, while trying to run Microsoft example for ML image classification.\r\n\r\nCode:\r\n\r\nIEstimator<ITransformer> pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""input"", imageFolder: _imagesFolder, inputColumnName: nameof(ImageData.ImagePath))\r\n                // The image transforms transform the images into the model\'s expected format.\r\n                .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""input"", imageWidth: InceptionSettings.ImageWidth, imageHeight: InceptionSettings.ImageHeight, inputColumnName: ""input""))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""input"", interleavePixelColors: InceptionSettings.ChannelsLast, offsetImage: InceptionSettings.Mean))\r\n\r\n.Append(mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel).\r\n    ScoreTensorFlowModel(outputColumnNames: new[] { ""softmax2_pre_activation"" }, inputColumnNames: new[] { ""input"" }, addBatchDimensionInput: true))\r\n\r\n.Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""LabelKey"", inputColumnName: ""Label""))\r\n\r\n\r\n.Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: ""LabelKey"", featureColumnName: ""softmax2_pre_activation""))\r\n\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabelValue"", ""PredictedLabel""))\r\n.AppendCacheCheckpoint(mlContext);\r\n\r\nIDataView trainingData = mlContext.Data.LoadFromTextFile<ImageData>(path:  _trainTagsTsv, hasHeader: false);\r\n\r\n//code above is working properly data preview shows proper data was loaded\r\n\r\nITransformer model = pipeline.Fit(trainingData);\r\n// fit ends with error \r\n\r\n Numsharp is v0. 20. 5\r\n'"
638238233,5240,b'DirectML support',b'Are there any plans to support DirectML as an alternative to TF?\r\nHave not seen this request in the Issues list.'
638097545,5238,b'Spell check in NormalizeRobustScaling',"b'These should say, ""Whether to center the data around 0 by removing the median. Defaults to true.""\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/207d466f94442ed58509e9f81dd6ec2a8ed193e7/src/Microsoft.ML.Transforms/NormalizerCatalog.cs#L366\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/207d466f94442ed58509e9f81dd6ec2a8ed193e7/src/Microsoft.ML.Transforms/NormalizerCatalog.cs#L366\r\n\r\nGood first PR for any community members; no need to ask first. In the PR description, add ""fixes #5238"", to auto-close this issue.'"
637972137,5237,b'Problem with ML.NET RobustScaler',"b'### System information\r\n\r\n- Windows 10 Enterprise 10.0 18363 Built 18363\r\n- Visual Studio 2019, build 16.6.2\r\n\r\n### Source code\r\n- I have put my reproduceable project on GitHUb at: https://github.com/CBrauer/Test_RobustScaler\r\n\r\n### Program output. Notice that RobustScaler produced an extra column for ""vwapGain""\r\n\r\n![image](https://user-images.githubusercontent.com/1317234/84540742-e4b97a80-acaa-11ea-9c8c-8f1504f7a2a6.png)\r\n\r\n### Source code\r\nMy test program looks like:\r\n```\r\nnamespace Test_RobustScaller {\r\n  internal class Program {\r\n    #region MyHead\r\n    public static void MyHead(IDataView train, int numRows) {\r\n      var trainPreview = train.Preview(maxRows: numRows);\r\n      var nColumns = trainPreview.ColumnView.Length;\r\n      var maxCharInHeaderName = 0;\r\n      for (var k = 0; k < nColumns; k++) {\r\n        var columnName = trainPreview.Schema[k].Name;\r\n        maxCharInHeaderName = Math.Max(maxCharInHeaderName, columnName.Length);\r\n      }\r\n      var nSpaces = new int[nColumns];\r\n      for (var k = 0; k < nColumns; k++) {\r\n        var columnName = trainPreview.Schema[k].Name;\r\n        for (var j = 0; j < maxCharInHeaderName - columnName.Length + 1; j++) {\r\n          Console.Write("" "");\r\n        }\r\n        Console.Write(""{0}"", columnName);\r\n        nSpaces[k] = maxCharInHeaderName - columnName.Length + 1;\r\n      }\r\n      Console.Write(""\\n"");\r\n\r\n      foreach (var row in trainPreview.RowView) {\r\n        for (var k = 0; k < row.Values.Length; k++) {\r\n          var field = string.Format(""{0}"", row.Values[k].Value);\r\n          var nSpace = maxCharInHeaderName - field.Length + 1;\r\n          for (var j = 0; j < nSpace; j++) {\r\n            Console.Write("" "");\r\n          }\r\n          Console.Write(row.Values[k].Value);\r\n        }\r\n        Console.Write(""\\n"");\r\n      }\r\n\r\n      Console.Write(""\\n"");\r\n    }\r\n    #endregion\r\n    public static void Run() {\r\n      var mlContext = new MLContext(seed: 1);\r\n\r\n      var df_full = DataFrame.LoadCsv(""../../../data/model.csv"");\r\n\r\n      var header_names = new List<string> {\r\n        ""BoxRatio"", ""Thrust"", ""Acceleration"", ""Velocity"",\r\n        ""OnBalRun"", ""vwapGain"", ""Altitude""\r\n      };\r\n      var nColumns = header_names.Count;\r\n      var df_columns = new DataFrameColumn[nColumns];\r\n      for (var k = 0; k < nColumns; k++) {\r\n        var name = header_names[k];\r\n        df_columns[k] = df_full.Columns[name];\r\n      }\r\n\r\n      var df = new DataFrame(df_columns);\r\n      Console.WriteLine(""Before transform:"");\r\n      Console.WriteLine(df.Head(5));\r\n\r\n      var pipeline = mlContext.Transforms.RobustScaler(""vwapGain"");\r\n      var model = pipeline.Fit(df);\r\n      var transformed = model.Transform(df);\r\n      Console.WriteLine(""After Transform:"");\r\n      MyHead(transformed, 5);\r\n    }\r\n\r\n    static void Main() {\r\n      Run();\r\n      Console.WriteLine(""Hit return to exit."");\r\n      Console.ReadKey();\r\n    }\r\n  }\r\n}\r\n```\r\nCharles'"
637880186,5235,b'AutoML - Better error message && stop inferring type for label column in regression && classification',"b""I have a dataset with sparse data and I can't perform value prediction. \r\n\r\nCan't upload dataset but I can share screen - Come Chat!"""
637171190,5230,b'[Feature Request] Add Seasonality Detection for Time-Series Data',"b'### Feature Description\r\n\r\nIn time series data, [seasonality](https://en.wikipedia.org/wiki/Seasonality) is the presence of variations that occur at specific regular intervals less than a year, such as weekly, monthly, or quarterly. With the support of seasonality and seasonality decomposition, we can improve a list of operations on time-series data:\r\n- Anomaly Detection\r\n- Forcasting\r\n- and more\r\n\r\nWe propose to provide\r\n1. [Seasonality Detection](http://alumni.cs.ucr.edu/~mvlachos/pubs/sdm05.pdf) Support for Time-Series Data based on [fourier analysis](https://en.wikipedia.org/wiki/Fourier_analysis). [PR 5231](https://github.com/dotnet/machinelearning/pull/5231)\r\n2. [Seasonality Decomposition](https://en.wikipedia.org/wiki/Decomposition_of_time_series) for Time-Series Data based on [STL](https://otexts.com/fpp2/stl.html). \r\n a. First, we support decomposition with Anomaly Detection [PR 5202](https://github.com/dotnet/machinelearning/pull/5202)\r\n b. Second, separate seasonality decomposition as a individual API as a Transformer \r\n\r\n### Detail API Proposal\r\n\r\n- DetectSeasonality\r\n\r\n```\r\n        /// <summary>\r\n        /// Obtain the period by adopting techniques of spectral analysis. which is founded by\r\n        /// the fourier analysis. returns -1 means there\'s no significant period. otherwise, a period\r\n        /// is returned.\r\n        /// </summary>\r\n        /// <param name=""catalog"">The detect seasonality catalog.</param>\r\n        /// <param name=""input"">Input DataView.The data is an instance of <see cref=""Microsoft.ML.IDataView""/>.</param>\r\n        /// <param name=""inputColumnName"">Name of column to process. The column data must be <see cref=""System.Double""/>.</param>\r\n        /// <param name=""seasonalityWindowSize"">An upper bound on the largest relevant seasonality in the input time-series.\r\n        /// When set to -1, use the whole input to fit model, when set to a positive integer, use this number as batch size.\r\n        /// Default value is -1.</param>\r\n        /// <returns>The detected period if seasonality period exists, otherwise return -1.</returns>\r\n        public static int DetectSeasonality(this AnomalyDetectionCatalog catalog, IDataView input, string inputColumnName, int seasonalityWindowSize = -1)\r\n```\r\n\r\n- Seasonality Decompose\r\nAdd two optional parameters to existing [DetectEntireAnomalyBySrCnn](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseriescatalog.detectentireanomalybysrcnn?view=ml-dotnet) API: \r\n-- period: Seasonality Period (either from user or auto-detected by the DetectSeasonality API.\r\n-- deseasonalityMode: Median, Average, STL.\r\n\r\n```\r\npublic static IDataView DetectEntireAnomalyBySrCnn(\r\n  this AnomalyDetectionCatalog catalog,\r\n  IDataView input, string outputColumnName, \r\n  string inputColumnName,\r\n  double threshold = 0.3, \r\n   int batchSize = 1024, \r\n   double sensitivity = 99, \r\n   SrCnnDetectMode detectMode = SrCnnDetectMode.AnomalyOnly, \r\n   int period = 0, \r\n   SrCnnDeseasonalityMode deseasonalityMode = SrCnnDeseasonalityMode.Stl)\r\n```\r\n'"
636319506,5225,"b'Find Regression Trainer that support Vector<> type of column ""Score""'","b'### System information\r\n\r\n- **OS Windows 7**:\r\n- **.NET 3.1.300**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** - I\'m trying to get prediction with Array type.\r\n- **What happened?** - column ""Label"" must be Single, and got Vector<Single>\r\nAre there RegressionTrainers that support Vector<> output?\r\n\r\n'"
636089763,5224,b'Filter anomalies according to boundaries under AnomalyAndMargin mode in SrCnnEntireAnomalyDetector',"b'In previous code of SrCnnEntireAnomalyDetector, under AnomalyAndMargin mode, we calculated UpperBoundary and LowerBoundary according to user\xe2\x80\x99s sensitivity setting, but didn\xe2\x80\x99t update the IsAnomaly field according to the boundaries since we want to allow this flexibility to user.\r\n\r\nBut considering the completeness of SrCnnEntireAnomalyDetector as a feature, the most important output should be the judgement whether a point is anomaly or not, namely IsAnomaly. It will be confused if user set different sensitivities but get the same IsAnomaly results. So we need to add anomalies filtering by boundries to the SrCnnEntireAnomalyDetector.'"
635783219,5222,b'Trouble using RobustScaler',"b'### System information\r\n\r\n- Microsoft Windows 10 Enterprise, Version\t10.0.18363 Build 18363\r\n\r\n- ML.NET v1.5\r\n\r\n### Issue\r\n\r\nI\'m trying to transform my dataset with the RobustScaler.  The program compiles and runs, but I get the exception:  \r\n\r\n`Unable to find an entry point named \'RobustScalerFeaturizer_float_CreateEstimator\' in DLL \'Featurizers\'.`\r\n\r\nHere is a segment of my code where the exception is thrown:\r\n\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Diagnostics;\r\nusing System.IO;\r\nusing System.Linq;\r\n\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.AutoML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Featurizers;\r\n.\r\n.\r\n.\r\n    var trainDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n        path: @""../../../data/train.csv"",\r\n        hasHeader: true,\r\n        separatorChar: \',\');\r\n\r\n    RobustScalerTransformer model = null;\r\n    var pipeline = mlContext.Transforms.RobustScaler(""vwapGain"");\r\n    try {\r\n      model = pipeline.Fit(trainDataView);\r\n    } catch (EntryPointNotFoundException ex) {\r\n      Console.WriteLine(""{0}:\\n   {1}"", ex.GetType().Name, ex.Message);\r\n    }\r\n```\r\nHere is a list of the packages in my program:\r\n\r\n![image](https://user-images.githubusercontent.com/1317234/84204754-a16bcb80-aa60-11ea-85ae-c7776b5fdccd.png)\r\n\r\nAny suggestions will be greatly appreciated.\r\n\r\nCharles\r\n'"
635599857,5221,b'CrossValidation Macros stops working in 1.5.0',"b""ML.NET 1.5.0\r\n\r\nHave NimbusML (built with ML.NET 1.5.0, here is [PR](https://dev.azure.com/aifx/public/_build/results?buildId=2988&view=results) that does this )\r\nRun the tests in [test.cv](https://github.com/microsoft/NimbusML/blob/master/src/python/nimbusml/tests/model_selection/test_cv.py) \r\ntest_default_label2  fails with error:\r\nError: *** System.InvalidOperationException: 'Column 'GroupId' not found' StackTrace:    at Microsoft.ML.EntryPoints.TrainerEntryPointsUtils.FindColumn(IExceptionContext ectx, DataViewSchema schema, Optional`1 value)\r\nat Microsoft.ML.EntryPoints.TrainerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\nat Microsoft.ML.Trainers.LightGbm.LightGbm.TrainRanking(IHostEnvironment env, Options input)\r\n\r\nThis is a regression from ML.NET 1.5.0.preview2\r\n\r\nI did some debugging, it appears that once macros is expanded ColumnSelector Transform drops GroupId. ColumnSelector appears to be added by Macros expansion.\r\n\r\n"""
635591558,5220,b'DateTimeTransformer cant find its own json data ',"b""ML.NET 1.5.0\r\nML.Featurizers 0.17.0\r\nFeaturizers 0.4.1\r\n\r\nRun NimbusML test_datetimesplitter.py method test_holidays. You get Exception:\r\n\r\nRuntimeError: Error: *** System.Exception: ''Canada' is not a supported country name'\r\nStackTrace:    at Microsoft.ML.Featurizers.DateTimeTransformer.TypedColumn.CreateTransformerFromEstimatorBase(HolidayList country)\r\nat Microsoft.ML.Featurizers.DateTimeTransformer..ctor(IHostEnvironment host, String inputColumnName, String columnPrefix, HolidayList country, DataViewSchema schema)\r\nat Microsoft.ML.Featurizers.DateTimeEstimator.Fit(IDataView input)\r\nat Microsoft.ML.Featurizers.DateTimeTransformerEntrypoint.DateTimeSplit(IHostEnvironment env, Options input)\r\n\r\nThis is regression from ML.NET 1.5.0.preview2. \r\n\r\n"""
635311962,5219,b'Train a simple neural network',"b'### System information\r\n\r\n- **OS Windows 7**:\r\n- **.NET 3.1.300**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** - I\'m trying to create a simple neural network that returns a given number\r\n- **What happened?** - I give bad prediction\r\n- **What did you expect?** - I expect to get number, which I give to model\r\n\r\n### Source code / logs\r\n\r\n```\r\n    class Program\r\n    {\r\n        static Input[] trainData;\r\n\r\n        static void CreateData(int count = 100)\r\n        {\r\n            trainData = new Input[count];\r\n\r\n            for (int i = 0; i < count; i++)\r\n            {\r\n                trainData[i] = new Input { Column1 = i, Result = i };\r\n            }\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            CreateData();\r\n            var mlContext = new MLContext();\r\n\r\n            var dataView = mlContext.Data.LoadFromEnumerable(trainData);\r\n            var pipeline = mlContext.Transforms.CopyColumns(""Label"", ""Result"")\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""Column1""))\r\n                .Append(mlContext.Regression.Trainers.Sdca()); \r\n\r\n            var model = pipeline.Fit(dataView);\r\n\r\n            var predictor = mlContext.Model.CreatePredictionEngine<Input, Output>(model);\r\n            var prediction = predictor.Predict(new Input { Column1 = 178, Result = 0});\r\n\r\n            Console.WriteLine(prediction.Result); //get 173\r\n            //with FastTree() train Method I get 94\r\n            Console.Beep(500, 100);\r\n            Console.Read();\r\n        }\r\n    }\r\n\r\n    class Input\r\n    {\r\n        public float Column1;\r\n\r\n        public float Result;\r\n    }\r\n    class Output\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public float Result;\r\n    }\r\n```\r\n'"
635209687,5217,b'Output vector size of FeaturizeText does not respect MaximumNgramsCount ',"b'### System information\r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.201\r\n Commit:    b1768b4ae7\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18362\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.201\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.3\r\n  Commit:  4a9f85e9f8\r\n\r\n.NET Core SDKs installed:\r\n  3.0.100 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.201 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.17 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.17 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.17 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n```\r\n\r\n### Issue\r\n\r\n- I build a pipline with ```FeaturizeText``` with MaximumNgramsCount = 50\r\n```\r\n\r\nlet featureEstimator = \r\n    let wordBagOptions = WordBagEstimator.Options(MaximumNgramsCount = [|50|]) \r\n    let textFeaturizeOptions =  \r\n        TextFeaturizingEstimator.Options(\r\n            OutputTokensColumnName = ""OutputTokens"",\r\n            CaseMode = Microsoft.ML.Transforms.Text.TextNormalizingEstimator.CaseMode.Lower,\r\n            KeepNumbers = true,\r\n            KeepPunctuations = false,\r\n            WordFeatureExtractor = wordBagOptions)\r\n    EstimatorChain()\r\n        .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName = ""Features"", options = textFeaturizeOptions, inputColumnNames =  [|""Text""|]))\r\n```\r\n\r\n- Features vector has a size of 1266 ``` Features: Vector<Single, 1266> ```\r\n- I expect features vector to be of size 50 (MaximumNgramsCount)\r\n[BowVectorSizeRepro.zip](https://github.com/dotnet/machinelearning/files/4750750/BowVectorSizeRepro.zip)\r\n\r\n\r\n'"
634796243,5215,b'Retrain Custom TensorFlow Model Feature Request',"b'I designed (not trained) a siamese CNN network in Keras (python) and exported it as a SavedModel with the random weights.\r\n_Input = 4 dimensions (left/right image, height, width, RGB).\r\nOutput = change of images being equal (sigmoid)\r\n\r\nBut I don\'t understand how I can train this model from .NET Core?\r\n\r\nWhen I use:\r\n```csharp\r\nusing var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(""./model"");\r\nvar pipeline = tensorFlowModel.ScoreTensorFlowModel(\r\n new[] { inputComparer.Name },\r\n new[] { outputComparer.Name }, addBatchDimensionInput: true);\r\n```\r\n\r\nThen I potentially can get the output from the model, but it\'s untrained, so this makes no sense.\r\nSo I need a trainer. I tried with LbfgsLogisticRegression but then I get ""Schema mismatch for label column \'StatefulPartitionedCall\': expected Boolean, got Vector<Single>"" which makes sense as the Tensorflow model don\'t output Booleans, but a Vector<Single>. Do I need another trainer?\r\n\r\nWhen I use the [ImageClassification](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification-api-transfer-learning) from this tutorial, I can only train one of the embedded networks from ImageClassificationTrainer.Architecture. It\'s a class output instead of binary, but that\'s OK. One class is also binary. But I want to train my own network.\r\n\r\n[This example](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/TensorflowTests.cs) was the closest I could find.\r\n\r\nHow do I train my binary output Tensorflow siamese network?\r\n\r\nThe reason I want to train this network from .NET Core instead of Python is to test the speed improvements and rollout something independently of Python.'"
634326757,5214,"b'Unseen labels during retraining map to value ""0"", results in System.InvalidOperationException: \'No valid training instances found, all instances have missing features.\' '","b'### System information\r\n\r\n- Windows Server 2016\r\n- .NET Version 3.1.300\r\n\r\n### Issue\r\nI\'m trying to do MultiClass LbfgsMaximumEntropy Re-training\r\nWhen trying to Fit new data, I get System.InvalidOperationException: \'No valid training instances found, all instances have missing features.\' on row\r\nITransformer _keyToValueModel1 = _mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(""Label"", ""Features"")\r\n        .Fit(transformedData, originalModelParameters.Model);\r\n[data1.zip](https://github.com/dotnet/machinelearning/files/4744624/data1.zip)\r\n\r\n\r\nI would appreciate either help or MultiClass LbfgsMaximumEntropy Re-training code sample.\r\n\r\n### Source code / logs\r\n\r\n```c#\r\n[data1.zip](https://github.com/dotnet/machinelearning/files/4744619/data1.zip)\r\n[data2.zip](https://github.com/dotnet/machinelearning/files/4744620/data2.zip)\r\n\r\n\r\npublic class GitHubIssueClassification\r\n  {\r\n    static List<GitHubIssueTransformed> testDatas = new List<GitHubIssueTransformed>()\r\n    {\r\n      new GitHubIssueTransformed() {Area=""11"", Title=""WHIRLPOOL AWE 50610"", Description="""" },\r\n      new GitHubIssueTransformed() {Area=""14"", Title=""FAGOR 4CC-130 E X"", Description="""" },\r\n      new GitHubIssueTransformed() {Area=""19"", Title=""AEG T8DFE68SC"", Description="""" },\r\n      new GitHubIssueTransformed() {Area=""999"", Title=""TEST 999"", Description="""" }\r\n    };\r\n\r\n    private static string _appPath => Path.GetDirectoryName(Environment.GetCommandLineArgs()[0]);\r\n    private static string _mainDataPath1 => Path.Combine(_appPath, "".."", "".."", "".."", ""Data"", ""data1.csv"");\r\n    private static string _mainDataPath2 => Path.Combine(_appPath, "".."", "".."", "".."", ""Data"", ""data2.csv"");\r\n    private static string _mainDataPath3 => Path.Combine(_appPath, "".."", "".."", "".."", ""Data"", ""data3.csv"");\r\n    private static string _modelPath => Path.Combine(_appPath, "".."", "".."", "".."", ""Models"", ""trainedModel.zip"");\r\n    private static string _keyToValueModelPath => Path.Combine(_appPath, "".."", "".."", "".."", ""Models"", ""keyToValueModel.zip"");\r\n\r\n    static DataOperationsCatalog.TrainTestData splittedData;\r\n\r\n    private static MLContext _mlContext;\r\n    private static PredictionEngine<GitHubIssueTransformed, IssuePrediction> _predEngine;\r\n    private static ITransformer _trainedModel { get; set; }\r\n    private static ITransformer _keyToValueModel { get; set; }\r\n    static IDataView _trainingDataView;\r\n    public static void Run()\r\n    {\r\n      _mlContext = new MLContext(seed: 0);\r\n\r\n      var allData = _mlContext.Data.LoadFromTextFile<GitHubIssue>(_mainDataPath1, hasHeader: true);\r\n      splittedData = _mlContext.Data.TrainTestSplit(allData, testFraction: 0.09);\r\n      _trainingDataView = splittedData.TrainSet;\r\n      Console.WriteLine($""=============== Finished Loading Dataset  ==============="");\r\n\r\n      var pipeline = ProcessData();\r\n      var transformedData = BuildAndTrainModel(_trainingDataView, pipeline);\r\n      Evaluate(_trainingDataView.Schema, transformedData, splittedData.TestSet);\r\n      PredictIssue_FirstLoadModelFromDisk();\r\n\r\n      SecondLap(_mlContext);\r\n    }\r\n\r\n    public static IEstimator<ITransformer> ProcessData()\r\n    {\r\n      Console.WriteLine($""=============== Processing Data ==============="");\r\n      var pipeline = _mlContext.Transforms.Conversion.MapValueToKey(inputColumnName: ""Area"", outputColumnName: ""Label"")\r\n                      .Append(_mlContext.Transforms.Text.FeaturizeText(inputColumnName: ""Title"", outputColumnName: ""TitleFeaturized""))\r\n                      .Append(_mlContext.Transforms.Text.FeaturizeText(inputColumnName: ""Description"", outputColumnName: ""DescriptionFeaturized""))\r\n                      .Append(_mlContext.Transforms.Concatenate(""Features"", ""TitleFeaturized"", ""DescriptionFeaturized""))\r\n                      .AppendCacheCheckpoint(_mlContext);\r\n\r\n      Console.WriteLine($""=============== Finished Processing Data ==============="");\r\n\r\n      return pipeline;\r\n    }\r\n\r\n    public static IDataView BuildAndTrainModel(IDataView trainingDataView, IEstimator<ITransformer> pipeline)\r\n    {\r\n      //var trainingPipeline = pipeline.Append(_mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy/*.SdcaMaximumEntropy*/(""Label"", ""Features""))\r\n      //    .Append(_mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n      var trainingPipeline = pipeline.Append(_mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy/*.SdcaMaximumEntropy*/(""Label"", ""Features""));\r\n      //var keyToValuePipeline = _mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"");\r\n      var keyToValuePipeline = trainingPipeline.Append(_mlContext.Transforms.Conversion.MapKeyToValue(""Area"", ""PredictedLabel""));\r\n\r\n      Console.WriteLine($""=============== Training the model  ==============="");\r\n\r\n      _trainedModel = trainingPipeline.Fit(trainingDataView);\r\n      var transformedData = _trainedModel.Transform(trainingDataView);\r\n      _keyToValueModel = keyToValuePipeline.Fit(transformedData);\r\n\r\n      _mlContext.Model.Save(_trainedModel, trainingDataView.Schema, _modelPath);\r\n      _mlContext.Model.Save(_keyToValueModel, transformedData.Schema, _keyToValueModelPath);\r\n\r\n      Console.WriteLine($""=============== Finished Training the model Ending time: {DateTime.Now.ToString()} ==============="");\r\n\r\n      // (OPTIONAL) Try/test a single prediction with the ""just-trained model"" (Before saving the model)\r\n      Console.WriteLine($""=============== Single Prediction just-trained-model ==============="");\r\n\r\n      _predEngine = _mlContext.Model.CreatePredictionEngine<GitHubIssueTransformed, IssuePrediction>(_keyToValueModel);\r\n      foreach (var testIssue in testDatas)\r\n      {\r\n        var prediction = _predEngine.Predict(testIssue);\r\n        if (prediction.Area.ToString() != testIssue.Area.ToString())\r\n          Console.ForegroundColor = ConsoleColor.Red;\r\n        else\r\n          Console.ForegroundColor = ConsoleColor.Blue;\r\n        Console.WriteLine($""=============== Single Prediction just-trained-model - Result: {prediction.Area}/{testIssue.Area} {testIssue.Title} ==============="");\r\n      }\r\n      Console.ResetColor();      \r\n\r\n      return transformedData;\r\n    }\r\n\r\n    public static void Evaluate(DataViewSchema trainingDataViewSchema, IDataView transformedData, IDataView testDataView2 = null)\r\n    {\r\n      // STEP 5:  Evaluate the model in order to get the model\'s accuracy metrics\r\n      Console.WriteLine($""=============== Evaluating to get model\'s accuracy metrics - Starting time: {DateTime.Now.ToString()} ==============="");\r\n\r\n      IDataView testDataView = testDataView2;\r\n\r\n      var testMetrics = _mlContext.MulticlassClassification.Evaluate(_trainedModel.Transform(testDataView));\r\n\r\n      Console.WriteLine($""=============== Evaluating to get model\'s accuracy metrics - Ending time: {DateTime.Now.ToString()} ==============="");\r\n      Console.WriteLine($""*************************************************************************************************************"");\r\n      Console.WriteLine($""*       Metrics for Multi-class Classification model - Test Data     "");\r\n      Console.WriteLine($""*------------------------------------------------------------------------------------------------------------"");\r\n      Console.WriteLine($""*       MicroAccuracy:    {testMetrics.MicroAccuracy:0.###}"");\r\n      Console.WriteLine($""*       MacroAccuracy:    {testMetrics.MacroAccuracy:0.###}"");\r\n      Console.WriteLine($""*       LogLoss:          {testMetrics.LogLoss:#.###}"");\r\n      Console.WriteLine($""*       LogLossReduction: {testMetrics.LogLossReduction:#.###}"");\r\n      Console.WriteLine($""*************************************************************************************************************"");\r\n\r\n      SaveModelAsFile(_mlContext, trainingDataViewSchema, transformedData, _trainedModel, _keyToValueModel);\r\n    }\r\n\r\n    public static void PredictIssue_FirstLoadModelFromDisk()\r\n    {\r\n      //ITransformer loadedModel = _mlContext.Model.Load(_modelPath, out var modelInputSchema);\r\n      ITransformer loadedModel = _mlContext.Model.Load(_keyToValueModelPath, out var modelInputSchema);\r\n\r\n      foreach (var testIssue in testDatas)\r\n      {\r\n        _predEngine = _mlContext.Model.CreatePredictionEngine<GitHubIssueTransformed, IssuePrediction>(loadedModel);\r\n        var prediction = _predEngine.Predict(testIssue);\r\n        if (prediction.Area.ToString() != testIssue.Area.ToString())\r\n          Console.ForegroundColor = ConsoleColor.Red;\r\n        else\r\n          Console.ForegroundColor = ConsoleColor.Blue;\r\n        Console.WriteLine($""=============== Single Prediction - Result: {prediction.Area}/{testIssue.Area} {testIssue.Title} ==============="");\r\n        Console.ResetColor();\r\n      }\r\n    }\r\n\r\n    private static void SaveModelAsFile(MLContext mlContext, DataViewSchema trainingDataViewSchema,\r\n      IDataView transformedData, ITransformer _trainedModel, ITransformer _keyToValueModel)\r\n    {\r\n      //mlContext.Model.Save(_trainedModel, trainingDataViewSchema, _modelPath);\r\n      //mlContext.Model.Save(_keyToValueModel, transformedData.Schema, _keyToValueModelPath);\r\n      Console.WriteLine(""The model is saved to {0}"", _modelPath);\r\n    }\r\n\r\n    static void SecondLap(MLContext _mlContext)\r\n    {\r\n      var allData = _mlContext.Data.LoadFromTextFile<GitHubIssue>(_mainDataPath2, hasHeader: true);\r\n      splittedData = _mlContext.Data.TrainTestSplit(allData, testFraction: 0.09);\r\n      _trainingDataView = splittedData.TrainSet;\r\n\r\n      ITransformer dataPrepPipeline = _mlContext.Model.Load(_modelPath, out var dataPrepPipelineSchema);\r\n      var originalModelParameters = (dataPrepPipeline as TransformerChain<ITransformer>).LastTransformer as MulticlassPredictionTransformer<MaximumEntropyModelParameters>;      \r\n\r\n      int rowsCount = splittedData.TrainSet.Preview().RowView.Count();\r\n      //var transformedData = dataPrepPipeline.Transform(splittedData.TrainSet);\r\n      //var transformedData = _keyToValueModel.Transform(splittedData.TrainSet);\r\n      var transformedData = _trainedModel.Transform(splittedData.TrainSet);\r\n\r\n      ITransformer _keyToValueModel1 = _mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(""Label"", ""Features"")\r\n        .Fit(transformedData, originalModelParameters.Model);\r\n    }\r\n  }\r\npublic class GitHubIssue\r\n  {\r\n    [LoadColumn(0)]\r\n    public string ID { get; set; }\r\n    [LoadColumn(1)]\r\n    public string Area { get; set; }\r\n    [LoadColumn(2)]\r\n    public string Title { get; set; }\r\n    [LoadColumn(3)]\r\n    public string Description { get; set; }\r\n  }\r\n\r\n  public class GitHubIssueTransformed: GitHubIssue\r\n  {\r\n    //[ColumnName(""PredictedLabel"")]\r\n    //public string XX;\r\n  }\r\n\r\n  public class IssuePrediction\r\n  {\r\n    //[ColumnName(""PredictedLabel"")]\r\n    public string Area;\r\n  }\r\n```\r\n'"
633229182,5213,b'CoreDump on LoadTensorFlowModel ',"b'### System information\r\n\r\n- **Windows 10 pro/18362.836**:\r\n- **.NET 4.7.2**: \r\n\r\n### Issue\r\n\r\n- **Trying to load TensorFlow model tensorflow_inception_graph **\r\n- **Illegal error**\r\n- **model loading**\r\n\r\n### Source code / logs\r\n Microsoft.ML.Transforms.TensorFlowModel tensorFlowModel = mlContext.Model.LoadTensorFlowModel(_inceptionTensorFlowModel);\r\nError occures on this line from microsoft manual. I have managed to load the model on my laptop and it works properly. When I have tried to run the same progect on my PC I had this error. Please help me to figure out wat is wrong. The problem is not in the code, becouse the same code works fine on the other machine. I have tried different versions of all libreries, but nothing helped.\r\n\r\nPC Information:\r\n\r\nProcessor: Intel(R) Core i7 CPU Q740 1.73GHz 1.73GHz \r\nRAM: 6.00 Gb\r\nx64\r\n\r\n""WpfApplication2.exe"" (CLR v4.0.30319: DefaultDomain). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_64\\mscorlib\\v4.0_4.0.0.0__b77a5c561934e089\\mscorlib.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: DefaultDomain). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\WpfApplication2.exe"". Symbols loaded.\r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\PresentationFramework\\v4.0_4.0.0.0__31bf3856ad364e35\\PresentationFramework.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\WindowsBase\\v4.0_4.0.0.0__31bf3856ad364e35\\WindowsBase.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Core\\v4.0_4.0.0.0__b77a5c561934e089\\System.Core.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System\\v4.0_4.0.0.0__b77a5c561934e089\\System.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_64\\PresentationCore\\v4.0_4.0.0.0__31bf3856ad364e35\\PresentationCore.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Xaml\\v4.0_4.0.0.0__b77a5c561934e089\\System.Xaml.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\Remote Debugger\\x64\\Runtime\\Microsoft.VisualStudio.Debugger.Runtime.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Configuration\\v4.0_4.0.0.0__b03f5f7f11d50a3a\\System.Configuration.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Xml\\v4.0_4.0.0.0__b77a5c561934e089\\System.Xml.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Drawing\\v4.0_4.0.0.0__b03f5f7f11d50a3a\\System.Drawing.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Windows.Forms\\v4.0_4.0.0.0__b77a5c561934e089\\System.Windows.Forms.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\WindowsFormsIntegration\\v4.0_4.0.0.0__31bf3856ad364e35\\WindowsFormsIntegration.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""c:\\program files (x86)\\microsoft visual studio\\2019\\community\\common7\\ide\\commonextensions\\microsoft\\xamldiagnostics\\Framework\\x64\\Microsoft.VisualStudio.DesignTools.WpfTap.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Xceed.Wpf.Toolkit.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Xceed.Wpf.AvalonDock.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Runtime.Serialization\\v4.0_4.0.0.0__b77a5c561934e089\\System.Runtime.Serialization.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\SMDiagnostics\\v4.0_4.0.0.0__b77a5c561934e089\\SMDiagnostics.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.ServiceModel.Internals\\v4.0_4.0.0.0__31bf3856ad364e35\\System.ServiceModel.Internals.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\PresentationFramework.Aero2\\v4.0_4.0.0.0__31bf3856ad364e35\\PresentationFramework.Aero2.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.Data.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\netstandard\\v4.0_2.0.0.0__cc7b13ffcd2ddd51\\netstandard.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.Core.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.ValueTuple\\v4.0_4.0.0.0__cc7b13ffcd2ddd51\\System.ValueTuple.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_64\\System.Data\\v4.0_4.0.0.0__b77a5c561934e089\\System.Data.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.ServiceModel\\v4.0_4.0.0.0__b77a5c561934e089\\System.ServiceModel.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\PresentationFramework-SystemXml\\v4.0_4.0.0.0__b77a5c561934e089\\PresentationFramework-SystemXml.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\PresentationFramework-SystemData\\v4.0_4.0.0.0__b77a5c561934e089\\PresentationFramework-SystemData.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\UIAutomationTypes\\v4.0_4.0.0.0__31bf3856ad364e35\\UIAutomationTypes.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\UIAutomationProvider\\v4.0_4.0.0.0__31bf3856ad364e35\\UIAutomationProvider.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\Accessibility\\v4.0_4.0.0.0__b03f5f7f11d50a3a\\Accessibility.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Numerics\\v4.0_4.0.0.0__b77a5c561934e089\\System.Numerics.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\PresentationFramework-SystemCore\\v4.0_4.0.0.0__b77a5c561934e089\\PresentationFramework-SystemCore.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.TensorFlow.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\v\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.DataView.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\System.Collections.Immutable.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.ImageAnalytics.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Microsoft.ML.StandardTrainers.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Newtonsoft.Json.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\System.Memory.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\TensorFlow.NET.dll"". \r\n""WpfApplication2.exe"" (CLR v4.0.30319: WpfApplication2.exe). Loaded ""C:\\Users\\MyPC\\Desktop\\test\\WpfApplication2\\bin\\Debug\\Google.Protobuf.dll"". Symbols loaded.\r\nProgram ""[6780] WpfApplication2.exe"" exited with code -1073741795 (0xc000001d) \'Illegal Instruction\'.\r\n'"
631325524,5211,b'MulticlassClassification.CrossValidate Arithmetic operation resulted in an overflow',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10 pro\r\n- **.NET Version (eg., dotnet --info)**: \r\n.Net Core 2.1.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am creating a multiclass classification experiment and after de best model is selected and I try to evaluate de model but this method throws an exception\r\nvar testMetrics = mlContext.MulticlassClassification.CrossValidate(testDataViewWithBestScore, bestRun.Estimator, numberOfFolds: 5, labelColumnName: ""reservation_status"");            \r\n \r\n- **What happened?**\r\nThe mlContext.MulticlassClassification.CrossValidate throws an exception\r\n\r\n- **What did you expect?**\r\nTo recover the metrics of the model on test data\r\n\r\n### Source code / logs\r\n\r\nCODE\r\n\r\n\r\nvar tmpPath = GetAbsolutePath(TRAIN_DATA_FILEPATH);\r\n            IDataView trainingDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n                                            path: tmpPath,\r\n                                            hasHeader: true,\r\n                                            separatorChar: \'\\t\',\r\n                                            allowQuoting: true,\r\n                                            allowSparse: false);\r\n\r\n            IDataView testDataView = mlContext.Data.BootstrapSample(trainingDataView);\r\n\r\n// STEP 2: Run AutoML experiment\r\n            Console.WriteLine($""Running AutoML Multiclass classification experiment for {ExperimentTime} seconds..."");\r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateMulticlassClassificationExperiment(ExperimentTime)\r\n                .Execute(trainingDataView, labelColumnName: ""reservation_status"");\r\n\r\n            // STEP 3: Print metric from the best model\r\n            RunDetail<MulticlassClassificationMetrics> bestRun = experimentResult.BestRun;\r\n            Console.WriteLine($""Total models produced: {experimentResult.RunDetails.Count()}"");\r\n            Console.WriteLine($""Best model\'s trainer: {bestRun.TrainerName}"");\r\n            Console.WriteLine($""Metrics of best model from validation data --"");\r\n            PrintMulticlassClassificationMetrics(bestRun.ValidationMetrics);\r\n\r\n            // STEP 4: Evaluate test data\r\n            IDataView testDataViewWithBestScore = bestRun.Model.Transform(testDataView);\r\n            var testMetrics = mlContext.MulticlassClassification.CrossValidate(testDataViewWithBestScore, bestRun.Estimator, numberOfFolds: 5, labelColumnName: ""reservation_status"");\r\n\r\nEXCEPTION\r\n\r\nUnhandled Exception: System.OverflowException: Arithmetic operation resulted in an overflow.\r\n   at Microsoft.ML.Data.VectorDataViewType.ComputeSize(ImmutableArray`1 dims)\r\n   at Microsoft.ML.Data.VectorDataViewType..ctor(PrimitiveDataViewType itemType, Int32[] dimensions)\r\n   at Microsoft.ML.Transforms.KeyToVectorMappingTransformer.Mapper..ctor(KeyToVectorMappingTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.KeyToVectorMappingTransformer.MakeRowMapper(DataViewSchema schema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.GetOutputSchema(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TrivialEstimator`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotHashEncodingTransformer..ctor(HashingEstimator hash, IEstimator`1 keyToVector, IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotHashEncodingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n   at Microsoft.ML.MulticlassClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numberOfFolds, String labelColumnName, String samplingKeyColumnName, Nullable`1 seed)\r\n   at ConsoleAppML2ML.ConsoleApp.ModelBuilder.CreateExperiment() in C:\\repos\\Curso ML\\Bootcamp-Handytec\\Clasificacion_multiclase\\ConsoleAppML2\\ConsoleAppML2ML.ConsoleApp\\ModelBuilder.cs:line 77\r\n   at ConsoleAppML2ML.ConsoleApp.Program.Main(String[] args) in C:\\repos\\Curso ML\\Bootcamp-Handytec\\Clasificacion_multiclase\\ConsoleAppML2\\ConsoleAppML2ML.ConsoleApp\\Program.cs:line 20\r\n[HotelBookings.tsv.zip](https://github.com/dotnet/machinelearning/files/4734119/HotelBookings.tsv.zip)\r\n\r\n'"
631211457,5210,b'File already exists error when loading LightGbmBinaryTrainer from MemoryStream',"b""### System information\r\nos version Windows (not sure)\r\n.net version 3.1.202\r\nmlnet version 1.3.1\r\n\r\n### Issue\r\nI am loading LightGbmBinaryTrainer from memory stream \r\n\r\n                ITransformer model = null;\r\n                using (MemoryStream ms = new MemoryStream(kv.Value))\r\n                {\r\n                    model = _mLContext.Model.Load(ms, out _inputSchema);\r\n                }\r\n\r\nNote, this code is executed in several threads in parallel over the same model. \r\n\r\nAnd I occasionally get the following exception: \r\n\r\nSystem.IO.IOException: The file 'D:\\SvcFab\\_App\\AIBuilder.Platform.Host_App157\\temp\\TLC_1CBA6C2E\\0' already exists. \r\n\r\nThis happens occasionally and I can't reliably reproduce this 100%. \r\n\r\n- **What did you expect?**\r\n1) I expected that no file operations are performed during loading from memory stream. My models are relatively small, but I can't guarantee that the filesystem is always available. I would appreciate to at least have some control over this behavior. \r\n\r\n2) But if file operations cannot be avoided, I expect to have no naming conflicts. \r\n\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.IO.IOException: The file 'D:\\SvcFab\\_App\\AIBuilder.Platform.Host_App157\\temp\\TLC_1CBA6C2E\\0' already exists.\r\n   at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath)\r\n   at System.IO.FileStream.Init(String path, FileMode mode, FileAccess access, Int32 rights, Boolean useRights, FileShare share, Int32 bufferSize, FileOptions options, SECURITY_ATTRIBUTES secAttrs, String msgPath, Boolean bFromProxy, Boolean useLongPath, Boolean checkHost)\r\n   at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n   at System.IO.Compression.ZipFileExtensions.ExtractToFile(ZipArchiveEntry source, String destinationFileName, Boolean overwrite)\r\n   at Microsoft.ML.RepositoryReader.OpenEntryOrNull(String dir, String name)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n\r\n"""
630938765,5208,b'Use the model designed by myself.',"b'Hi\r\n\r\nI am new to ML, so this might seem like a stupid question, may be it is wrong, but when I learn the ML.NET, I found that all of the models or the way training data in ML.NET have been designed, or you should import it from tensorflow or OXXN.  However, is it possible use the model that the structure of the neural network is designed by myself which has the pooling layers , convolutional layers and so on, just like Tensorflow and Pytorch to trainging the model? Also, could I change the  loss function which designed by myself?'"
630815095,5207,b'Make Microsoft.ML more developer friendly',"b""Microsoft.ML team, thank you for you job, as I can see, Microsoft.ML is the main hope for dotnet in machine learning word.\r\n\r\nI would like to express my concern about the closeness of Microsoft.ML from developer side.\r\n\r\nEach time I try to dive in the  Microsoft.ML I have the same scenario:\r\n\r\n1. I manage to run some standard code from samples\r\n\r\n2. I fail when I try to tune or discover my solution\r\n  - A year ago it was imposibility to get phi/theta matrixes https://github.com/dotnet/machinelearning/issues/3092\r\n\r\n  - This time I run text classification task: FeaturizeText -> SdcaLogisticRegression\r\n    - I try to plot ROC curve but Microsoft.ML.Data.BinaryClassifierEvaluator.EvaluateWithPRCurve   is not available (not yiet available from public API)\r\n  \r\n    - I try to get Vocabulary from FeaturizeTextExstimator to perform some sort of PFI analysis, this data is not available too.\r\n\r\n3. I fight with this closeness several days, I'm losing this battle, I'm going back to use .py libraries\r\n\r\n\r\nMy opinion: **internal is always evil** if your can't leave inner imlementation of your class private/protected, if ohter classes of yout Library require asses this methods or properties, most likely this functionality must be available to consumers of your library.\r\n\r\nI undestand, that internal classes reduce the amount of API yout should support. Maybe it makes sense to move all internall classes to '.*.Internal' namespace, with convention, that classes from this namespaces should be used 'without guarantee of compatibility between versions' """
630685367,5206,b'Fitting model with array',"b'### System information\r\n\r\n- **OS Windows 7**:\r\n- **.NET Version 3.1.300**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** - I try to fit pipeline with byte[ ] columns.\r\n- **What happened?** - I get ""System.ArgumentOutOfRangeException: ""Schema mismatch for feature column \'Features\': expected Vector<Single>, got VarVector<Single> """".\r\n- **What did you expect?** - I expected my model fitting with non-float data. In general, I want to load some muscial files into a model. And I want to get some data from model in byte[ ] type.\r\n\r\n### Source code / logs\r\n\r\n```\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n            var testData = new TestData { Values = new byte[] { 1, 2 }, PredictedLabel = new byte[] { 3 } };\r\n            var dataView = mlContext.Data.LoadFromEnumerable(new TestData[] { testData });\r\n            var pipeline = mlContext.Transforms\r\n                .CopyColumns(""Label"", ""PredictedLabel"")\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""Values""))\r\n                .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n            var model = pipeline.Fit(dataView);\r\n        }\r\n        class TestData\r\n        {\r\n            public byte[] Values;\r\n\r\n            public byte[] PredictedLabel;\r\n        }\r\n\r\n        class PredictedData\r\n        {\r\n            public byte[] PredictedLabel;\r\n        }\r\n    }\r\n```\r\n\r\n'"
630343727,5204,b'Records | C# 9 + F# Improved Interop',"b'At //Build 2020, plans for [records in C# 9](https://devblogs.microsoft.com/dotnet/welcome-to-c-9-0/#records) were announced. Referencing issue #180 which originally raised this question. While you can use records in F# to define the `DataViewSchema`,  once records support becomes available in C# 9, it could potentially be an opportunity to further improve the interop and experience with F#.'"
630336084,5203,b'ApplyOnnxModel() throw runtime error in an ongoing sample for onnx conversion',b'Can reproduce using https://github.com/dotnet/machinelearning/pull/5195/commits/0b1a59c95b281eedfd2bfb723b6b8e4e33182045\r\nThe related file is OnnxConversion.cs. \r\nJust curious why ML.NET model can make through but onnx model not.'
629733250,5199,b'Loading ML Model from a Stream',"b'Trying to load a ML model from a stream (having the model as an embedded resource in the project), I get the below exception at mlContext.Model.Load() line. \r\n\r\nSame code snippet works if I load the model using the absolute filepath for the model.\r\n\r\nPackage Version: 1.5\r\n\r\n`""System.ArgumentException: Illegal characters in path. (Parameter \'path\')\\r\\n   at System.IO.Path.GetFullPath(String path)\\r\\n   at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\\r\\n   at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\\r\\n   at System.IO.File.OpenRead(String path)\\r\\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\\r\\n   at PassionFruit.ML.Engines.SentimentPrediction.CreatePredictionEngine()`\r\n\r\n\r\n                // Create new MLContext\r\n                MLContext mlContext = new MLContext();\r\n                string modelName = ""PassionFruit.ML.MLModel.zip"";\r\n                var assembly = Assembly.GetExecutingAssembly();\r\n\r\n                using (var stream = assembly.GetManifestResourceStream(modelName))\r\n                using (StreamReader reader = new StreamReader(stream))\r\n                {\r\n                    var modelStream = reader.ReadToEnd();\r\n                    ITransformer mlModel = mlContext.Model.Load(modelStream, out DataViewSchema inputSchema);\r\n                    var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n                    return predEngine;\r\n                }\r\n```'"
629473390,5193,b'Error running experiment when specifying validationDataSet that contains a vector',"b'### System information\r\n\r\n- OS: Windows 10.0.18363\r\n- .NET Version 3.1.101\r\n\r\n### Issue\r\n\r\n- Running classification experiment with training/validation datasets the same, but containing:\r\n\r\n        [VectorType(10)]\r\n        public float[] d_hist{ get; set; }\r\n\r\n- Exception: Training data and validation data schemas do not match. Column \'d_hist\' is of type Vector<Single, 10> in train data, and type Vector<Single, 10> in validation data. (Parameter \'validationData\').\r\n- When not specifying the validation dataset I can build the model and validate manually after but cannot pass the validation dataset directly to the experiment.\r\n\r\n### Source code / logs\r\nSeems to be failing in UserInputValidation:\r\n\r\n```\r\nif (trainCol.Type != validCol.Value.Type)\r\n                {\r\n                    throw new ArgumentException($""{schemaMismatchError} Column \'{trainCol.Name}\' is of type {trainCol.Type} in train data, and type "" +\r\n                        $""{validCol.Value.Type} in validation data."", nameof(validationData));\r\n                }\r\n```\r\n\r\nI wonder if the comparison should be:\r\n\r\n`trainCol.Type.Equals(validCol.Value.Type)`'"
629137873,5191,b'Race condition with named model pool initialization.',"b""### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nChanged my call to AddPredictionEnginePool in my ASP.net Core app to use a model name and updated my Predict function to load the named model.\r\n\r\n- **What happened?**\r\n\r\nCalling the API with more than one prediction request at once started causing the API to crash.\r\n\r\n- **What did you expect?**\r\n\r\nThe PredictionEnginePool should have been able to handle multiple requests at once, as it did with the default pool. Adding a call on API startup to get the prediction engine for that name and returning works as a workaround (or adding a lock around the Predict call), but should the named pools not be initialized on startup like the default pool is? Or provide the option to perform that initialization automatically or warn in the documentation that the named pools aren't thread safe on the first call.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
628972165,5190,b'Attempted to read or write protected memory. This is often an indication that other memory is corrupt',b'### System information\r\n\r\n- Windows 10 10.0.18363.836\r\n- .NET Core 3.1\r\n- Microsoft.ML 1.5\r\n\r\n### Issue\r\n\r\n- How to fix this.\r\n\r\n![image](https://user-images.githubusercontent.com/11924335/83492875-22194d80-a4de-11ea-9d0d-4066d8a132b2.png)'
628878114,5188,b'Add  a threshold parameter for root cause analysis',"b'### Issue\r\n\r\n- **Users want a threshold to determin whether the selected is a root cause, so we add a new parameter in the interface. The default value is 0.95**\r\n\r\n'"
628604295,5184,b'CI crash on mac os ',b'Randomly see below 3 crash only on mac os:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=637346&view=logs&jobId=23576d1c-355e-5d27-4c31-0725f923794b&j=23576d1c-355e-5d27-4c31-0725f923794b&t=5b5048ea-91bc-5d7d-fb0b-ace30192f432\r\n\r\nThe active Test Run was aborted because the host process exited unexpectedly while executing following test(s):\r\nMicrosoft.ML.RunTests.TestDataPipe.SavePipeTrainAndScoreFccTransformStr\r\n\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=662867&view=logs&jobId=23576d1c-355e-5d27-4c31-0725f923794b&j=23576d1c-355e-5d27-4c31-0725f923794b&t=bcab25d9-33c3-57fc-b368-7b48febf4d8a\r\n\r\nThe active Test Run was aborted because the host process exited unexpectedly while executing following test(s):\r\nMicrosoft.ML.RunTests.TestDataPipe.SavePipeNgramHash\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=653881&view=logs&j=23576d1c-355e-5d27-4c31-0725f923794b&t=bcab25d9-33c3-57fc-b368-7b48febf4d8a\r\n\r\nThe active Test Run was aborted because the host process exited unexpectedly while executing following test(s):\r\nMicrosoft.ML.Functional.Tests.Evaluation.TrainAndEvaluateWithPrecisionRecallCurves\r\n'
628471619,5183,b'[feature request] Dimensionality Reduction API',b'### Features Reduction\r\n\r\nIt would be great if dimensionality reduction API could be added to ML.NET. This will be a major advantage in shortening training time.'
627703765,5182,"b""Schema mismatch for input column 'Image': expected image, got Vector<Byte> for Predictions made using model trained with MobilenetV2 and ResnetV250""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\nI\'m running an ASP.NET Core 3.1 Web app with ML.NET. I\'m unable to make predictions with trained model when using ImageClassificationTrainer.Architecture.MobilenetV2 and ImageClassificationTrainer.Architecture.ResnetV250. \r\n\r\nHowever it works with ImageClassificationTrainer.Architecture.InceptionV3 and ImageClassificationTrainer.Architecture.ResnetV2101.\r\n\r\n- **What did you do?**\r\nI\'ve trained the model. Then I\'ve made a prediction with prediction engine pool.\r\n- **What happened?**\r\nGot a mismatch error when trying to predict.\r\n- **What did you expect?**\r\nI\'d like to be able to make predictions with MobilenetV2 and ResnetV250 as well.\r\n### Source code / logs\r\n               \r\n\r\n                var trainDataRawBytes = _mapper.Map<IEnumerable<ImageDataRaw>>(imageData);\r\n                var testDataRawBytes = _mapper.Map<IEnumerable<ImageDataRaw>>(testData);\r\n\r\n                trainingData = _mlContext.Data.LoadFromEnumerable(trainDataRawBytes);\r\n\r\n                var options = new ImageClassificationTrainer.Options\r\n                {\r\n                    FeatureColumnName = ""Image"",\r\n                    LabelColumnName = ""LabelKey"",\r\n                    Arch = ImageClassificationTrainer.Architecture.MobilenetV2,\r\n                    Epoch = 50,       //100\r\n                    BatchSize = 10,\r\n                    LearningRate = 0.01f\r\n                };\r\n\r\n                IEstimator<ITransformer> pipeline =\r\n                    _mlContext.Transforms.Conversion.MapValueToKey(""LabelKey"", ""Label"")\r\n                        .Append(_mlContext.MulticlassClassification.Trainers\r\n                            .ImageClassification(options))\r\n                        .Append(_mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabelValue"",\r\n                            ""PredictedLabel""))\r\n                        .AppendCacheCheckpoint(_mlContext);\r\n\r\n                model = pipeline.Fit(trainingData);\r\n                testingResults = EvaluateModel(testDataRawBytes);`\r\n\r\n```        \r\n        private List<ImagePredictionResult> EvaluateModel(IEnumerable<ImageDataRaw> imageData)\r\n        {\r\n            return imageData.ToList().Select(image => _predictionEnginePool.Predict(""ImageClassificationModel"", image))\r\n                .ToList().Select(\r\n                    imagePrediction => new ImagePredictionResult\r\n                    {\r\n                        RealLabel = imagePrediction.Label,\r\n                        PredictedLabel = imagePrediction.PredictedLabelValue,\r\n                        Score = imagePrediction.Score.Max()\r\n                    }).ToList();\r\n        }\r\n```\r\n\r\n```System.ArgumentOutOfRangeException: Schema mismatch for input column \'Image\': expected image, got Vector<Byte> (Parameter \'inputSchema\')\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.CheckInputColumn(DataViewSchema inputSchema, Int32 col, Int32 srcCol)\r\n   at Microsoft.ML.Data.OneToOneTransformerBase.CheckInput(DataViewSchema inputSchema, Int32 col, Int32& srcCol)\r\n   at Microsoft.ML.Data.OneToOneTransformerBase.OneToOneMapperBase..ctor(IHost host, OneToOneTransformerBase parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper..ctor(ImageResizingTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.MakeRowMapper(DataViewSchema schema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngine`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.ModelOperationsCatalog.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolPolicy`2.Create()\r\n   at Microsoft.Extensions.ObjectPool.DefaultObjectPool`1.Create()\r\n   at Microsoft.Extensions.ObjectPool.DefaultObjectPool`1.Get()\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.GetPredictionEngine(String modelName)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at PDCSBE.Services.Implementation.TrainService.<EvaluateModel>b__9_0(ImageDataRaw image) in D:\\...\\TrainService.cs:line 175\r\n   at System.Linq.Enumerable.SelectListIterator`2.ToList()\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at PDCSBE.Services.Implementation.TrainService.EvaluateModel(IEnumerable`1 imageData) in D:\\...\\TrainService.cs:line 175\r\n   at PDCSBE.Services.Implementation.TrainService.TrainModel(IEnumerable`1 imageData, IEnumerable`1 testData, Int32 modelId) in D:\\...\\TrainService.cs:line 106\r\n   at PDCSBE.Services.Implementation.TrainService.TrainModelWithMetrics(Int32 modelId) in D:\\...\\TrainService.cs:line 50\r\n   at PDCSBE.Api.Controllers.TrainController.TrainModel(Int32 modelId) in D:\\...\\TrainController.cs:line 24\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at Microsoft.Extensions.Internal.ObjectMethodExecutor.Execute(Object target, Object[] parameters)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
627658869,5181,"b""InvalidOperationException - Invalid TValue in GetGetter: 'System.Collections.Generic.IEnumerable`1[System.Collections.Generic.IDictionary`2[System.Int64,System.Single]]'""","b'### System information\r\n- Runtime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n .Net Framework 4.7.2 x64\r\n\r\nLibraries:\r\nMicrosoft.ML 1.5.0\r\nMicrosoft.ML.OnnxTransformer 1.5.0\r\nMicrosoft.ML.OnnxRuntime 1.3.0\r\n\r\n- Issue:\r\nThe following code below fails with an InvalidOperationException - Invalid TValue in GetGetter: \'System.Collections.Generic.IEnumerable`1[System.Collections.Generic.IDictionary`2[System.Int64,System.Single]]\'\r\n\r\n- Repro steps below\r\n- Trying to get the output_probability field (which is Sequence of Maps) from an sklearn RandomForestClassifier model converted to onnx using skl2onnx library.\r\n- I expected ML.Net to support this scenario since I have seen other posts of users using similar fields as models outputs.\r\n\r\nCall Stack:\r\nUnhandled Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.InvalidOperationException: Invalid TValue in GetGetter: \'System.Collections.Generic.IEnumerable`1[System.Collections.Generic.IDictionary`2[System.Int64,System.Single]]\'\r\n   at Microsoft.ML.Data.RowToRowMapperTransform.Cursor.GetGetter[TValue](Column column)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.CreateDirectSetter[TDst](DataViewRow input, Int32 col, Delegate poke, Delegate peek)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.GenerateSetter(DataViewRow input, Int32 index, Column column, Delegate poke, Delegate peek)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase..ctor(TypedCursorable`1 parent, DataViewRow input, String channelMessage)\r\n   at Microsoft.ML.Data.TypedCursorable`1.GetCursor(Func`2 additionalColumnsPredicate, Nullable`1 randomSeed)\r\n   at Microsoft.ML.Data.TypedCursorable`1.GetCursor()\r\n   at Microsoft.ML.PipeEngine`1.<RunPipe>d__3.MoveNext()\r\n   at testonnx.Program.Main(String[] args)\r\n\r\n### Source code Repro:\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Transforms.Onnx;\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing System.Threading.Tasks;\r\n\r\nnamespace testonnx\r\n{\r\n    public class OutputData\r\n    {\r\n        [ColumnName(""output_probability"")]\r\n        [OnnxSequenceType(typeof(IDictionary<long, float>))]\r\n        public IEnumerable<IDictionary<long, float>> OutputProbabilities;\r\n    }\r\n\r\n    public class InputData\r\n    {\r\n        [ColumnName(""float_input"")]\r\n        [VectorType(4)]\r\n        public float[] Input { get; set; }\r\n    }\r\n\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var outputSchemaDef = SchemaDefinition.Create(typeof(OutputData));\r\n            var inputSchemaDef = SchemaDefinition.Create(typeof(InputData));\r\n            var mlContext = new MLContext();\r\n            var pipeline = mlContext.Transforms\r\n               .ApplyOnnxModel(new string[] { ""output_probability"", ""output_label"" }, new string[] { ""float_input"" }, ""rf_iris_new.onnx"");\r\n\r\n            var inputs = new List<InputData>() { new InputData() { Input = new float[] { 3.1f, 0.9f, 1.2f, 0.8f } } };\r\n\r\n            var data = mlContext.Data.LoadFromEnumerable(inputs, inputSchemaDef);\r\n\r\n            var model = pipeline.Fit(data);\r\n\r\n            var transformedValues = model.Transform(data);\r\n\r\n            var predictions = mlContext.Data.CreateEnumerable<OutputData>(\r\n                transformedValues, reuseRowObject: false, true, outputSchemaDef);\r\n\r\n            foreach (var pred in predictions) \r\n            {\r\n                Console.WriteLine(pred.OutputProbabilities.First()[0].ToString());              \r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n[rf_iris_new.zip](https://github.com/dotnet/machinelearning/files/4705133/rf_iris_new.zip)\r\n'"
627374335,5179,b'`ImageClassification` prediction appears slow',"b""I don't have much experience with DNN (more with traditional machine learning algorithms) so I went through the automated visual inspection tutorial. The training of the 400 subset images is relatively quick. However, the prediction time is incredibly slow. Running the prediction through 400 images took about 90sec using `ResnetV2101` and 10sec using `MobilenetV2`. For my application, I would need it to be about at least 5x to 10x faster (hopefully close to real-time).\r\n\r\nMy question is, am I doing something wrong or is there something I can do to improve prediction speed?\r\n\r\nThank you!"""
627029027,5178,"b""[Windows 10] : 'Unable to load DLL 'MklImports' or one of its dependencies'""","b""### System information\r\n\r\n- **OS version/distro**:  Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.300\r\n Commit:    b2475c1295\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.300\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.4\r\n  Commit:  0c2e69caa6\r\n\r\n.NET Core SDKs installed:\r\n  1.0.0 [C:\\Program Files\\dotnet\\sdk]\r\n  2.0.2 [C:\\Program Files\\dotnet\\sdk]\r\n  2.0.3 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.2 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.4 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.101 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.102 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.103 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.104 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.200-preview-007576 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.200 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.201 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.300-preview2-008533 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.301 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.400-preview-009063 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.401 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.402 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.403 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.500-preview-009297 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.500-preview-009335 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.503 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.504 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.507 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.508 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.509 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.511 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.600-preview-009472 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.800-preview-009696 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.801 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.802 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.103 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.100-preview6-012264 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.101 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.101 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.300 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.0-preview2-final [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.15 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.18 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.0-preview2-final [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.15 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.18 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.0-preview6.19307.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 1.0.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 1.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.0-preview2-26406-04 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.3-servicing-26724-03 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.15 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.18 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n     Creating a Prediction using ML.Net time-series\r\n.Net core: 3.1.300\r\nMicrosoft.ML : 1.5.0\r\nMicrosoft.ML.TimeSeries : 1.5.0\r\nVisual Studio 2019 16.6.0\r\n \r\n- **What happened?**\r\nI am getting 'Unable to load DLL 'MklImports' or one of its dependencies' while calling Fit method of ForecastBySsa() in a time series prediction.\r\n\r\nThe issue surfaced in Jupyter notebook only, the same code runs fine in Visual Studio 2019.\r\n\r\n- **What did you expect?**\r\nNo error \r\nChecked https://github.com/dotnet/machinelearning/issues/3903\r\nIt has a workaround for macOS and nothing for windows, hence opening this issue specifically for Windows.\r\n\r\n### Source code / logs\r\n\r\nLogs\r\nSubmitCode: var model = pipeline.Fit(data);\r\nCodeSubmissionReceived: var model = pipeline.Fit(data);\r\nCompleteCodeSubmissionReceived: var model = pipeline.Fit(data);\r\nSystem.DllNotFoundException: Unable to load DLL 'MklImports' or one of its dependencies: The specified module could not be found. (0x8007007E)\r\nat Microsoft.ML.Transforms.TimeSeries.EigenUtils.Dsytrd(Layout matrixLayout, Uplo uplo, Int32 n, Double[] a, Int32 lda, Double[] d, Double[] e, Double[] tau)\r\nat Microsoft.ML.Transforms.TimeSeries.EigenUtils.MklSymmetricEigenDecomposition(Single[] input, Int32 size, Single[]& eigenValues, Single[]& eigenVectors)\r\nat Microsoft.ML.Transforms.TimeSeries.TrajectoryMatrix.ComputeSvd(Single[]& singularValues, Single[]& leftSingularvectors)\r\nat Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModelerInternal.TrainCore(Single[] dataArray, Int32 originalSeriesLength)\r\nat Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModelerInternal.Train(RoleMappedData data)\r\nat Microsoft.ML.Transforms.TimeSeries.SsaForecastingTransformer..ctor(IHostEnvironment env, Options options, IDataView input)\r\nat Microsoft.ML.Transforms.TimeSeries.SsaForecastingEstimator.Fit(IDataView input)\r\nat Submission#30.<>d__0.MoveNext()\r\n\r\n"""
625916727,5171,b'Feature request: ONNX Export to older file versions/opsets',"b'### Intro\r\nML.NET supports exporting trained models to the ONNX file format, but only allows export to the latest version/opset. The version of the exported model can also change as ML.NET is updated, which can break compatibility with other toolsets that only support older ONNX versions.\r\n\r\n### Feature Request\r\n- Support exporting models to older ONNX versions and opsets (ONNX version 1.4, opset 9 or older)\r\n\r\n### Use case\r\nWe would like to run a model trained with ML.NET on Windows devices using the inbox Windows ML runtime, but it does not support the latest [ONNX versions](https://docs.microsoft.com/en-us/windows/ai/windows-ml/onnx-versions) which ML.NET exports to.\r\n\r\n### Workarounds\r\n- Exported models can be converted using the [ONNX Version Converter](https://github.com/onnx/onnx/blob/master/docs/VersionConverter.md), but it does not work on all models.\r\n- Models can also be hand-edited.'"
625505339,5170,"b""Unable to load DLL 'tensorflow' with published WPF app""","b""### System information\r\n\r\n- **OS version/distro**: Window 10\r\n- **.NET Version (eg., dotnet --info)**: .NET framework 4.7.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** I'm trying sample code for image classification using MLNet. \r\n- **What happened?** Everything works fine in development environment which means that I can use model to predict label of images. However, when I tried to publish a ClickOnce application, the exception System.DllNotFoundException: Unable to load DLL 'tensorflow': The specified module could not be found keeps throwing.\r\n- **What did you expect?** I want to know how to deliver WPF application with MLNet properly\r\n\r\n### Source code / logs\r\nSystem.DllNotFoundException: Unable to load DLL 'tensorflow': The specified module could not be found.\r\n![image](https://user-images.githubusercontent.com/20205286/82997902-328a7d80-a031-11ea-86ce-478c5d726db0.png)\r\n\r\nFor source code, it is the same as https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification but I update the code to see if all libraries is loaded correctly\r\n\r\n[WpfApp1.zip](https://github.com/dotnet/machinelearning/files/4687605/WpfApp1.zip)\r\n"""
625427239,5168,"b""AUC is not defined when there is no positive class in the data (Parameter 'PosSample')""","b""\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.201\r\n Commit:    b1768b4ae7\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.14393\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.201\\\r\n\r\n### AUC is not defined when there is no positive class in the data (Parameter 'PosSample')\r\n![image](https://user-images.githubusercontent.com/8334797/82986574-3080e880-a04a-11ea-8cb3-d41fa3572a97.png)\r\n\r\nI get this exception while doing an evaluation on the **AnomalyDetection** model. i am using the **CreditCardFraudDetection** sample and running it on my dataset. i have checked if my test dataset has both positive and negative classes and they are present.\r\n\r\n![image](https://user-images.githubusercontent.com/8334797/82986627-4d1d2080-a04a-11ea-87cf-4cd4182e91cf.png)\r\n\r\n![image](https://user-images.githubusercontent.com/8334797/82986658-5908e280-a04a-11ea-9315-50f93b0a8803.png)\r\n\r\nAm i missing something?"""
625170781,5165,b'Tracking ML .NET behavior on AMD builds',"b""This issue is for tracking ML .NET behavior on AMD builds.\r\n\r\nCurrently we are testing our builds on Intel CPUs and NVIDIA GPUs (please correct me if I'm wrong!) However, as Issue #4703 indicates, we might be obtaining different results on other builds such as:\r\n\r\n- AMD CPU/ No GPU\r\n    - Currently testing through [D4as_v4 ](https://docs.microsoft.com/en-us/azure/virtual-machines/dav4-dasv4-series#dasv4-series)VM on Azure\r\n- AMD CPU/ NVIDIA GPU (build of Issue #4703's author)\r\n- AMD CPU/AMD GPU\r\n\r\nI don't fully understand why exactly we obtain different behavior in these builds. However it is important to track these, and perhaps do regular CI test builds on these possibilities. """
624937784,5164,b'How RMSE is calculated ? ',"b'### System information\r\n\r\nSDK .NET Core (refl\xc3\xa9tant tous les global.json)\xc2\xa0:\r\n Version:   3.1.300\r\n Commit:    b2475c1295\r\n\r\nEnvironnement d\'ex\xc3\xa9cution\xc2\xa0:\r\n OS Name:     ubuntu\r\n OS Version:  18.04\r\n OS Platform: Linux\r\n RID:         ubuntu.18.04-x64\r\n Base Path:   /usr/share/dotnet/sdk/3.1.300/\r\n\r\nHost (useful for support):\r\n  Version: 3.1.4\r\n  Commit:  0090613580\r\n\r\n.NET Core SDKs installed:\r\n  3.1.300 [/usr/share/dotnet/sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI wanted to calculate the RMSE of a FastTree model. \r\n\r\nI created a FastTree model. I trained him. I evaluated it on a test dataset.\r\n\r\nI displayed the result using the `Evaluate()` function.\r\n\r\n```csharp\r\npublic static void TrainTest(....){\r\n..... // train and test method\r\nvar metrics = mlContext.Regression.Evaluate(predictions, ""Label"", ""Score"");\r\nDumpMetrics(name, metrics);\r\n}\r\n\r\npublic static void DumpMetrics(string name, RegressionMetrics metrics)\r\n        {\r\n            Console.WriteLine();\r\n            Console.WriteLine($""*************************************************"");\r\n            Console.WriteLine($""*       Model quality metrics evaluation         "");\r\n            Console.WriteLine($""*       "" + name);\r\n            Console.WriteLine($""*------------------------------------------------"");\r\n            Console.WriteLine($""*       R2 Score:      {metrics.RSquared:0.###}"");\r\n            Console.WriteLine($""*       RMS loss:      {metrics.RootMeanSquaredError:#.###}"");\r\n            Console.WriteLine($""*       MAE loss:      {metrics.MeanAbsoluteError:#.###}"");\r\n            Console.WriteLine($""*************************************************"");\r\n        }\r\n```\r\n\r\n- **What happened?**\r\n\r\n```bash \r\n*************************************************\r\n*       Model quality metrics evaluation         \r\n*       \r\n*------------------------------------------------\r\n*       R2 Score:      0,882\r\n*       RMS loss:      30,57\r\n*       MAE loss:      20,03\r\n*************************************************\r\n```\r\n\r\nSo the RMSE is: `30,57`.\r\n\r\n- **What did you expect?**\r\n\r\nI saved the output of the model to a CSV file.\r\n\r\nI used the `mean_squared_error` function from the Python scikit-learn library and got a completely different value for RMSE. \r\n\r\n```python\r\nimport pandas as pd\r\nimport math\r\ndf =pd.read_csv(\'test.csv\',decimal=\',\',sep=\';\')\r\nprint(math.sqrt(mean_squared_error(df[\'label\'],df[\'prediction\'])))\r\n```\r\nThe result is: \r\n\r\n```bash \r\n125.30721032995426\r\n```\r\n\r\n```python\r\ndef rmse(predictions, targets):\r\n    return np.sqrt(((predictions - targets) ** 2).mean())\r\nrmse(df[\'prediction\'].values,df[\'label\'].values)\r\n```\r\n\r\nThe result is: \r\n```bash\r\n125.30721032995426\r\n```\r\n\r\nSo my questions are: does the value found in the object returned by the `Evaluate` function apply the following formula between  `target` and `prediction`? If yes, why the results are different ? \r\n\r\n![RMSE](http://www.sciweavers.org/tex2img.php?eq=%5Csqrt%7B%28%5Cfrac%7B1%7D%7Bn%7D%29%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%28y_%7Bi%7D%20-%20x_%7Bi%7D%29%5E%7B2%7D%7D&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
624303051,5162,b'Auto.ML Regression Experiment throwing Exception when culture is pl-PL',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1.300-preview-015135\r\n- **Auto.ML Version**: v0.17.0-preview2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAutoML experiment using Boston houses dataset, RegressionExperiment and pl-PL culture\r\n- **What happened?**\r\nException was thrown after ~3 minutes of experiment - `float.Parse` could not parse string.\r\n- **What did you expect?**\r\nException should not be thrown.\r\n\r\n### Source code / logs\r\n\r\nCall stack:\r\n\r\nUnhandled exception. System.OverflowException: Value was either too large or too small for a Decimal.\r\n   at System.Number.ThrowOverflowOrFormatException(ParsingStatus status, TypeCode type)\r\n   at System.Single.Parse(String s)\r\n   at Microsoft.ML.AutoML.SweeperProbabilityUtils.ParameterSetAsFloatArray(IValueGenerator[] sweepParams, ParameterSet ps, Boolean expandCategoricals)\r\n   at Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnu\r\nmerable`1 trainerWhitelist)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.ExecuteCrossVal(IDataView[] trainDatasets, ColumnInformation columnInfo, IDataView[] validationDatasets, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, UInt32 numberOfCVFolds, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Playground.Program.AutoMl() in C:\\GIT\\ML\\dotnet\\AI\\Playground\\Program.cs:line 37\r\n   at Playground.Program.Main(String[] args) in C:\\GIT\\ML\\dotnet\\AI\\Playground\\Program.cs:line 19\r\n\r\nManual setting culture using `Thread.CurrentThread.CurrentCulture = new CultureInfo(""en-US"");` solves issue.'"
624250995,5161,b'Gradual Memory Increase',"b'I am not sure whether this is write channel but I need quick help\r\n\r\nWe have observed that gradual increase in memory of Host object of module Microsoft.ML.Data.\r\n\r\nWe have .net core worker service running as windows service.\r\n\r\nIt does prediction for 50 ML models in parallel.\r\n\r\n1. We are loading all models into memory then creating 50 threads for 50 models which would be running continuously and predicting values.\r\n\r\n2. For testing purpose we stop all threads ever 1hour and dispose it. Then calling GC.Collect().\r\n\r\n3. Also taking memory snapshot every 1 hour using VS performance profiler. We have observed that\r\ngradual increase in memory of Host object of module Microsoft.ML.Data. \r\n\r\n4. If we remove all loded models from memory and call GC.  the the memory consumed by Host object of module Microsoft.ML.Data gets freed.\r\n\r\nCould you please suggest anything if we want to resolve gradual increase of memory without removing models from memory.\r\n\r\n``` csharp\r\n\r\nprivate List<PredictionResult> ExecuteModel(ModelTransformer modelTransformer, IDataView dataView, DateTime requestDateTime) \r\n        {\r\n            List<PredictionResult> predictionResults = null;\r\n            try\r\n            {\r\n                if (modelTransformer.Transformer != null)\r\n                {\r\n                    string modelConfigId = modelTransformer.ModelConfigId;\r\n                    string actualValueColumnName = modelTransformer.TextLoaderOutputColumn;\r\n                    string tagNameForPredictedValue = modelTransformer.PredictedTagName;\r\n                    string tagNameForActualValue = modelTransformer.TargetVariable;\r\n\r\n                    predictionResults = new List<PredictionResult>();\r\n                    IDataView predictions = modelTransformer.Transformer.Transform(dataView);\r\n\r\n                    Logger.log.InfoFormat(""[Request at {0} Model Id: {1}] prediction value extraction"", requestDateTime, modelConfigId);\r\n\r\n                    IEnumerable<float> listScore = predictions.GetColumn<float>(""Score"");\r\n\r\n                    Logger.log.InfoFormat(""[Request at {0} Model Id: {1}] score extraction completed"", requestDateTime, modelConfigId);\r\n\r\n                    IEnumerable<string> listTime = predictions.GetColumn<string>(preModelExecutionDetails.TextLoaderColumn[0].Name);\r\n\r\n                    Logger.log.InfoFormat(""[Request at {0} Model Id: {1}] Time extraction completed"", requestDateTime, modelConfigId);\r\n\r\n                    IEnumerable<float> listActualValues = predictions.GetColumn<float>(actualValueColumnName);\r\n\r\n                    predictions = null;\r\n\r\n                    Logger.log.InfoFormat(""[Request at {0} Model Id: {1}] actual value extraction completed"", requestDateTime, modelConfigId);\r\n\r\n                    predictionResults.AddRange(\r\n                        listTime.Zip(listScore, (time, score) => new PredictionResult\r\n                        {\r\n                            TagName = tagNameForPredictedValue,\r\n                            Timestamp = Convert.ToDateTime(time),\r\n                            Confidence = ConfigParameters.TagValueDefaultConfidence,\r\n                            Value = score.ToString(),\r\n                            ValueType = Models.ValueType.SCORE.ToString()\r\n                        }).ToList());\r\n\r\n                    predictionResults.AddRange(\r\n                        listTime.Zip(listActualValues, (time, actualVal) => new PredictionResult\r\n                        {\r\n                            TagName = tagNameForActualValue,\r\n                            Timestamp = Convert.ToDateTime(time),\r\n                            Confidence = ConfigParameters.TagValueDefaultConfidence,\r\n                            Value = actualVal.ToString(),\r\n                            ValueType = Models.ValueType.ACTUAL.ToString()\r\n                        }).ToList());\r\n                }\r\n            }\r\n            finally\r\n            {\r\n                modelTransformer = null;\r\n            }\r\n            return predictionResults;\r\n        }\r\n```\r\n'"
623890544,5159,b'Feature request: Built-in support for ELMO/BERT embeddings',"b""# Intro\r\nML.NET is not yet very well equipped for some natural-language processing (NLP) workloads. While there is already support for basic processing steps (tokenization, stop word removal, ...) and sentiment, other, higher-level workloads are not yet supported.\r\n\r\n# Feature request\r\n\r\n- Pre-trained embeddings, like BERT or GloVe, for documents are useful for down-level tasks.\r\n- It'd be even better if there was an easy to use API to tune or train custom models on custom datasets.\r\n\r\n# Use case\r\nIn our specific use case, we develop document classifiers. We only have a limited set of labeled documents to train with. Our plan is to use a pretrained or trained document embeddings, and learn a simple classifier on top, using the labeled documents.\r\n\r\n# Workarounds\r\nThere is already a project that runs BERT as ONNX on top of ML.NET, see https://github.com/GerjanVlot/BERT-ML.NET. I'd like to see this become an official part of ML.NET, with a good API, properly maintained and updated.\r\n\r\n# Outlook\r\nThese models are building-blocks for other features, like entity recognition (#630). Ideally ML.NET would support many more NLP tasks, as listed in https://github.com/microsoft/nlp-recipes#content. Generally, we notice an uptake in NLP-related project inquiries."""
623844319,5157,b'KeyNotFoundException after Bottleneck Computation phase finishes while training image classification model',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1.1\r\n\r\n### Issue\r\n\r\n- While trying to train an image classification model I get \r\n**KeyNotFoundException: The given key \'3711\' was not present in the dictionary.** (key varies  every new time I start the app)\r\njust after the Bottleneck Computation phase using the validation dataset finishes.\r\nThe only solution I found was [this article](https://developers.de/2020/03/05/ml-net-fails-with-keynotfoundexception/)\r\nHowever I didn\'t find any cache folders, so I just deleted workspace files and although the app starts to train the model from scratch, I still get the same error.\r\n\r\n### Source code / logs\r\nMy Program.cs file: \r\n\r\n`\r\n \r\n\r\n\r\n\r\n     class Program\r\n           {\r\n           static void Main(string[] args)\r\n            {\r\n            var mlContext = new MLContext();\r\n            \r\n            var projectDirectory = Path.GetFullPath(Path.Combine(AppContext.BaseDirectory, ""../../../""));\r\n            var trainRelativePath = Path.Combine(projectDirectory, ""Data\\\\train"");\r\n            var testRelativePath = Path.Combine(projectDirectory, ""Data\\\\test1"");\r\n            var workspaceRelativePath = Path.Combine(projectDirectory, ""Workspace"");\r\n\r\n            var trainImages = LoadImagesFromDirectory(trainRelativePath);\r\n            var testImages = LoadImagesFromDirectory(testRelativePath);\r\n\r\n            var trainData = mlContext.Data.LoadFromEnumerable(trainImages);\r\n            var testData = mlContext.Data.LoadFromEnumerable(testImages);\r\n\r\n            var shuffledData = mlContext.Data.ShuffleRows(trainData);            \r\n            \r\n            var preprocessingPipeline = mlContext.Transforms.Conversion.MapValueToKey(\r\n                    inputColumnName: ""Label"",\r\n                    outputColumnName: ""LabelAsKey"")\r\n                .Append(mlContext.Transforms.LoadRawImageBytes(\r\n                    outputColumnName: ""Image"",\r\n                    imageFolder: trainRelativePath,\r\n                    inputColumnName: ""ImagePath""));\r\n\r\n            var preProcessedData = preprocessingPipeline\r\n                .Fit(shuffledData)\r\n                .Transform(shuffledData);\r\n            \r\n            var testProcessedData = preprocessingPipeline\r\n                .Fit(testData)\r\n                .Transform(testData);\r\n\r\n            var trainProcessedSet = mlContext.Data.TrainTestSplit(preProcessedData, testFraction: 0.999f);\r\n\r\n            var testSplit = mlContext.Data.TrainTestSplit(testProcessedData, testFraction: 0.999f);\r\n            var validationSet = testSplit.TrainSet;\r\n            var testSet = testSplit.TestSet;\r\n\r\n            var classifierOptions = new ImageClassificationTrainer.Options()\r\n            {\r\n                FeatureColumnName = ""Image"",\r\n                LabelColumnName = ""LabelAsKey"",\r\n                ValidationSet = validationSet,\r\n                Arch = ImageClassificationTrainer.Architecture.ResnetV2101,\r\n                MetricsCallback = Console.WriteLine,\r\n                TestOnTrainSet = false,\r\n                ReuseTrainSetBottleneckCachedValues = false,\r\n                ReuseValidationSetBottleneckCachedValues = false,\r\n                WorkspacePath=workspaceRelativePath,\r\n                Epoch = 100\r\n            };\r\n            \r\n            var trainingPipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(classifierOptions)\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\n            var trainedModel = trainingPipeline.Fit(trainProcessedSet.TrainSet);\r\n            mlContext.Model.Save(trainedModel, trainData.Schema,""Model.zip"");\r\n            \r\n            Console.ReadLine();\r\n        }\r\n\r\n        private static IEnumerable<ImageData> LoadImagesFromDirectory(string folder)\r\n        {\r\n            var files = Directory.GetFiles(folder, ""*"",\r\n                searchOption: SearchOption.AllDirectories);\r\n\r\n            foreach (var file in files)\r\n            {\r\n                    var label = Path.GetFileName(file).Split(""."")[0];\r\n                    \r\n                    yield return new ImageData()\r\n                    {\r\n                        ImagePath = file,\r\n                        Label = label\r\n                    };\r\n            }\r\n        }\r\n    }\r\n`\r\n\r\nImageData.cs: \r\n` \r\n    \r\n           public class ImageData\r\n           {\r\n                    public string ImagePath { get; set; }\r\n\r\n                    public string Label { get; set; }\r\n            }\r\n\r\n`\r\n\r\nModelInput.cs: \r\n`\r\n\r\n    public class ModelInput\r\n    {\r\n        public byte[] Image { get; set; }\r\n        \r\n        public UInt32 LabelAsKey { get; set; }\r\n\r\n        public string ImagePath { get; set; }\r\n\r\n        public string Label { get; set; }\r\n    }\r\n\r\n\r\n\r\n\r\n`\r\nModelOutput.cs:\r\n`\r\n\r\n\r\n    public class ModelOutput\r\n    {\r\n        public string ImagePath { get; set; }\r\n\r\n        public string Label { get; set; }\r\n\r\n        public string PredictedLabel { get; set; }\r\n    }\r\n\r\n\r\n`\r\n\r\nDetailed Exception info: \r\n**Unhandled exception. System.Collections.Generic.KeyNotFoundException: The given key \'3711\' was not present in the dictionary.\r\n   at System.Collections.Generic.Dictionary 2.get_Item(TKey key)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainAndEvaluateClassificationLayer(String trainBottleneckFilePath, Options options, String validationSetBottleneckFilePath, Int32 trainingsetSize)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase 2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase 2.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain 1.Fit(IDataView input)\r\n   at ModelBuilder.Program.Main(String[] args) in C:\\Users\\User\\RiderProjects\\CatVsDogsBinaryClassification\\ModelBuilder\\Program.cs:line 71**\r\n\r\n'"
623733113,5156,b'CustomMappingEstimator Exportable to ONNX?',b'### Question\r\n\r\n- **Will be CustomMappingEstimator exportable to ONNX in the future?**\r\n'
623665093,5155,b'Application crashes inside Docker containing when using .Fit()',"b'When creating a model for a recommender system that uses MatrixFactorization, the Docker Container crashes on an Ubuntu server without further notice.\r\n\r\nThe only note in the kernel log is\r\n`kernel: [12922.080806] traps: dotnet[30957] trap invalid opcode ip:7f07d81b5efc sp:7ffdc5965110 error:0 in libMatrixFactorizationNative.so[7f07d81a5000+2a000]`\r\n\r\nIn the local version the recommender system and the training of the model are working.\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\nUbuntu 18.04.4 LTS (GNU/Linux 4.15.0-101-generic x86_64)\r\n- **.NET Version (eg., dotnet --info)**: \r\nHost (useful for support):\r\n  Version: 3.1.4\r\n  Commit:  0c2e69caa6\r\n.NET Core SDKs installed:\r\n  No SDKs were found.\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\r\n\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nStarting training of a new model using matrix factorization\r\n- **What happened?**\r\nThe application and the Docker Container crash without further message or exception.\r\n- **What did you expect?**\r\nTraining of a new model or at least an exception\r\n\r\n### Source code / logs\r\n\r\n#### Implementation:\r\n```\r\nLog.Information(""Extracting train data..."");\r\nvar trainingData = GetDataView(trainData);\r\n\r\nvar options = new MatrixFactorizationTrainer.Options\r\n{\r\n    MatrixColumnIndexColumnName = UserIdEncoding,\r\n    MatrixRowIndexColumnName = MusicIdEncoding,\r\n    LabelColumnName = ""Label"",\r\n    NumberOfIterations = 20,\r\n    ApproximationRank = 100,\r\n    //Quiet = false\r\n};\r\nLog.Information(""Setting Matrix Factorization"");\r\nvar trainingPipeline = trainingData.Transformer.Append(\r\n    MLContext.Recommendation().Trainers.MatrixFactorization(options));\r\n\r\nLog.Information(""Starting training..."");\r\nITransformer trainedModel = trainingPipeline.Fit(trainingData.DataView);\r\n\r\nLog.Information(""Saving model..."");\r\nMLContext.Model.Save(trainedModel, trainingData.DataView.Schema, ModelPath);\r\n\r\nLog.Information(""Extracting test data...""); ;\r\nvar testingData = GetDataView(testData);\r\n\r\nLog.Information(""Starting model testing..."");\r\nvar testingTransform = trainedModel.Transform(testingData.DataView);\r\n\r\nLog.Information(""Evaluating model"");\r\nreturn MLContext.Recommendation().Evaluate(testingTransform);\r\n```\r\n\r\n#### Container Logs:\r\n\r\n```\r\n[13:45:25 Information]\r\nPreparing prediction Model\r\n\r\n[13:45:25 Information]\r\nStarting Model Training...\r\n\r\n[13:45:25 Information]\r\nExtracting train data...\r\n\r\n[13:45:25 Information]\r\nSetting Matrix Factorization\r\n\r\n[13:45:25 Information]\r\nStarting training...\r\n\r\nWarning: insufficient blocks may slow down the trainingprocess (4*nr_threads^2+1 blocks is suggested)\r\nWarning: insufficient blocks may slow down the trainingprocess (4*nr_threads^2+1 blocks is suggested)\r\n--> Application crash\r\n```\r\n\r\n'"
621283052,5144,b'Add line limit to readMultilines in TextLoader',"b'_(This issue tracks @justinormont \'s suggestion [here](https://github.com/dotnet/machinelearning/pull/5125#discussion_r427002585))_\r\n\r\nRecent PR #5125 added a `readMultilines `option to `TextLoader `to enable the posibility of including newlines inside quoted fields.\r\n\r\nA problem with this is that if the input file isn\'t correctly formatted (i.e., if it has a quote that opens a quoted field, that is never closed) then the `Multilinereader `will actually load every line until it finds another quote. Depending on the dataset (and on how many incorrectly formatted rows it has) it could actually load into memory the whole dataset (or as much as the `StringBuilder `supports, which is [typically 2^32 chars ](https://docs.microsoft.com/en-us/dotnet/api/system.text.stringbuilder.maxcapacity?view=netcore-3.1#System_Text_StringBuilder_MaxCapacity))\r\n\r\nFor example:\r\n```\r\nid,description,animal\r\n0,""this quoted field isnt closed,cat\r\n1,this field doesnt include quotes,dog\r\n... // no quoted fields in here\r\n2555,""it is until this quoted field that the multilinereader actually stops reading row 0"",bird\r\n2556,""this row will be read correctly"",dog\r\n```\r\n\r\n@justinormont \'s suggestion here: https://github.com/dotnet/machinelearning/pull/5125#discussion_r427002585\r\n\r\nis to add another option to the `TextLoader `that let the user set the maximum length of a row, and if that threshold is passed, then simply ignore the line and continue reading the input file without loading everything into it.\r\n\r\nI think that before introducing more options to the `TextLoader`, it\'s better to see if users actually hit this problem when using `readMultilines`.'"
620810508,5142,b'Is it possible to avoid the runtimes folder in build output',"b'I have included the `Microsoft.ML` and `Microsoft.ML.TimeSeries` packages in an ASP.NET Core 3.1 project. Things are working great. I noticed that when including those packages in my project, I get a `runtimes` folder (almost 300 MB) in my build output. Setting `--self-contained false` as a parameter for my `deploy` command still include this folder. I have been reading about this folder being included when project includes code generating assemblies. Do one of these packages include such assemblies and is it possible to avoid having this `runtimes` folder as part of the build output?'"
619369371,5139,b'Legacy tests - partially disabled tests',"b'We have some tests that are partially disabled based on OS, arch or netcore version, resolve them or at least root cause them and let test running on all platform.\r\n\r\n\r\nTest | Category | Status | Owner\r\n-- | -- | -- | --\r\nMulticlassTreeFeaturizedLRTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nLinearClassifierTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nBinaryClassifierLogisticRegressionTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nBinaryClassifierSymSgdTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nBinaryClassifierTesterThresholdingTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nFastForestClassificationTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nFastTreeBinaryClassificationTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nFastTreeBinaryClassificationCategoricalSplitTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nFastTreeBinaryClassificationNoOpGroupIdTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nFastTreeHighMinDocsTest | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nCommandCrossValidationKeyLabelWithFloatKeyValues | [X64Fact(""x86   output differs from Baseline"")] | resolve | Mustafa\r\nTestTreeEnsembleCombiner | [X64Fact(""x86   fails. Associated GitHubIssue:   https://github.com/dotnet/machinelearning/issues/1216"")] | resolve | Frank\r\nTestTreeEnsembleCombinerWithCategoricalSplits | [X64Fact(""x86   fails. Associated GitHubIssue:   https://github.com/dotnet/machinelearning/issues/1216"")] | resolve | Frank\r\nTestEnsembleCombiner | [X64Fact(""x86   fails. Associated GitHubIssue:   https://github.com/dotnet/machinelearning/issues/1216"")] | resolve | Frank\r\nTestMulticlassEnsembleCombiner | [X64Fact(""x86   fails. Associated GitHubIssue:   https://github.com/dotnet/machinelearning/issues/1216"")] | TextLoader is   throwing exception: Unhandled exception at 0x15B296B3 (coreclr.dll) in   dotnet.exe.14324.dmp: 0xC0000005: Access violation writing location   0x17A41000.   resolve | Frank\r\nExprBind | [X64Fact(""sin(1e+30)   gives different value on x86.""), TestCategory(""Expr   Language"")] | Resolve   \xc2\xa0   Math.Sin has valid   value range from approximately -9223372036854775295 to approximately   9223372036854775295: https://docs.microsoft.com/en-us/dotnet/api/system.math.sin?view=netcore-3.1.   If value is out of range, Math.Sin will return value passed in and not   throwing exception.   \xc2\xa0   Below is some test   result:   \xc2\xa0   Math.Sin(1e+30):   \xc2\xa0   NetCoreApp X64:   0.0093314689311758247   NetCoreApp X86:   -0.75626273033357649   Net FX: 1e+30   \xc2\xa0   \xc2\xa0   Math.Sin(1e+10):   \xc2\xa0   NetCoreApp X64:   -0.48750602508751067   NetCoreApp X86:   -0.48750602507627   Net FX:\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0 -0.48750602507627   \xc2\xa0   \xc2\xa0   So this is   acceptable to skip in x86 and net framework, but we should consider to use   Math.Sin within its valid range. | Frank\r\nEntryPointPipelineEnsembleGetSummary | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nTestCrossValidationMacro | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nMulticlassLRTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nMulticlassLRNonNegativeTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nBinaryClassifierLogisticRegressionBinNormTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nDefaultCalibratorPerceptronTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nPAVCalibratorPerceptronTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nBinaryClassifierLDSvmTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nBinaryClassifierLDSvmNoBiasTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nCommandTrainMlrWithStats | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nKmeansOnnxConversionTest | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nSavePipeSsaSpikeNoData | [LessThanNetCore30OrNotNetCoreFact(""netcoreapp3.1   output differs from Baseline"")] | resolve | Frank\r\nEnsemblesMultiClassBootstrapSelectorTest | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nEnsemblesMultiAveragerTest | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nEnsemblesMultiVotingCombinerTest | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nEnsemblesMultiStackCombinerTest | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nChangePointDetectionWithSeasonality | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nChangePointDetectionWithSeasonalityPredictionEngineNoColumn | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nChangePointDetectionWithSeasonalityPredictionEngine | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nSsaForecast | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nSsaForecastPredictionEngine | [LessThanNetCore30OrNotNetCoreFact(""output   on .NetCore 3.0 differs. Tracked on issue 3856 in GitHub."")] | resolve | Frank\r\nBinaryClassifierLogisticRegressionNonNegativeTest | [LessThanNetCore30OrNotNetCoreAndX64Fact(""netcoreapp3.1   and x86 output differs from Baseline"")] | resolve | Frank\r\nBinaryClassifierLogisticRegressionGaussianNormTest | [LessThanNetCore30OrNotNetCoreAndX64Fact(""netcoreapp3.1   and x86 output differs from Baseline"")] | resolve | Frank\r\nRandomCalibratorPerceptronTest | [LessThanNetCore30OrNotNetCoreAndX64Fact(""netcoreapp3.1   and x86 output differs from Baseline"")] | resolve | Frank\r\nBinaryClassifierSymSgdTest | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   Root cause: Linux uses a version of   MKL that doesn\'t support conditional numerical reproducibility the same way   as Windows runs.   \xc2\xa0   The different   during different OS as well as unstable result for Linux is from MKL library   (method cblas_sdot). | Frank\r\nCommandTrainingBinaryFactorizationMachineWithValidation | RuntimeInformation.IsOSPlatform | Resolve   -    Lower   precision on Linux platforms   \xc2\xa0   This   test is skipped due to missing dataset, also   Linux   uses lower precision due to below issue:   https://github.com/dotnet/machinelearning/issues/404 | Frank\r\nCommandTrainingBinaryFactorizationMachineWithValidationAndInitialization | RuntimeInformation.IsOSPlatform | Resolve -    Lower precision on   Linux platforms   \xc2\xa0   Linux uses lower   precision due to below issue and PR:   https://github.com/dotnet/machinelearning/issues/404   https://github.com/dotnet/machinelearning/pull/1206 | Frank\r\nIrisLightGbm | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   resolve PR #5080 | Mustafa\r\nIrisLightGbmWithLoadColumnName | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   Resolve PR #5080 | Mustafa\r\nIrisVectorLightGbm | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   Resolve PR #5080 | Mustafa\r\nIrisVectorLightGbmWithLoadColumnName | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   Resolve PR #5080 | Mustafa\r\nIrisSdcaMaximumEntropy | RuntimeInformation.IsOSPlatform | Skipped on   Non-Windows platforms   Resolve PR #5080 | Mustafa\r\nTextNormalizingOnnxConversionTest | RuntimeInformation.IsOSPlatform | Skipped on Linux   platforms   \xc2\xa0   Skipped due to   below locale exception:   Failed to   construct locale with name:en_US.UTF-8:locale::facet::_S_create_c_locale name   not valid:Please, install necessary language-pack-XX and configure locales   \xc2\xa0   https://github.com/dotnet/machinelearning/issues/5093   \xc2\xa0   Mustafa will work   on a fix later | Mustafa\r\nTensorFlowTransformCifar | RuntimeInformation.IsOSPlatform | Resolved -    Different expected   results between Windows vs. Linux/OSX, runs only on 64-bit due to TF   \xc2\xa0   By Design, this   difference is explained below:   \xc2\xa0   //   taco_invalidpixelformat.jpg has \'8207\' pixel format on Windows but this   format translates to Format32bppRgb   \xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0 // on macOS and Linux, hence on   Windows this image\'s pixel format is converted in resize transformer to   Format32bppArgb   \xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0 // and on linux and macOS it is   not converted in resize transform since pixel format \'Format32bppRgb\' can be   resized but   \xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0 // in   ImagePixelExtractingTransformer it is converted to Format32bppArgb since   there we just support two    \xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0 // pixel formats, i.e   Format32bppArgb and Format16bppArgb. | Frank\r\nTensorFlowImageClassificationDefault | RuntimeInformation.IsOSPlatform | Resolved \xe2\x80\x93 already   runs on all OS\'s, runs only on 64-bit due to TF | Mustafa\r\nTensorFlowImageClassification | RuntimeInformation.IsOSPlatform | Resolved \xe2\x80\x93 already   runs on all OS\'s, runs only on 64-bit due to TF | Mustafa\r\nMatrixFactorizationSimpleTrainAndPredict | RuntimeInformation.IsOSPlatform | Lower precision on   Linux, skipped on OSX | Mustafa   Mustafa\r\nOneClassMatrixFactorizationInMemoryDataZeroBaseIndex | RuntimeInformation.IsOSPlatform | Resolved -    Lower precision on   non-Windows platforms   \xc2\xa0   There are   randomness during initialization in native matrix factorization   library(default_random_engine). This default_random_engine seems have   different implementation on different OS.   https://stackoverflow.com/questions/32730906/random-generates-same-number-in-linux-but-not-in-windows/32731387 | Frank\r\nMulticlassLRTest | Debug   Release Different Baseline | resolve | Mustafa\r\nRandomCalibratorPerceptronTest | Debug   Release Different Baseline | resolve | Mustafa\r\nLinearClassifierTest | Debug   Release Different Baseline | resolve | Mustafa\r\nMulticlassTreeFeaturizedLRTest | Debug   Release Different Baseline | resolve | Mustafa\r\nFastForestClassificationTest | Debug   Release Different Baseline | resolve | Mustafa\r\nBinaryClassifierLogisticRegressionNormTest | Debug   Release Different Baseline | resolve | Mustafa\r\n\r\n\r\n'"
618701984,5132,b'Method to check if a modelName already exists in the PredictionEnginePool',"b""This is related to an issue I brought up in Stack Overflow - https://stackoverflow.com/questions/61695078/ml-net-how-to-detect-a-model-is-missing-from-the-predictionenginepool/61773814#61773814\r\n\r\nIn the Web API, I need someway to PredictionEnginePool.GetModel by model name. I'd like to also do AddPredictionEnginePool outside of the Startup.cs. In my service layer, I check if a model doesnt exists then I will add it on the fly coz the new model had just been created post startup.\r\n\r\nThanks you very much in advance"""
618498354,5129,b'Improve error messaging for non-parsable datasets',"b'I\'d recommend improving the current error message:\r\nhttps://github.com/dotnet/machinelearning/blob/e5a19af589dfb1468cd99628e82f6b49fb125323/src/Microsoft.ML.AutoML/ColumnInference/ColumnInferenceApi.cs#L120-L123\r\n\r\nIt currently says, `""Unable to split the file provided into multiple, consistent columns.""`, which is rather uninformative and non-actionable.\r\n\r\nPerhaps, as I think @briacht is suggesting, have it list the acceptable file formats we can parse: `""Unable to split the file provided into multiple, consistent columns. Readable formats include delimited files such as CSV/TSV. Check for a consistent number of columns and proper escaping and quoting.""`.\r\n\r\nThis messaging now includes, the problem, and next steps for the user.\r\n\r\nI mention delimited as AutoML supports more than CSV/TSV as it tries tab, comma, space, semi-colon as the separator ([src](https://github.com/dotnet/machinelearning/blob/e50c4d20012e0d62852f404ae443afca7dad043e/src/Microsoft.ML.AutoML/ColumnInference/TextFileContents.cs#L40)). If we run into other common separators, we can trivially augment this list. One candidate is the vertical bar `|`.'"
616188351,5116,b'FileNotFound error when saving the model.zip file on AML',"b""### System information\r\n\r\n- **OS version/distro**: Not sure, running on AML Compute.\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have an AML pipeline where I use ML.NET to train a LightGBM model and save results on a blob storage. This pipeline reads data from ADLS.\r\n- **What happened?**\r\nThe training stage failed with an exception that suggests an I/O error (file not found).\r\n- **What did you expect?**\r\nThis same pipeline have worked in the recent past. This is the first time I'm seeing this error.\r\n\r\n### Source code / logs\r\n\r\nLogs from the training stage:\r\n_[1] 'Loading data for LightGBM' finished in 00:27:01.1484891.\r\n[2] 'Training with LightGBM' started.\r\n.***** Unexpected failure. Please refer to https://aka.ms/MLNetIssue to file an issue with details *****\r\n***** Error log has been saved to '/tmp/TLC/Error_20200511_192219_facb0cb4-1e59-4354-b1c2-870a44ba1ca4.log', please refer to https://aka.ms/MLNetIssue to file an issue with details *****\r\n===== Begin detailed dump =====\r\n(1) Unexpected exception: Could not find file '/mnt/batch/tasks/shared/LS_root/jobs/devexperimentation/azureml/bdaad31a-ef2f-47cd-b99b-85119e487d7c/mounts/workspaceblobstore/azureml/bdaad31a-ef2f-47cd-b99b-85119e487d7c/ModelOutput/model.zip'., 'System.IO.FileNotFoundException'\r\n   at Interop.ThrowExceptionForIoErrno(ErrorInfo errorInfo, String path, Boolean isDirectory, Func`2 errorRewriter)\r\n   at Microsoft.Win32.SafeHandles.SafeFileHandle.Open(String path, OpenFlags flags, Int32 mode)\r\n   at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n   at Microsoft.ML.Data.SimpleFileHandle.OpenReadStream() in /machinelearning/src/Microsoft.ML.Core/Data/IFileHandle.cs:line 193\r\n   at Microsoft.ML.Tools.SavePredictorCommand.Run() in /machinelearning/src/Microsoft.ML.Data/Commands/SavePredictorCommand.cs:line 82\r\n   at Microsoft.ML.Tools.Maml.MainCore(IHostEnvironment env, String args, Boolean alwaysPrintStacktrace) in /machinelearning/src/Microsoft.ML.Maml/MAML.cs:line 142\r\n====== End detailed dump =====_\r\n\r\n"""
616105156,5115,b'Survey: repo contribution experience',"b'We\xe2\x80\x99ve been working as a team, and community, for five years in the dotnet org on the .NET Core project. Many of the same GitHub handles have remained constant over that time, some are new, and others have come and gone. Thanks to everyone that has contributed! We normally focus on how to improve the product, but we\xe2\x80\x99re turning our focus to improving the open source project. We\xe2\x80\x99ve created a survey to better understand your individual experience of participating and contributing in this project.\r\n\r\nWe would appreciate your feedback so we can work to address shortcomings and missed opportunities. If you don\xe2\x80\x99t supply contact details, then responses will be anonymous.\r\n\r\n[Survey](https://www.surveymonkey.com/r/ZLPVNX9?SourceRepo=dotnet%2Fmachinelearning)\r\n\r\nThank you for your time!\r\n\r\n### Discussion\r\n\r\nFor discussion, please go to https://github.com/dotnet/runtime/issues/36235.'"
615403389,5113,b'Evaluating model that loads images from disk throws an exception in ASP.NET core',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: ASP.NET Core 3.1\r\n\r\n### Issue\r\n\r\nI\'m running ASP.NET Core 3.1. Training the model works fine. PredictionEnginePool predicts fine. However if I try to get the metrics of the trained model I\'m getting the below exception. Is it that ASP.NET Core doesn\'t support System.Drawing.Bitmap? If so, is there any alternative option to evaluate a model in ASP.NET Core?\r\n\r\n### Source code / logs\r\n\r\n     var trainingData = _mlContext.Data.LoadFromEnumerable(imageDataTags);\r\n     var model = pipeline.Fit(trainingData);\r\n     var testingData = _mlContext.Data.LoadFromEnumerable(testImageDataTags);\r\n     var predictions = model.Transform(testingData);\r\n     var metrics = _mlContext.MulticlassClassification.Evaluate(predictions,""LabelKey"");\r\n\r\n```System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.ArgumentException: Parameter is not valid.\r\n   at System.Drawing.Bitmap..ctor(String filename, Boolean useIcm)\r\n   at System.Drawing.Bitmap..ctor(String filename)\r\n   at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__0(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass18_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.MulticlassClassificationEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.MulticlassClassificationCatalog.Evaluate(IDataView data, String labelColumnName, String scoreColumnName, String predictedLabelColumnName, Int32 topKPredictionCount)\r\n   at PDCSBE.Services.Implementation.PredictionService.TrainModel() in D:\\...\\Services\\Implementation\\PredictionService.cs:line 91\r\n   at PDCSBE.Api.Controllers.PredictController.TrainModel(ModelTrainerDataInputDto input) in D:\\...\\Controllers\\PredictController.cs:line 26\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at Microsoft.Extensions.Internal.ObjectMethodExecutor.Execute(Object target, Object[] parameters)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Routing.EndpointRoutingMiddleware.<Invoke>g__AwaitMatcher|8_0(EndpointRoutingMiddleware middleware, HttpContext httpContext, Task`1 matcherTask)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)\r\n\r\nHEADERS\r\n=======\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate, br\r\nCache-Control: no-cache\r\nConnection: keep-alive\r\nContent-Length: 214\r\nContent-Type: application/json\r\nHost: localhost:44370\r\nUser-Agent: PostmanRuntime/7.24.1\r\nPostman-Token: ced1eca6-9e0b-4292-9887-f46a6d1c57d5\r\n```'"
615394321,5112,b'Training ImageClassification in parallel throws when trying to use the same WorkspacePath',"b""Using ImageClassification (ImageClassificationTrainer) on the machine as a job.\r\nThe job is implemented as a Azure Function, which is triggered by message in the storage queue. Every time the job receive a message the training process is calculated. The training runs for different data sets. That means, the function can observe multiple requests \r\n\r\nUnfortunately, when two training are running simultaneously on the same machine, we get following error:\r\n```\r\n\r\n2020-05-10T13:27:27  PID[11748] Information  ---> System.IO.IOException: Could not open file 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\LocalAppData\\cache\\bottleneck_train_cache.cac'. Error is: The process cannot access the file 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\LocalAppData\\cache\\bottleneck_train_cache.cac' because it is being used by another process.\r\n2020-05-10T13:27:27  PID[11748] Information  ---> System.IO.IOException: The process cannot access the file '***\\LocalAppData\\cache\\bottleneck_train_cache.cac' because it is being used by another process.\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n2020-05-10T13:27:27  PID[11748] Information    at Microsoft.ML.Internal.Utilities.StreamUtils.OpenInStream(String fileName)\r\n2020-05-10T13:27:27  PID[11748] Information    at Microsoft.ML.Data.MultiFileSource.Open(Int32 index)\r\n2020-05-10T13:27:27  PID[11748] Information    --- End of inner exception stack trace ---\r\n```\r\n\r\nBy following the error shown above, it looks as trainer uses internal a local file(s), which should not be touched by multiple threads.\r\nI guess, this can be solved by providing a different 'WorkspacePath' for every request? In any case, such internal details, should be transparent for developers. Moreover, ML algorithms, at least in the .NET ecosystem should not internal create any kind of singleton inside of process and also machine.\r\nThis is very untypical for .NET. \r\n\r\nIn my opinion this is a not best design and it should should be fixed. """
615265479,5111,b'Issue with image classification trainer creating files (such as TrainingSetSize.txt) on WebJobs',"b'Running the ML.NET image classification inside of WebJob (windows platform/.NET Core 3.1)\r\nAll works fine when executed locally. Unfortunately, when running as job it fails with the following error: \r\n\r\n> 2020-05-09T19:30:04  PID[9552] Information       The building model process has failed.\r\n> 2020-05-09T19:30:04  PID[9552] Information System.IO.FileNotFoundException: Could not find file \'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\cache\\TrainingSetSize.txt\'.\r\n> 2020-05-09T19:30:04  PID[9552] Information File name: \'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\cache\\TrainingSetSize.txt\'\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.StreamReader.ValidateArgsAndOpenPath(String path, Encoding encoding, Int32 bufferSize)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.StreamReader..ctor(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.File.OpenText(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.GetNumSamples(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.TrainAndEvaluateClassificationLayer(String trainBottleneckFilePath, Options options, String validationSetBottleneckFilePath, Int32 trainingsetSize)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.MulticlassClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numberOfFolds, String labelColumnName, String samplingKeyColumnName, Nullable`1 seed)\r\n\r\nCreating of the text file seems not to be correctly implemented. If the path is not set to the permitted location, the required text file will not be created. In that case another error message should be created. \r\nFor example, following path is in WebJob (hosted in IIS) not allowed:\r\n\r\n`C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob`\r\n\r\nIt corresponds to %AppData% of the local machine. It is the working folder of IIS in context of an Azure Job. By changing the path to following one, all will work fine:\r\n\r\n`C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\Local`\r\n \r\nIn the code, this can be achieved by following:\r\n~~~\r\nWorkspacePath = Environment.GetFolderPath(Environment.SpecialFolder.LocalApplicationData),\r\n~~~\r\n\r\n### Recap\r\nTrainer creates internally many files. One of them is *TrainingSetSize.txt*. If the *options.WorkspacePath* is set to location on which the process has no write permission, the correct exception should be thrown. \r\n\r\nThis might also be a security issue is one chose path like ""WorkspacePath = ""..\\..\\xy"". That would lead the job process to touch the path, which possibly belongs to the job owned by some other customer. At the moment of writing of this, I didn\'t see security issue here, but who know what might happen in the future.'"
614974792,5109,b'Training / Predicting from in-memory Bitmap',"b'Hi,\r\n\r\nJust started playing with Microsoft.ML and am pretty impressed. I followed [this tutorial](https://devblogs.microsoft.com/dotnet/train-image-classification-model-azure-mlnet-model-builder/) to build an image classifier model that works reasonably well (limited training data). I now want to put this model to use but have hit an issue:\r\n\r\nThe images I want to classify will be in-memory (as a Bitmap) but the trained model seems to need the images on disk. Obviously I could save the image to a temporary file but this seems wasteful when the model will need to read it back in again. From what I can see in the source code, the ""LoadRawImageBytes"" transform from the [Model Builder generated] pipeline shown below doesn\'t have any kind of overload for loading in-memory data:\r\n\r\n```c#\r\nvar pipeline = context.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n    .Append(context.Transforms.LoadRawImageBytes(""ImageSource_featurized"", null, ""Image""))\r\n    .Append(context.Transforms.CopyColumns(""Features"", ""ImageSource_featurized""));\r\n```\r\n\r\nAfter a lot of searching I found [this issue](https://github.com/dotnet/machinelearning/issues/4944) in which @huy-lv asks how to do pretty much exactly what I want to do. @Lynx1820 replied pointing to [this sample](https://github.com/dotnet/machinelearning-samples/tree/e43e429cce06f246a38053e01f1a8e9392f2d36f/samples/csharp/end-to-end-apps/DeepLearning_ImageClassification_TensorFlow) which I have endeavoured to follow.\r\n\r\nI now have the following pipeline:\r\n\r\n```c#\r\nvar pipeline = context.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n    .Append(context.Transforms.ResizeImages(outputColumnName: ""ScaledImage"", imageWidth: 227, imageHeight: 227, inputColumnName: ""Image""))\r\n    .Append(context.Transforms.ExtractPixels(outputColumnName: ""ImageSource_featurized"", inputColumnName: ""ScaledImage"", outputAsFloatArray: false))\r\n    .Append(context.Transforms.CopyColumns(""Features"", ""ImageSource_featurized""));\r\n\r\nvar trainer = context.MulticlassClassification.Trainers.ImageClassification(new ImageClassificationTrainer.Options() { LabelColumnName = ""Label"", FeatureColumnName = ""Features"" })\r\n    .Append(context.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n\r\nvar trainingPipeline = pipeline.Append(trainer);\r\n```\r\n\r\nBut when I try to train the model (with `trainingPipeline.Fit(trainingData)`) I receive the error:\r\n\r\n`Schema mismatch for feature column \'Features\': expected VarVector<Byte>, got Vector<Byte> \'`\r\n\r\nCould you provide an example of how to use `Transforms.ExtractPixels` with `MulticlassClassification.Trainers.ImageClassification` or suggestions on how to train/predict from an in-memory `Bitmap` source?\r\n\r\nThanks!'"
614199695,5105,b'Regression with image',"b""How to concatenate image with some Single values? I was trying to convert image to `ExtractPixels` and `LoadRawImageBytes` but I can't find any way to concatenate this with single values. """
613641823,5101,b'Negative scores evalauate for LightGBMMulti model',"b'I have a multi class classification model trained to classify to 3 values (-1,0,1) looking at 26 feature columns which are RGB color values as float.\r\nwhen predicting, score values returned are sometimes negative. From my basic understanding, the score values are confidence on each class and they should add up to 1 and each value should be between 0 and 1.\r\n\r\nModel was created using AutoML.\r\nMulticlassExperimentSettings settings = new MulticlassExperimentSettings\r\n{\r\n    MaxExperimentTimeInSeconds = (uint)(trainer.TrainingDuration * 60),\r\n    CacheDirectory = new DirectoryInfo(ModelCache),\r\n    OptimizingMetric = MulticlassClassificationMetric.MicroAccuracy\r\n};\r\n\r\nvar experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(settings);\r\nvar progress = new Progress<RunDetail<MulticlassClassificationMetrics>>(p =>{});\r\nvar result = experiment.Execute(trainSet, testSet, labelColumnName: ""Classification"", progressHandler: progress);\r\n\r\n\r\n![vs](https://user-images.githubusercontent.com/31455766/81232882-eceb0f80-8fb2-11ea-9686-acba9c57b898.jpg)\r\n'"
613253035,5096,b'Add new models in prediction pool during runtime',"b""I have two separate .NET Core Web API projects deployed to Kubernetes as separate Docker containers. One for training and the other for predictions. The users can upload a training file into the training API to create a new model and the filename and path of the model.zip file are saved into a table in SQL Server DB and the model.zip file is saved in PersistentVolume. \r\n\r\nIn the prediction service, I create the PredictionEnginePool in ConfigureServices in Startup.cs. \r\n\r\nHow can I lookup a model by name to check if my models have been loaded into the pool and if not, how can I dynamically add the newly trained models that had just been created by the separate training API without having to restart the prediction API ? Is there any way I can do this outside of the Startup.cs e.g. in the controller so that I can take control of the pool at runtime?\r\n\r\nCan you provide sample codes that dynamically read .zip files from a folder, check if they're already in the pool and if not then add it into the prediction pool, all done inside a controller?"""
612858082,5093,b'Ubuntu ML .NET Docker Image has no configured locales',"b'The Ubuntu ML .NET Docker image does not have configured locals, which is resulting in the following error statement:\r\n\r\n>    System.InvalidOperationException : Error initializing model :Microsoft.ML.OnnxRuntime.OnnxRuntimeException: [ErrorCode:RuntimeException] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/nn/string_normalizer.cc:87 onnxruntime::string_normalizer::Locale::Locale(const string&) Failed to construct locale with name:en_US.UTF-8:locale::facet::_S_create_c_locale name not valid:Please, install necessary language-pack-XX and configure locales\r\n\r\nThis error is the reason why `TextNormalizingOnnxConversionTest()` is currently disabled on Linux at line 462:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c83ea54a0874fbeac0d16cb5f31e3cd97f8d97ed/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L440-L473\r\n\r\nThe ONNX Runtime team encountered a similar issue with their docker images and fixed it with [onnxruntime PR#19](https://github.com/onnx/backend-scoreboard/pull/19), where `locales` was installed with `apt-get` and the `en_US.UTF-8` locale was configured.\r\n\r\n**TODO**: Edit the Dockerfile (which is not in this repo) for our Ubuntu builds and add the following:\r\n```\r\nRUN apt-get update && apt-get install -y locales\r\nRUN locale-gen en_US.UTF-8 && update-locale LANG=en_US.UTF-8\r\n```'"
611812327,5089,b'The future of ML.NET',"b""Back in 3/26/2020 I was surveyed by members of the ML.NET team, who were gathering feedback about uses of ML.NET. \r\nI'm wondering broadly what the future of ML.NET will look like? Will you continue to invest in making it a stand alone product for machine learning, extending the breath and depth of the library? Or perhaps it'll end up being more of a hosting environment for models and statistical studies built in other languages like python/R ?\r\nI personally would love to have ML.NET eventually be a one stop shop, with everything I need. But I wonder what the team is thinking? \r\nThanks! """
611758370,5088,b'Update ML.NET trained Model in ASP.NET Core without restarting the app',"b'### System information\r\nWindows 10\r\n- **OS version/distro**: Education\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\nUnable to update a ML.NET trained model in ASP.NET Core without restarting the web app\r\n- **What did you do?**\r\n\r\nLike the title says, I\'m trying to retrain an existing ML.NET model in an ASP.NET Core web app. The setup: I have an existing model.zip file on the local disk. In Startup.cs I\'m injecting the prediction engine pool service\r\n\r\n`services.AddPredictionEnginePool<ImageData, ImagePrediction>().FromFile(\r\n        ""ImageClassificationModel"", _modelPath, true);`\r\n\r\nby loading the existing model from the disk. The _modelPath variable indicates the path to the zip file, and the true parameter indicates that the Prediction Engine Pool should watch the model for changes. According to https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/serve-model-web-api-ml-net,\r\n\r\n> The PredictionEnginePool service provides a mechanism to reload an updated model without taking your application down.\r\n\r\nI\'ve also created a service that takes the path to some image folders and trains a new model, then saves it to the same location _modelPath indicates. That service is exposed through an API Endpoint.\r\n\r\n- **What happened?**\r\n\r\nThe problem: When accessing the train endpoint, the app works fine. It retrains the model and saves it to the indicated path. I can do this several times. However, if I use the model to predict an image\'s label, I\'m no longer able to retrain the model. If I try to call the train endpoint again, I\'m getting an error that says the model file is already in use.\r\n\r\n> System.IO.IOException: \'The process cannot access the file \'\\MLModel\\model.zip\' because it is being used by another process.\'\r\n\r\nThe only way to update the model so far would be to completely restart the web app and call the train endpoint first thing.\r\n\r\n- **What did you expect?**\r\n\r\nThe expected result would be able to retrain the model without restarting the web app.\r\n\r\n'"
611555591,5086,b'Auto.ML.0.16.0 and System.Memory 4.0.1.0',"b""Moving issue raised by @ericdransfeldt in Docs repo since it's a product question.\r\n\r\nHi,\r\n\r\nI love the Microsoft.ML and AutoML platforms but am having an issue when I upgraded my AutoML version via NuGet. When I upgraded from Microsoft.ML.AutoML from version 0.15.0 to 0.16.0 I started getting an error when I ran my code. Nothing changed in my source code except to recompile. It seems like it can't find System.Memory 4.0.1.0.\r\n\r\nCould not load file or assembly 'System.Memory, Version=4.0.1.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51' or one of its dependencies. The system cannot find the file specified., Stack: at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(String name, Type rawType, IEnumerable1 attributes, Boolean& isVector, Type& itemType) at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(MemberInfo memberInfo, Boolean& isVector, Type& itemType) at Microsoft.ML.Data.SchemaDefinition.Create(Type userType, Direction direction) at Microsoft.ML.Data.DataViewConstructionUtils.CreateFromEnumerable[TRow](IHostEnvironment env, IEnumerable1 data, SchemaDefinition schemaDefinition)\r\n\r\nI went back to the older version and it worked fine. No dependency issues.. Any ideas..?\r\n\r\nThanks for any help or ideas!\r\n\r\nCheers,\r\nEric"""
611227166,5083,b'Docker issue with TensorFlow inception_v3.meta model',"b'### System information\r\n\r\n- Windows 10, Docker desktop Linux. v. 19.03.8, build afacb8b\r\n- .NET Core Version 3.1\r\n- ML.NET 1.4.0\r\n\r\n### Issue\r\nWhen working with image classification and TensorFlow model, the TensorFlowUtils tries to download the inception file.\r\nFirst of all the dockerfile already copies the inception file to the /tmp/MLNET location. As you can see on the picture the file is in there. It is trying to download it if the file already exists?\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/80869999-ed7a6200-8ca3-11ea-8904-0b49822331e1.png)\r\n\r\nHow to prevent downloading of the inception file?\r\n\r\nThanks\r\nDamir'"
610195701,5073,b'Run Evaluation on full test dataset',"b'Hello, I would like to know how do I run the evaluation on the full test dataset instead of doing it in a single line.\r\n\r\nI noticed that in `Program.cs` we are only running the prediction for one single line:\r\n\r\n```\r\n// Here (ModelInput object) you could provide new test data, hardcoded or from the end-user application, instead of the row from the file.\r\n            ModelInput sampleForPrediction = mlContext.Data.CreateEnumerable<ModelInput>(dataView, false)\r\n                                                                        .First();\r\n```\r\n\r\nIs there any other option to run on the full test set? \r\n\r\nKind regards'"
608918711,5070,b'Test dataset using the command line',"b'Hello, I am using MLNET using the CLI and I have a doubt regarding the test dataset. \r\n\r\n`mlnet auto-train --task multiclass-classification --dataset ""xxxx.tsv"" --ignore-columns ""Id,Task,CreatedOn"" --test-dataset ""xxx.tsv"" --max-exploration-time 600 --label-column-name Type`\r\n\r\nThe training results look very optimistic and I was wondering if it is not tuning on the test dataset which would not be ideal. Is the test dataset being used only for ""inference"" after the training is complete? Do I need to pass an evaluation dataset also so the fine-tuning will be made on that or is none is given it is doing Cross Validation?\r\n\r\nKind regards\r\n'"
608794323,5069,b'Microsoft.ML with onnx can not get Column',"b'### System information\r\n\r\n- **OS version/distro**: win10 1909\r\n- **.NET Version (eg., dotnet --info)**: Core 3.1\r\n\r\n### Issue\r\n\r\nAn exception occurred while getting the inference result \r\nException:\r\nSystem.ArgumentOutOfRangeException: \'Cannot map column (name: loss, type: Microsoft.ML.Transforms.Onnx.OnnxSequenceType) in data to the user-defined type, ConsoleApp1.OutPut. (Parameter \'column\')\'\r\n\r\n### Source code / logs\r\nPackage \r\n    Microsoft.ML1.5.0-preview2\r\n    Microsoft.ML.ImageAnalytics1.5.0-preview2\r\n    Microsoft.ML.OnnxRuntime1.2.0\r\n    Microsoft.ML.OnnxTransformer1.5.0-preview2\r\n\r\nCode \r\n    Console.WriteLine(""Hello World!"");\r\n            MLContext mlContext = new MLContext();\r\n            var data = mlContext.Data.LoadFromEnumerable(new List<ApiInput>());\r\n            var PIL = mlContext.Transforms.LoadImages(outputColumnName: ""data"",\r\n                imageFolder: null,\r\n                inputColumnName: ""ImagePath"")\r\n                .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""data"", imageWidth: 224, imageHeight: 224, inputColumnName: ""data""))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""data""))\r\n                .Append(mlContext.Transforms.ApplyOnnxModel(outputColumnName: ""loss"", inputColumnName:  ""data"" , modelFile: ""model.onnx""));\r\n            var model = PIL.Fit(data);\r\n            var ss = new List<ApiInput>\r\n            {\r\n                new ApiInput() { ImagePath = ""C:\\\\1.png"" }\r\n            };\r\n            var data1 = mlContext.Data.LoadFromEnumerable(ss);\r\n            var reml = model.Transform(data1);\r\n            var re = reml.GetColumn<OutPut>(""loss"");\r\n\r\n public class ApiInput\r\n    {\r\n        public string ImagePath { get; set; }\r\n    }\r\n\r\n  public class OutPut\r\n    {\r\n        [OnnxSequenceType(typeof(string))]\r\n        public string n;\r\n        [OnnxSequenceType(typeof(float))]\r\n        public float n1;\r\n\r\n    }\r\nThe input and output of the model is shown below\r\n![_(($TF0ZVX43WZD)O4E~WHX](https://user-images.githubusercontent.com/62022463/80564103-77fe5f80-8a1f-11ea-9c61-8d2e3ae1ec55.png)\r\n\r\nThere are two kinds of output in this model. I can get the result in classLabel normally, but for loss I have not found any method that can get it correctly  \r\n\r\n\r\n'"
608636254,5067,b'Update NumberOfThreads default value for MatrixFactorization trainer ',"b'The default value for MatrixFactorization will use all threads, which might trigger a warning in [libmf](https://github.com/cjlin1/libmf/blob/e70b9a32f7df32cce961bbbb997da074759a16fe/mf.cpp#L4024) when it exceeds two times of nr_bins.\r\n\r\n\r\n\r\n'"
608507166,5065,b'deterministic result in ML.net | KmeansTrainer vs EstimatorChain<ClusteringPredictionTransformer<Microsoft.ML.Trainers.KMeansModelParameters>>',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nPerform a clustering on some datas using ML.net and clustering based on the iris sample on docs.microsoft.com\r\n- **What happened?**\r\nWe have noticed that the result are not deterministic for a specified feature vector when a non vector property of the class value changes.\r\n\r\n- **What did you expect?**\r\nWe expected the ml.net clustering algorithm to issue always the same result in the same conditions if the feature array remains the same even if another property of the data class is modified.\r\n\r\n### Source code / logs\r\n\r\nstring featuresColumnName = _featureColumnName;\r\n            var pipeline = _mlContext.Transforms\r\n                .Concatenate(featuresColumnName, featureArrayLabel)\r\n                .Append(_mlContext.Clustering.Trainers.KMeans(featuresColumnName, numberOfClusters: _cluster));\r\n           pipeline;\r\nwhen pipeline is EstimatorChain<ClusteringPredictionTransformer<Microsoft.ML.Trainers.KMeansModelParameters>> \r\nthe fit method is not derministic\r\n'"
606526503,5062,b'Can i use ML.NET do train a face recognition model',"b'Hi\r\n\r\nIm new to ML, so this might seem like a stupid question, but, id like to use C# to train a face recognition model.\r\n\r\nThe face detection part would be done by Dlib which will extract the face encodings  (double[128])\r\n\r\nSo the question would be can i use ML.NET to train a model that gets face vectors for input\r\nInput would be:\r\nLabel: string \r\nFeature: double array\r\n\r\nAnd trains a model that when an image comes in and i extract the face encodings from it, it could predict which person it is. (I have about 2000 person with 2-3 images per person (2-3 encodings))\r\n\r\nIs it possible and what algorithms are suitable for this task ?\r\n\r\nThanks for a answer\r\nMati'"
606114582,5061,b'Converting Naive Bayes Scores to Probabilities',"b'Hello,\r\nWhat are the scores produced from the NaiveBayes classifier, are they log probabilities? As I seem to get very large minus values. Whereas I did something similar in sci-kit learns NaiveBayes and the log probabilities were much lower negative values. How do you suggest converting these scores to probabilities? Should I call an exponential function on them if they are in fact log probabilities?\r\n\r\nThanks\r\n'"
605892251,5055,b'Investigate thresholding binary log-loss',"b'Multi-class log-loss has an `epsilon` value which thresholds the input probability between `epsilon` and `1.0`. This causes multi-class log-loss to never be `Infinity`.\r\n\r\nThe binary log-loss does not have an `epsilon` threshold, which causes the returned log-loss to be `Infinity` when the prediction is perfectly confident (p=0.0 or p=1.0) and incorrect about the true label.\r\n\r\nLog-loss for binary classification:\r\nhttps://github.com/dotnet/machinelearning/blob/062be280a9d6de23838d4db5ad93fea9d7d0c1f6/src/Microsoft.ML.Data/Evaluators/BinaryClassifierEvaluator.cs#L663-L677\r\n\r\nLog-loss for multi-class:\r\nhttps://github.com/dotnet/machinelearning/blob/062be280a9d6de23838d4db5ad93fea9d7d0c1f6/src/Microsoft.ML.Data/Evaluators/MulticlassClassificationEvaluator.cs#L450-L458\r\n\r\nAs part of thinking through the right behavior, we should investigate the behavior of other ML packages like scikit-learn/TensorFlow/PyTorch.'"
605646052,5054,b'Can speech recognition be done in ML.NET?',"b'### System information\r\n\r\n- **OS version/distro**:Windows\r\n- **.NET Version (eg., dotnet --info)**: 3.1.201\r\n\r\n### Issue\r\nhi \r\ni want to Speech recognition in ml .net i see issue list in #2732 is same but i want know now i can do it or not ??'"
605620858,5053,b'Support entire timeseries anomaly detection for SrCnn model',"b""### New estimator for SrCnn Algorithm to support entire anomaly detection\r\nBy creating a SrCnnAnomalyEstimator, user could do anomaly detection using SrCnn algorithm, this estimator is implemented in streaming way, for each arrived point, it will use a window of cached previous points to do calculation. But if the entire timeseries is alreay known, it would be more time efficient to do anomaly detection in entire way instead of streaming way. SrCnnEntireAnomalyDetector is implemented to provide this entire timeseries anomaly detection.\r\n\r\nBesides, by old SrCnnAnomalyEstimator, user could only get whether the point is an anomaly or not, but has no way to set sensitivity value for the anomaly. Sometimes an anomaly do happens, but with a low sensitivity setting, it may not be a valid alert. The SrCnnEntireAnomalyDetector will allow user to set sensitivity, and output margin for the point according to the sensitivity, so that when you get an anomaly point, you could judge if it's a valid alert by comparing the value with upper boundary and lower boundary.\r\n\r\nThe SrCnnEntireAnomalyDetector provides 3 modes, and output varies depending on selected mode:\r\n\r\n* **AnomalyOnly.** Only do anomaly detection. Output 3-element Double vector of (IsAnomaly, RawScore, Mag)\r\n* **AnomalyAndExpectedValue.** Besides anomaly detection, calculate expected value for each point. Output 4-element Double vector of (IsAnomaly, RawScore, Mag, ExpectedValue)\r\n* **AnomalyAndMargin.** Besides anomaly detection and expected value calculation, also estimate boundaries under given sensitivity. Output a 7-element Double vector of (IsAnomaly, AnomalyScore, Mag, ExpectedValue, BoundaryUnit, UpperBoundary, LowerBoundary).\r\n\r\n### Benchmark report\r\n#### 1. Dataset\r\nWe evaluate on the Yahoo timeseries dataset, which has 367 timeseries and 572966 points in total.\r\n#### 2. Evaluation method and score\r\n\r\nWe calculate the Precision, Recall, and F1 score using the method of\xef\xbc\x9a [https://github.com/iopsai/iops/tree/master/evaluation](https://github.com/iopsai/iops/tree/master/evaluation).\r\n\r\nThe anomaly detection part is the same for 3 modes, so the scores are the same among each mode.\r\nPrecision | Recall | F1 | #TruePositive | #Positives | #Anomalies | Fine tuned   parameters\r\n-- | -- | -- | -- | -- | -- | --\r\n0.816 | 0.669 | 0.735 | 2619 | 3208 | 3915 | Threshold=0.35, BatchSize=512\r\n\r\n#### 3. Latency:\r\nAnd we ran the three modes on a machine with Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz, 16GB memory, x64 operating system.\r\n\r\nWe divided the input series into different sizes of buckets to get the estimation of latency under different point counts and different modes, the unit is ms.\r\n\r\n#Point Count | AnomalyOnly(ms) | AnomalyAndExpectedValue(ms) | AnomalyAndMargin(ms)\r\n-- | -- | -- | --\r\n128 | 0.0266 | 0.0357 | 0.0753\r\n256 | 0.2057 | 0.8722 | 1.0368\r\n512 | 1.0607 | 1.0700 | 1.3943\r\n1024 | 2.0589 | 2.0937 | 3.2415\r\n2048 | 3.8632 | 4.3912 | 8.0051\r\n4096 | 7.8000 | 9.0978 | 16.6674\r\n8129 | 16.5667 | 19.2133 | 35.2733"""
604976647,5052,"b""ImageClassificationTrainer can't load model""","b'### System information\r\n\r\n- Windows 10 Pro\r\n- .NET 4.8 and .NET Core 3.1: \r\n- Memory 12GB\r\n- Processor Intel Core i7 CPU 950 @ 3.07GHz\r\n\r\n### Issue\r\n\r\n- Tried to train an image classification using the Model Builder.\r\n\r\nSteps: Create a project.\r\nAdd a Machine Learning through solution explorer, then in the ML.NET Model Builder:\r\n\r\n1. Scenario -> Image Classification\r\n2. Data -> A folder with around 8.000 images (.png) separated in 8 folders/categories.\r\n3. Train -> Start Training\r\n\r\nIt will result in a popup (image attached) saying ""Model Builder Error"".\r\n![Model Builder Error](https://user-images.githubusercontent.com/16278387/76725716-d1d7ee00-672d-11ea-8589-7ed8b803321e.png)\r\n\r\n```\r\n> Output/log from Machine Learning output:\r\n> |     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003974.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0004556.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003859.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003999.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003329.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003310.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003954.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0004090.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003738.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0004048.\r\n> [Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n> [Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=RawByteImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: N\xc3\xa3o \xc3\xa9 poss\xc3\xadvel carregar a DLL \'tensorflow\': Uma rotina de inicializa\xc3\xa7\xc3\xa3o da biblioteca de v\xc3\xadnculo din\xc3\xa2mico (DLL) falhou. (Exce\xc3\xa7\xc3\xa3o de HRESULT: 0x8007045A)\r\n>    em Tensorflow.c_api.TF_NewGraph()\r\n>    em Tensorflow.Graph..ctor()\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    --- Fim do rastreamento de pilha de exce\xc3\xa7\xc3\xb5es internas ---\r\n>    em Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n>    em Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n>    em Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n>    em Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n> [Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n> Tensorflow exception triggered while loading model.\r\n> \r\n> \r\n```'"
604976498,5051,b'[AutoML] Auto detection of extra header rows mixed into the dataset',"b'I have dataset in text file with 20 columns, 1st column is the class name (string), other columns are features (floats)\r\n\r\nHere are first lines of this file\r\n```\r\nClass\tA1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\tA14\tA15\tA16\tA17\tA18\tA19\r\nCS\t61.00000\t0.16855\t0.00000\t1.77778\t3.00000\t0.25375\t0.07984\t0.00169\t0.02250\t0.01535\t0.07984\t0.01027\t0.27415\t6.00000\t4.00000\t0.37649\t3552.00000\t0\t26.00000\r\nCS\t316.00000\t0.14823\t15.00000\t1.77778\t10.00000\t0.02352\t0.00440\t0.20407\t0.00357\t0.00914\t0.03585\t0.14171\t0.01674\t21.00000\t4.00000\t0.14961\t4235.00000\t0\t17.00000\r\nCS\t176.00000\t0.00000\t20.00000\t1.77778\t3.00000\t0.01850\t0.19659\t0.00469\t0.03895\t0.00000\t0.19659\t0.59670\t0.19659\t10.00000\t5.00000\t0.23767\t3850.00000\t0\t24.00000\r\nCS\t133.00000\t0.00000\t4.00000\t1.33333\t3.00000\t0.00049\t0.01214\t0.22827\t0.18777\t0.18778\t0.12627\t0.00915\t0.18777\t11.00000\t7.00000\t0.32619\t1880.00000\t0\t16.00000\r\nCS\t140.00000\t0.00000\t14.00000\t1.33333\t1.00000\t0.01787\t0.02860\t0.48472\t0.02860\t0.59853\t0.02860\t1.06538\t0.02860\t9.00000\t7.00000\t0.02860\t1876.00000\t0\t142.00000\r\n```\r\nand the full file [data.txt](https://github.com/dotnet/machinelearning/files/3180842/data.txt)\r\n\r\nLet\'s execute AutoML\r\n\r\n> mlnet auto-train --task `multiclass-classification` --dataset ""data.txt"" --has-header --label-column-name `Class` --max-exploration-time 10\r\n\r\nas a  results AutoML will generate `ModelInput.cs` file that starts like this\r\n```csharp\r\n public class ModelInput\r\n    {\r\n        [ColumnName(""Class""), LoadColumn(0)]\r\n        public string Class { get; set; }\r\n        [ColumnName(""A1""), LoadColumn(1)]\r\n        public string A1 { get; set; }\r\n        [ColumnName(""A2""), LoadColumn(2)]\r\n        public string A2 { get; set; }\r\n        [ColumnName(""A3""), LoadColumn(3)]\r\n        public string A3 { get; set; }\r\n```\r\n\r\nall columns are recognized as `string` instead of `float` \xf0\x9f\x98\xa2\r\n\r\nas a result data pipeline also incorrect (`OneHotEncoding` was applied to numeric columns)\r\n```csharp\r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Class"", ""Class"")\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(new[]\r\n                {\r\n                    new InputOutputColumnPair(""A3"", ""A3""), new InputOutputColumnPair(""A4"", ""A4""),\r\n                    new InputOutputColumnPair(""A5"", ""A5""), new InputOutputColumnPair(""A14"", ""A14""),\r\n                    new InputOutputColumnPair(""A15"", ""A15""), new InputOutputColumnPair(""A18"", ""A18"")\r\n                }))\r\n                .Append(mlContext.Transforms.Categorical.OneHotHashEncoding(new[]\r\n                {\r\n                    new InputOutputColumnPair(""A1"", ""A1""), new InputOutputColumnPair(""A2"", ""A2""),\r\n                    new InputOutputColumnPair(""A6"", ""A6""), new InputOutputColumnPair(""A17"", ""A17""),\r\n                    new InputOutputColumnPair(""A19"", ""A19"")\r\n                }))\r\n                .Append(mlContext.Transforms.Concatenate(""Features"",\r\n                    new[] {""A3"", ""A4"", ""A5"", ""A14"", ""A15"", ""A18"", ""A1"", ""A2"", ""A6"", ""A17"", ""A19""}))\r\n                .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""))\r\n                .AppendCacheCheckpoint(mlContext);\r\n```\r\n\r\nWhy in this case all columns recognized as strings?\r\nWhy in some columns `OneHotHashEncoding` was used instead of `OneHotEncoding`?'"
604909183,5050,b'AutoML silently fails on the training phase of a binary classification problem.',"b'Hey guys,\r\n\r\n### Problem\r\nI am submitting a test project that demonstrates a bug.\r\nAutoML silently fails on the training phase of a binary classification problem.\r\n\r\n### Reproducible Code\r\nMy reproducible code can by downloaded from: https://github.com/CBrauer/Test_ML.NET\r\n\r\n### My environment is:\r\n  Microsoft Visual Studio Professional 2019 Preview\r\n  Version 16.6.0 Preview 2.1\r\n  VisualStudio.16.Preview/16.6.0-pre.2.1+30001.183\r\n  Microsoft .NET Framework\r\n  Version 4.8.03752\r\nI am running on Windows 10 Enterprise, version 1909 (OS Build 18.363.815).\r\nMy project uses the latest preview2 code.\r\n\r\n### Running the test program\r\nWhen you run the program you will see output like:\r\n\r\nRunning AutoML binary classification experiment using: FastTree,F1Score\r\n     Trainer                               Accuracy    AUC       AUPRC   F1-score  Duration\r\n   1 FastTreeBinary                         0.8610    0.7071    0.3537    0.1346    1.5480\r\n  11 FastTreeBinary                         0.8544    0.7357    0.3300    0.2445    2.8725\r\n  16 FastTreeBinary                         0.8722    0.7520    0.4299    0.3119   10.6857\r\n  33 FastTreeBinary                         0.8730    0.7357    0.4213    0.3188    3.0864\r\n  40 FastTreeBinary                         0.8730    0.7421    0.4410    0.3407   10.6638\r\n  50 FastTreeBinary                         0.8714    0.7496    0.4230    0.3584    9.2112\r\n  73 FastTreeBinary                         0.8695    0.7426    0.4184    0.3717   10.4270\r\n 118 FastTreeBinary                         0.8714    0.7307    0.4090    0.3822   10.6095\r\n 244\r\n\r\nEach experiment should last only one-hour.  I ran the program over-night, and it never finished. \r\n\r\nCharles\r\n\r\n'"
604620503,5049,b'Slots out of range',"b'In the example, won\'t `item.Key` go up to the bit length specified.\r\nIf there\'s no matching slot, this will throw.\r\n\r\n```\r\n            foreach (var featureRow in NgramFeaturesColumn)\r\n            {\r\n                foreach (var item in featureRow.Items())\r\n                    Console.Write($""{slots[item.Key]}  ""); // out of range possible\r\n                Console.WriteLine();\r\n            }\r\n```\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: da8a2391-a844-b431-0b36-992fcba2aeb4\r\n* Version Independent ID: 19a18209-4127-4079-0e38-311b7de733bd\r\n* Content: [TextCatalog.ProduceHashedNgrams Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.textcatalog.producehashedngrams?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/TextCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TextCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
604343678,5044,b'support AVX instruction set at CPUMath native',"b'In CPUMath native we only support SSE.\r\nIn dotnet framework and dotnet core 2.1 we are using CPUMath native directly which means we only have SSE.\r\nIn dotnet core 2.2 or later version, dotnet core supports hardware Intrinsics so have support for both AVX and SSE.\r\n\r\nSupport AVX in CPUMath native will have performance benefit as well as generates identical result from different dotnet framework version using.'"
603573648,5042,b'Return average metrics in AutoML CrossValSummaryRunner',"b'Related to #4663 \r\nSee also https://github.com/dotnet/machinelearning/pull/5031#discussion_r409233020\r\n\r\n`CrossValSummaryRunner` in AutoML gets invoked when the dataset size is less than 15k rows. It runs 10-fold cross validation and computes the average optimization metric across the folds. It then reports all the metrics from the fold that has the optimization metric closest to this average.\r\nhttps://github.com/dotnet/machinelearning/blob/214926fcf5753ad62acf32c0759bdaf8fcd13b73/src/Microsoft.ML.AutoML/Experiment/Runners/CrossValSummaryRunner.cs#L76-L78\r\n\r\nA better way to do this would be to calculate the average of all the metrics, instantiate a new metrics class with these averages, and return that in the run details. This could reuse the code for calculating the average of non_NaN metrics from #5031. The following two things will need to be figured out and need more discussion:\r\n\r\n1. `PerClassLogLoss`: For multiclass classification, the ordering of the class labels may be different across the 10 folds. So, the `PerClassLogLoss` metric from each fold will have different indices for the class labels. In this situation, a standardized ordering would need to be figured out and the averages calculated for each class accordingly.\r\n\r\n2. `ConfusionMatrix`: For multiclass classification, the same problem as above needs solving. In addition, for both binary and multiclass classification, what confusion matrix is returned needs discussion. The distribution of class labels will be different across the folds, so what exactly is the ""average"" of a confusion matrix? Do we return a confusion matrix at all? Do we just return the confusion matrix from the fold with optimization metric closest to the average (current behavior)? If we are going this route, the confusion matrix property in the metrics classes will need to be made internally settable, as there is no constructor that takes the confusion matrix as an argument.\r\n\r\n'"
601079846,5033,b'Unexpected behavior using multiple pipelines for training vs one',"b'### System information\r\n\r\n- **OS version/distro**:\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n-**What did I do?**\r\n- Instead of one training pipeline, I split the pipeline to fit and transform the data into a featurized IDataView, and used that to train a classifier\r\n-**What happened?**\r\nClassifier accuracy was 50% of accuracy when the training pipeline is a complete chain.\r\n-**What did I expect**\r\nI expect that the accuracy of the model trained on either with the TransformerChain pipeline or trainingData transformed by the same TransformerChain be similar in accuracy\r\n\r\n### Source code / logs\r\n\r\nThis is what I mean by splitting the pipeline.\r\n\r\n`var dataProcessPipeline =\r\n                                      mlContext.Transforms.Text.FeaturizeText(""WordFeatures"", ""Transcript"")\r\n                                      .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""));`\r\n\r\n`IDataView transformedTrainingData = dataProcessPipeline.Fit(trainingDataView).Transform(trainingDataView);`\r\n\r\n`var trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName:""Label"", featureColumnName: ""Features"")\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));`\r\n\r\n`ITransformer model = trainer.Fit(transformedTrainingData );`\r\n\r\nI understand this to be conceptually similar to\r\n\r\n`\r\n            var dataProcessPipeline =\r\n                                      mlContext.Transforms.Text.FeaturizeText(""WordFeatures"", ""Transcript"")\r\n                                      .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""));`\r\n\r\n           var trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: ""Label"", featureColumnName: ""Features"")\r\n                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);`\r\n\r\n`ITransformer model =trainingPipeline .Fit(trainingDataView);`\r\n\r\n\r\nThe first gives me ~50% accuracy on the test set, the second ~98.9%. Is my understanding incorrect? Is there a missing step on doing things this way? My goal is to create a single Transformer for featurizing data that can then be used in more than one model, without having to build multiple models that featurize the data in the exact same way. \r\n\r\nHopefully the example makes sense. I can clarify if not.\r\n\r\n'"
600650602,5030,b'I cannot save the model for some weird reason.',"b'### System information\r\n\r\n- **OS version/distro**:win10-x64\r\n- **.NET Version (eg., dotnet --info)**: 3.1.101\r\n\r\n### Issue\r\n\r\n- **Have been playing around with machine learning as of late, made a basic machine learning algorithm. It was working perfectly and then I broke something and now it refuses to save the model.**\r\n- **I cannot save the model. I\'m not sure what caused that. I\'m a beginner.**\r\n- **That I could save the model**\r\n\r\n-Here\'s the error code:\r\n`System.ArgumentException\r\n  HResult=0x80070057\r\n  Message=The path is not of a legal form.\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.IO.Path.NewNormalizePath(String path, Int32 maxPathLength, Boolean expandShortPaths)\r\n   at System.IO.Path.NormalizePath(String path, Boolean fullCheck, Int32 maxPathLength, Boolean expandShortPaths)\r\n   at System.IO.Path.GetFullPathInternal(String path)\r\n   at System.IO.Path.GetFullPath(String path)\r\n   at System.Diagnostics.FileVersionInfo.GetFullPathWithAssert(String fileName)\r\n   at System.Diagnostics.FileVersionInfo.GetVersionInfo(String fileName)\r\n   at Microsoft.ML.RepositoryWriter.CreateNew(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, Stream stream)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, String filePath)\r\n   at MachineLearningTest.ModelBuilder.SaveModel(MLContext mlContext, ITransformer mlModel, String modelRelativePath, DataViewSchema modelInputSchema) in C:\\Users\\Michael\\source\\repos\\new\\MachineLearingTest\\ModelBuilder.cs:line 48\r\n   at MachineLearningTest.ModelBuilder.CreateModel() in C:\\Users\\Michael\\source\\repos\\new\\MachineLearingTest\\ModelBuilder.cs:line 43\r\n   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)\r\n   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)\r\n   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n   at System.Threading.ThreadHelper.ThreadStart()\r\n\r\n  This exception was originally thrown at this call stack:\r\n\tSystem.IO.Path.NewNormalizePath(string, int, bool)\r\n\tSystem.IO.Path.NormalizePath(string, bool, int, bool)\r\n\tSystem.IO.Path.GetFullPathInternal(string)\r\n\tSystem.IO.Path.GetFullPath(string)\r\n\tSystem.Diagnostics.FileVersionInfo.GetFullPathWithAssert(string)\r\n\tSystem.Diagnostics.FileVersionInfo.GetVersionInfo(string)\r\n\tMicrosoft.ML.RepositoryWriter.CreateNew(System.IO.Stream, Microsoft.ML.Runtime.IExceptionContext, bool)\r\n\tMicrosoft.ML.ModelOperationsCatalog.Save(Microsoft.ML.ITransformer, Microsoft.ML.DataViewSchema, System.IO.Stream)\r\n\tMicrosoft.ML.ModelOperationsCatalog.Save(Microsoft.ML.ITransformer, Microsoft.ML.DataViewSchema, string)\r\n    MachineLearningTest.ModelBuilder.SaveModel(Microsoft.ML.MLContext, Microsoft.ML.ITransformer, string, Microsoft.ML.DataViewSchema) in ModelBuilder.cs\r\n    ...\r\n    [Call Stack Truncated]\r\n`\r\n\r\n### Source code / logs\r\n\r\nAnd here\'s the code:\r\n`// This file was auto-generated by ML.NET Model Builder. \r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing System.Windows.Forms;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers.LightGbm;\r\n\r\nnamespace MachineLearningTest\r\n{\r\n    public static class ModelBuilder\r\n    {\r\n        private static string TRAIN_DATA_FILEPATH = Program.dataPath;\r\n        private static string MODEL_FILEPATH = @""MLModel.zip"";\r\n        // Create MLContext to be shared across the model creation workflow objects \r\n        // Set a random seed for repeatable/deterministic results across multiple trainings.\r\n        private static MLContext mlContext = new MLContext(seed: 1);\r\n\r\n        public static void CreateModel()\r\n        {\r\n            // Load Data\r\n            IDataView trainingDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n                                            path: TRAIN_DATA_FILEPATH,\r\n                                            hasHeader: true,\r\n                                            separatorChar: \',\',\r\n                                            allowQuoting: true,\r\n                                            allowSparse: false);\r\n\r\n            // Build training pipeline\r\n            IEstimator<ITransformer> trainingPipeline = BuildTrainingPipeline(mlContext);\r\n            \r\n\r\n            // Evaluate quality of Model\r\n            //Evaluate(mlContext, trainingDataView, trainingPipeline);\r\n\r\n            // Train Model\r\n            ITransformer mlModel = TrainModel(mlContext, trainingDataView, trainingPipeline);\r\n\r\n            // Save model\r\n            SaveModel(mlContext, mlModel, MODEL_FILEPATH, trainingDataView.Schema);\r\n        }\r\n        private static void SaveModel(MLContext mlContext, ITransformer mlModel, string modelRelativePath, DataViewSchema modelInputSchema)\r\n        {\r\n            // This causes the exception\r\n                mlContext.Model.Save(mlModel, modelInputSchema, (GetAbsolutePath(modelRelativePath)));\r\n        }\r\n\r\n        public static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)\r\n        {\r\n            // Data process configuration with pipeline data transformations \r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""White"", ""White"")\r\n                                      .Append(mlContext.Transforms.Concatenate(""Features"", new[] { ""Hue"", ""Saturation"", ""Brightness"" }));\r\n            // Set the training algorithm \r\n            var trainer = mlContext.MulticlassClassification.Trainers.LightGbm(new LightGbmMulticlassTrainer.Options() { NumberOfIterations = 20, LearningRate = 0.05916024f, NumberOfLeaves = 4, MinimumExampleCountPerLeaf = 1, UseCategoricalSplit = false, HandleMissingValue = true, MinimumExampleCountPerGroup = 200, MaximumCategoricalSplitPointCount = 8, CategoricalSmoothing = 20, L2CategoricalRegularization = 1, UseSoftmax = true, Booster = new GradientBooster.Options() { L2Regularization = 0, L1Regularization = 0.5 }, LabelColumnName = ""White"", FeatureColumnName = ""Features"" })\r\n                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            return trainingPipeline;\r\n        }\r\n\r\n        public static ITransformer TrainModel(MLContext mlContext, IDataView trainingDataView, IEstimator<ITransformer> trainingPipeline)\r\n        {\r\n            Console.WriteLine(""=============== Training  model ==============="");\r\n            ITransformer model = trainingPipeline.Fit(trainingDataView);\r\n\r\n            Console.WriteLine(""=============== End of training process ==============="");\r\n            return model;\r\n        }\r\n\r\n        private static void Evaluate(MLContext mlContext, IDataView trainingDataView, IEstimator<ITransformer> trainingPipeline)\r\n        {\r\n            // Cross-Validate with single dataset (since we don\'t have two datasets, one for training and for evaluate)\r\n            // in order to evaluate and get the model\'s accuracy metrics\r\n            Console.WriteLine(""=============== Cross-validating to get model\'s accuracy metrics ==============="");\r\n            var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(trainingDataView, trainingPipeline, numberOfFolds: 5, labelColumnName: ""White"");\r\n            PrintMulticlassClassificationFoldsAverageMetrics(crossValidationResults);\r\n        }\r\n\r\n        \r\n\r\n        public static string GetAbsolutePath(string relativePath)\r\n        {\r\n            FileInfo _dataRoot = new FileInfo(typeof(Program).Assembly.Location);\r\n            string assemblyFolderPath = _dataRoot.Directory.FullName;\r\n\r\n            string fullPath = Path.Combine(assemblyFolderPath, relativePath);\r\n            return fullPath;\r\n        }\r\n        public static void PrintMulticlassClassificationMetrics(MulticlassClassificationMetrics metrics)\r\n        {\r\n            Console.WriteLine($""************************************************************"");\r\n            Console.WriteLine($""*    Metrics for multi-class classification model   "");\r\n            Console.WriteLine($""*-----------------------------------------------------------"");\r\n            Console.WriteLine($""    MacroAccuracy = {metrics.MacroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better"");\r\n            Console.WriteLine($""    MicroAccuracy = {metrics.MicroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better"");\r\n            Console.WriteLine($""    LogLoss = {metrics.LogLoss:0.####}, the closer to 0, the better"");\r\n            for (int i = 0; i < metrics.PerClassLogLoss.Count; i++)\r\n            {\r\n                Console.WriteLine($""    LogLoss for class {i + 1} = {metrics.PerClassLogLoss[i]:0.####}, the closer to 0, the better"");\r\n            }\r\n            Console.WriteLine($""************************************************************"");\r\n        }\r\n\r\n        public static void PrintMulticlassClassificationFoldsAverageMetrics(IEnumerable<TrainCatalogBase.CrossValidationResult<MulticlassClassificationMetrics>> crossValResults)\r\n        {\r\n            var metricsInMultipleFolds = crossValResults.Select(r => r.Metrics);\r\n\r\n            var microAccuracyValues = metricsInMultipleFolds.Select(m => m.MicroAccuracy);\r\n            var microAccuracyAverage = microAccuracyValues.Average();\r\n            var microAccuraciesStdDeviation = CalculateStandardDeviation(microAccuracyValues);\r\n            var microAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(microAccuracyValues);\r\n\r\n            var macroAccuracyValues = metricsInMultipleFolds.Select(m => m.MacroAccuracy);\r\n            var macroAccuracyAverage = macroAccuracyValues.Average();\r\n            var macroAccuraciesStdDeviation = CalculateStandardDeviation(macroAccuracyValues);\r\n            var macroAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(macroAccuracyValues);\r\n\r\n            var logLossValues = metricsInMultipleFolds.Select(m => m.LogLoss);\r\n            var logLossAverage = logLossValues.Average();\r\n            var logLossStdDeviation = CalculateStandardDeviation(logLossValues);\r\n            var logLossConfidenceInterval95 = CalculateConfidenceInterval95(logLossValues);\r\n\r\n            var logLossReductionValues = metricsInMultipleFolds.Select(m => m.LogLossReduction);\r\n            var logLossReductionAverage = logLossReductionValues.Average();\r\n            var logLossReductionStdDeviation = CalculateStandardDeviation(logLossReductionValues);\r\n            var logLossReductionConfidenceInterval95 = CalculateConfidenceInterval95(logLossReductionValues);\r\n\r\n            Console.WriteLine($""*************************************************************************************************************"");\r\n            Console.WriteLine($""*       Metrics for Multi-class Classification model      "");\r\n            Console.WriteLine($""*------------------------------------------------------------------------------------------------------------"");\r\n            Console.WriteLine($""*       Average MicroAccuracy:    {microAccuracyAverage:0.###}  - Standard deviation: ({microAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({microAccuraciesConfidenceInterval95:#.###})"");\r\n            Console.WriteLine($""*       Average MacroAccuracy:    {macroAccuracyAverage:0.###}  - Standard deviation: ({macroAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({macroAccuraciesConfidenceInterval95:#.###})"");\r\n            Console.WriteLine($""*       Average LogLoss:          {logLossAverage:#.###}  - Standard deviation: ({logLossStdDeviation:#.###})  - Confidence Interval 95%: ({logLossConfidenceInterval95:#.###})"");\r\n            Console.WriteLine($""*       Average LogLossReduction: {logLossReductionAverage:#.###}  - Standard deviation: ({logLossReductionStdDeviation:#.###})  - Confidence Interval 95%: ({logLossReductionConfidenceInterval95:#.###})"");\r\n            Console.WriteLine($""*************************************************************************************************************"");\r\n\r\n        }\r\n\r\n        public static double CalculateStandardDeviation(IEnumerable<double> values)\r\n        {\r\n            double average = values.Average();\r\n            double sumOfSquaresOfDifferences = values.Select(val => (val - average) * (val - average)).Sum();\r\n            double standardDeviation = Math.Sqrt(sumOfSquaresOfDifferences / (values.Count() - 1));\r\n            return standardDeviation;\r\n        }\r\n\r\n        public static double CalculateConfidenceInterval95(IEnumerable<double> values)\r\n        {\r\n            double confidenceInterval95 = 1.96 * CalculateStandardDeviation(values) / Math.Sqrt((values.Count() - 1));\r\n            return confidenceInterval95;\r\n        }\r\n    }\r\n}\r\n`'"
599102890,5022,"b'ML.Ranking LightGBM - Getting error ""Value cannot be null. Parameter name: items""'","b'### System information\r\n\r\n- Windows:\r\n- .net Core 3.0: \r\n\r\n### Issue\r\n\r\n- I am trying to generate a simple ranking of candidates based on a few features for a recruitment application. \r\n- But when running the trainer, I get the following message which is not clear - ""Value cannot be null. Parameter name: items""\r\n\r\n\r\n### Source code / logs\r\n\r\n![Capture](https://user-images.githubusercontent.com/12490592/79155380-f07ee280-7dc8-11ea-859e-fee03d4d7e24.PNG)\r\n\r\n```C#\r\n//Training Pipeline\r\n            IEstimator<ITransformer> dataPipeline = mlContext.Transforms.Categorical.OneHotEncoding(""HIGHESTEDUCATION"", ""HIGHESTEDUCATION"")\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""SOURCE"", ""SOURCE""))\r\n                .Append(mlContext.Transforms.Text.FeaturizeText(""SKILLSET"", ""SKILLSET""))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""TOWNCITY"", ""TOWNCITY""))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""YEARSOFEXPERIENCE"", ""YEARSOFEXPERIENCE""))\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""HIGHESTEDUCATION"", ""SKILLSET"", ""SOURCE"", ""TOWNCITY"", ""YEARSOFEXPERIENCE""))\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(""Label"",""Label""))\r\n                .Append(mlContext.Transforms.Conversion.Hash(""GroupId"", nameof(Candidate.VACANCYID), numberOfBits: 20));\r\n\r\n            // Set the LightGBM LambdaRank trainer.\r\n            IEstimator<ITransformer> trainer = mlContext.Ranking.Trainers.LightGbm(labelColumnName: ""Label"", featureColumnName: ""Features"", rowGroupColumnName: ""GroupId""); \r\n            IEstimator<ITransformer> trainerPipeline = dataPipeline.Append(trainer);\r\n```\r\n```C#\r\n// Domain Model\r\npublic class Candidate\r\n    {\r\n        [LoadColumn(0)]\r\n        public string HIGHESTEDUCATION { get; set; }\r\n\r\n        [ColumnName(""Label""),LoadColumn(1)]\r\n        public Single RELEVANCESCORE { get; set; }\r\n\r\n        [LoadColumn(2)]\r\n        public string SKILLSET { get; set; }\r\n\r\n        [LoadColumn(3)]\r\n        public string SOURCE { get; set; }\r\n\r\n        [LoadColumn(4)]\r\n        public string TOWNCITY { get; set; }\r\n\r\n        [ ColumnName(""GroupId""), LoadColumn(5)]\r\n        public string VACANCYID { get; set; }\r\n\r\n        [LoadColumn(6)]\r\n        public string YEARSOFEXPERIENCE { get; set; }\r\n        \r\n    }\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
598621005,5020,"b'Error scoring Tensorflow model mtcnn.pb. The second input must be a scalar, but it has shape [1,1]'","b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I have run TensorFlow scoring using mtcnn.pb model\r\n- **What happened?** I got Tensorflow.TensorflowException: The second input must be a scalar, but it has shape [1,1]\r\n\t [[Node: _clooppnet/while/add/y/_2 = Switch[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_clooppnet/while/add/y/_1, pnet/while/LoopCond/_135)]]\r\n- **What did you expect?** To get the bounding box, maybe probability and landmarks as well.\r\n\r\n### Source code / logs\r\n\r\nHere is the mtcnn.pb model: [mtcnn.zip](https://github.com/dotnet/machinelearning/files/4467608/mtcnn.zip)\r\n\r\nThese are the inputs:\r\n![Untitled](https://user-images.githubusercontent.com/15055082/79085329-7737af00-7d38-11ea-9e1d-bd57d21a09df.png)\r\n\r\nThis is one of the outputs node (box):\r\n![Untitled](https://user-images.githubusercontent.com/15055082/79085482-0218a980-7d39-11ea-8c33-50f57b0c3f8a.png)\r\n\r\n```csharp\r\n        class PredictedImageData\r\n        {\r\n            [ColumnName(""box"")]\r\n            [VectorType(1)]\r\n            public float[] BoundingBox { get; set; }\r\n\r\n            [ColumnName(""landmarks"")]\r\n            [VectorType(1)]\r\n            public float[] Landmarks { get; set; }\r\n\r\n            [ColumnName(""prob"")]\r\n            public float Probability { get; set; }\r\n        }\r\n\r\n        private struct ImageNetSettings\r\n        {\r\n            public const int imageHeight = 224;\r\n            public const int imageWidth = 224;\r\n        }\r\n\r\n        public class ImageNetData\r\n        {\r\n            public string ImagePath;\r\n\r\n            //[ImageType(ImageNetSettings.imageHeight, ImageNetSettings.imageWidth)]\r\n            //[VectorType(1)]\r\n            //[ColumnName(""input"")]\r\n            //public Bitmap Input { get; set; }\r\n\r\n            [VectorType(1)]\r\n            [ColumnName(""min_size"")]\r\n            public float[] MinSize;\r\n\r\n            [VectorType(1)]\r\n            [ColumnName(""factor"")]\r\n            public float[] Factor;\r\n\r\n            [VectorType(3)]\r\n            [ColumnName(""thresholds"")]\r\n            public float[] Thresholds;\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext(seed: 1);\r\n            var modelLocation = ""mtcnn.pb"";\r\n            var data = mlContext.Data.LoadFromEnumerable(new List<ImageNetData>());\r\n\r\n            var pipeline = mlContext\r\n                .Transforms.LoadImages(\r\n                    outputColumnName: ""input"",\r\n                    imageFolder: """",\r\n                    inputColumnName: nameof(ImageNetData.ImagePath))\r\n                .Append(mlContext\r\n                .Transforms.ResizeImages(\r\n                    outputColumnName: ""input"",\r\n                    imageWidth: ImageNetSettings.imageWidth,\r\n                    imageHeight: ImageNetSettings.imageHeight,\r\n                    inputColumnName: ""input""))\r\n                .Append(mlContext.Transforms.ExtractPixels(\r\n                    outputColumnName: ""input""))\r\n                .Append(mlContext.Model.LoadTensorFlowModel(modelLocation).ScoreTensorFlowModel(\r\n                    inputColumnNames: new[] { ""input"", ""thresholds"", ""min_size"", ""factor"" },\r\n                    //outputColumnNames: new[] { ""box"", ""prob"", ""landmarks"" },\r\n                    outputColumnNames: new[] { ""box"" },\r\n                    addBatchDimensionInput: true));\r\n\r\n            ITransformer model = pipeline.Fit(data);\r\n\r\n            var predictionEngine = mlContext.Model.CreatePredictionEngine<ImageNetData, PredictedImageData>(model);\r\n\r\n            var prediction = predictionEngine.Predict(new ImageNetData\r\n            {\r\n                ImagePath = ""anastasia3.jpg"",\r\n                //Input = (Bitmap)Image.FromFile(""anastasia3.jpg""),\r\n                MinSize = new float[] { 40F },\r\n                Factor = new float[] { 0.709F },\r\n                Thresholds = new float[] { 0.6F, 0.7F, 0.7F }\r\n            });\r\n        }\r\n```\r\n'"
598223556,5016,b'Build failed in non-english cultures using build.sh',"b""### System information\r\n\r\n- **OS version/distro**: Mac OS Catalina\r\n- **.NET Version (eg., dotnet --info)**: 3.1.200\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCloned the repository and builded the project using build.sh file \r\n- **What happened?**\r\nThe project `Microsoft.ML.FSharp.Tests.fsproj` fails to build with error FS0246. My default localization use comma to separate decimal places and when it's building the project it tries to parse in my current culture instead of en-US.\r\n- **What did you expect?**\r\nThe project should build successfully.\r\n\r\n### Source code / logs\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n`\r\nFSC : error FS0246: Valor n\xc3\xa3o reconhecido '4.7' para --langversion use --langversion:? para a lista completa \r\n`"""
596065428,5007,b'Remarks section appears malformed',b'Docs rendering bug\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: ce7a249f-fd8a-5869-8dc7-9142e7cba9d2\n* Version Independent ID: 58ab615c-8c4b-b22c-57fc-99872b0d5445\n* Content: [SsaForecastingEstimator Class (Microsoft.ML.Transforms.TimeSeries)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.timeseries.ssaforecastingestimator?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms.TimeSeries/SsaForecastingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms.TimeSeries/SsaForecastingEstimator.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'
595197773,5001,b'\xf0\x9f\x93\x9d Alternative ways to prepare dataset',"b""How can I extract model class because builder doesn't work? (error https://github.com/dotnet/machinelearning/issues/4879)\r\n\r\nCan I train simple matrix, like \r\n`           var labels = new List<double>();\r\n            var features = new List<List<double>>();`\r\n\r\nOr dataframe loaded by **CsvHelper**?\r\n\r\nAny other alternatives to prepare dataset?"""
591301510,4987,b'Caching discrepancy between API docs and TrainerInfo.WantCaching property',"b'There are discrepancies in the docs for trainers on whether caching is required or not.\r\n\r\nFor example: [MatrixFactorizationTrainer](https://github.com/dotnet/machinelearning/blob/fbd1b93065b451401b1e3276e5ac65b9f303f90b/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs)\r\n\r\nIn the documentation, it says caching is required:\r\n\r\n| Is caching required? | Yes |\r\n\r\nHowever, the `TrainerInfo.WantCaching` property is set to false.\r\n\r\n```csharp\r\n_info = new TrainerInfo(normalization: false, caching: false);\r\n```\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fbd1b93065b451401b1e3276e5ac65b9f303f90b/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs#L370\r\n\r\nTo-Do:\r\n\r\n- [x] Get list of trainers these discrepancies occur.\r\n\r\n\r\n'"
590920427,4986,b'Retrain same data results in different accuracy',"b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1\r\n\r\n### Issue: When I retrain the data with the ML.Net Model Builder with the same data and training parameters, there is a difference in Micro- and Macro-Accuracy.\r\n\r\n- **What did you do?\r\nUsing the Model Builder to train a data set\r\n\r\n- **What happened?**\r\nWhen I retrain the same data (by pressing the Start training button again) with the same label, features and training time, I see a difference in accuracy. Is there a reason why this is?\r\n\r\n- **What did you expect?**\r\nI expected more or less the same accuracy because all data and parameters are identical.\r\n\r\n### Source code / logs\r\n\r\n**First training:**\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n|1    FastTreeOva                                 0.8575         0.7943      23.3          1                     |\r\n|2    LightGbmMulti                               0.8568         0.8002       3.8          2                     |\r\n|3    FastTreeOva                                 0.8538         0.7843      27.0          3                     |\r\n|4    FastForestOva                               0.8513         0.7889      26.5          4                     |\r\n|5    LightGbmMulti                               0.8511         0.7808       6.4          5                     |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\n\r\n**Second training**\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n|1    FastTreeOva                                 0.9016         0.7241      44.8          1                     |\r\n|2    FastForestOva                               0.8847         0.6465      42.9          2                     |\r\n|3    AveragedPerceptronOva                       0.8575         0.6175      13.3          3                     |\r\n|4    SymbolicSgdLogisticRegressionOva            0.8387         0.4301       7.1          4                     |\r\n|5    SdcaMaximumEntropyMulti                     0.8331         0.3212       5.1          5                     |\r\n'"
590581883,4982,b'TextLoader Load From Multiple Files Inconsistent Behavior',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1\r\n- **ML.NET Version (eg., dotnet --info)**: 1.5.0-preview2\r\n\r\n### Issue\r\n\r\nWhen loading data that is in multiple files, whether the data is in a single folder or multiple folders, the behavior in inconsistent. When the data is in a single folder, wildcards can be used. That, however is not the case when the data is in separate folders/subfolders.\r\n\r\nThe non-working examples don\'t work for various reasons. However, in general, the behavior appears inconsistent depending on the structure of the folder.\r\n\r\n### Source code / logs\r\nData Folder Structure:\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/77959332-6735bf00-72a4-11ea-9657-618e6fd1e44c.png)\r\n\r\nData Sample:\r\n\r\n```text\r\nSize (Sq. ft.), HistoricalPrice1 ($), HistoricalPrice2 ($), HistoricalPrice3 ($), Current Price ($)\r\n700, 100000, 3000000, 250000, 500000\r\n```\r\n\r\nSource code:\r\n\r\n```csharp\r\nclass Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext ctx = new MLContext();\r\n\r\n            TextLoader textLoader = ctx.Data.CreateTextLoader<HousingData>(separatorChar: \',\', hasHeader: true);\r\n\r\n            IDataView dvSingleFolder = textLoader.Load(""Data/*"");\r\n            IDataView dvMultipleFoldersNotWorking = textLoader.Load(""DataFolder/*/*"");\r\n            IDataView dvMultipleFoldersNotWorking2 = textLoader.Load(""DataFolder/SubFolder1/*"", ""DataFolder/SubFolder2/*"");\r\n            IDataView dvMultileFoldersWorking = textLoader.Load(""DataFolder/SubFolder1/1.csv"", ""DataFolder/SubFolder2/2.csv"");\r\n\r\n            var singleFolderPreview = dvSingleFolder.Preview();\r\n            var multipleFolderPreview = dvMultipleFoldersNotWorking.Preview();\r\n            var multipleFolderPreview2 = dvMultipleFoldersNotWorking2.Preview();\r\n            var multipleFoldersWorkingPreview = dvMultileFoldersWorking.Preview();\r\n        }\r\n    }\r\n\r\npublic class HousingData\r\n    {\r\n        [LoadColumn(0)]\r\n        public float Size { get; set; }\r\n\r\n        [LoadColumn(1, 3)]\r\n        [VectorType(3)]\r\n        public float[] HistoricalPrices { get; set; }\r\n\r\n        [LoadColumn(4)]\r\n        [ColumnName(""Label"")]\r\n        public float CurrentPrice { get; set; }\r\n    }\r\n```\r\n'"
590143327,4981,b'PredictionEnginePool.GetPredictionEngine is not thread safe',"b'### System information\r\n\r\n- **OS version/distro**:Windows 10 Server 2019 \r\n- **.NET Version (eg., dotnet --info)**: core 3.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nInvoked PredictionEnginePool.Predict(""MyModelName"", example) from multiple threads.\r\n- **What happened?**\r\nCollection was modified; enumeration operation may not execute. \r\n- **What did you expect?**\r\nMethod is thread safe \r\n### Source code / logs\r\n\r\nPackage\r\nMicrosoft.Azure.Functions.Extensions Version=""1.0.0""\r\nMicrosoft.Extensions.MLVersion=""1.5.0-preview2"" or 1.40\r\nMicrosoft.ML Version=""1.5.0-preview2"" or 1.40\r\nMicrosoft.NET.Sdk.Functions Version=""3.0.3""\r\n\r\n\r\nin startup \r\n\r\n builder.Services.AddPredictionEnginePool<Input, PredictedEngineOutput>().FromFile(""ModelName"", ""ModelPath"", true);\r\n\r\nin function \r\n             var re = _PredictionEnginePool.Predict(""ModelName"", new Input() {String = str });\r\n\r\nException\r\n\r\n```\r\n   at System.Collections.Generic.List`1.Enumerator.MoveNextRare()\r\n   at System.Linq.Enumerable.Any[TSource](IEnumerable`1 source, Func`2 predicate)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolPolicy`2.Return(PredictionEngine`2 obj)\r\n   at Microsoft.Extensions.ObjectPool.DefaultObjectPool`1.Return(T obj)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.ReturnPredictionEngine(String modelName, PredictionEngine`2 engine)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at BLDM_F.F.Predict(HttpRequest req, ILogger log) in C:\\tfs\\BLDM_F\\Function1.cs:line 148\r\n```\r\n\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
589549115,4980,b'How to Add Date column in the Input Class',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  VS 2019\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried to modify the TaxiFairExample ; Just copied the  code and include few fields \r\n1) Date \r\n2) Punctured \r\nto predict whether the taxi would likely to punctured in the coming date.\r\n\r\n- **What happened?**\r\nWhen I included Date column in the class and try to debug the code ; following errors rises\r\n\r\nSystem.ArgumentOutOfRangeException: \'Could not determine an IDataView type for member Date\r\nParameter name: rawType\'\r\n\r\n![IDataView type for member Date](https://user-images.githubusercontent.com/7997380/77820851-31a79f00-7107-11ea-87d1-e6576edc073e.png)\r\n\r\n- **What did you expect?**\r\nI just expect to predict whether the Taxi is likely to puncture or not in the given date \r\n### Source code / logs\r\n\r\n```\r\n public class ItemStock\r\n    {\r\n        [Column(""0"")]\r\n        public string CarID;\r\n\r\n        [Column(""1"")]\r\n        public float LocID;\r\n\r\n        [Column(""2"")]\r\n        public DateTime Date;\r\n\r\n        [Column(""3"")]\r\n        public float Punctured;\r\n    }\r\n\r\n    public class itemStockQtyPrediction\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public float Punctured;\r\n    }\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n\r\n'"
589039256,4977,"b""Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1 \r\n\r\n### Issue\r\n\r\n- **What did you do?** : Train a model from a json File\r\n- **What happened?** Schema mismatch for feature column \'Features\': expected Vector<Single>, got VarVector<Single> \'\r\n\r\n### Source code / logs\r\nHere is the code to train the model : \r\n```C#\r\nprivate static ITransformer trainWithJson(MLContext mlContext)\r\n        {\r\n            using (StreamReader r = new StreamReader(""datasetCrewCleaned.json""))\r\n            {\r\n                string json = r.ReadToEnd();\r\n                List<FilmModel> items = JsonConvert.DeserializeObject<List<FilmModel>>(json);\r\n                List<FilmModel> itemsTrain = new List<FilmModel>();\r\n                for (int i = 0; i < items.Count; i++)\r\n                {\r\n                    if (i > 24000)\r\n                    {\r\n                        break;\r\n                    }\r\n                    itemsTrain.Add(items[i]);\r\n                }\r\n                var data = mlContext.Data.LoadFromEnumerable(itemsTrain);\r\n                var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: ""Label"",    inputColumnName: nameof(FilmModel.BoxOffice))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName:   ""NameEncoded"", inputColumnName: nameof(FilmModel.Name)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""DurationEncoded"", inputColumnName: nameof(FilmModel.Duration)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""ClassificationEncoded"", inputColumnName: nameof(FilmModel.Classification)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""GenreEncoded"", inputColumnName: nameof(FilmModel.Genre)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""StudioEncoded"", inputColumnName: nameof(FilmModel.Studio)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""BudgetEncoded"", inputColumnName: nameof(FilmModel.Budget)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""ReleaseDateEncoded"", inputColumnName: nameof(FilmModel.ReleaseDate)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""CrewEncoded"", inputColumnName: nameof(FilmModel.Crew)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""ActorsEncoded"", inputColumnName: nameof(FilmModel.Actors)))\r\n               .Append(mlContext.Transforms.Concatenate(""Features"", ""NameEncoded"", ""ClassificationEncoded"", ""DurationEncoded"", ""GenreEncoded"", ""StudioEncoded"", ""BudgetEncoded"", ""ReleaseDateEncoded"", ""CrewEncoded"", ""ActorsEncoded""))\r\n          .Append(mlContext.Regression.Trainers.LbfgsPoissonRegression());\r\n                var model = pipeline.Fit(data);\r\n                return model;\r\n            }\r\n        }\r\n```\r\n\r\nAnd here is the class I\'m using to deSerialize the Json File:\r\n\r\n```C#\r\npublic class FilmModel\r\n    {\r\n        public FilmModel(float boxOffice, string[] crew, string[] actors, string releaseDate = null, string  name = null, string classification = null, string duration = null, string genre = null, string studio =  null, string budget = null)\r\n          {\r\n            Name = name;\r\n            Classification = classification;\r\n            Duration = duration;\r\n            Genre = genre;\r\n            Studio = studio;\r\n            Budget = budget;\r\n            BoxOffice = boxOffice;\r\n            ReleaseDate = releaseDate;\r\n            Crew = crew;\r\n            Actors = actors;\r\n         }\r\n         public string Name { get; set; }\r\n         public string Classification { get; set; }\r\n         public string Duration { get; set; }\r\n         public string Genre { get; set; }\r\n         public string Studio { get; set; }\r\n         public string Budget { get; set; }\r\n         public float BoxOffice { get; set; }\r\n         public string ReleaseDate { get; set; }\r\n         public string[] Actors { get; set; }\r\n         public string[] Crew { get; set; }\r\n    }\r\n```\r\n\r\nThe [] Actors and Crew do not have the same length for each row. For instance a movie could have 4 crew members and another 8. I think that\'s the problem but I do not know how to fix this.'"
588302413,4975,b'How to generate faster_RCNN_Inception_V2 model in ML.NET?',"b'### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  .net core 2.1\r\n\r\n### Issue\r\n\r\n- Use faster_RCNN_Inception_V2 model  doing object detection \r\n-  There is no document about this model  with ML.NET\r\n- How to apply faster_RCNN_Inception_V2 model in ML.NET?\r\nThanks\r\n\r\n\r\n'"
587681463,4970,"b""ColumnSelectingTransformer exported onnx model doesn't drop input columns coming from input dataview""","b""The `ColumnSelectingTransformer` has the ability to drop columns that aren't desired by the user. The Onnx exported model eliminates those columns from the Onnx model graph output, but this isn't enough to remove them from the output `Schema`, so even if they're removed from the onnx model, those columns are still there in the output after using the `ApplyOnnxModel` method. The reason for this is that the `OnnxTransformer` (which is used by the `ApplyOnnxModel` method) is a `RowToRowTransformer`, and such transformers don't have the capacity to drop columns, only to add them to the input DataView.\r\n\r\n### Code\r\nThe existing test for ColumnSelectingTransformer can be used to notice this issue\r\nhttps://github.com/dotnet/machinelearning/blob/22c7ac8921fa0846717662181b334de3b41e9932/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L1707-L1765\r\n\r\nBy setting a breakpoint, and inspecting into the schema of the outputs, I get the following result:\r\n![image](https://user-images.githubusercontent.com/38739674/77539211-385fb900-6e5e-11ea-9bd2-a276697bf264.png)\r\n\r\nIt shows that the undesired columns were correctly dropped by the `ColumnSelectingTransformer`, but not by the `OnnxModel`. This test should also include comparing both schemas, to make sure that the onnxmodel is actually dropping the undesired columns.\r\n"""
587172628,4965,b'Unable to score using PredictionEnginePool with a pipeline/model that contains custom transforms',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n`PredictionEngine` is not thread safe. Therefore, in multi-threaded environments, it is *highly* recommended to use `PredictionEnginePool`.\r\n\r\nWhen you want to save a pipeline that contains custom transforms, you have to provide a contract name. If you want to use the saved pipeline / model, using your `MLContext`, you have to register the custom transform using the `CompontentCatalog.RegisterAssembly` method. \r\n\r\nFor more details, see [documentation on using custom transforms](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-can-i-define-my-own-transformation-of-data).\r\n\r\n`PredictionEnginePool` does not provide access to `MLContext`, therefore it\'s not possible to register the custom transforms using `CompontentCatalog.RegisterAssembly`. Therefore, you can\'t safely deploy models using `PredictionEnginePool`. This affects ASP.NET Core Web Apps (API,MVC,Blazor,Razor Pages) and Azure Functions. \r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar pipeline = mlContext.Transforms.LoadImages(""ImageSource_featurized"", null, ""ImageSource"")\r\n                          .Append(mlContext.Transforms.ResizeImages(""ImageSource_featurized"", 224, 224, ""ImageSource_featurized""))\r\n                          .Append(mlContext.Transforms.ExtractPixels(""ImageSource_featurized"", ""ImageSource_featurized""))\r\n                          .Append(mlContext.Transforms.CustomMapping<NormalizeInput, NormalizeOutput>(\r\n                              (input, output) => NormalizeMapping.Mapping(input, output),\r\n                              contractName: nameof(NormalizeMapping)))\r\n                          .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: ONNX_MODEL))\r\n                          .Append(mlContext.Transforms.CustomMapping<LabelMappingInput, LabelMappingOutput>(\r\n                              (input, output) => LabelMapping.Mapping(input, output),\r\n                              contractName: nameof(LabelMapping)));\r\n```\r\n\r\nCreating PredictionEngine:\r\n\r\n```csharp\r\n// Create new MLContext\r\nMLContext mlContext = new MLContext();\r\n\r\n// Register NormalizeMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(NormalizeMapping).Assembly);\r\n\r\n// Register LabelMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(LabelMapping).Assembly);\r\n\r\n// Load model & create prediction engine\r\nstring modelPath = @""C:\\Users\\luquinta.REDMOND\\AppData\\Local\\Temp\\MLVSTools\\LandUseUWPML\\LandUseUWPML.Model\\MLModel.zip"";\r\nITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n```\r\n\r\nCreate PredictionEnginePool:\r\n\r\n```csharp\r\n//Registered using dependency injection\r\nservices.AddPredictionEnginePool<ModelInput, ModelOutput>()\r\n                .FromFile(""MLModel.zip"");\r\n```\r\n\r\nStack Trace from ASP.NET Core Web API:\r\n\r\n```text\r\nSystem.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Unable to locate an extension for the contract \'NormalizeMapping\'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a \'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute\'.\r\n   at Microsoft.ML.Runtime.ComponentCatalog.GetExtensionValue(IHostEnvironment env, Type attributeType, String contractName)\r\n   at Microsoft.ML.Transforms.LambdaTransform.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.Extensions.ML.FileModelLoader.LoadModel()\r\n   at Microsoft.Extensions.ML.FileModelLoader.Start(String filePath, Boolean watchFile)\r\n   at Microsoft.Extensions.ML.BuilderExtensions.<>c__DisplayClass9_0`2.<FromFile>b__0(PredictionEnginePoolOptions`2 options, FileModelLoader loader)\r\n   at Microsoft.Extensions.Options.ConfigureNamedOptions`2.Configure(String name, TOptions options)\r\n   at Microsoft.Extensions.Options.OptionsFactory`1.Create(String name)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2..ctor(IServiceProvider serviceProvider, IOptions`1 mlContextOptions, IOptionsFactory`1 predictionEngineOptions)\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.<>c__DisplayClass1_0.<RealizeService>b__0(ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType)\r\n   at Microsoft.Extensions.DependencyInjection.ActivatorUtilities.GetService(IServiceProvider sp, Type type, Type requiredBy, Boolean isDefaultParameterRequired)\r\n   at lambda_method(Closure , IServiceProvider , Object[] )\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerActivatorProvider.<>c__DisplayClass4_0.<CreateActivator>b__0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerFactoryProvider.<>c__DisplayClass5_0.<CreateControllerFactory>g__CreateController|0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextResourceFilter>g__Awaited|24_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeFilterPipelineAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)\r\n```'"
586951635,4964,"b""Can't load type Microsoft.ML.IPredictorProducing`1[System.Single]""","b'### System information\r\n\r\n- Windows 10 Home\r\n- .NET : .NET Core 2.1\r\n- ML.NET : 1.5-preview2\r\n- ML.FastTree : 1.5-preview2\r\n\r\n### Issue:\r\n\r\nThe following error occurs when reading from disk:\r\n\r\nCan\'t load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nModel is available here: https://github.com/infiniteloopltd/ML-Problem\r\n\r\nMay be related to [PR4385](https://github.com/dotnet/machinelearning/issues/4385)\r\n\r\n### Source code / logs\r\n\r\n````\r\nvar mlContext = new MLContext();\r\nvar modelPath = @""MLModel.zip"";\r\nvar mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n````\r\n'"
586448076,4961,b'Hierarchical clustering ',b'Is hierarchical clustering supported/implemented? \r\n'
586012567,4960,b'Add root cause localization algorithm',b'### New Algorithm\r\n\r\nAdd a decision tree based root cause localization algorithmm to detect the root causes of an incident on multi-dimensional time series at a timestamp.\r\n'
585723799,4958,b'Add new mode for SR anomaly detector',"b""### New mode for exisiting SR algorithm\r\n\r\nBy old SR(Spectral Residual) anomaly detection, user could only get whether the point is an anomaly or not, but has no way to set sensitivity value for the anomaly. Sometimes an anomaly do happens, but with a low sensitivity setting, it may not be a valid alert. With this new option, the SR anomaly detector will allow user to set sensitivity, and output margin for the point according to the sensitivity, so that when you get an an anomaly point, you could judge if it's a valid alert by comparing the value with margin.\r\n### Backward compatibility\r\n\r\nThis change is backward compatible. By default the SR anomaly detector will use AnomalyOnly mode, which have exactly the same intput and output with original method. And the user could also load old saved models with the new detector.\r\n\r\n### Benchmark report\r\n#### 1. Dataset\r\nWe evaluate on the Yahoo timeseries dataset, which has 367 timeseries and 572966 points in total.\r\n#### 2. Evaluation method\r\n\r\nWe calculate the Precision, Recall, and F1 score using the method of\xef\xbc\x9a [https://github.com/iopsai/iops/tree/master/evaluation](https://github.com/iopsai/iops/tree/master/evaluation).\r\n\r\nThis change did not modify the original anomaly detection part, so the scores remains the same between AnomalyOnly mode and AnomalyAndMargin mode.\r\n\r\nAnd we ran the two modes of SR on a machine with Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz, 16GB memory, x64 operating system.\r\n#### 3. Score and Latency:\r\nMode | Precision | Recall | F1 | #TruePositive | #Positives | #Anomalies | Average latency to   predict the whole dataset | Fine tuned   parameters\r\n-- | -- | -- | -- | -- | -- | -- | -- | --\r\nAnomalyOnly mode | 0.601 | 0.670 | 0.634 | 2625 | 4370 | 3915 | 21167ms | WindowSize=64,   BackAddWindowSize=5, LookaheadWindowSize=5, AveragingWindowSize=3,   JudgementWindowSize=64, Threshold=0.45\r\nAnomalyAndMargin mode | 0.601 | 0.670 | 0.634 | 2625 | 4370 | 3915 | 41717ms | WindowSize=64,   BackAddWindowSize=5, LookaheadWindowSize=5, AveragingWindowSize=3,   JudgementWindowSize=64, Threshold=0.45, Sensitivity=90"""
584590656,4954,b'Unexpected WordEmbedding behavior as feature vector to a multi-class classifier',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n3.1.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nApply the WordEmbedding transformer to a multiclass prediction trainer.\r\n- **What happened?**\r\nCross validation resulted errors and NaN scores in multiclass predictions. \r\n- **What did you expect?**\r\nI expect to be able to use the word embedding feature vector, concatenate it with other features, and apply it to my classifier.\r\n\r\n### Source code / logs\r\n\r\nI\'m trying to use either downloaded FastText word vectors or the built-in ones. My Data Processing pipeline looks like this:\r\n\r\n` Append(mlContext.Transforms.Text.FeaturizeText(""FeaturesA"", options, ""Transcript""))\r\n .Append(mlContext.Transforms.Text.TokenizeIntoWords(""Tokens"", ""Transcript""))\r\n .Append(mlContext.Transforms.Text.ApplyWordEmbedding(""WordEmbeddings"", ""OutputTokens"", WordEmbeddingEstimator.PretrainedModelKind.GloVe50D))\r\n .Append(mlContext.Transforms.Text.ApplyWordEmbedding(""WordEmbeddings"", WORDVECTOR_PATH, ""Tokens""))\r\n.Append(mlContext.Transforms.NormalizeMinMax(""FeaturesA"", ""FeaturesA""))\r\n.Append(mlContext.Transforms.CopyColumns(""FeaturesB"", ""WordEmbeddings""))\r\n.Append(mlContext.Transforms.Concatenate(""Features"", ""FeaturesA"", ""FeaturesB""))\r\n.AppendCacheCheckpoint(mlContext);\r\n \r\nvar trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: ""Label"", featureColumnName: ""Features"")\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer);\'\r\n\r\nI don\'t get a functioning model, the prediction scores are NaN. I have a couple of questions on this.\r\nI understand that ApplyWordEmbedding returns an estimator, but I had it understood it outputs the average/min/max of all the token vectors, so word vector dimensions *3. \r\n\r\n1) Why isn\'t this usable as a feature vector into a classifier? If I apply another transform, like NormalizeMinMax, it suddenly works, but that\'s squashing the values in a way that doesn\'t make sense.\r\n\r\n2) Why is the model size so small? I expected that, as part of the transform, the whole wordvector model would be included, but it seems like if the data doesn\'t contain the token, it\'s not included in the model. That doesn\'t make word embeddings that useful as part of the point of word vectors is to provide a language model. If I want to classify a sentence containing cat as ""Animal"" but my data doesn\'t contain dog, the model should still be able to featurize dog as part of the sentence, but it doesn\'t seem like the model would be able to do that. Apologies if I\'m missing something very obvious, going through the WordEmbedding documentation has been a bit difficult for me.\r\n\r\n3) How can I select just the average features? It\'s not clear from the docs either.\r\n\r\nThank you!\r\n\r\n'"
583898371,4952,b'Request: expose Experiment._modelDirectory',"b'Hi all,\r\n\r\nIn AutoML, when configuring the `ExperimentSettings`, one can set a `CacheDirectory` where the intermediate models will be stored. However, the models are actually stored in a subfolder, called ""ExperimentXX"", where XX in an auto-increment integer in v.0.14.0, and some random characters in the recent preview releases. Navigating the source code, I found that this path is stored inside the private readonly field `_modelDirectory` belonging to the internal class `Experiment<TRunDetail, TMetrics>`. When running many experiments, there is no way to associate each experiment to each subfolder. \r\nIn my scenario, caching is necessary due to dataset size, and I would like to delete the temporary models at the end of the experiment without bothering other experiments that may be running simultaneously.\r\n\r\nThanks\r\n\r\n'"
583259931,4948,b'Wrong Transform Sample',"b'Sample shows `LoadImages` not `LoadRawImageBytes`\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 935b3cba-8385-d7b1-0d1c-92ce1e5b6bef\r\n* Version Independent ID: f4c01ba9-1f3e-03fa-48ea-1a62a13e11b4\r\n* Content: [ImageEstimatorsCatalog.LoadRawImageBytes(TransformsCatalog, String, String, String) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.imageestimatorscatalog.loadrawimagebytes?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/ImageEstimatorsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ImageEstimatorsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
583239359,4947,b'ordinal regression in ML.NET ',"b'The page [ordinal-regression.md](https://github.com/MicrosoftDocs/azure-reference-other/blob/master/studio-module-reference/ordinal-regression.md) describes the ordinal regression module. Is there a way to use this module/class in ML.NET in C#?\r\nAny hints are welcome.\r\nGreetings, Wido\r\n\r\nSee https://github.com/MicrosoftDocs/azure-reference-other/issues/90 for the original issue.\r\n'"
581622528,4944,b'How to train model from image bitmap',"b'### System information\r\nWindow 10\r\n\r\n### Issue\r\n- **What did you do?**\r\nHi everyone, I want to build a model from training data like this\r\n```\r\nclass ModelInput {\r\n    Bitmap image { get; set; }\r\n}\r\n```\r\nI cant find any example with input data as bitmap. How do i do that?\r\n'"
579694210,4937,"b""model.LastTransformer doesn't exist""","b""I was trying to implement Permutation Feature Importance (PFI) for Binary Classification.  But I was stuck on the following line of code.  This method simply doesn't exist.\r\n// Extract the predictor.\r\nvar linearPredictor = model.LastTransformer;\r\n\r\nI was following the example on https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet\r\n\r\nAny idea?\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\r\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\r\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**"""
579237248,4933,b'AccessViolationException PredictionEngine when 100-200 concurrent predictions running async',"b'### System information\r\n\r\n- Windows 10 64bit latest. 4 core CPU with hyperthreading.\r\n- Main app net48, that loads dependency in net472 that loads Microsoft.ML.Tensorflow 1.4: \r\n\r\n### Issue\r\n\r\n- Multiple concurrent tasks scheduled with `Task.WhenAll`. All tasks perform the same lambda, that involves calling PredictionEngineBase.Predict call. Number of tasks in parallel stacks window is about 100-200. \r\n- `AccessViolationException` thrown with message ""Attempted to read or write protected memory. This is often an indication that other memory is corrupt.""\r\n- As in case when number of tasks is not that big, ~30-50 I would expect no exception.\r\n\r\n### Source code / logs\r\nTwo different stack traces point to about same location in the code. The difference is that I rearrange a little async workflow by switch couple of async tasts around.\r\n```stacktrace\r\n   at System.SpanHelpers.CopyTo[T](T& dst, Int32 dstLength, T& src, Int32 srcLength)\r\n   at System.Span`1.TryCopyTo(Span`1 destination)\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.Predict(TfGpSeriesV2 series)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.CorrectInternal(T model, TfInput input)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.TimerAction[T](Func`1 func)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.EstimateAndEvaluate(TfInput input)\r\n```\r\n\r\n```stacktrace\r\n   at Tensorflow.c_api.TF_TensorByteSize(IntPtr tensor)\r\n   at Tensorflow.Tensor.get_bytesize()\r\n   at Tensorflow.Tensor.get_size()\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Estimator.TfEstimatorBase.Predict(TfSeries series) in C:\\src\\instaflow\\dotnet\\InstaFlow.TensorFlow\\Estimator\\TfEstimatorBase.cs:line 101\r\n```'"
579215175,4932,b'TensorFlowEstimator initialization info is missing',b'`TensorFlowEstimator` is not static and has no public constructors. Therefore the link to the documentation on how to initialize `TensorFlowEstimator` is essential.\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 7366dd71-3899-63fb-690e-5e0d11a5bf13\r\n* Version Independent ID: 4e44da94-51eb-2617-135a-eb71186b4da9\r\n* Content: [TensorFlowEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowestimator?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'
578330610,4926,b'SdcaMaximumEntropy trainer goes into an infinite loop if it takes already transformed data view as an input',"b'### System information\r\n\r\n- **OS version**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What I did**\r\n- create data-preparation pipeline \r\n- create trainer SdcaMaximumEntropy \r\n- execute pipeline, e.g. to debug transformed data view \r\n- add trainer to the pipeline and execute pipeline again, with the trainer included \r\n \r\n**What happened**\r\n\r\nIf I execute pipeline once, e.g. load from enumerables into data view and then execute entire transformation chain that includes transformations and trainer, everything works fine. \r\n\r\nIf I execute pipeline twice, first time - separately, then - as a part of entire transformation chain, it consumes 3GB of RAM memory out of 16GB available, then **training hangs indefinitely** and never ends. \r\nFixed this temporarily by changing this `MaximumNumberOfIterations` option, but not sure if it\'s a good idea...  \r\n\r\n**What I expect**\r\n\r\nI expect training to stop eventually, no matter how many times I execute pipeline. \r\n**Check the comment on the last line in the core below.**\r\n\r\n### Source code \r\n\r\nSource code is taken from this issue https://github.com/dotnet/machinelearning/issues/4903\r\n\r\n```C#\r\n\r\npublic IEstimator<ITransformer> GetPipeline(IEnumerable<string> columns)\r\n{\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .MapValueToKey(new[] { new InputOutputColumnPair(""Label"", ""Strategy"") })\r\n    .Append(Context.Transforms.Concatenate(""Combination"", columns.ToArray())) // merge ""dynamic"" colums into single property\r\n    .Append(Context.Transforms.NormalizeMinMax(new[] { new InputOutputColumnPair(""Features"", ""Combination"") })) // normalize merged columns into Features\r\n    .Append(Context.Transforms.SelectColumns(new string[] { ""Label"", ""Features"" })); // remove everything from data view, except transformed columns\r\n\r\n  return pipeline;\r\n}\r\n\r\npublic IEstimator<ITransformer> GetEstimator()\r\n{\r\n  var options = new SdcaMaximumEntropyMulticlassTrainer.Options\r\n  {\r\n    // MaximumNumberOfIterations = 100  // uncomment this to fix the issue\r\n  };\r\n\r\n  var estimator = Context\r\n    .MulticlassClassification\r\n    .Trainers\r\n    .SdcaMaximumEntropy(options)\r\n    .Append(Context.Transforms.Conversion.MapKeyToValue(new[]\r\n    {\r\n      new InputOutputColumnPair(""Prediction"", ""PredictedLabel"") // set trainer to use Prediction property as output\r\n    }));\r\n\r\n  return estimator;\r\n}\r\n\r\npublic void TrainModel(IEnumerable<string> columns, IEnumerable<InputModel> items)\r\n{\r\n  var estimator = GetEstimator();\r\n  var pipeline = GetPipeline(columns);\r\n  var inputs = Context.Data.LoadFromEnumerable(items);  // create view \r\n\r\n  // If I stop execution here, everything is ok\r\n\r\n  var model = pipeline.Append(estimator).Fit(inputs);  // works fine for the data view loaded from enumerables\r\n\r\n  // Data preparation pipeline is a part of a transformation chain, so I don\'t need next 2 lines, but I don\'t understand why it\'s causing the issue\r\n  \r\n  var pipelineModel = pipeline.Fit(inputs);  \r\n  var pipelineView = pipelineModel.Transform(inputs); // execute pipeline before the training\r\n  var model = pipeline.Append(estimator).Fit(pipelineView); // use transformed pipelineView instead of initial inputs and ... go into infinite loop ... why?\r\n}\r\n```'"
577382791,4923,b'How Transformer converts structured or custom data view type into a feature value?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Question\r\n\r\nWhen implementing a custom data view type, how does transformer know what to use as a ""value"" of this type? Does it use `GetHashCode()` method for this?\r\n\r\n### Source code \r\n\r\nConsidering, we have this custom image type with properties Width and Height. \r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageType.cs \r\n\r\nThen, we have this transformer code that merges several columns into one called `Features`. \r\nOne of these columns has type `ImageType`. \r\n\r\n```C#\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .Append(Context.Transforms.Concatenate(""Features"", new[] { ""ImageColumn"", ""Points"" }));\r\n```\r\n\r\nAs far as I understand, for ML engine to learn something from the provided data, `Features` should be an array of float values. So, the question is, how `ImageColumn` and `Points` will be converted to floats? \r\n\r\nAnother example that I found is this test for custom type registration. \r\nIt\'s also using GetHashCode method. \r\nhttps://github.com/dotnet/machinelearning/blob/release/1.5-preview/test/Microsoft.ML.Core.Tests/UnitTests/TestCustomTypeRegister.cs\r\n\r\n**I\'d like somebody to confirm that whatever is returned from GetHashCode method will be used in training the model.**\r\n\r\n```C#\r\npublic override int GetHashCode() // unique value for ImageType\r\n{\r\n    return Hashing.CombineHash(Height.GetHashCode(), Width.GetHashCode());\r\n}\r\n```\r\n\r\nI\'m asking because, e.g. OnnxMapType or OnnxSequenceType are completely different animals, whose GetHashCode method returns value based on a data type, not its value.\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.OnnxTransformer/OnnxMapType.cs\r\n\r\n```C#\r\npublic override int GetHashCode() // uniquer value for OnnxMapType\r\n{\r\n    return RawType.GetHashCode();\r\n}\r\n```\r\n\r\n**Does it mean that ONNX types cannot be used for training because their hash code is based on a System.Type instead of actual observation?**'"
576429602,4920,"b'Create DataView from IEnumerable<HashTable> or IEnumerable<IDictionary<string,dynamic>>'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What did you do?**\r\n\r\nTrying to create a data view from a list of IDictionary objects. \r\n\r\n- `IEnumerable<Expando>` or ...\r\n- `IEnumerable<HashTable>` or ...\r\n- `IEnumerable<Dictionary<string, object>>`\r\n- `IEnumerable<Dictionary<string, dynamic>>`\r\n\r\nIn this case, Keys would be used as column names, and Values as a data. \r\n\r\n**What happened?**\r\n\r\nWhen I add column names or implement ValueGetter, I need to specify a type of the column. \r\nThis code from ValueGetter gives an exception - could not cast type String to ReadOnlyMemory<char>\r\n\r\n```C#\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name]\r\n```\r\n\r\nIn this code from data view constructor I don\'t know how to set column type as ""dynamic"". \r\n\r\n```C#\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n\r\n    foreach (var k in items.First().Keys)\r\n    {\r\n      builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn\'t have type for its Values\r\n    }\r\n    \r\n    Schema = builder.ToSchema();\r\n  }\r\n```\r\n\r\n**What did you expect?**\r\n\r\n- how to define all columns as `object` or `dynamic` or ... \r\n- is it possible to implement custom column type for a data view, something like DataKind.MixedEnumerableFloatString or ... \r\n- define Switch-Case mapping between System.Type and DataView.Kind like in the pseudo-code below?\r\n\r\n```C#\r\npublic override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n{\r\n  // Ideally, would be good to have some generic delegate that could return some ""dynamic"" type instead of hardcoded type-casting \r\n  // If we iterate over data view collection using cursor, we don\'t need to know the type of the column \r\n\r\n  switch (column.GetType().Name)\r\n  {\r\n    case ""Float"": return (ValueGetter<float>)_enumerator.Current[column.Name];\r\n    case ""Boolean"": return (ValueGetter<bool>)_enumerator.Current[column.Name];\r\n    case ""String"": return (ValueGetter<ReadOnlyMemory<char>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  if (column is IEnumerable) \r\n  {\r\n    return (ValueGetter<IEnumerable<float>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name];\r\n}\r\n```\r\n\r\n### Source code / logs\r\n\r\nUsing this guide as an example. \r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet \r\n\r\n```C#\r\npublic class DictionaryView : IDataView\r\n{\r\n  public bool CanShuffle => false;\r\n  public long? GetRowCount() => 0;\r\n  public DataViewSchema Schema { get; }\r\n  public IEnumerable<HashTable> Items = null;\r\n\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n    builder.AddColumn(""Label"", TextDataViewType.Instance); // add multiple properties dynamically from IDictionary or HashTable item \r\n    \r\n    //foreach (var k in items.First().Keys)\r\n    //{\r\n    //  builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn\'t have type for its Values\r\n    //}\r\n    \r\n    //builder.AddColumn(""Value"", TextDataViewType.Instance);\r\n    Schema = builder.ToSchema();\r\n  }\r\n\r\n  public DataViewRowCursor GetRowCursor(IEnumerable<DataViewSchema.Column> columns, Random seed = null) => new Cursor(this);\r\n  public DataViewRowCursor[] GetRowCursorSet(IEnumerable<DataViewSchema.Column> columns, int n, Random seed = null) => new[] { GetRowCursor(columns, seed) };\r\n\r\n  private sealed class Cursor : DataViewRowCursor\r\n  {\r\n    private long _position = -1;\r\n    private bool _inactive = false;\r\n    private readonly IEnumerator<HashTable> _enumerator = null;\r\n\r\n    public override long Batch => 0;\r\n    public override long Position => _position;\r\n    public override DataViewSchema Schema { get; } = null;\r\n    public override bool IsColumnActive(DataViewSchema.Column column) => true;\r\n    public override ValueGetter<DataViewRowId> GetIdGetter() => (ref DataViewRowId id) => id = new DataViewRowId();\r\n\r\n    public Cursor(DataViewManager view)\r\n    {\r\n      _position = -1;\r\n      _enumerator = view.Items.GetEnumerator();\r\n\r\n      //_getters = new Delegate[]\r\n      //{\r\n      //  (ValueGetter<ReadOnlyMemory<char>>)LabelGetterImplementation\r\n      //};\r\n\r\n      Schema = view.Schema;\r\n    }\r\n\r\n    //private readonly Delegate[] _getters;\r\n    //private void LabelGetterImplementation(ref ReadOnlyMemory<char> value) => value = $""{ _enumerator.Current[""Label""] }"".AsMemory();\r\n\r\n    public override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n    {\r\n      if (_enumerator.Current == null)\r\n      {\r\n        MoveNext();\r\n      }\r\n\r\n      return (ValueGetter<TValue>)_enumerator.Current[column.Name]; // extract property by name from the current row of HashTable or IDictionary type\r\n\r\n      //return (ValueGetter<TValue>)_getters[column.Index];\r\n    }\r\n\r\n    protected override void Dispose(bool disposing)\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return;\r\n      }\r\n\r\n      if (disposing)\r\n      {\r\n        _enumerator.Dispose();\r\n        _position = -1;\r\n      }\r\n\r\n      _inactive = true;\r\n\r\n      base.Dispose(disposing);\r\n    }\r\n\r\n    public override bool MoveNext()\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return false;\r\n      }\r\n\r\n      if (_enumerator.MoveNext())\r\n      {\r\n        _position++;\r\n        return true;\r\n      }\r\n\r\n      Dispose();\r\n\r\n      return false;\r\n    }\r\n  }\r\n}\r\n```'"
575481194,4917,b'Error loading LightGBM model',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .Net Standard 2.0\r\n- **ML.Net version**: 1.4\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nBuild and trained a model with FastTree, saved it and finally load it and all worked. Changed to LightGBM and got an error when I try to load it.\r\n\r\nThe error is following:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n### Source code / logs\r\n\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Error during class instantiation\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\r\n  \r\n\r\n  This exception was originally thrown at this call stack:\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.TryGetIniters(System.Type, System.Type, System.Type[], out System.Reflection.MethodInfo, out System.Reflection.ConstructorInfo, out System.Reflection.MethodInfo, out bool)\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.RegisterAssembly(System.Reflection.Assembly, bool)\r\n\tMicrosoft.ML.ModelLoadContext.EnsureLoaderAssemblyIsRegistered(Microsoft.ML.Runtime.ComponentCatalog)\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModelCore<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, object[])\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModelOrNull<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, string, object[])\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 2:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 3:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 4:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 5:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 6:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n\r\n"""
575301003,4916,"b'how we show score,probability associated with Permutation Feature Importance (PFI) so end user can easily identify?'","b'@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\nreferences link:\r\n[how we show permutation slot associated with feature so end user easily identify? #4739](url)\r\n\r\nhow we can get score,probability of PFI?\r\nwe have get globally score and probability but we cannot get at PFI. how we can achieve this?'"
575279610,4915,b'how we can show confusion matrix of Permutation Feature Importance so end user easily identify?',"b'@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nhow we can show score,probability,confusion matrix of Permutation Feature Importance?'"
575074859,4914,b'WeakReference<IHost> memory leak?',b'### System information\r\n\r\n- **ML.NET Version**: 1.4.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n1. Created a pipeline of ImageLoadingEstimator + ImageResizingEstimator + ImagePixelExtractingEstimator + OnnxScoringEstimator.\r\n2. Create a ITransformer object by fitting the pipeline.\r\n3. Performed ITransformer.Transform multiple times.\r\n\r\nPS: Creating a PredictionEngine and performing PredictionEngine.Predict seems to lock the image as mentioned in issue [4585](https://github.com/dotnet/machinelearning/issues/4585 )\r\n\r\n- **What happened?** \r\n\r\nWeakReference<IHost> objects seems to accumulate.\r\n\r\nThe number of objects does not change even after performing GC.Collect()\r\n\r\nIs this possibly a memory leak?\r\nThe application is built is Release configuration.\r\n\r\n![image](https://user-images.githubusercontent.com/2994809/75835713-f44f3a80-5e02-11ea-8454-abea45097ecc.png)\r\n'
574872193,4912,b'how we show bins associated with numeric feature so end user can easily identify?',"b'@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nthanks for giving example for each feature weights.\r\n\r\nwith the references below link with subject lines:-\r\nhow we show permutation slot associated with feature so end user easily identify?\r\n[https://github.com/dotnet/machinelearning/issues/4739](url)\r\n\r\n![Picture1](https://user-images.githubusercontent.com/37444019/75969231-a286dd00-5ef4-11ea-955f-60900fc8fdbe.png)\r\n\r\nsuppose if this is yearatcomapny feature is having numeric data how we can get bins with model weights if this data is continuous then how we can get scatter points? \r\n\r\n2) how we can get  score,probability,confusion matrix of PFI also?'"
574851779,4911,b'Implementing a custom `IEstimator` and `ITransformer`',"b""I am currently working on a custom algorithm to transform my data for my application. I would like to include this transform into my pipeline so I can save and load it along with the model. \r\n\r\nI started out by implementing the `IEstimator<ITransformer>` and `ITransformer` interfaces. The `Fit(...)` and `Transform(...)` methods were fairly easy to implement but I'm struggling with how these models can be saved. The `ModelSaveContext` in the `Save(...)` method contains only `internal` properties which I cannot access.\r\n\r\nI realize I could technically implement a `CustomMappingEstimator` but it doesn't really appear to do anything during the `Fit` part of the training. My algorithm generates data (just a list of indexes to determine with features to use), which is then passed to the `ITransformer`.\r\n\r\nAre there examples of how to do this?"""
574621779,4910,b'Poor accuracy with non-US regional settings',"b""### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Core 2.2**: \r\n\r\n### Issue\r\nGetting poor accuracy running the training code on a system with non-US regional settings. The issue is number format. After replacing ',' as decimal symbol to '.' all works fine.\r\n\r\nAccuracy with ',' decimal symbol:\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/75774084-754cfa00-5d4f-11ea-929e-891b85175b34.png)\r\n\r\nAccuracy with '.' decimal symbol:\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/75774069-6bc39200-5d4f-11ea-9274-bafc5bb4789d.png)\r\n\r\nIs there some way to take a control of localization in .NET ML?\r\n\r\nThanks\r\nDamir"""
574566993,4909,b'AppendCacheCheckpoint is ignored at the beginning of the pipeline',"b'When an empty `EstimatorChain` is created, and `AppendCacheCheckpoint` is called before adding any estimators, then no caching occurs. \r\nThe expected behavior should be to either cache the data before fitting the first estimator in the chain, or disallow calling `AppendCacheCheckpoint` on empty chains, so that the user knows to cache the data explicitly before fitting. (I think the first solution is preferable, but open to other opinions).'"
574137098,4906,b'AutoML Regression Experiment fails after 67iterations',"b'Hi,\r\n\r\nWhen running a Regression Experiment, AutoML sistematically fails after 67 iterations, raising the Exception ""All instances skipped due to missing features"". By looking at other issues, I got the idea that the SmacSweeper could be the cause. This is also suggested by the stack strace:\r\n\r\n```\r\nin Microsoft.ML.Trainers.FastTree.DataConverter.MemImpl.MakeBoundariesAndCheckLabels(Int64& missingInstances, Int64& totalInstances)\r\n   in Microsoft.ML.Trainers.FastTree.DataConverter.MemImpl..ctor(RoleMappedData data, IHost host, Double[][] binUpperBounds, Single maxLabel, Boolean dummy, Boolean noFlocks, PredictionKind kind, Int32[] categoricalFeatureIndices, Boolean categoricalSplit)\r\n   in Microsoft.ML.Trainers.FastTree.DataConverter.Create(RoleMappedData data, IHost host, Int32 maxBins, Single maxLabel, Boolean diskTranspose, Boolean noFlocks, Int32 minDocsPerLeaf, PredictionKind kind, IParallelTraining parallelTraining, Int32[] categoricalFeatureIndices, Boolean categoricalSplit)\r\n   in Microsoft.ML.Trainers.FastTree.ExamplesToFastTreeBins.FindBinsAndReturnDataset(RoleMappedData data, PredictionKind kind, IParallelTraining parallelTraining, Int32[] categoricalFeaturIndices, Boolean categoricalSplit)\r\n   in Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3.ConvertData(RoleMappedData trainData)\r\n   in Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer.TrainModelCore(TrainContext context)\r\n   in Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   in Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   in Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   in Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   in Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerWhitelist)\r\n   in Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   in Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   in Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n```\r\nHowever, compared to the other issues, I\'m running a console application, I\'m loading data from database with no missing values. and I hopefully have the right NuGet dependencies:\r\n\r\n- Microsoft.ML.AutoML and Microsoft.ML.Recommender: 0.16.0\r\n- Microsoft.ML and all the other ML packages: 1.4.0\r\n\r\nI understand that the problem might be caused by some of the third-party libraries ML depends on, but isn\'t at least possible to ignore the exception thrown by a single trainer without compromising the whole regression experiment? I would like to be able to access the `BestRun` object and choose the best out of the first 67 experiments without having to look back at the `CacheDirectory`.\r\n\r\nIf necessary, I can generate a csv with all the data used for training.\r\n\r\nThanks\r\n'"
573516095,4905,b'LightGbm trainer fails in linux container',"b""### System information\r\n\r\n- mcr.microsoft.com/dotnet/core/aspnet:3.1\r\n- Version: 3.1.1 \r\n\r\n### Issue\r\n\r\n- Created application using AutoML. LightGbm trainer was selected.\r\n- Dockerized a webapp using mcr.microsoft.com/dotnet/core/aspnet:3.1 as base.\r\n- Expected: It trains.\r\n- Actual: Unable to load shared library 'lib_lightgbm' (see below).\r\n\r\nAs per https://github.com/dotnet/machinelearning/issues/4600 it appears that the trainer can be used if clang is present, for example:\r\n\r\n```\r\nRUN apt-get update && apt-get install -y \\\r\n    clang-3.9 \\\r\n && rm -rf /var/lib/apt/lists/*\r\n```\r\n\r\nHowever this doesn't seem like a satisfactory solution as it adds about a gigabyte to the image size. Surely there is a better answer?\r\n\r\n### Source code / logs\r\n\r\n```\r\nSystem.AggregateException: One or more errors occurred. (Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: liblib_lightgbm: cannot open shared object file: No such file or directory)\r\n ---> System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: liblib_lightgbm: cannot open shared object file: No such file or directory\r\n```"""
572912369,4903,b'Dynamic number of features for the trainer / schema',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Issue \r\nTrying to use variable number of properties (dynamic schema) for the trainer using dataView.SelectColumns. This creates correct trainer with only 2 features, but prediction engine still requires to specify original input model and uses all 10+ features, even though all features except selected 2 were set to 0.  \r\n\r\n### What did you do?\r\n- use input model with 10 features / properties\r\n- create data view and select only 2 of these features \r\n- use LGBM as a trainer \r\n- create 3 input items with labels - Strategy1, Strategy2, Strategy3 and train estimator \r\n- try to make prediction providing test item identical to Strategy3\r\n\r\n### What happened?\r\n- output schema in CreatePredictionEngine shows that there are 10+ columns, even though, when I created a data view for training, I selected only 2 features\r\n- result of prediction is always the same - Strategy1, most probably because trainer always compares 10+ features instead of 2, even though all features except selected 2 were set to 0 \r\n\r\n### What did you expect?\r\n- if estimator was trained to use only 2 features / input properties, then prediction engine should use provided data view schema and should also work only with 2 selected properties\r\n- in the code below I\'d like to make sure that properties Contrast, Param1 ... Param5 are ignored by prediction engine\r\n\r\n### Source code / logs\r\n\r\n```C#\r\npublic class MyInputModel\r\n{\r\n  [ColumnName(nameof(PredictorLabelsEnum.Strategy)), LoadColumn(0)]\r\n  public string Strategy { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Pitch)), LoadColumn(1)]\r\n  public float Pitch { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Energy)), LoadColumn(2)]\r\n  public float Energy { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Contrast)), LoadColumn(3, 8), VectorType(6)]\r\n  public float[] Contrast { get; set; }\r\n  \r\n  [ColumnName(nameof(InputNamesEnum.Param1)), LoadColumn(9)]\r\n  public float Param1 { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Param2)), LoadColumn(10)]\r\n  public float Param2 { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Param3)), LoadColumn(11)]\r\n  public float Param3 { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Param4)), LoadColumn(12)]\r\n  public float Param4 { get; set; }\r\n\r\n  [ColumnName(nameof(InputNamesEnum.Param5)), LoadColumn(13)]\r\n  public float Param5 { get; set; }\r\n}\r\n\r\npublic IEstimator<ITransformer> GetPipeline(IEnumerable<string> columns)\r\n{\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .MapValueToKey(new[] { new InputOutputColumnPair(""Label"", ""Strategy"") })  // use property ""strategy"" as categorizable label\r\n    .Append(Context.Transforms.Concatenate(""Combination"", columns.ToArray()))  // merge properties selected for analysis into ""Combination""\r\n    .Append(Context.Transforms.NormalizeMinMax(new[] { new InputOutputColumnPair(""Features"", ""Combination"") }));  // normalize selected properties as ""Features""\r\n\r\n  return pipeline;\r\n}\r\n\r\npublic IEstimator<ITransformer> GetEstimator()\r\n{\r\n  var estimator = Context\r\n    .MulticlassClassification\r\n    .Trainers\r\n    .LightGbm()\r\n    .Append(Context.Transforms.Conversion.MapKeyToValue(new[] { new InputOutputColumnPair(""Prediction"", ""PredictedLabel"") }));\r\n\r\n  return estimator;\r\n}\r\n\r\npublic byte[] SaveModel(IEnumerable<MyInputModel> items)\r\n{\r\n  var columns = new [] { ""Pitch"", ""Energy"" };\r\n  var estimator = GetEstimator();\r\n  var pipeline = GetPipeline(columns);\r\n  var sourceInputs = Context.Data.LoadFromEnumerable(items);\r\n  var inputs = Context\r\n    .Transforms\r\n    .SelectColumns(columns.Concat(new List<string> { ""Strategy"" }).ToArray()) // model has ~10 properties, we select only 2 of them \r\n    .Fit(sourceInputs)\r\n    .Transform(sourceInputs);\r\n\r\n  var pipelineModel = pipeline.Fit(inputs);\r\n  var pipelineView = pipelineModel.Transform(inputs);\r\n  var estimatorModel = pipeline.Append(estimator).Fit(inputs);\r\n  var model = new byte[0];\r\n\r\n  using (var memoryStream = new MemoryStream())\r\n  {\r\n    Context.Model.Save(estimatorModel, pipelineView.Schema, memoryStream);\r\n    model = memoryStream.ToArray();\r\n  }\r\n\r\n  return model;\r\n}\r\n\r\npublic string LoadModelAndEstimate(byte[] predictor)\r\n{\r\n  var prediction = string.Empty;\r\n\r\n  // let\'s make input identical to Strategy3, but somehow predicted result is still Strategy1\r\n\r\n  var input = new MyInputModel \r\n  {\r\n    Pitch = 50,\r\n    Energy = 10,\r\n    Contrast = new [] { 0, 0, 0, 0, 0, 0 },\r\n    Param1 = 0,\r\n    Param2 = 0,\r\n    Param3 = 0,\r\n    Param4 = 0,\r\n    Param5 = 0\r\n  };\r\n\r\n  using (var stream = new MemoryStream(predictor))\r\n  {\r\n    var model = Context.Model.Load(stream, out var schema) as TransformerChain<ITransformer>;\r\n    var chain = (model.LastTransformer as IEnumerable<ITransformer>).First() as MulticlassPredictionTransformer<OneVersusAllModelParameters>;\r\n    var chainModel = chain.Model as OneVersusAllModelParameters; // here I see only 3 properties with weights - Pitch, Energy, Label\r\n    var engine = Context.Model.CreatePredictionEngine<MyInputModel, MyOutputModel>(model); // here output schema shows 10+ columns, even though I expect 3\r\n    \r\n    // also tried to specify data view schema from the model explicitly for prediction engine\r\n    // var engine = Context.Model.CreatePredictionEngine<MyInputModel, MyOutputModel>(model, schema); \r\n    \r\n    prediction = engine.Predict(input);\r\n  }\r\n\r\n  return prediction;\r\n}\r\n```\r\n\r\n###  Example \r\n```\r\nvar testData = \r\n[\r\n  { \r\n    Strategy = ""Strategy1"",\r\n    Pitch = 115,\r\n    Energy = 50,\r\n    Contrast = new [] { 0, 0, 0, 0, 0, 0 },\r\n    Param1 = 0, Param2 = 0, Param3 = 0, Param4 = 0, Param5 = 0\r\n  },\r\n  {\r\n    Strategy = ""Strategy2"",\r\n    Pitch = 90,\r\n    Energy = 30,\r\n    Contrast = new [] { 0, 0, 0, 0, 0, 0 },\r\n    Param1 = 0, Param2 = 0, Param3 = 0, Param4 = 0, Param5 = 0\r\n  },\r\n  {\r\n    Strategy = ""Strategy3"",\r\n    Pitch = 50,\r\n    Energy = 10,\r\n    Contrast = new [] { 0, 0, 0, 0, 0, 0 },\r\n    Param1 = 0, Param2 = 0, Param3 = 0, Param4 = 0, Param5 = 0\r\n  }\r\n]\r\n```\r\n\r\n```\r\nvar trainData = \r\n[\r\n  {\r\n    Strategy = ""Strategy3"",\r\n    Pitch = 50,\r\n    Energy = 10,\r\n    Contrast = new [] { 0, 0, 0, 0, 0, 0 },\r\n    Param1 = 0, Param2 = 0, Param3 = 0, Param4 = 0, Param5 = 0\r\n  }\r\n]\r\n```'"
571749579,4898,b'What is the exact behavior of CreateTextLoader<TInput> when dataSample is given?',"b'We have this overload for `CreateTextLoader<TInput>`, where the schema is defined in `TInput`. \r\nhttps://github.com/dotnet/machinelearning/blob/c3d15927522ef9645dd335d9375fda15a2aaab34/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L90-L98\r\n\r\nThe `dataSample` argument is meant to be used to infer schema. Since `TInput` must contain at least one field, there is always at least one column in the schema. Then, this condition is never hit, and consequently, `dataSample` is never used to infer the schema with the `CreateTextLoader<TInput>` overload.\r\nhttps://github.com/dotnet/machinelearning/blob/c3d15927522ef9645dd335d9375fda15a2aaab34/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1118\r\n\r\n~Presence of the `dataSample` argument is confusing here as it implies that a sample can be provided. In other places, this sample is used to infer schema, so the user would expect this to be the case here as well, but `dataSample` is ignored here.~\r\n\r\n~I will update the documentation to reflect this, but this should be removed. Since this will be an API breaking change, this should be revisited for 2.0.~'"
571704768,4895,b'Please Expose ParquetDataLoader add implement ParquetWriter',"b'Apache Parquet is a popular data format in the industry.  It is used in ScikitLearn, Spark and a many other ML and big-data related software.   Currently ParquetReader is an internal class that is not exposed to end users.\r\nFeature Request:\r\n- Please provide ParquetReader to ML.NET users\r\n- Please implement ParquetWriter to ML.NET users.\r\n- Update Parquet.NET used by the framework to the latest as it offers bug fixes and perf improvements.\r\n\r\nThis would significantly simplify integration with various other ML and ETL  processes.\r\nThis would also provide a good industry-standard data interop between ML.NET and other ML and data tools, as an alternative to CSVs.'"
571653515,4894,b'how to add this option to LightGBM?',"b'Is there a reference for how to add options (like below) to: mlContext.BinaryClassification.Trainers.LightGBM(...  ?\n\n            var options = new LightGbmBinaryTrainer.Options\n            {\n                NumberOfThreads = 4,\n                UnbalancedSets = true,\n                EvaluationMetric = LightGbmBinaryTrainer.Options.EvaluateMetricType.AreaUnderCurve\n            };\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 6c83c9a9-84be-c526-4e54-62930bc16974\n* Version Independent ID: 63652672-e3bb-90c6-9f7d-470ed8dd32f5\n* Content: [LightGbmMulticlassTrainer.Options.UnbalancedSets Field (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmmulticlasstrainer.options.unbalancedsets?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmMulticlassTrainer+Options.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmMulticlassTrainer+Options.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'"
571499565,4892,b'AveragedPerceptron failure when used as a multiclass classifier with only one prediction specified in the input file',"b""When evaluating a model (MulticlassClassification.Evaluate) with testing data against a model created using the AveragedPerceptronTrainer in a multiclass scenario I get the failure shown below. This only occurs when the input data has a single prediction class and not multiple prediction classes.\r\n\r\n_'Schema mismatch for score column 'Score': expected vector of two or more items of type Single, got Vector<Single, 1>_\r\n\r\nIf I supply 1 to 'n' classes it should be consistent, """
570741185,4886,"b'Remove reference to ""Future"" plans in this doc'","b'https://docs.microsoft.com/en-us/dotnet/machine-learning/automate-training-with-cli#what-is-the-mlnet-command-line-interface-cli\r\n\r\nThe last bullet of the section above mentions ""Future"" plans, which is confusing for customers.'"
569550100,4880,b'ML.NET Model Builder Feedback',"b'I have been trying the ML.NET Model Builder Visual Studio Marketplace extension. I like it very much as I am able to jump into ML.NET and gain an understanding of the many moving parts with minimal effort. That said I have a few question.\r\n\r\n### Goal\r\nMy goal is to allow for the evaluation of text messages. I would like to score the message using multiple categorization and binary sentiment sets.  For instance I would like to give messages a emotional categorization, topic categorization, and N categorizations as I think of them.\r\n\r\nI would also like to do this with minimal code bloat, maximum code reuse, and support for future proofing (updating) my models without my current process of delete and create new-project.\r\n\r\nI understand this will take some work on my end refactoring the template projects, but I am struggling to envision what this refactor will look like. Additional resource links appreciated. \r\n\r\n### Solution Bloat / Model Reuse\r\nEvery time I go through the process of adding a new machine learning model, it produces two new projects. A model and a console app. The schema for some of these models are identical, and would like to consolidate them. Is this possible? What is the best strategy for consolidating this? \r\n\r\ne.g. A binary text model with csv for positive/negative sentiment and another csv for masculine/feminine sentiment?\r\n\r\n### Retraining / re-running the model\r\nWhen I run the console app that is generated, it completes really fast. The initial training for one of my data sets was 90 minutes long, but, the console when run on its own is only a second. \r\n\r\nI was thinking I could use this project for adding new / updated data to my model, but I am not so sure of that because it completes so fast. What is this project even doing? If I improve my data set, should I delete these template projects and restart the process!?\r\n\r\n'"
569234930,4874,b'MatrixFactorizationSimpleTrainAndPredict() on MacOS is broken',"b'The test MatrixFactorizationSimpleTrainAndPredict() is run on MacOS, but its calculate MSE is not checked. It is denoted as ""broken"" on MacOS.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fbd1b93065b451401b1e3276e5ac65b9f303f90b/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L135-L141'"
569152780,4872,b'Update docs to remove mentions of GPU support in ApplyOnnxModel',"b'When Onnxruntime released 1.0, they changed the API and broke the interface from 0.5 so that now it is not possible to ever exercise the GPU code path unless someone compiles ML.NET privately and links it to Microsoft.ML.OnnxRuntime.Gpu specifically.\r\n\r\nRelated to #4478 and #4656 '"
569016336,4871,b'How to get information about the model (number of hidden layer)?',"b""Hi,  \r\nI've trained and saved my model and everything is working fine. I just wonder if its possible to access information about the model like the number of nods in the different layers or the values of the weights?"""
568952270,4870,"b""Unable to load DLL 'CpuMathNative' ""","b""### System information\r\n\r\n-  Windows 10\r\n- **.NET  Framework 4.7.2\r\n\r\n### Issue\r\nUnable to load DLL 'CpuMathNative'\r\n\r\n\r\nWhat did you do?:\r\n\r\nCreated a new .net standard project, added ML.NET from nuget and added the project to my existing solution (.net Framework 4.7.2). Set to Any x64.\r\n\r\n\r\n"""
568711510,4868,b'Can not load model from local disk',"b'### System information\r\n\r\n- OS Version \xef\xbc\x9awindows 10.0.18363\r\n- .NET Version Info:   3.1.101\r\n\r\n### Issue\r\nHi, I used ml.net to build a movie Recommendation System Model, and when I finished build my model, I saved it into my local disk . And then when I load the model from local disk to predict my test data , it appeared this error  .\r\n![image](https://user-images.githubusercontent.com/5799487/75001311-f973c780-549b-11ea-9310-2c5b153ffe11.png)\r\nHere is my source code \xef\xbc\x9ahttps://github.com/Benknightdark/mlnet\r\n\r\n'"
568608867,4865,b'move from net core 3.0 to 3.1 on CI test',b'as net core 3.0 will be out of support soon\r\n'
568566107,4864,b'Is there a way to get individual metrics from a binaryclassifier in a multiclass scenario',"b""I'm using the averaged perceptron method in a mutliclas scenario. So my training data consists of predictions for more then one type, say types ABC, DEF and GHI. Once trained I can get the overall metrics but is there a way to get the metrics for ABC, DEF and GHI separately so that I can see where training was better or worse?"""
567371377,4856,b'Use ONNX model in ML.Net',"b""Hello,\r\nI created and trained a model in a keras.\r\nThe basis is a simple and standard task for the classification of irises. The CSV file looks like this\r\n\r\nSepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species\r\n5.1,3.5,1.4,0.2, iris-setosa\r\n\r\nModel in keras\r\nmodel = Sequential ()\r\nmodel.add (Dense (128, input_dim = 4, activation = 'relu'))\r\nmodel.add (Dense (Y.shape [1], activation = 'softmax'))\r\nmodel.compile (loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\r\n\r\nI understand that this problem can be solved without keras using ML.NET, but the principle of using keras models in ML.NET is important to me.\r\nNext I save the model to ONNX\r\nonnx_model = keras2onnx.convert_keras (model, model.name)\r\nonnx.save_model (onnx_model, 'model_.onnx')\r\n\r\nTell me how in the future, I can use this model in ML.NET, for predictions?\r\n\r\nThanks in advance."""
567137571,4852,b'Varying prediction error tolerances for different builds & their notations',"b'In our codebase there are instances where differing error tolerance values are defined for our different builds. **It is currently difficult for us to track where we have set these differing error tolerance values.**\r\n\r\nHere is one instances where the error tolerance values are different for Windows and Linux builds (a value for MacOS is defined as well, but is currently commented out):\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3dcac4909433cb4a7c70ed1cbd216c2150bedfe0/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L123-L146\r\n\r\nAlso in `MatrixFactorizationTests.cs`, there are 3 different cases (in addition to the example above) where varying prediction errors are asserted:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3dcac4909433cb4a7c70ed1cbd216c2150bedfe0/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L356-L357\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3dcac4909433cb4a7c70ed1cbd216c2150bedfe0/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L469-L470\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3dcac4909433cb4a7c70ed1cbd216c2150bedfe0/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L609-L610\r\n\r\nIt would be a good idea to track these prediction error rates, as this way we can easily find where we\'ve defined varying tolerances for different builds.\r\n\r\nThe best to do this seems to be making a static class (for example, called `TestingTolerance`) with data structures suitable for storing varying tolerances based on (1) build OS, (2) given unit test, and (3) exact assertion in a given unit test.\r\n\r\nAnother way to do this is by adding an extra trait to each function that has varying tolerances, and then adding logs stating varying tolerances are occurring:\r\n\r\n```\r\n[TestCategory(""VaryingTolerances"")]\r\npublic void MatrixFactorizationSimpleTrainAndPredict() {\r\n...\r\nConsole.WriteLine(""Tolerance values for Windows, MacOS, and Linux builds are different."");\r\n...\r\n}\r\n```'"
566982604,4851,b'Extract MaximumEntropyModelParameters from MulticlassPredictionTransformer ITransformer model',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**: .NET Framework 4.7.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI want to re-train multi-class (`LbfgsMaximumEntropyMulticlassTrainer`).\r\n- **What happened?**\r\nI train and load model, but i cannot extract `MaximumEntropyModelParameters`.\r\n- **What did you expect?**\r\nI want to extract `MaximumEntropyModelParameters` my pre-trained model.\r\nI want to retrain my model by using `LbfgsMaximumEntropyMulticlassTrainer.Fit(IDataView, MaximumEntropyModelParameters)` method.\r\n\r\nSimilar to #4099 but I\'m using only one model\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```\r\n//Create a ITransformer from my IDataView\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey()\r\n    .Append(mlContext.Transforms.Text.FeaturizeText())\r\n    .AppendCacheCheckpoint(mlContext);\r\nvar trainingPipeline = pipeline.Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy())\r\n    .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\nITransformer trainedModel = trainingPipeline.Fit(splitTrainSet);\r\n\r\n//Try to retrain it by extracting the parameters\r\nvar originalModelParameters = ((MulticlassPredictionTransformer<object>)model).Model as MaximumEntropyModelParameters;\r\nmodel = mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy().Fit(transformedNewData, originalModelParameters);\r\n```\r\n\r\n### Logs\r\n\r\n> System.InvalidCastException: \'Unable to cast object of type \'Microsoft.ML.Data.TransformerChain`1[Microsoft.ML.ITransformer]\' to type \'Microsoft.ML.Data.MulticlassPredictionTransformer`1[System.Object]\'.\'\r\n'"
566695562,4850,b'CentOS CI builds failing due to insufficient storage on agent machines/pipelines',"b'As seen in the latest builds of PRs #4849 and #4846, the CentOS debug and release builds are failing due to out-of-memory issues.\r\n\r\nThe debug build on Centos_x64_NetCoreApp30 is failing due to insufficient storage during the phase of [building packages](https://dev.azure.com/dnceng/public/_build/results?buildId=525273&view=logs&j=162a17ee-8d83-5c8b-18ac-724700af9c9e&t=4fd67eef-610a-5fe5-ffee-3a77270fec0b&l=386). The release build on Centos_x64_NetCoreApp30 is also failing due to insufficient storage, but this time this happens when [benchmark data is being downloaded](https://dev.azure.com/dnceng/public/_build/results?buildId=525273&view=logs&j=180e3155-cea9-5b82-0850-5dfb7f33e22f&t=594e75e0-8e83-50e9-4d0d-362f44590401&l=41). \r\n\r\nCentOS debug build output:\r\n\r\n> 2020-02-18T05:02:16.7235083Z Build FAILED.\r\n> 2020-02-18T05:02:16.7235297Z \r\n> 2020-02-18T05:02:16.7241364Z /__w/1/s/Tools/dotnetcli/sdk/3.0.100/Sdks/NuGet.Build.Tasks.Pack/build/NuGet.Build.Tasks.Pack.targets(198,5): error : No space left on device [/__w/1/s/pkg/Microsoft.ML.DnnImageFeaturizer.ResNet101/Microsoft.ML.DnnImageFeaturizer.ResNet101.nupkgproj]\r\n> 2020-02-18T05:02:16.7241930Z /__w/1/s/Tools/dotnetcli/sdk/3.0.100/Sdks/NuGet.Build.Tasks.Pack/build/NuGet.Build.Tasks.Pack.targets(198,5): error : No space left on device [/__w/1/s/pkg/Microsoft.ML.DnnImageFeaturizer.ResNet101/Microsoft.ML.DnnImageFeaturizer.ResNet101.symbols.nupkgproj]\r\n> 2020-02-18T05:02:16.7242290Z /__w/1/s/Tools/dotnetcli/sdk/3.0.100/Sdks/NuGet.Build.Tasks.Pack/build/NuGet.Build.Tasks.Pack.targets(198,5): error : No space left on device [/__w/1/s/pkg/Microsoft.ML.DnnImageFeaturizer.ResNet50/Microsoft.ML.DnnImageFeaturizer.ResNet50.nupkgproj]\r\n> 2020-02-18T05:02:16.7242672Z /__w/1/s/Tools/dotnetcli/sdk/3.0.100/Sdks/NuGet.Build.Tasks.Pack/build/NuGet.Build.Tasks.Pack.targets(198,5): error : No space left on device [/__w/1/s/pkg/Microsoft.ML.DnnImageFeaturizer.ResNet50/Microsoft.ML.DnnImageFeaturizer.ResNet50.symbols.nupkgproj]\r\n> 2020-02-18T05:02:16.7243007Z /__w/1/s/Tools/dotnetcli/sdk/3.0.100/Sdks/NuGet.Build.Tasks.Pack/build/NuGet.Build.Tasks.Pack.targets(198,5): error : No space left on device [/__w/1/s/pkg/Microsoft.ML.Mkl.Redist/Microsoft.ML.Mkl.Redist.nupkgproj]\r\n\r\nCentOS release build output:\r\n\r\n> Downloading from ""https://aka.ms/mlnet-resources/benchmarks/digits.csv"" to ""/__w/1/s/test/data/external/digits.csv"" (264,712 bytes).\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTest240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KTest240kRows.tsv"" (172,985,414 bytes).\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTrain720kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KTrain720kRows.tsv"" (519,712,566 bytes).\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): warning MSB3924: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"". Beginning retry 2 in 5000ms. No space left on device\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): warning MSB3924: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"". Beginning retry 3 in 5000ms. No space left on device\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): warning MSB3924: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"". Beginning retry 4 in 5000ms. No space left on device\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): warning MSB3924: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"". Beginning retry 5 in 5000ms. No space left on device\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): warning MSB3924: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"". Beginning retry 6 in 5000ms. No space left on device\r\n>   Downloading from ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"" to ""/__w/1/s/test/data/external/MSLRWeb10KValidate240kRows.tsv"" (169,246,139 bytes).\r\n> /__w/1/s/build.proj(90,5): error : MSB3923: Failed to download file ""https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv"".  No space left on device\r\n> \r\n> Build FAILED.\r\n'"
565742168,4848,b'Misleading error message when a column is not found',"b""- version 1.5.0-preview\r\n\r\nWhen I tried to create a prediction engine for one of my first models, I received an `ArgumentOutOfRangeException`. I think the error message means to tell me that the column named 'Features1' with the role 'Feature' was not found.\r\nI would have expected to see my input, 'Features1', in quotes, rather than the column role, which should only take fixed values anyway.\r\n\r\n_Feature column 'Features1' not found_ would have come more naturally to me.\r\n\r\n\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/78c406cf1f4a72751e389074e2f88574fafee8ea/src/Microsoft.ML.Core/Data/RoleMappedSchema.cs#L229\r\n\r\n```Csharp\r\nAn exception of type 'System.ArgumentOutOfRangeException' occurred in Microsoft.ML.Core.dll but was not handled in user code: 'Features1 column 'Feature' not found'\r\n   at Microsoft.ML.Data.RoleMappedSchema.MapFromNames(DataViewSchema schema, IEnumerable`1 roles, Boolean opt)\r\n   at Microsoft.ML.Data.RoleMappedSchema..ctor(DataViewSchema schema, IEnumerable`1 roles, Boolean opt)\r\n   at Microsoft.ML.Data.GenericScorer.Bindings.Create(IHostEnvironment env, ISchemaBindableMapper bindable, DataViewSchema input, IEnumerable`1 roles, String suffix, Boolean user)\r\n   at Microsoft.ML.Data.GenericScorer.Bindings.ApplyToSchema(IHostEnvironment env, DataViewSchema input)\r\n   at Microsoft.ML.Data.GenericScorer..ctor(IHostEnvironment env, GenericScorer transform, IDataView data)\r\n   at Microsoft.ML.Data.GenericScorer.ApplyToDataCore(IHostEnvironment env, IDataView newSource)\r\n   at Microsoft.ML.Data.RowToRowScorerBase.ApplyToData(IHostEnvironment env, IDataView newSource)\r\n   at Microsoft.ML.Data.PredictionTransformerBase`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngine`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.ModelOperationsCatalog.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n```"""
565404883,4843,b'Is this anomaly detection approach doable?',"b'First time creating an issue, apologies in advance if I\'m doing it wrong.\r\n\r\nAnomaly detection in general seems to go against my expectations. I\'ve looked at every example I can find for anomaly detection and they all follow the pattern of having some dataset that the anomaly detector examines to see what anomalies it can find within that data set.\r\n\r\nMy needs are different than that. I want to provide the anomaly detector a set of data that has no anomalies. This dataset should be used to train and create a model for comparison against a second data sets to see what anomalies it detects in this second data set. \r\n\r\nThus far, my attempts have ended up with an anomaly detector that finds ""anomalies"" in my first data set, which is not valid in my scenario. The first data set should be considered all valid (non-anomaly) values, no matter what seemingly spikes or change points may exist within it. The second data set should be examined for spikes or change points through the lens of was seen in the first data set.\r\n\r\nCan this be done? I\'ve been trying to make it work on my own but it seems like either this is not how anomaly detection was intended to work, or I\'m completely off base in my implementation.'"
565231976,4842,b'how to generate tensorflow inception-v1 model using ML.NET?',"b'Hi, I am using ML.NET to classify image, both online and offline mode.\r\nonline mode:  app send image to web server, the server classify image.\r\noffline mode: app download trained model, and classify image locally.\r\n\r\nhow to generate tensorflow inception-v1 model using ML.NET? \r\n'"
565046323,4840,b'generate test failure rate report using runfo tool',b'https://github.com/jaredpar/random/blob/master/dotnet/Azure/runfo/README.md'
565046013,4839,b'update build to include a binlog instead of the plain text err/wrn/out files',b'http://msbuildlog.com/ \r\n'
564645526,4832,b'how we get roc points to draw roc graph?',"b'@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\nhow we get roc points to draw roc graph?'"
563016169,4825,b'Expose Ensembling in ML.NET ',"b'The ensembles in Microsoft.ML.Ensemble/OutputCombiners would be very useful for our use cases for regressions. Can you help exposing them into ML.NET ?\r\n\r\nMost useful would be stacking and weighted average, and of course average and median.'"
562631891,4821,b'AutoML throws several OperationCanceledExceptions',"b'Greetings,\r\n\r\nwhen using any AutoML API project such as [Sentiment Analysis for User Reviews](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/BinaryClassification_AutoML), several exceptions are thrown in the background.\r\n\r\nThis is probably due to some internal cancellation and has no additional negative impacts but is pretty ugly in the debugger.\r\n\r\nWould it be feasible to wrap this cancellation in a `Task.ContinueWith()` in order to keep the debugger clean?\r\n\r\nKeep up the great work!'"
562047243,4819,b'Shuffle input cursor reader failed with an exception in ml.net 1.4.0',"b'- Windows 10 x64\r\n- NET Framework 4.7.2, ML.Net 1.4.0\r\n\r\nI create project for multiclass classification, some code:\r\n`var trainingDataView = mlContext.Data.LoadFromEnumerable(allTrainData);\r\n\r\nvar trainingPipeline = mlContext.Transforms.Conversion.MapValueToKey(inputColumnName: ""IdCategory"", outputColumnName: ""Label"")\r\n\t.Append(mlContext.Transforms.Text.FeaturizeText(inputColumnName: ""HeaderProduct"", outputColumnName: ""HeaderProductFeaturized""))\r\n\t.Append(mlContext.Transforms.Text.FeaturizeText(inputColumnName: ""DescriptionProduct"", outputColumnName: ""DescriptionProductFeaturized""))\r\n\t.Append(mlContext.Transforms.Concatenate(""Features"", ""HeaderProductFeaturized"", ""DescriptionProductFeaturized""))\r\n\t.Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy())\r\n\t.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nvar trainedModel = trainingPipeline.Fit(trainingDataView);`\r\n\r\nI try train model and have Exception:\r\n Shuffle input cursor reader failed with an exception, (   in Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore()\r\n   in  Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   in  Microsoft.ML.Trainers.TrainingCursorBase.MoveNext()\r\n   in  Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   in  Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   in  Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   in  Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n\r\nI downgraded the version ml.net to 1.3.1 an all worked fine.\r\na little later, I upgraded the version to 1.5.0-preview and all worked fine.\r\n'"
561572565,4807,b'ImageClassifier with ExponentialLRDecay: metrics not updated/calculated during validation',"b'### System information\r\n\r\n- **OS version**: Windows 10 Pro 18363\r\n- **.NET Version**:  Core 2.1\r\n- **Platform**: x64\r\n- **ML.NET version**: 0.15-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n  I am trying to train an image classifier that makes use of `ExponentialLRDecay`.\r\n  I would like to see the metrics for training and validation for each epoch.\r\n\r\n  ```csharp\r\n  var options = new ImageClassificationTrainer.Options()\r\n  {\r\n    LearningRateScheduler = new ExponentialLRDecay(),\r\n    ValidationSetFraction = 0.1f,\r\n    MetricsCallback = (metrics) => Console.WriteLine(metrics  + $""   CrossEntropy: {metrics.Train.CrossEntropy}, LearningRate: {metrics.Train.LearningRate})\r\n  };\r\n  var model = mlContext.MulticlassClassification.Trainers.ImageClassification(options);\r\n  ```\r\n\r\n  (I added `  + $""   CrossEntropy: {metrics.Train.CrossEntropy}, LearningRate: {metrics.Train.LearningRate}""`, because the crossentropy and learning rate are not printed by default for the validation set.)\r\n\r\n- **What happened?**\r\n  * The learning rate is not updated for the validation set (seen on every even row in the image).\r\n  * The cross-entropy is not calculated for the validation set (seen on every even row in the image).\r\n  * The learning rate is not updated after the second epoch like the default value of `2` for `numEpochsPerDecay ` in `ExponentialLRDecay()`, but after the first instead (seen on the third row in the image). After that, the learning rate is correctly updated every 2 epochs. I\'m not sure if this is the expected behavior.\r\n\r\n  ![image](https://user-images.githubusercontent.com/20618666/74023199-60bf5100-499f-11ea-8511-c003965b1c90.png)\r\n\r\n- **What did you expect?**\r\n  * I expected a decaying learning rate in the validation step, equal to the one in the training step.\r\n  * I expected the cross-entropy to be calculated in the validation step. The model with the highest `Accuracy` and lowest `CrossEntropy` are the best, so if 2 models perform equally well in terms of accuracy, the one with the lowest cross-entropy on the validation set should be picked.\r\n  * Further, I expected the learning rate to start decaying after the 2nd epoch.'"
561209093,4796,b'See also xref  is broken',"b'The xref under ""See also"" appears as plaintext, incorrectly\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 16bcaa45-114e-32f9-c72c-61339bf5aa65\n* Version Independent ID: 28a14833-c964-a8ef-aabe-7118e0ffe48c\n* Content: [ApproximatedKernelMappingEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.approximatedkernelmappingestimator?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/ApproximatedKernelMappingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/ApproximatedKernelMappingEstimator.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'"
561109542,4795,b'Microsoft.ML.OnnxRuntime.OnnxRuntimeException: 1 : FAIL : Failed to find kernel for Neg',"b'### System information\r\nWindows 10\r\nMicrosoft.ML v.15.0/preview\r\nMicrosoft.Ml.OnnxRuntime v1.1.1\r\n.NET Framework 4.8\r\n\r\n### Issue\r\nI amtrying to run prediction engine using a pretrained .onnx model in ML.net.  The Onnx model is Unet architecture and I used latest master build of ONNX and ONNXRUNTIME for creating .onnx file.\r\n\r\nOn calling ""mlContext.Transforms.ApplyOnnxModel"" i get RuntimeException (refer to figure attached)\r\n\r\n![mlerror](https://user-images.githubusercontent.com/54295010/73954140-b1806c80-4901-11ea-95b3-8fd3a19143ed.PNG)\r\n\r\nI had the same error in Onnxrumtime beacuse of int64 support unavailability. Now they have added this support. Refer to these links \r\nhttps://github.com/microsoft/onnxruntime/issues/2875\r\nhttps://github.com/microsoft/onnxruntime/pull/2945\r\n\r\n\r\nI am not sure if its same problem. Any leads on this will be appreciable :)\r\n\r\nThank you.'"
561008224,4789,b'BaseTestPredictorsMaml.Run_Test() is broken',"b""I am trying to test a previously saved LightGBM model to see if it outputs expected baseline figures. However, the baseline that `Run_Test()` generates is as follows:\r\n\r\n> ***** Unexpected failure. Please refer to https://aka.ms/MLNetIssue to file an issue with details *****\r\n> \r\n> ***** Error log has been saved to 'C:\\Users\\mubal\\AppData\\Local\\Temp\\TLC\\Error_20200206_193056_51208d31-0f5c-4ff9-b7a8-7f853d81fc14.log', please refer to https://aka.ms/MLNetIssue to file an issue with details *****\r\n> \r\n> ===== Begin detailed dump =====\r\n> \r\n> (1) Unexpected exception: Assert failed: Assertion Failed\r\n> \r\n> Expected: True\r\n> \r\n> Actual:   False, 'Xunit.Sdk.TrueException'\r\n> \r\n>    at Xunit.Assert.True(Nullable`1 condition, String userMessage) in C:\\Dev\\xunit\\xunit\\src\\xunit.assert\\Asserts\\BooleanAsserts.cs:line 95\r\n> \r\n>    at Microsoft.ML.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs:line 71\r\n> \r\n>    at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 781\r\n> \r\n>    at Microsoft.ML.Runtime.Contracts.DbgFail(IExceptionContext ctx) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 790\r\n> \r\n>    at Microsoft.ML.Runtime.Contracts.Assert(Boolean f) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 839\r\n> \r\n>    at Microsoft.ML.Runtime.ComponentCatalog.ParseArguments(IHostEnvironment env, Object args, String settings, String name) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 1067\r\n> \r\n>    at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 1036\r\n> \r\n>    at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 993\r\n> \r\n>    at Microsoft.ML.Tools.Maml.MainCore(IHostEnvironment env, String args, Boolean alwaysPrintStacktrace) in C:\\Users\\mubal\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 129\r\n> \r\n> ====== End detailed dump =====\r\n\r\n\r\nMy code where this happens is:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/0ea84a6f3fb2cde29f70ec638c3f06317028225e/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs#L489-L511\r\n\r\nI've confirmed that my model and and baseline files exist, and that my model is valid.\r\n\r\nPerhaps this issue was known to previous ML.NET developers as Run_Test() and its dependent Run_TrainSaveTest() are not used anywhere in the codebase. However, this is the only way (as far as I know) i n which one can test the baseline output of a model with `TestDatasets` and `TestLearners`.\r\n\r\nBecause Run_Test() is broken, Run_TrainSaveTest() is also broken.\r\n\r\nPS: I discovered this while trying to add a unit test in my PR #4695  to check the run-time behavior of LightGBM does not change by modifying the flags used by LightGBM with CursOpt.AllFeatures, and that this change does not affect the features extracted during validation. """
560786071,4788,b'Enable parallelism in Windows test agent if parallelism not causing network issue',"b""Related to this PR: https://github.com/dotnet/machinelearning/pull/4776 \r\n\r\nWe met download/restore timeout issue on some build agent, one possible reason cause this is restore consuming too much connections and affected the network performance.\r\n\r\nIn this PR we are trying to disable parallelism in all test agents to see if we mitigate the issue, otherwise we should enable parallelism again in windows test agent as according to @sharwell 's experience parallelism should not cause problem.\r\n"""
559827625,4778,b'Re-training an ImageClassificationTrainer',"b'### System information\r\n\r\n- **OS version**: Windows 10 Pro 18363\r\n- **.NET version**: Core 2.1\r\n- **Platform**: x64\r\n- **ML.NET version**: 0.15-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI started working from [this example](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.visioncatalog.imageclassification?view=ml-dotnet#Microsoft_ML_VisionCatalog_ImageClassification_Microsoft_ML_MulticlassClassificationCatalog_MulticlassClassificationTrainers_Microsoft_ML_Vision_ImageClassificationTrainer_Options_), to perform multiclass classification using transfer learning.\r\nTraining, saving, loading, and consuming the model works as intended.\r\nNow I am trying to train further on that trained model (re-training), using these 2 steps:\r\n  * [Extract pre-trained model parameters](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net#re-train-model)\r\n  * [Re-train model](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net#re-train-model)\r\n\r\n  Similar to those steps, I came up with this piece of code:\r\n\r\n```csharp\r\n // Extract trained model parameters\r\nImageClassificationModelParameters originalParameters = ((ISingleFeaturePredictionTransformer<object>)trainedModel).Model as ImageClassificationModelParameters;\r\n// Retrain model\r\nMulticlassPredictionTransformer<ImageClassificationModelParameters> trainedModelFurther = mlContext.MulticlassClassification.Trainers.ImageClassification().Fit(trainImages, originalParameters);\r\n```\r\n\r\n- **What happened?**\r\nAt the end of the last line, the method `Fit(IDataView, ImageClassificationModelParameters)` does not exist ([docs](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.vision.imageclassificationtrainer?view=ml-dotnet#methods)).\r\n\r\n- **What did you expect?**\r\n  * First of all, I expected a similar method as `Fit(IDataView, LinearModelParameters)` in `OnlineGradientDescentTrainer` ([docs](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.onlinelineartrainer-2.fit?view=ml-dotnet#Microsoft_ML_Trainers_OnlineLinearTrainer_2_Fit_Microsoft_ML_IDataView_Microsoft_ML_Trainers_LinearModelParameters_)), `Fit(IDataView, MaximumEntropyModelParameters)` in `LbfgsMaximumEntropyMulticlassTrainer` ([docs](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lbfgsmaximumentropymulticlasstrainer.fit?view=ml-dotnet#Microsoft_ML_Trainers_LbfgsMaximumEntropyMulticlassTrainer_Fit_Microsoft_ML_IDataView_Microsoft_ML_Trainers_MaximumEntropyModelParameters_)), or other trainers to exist.\r\nI believe the `ImageClassificationTrainer` makes use of an `LbfgsMaximumEntropyMulticlassTrainer` behind the scenes, to classify the extracted features from the images.\r\n\r\n  * Secondly (unrelated), the method `Fit(IDataView, IDataView)` in `ImageClassificationTrainer` seems unnecessary, as you can already specify the validation set (or a fraction of the training set to use for validation) in `ImageClassificationTrainer.Options`.\r\n\r\n### Question\r\n\r\nIs it possible to re-train this model on new data, maybe using some extra steps to convert the `ImageClassificationTrainer` to an `LbfgsMaximumEntropyMulticlassTrainer`? If not, when is this functionality expected?'"
559700004,4777,b'How to determine optimal number of clusters with K-Mean',"b'### System information\r\n\r\nML.NET 1.4.0\r\n\r\n### Issue\r\n\r\nI need to know how to find optimal number of clusters for K-Mean for the dataset, there are some methods that can be used like Silhouette Method or Gap analysis or Elbow methods. Does ML.NET have any API that i can use for identifying optimal K for the dataset or any way i can find.  Attaching my dataset also. It will be very helpful for my use case.\r\n\r\n[InputforClustering.xlsx](https://github.com/dotnet/machinelearning/files/4153355/InputforClustering.xlsx)\r\n\r\n\r\n### Source code / logs\r\n\r\n'"
559379667,4773,b'async code will cause dead lock with xunit',b'https://github.com/xunit/xunit/issues/864\r\nhttps://github.com/xunit/xunit/issues/1935\r\n\r\nCalling .Wait() causes deadlocks.\r\nCalling .Result causes deadlocks.\r\nCalling .GetAwaiter().GetResult() causes deadlocks.\r\n\r\nwe need to fix the way we use in async to prevent dead lock with xunit'
558998101,4769,b'Issue on MacOs',"b""There's an issue on MacOs while trying to replicate the example.\n\nException has occurred: CLR/System.DllNotFoundException\nAn unhandled exception of type 'System.DllNotFoundException' occurred in Microsoft.ML.TimeSeries.dll: 'Unable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found'\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: be5ae8c9-5caa-4f64-8587-d8f8910ce911\n* Version Independent ID: 0810e529-6f15-d64d-94a3-7e93c1b67daa\n* Content: [TimeSeriesCatalog.ForecastBySsa(ForecastingCatalog, String, String, Int32, Int32, Int32, Int32, Boolean, Single, RankSelectionMethod, Nullable&lt;Int32&gt;, Nullable&lt;Int32&gt;, Boolean, Boolean, Nullable&lt;GrowthRatio&gt;, String, String, Single, Boolean) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseriescatalog.forecastbyssa?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/TimeSeriesCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TimeSeriesCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**"""
558886255,4768,b'KMean clustering ML.Net vs scikit-learn (Python)',"b'### System information\r\n\r\nML.NET version is 1.4.0\r\n[PresentationMatrix.xlsx](https://github.com/dotnet/machinelearning/files/4146625/PresentationMatrix.xlsx)\r\n\r\n\r\n\r\n### Issue\r\n\r\nWe try to do KMean clustering for the attached data (PresentationMatrix.csv) while doing so seeing a difference in behavior between ML.Net and scikit-learn (Python).  With ML.net i am keep getting error ""Failed to initialize clusters: too few examples"", when i try number of clusters as 60 or above, sometimes even with lesser number of clusters, where as with Scikit-learn able to proceed with out any error for more than 60 Clusters.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
558815683,4767,b'SDCA seems to contain a livelock',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried to call the SDCA method and fit the model.\r\n- **What happened?**  When I call the SDCA method in the pipeline, the code wont get past the Fit method. Noticeable is the fact that the CPU percentage wont go down, so its still calculating\r\n\r\nHowever there is no exception. The program just freezes\r\n\r\n### Source code / logs\r\n![grafik](https://user-images.githubusercontent.com/48481041/73623012-b14f4b00-463b-11ea-9531-7d7390a4980f.png)\r\n\r\nCPU usage:\r\n![grafik](https://user-images.githubusercontent.com/48481041/73623037-cd52ec80-463b-11ea-9ed8-3f6a0122564d.png)\r\n\r\n'"
558404588,4760,b'Set seed in PredictorTests',"b'All the tests in [TestPredictors.cs](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs) call some combination of `RunAllTests`, `RunOneAllTests`, `Run_TrainTest`, and `Run_CV`.\r\nhttps://github.com/dotnet/machinelearning/blob/76777592cf7e094f5361285bc64111d09d5bdb7c/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs#L95\r\nwhere `ctx.ExtraArgs` is used to add additional arguments when building the `maml` command to be run\r\nhttps://github.com/dotnet/machinelearning/blob/76777592cf7e094f5361285bc64111d09d5bdb7c/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs#L143-L147\r\n\r\nThis can be used to set the seed for `maml`. All calls to `Run*` in `TestPredictiors.cs` should pass `extraSettings: new[] { ""seed=1"" }` to set the seed.\r\n\r\ncc: @harishsk  '"
557885514,4752,b'Default seed is not propagated from MLContext',"b""In theory, the seed set in `MLContext` is intended to provide the global seed for all components and operations requiring randomness, e.g. sampling, permutation, etc. In practice, this doesn't always hold true.\r\n\r\n`TrainTestSplit`, `CrossValidationSplit`, and `CrossValidate` all have a user specified seed and call `EnsureGroupPreservationColumn`, which in turn uses `GenerateNumberTransform` and `HashingEstimator`.\r\n\r\nWhen the seed is not specified by the user, it is not derived from `MLContext`. Instead, `GenerateNumberTransform` and `HashingEstimator` use their own defaults, so that if a user doesn't specify a seed to `TrainTestSplit`, `CrossValidationSplit`, or `CrossValidate`, they will always get a deterministic split regardless of the seed in `MLContext`.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24c827416d23a6a74f16f71ec9123ca15e0e12fd/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L496-L505\r\nhttps://github.com/dotnet/machinelearning/blob/24c827416d23a6a74f16f71ec9123ca15e0e12fd/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L521-L525\r\n\r\ncc: @harishsk @justinormont """
557845624,4749,b'[Meta Issue] Changing defaults',"b""First of all, is this a breaking change? @terrajobst suggested it is an acceptable breaking change https://github.com/dotnet/machinelearning/issues/2305#issuecomment-508197927, @eerhardt commented that is was decided that changing defaults is acceptable https://github.com/dotnet/machinelearning/issues/2305#issuecomment-509289908\r\n\r\n- Change the following defaults based on results from @justinormont:\r\n\r\n  - #2870 `FeatirizeText` default n-grams lengths to match default text recipe:\r\n    - word: 1 -> 2\r\n    - char: no change\r\n    - @justinormont correct me if I am wrong: was the default weighting TF-IDF in TLC? It is currently TF\r\n\r\n  - #2305 `AveragedPerceptron` default iterations from 1 to 10\r\n\r\n- #3365 `RowGroupColumnName` in `FastTree` and `LightGbm` ranking trainer `Options` classes: `null` -> `'GroupId'`\r\n  - This won't actually break anything since a ranking trainer would throw anyway if there was no group ID column specified https://github.com/dotnet/machinelearning/issues/3365#issuecomment-497775736\r\n  - This would make it consistent with the API for the rankers without the `Options` class, where the default is `'GroupId'`\r\n  - They should be consistent, at least. Either `null` everywhere or `'GroupId'` everywhere.\r\n\r\ncc: @harishsk @justinormont @gvashishtha @eerhardt """
557833624,4748,b'[Meta Issue] LDA topic word summary and other enhancements',"b'This issue summarizes many user requests for exposing or adding functionality to Latent Dirichlet Allocation (LDA) model, as well as some nits.\r\n\r\n## P1: LDA model generates inconsistent result after model save and load\r\n#1004\r\n\r\n## P1: Topic Word Summary\r\nAlready existing functionality not working as advertised.\r\n\r\nThe `LatentDirichletAllocation` transform provides a popular topic modeling algorithm. It learns a model to categorize a document into `n` topics, and outputs an n-dimensional topic vector for each document, with scores for the document belonging to each topic.\r\n```\r\nTopic1  Topic2  Topic3\r\n0.6364  0.2727  0.0909\r\n0.5455  0.1818  0.2727\r\n```\r\nThere are two use cases for this:\r\n\r\n1. Use the topic vector as a featurizer for a trainer.\r\n2. Predict which topic a document belongs to directly from the LDA model, for example ""Cat related"", ""Dog related"", ""Tech news"", etc.\r\n\r\n(1) works fine as is, but (2) has usability issues related to interpretibility of the learned topics. The topic vector doesn\'t actually name the topics so it is not possible to tell what a topic actually is.\r\n\r\nLDA has a parameter `numberOfSummaryTermsPerTopic`, which in theory is supposed to provide a list of most important terms for each topic. These terms would identify what a topic learned by the model actually is. However, there is no way to get this summary from the model currently, as the model parameters are not exposed, and is therefore misleading the user into thinking that this is possible.\r\n\r\nIt used to be accessible in the old PigSty API (#1411) but that has since been removed. It was also present in TLC as a text file in the model.zip, which wasn\'t a particularly user friendly way anyway https://github.com/dotnet/machinelearning/issues/4322#issuecomment-572333759. This should be made accessible to the user by extracting the parameters from `LdaState` https://github.com/dotnet/machinelearning/issues/1411#issue-374603754.\r\n\r\nMain issue containing the discussion: #4322 \r\nDuplicate issues with the same ask: #1411 #2197 #3092 #4328 #4735 \r\n\r\n## P2: Export Full Model\r\nNew feature request: #3092 \r\n\r\nThis ask is to expose more model parameters than just topic word summary.\r\n\r\n## P2: Seeded LDA\r\nNew feature request: #4143 \r\n\r\nSeed each topic with a list of words, which will make the topic words converge in that direction. May not be present in [LightLDA](https://github.com/microsoft/LightLDA), which ML.NET wraps.\r\n\r\n## P3: Nits\r\nLDA always prints to console: #3192\r\n\r\nThank you to our users who have brought these to our attention:\r\n@hobbsa @IvanAntipov @MagicMaxxx @nukeandserve @PaulDMendoza\r\n\r\ncc: @harishsk @justinormont @yaeldekel @antoniovs1029 @gvashishtha '"
557678434,4742,b'Remove extraSettings param in unit test datasets',"b""Various of the unit test datasets reference `extraSettings`. I think this is vestigial and unused any more. The language within there (e.g. `/cacheinst- /inst`) is for a very old version of TLC that doesn't exist any more either externally or internally (tl.exe not maml.exe or tlc.exe).\r\n\r\nI believe it's safe to remove the `extraSettings` from the test dataset settings and from the test framework. Blanking them and seeing that no unit tests fail is likely a quick test to see that they are no longer used in ML\xe2\x80\xa4NET.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/36fab9b6806260e64e50992450a219e869c7f74a/test/Microsoft.ML.TestFrameworkCommon/Datasets.cs#L90-L99"""
557633231,4741,b'Fix net461/netstandard2.0 incompatibility',"b""net461 isn't compatible with netstandard2.0. In the netfx build configurations, some projects target net461 and reference Microsoft.ML.Core, which only targets netstandard2.0. There are a few options:\r\n\r\n1. Multitarget the projects that currently target netstandard2.0 to also target net461\r\n1. Update the netfx build to use net46 instead of net461, and multitarget the netstandard projects to also target netstandard1.3\r\n1. Update the netfx build to use net472 instead of net461\r\n\r\nWe used option 2 in Roslyn 1.x and 2.x, and switched to option 3 in Roslyn 3."""
557382564,4739,b'how we show permutation slot associated with feature so end user easily identify?',"b'@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE \r\n\r\nwe required deep PFI and FCC on feature of their values.\r\nwe calculate PFI as per below link-\r\nhttps://devblogs.microsoft.com/premier-developer/permutation-implementation-with-ml-net/\r\nfollowing top 4 feature we got and we draw bar charts.\r\n\r\nTop 4   Features | Comments of   this Observation\r\n-- | --\r\nOvertime | Higher\xc2\xa0reported   Overtime, employees are\xc2\xa0more\xc2\xa0likely to leave.\r\n**Marital Status** | Certain\xc2\xa0group   of marital status is more likely to leave than the other group. As far as   which group, it could be identified through the debugging of each permutation   slot associated.\r\nDepartment | Certain   department employees are more likely leave than other departments. Again, the   identification could have been done as well.\r\nYears At   Company | Number   of years at the same company are factored. Again, is it more   years\xc2\xa0more\xc2\xa0likely to leave or\xc2\xa0less\xc2\xa0likely to leave?\r\n\r\nnow if you see comments on related Marital Status feature, we want to show permutation slot associated Marital Status so end user easily identify which Certain\xc2\xa0group of marital status is more likely to leave than the other group.\r\n\r\nThanks and Regards,\r\nAtul\r\n![PFI slot](https://user-images.githubusercontent.com/37444019/73481000-f1ef6000-43c0-11ea-9b4b-102a297c9ed7.png)\r\n[attrition.xlsx](https://github.com/dotnet/machinelearning/files/4135819/attrition.xlsx)\r\n\r\n'"
557233165,4738,b'PredictionEngine.Predict locks file even after disposing and going out of context',"b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  .NET 4.7.2\r\n- **ML.NET**: 1.4.0\r\n\r\n### Issue\r\n\r\nCreating PredictionEngine and using Predict on an Image data locks the image file.\r\nDisposing the prediction engine has no effect as well.\r\n\r\n~~ImageLoadingEstimator locks the image file and does not release the lock even after going out of\r\ncontext.~~\r\n\r\n\r\n'"
557108438,4735,"b'I am working with the LDA functionality of ML.NET. How can I see the summary terms for a topic. I have the default 10 summary terms per topic set, but after fitting I cannot find the terms.'","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
556922207,4730,b'TensorFlow exception triggered while loading Inception model in a Jupyter C# notebook',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro Build 19008 (x64)\r\n- **.NET Version (eg., dotnet --info)**: NET Core SDK 3.0.100\r\n- !!! **I am hosting my code in a C# kernel in Jupyter on Anaconda 4.8.1** !!!\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI\'m running a C# kernel in an Anaconda3 Jupyter server as per these instructions: https://www.hanselman.com/blog/AnnouncingNETJupyterNotebooks.aspx. This works great and my notebooks can run most ML.NET demos without any trouble.\r\n\r\nI am now buildingt a C# Jupyter notebook that demonstrates the object detection capabilities of the ML.NET library. I\'m trying to run the DeepLearning_ImageClassification_TensorFlow demo (here: https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow). \r\n\r\n- **What happened?**\r\n\r\nEverything works fine up until this point in the code:\r\n\r\n`var temp = mlContext.Model.LoadTensorFlowModel(""models/tensorflow_inception_graph.pb"");\r\n`\r\n\r\nThis method LoadTensorFlowModel throws an exception: System.FormatException: Tensorflow exception triggered while loading model.\r\n\r\n- **What did you expect?**\r\n\r\nI expected the method to load the tensorflow inception graph. This is what happens when running the same code on the Windows command line.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nThe following is a minimal Jupyter C# notebook with only 2 code cells to reproduce the issue:\r\n\r\nCode cell 1\r\n```\r\n#r nuget:Microsoft.ML\r\n#r nuget:Microsoft.ML.ImageAnalytics\r\n#r nuget:Microsoft.ML.TensorFlow\r\n```\r\n\r\nCode cell 2\r\n```\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System.IO;\r\n\r\n// create a machine learning context\r\nvar mlContext = new MLContext();\r\n\r\n// load the inception graph\r\nvar temp = mlContext.Model.LoadTensorFlowModel(""models/tensorflow_inception_graph.pb"");\r\n```\r\n\r\nThe full exception is:\r\n\r\n```\r\nSystem.FormatException: Tensorflow exception triggered while loading model.\r\n ---> System.ArgumentNullException: Value cannot be null. (Parameter \'libraryPath\')\r\n   at System.Runtime.InteropServices.NativeLibrary.Load(String libraryPath)\r\n   at MLS.Agent.NativeAssemblyLoadHelper.Resolve(String libraryName, Assembly assembly, Nullable`1 searchPath) in F:\\workspace\\_work\\1\\s\\MLS.Agent\\NativeAssemblyLoadHelper.cs:line 47\r\n   at System.Runtime.InteropServices.NativeLibrary.LoadLibraryCallbackStub(String libraryName, Assembly assembly, Boolean hasDllImportSearchPathFlags, UInt32 dllImportSearchPathFlags)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.GetSession(IHostEnvironment env, String modelPath, Boolean metaGraph)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTensorFlowModel(IHostEnvironment env, String modelPath)\r\n   at Microsoft.ML.TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog catalog, String modelLocation)\r\n   at Submission#11.<<Initialize>>d__0.MoveNext()\r\n```\r\n\r\nAnd the inner exception is:\r\n\r\n```\r\nSystem.ArgumentNullException: Value cannot be null. (Parameter \'libraryPath\')\r\n   at System.Runtime.InteropServices.NativeLibrary.Load(String libraryPath)\r\n   at MLS.Agent.NativeAssemblyLoadHelper.Resolve(String libraryName, Assembly assembly, Nullable`1 searchPath) in F:\\workspace\\_work\\1\\s\\MLS.Agent\\NativeAssemblyLoadHelper.cs:line 47\r\n   at System.Runtime.InteropServices.NativeLibrary.LoadLibraryCallbackStub(String libraryName, Assembly assembly, Boolean hasDllImportSearchPathFlags, UInt32 dllImportSearchPathFlags)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n```\r\n\r\nI installed the Tensorflow package in Anaconda3, but my hunch is that the wrapper code in ML.NET is somehow not able to find the native library, possibly because dotnet-try is hosting the C# code.\r\n\r\nI realize this is an unconventional configuration, but I\'m trying to get as much of ML.NET as possible working in Jupyter notebooks so that C# becomes a viable language for ML training. \r\n '"
556904758,4729,"b""Any plans to include DBSCAN algorithm for clustering? DBSCAN doesn't need the cluster number before clustering.""",b'### Issue\r\n\r\n- **I have tried to cluster some dense vectors using KMeans**\r\n- **The number of clusters is needed**\r\n- **I have made some research and I have found DBSCAN which works with unknown number of clusters. Any plans to include DBSCAN in ML.NET? https://en.wikipedia.org/wiki/DBSCAN**'
556639076,4725,b'object detection training ',"b""Is there a possibility to do object detection training with ml.net comparable to the custom vision object detection services (azure)? If yes, is there a tutorial / sample out there? I couldn't find any object detection training sample. """
556557772,4719,b'ExpressionEstimator Description Too Long',b'Most of this page is taken up by the ExpressionEstimator description. \n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 881dc206-da7e-738d-4fb2-5f792163ab89\n* Version Independent ID: a6456027-81b5-faa0-2d6a-d37099133234\n* Content: [Microsoft.ML.Transforms Namespace](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/ns-Microsoft.ML.Transforms.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/ns-Microsoft.ML.Transforms.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'
555456797,4713,"b'If evaluation data has only one class, how should we compute AUC?'","b'Currently if there is only data from one class, we throw an exception (see issue #4692 ).\r\nIt might make more sense to return NaN instead of that.'"
555380328,4712,"b""DllNotFoundException: Unable to load DLL 'tensorflow': The specified module could not be found. (Exception from HRESULT: 0x8007007E)""","b'I am trying to Consume the ML.NET model to predict the results via following code \r\n\r\n\r\npublic static ModelOutput Predict(ModelInput input)\r\n        {\r\n\r\n\r\n            // Create new MLContext\r\n            MLContext mlContext = new MLContext();\r\n            ModelOutput result = new ModelOutput();\r\n            try\r\n            {\r\n\r\n\r\n                Load model &create prediction engine\r\n                string modelPath = AppDomain.CurrentDomain.BaseDirectory + ""MLModel.zip"";\r\n                ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n                var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n\r\n                Use model to make prediction on input dataDllNotFoundException: Unable to load DLL \'tensorflow\': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n\r\n                result = predEngine.Predict(input);\r\n                Console.WriteLine(result);\r\n\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                Console.WriteLine(e.ToString());\r\n            }\r\n            return result;\r\n        }\r\n\r\n\r\n\r\nI am having tensorflow.dll error while it is installed and present in respective folder too. '"
555241878,4711,b'Q: PCA Anomaly Detection - Time series data possible?',"b'Hi all,\r\n\r\nI have been trying unsuccessfully to do PCA on time series based data to identify anomalies.\r\n\r\nI see that the PCA credit card fraud example and scenario uses a bool and is credit card data (not time based).\r\n\r\nMy question is whether this is possible using time series data in principle or is the scenario inappropriate? I have floats, must they be transformed?\r\n\r\nThanks\r\n\r\nFig'"
555099972,4709,b'Save method on asp.net core get an error that access denied path',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NetCore 3.1.1\r\n\r\n### Issue\r\n\r\nWhen I want save trained model with the Save Method on asp.net core, I get an error that access denied path. I used other way instead of it.\r\n[Follow here](https://github.com/Cyrus-Sushiant/MLDotNetTitanic/blob/master/MLDotNetTitanic/ML/ModelBuilder.cs#L68).\r\n\r\n### Source code / logs\r\n\r\n`mlContext.Model.Save(mlModel, modelInputSchema, modelPath);`\r\n'"
555056662,4708,"b""Tensorflow.TensorflowException Can't copy 64064 bytes of a tensor into another with 32032 bytes buffer""","b""### System information\r\n\r\n- **Windows 10 pro**:\r\n- **.NET Version .net core 3.1**: \r\n\r\n### Issue\r\n\r\n- **I've generated model for image classification by using ML.Net Model builder , 2 labels (OK & NG) 10 images in total , model was correctly created together with the C# code **\r\n- **I've checked that everything was working fine then i've added SciSharp.TensorFlow.Redist-Windows-GPU in order to check the behavior with GPU**\r\n- **I was expecting that the model will be generated just simply more fast by using GPU , unfortunately it goes in error . attached source code and snip of the error .*\r\n\r\n[ML.zip](https://github.com/dotnet/machinelearning/files/4111726/ML.zip)\r\n"""
554985537,4707,b'OnnxTransformer docs xml code sample should use latest dynamic API',b'It currently uses the old static API\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/53fba319042f27efc64ef45889c9d9467ac20785/src/Microsoft.ML.OnnxTransformer/doc.xml#L49-L62\r\n'
554795631,4703,b'Bottleneck phase produces bad files (invalid or with poor accuracy results) on some configuration',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**: 3.1.101\r\n- **ML.NET Version**: 1.4.0 \r\n- **CPU : AMD Ryzen 9 3900X 12-Core**\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRunning a simple example of image classification, based on https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification-api-transfer-learning\r\n\r\n- **What happened?**\r\nUsing only CPU, the process completes but provides a very poor accuracy (0.014)\r\nUsing GPU, the process passes the bottleneck phase but cannot begin the train due to an error.\r\n\r\n- **What did you expect?**\r\nUsing only CPU, I expect a better result (around 0.70).\r\nUsing GPU, I expect the process to continue and train.\r\n\r\n- **Additionnal informations**\r\nThe same program with the same dataset works fine on another computer (Intel based CPU) and have a correct accuracy (0.70).\r\nNo problem occurs when using the GPU.\r\nIf I copy/paste the cached files from the working computer to my computer, the process is working fine (with or without GPU) and have the expected accuracy (0.70).\r\nSo, I guess the problem relies in the files generated during the bottleneck phase and is related to the hardware configuration, since same program with same dataset have very different behaviours.\r\n\r\n### Source code / logs\r\nComplete logs (CPU Only) when using generated cached files during the bottleneck phase\r\n```\r\n*** Training the image classification model with DNN Transfer Learning on top of the selected pre-trained model/architecture ***\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0083464.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n2020-01-24 16:03:09.939754: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nSaver not created because there are no variables in the graph to restore\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:       0,01 Epoch:   0, Accuracy:  0,6121079, Cross-Entropy: 4,300151E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   0, Accuracy: 0,01333781\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:       0,01 Epoch:   1, Accuracy:  0,6213207, Cross-Entropy: 3,970512E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   1, Accuracy: 0,01346435\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:     0,0094 Epoch:   2, Accuracy:  0,6239617, Cross-Entropy: 3,621145E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   2, Accuracy: 0,01293448\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:     0,0094 Epoch:   3, Accuracy:  0,6224542, Cross-Entropy: 3,632903E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   3, Accuracy: 0,01363834\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:   0,008836 Epoch:   4, Accuracy:  0,6240405, Cross-Entropy: 3,406656E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   4, Accuracy: 0,01359484\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:   0,008836 Epoch:   5, Accuracy:  0,6223006, Cross-Entropy: 3,40876E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   5, Accuracy: 0,01343272\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,008305839 Epoch:   6, Accuracy:  0,6249708, Cross-Entropy: 3,204811E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   6, Accuracy:  0,0134169\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,008305839 Epoch:   7, Accuracy:  0,6249651, Cross-Entropy: 3,184228E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   7, Accuracy: 0,01392107\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,007807489 Epoch:   8, Accuracy:  0,6232149, Cross-Entropy: 3,004976E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   8, Accuracy: 0,01329432\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,007807489 Epoch:   9, Accuracy:  0,6227242, Cross-Entropy: 3,030696E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   9, Accuracy: 0,01335956\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,00733904 Epoch:  10, Accuracy:  0,6246268, Cross-Entropy: 2,813951E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  10, Accuracy: 0,01338527\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,00733904 Epoch:  11, Accuracy:  0,6228801, Cross-Entropy: 2,828588E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  11, Accuracy: 0,01380046\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006898697 Epoch:  12, Accuracy:  0,6257862, Cross-Entropy: 2,645051E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  12, Accuracy: 0,01335957\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006898697 Epoch:  13, Accuracy:  0,6236802, Cross-Entropy: 2,659039E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  13, Accuracy: 0,01352564\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006484775 Epoch:  14, Accuracy:  0,6229582, Cross-Entropy: 2,493187E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  14, Accuracy: 0,01385187\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006484775 Epoch:  15, Accuracy:  0,6234171, Cross-Entropy: 2,496486E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  15, Accuracy: 0,01407331\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006095689 Epoch:  16, Accuracy:  0,6221284, Cross-Entropy: 2,340333E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  16, Accuracy: 0,01392898\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006095689 Epoch:  17, Accuracy:  0,6231769, Cross-Entropy: 2,359828E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  17, Accuracy: 0,01311638\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005729948 Epoch:  18, Accuracy:  0,6233777, Cross-Entropy: 2,180089E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  18, Accuracy: 0,01357309\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005729948 Epoch:  19, Accuracy:  0,6225668, Cross-Entropy: 2,219908E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  19, Accuracy: 0,01381233\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005386151 Epoch:  20, Accuracy:  0,6234834, Cross-Entropy: 2,070789E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  20, Accuracy: 0,01392503\r\nSaver not created because there are no variables in the graph to restore\r\n```\r\n\r\nEnd logs (CPU Only) when using cached files from a working computer (more epoch and better results)\r\n```Phase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 222, Accuracy:  0,7872852\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 1,040379E-05 Epoch: 223, Accuracy:  0,8063375, Cross-Entropy:  0,7515593\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 223, Accuracy:  0,7873719\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,779563E-06 Epoch: 224, Accuracy:  0,8058808, Cross-Entropy:  0,7523516\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 224, Accuracy:  0,7878902\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,779563E-06 Epoch: 225, Accuracy:  0,8060154, Cross-Entropy:  0,7517532\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 225, Accuracy:  0,7882423\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,19279E-06 Epoch: 226, Accuracy:  0,8054689, Cross-Entropy:  0,7526353\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 226, Accuracy:   0,788062\r\n```\r\n\r\nLogs when using GPU\r\n```\r\n*** Training the image classification model with DNN Transfer Learning on top of the selected pre-trained model/architecture ***\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0088906.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n2020-01-24 16:11:47.949314: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-01-24 16:11:47.960130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n2020-01-24 16:11:47.998004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.785\r\npciBusID: 0000:2d:00.0\r\n2020-01-24 16:11:48.000866: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-24 16:11:48.003049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2020-01-24 16:11:49.018802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-24 16:11:49.020743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2020-01-24 16:11:49.021869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2020-01-24 16:11:49.023948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6290 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)\r\nSaver not created because there are no variables in the graph to restore\r\n2020-01-24 16:11:49.891634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.785\r\npciBusID: 0000:2d:00.0\r\n2020-01-24 16:11:49.894813: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-24 16:11:49.897236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2020-01-24 16:11:49.899756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-24 16:11:49.902237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2020-01-24 16:11:49.903756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2020-01-24 16:11:49.906049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6290 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)\r\nCan't copy 160160 bytes of a tensor into another with 80080 bytes buffer.\r\n         [[{{node _arg_input_1/BottleneckInputPlaceholder_0_0}}]]\r\n```\r\n"""
554489330,4700,b'Using PlattCalibratorTransformer with custon name for Score Column',"b'### Issue\r\n\r\n- **What did you do?**\r\nI tried to create a model with a PlattCalibratorEstimator that uses a `scoreColumnName` with a name different from ""Score"" (as done through [this API](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.calibratorscatalog.platt?view=ml-dotnet#Microsoft_ML_BinaryClassificationCatalog_CalibratorsCatalog_Platt_System_String_System_String_System_String_))\r\n\r\n- **What happened?**\r\nAfter fitting the estimator, and while trying to transform the input dataview, the following exception is thrown:\r\n`System.InvalidOperationException: \'The data to calibrate contains no \'Score\' column\'`\r\n\r\n- **What did you expect?**\r\nThe model to work the same way as if I had used the name ""Score"" for my score column\r\n\r\nFurthermore, I couldn\'t find any sample or test that actually used the optional parameter `scoreColumnName` of PlattCalibratorEstimator, or the other parameters (such as labelColumnName). So adding such tests might be also necessary (if my PR #4700 gets in, then fixing this issue in here would also require to add onnx tests to check that PlattCalibrator with custom scoreColumnName is saved correctly to onnx). Checking if this problem also occurs in the other CalibratorTransformers would also be relevant.\r\n\r\nNotice that a simple workaround for this would be to copy the column that holds the score into a new column called Score, and specify Score as the scoreColumnName.\r\n\r\n### Source code / logs\r\nIn EXAMPLE 1 I show that it works if my score column is named ""Score"". But if I change the name, then it doesn\'t work.\r\n\r\n```C#\r\nusing Microsoft.ML;\r\n\r\nnamespace Platt2\r\n{\r\n    public static class Platt2\r\n    {\r\n\r\n        class ModelInput\r\n        {\r\n            public bool Label { get; set; }\r\n            public float Score { get; set; }\r\n        }\r\n\r\n        class ModelInput2\r\n        {\r\n            public bool Label { get; set; }\r\n            public float ScoreX { get; set; }\r\n        }\r\n\r\n        public static void Main()\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n\r\n            // EXAMPLE 1 - Works\r\n            IDataView data = mlContext.Data.LoadFromEnumerable<ModelInput>(\r\n                new ModelInput[]\r\n                {\r\n                                new ModelInput { Score = 10, Label = true },\r\n                                new ModelInput { Score = 15, Label = false },\r\n                }\r\n            );\r\n\r\n            var calibratorEstimator = mlContext.BinaryClassification.Calibrators\r\n                .Platt();\r\n\r\n            var calibratorTransformer = calibratorEstimator.Fit(data);\r\n            var finalData = calibratorTransformer.Transform(data);\r\n            var prev = finalData.Preview();\r\n\r\n\r\n            // EXAMPLE 2 - Doesn\'t Work\r\n            IDataView data2 = mlContext.Data.LoadFromEnumerable<ModelInput2>(\r\n                new ModelInput2[]\r\n                {\r\n                                new ModelInput2 { ScoreX = 10, Label = true },\r\n                                new ModelInput2 { ScoreX = 15, Label = false },\r\n                }\r\n            );\r\n\r\n            calibratorEstimator = mlContext.BinaryClassification.Calibrators\r\n                .Platt(scoreColumnName: ""ScoreX"");\r\n\r\n            calibratorTransformer = calibratorEstimator.Fit(data2);\r\n            finalData = calibratorTransformer.Transform(data2); // Throws exception\r\n            prev = finalData.Preview();\r\n\r\n        }\r\n\r\n    }\r\n}\r\n```\r\n'"
553863174,4693,b'SelectFeaturesBasedOn* Transformers are not outputing vectors of known size.',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n**Code that failed:**\r\n\r\nContext.Transforms.Text.TokenizeIntoWords(""TextFeature"")                                   .Append(Context.Transforms.FeatureSelection.SelectFeaturesBasedOnCount(""TextFeature"", ""TextFeature"", 10)).\r\nAppend(Context.Transforms.FeatureSelection.SelectFeaturesBasedOnMutualInformation(""TextFeature"", ""TextFeature"", ""Label"", 5000))\r\n.Append(Context.Transforms.NormalizeLpNorm(""TextFeature"", ""TextFeature"", Microsoft.ML.Transforms.LpNormNormalizingEstimatorBase.NormFunction.L2, true));\r\n\r\n**Error:**\r\nAt NormalizeLpNorm, it fails with\r\nSchema mismatch for input column \'TextFeature\': expected Expected Single or known-size vector of Single, got VarVector<Single>\r\n\r\n'"
553703564,4692,b'AutoML: Binary classification - AUC is not defined',"b'\r\nHi,\r\n\r\nI am struggling with this baffling exception. My data label is binary and I have 1,0 in the csv. I am sure that I have enough data and the splitter is able training and testing data to include positive values.\r\n\r\nIs there anything that I can try?\r\n\r\nThanks\r\n\r\n\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML bin classification experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration                        |\r\nException during AutoML iteration: System.ArgumentOutOfRangeException: AUC is not defined when there is no positive class in the data\r\nParameter name: PosSample\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)'"
553416639,4689,b'SVM Light loader bug',"b'When SVM Light loader encounters a feature index greater than `int.MaxValue` it ignores the value with this index, but it creates a schema where the length of the Features column is `int.MaxValue`. However, if the file is saved with the SVM Light saver, and then loaded again with SVM Light loader, the feature with that index will not be there, so the new loader will have a different length for the Features column. \r\nSaving and reloading should give the same data and the same schema, so SVM Light loader should not assign `int.MaxValue` as the length of the Features column, but instead it should assign the maximum valid index in the file.'"
553229574,4686,b'upload procdump to Tools repro',b'Upload procdump.exe tool to Tools repro'
552717639,4681,b'LightGBM trainer filters out rows with NaN features',"b'LightGBM (binary trainer) will filter out NaN (feature)-values even though we have the option of `HandleMissingValue` which allows LightGBM to properly deal with missing values:\r\n\r\nhttps://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7a4372e1dda8f5d5c070ffce6bd1929216939d90/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L178\r\n\r\nI think this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7a4372e1dda8f5d5c070ffce6bd1929216939d90/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L439\r\n\r\n\r\nshould also specify the flag ""AllFeatures"" so they\'re allowed through.'"
552611803,4680,b'New feature request: Image regression model',"b'It would be nice to have a regression model that works on images, so an image rank can be predicted.  eg. Train images of the sky with a cloudiness rank of 1-100, get prediction as a float instead of bucketing into classifications.'"
552604981,4679,"b""Unable to load DLL 'tensorflow'""","b""### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro v 1903\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n   - Create a new .NET Core console application\r\n   - Right-click, Add Machine Learning\r\n   - Image classification\r\n   - Select input path for images\r\n   - Start Training\r\n\r\n- **What happened?**\r\n   - Crashed with: System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n\r\n- **What did you expect?**\r\n   - Training to occur\r\n\r\n### Source code / logs\r\n\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] Downloading resnet_v2_50_299.meta from https://aka.ms/mlnet-resources/resnet_v2_50_299.meta to D:\\User Temp\\MLNET\\resnet_v2_50_299.meta\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 3711 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 10264576 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 20525056 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 30785536 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 41050112 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 51310592 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 61571072 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 71835648 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 82096128 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 92356608 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Downloaded 102616931 bytes out of 102616931\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Info] resnet_v2_50_299.meta: Download complete\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:52.2037712.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0005611.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003606.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0004386.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0003186.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0004189.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0007600.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0009608.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0002711.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0006318.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ValueToKeyMapping{ col=Label:Label} xf=ImageLoading{ col=ImageSource_featurized:ImageSource imageFolder=} xf=ColumnCopying{ col=Features:ImageSource_featurized} tr=ImageClassification{} xf=KeyToValueMapping{ col=PredictedLabel:PredictedLabel} cache=- . Exception: System.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow': A dynamic link library (DLL) initialization routine failed. (Exception from HRESULT: 0x8007045A)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadMetaGraph(String path)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n[Source=ImageClassificationTrainer; ImageClassificationTrainer, Kind=Trace] Channel started\r\nTensorflow exception triggered while loading model.\r\n\r\n"""
552334663,4678,"b""System.MissingMethodException: 'Method not found: 'Tensorflow.Tensor Tensorflow.tensorflow.truncated_normal'""","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindow 10 build-17134\r\n- **.NET Version (eg., dotnet --info)**: \r\nNetCore 3.1\r\n### Issue\r\n\r\n- **What did you do?**\r\nThat example [**Tutorial: Automated visual inspection using transfer learning with the ML.NET Image Classification AP**I](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification-api-transfer-learning)\r\n- **What happened?**\r\nException on step _ITransformer trainedModel = trainingPipeline.Fit(trainSet)_;:\r\n\r\n> Method not found: \'Tensorflow.Tensor Tensorflow.tensorflow.truncated_normal(Int32[], Single, Single, Tensorflow.TF_DataType, System.Nullable`1<Int32>, System.String)\'.\r\n\r\n```csharp\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var workspaceRelativePath = @""C:\\Test_dev\\ML_Main_Test\\workspace"";\r\n            var assetsRelativePath = @""C:\\Test_dev\\ML_Main_Test\\assets"";\r\n\r\n            MLContext mlContext = new MLContext();\r\n\r\n            IEnumerable<ImageData> images = LoadImagesFromDirectory(folder: assetsRelativePath, useFolderNameAsLabel: true);\r\n\r\n            var test = images.First();\r\n\r\n            IDataView imageData = mlContext.Data.LoadFromEnumerable(images);\r\n\r\n            IDataView shuffledData = mlContext.Data.ShuffleRows(imageData);\r\n\r\n            var preprocessingPipeline = mlContext.Transforms.Conversion.MapValueToKey(\r\n                                    inputColumnName: ""Label"",\r\n                                    outputColumnName: ""LabelAsKey"")\r\n                                .Append(mlContext.Transforms.LoadRawImageBytes(\r\n                                    outputColumnName: ""Image"",\r\n                                    imageFolder: assetsRelativePath,\r\n                                    inputColumnName: ""ImagePath""));\r\n\r\n            IDataView preProcessedData = preprocessingPipeline.Fit(shuffledData)\r\n                                            .Transform(shuffledData);\r\n\r\n            TrainTestData trainSplit = mlContext.Data.TrainTestSplit(data: preProcessedData, testFraction: 0.2);\r\n            TrainTestData validationTestSplit = mlContext.Data.TrainTestSplit(trainSplit.TestSet);\r\n\r\n            IDataView trainSet = trainSplit.TrainSet;\r\n            IDataView validationSet = validationTestSplit.TrainSet;\r\n            IDataView testSet = validationTestSplit.TestSet;\r\n\r\n            var classifierOptions = new ImageClassificationTrainer.Options()\r\n            {\r\n                FeatureColumnName = ""Image"",\r\n                LabelColumnName = ""LabelAsKey"",\r\n                ValidationSet = validationSet,\r\n                Arch = ImageClassificationTrainer.Architecture.ResnetV2101,\r\n                MetricsCallback = Console.WriteLine,\r\n                TestOnTrainSet = false,\r\n                ReuseTrainSetBottleneckCachedValues = true,\r\n                ReuseValidationSetBottleneckCachedValues = true,\r\n                WorkspacePath = workspaceRelativePath\r\n            };\r\n            var trainingPipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(classifierOptions)\r\n                                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\n            ITransformer trainedModel = trainingPipeline.Fit(trainSet);\r\n\r\n            mlContext.Model.Save(trainedModel, preProcessedData.Schema, ""model.zip"");\r\n\r\n            ClassifySingleImage(mlContext, testSet, trainedModel);\r\n        }\r\n\r\n```\r\n'"
552210125,4677,b'Domain request for ML.net ',"b'Would be great if Microsoft has the domain ml.net to link to https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet because at the moment ml.net is unresolved, but asp.net redirects.'"
551919346,4675,"b'Add support for stateful custom mappers, and for custom filters'",b''
551609651,4672,b'New feature request: Additional TimeseriesCatalog estimators ',"b'Dear all,\r\n\r\nUnless I am mistaken there is currently a single model suitable for time-series forecasting (ForecastBySsa). \r\n\r\nThe other models within this catalogue target anomaly detection. There are various alternative methods that may be used to forecast time. \r\n\r\nIt would be nice to have a choice and the option to try a different method.\r\n\r\nThank you\r\n\r\nFig'"
551554129,4671,"b'Loading Data from DataTable or ""Dynamic"" Model'","b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.8\r\n\r\n### Issue\r\nI would like to know how I can leverage a datatable or some similar type instead of using model classes.  To start with, I am currently able to successfully train and predict with a model class using the multi-class classification.  The current model in my setup looks like this:\r\n\r\n     public class MultiClassInput\r\n      {\r\n        [ColumnName(""Statement"")]\r\n        public string Statement { get; set; }\r\n        [ColumnName(""Label"")]\r\n        public string Label { get; set; }\r\n      }\r\n\r\nI am essentially creating a List<MultiClassInput> from data in a datatable.  Some sample data I used to successfully train and predict:\r\n \r\n                    v_ModelTrainingData.Rows.Clear();\r\n                    v_ModelTrainingData.Rows.Add(""I need to Reset Password"", ""#ITSupport"");\r\n                    v_ModelTrainingData.Rows.Add(""I want to Reset Password"", ""#ITSupport"");\r\n                    v_ModelTrainingData.Rows.Add(""Password Reset"", ""#ITSupport"");\r\n                    v_ModelTrainingData.Rows.Add(""Reset My Password"", ""#ITSupport"");\r\n                    v_ModelTrainingData.Rows.Add(""Pass Reset"", ""#ITSupport"");\r\n                    v_ModelTrainingData.Rows.Add(""Pay Bill"", ""#Billing"");\r\n                    v_ModelTrainingData.Rows.Add(""Pay Invoice"", ""#Billing"");\r\n                    v_ModelTrainingData.Rows.Add(""Billing Problems"", ""#Billing"");\r\n                    v_ModelTrainingData.Rows.Add(""Review Charges"", ""#Billing"");\r\n                    v_ModelTrainingData.Rows.Add(""Pay Charges"", ""#Billing"");\r\n                    v_ModelTrainingData.Rows.Add(""Invoice Problem"", ""#Billing"");\r\n\r\nWhat I would like to do is figure out some way to have a user pick a column to be the label -- that way I can support multiple columns of data to act as input to the training process without creating multiple classes.  Everything I have found so far looks like it requires a known model class.  Any thoughts on how I can achieve this? Thanks.\r\n\r\n### Source code / logs\r\nRead documentation for loading data: https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/load-data-ml-net'"
551287109,4670,b'MultiClass Classification - feature contribution',"b'Hello,\r\n\r\nDo you plan on adding Feature Contribution to multi class classification problem?\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 72fdbc4e-fdca-27da-91d3-93fb0d397185\r\n* Version Independent ID: ad7c3810-5cdf-5fc8-b856-7ce0a0f2e2f1\r\n* Content: [FeatureContributionCalculatingEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.featurecontributioncalculatingestimator?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/FeatureContributionCalculatingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/FeatureContributionCalculatingEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**'"
551143602,4668,b'Create TestRunner for ML.NET tests',"b'Start the test process from a managed place instead directly from xunit, that will give us better control:\r\n1. logging and restart test process if crashes\r\n2. retry flaky test with everything reset\r\n3. logging when test process hangs\r\n'"
551001963,4664,b'F1-score to return 0.0 instead of NaN',"b'Our `F1` metric can currently return a `NaN` value when both the precision and recall are zero, as `F1 = 2 * precision * recall / (precision + recall)`, which turns into `0 / 0`. Precision/recall being zero occurs for a trivial model which always guesses the majority class zero.\r\n\r\nWe should return `F1=0.0` instead of `NaN`  -- this is done in sklearn ([code](https://github.com/scikit-learn/scikit-learn/blob/4b82c4450b759f4efd0dbad2840739ffc416e533/sklearn/metrics/classification.py#L927-L929)), and others ([note](https://github.com/dice-group/gerbil/wiki/Precision,-Recall-and-F1-measure#dividing-by-0)) \r\n<br/>Our `F1` calculation code:\r\nhttps://github.com/dotnet/machinelearning/blob/610ffcb67083c2e5e6e1a14884ba24b1da0384c7/src/Microsoft.ML.Data/Evaluators/BinaryClassifierEvaluator.cs#L483\r\n\r\nSee background: https://github.com/dotnet/machinelearning/issues/4648#issuecomment-574886743'"
551000677,4663,b'NaN metric value handling in AutoML',"b'AutoML API code is not handing `NaN` values for metrics. During the sweep, when a model returns a `NaN` value for the metric being optimized, AutoML crashes.\r\n\r\nSee background: https://github.com/dotnet/machinelearning/issues/4648#issuecomment-574886743'"
550396115,4660,b'Using an ImageClassificationTrainer with a dataset that only contains one class of images',"b'### Issue\r\n\r\n- **What did you do?**\r\nI tried to train a model that uses the `ImageClassificationTrainer`, using a dataset that only contains images labeled as \'dog\'.\r\n\r\n- **What happened?**\r\nI got a `System.InvalidOperationException: \'Metadata KeyValues does not exist\'` while fitting the model, which isn\'t very informative about the problem. If I didn\'t know my dataset only contained one label, or if I were to split the dataset in a way that the training set had only one label, then getting that exception wouldn\'t help to fix the problem.\r\n\r\nAlso notice that the exception is thrown _after_ training is done, so an user would have already invested time on it before noticing that something is wrong. \r\n\r\n- **What did you expect?**\r\nProbably an exception which tells me that there is only one class in my dataset, as done by other multiclass trainers such as the Multiclass LightGBM which throws a `""System.InvalidOperationException: \'LightGBM Error, code is -1, error message is \'Number of classes should be specified and greater than 1 for multiclass training\'.\'""`, or the `LinearMulticlassModelParametersBase` which throws a `System.ArgumentOutOfRangeException: \'Must be at least 2. Parameter name: numClasses\'` in [here](https://github.com/dotnet/machinelearning/blob/c4e4263188dccf16903b8f3fea7e65213a69c6e3/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/MulticlassLogisticRegression.cs#L505).\r\n\r\nIf I changed my dataset to include other labels, then the exception is gone and it works as expected.\r\n\r\n### Source code / logs\r\n[dataset.zip](https://github.com/dotnet/machinelearning/files/4067127/dataset.zip)\r\n\r\n```C#\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Vision;\r\n\r\nnamespace Microsoft.ML.Samples\r\n{\r\n    public class ModelInput\r\n    {\r\n        [ColumnName(""Label""), LoadColumn(0)]\r\n        public string Label { get; set; }\r\n\r\n\r\n        [ColumnName(""ImageSource""), LoadColumn(1)]\r\n        public string ImageSource { get; set; }\r\n    }\r\n\r\n    public static class Program\r\n    {\r\n        // private static string TRAIN_DATA_FILEPATH = @""C:\\Users\\anvelazq\\Desktop\\issue19\\dogs-cats-horses.tsv""; // This one works because it has multiple classes\r\n        private static string TRAIN_DATA_FILEPATH = @""C:\\Users\\anvelazq\\Desktop\\issue19\\only-dogs.tsv""; // This one doesn\'t work because it has only one class\r\n\r\n        private static MLContext mlContext = new MLContext(seed: 1);\r\n\r\n        public static void Main()\r\n        {\r\n            IDataView trainingDataView = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n                                            path: TRAIN_DATA_FILEPATH,\r\n                                            hasHeader: true,\r\n                                            separatorChar: \'\\t\',\r\n                                            allowQuoting: true,\r\n                                            allowSparse: false);\r\n\r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n                                      .Append(mlContext.Transforms.LoadRawImageBytes(""ImageSource_featurized"", null, ""ImageSource""))\r\n                                      .Append(mlContext.Transforms.CopyColumns(""Features"", ""ImageSource_featurized""));\r\n\r\n            var trainer = mlContext.MulticlassClassification.Trainers.ImageClassification(new ImageClassificationTrainer.Options() { LabelColumnName = ""Label"", FeatureColumnName = ""Features"" })\r\n                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            var model = trainingPipeline.Fit(trainingDataView); // System.InvalidOperationException: \'Metadata KeyValues does not exist\'\r\n\r\n            var transformed = model.Transform(trainingDataView);\r\n            var transformedPreview = transformed.Preview();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n### Nugets used:\r\n![image](https://user-images.githubusercontent.com/38739674/72475405-ac674c00-379f-11ea-8c71-815038ef1374.png)\r\n'"
550238664,4658,b'Q: Correct params for Timeseries analysis',"b'Hi all,\r\n\r\nI would appreciate checking my interpretation of the explanatory code comments for the following parameters used for time series analysis.\r\n\r\nThe example uses daily data and has:\r\nvar forecastingPipeline = mlContext.Forecasting.ForecastBySsa(\r\n     windowSize: 7,\r\n    seriesLength: 30,\r\n    trainSize: 365,\r\n    horizon: 7,\r\n   \r\nIs there a specific reason to use 30 (a month) and 7 (a week)? Also the trainSize is 365. Does this simply equate to the 365 samples used for training or represent days in a year?\r\n\r\nThanks!\r\n\r\nFig '"
550118135,4656,b'Error when using onnx models with GPU (CUDA 10)',"b'### System information\r\n\r\n- Microsoft.ML.OnnxTransformer : 1.4.0\r\n\r\n- Microsoft.ML : 1.4.0\r\n\r\n- OnnxRuntime.Gpu (test) : 1.0.1\r\n\r\n- CUDA/cuDNN version: : CUDA 10.0.130, cuDNN 7.6.2.\r\n\r\n- .NET Core 2.0\r\n\r\n\r\n### Issue\r\nI\'m currently trying to use an onnx model with a GPU and I get the following exception: \r\n\r\nSystem.EntryPointNotFoundException: Unable to find an entry point named \'OrtSessionOptionsAppendExecutionProvider_CUDA\' in DLL \'onnxruntime\'.\r\n\r\nThis exception appear when I use the ApplyOnnxModel method : \r\n`var pipeline =_mlContext.Transforms.ApplyOnnxModel(\r\n\t\t\t\tgpuDeviceId: gpuDeviceId,\r\n\t\t\t\tmodelFile: onnxModelFilePath);`\r\n\r\nI have tried with and without installing the NuGet package Microsoft.ML.OnnxRuntime.Gpu (1.0.1) and I get the same exception.  I have no problem using my onnx model when I use the OnnxRuntime.Gpu package directly.\r\n\r\nIt seems like even when I install the OnnxRuntime.Gpu package, it\'s the CPU version that is used. I would like to know if there is a way to make it work without having to build a local ML.NET OnnxTransformer package from source which depends on the OnnxRuntime.Gpu package.\r\n\r\n### Source code / logs\r\n\r\n<img width=""934"" alt=""error_with_onnx_gpu"" src=""https://user-images.githubusercontent.com/33623029/72428589-51792900-378e-11ea-9b4f-1a2c024f0e50.PNG"">\r\n'"
549793761,4651,b'Tensorflow exception triggered while loading model.',b'I tried to train an image classification model from ML builder but it always crashes instantly with the following stack trace \r\n[20200113 - Stack trace.txt](https://github.com/dotnet/machinelearning-modelbuilder/files/4055732/20200113.-.Stack.trace.txt)\r\n\r\nOperating System: windows\r\n\r\nAny hint to solve this problem ?\r\n'
549108532,4648,b'Strange error message',"b""Hello,\r\n\r\nI just upgraded my project to the new pre-release versions of ML.NET and I got the following error message when I ran my program:\r\n\r\n![bug](https://user-images.githubusercontent.com/1317234/72281674-ccf0a400-35ef-11ea-898e-997cf19c71f0.png)\r\n\r\nI have added a Zip file of my program and dataset.  I hope you guys can help me find out why I'm getting this error,\r\n\r\nCharles\r\n\r\n[bug.zip](https://github.com/dotnet/machinelearning/files/4055108/bug.zip)\r\n\r\n\r\n"""
549067915,4646,b'Exception on loading ONNX model',"b'I am unable to use an ONNX model for a transformation that happily works when used directly from M.OnnxRuntime using `InferenceSession`. The model was created using a RandomForestClassifier from SciKitLearn in python.\r\n\r\nRepro: [onnx-issue-repro.zip](https://github.com/dotnet/machinelearning/files/4054732/onnx-issue-repro.zip)\r\n\r\n```csharp\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext();\r\n            var transform = mlContext.Transforms.ApplyOnnxModel(""rf_iris.onnx"");\r\n        }\r\n    }\r\n```\r\n\r\n```\r\n> cd TestMLNet\r\n> dotnet run\r\n Unhandled exception. System.ArgumentOutOfRangeException: dim (Parameter \'Dimension { } in ONNX tensor cannot exceed the maximum of 32-bit signed integer.\')\r\nActual value was 0.\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTypeParser.GetDimValue(Dimension dim)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTypeParser.GetTensorDims(TensorShapeProto tensorShapeProto)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTypeParser.GetDataViewType(TypeProto typeProto)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, Boolean ownModelFile, IDictionary`2 shapeDictionary)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, Byte[] modelBytes)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, String[] outputColumnNames, String[] inputColumnNames, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, IDictionary`2 shapeDictionary)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxScoringEstimator..ctor(IHostEnvironment env, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, IDictionary`2 shapeDictionary)\r\n   at Microsoft.ML.OnnxCatalog.ApplyOnnxModel(TransformsCatalog catalog, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu)\r\n   at TestMLNet.Program.Main(String[] args) in C:\\demos\\onnx-issue-repro\\TestMLNet\\Program.cs:line 11\r\n```\r\n\r\nA sample using this model directly with OnnxRuntime is in the `TestOnnxRuntime` subfolder.\r\n\r\nThe used ONNX model represens a model similar to what we intend to be using, but has been generated as a dummy from the Iris Dataset:\r\n<details>\r\n<summary>Python Code</summary>\r\n\r\n```python\r\nfrom sklearn.datasets import load_iris\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.ensemble import RandomForestClassifier\r\niris = load_iris()\r\nX, y = iris.data[:10], iris.target[:10]\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\r\nclr = RandomForestClassifier()\r\nclr.fit(X_train, y_train)\r\n# Convert into ONNX format\r\nfrom skl2onnx import convert_sklearn\r\nfrom skl2onnx.common.data_types import FloatTensorType\r\ninitial_type = [(\'float_input\', FloatTensorType([None, 4]))]\r\nonx = convert_sklearn(clr, initial_types=initial_type)\r\nwith open(""rf_iris.onnx"", ""wb"") as f:\r\n    f.write(onx.SerializeToString())\r\n# Compute the prediction with ONNX Runtime\r\nimport onnxruntime as rt\r\nimport numpy\r\nsess = rt.InferenceSession(""rf_iris.onnx"")\r\ninput_name = sess.get_inputs()[0].name\r\nlabel_name = sess.get_outputs()[0].name\r\npred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})\r\n```\r\n</details>\r\n\r\n### System information\r\n\r\n- **OS version/distro**: Windows 10 1909\r\n- **.NET Version (eg., dotnet --info)**: 3.1.0 / SDK 3.1.100\r\n<details>\r\n<summary>dotnet-info output</summary>\r\n\r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.1.100\r\n Commit:    cd82f021f4\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.1.100\\\r\n\r\nHost (useful for support):\r\n  Version: 3.1.0\r\n  Commit:  65f04fb6db\r\n\r\n.NET Core SDKs installed:\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.500 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.502 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.503 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.504 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.505 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.507 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.508 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.509 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.600-preview-009426 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.600-preview-009472 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.600-preview-009497 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.600 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009597 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009618 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.701 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.800-preview-009677 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.800-preview-009696 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.800 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.801 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.802 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.101 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.103 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.104 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.106 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.200-preview-009648 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.200-preview-009748 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.200-preview-009804 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.200 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.201 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.203 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300-preview-010046 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300-preview-010050 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300-preview-010067 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.400-preview-010195 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.400-preview-010219 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.400 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.100-preview6-012264 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.100 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.14 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.14 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.0-preview6.19307.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.14 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n```\r\n</details>'"
548269763,4643,b'FastTree doesnt support changing default calibrator .',"b'### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  .NET core\r\n\r\n### Issue\r\n\r\n- **What did you do?** Using FastTree model for fraud protection.\r\n- **What happened?** FastTree uses default calibrator FixedPlatCailberator and Data Scientist want to use different calibrator and additional calibrator is not same as using just one calibrator , \r\n- **What did you expect?**\r\nso there must have requirement is to just able to use one calibrator .\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
548119403,4641,b'Re-train OneVersus all models',"b'### System information\r\n\r\n- Win 10\r\n- .NET 4.7.2\r\n\r\n### Question\r\nLooking at [https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net\r\n) I see that an AveragedPercepton model can be retrained but this only seems to be when used as a binary classifier.  Using it as part of a multiclass pipeline (see below) then the fit method does not support model parameters. I may be missing something but it does not appear that you can retrain binary classifiers in this scenario.\r\n\r\n### Source code / logs\r\n```\r\nvar dataProcessPipeline = \r\n   ctx.Transforms.Conversion.MapValueToKey(""Category"", ""Prediction"")\r\n  .Append(ctx.Transforms.Text.FeaturizeText(""Description_tf"", textOptions, ""Features""))\r\n  .Append(ctx.Transforms.CopyColumns(""Features"", ""Description_tf""))\r\n  .Append(ctx.Transforms.NormalizeMinMax(""Features"", ""Features""))\r\n  .AppendCacheCheckpoint(ctx);\r\n\r\nvar trainer = ctx.MulticlassClassification.Trainers\r\n  .OneVersusAll(ctx.BinaryClassification.Trainers\r\n  .AveragedPerceptron(""Category"", numberOfIterations: iterations), ""Category"")\r\n  .Append(ctx.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer);\r\nreturn trainingPipeline.Fit(trainingDataView);\r\n```'"
547823362,4640,b'Training step failed: AutoML should return more meaningful errors which can be understood easily by users',"b'Model Builder 16.0.1905.641\r\nOS Windows 10 Pro 17134.765\r\nVS Studion 2019 16.1.1\r\nI made very simple sample - XOR data set. Trying with csv format with "","" seporated and tsv - no matter.\r\nHere is my tsv data set:\r\n**x\ty\tz\r\n1\t0\t1\r\n0\t1\t1\r\n1\t1\t0\r\n0\t0\t0**\r\nWhen i choose binary-classification on a trin step i got this:\r\n`Inferring Columns ...\r\nCreating Data loader ...\r\nLoading data ...\r\nExploring multiple ML algorithms and settings to find you the best model for ML task: binary-classification\r\nFor further learning check: https://aka.ms/mlnet-cli\r\n[Source=AutoML, Kind=Trace] Channel started\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration #Iteration             |\r\nParameter name: PosSample\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=AveragedPerceptronBinary{}  cache=+\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=AveragedPerceptronBinary{}  cache=+ . Exception: System.ArgumentOutOfRangeException: AUC is not definied when there is no positive class in the data\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n[Source=AutoML, Kind=Trace] 1\t\xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae\t00:00:00.6932896\txf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=AveragedPerceptronBinary{}  cache=+\r\n|1    AveragedPerceptronBinary             \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae  \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae       0,7          0             |\r\nSystem.ArgumentOutOfRangeException: AUC is not definied when there is no positive class in the data\r\nParameter name: PosSample\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=SdcaLogisticRegressionBinary{}  cache=+\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=SdcaLogisticRegressionBinary{}  cache=+ . Exception: System.ArgumentOutOfRangeException: AUC is not definied when there is no positive class in the data\r\nParameter name: PosSample\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n[Source=AutoML, Kind=Trace] 2\t\xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae\t00:00:06.9448234\txf=ColumnConcatenating{ col=Features:x,y} xf=Normalizing{ col=Features:Features} tr=SdcaLogisticRegressionBinary{}  cache=+\r\n|2    SdcaLogisticRegressionBinary         \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae  \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae       7,0          0             |\r\nSystem.ArgumentOutOfRangeException: AUC is not definied when there is no positive class in the data\r\nParameter name: PosSample\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=ColumnConcatenating{ col=Features:x,y} tr=LightGbmBinary{}  cache=-\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=ColumnConcatenating{ col=Features:x,y} tr=LightGbmBinary{}  cache=- . Exception: System.ArgumentNullException: Value cannot be null.\r\nParameter name: items\r\n   at System.Collections.Immutable.Requires.FailArgumentNullException(String parameterName)\r\n   at System.Collections.Immutable.ImmutableArray.Create[T](T[] items, Int32 start, Int32 length)\r\n   at Microsoft.ML.Trainers.FastTree.RegressionTreeBase..ctor(InternalRegressionTree tree)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.<>c.<CreateTreeEnsembleFromInternalDataStructure>b__5_0(InternalRegressionTree tree)\r\n   at System.Linq.Enumerable.SelectListIterator`2.ToList()\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsemble`1..ctor(IEnumerable`1 trees, IEnumerable`1 treeWeights, Double bias)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.CreateTreeEnsembleFromInternalDataStructure()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer.CreatePredictor()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] 3\t\xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae\t00:00:00.1836263\txf=ColumnConcatenating{ col=Features:x,y} tr=LightGbmBinary{}  cache=-\r\n|3    LightGbmBinary                       \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae  \xc2\xad\xd2\x90\xd1\x8f\xd0\xb7\xd0\x81\xd0\xb1\xc2\xab\xc2\xae       0,2          0             |\r\nSystem.ArgumentNullException: Value cannot be null.\r\n   at System.Collections.Immutable.Requires.FailArgumentNullException(String parameterName)\r\nParameter name: items\r\n   at System.Collections.Immutable.ImmutableArray.Create[T](T[] items, Int32 start, Int32 length)\r\n   at Microsoft.ML.Trainers.FastTree.RegressionTreeBase..ctor(InternalRegressionTree tree)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.<>c.<CreateTreeEnsembleFromInternalDataStructure>b__5_0(InternalRegressionTree tree)\r\n   at System.Linq.Enumerable.SelectListIterator`2.ToList()\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsemble`1..ctor(IEnumerable`1 trees, IEnumerable`1 treeWeights, Double bias)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.CreateTreeEnsembleFromInternalDataStructure()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer.CreatePredictor()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\nException occured while exploring pipelines:\r\nTraining failed with the exception: System.ArgumentNullException: Value cannot be null.\r\nParameter name: items\r\n   at System.Collections.Immutable.Requires.FailArgumentNullException(String parameterName)\r\n   at System.Collections.Immutable.ImmutableArray.Create[T](T[] items, Int32 start, Int32 length)\r\n   at Microsoft.ML.Trainers.FastTree.RegressionTreeBase..ctor(InternalRegressionTree tree)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.<>c.<CreateTreeEnsembleFromInternalDataStructure>b__5_0(InternalRegressionTree tree)\r\n   at System.Linq.Enumerable.SelectListIterator`2.ToList()\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsemble`1..ctor(IEnumerable`1 trees, IEnumerable`1 treeWeights, Double bias)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.CreateTreeEnsembleFromInternalDataStructure()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer.CreatePredictor()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\nSystem.InvalidOperationException: Training failed with the exception: System.ArgumentNullException: Value cannot be null.\r\nParameter name: items\r\n   at System.Collections.Immutable.Requires.FailArgumentNullException(String parameterName)\r\n   at System.Collections.Immutable.ImmutableArray.Create[T](T[] items, Int32 start, Int32 length)\r\n   at Microsoft.ML.Trainers.FastTree.RegressionTreeBase..ctor(InternalRegressionTree tree)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.<>c.<CreateTreeEnsembleFromInternalDataStructure>b__5_0(InternalRegressionTree tree)\r\n   at System.Linq.Enumerable.SelectListIterator`2.ToList()\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsemble`1..ctor(IEnumerable`1 trees, IEnumerable`1 treeWeights, Double bias)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.CreateTreeEnsembleFromInternalDataStructure()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer.CreatePredictor()\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n   at Microsoft.ML.CLI.CodeGenerator.CodeGenerationHelper.GenerateCode()\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass1_0.<Main>b__0(NewCommandSettings options)\r\nPlease see the log file for more info.\r\nExiting ...`'"
547361667,4638,b'Misc misspellings',"b'Queries which bring up misspellings:\r\n- (45) https://github.com/dotnet/machinelearning/search?q=occurence\r\n- (9) https://github.com/dotnet/machinelearning/search?q=accomodate\r\n- (7) https://github.com/dotnet/machinelearning/search?q=occured\r\n- (6) https://github.com/dotnet/machinelearning/search?q=becuase\r\n- (5) https://github.com/dotnet/machinelearning/search?q=begining\r\n- (2) https://github.com/dotnet/machinelearning/search?q=neccessary\r\n- (2) https://github.com/dotnet/machinelearning/search?q=publically\r\n- (2) https://github.com/dotnet/machinelearning/search?q=accomodated\r\n- (2) https://github.com/dotnet/machinelearning/search?q=preceeding\r\n- (2) https://github.com/dotnet/machinelearning/search?q=acheived\r\n- (2) https://github.com/dotnet/machinelearning/search?q=mantains \r\n- (2) https://github.com/dotnet/machinelearning/search?q=entrypy\r\n- (1) https://github.com/dotnet/machinelearning/search?q=definitly\r\n- (1) https://github.com/dotnet/machinelearning/search?q=realy\r\n- (1) https://github.com/dotnet/machinelearning/search?q=seperate\r\n- (1) https://github.com/dotnet/machinelearning/search?q=orignal\r\n- (1) https://github.com/dotnet/machinelearning/search?q=diffrence\r\n- (1) https://github.com/dotnet/machinelearning/search?q=untill\r\n- (1) https://github.com/dotnet/machinelearning/search?q=sucessfully\r\n\r\nWikipedia [list](https://en.wikipedia.org/wiki/Commonly_misspelled_English_words) was used to create regex:\r\n```bash\r\ngrep -nIiR --color=always --exclude-dir={packages,bin,Tools,./test/BaselineOutput/Common/Text,./test/BaselineOutput/SingleRelease/Text,./test/BaselineOutput/SingleDebug/Text,./test/data} -E ""abcense|absance|acceptible|accidentaly|accomodate|acommodate|acheive|acknowlege|aknowledge|acquaintence|aquaintance|aquire|adquire|aquit|acrage|acerage|adultary|adviseable|advizable|agression|agressive|allegaince|allegience|alegiance|allmost|amatuer|amature|annualy|apparant|aparent|arguement|athiest|awfull|aweful|becuase|beatuful|becomeing|begining|beleive|bellweather|bouy/bouyant|buisness|calender|camoflage|camoflague|Carribean|catagory|cauhgt|caugt|cemetary|cematery|changable|collaegue|collegue|comming|commited|comitted|comparsion|conceed|congradulate|consciencious|concious|consious|concensus|contraversy|cooly|dacquiri|daquiri|decieve|definate|definitly|definately|defiantly|desparate|diffrence|dilema|dissapoint|disasterous|drunkeness|dumbell|embarass|equiptment|excede|exilerate|existance|experiance|extreem|facinating|firey|flourescent|foriegn|freind|gratefull|greatful|garantee|garentee|garanty|guidence|harrass|heighth|heigth|heirarchy|hors derves|ordeurves|humerous|hygene|hygine|hiygeine|higeine|hygeine|hipocrit|ignorence|immitate|imediately|independant|indispensible|innoculate|inteligence|intelligance|jewelery|kernal|liesure|liason|libary|liberry|lisence|lightening|maintainance|maintnance|mantain|medeval|medevil|mideval|millenium|milennium|miniture|miniscule|mischievious|mischevous|mischevious|mispell|misspel|neccessary|necessery|neice|nieghbor|noticable|occassion|occasionaly|occassionally|occurrance|occurence|occured|ommision|omision|orignal|outragous|parliment|passtime|pasttime|percieve|perseverence|personell|personel|plagerize|playright|playwrite|posession|possesion|potatos|preceed|presance|privelege|priviledge|professer|promiss|pronounciation|prufe|prophesy|publically|quarentine|questionaire|questionnair|readible|realy|recieve|reciept|recomend|reccommend|refered|referance|refrence|relevent|revelant|religous|religius|repitition|restarant|restaraunt|rythm|rythem|secratary|secretery|sieze|seperate|sargent|similer|skilfull|speach|speeche|succesful|sucessful|supercede|suprise|surprize|tomatos|tommorow|tommorrow|twelth|tyrany|underate|untill|upholstry|vaccuum|vaccum|vacume|vehical|visious|wether|wierd|wellfare|welfair|wether|wilfull|withold|writting|writeing"" .\r\n```'"
546810837,4637,b'Q: Interpreting Feature PFI results',"b'Hi all,\r\n\r\nI have been doing a little deep dive into some of my models in order to understand a little more about feature relevance. My results for running feature explanatory analysis is as follows for bin classification:\r\n\r\n2020-01-08 11:34:03.813 +00:00 [INF] BinaryFastTreeParameters\r\n2020-01-08 11:34:03.815 +00:00 [INF] Bias: 0\r\n2020-01-08 11:34:03.816 +00:00 [INF] Feature Weights:\r\n2020-01-08 11:34:03.843 +00:00 [INF]  Feature: CloseWeight: 0.1089412\r\n2020-01-08 11:34:03.931 +00:00 [INF]  Feature: OpenWeight: 0.3691619\r\n2020-01-08 11:34:03.932 +00:00 [INF]  Feature: HighWeight: 0.06676193\r\n2020-01-08 11:34:03.933 +00:00 [INF]  Feature: LowWeight: 0.1926264\r\n2020-01-08 11:34:03.934 +00:00 [INF]  Feature: STO_FastStochWeight: 0.19846\r\n2020-01-08 11:34:03.938 +00:00 [INF]  Feature: STO_StochKWeight: 0.5019926\r\n2020-01-08 11:34:03.941 +00:00 [INF]  Feature: STO_StochDWeight: 0.3781931\r\n2020-01-08 11:34:03.942 +00:00 [INF]  Feature: STOWeight: 0\r\n2020-01-08 11:34:03.943 +00:00 [INF]  Feature: CCI_TypicalPriceAvgWeight: 0.131141\r\n2020-01-08 11:34:03.944 +00:00 [INF]  Feature: CCI_TypicalPriceMADWeight: 0.1299266\r\n2020-01-08 11:34:03.946 +00:00 [INF]  Feature: CCIWeight: 1\r\n2020-01-08 11:34:03.947 +00:00 [INF]  Feature: RSIDownWeight: 0.4761779\r\n2020-01-08 11:34:03.948 +00:00 [INF]  Feature: RSIUpWeight: 0.1249975\r\n2020-01-08 11:34:03.951 +00:00 [INF]  Feature: RSIWeight: 0.2877662\r\n2020-01-08 11:34:03.952 +00:00 [INF]  Feature: MOMWeight: 0.1822069\r\n2020-01-08 11:34:03.953 +00:00 [INF]  Feature: ADX_PositiveDirectionalIndexWeight: 0.2435836\r\n2020-01-08 11:34:03.954 +00:00 [INF]  Feature: ADX_NegativeDirectionalIndexWeight: 0.4263106\r\n2020-01-08 11:34:03.955 +00:00 [INF]  Feature: ADXWeight: 0.1899773\r\n2020-01-08 11:34:03.956 +00:00 [INF]  Feature: CMOWeight: 0.2601428\r\n\r\nBut for PFI I have the following:\r\n2020-01-08 11:34:09.369 +00:00 [INF] Calculating Binary Classification Feature PFI\r\n2020-01-08 11:34:09.371 +00:00 [INF] Feature PFI for learner:BinaryFastTree\r\n2020-01-08 11:34:09.383 +00:00 [INF] Close|\t0.000000\r\n2020-01-08 11:34:09.384 +00:00 [INF] Open|\t0.000000\r\n2020-01-08 11:34:09.385 +00:00 [INF] High|\t0.000000\r\n2020-01-08 11:34:09.386 +00:00 [INF] Low|\t0.000000\r\n2020-01-08 11:34:09.391 +00:00 [INF] STO_FastStoch|\t0.000000\r\n2020-01-08 11:34:09.400 +00:00 [INF] STO_StochK|\t0.000000\r\n2020-01-08 11:34:09.401 +00:00 [INF] STO_StochD|\t0.000000\r\n2020-01-08 11:34:09.402 +00:00 [INF] STO|\t0.000000\r\n2020-01-08 11:34:09.404 +00:00 [INF] CCI_TypicalPriceAvg|\t0.000000\r\n2020-01-08 11:34:09.406 +00:00 [INF] CCI_TypicalPriceMAD|\t0.000113\r\n2020-01-08 11:34:09.408 +00:00 [INF] CCI|\t0.000000\r\n2020-01-08 11:34:09.414 +00:00 [INF] RSIDown|\t0.000221\r\n2020-01-08 11:34:09.416 +00:00 [INF] RSIUp|\t0.000000\r\n2020-01-08 11:34:09.431 +00:00 [INF] RSI|\t0.000000\r\n2020-01-08 11:34:09.443 +00:00 [INF] MOM|\t-0.003003\r\n2020-01-08 11:34:09.457 +00:00 [INF] ADX_PositiveDirectionalIndex|\t0.000000\r\n2020-01-08 11:34:09.467 +00:00 [INF] ADX_NegativeDirectionalIndex|\t0.000000\r\n2020-01-08 11:34:09.470 +00:00 [INF] ADX|\t0.000000\r\n2020-01-08 11:34:09.479 +00:00 [INF] CMO|\t0.000000\r\n\r\nMy question is essentially - what should I read (if anything) into zero values for PFI. The evaluation score too:\r\n020-01-08 11:34:17.135 +00:00 [INF] Score: -4.640871\r\n2020-01-08 11:34:17.138 +00:00 [INF] Probability: 0.1351293\r\n\r\nI would appreciate any thoughts that you may have regarding using such info to improve model veracity. \r\n\r\nThank you\r\nFig\r\n\r\n'"
546514602,4634,"b""Sweepable Parameter can't handle Russia Format""","b'If, for example, in SweepableFloatParam, the raw text value is 0,00123454, it will be parsed into 123454 instead of 0.00123454\r\n\r\nSee this [Issue](https://github.com/dotnet/machinelearning-modelbuilder/issues/363) for further details'"
545881605,4632,b'image classification needs cancel',"b'Hi, is there any plan to add cancel support for image classification API so that we can cancel an image classification training by passing in a cancellation token? \r\n\r\n[related issue](https://app.zenhub.com/workspaces/mlnet-tools-5cde1c97e3106e39e8ae08fc/issues/dotnet/machinelearning-modelbuilder/413)'"
545407193,4630,b'Q: A calibrator is required for Bin Classification Evaluate',"b'Hi,\r\n\r\nConcerning Binary Classification features analysis I find that for evaluation of scores a calibrator is required, such as\r\n\r\nLogger.Info(""===== Evaluating Model\'s accuracy with Test data ====="");\r\n            var trainingPipeline = dataProcessPipeline.Append(algorithm)\r\n                .Append(mlContext.BinaryClassification.Calibrators.Platt()); \r\n\r\nI can understand this being standard behaviour for uncalibrated learners but even with calibrated learners such as the following this is still needed (for the Probability column to be found):\r\n\r\nvar algorithm = mlContext.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: ""Label"",  featureColumnName: ""Features"");\r\n\r\nIs this correct behaviour?\r\n\r\nMany thanks\r\n\r\nFig'"
544399194,4619,"b'[AutoML] the ""Label"" column was not found'","b'System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Framework 4.8\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n i use this code:\r\n`MLContext mlContext = new MLContext();\r\n            ColumnInferenceResults columnInference = mlContext.Auto().InferColumns(fname_train, labelColumnIndex: 0, hasHeader: false, separatorChar: \';\') ;\r\n            TextLoader textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n            IDataView trainDataView = textLoader.Load(fname_train);\r\n            IDataView testDataView = textLoader.Load(fname_test);\r\n            IDataView validDataView = textLoader.Load(fname_valid);\r\n            \r\n            ColumnInformation columnInformation = columnInference.ColumnInformation;\r\n            \r\n            var experimentSettings = new MulticlassExperimentSettings();\r\n            experimentSettings.MaxExperimentTimeInSeconds = MyExperimentTime;\r\n            experimentSettings.CancellationToken = cts.Token;          \r\n            experimentSettings.OptimizingMetric = MulticlassClassificationMetric.MacroAccuracy;\r\n            experimentSettings.CacheDirectory = null;\r\n            \r\n            var progressHandler = new MulticlassExperimentProgressHandler();\r\n            progressHandler.EventUpdateMulticlassExperiment += TextBoxNewDataMulticlassExperiment;            \r\n            \r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateMulticlassClassificationExperiment(experimentSettings)\r\n                .Execute(trainDataView, validDataView, columnInformation, progressHandler: progressHandler);`\r\nto generate the model successfully\r\n- **What happened?**\r\nWhen I load the model by this code\r\n`public ObservableCollection<MLmodel> MLmodels { get; set; }\r\n        private MLContext mlContext = new MLContext();\r\n        DataViewSchema modelInputSchema;\r\n\r\n        private Dictionary<string, PredictionEngine<BarLoadBinary, BarLoadBinaryPrediction>> binaryDictionary = new Dictionary<string, PredictionEngine<BarLoadBinary, BarLoadBinaryPrediction>>();\r\n        private Dictionary<string, PredictionEngine<BarLoadMulti, BarLoadMultiPrediction>> multiDictionary = new Dictionary<string, PredictionEngine<BarLoadMulti, BarLoadMultiPrediction>>();\r\n        private Dictionary<string, PredictionEngine<BarLoadRegression, BarLoadRegressionPrediction>> regressionDictionary = new Dictionary<string, PredictionEngine<BarLoadRegression, BarLoadRegressionPrediction>>();\r\n\r\n        public Listener (ObservableCollection<MLmodel> mlModels, string ip, string port)\r\n        {\r\n            MLmodels = mlModels;\r\n            IPadress = ip;\r\n            Port = port;\r\n\r\n            try\r\n            {\r\n                foreach (var model in MLmodels)\r\n                {\r\n                    ITransformer loadedModel = mlContext.Model.Load(model.FileNameModel, out DataViewSchema modelInputSchema);\r\n\r\n                    if (model.TitleModel == ""Binary Classification"")\r\n                        binaryDictionary.Add(model.PostfixModel, mlContext.Model.CreatePredictionEngine<BarLoadBinary, BarLoadBinaryPrediction>(loadedModel));\r\n                    if (model.TitleModel == ""Multi-class Classification"")\r\n                        multiDictionary.Add(model.PostfixModel, mlContext.Model.CreatePredictionEngine<BarLoadMulti, BarLoadMultiPrediction>(loadedModel));\r\n                    if (model.TitleModel == ""Regression"")\r\n                        regressionDictionary.Add(model.PostfixModel, mlContext.Model.CreatePredictionEngine<BarLoadRegression, BarLoadRegressionPrediction>(loadedModel));\r\n                }\r\n            }\r\n            catch (Exception ex) { MessageBox.Show(ex.ToString()); }\r\n\r\n            ipPoint = new IPEndPoint(IPAddress.Parse(IPadress), Convert.ToInt32(Port));\r\n            \r\n        }`\r\n, I get an error saying that the ""Label"" column was not found\r\n- **What did you expect?**\r\nI expected full application of models\r\n\r\n![issue](https://user-images.githubusercontent.com/18124355/71646139-e6821980-2cda-11ea-9804-10bf533cac4d.PNG)\r\n![issue2](https://user-images.githubusercontent.com/18124355/71646140-e6821980-2cda-11ea-8253-4e6c1307b94c.PNG)\r\n![issue3](https://user-images.githubusercontent.com/18124355/71646142-e71ab000-2cda-11ea-9e0d-2f82f948f8fe.PNG)\r\n\r\n\r\n\r\n\r\n\r\n'"
544395631,4618,"b""Could not find label column 'Label'""","b'### System information\r\n\r\n- Microsoft.ML 1.4.0\r\n- dotnet Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI\'am running  a test for the full data set\r\n```\r\n            var pipeline = context.Transforms.CustomMapping<FromLabel, ToLabel>(\r\n    mapAction: (input, output) => { output.SentimentLabel = input.Sentiment == 0? ""Bad Review \xf0\x9f\x98\xa1"" : ""Good Review  \xf0\x9f\x98\x8d""; },\r\n    contractName: ""MyLambda"")\r\n     .Append(context.Transforms.Text.FeaturizeText(\r\n        outputColumnName: ""Features"",\r\n        inputColumnName: nameof(DataInputModel.SentimentText)))\r\n    .Append(context.BinaryClassification.Trainers.SdcaLogisticRegression());\r\n\r\n            Console.WriteLine(""Performing cross validation..."");\r\n       var res=     data.Preview();\r\n            var cvResults = context.BinaryClassification.CrossValidate(\r\n                partitions.TrainSet,\r\n               pipeline,5);\r\n```\r\n\r\n- **What happened?**\r\nAn exceptions is thrown ""Could not find label column \'Label\'""\r\n- **What did you expect?**\r\nget result of the test or a clean error message \r\n### Source code / logs\r\nData CSV Source example >\r\n```\r\nSentimentText\tSentiment\r\n""first think another Disney movie, might good, it\'s kids movie. watch it, can\'t help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can\'t help, enjoy movie! give 10/10!""\t 1\r\n""Put aside Dr. House repeat missed, Desperate Housewives (new) watch one. don\'t know exactly plagued movie. never thought I\'d say this, want 15 minutes fame back.<br /><br />Script, Direction, can\'t say. recognized stable actors (the usual suspects), thought Herbert Marshall class addition sat good cheesy flick. Boy, wrong. Dullsville.<br /><br />My favorite parts: """"office girl"""" makes 029 keypunch puts cards 087 sorter. LOL @ """"the computer"""". I\'d like someone identify next device - 477 ? It\'s even dinosaur\'s time.<br /><br />And dinosaurs don\'t much time waste.""\t 0\r\n""big fan Stephen King\'s work, film made even greater fan King. Pet Sematary Creed family. moved new house, seem happy. pet cemetery behind house. Creed\'s new neighbor Jud (played Fred Gwyne) explains burial ground behind pet cemetery. burial ground pure evil. Jud tells Louis Creed bury human (or kind pet) burial ground, would come back life. problem, come back, person, they\'re evil. Soon Jud explains everything Pet Sematary, everything starts go hell. wont explain anymore don\'t want give away main parts film. acting Pet Sematary pretty good, needed little bit work. story one main parts movie, mainly original gripping. film features lots make-up effects make movie way eerie, frightening. One basic reasons movie sent chills back, fact make-up effects. one character film truly freaky. character """"Zelda."""" particular character pops film three times precise. Zelda Rachel Creed\'s sister passed away years before, Rachel still haunted her. first time Zelda appears movie isn\'t generally scary isn\'t talking anything, second time worst, honest, second time scares living **** me. absolutely nothing wrong movie, almost perfect. Pet Sematary delivers great scares, pretty good acting, first rate plot, mesmerizing make-up. truly one favorite horror films time. 10 10.""\t 1\r\n""watched horrid thing TV. Needless say one movies watch see much worse get. Frankly, don\'t know much lower bar go. <br /><br />The characters composed one lame stereo-type another, obvious attempt creating another """"Bad News Bears"""" embarrassing say least.<br /><br />I seen prized turkeys time, reason list since """"Numero Uno"""".<br /><br />Let put way, watched Vanilla Ice movie, bad funny. This...this...is even good.""\t 0\r\n```\r\n```\r\nSystem.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  Message=Could not find label column \'Label\'\r\nArg_ParamName_Name\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n   at Microsoft.ML.BinaryClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numberOfFolds, String labelColumnName, String samplingKeyColumnName, Nullable`1 seed)\r\n   at SentimentAnalyzer.Program.Main(String[] args) in \\Program.cs:line 34\r\n```\r\n'"
544351507,4615,b'Support saving as ONNX for ExpressionTransformer',"b'This is needed, as mentioned in [this comment](https://github.com/dotnet/machinelearning/pull/4548#pullrequestreview-335990337).'"
544280598,4611,b'Broken cross references in estimator transformer docs',b'See https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.expressionestimator?view=ml-dotnet&branch=smoke-test\r\n\r\nThe xrefs should render as hyperlinks to the relevant API docs.\r\n\r\nXrefs not rendering:\r\n- <xref:Microsoft.ML.Data.ExpressionTransformer> This one might be because it is new\r\n- <xref:Microsof.ML.Data.VectorDataViewType> This one should work'
544278343,4610,b'Move API docs for new APIs into <remarks> (rather than summary)',"b'Problem seen here:\r\n- See: https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms?view=ml-dotnet&branch=smoke-test \r\n- https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data?view=ml-dotnet&branch=smoke-test\r\n\r\nIncludes docs for these components\r\n\r\n- https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.svmlightloader?view=ml-dotnet&branch=smoke-test\r\n- https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.expressionestimator?view=ml-dotnet&branch=smoke-test\r\n\r\n\r\nAll of the docs are in the summary element, which renders too much information on the summary page. If we move most of it into the remarks section, then this will be fixed.\r\n\r\n<img width=""1132"" alt=""Screen Shot 2019-12-31 at 2 10 14 PM"" src=""https://user-images.githubusercontent.com/3302433/71635220-80f93480-2bd7-11ea-90af-87d1fc33907b.png"">\r\n'"
543962130,4607,b'Not finding assembly for Microsoft.ML ',"b'### System information\r\n\r\n- **OS version: Windows 10 (64)\r\n- **.NET Version : .Net Core 3.1\r\n\r\n### Issue\r\nI have installed ML.Net, I am trying to build a simple ML app using default template in VS 2019, \r\nAfter completing all five steps (Scenario, Data, Train, Evaluate, Code) successfully when it generate some code, I am not able to compile the code because the assembly Microsoft.ML is missing\r\nI tried to install the assembly using Nuget but not find the assembly, (though I see  ML.NET Model Builder is installed )\r\n\r\nI need Microsoft.ML assembly version 1.4.0 , but not finding any. please guide \r\n\r\n### Source code / logs\r\nPlease take a look at the attached screenshot \r\n![ml-net-not-found](https://user-images.githubusercontent.com/37655243/71594028-3090c100-2b5c-11ea-84d1-062cfe89f96a.png)\r\n\r\n\r\n\r\n\r\n'"
543562955,4606,b'Q: Feature Contributions for Timeseries analysis ',"b'Hi there,\r\n\r\nI use the fabulous time series analysis models and would appreciate a little help to understand what support there is (if any) to understand:\r\n\r\n- Feature weights, Importance and Contributions (as with regression and classification learners)\r\n- PermutationMetrics \r\n\r\nMuch obliged\r\n\r\nFig\r\n\r\n'"
543114556,4605,b'How to create NN model for NEAT in ML dot net ??',b'Happy Christmas Guys...\r\n\r\nI want to create a **Neural Net model** in ML.NET and also want to manipulate weights and biases for **NEAT(Neuro Evolution of Augmented Topologies)**. Is this possible to dot this in **_native c# only_**?\r\nIs there **any way to create Neural Nets** if not when we will get the ability to create NN in c# or there **any plan to provide any API for NN in the future**? I am really sick of Tensorflow.\r\n\r\nEnjoy your holiday guys...\r\n'
541953441,4603,b'Passing input from GPU',"b'I am working in a pipeline architecture where all intermediary data resides in the GPU. I am interested in passing data already in the GPU into a DL network with the output still residing in the GPU to be passed to the next element in a pipeline. Essentially I would like to pass a cuda array into the network, get an output and convert back into a cuda array. I\xe2\x80\x99d like to do this without having to perform CPU/GPU copies. Is this possible at the moment?'"
541200983,4601,b'Generated Model cannot be converted to ONNX',"b'**System Information (please complete the following information):**\r\n - Model Builder Version: 1.4.0\r\n - Visual Studio Version 2019/16.3.10\r\n\r\n**Describe the bug**\r\nI used the Model Builder to Classify basketball balls and soccer balls. It works very well. then I tried to convert the generated model to ONNX using the code bellow:\r\n`\r\nstring modelPath = AppDomain.CurrentDomain.BaseDirectory + ""MLModel.zip"";\r\n\r\nITransformer mlModel = mLContext.Model.Load(modelPath, out var modelInputSchema);\r\n\r\nIDataView dataView = mLContext.Data.LoadFromTextFile<ModelInput>(\r\n                                            path: DATA_FILEPATH,\r\n                                            hasHeader: true,\r\n                                            separatorChar: \'\\t\',\r\n                                            allowQuoting: true,\r\n                                            allowSparse: false);\r\n\r\nMemoryStream memoryStream = new MemoryStream();\r\n\r\n**mLContext.Model.ConvertToOnnx(mlModel, dataView, memoryStream);**\r\n\r\nbyte[] data = memoryStream.ToArray();\r\n\r\nusing (FileStream fileStream = File.Create(@""C:\\temp\\SportsBall.onnx"")) {\r\n       fileStream.Write(data, 0, data.Length);\r\n}\r\n`\r\nIn the Bold line I get the following error:\r\n\r\nSystem.InvalidOperationException: \'The targeted pipeline can not be fully converted into a well-defined ONNX model. Please check if all steps in that pipeline are convertible to ONNX and all necessary variables are not dropped (via command line arguments).\'\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Create a simple model \r\n2. Convert to ONNX model with provided code\r\n3. See Error\r\n\r\n**Expected behavior**\r\nThe new ONNX model should be generated in the path:\r\nC:\\temp\\SportsBall.onnx\r\n\r\n**Screenshots**\r\nNA\r\n\r\n**Additional context**\r\nNA\r\n'"
541112651,4600,b'LightGbm in Linux Container',"b""### System information\r\n\r\n- **Ubuntu*:\r\n- **.NET Core 3.0**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDeployed a .Net Core 3.0 ML.NET app to Azure Container Instances (Linux Container). This same training app was working with other trainers but fails with the LightGbmRanking trainer.\r\n\r\n- **What happened?**\r\n\r\nReceived the error below.\r\n\r\n\r\n- **What did you expect?**\r\n\r\nI expected training to complete.\r\n\r\n### Source code / logs\r\n\r\n`Unhandled exception. System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: liblib_lightgbm: cannot open shared object file: No such file or directory\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmInterface.DatasetCreateFromSampledColumn(IntPtr sampleValuePerColumn, IntPtr sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String parameters, IntPtr& ret)\r\n   at Microsoft.ML.Trainers.LightGbm.Dataset..ctor(Double[][] sampleValuePerColumn, Int32[][] sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String param, Single[] labels, Single[] weights, Int32[] groups)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)`\r\n\r\n- **What have you tried?**\r\n\r\nInstalling libomp in the docker build as mentioned [here](https://github.com/dotnet/machinelearning/issues/1282)"""
540768552,4599,b'SEE LINK https://dotnet.microsoft.com/learn/ml-dotnet/what-is-mldotnet',"b'### System information\r\n\r\n- **OS version/distro**:\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\nML.NET 1.4.0\r\n\r\n### Issue\r\nSEE LINK https://dotnet.microsoft.com/learn/ml-dotnet/what-is-mldotnet\r\n\r\nin test code below line write wrong\r\n\r\nvar predEngine = mlContext.Model.CreatePredictionEngine(model); \r\n\r\nin framework CreatePredictionEngine definition not same as above line.\r\n \r\n\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
540149339,4595,b'pipeline.Fit Method not responding on after 1046th row in dataset',"b'I have a dataset with 3000 (BrandId, price) rows. When I run sdca regression algorithm in ML.net, pipeline.Fit method get stuck, it doesnt go to the next row in code (it keeps running but with %0 cpu usage). I thought the data may have problem, then I reduced the data. But when I remove until 1046, it starts working, but when I add one more row, it stops responding. The data looks normal, nothing is abnormal in my opionion\r\nyou can find the issue in my question at stackoverflow\r\n[you can find the code and dataset in this link](https://stackoverflow.com/questions/59404619/ml-net-pipeline-fit-not-responding-after-specific-row-number-in-d)'"
539843398,4589,b'throw build error for missing documentation of public class/method/property etc',b'RT'
539698912,4586,b'how to pass dynamics created class or object in function In of TRow type',"b'https://github.com/dotnet/machinelearning/blob/290e0695b22cf9c6f49fcd222b10553b5a19a63a/src/Microsoft.ML.Data/Model/PredictionEngineExtensions.cs#L27\r\n\r\n MLContextRef.Model.CreatePredictionEngine(Of TRow, TDst)(loadedModel) \r\n\r\n\r\nhow to pass dynamics created class or object in above function In of TRow type\r\n\r\n\r\n'"
539659045,4585,b'Cannot delete image file passsed to PredictionEngine for Image Classification after disposing the engine',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro 10.0.18363\r\n- **.NET Version (eg., dotnet --info)**:   3.1.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**: I\'ve tried to delete an image file used by PredictionEngine after disposing the engine\r\n- **What happened?**: An exception was thorwn: ""The process cannot access the file  because it is being used by another process.""\r\n- **What did you expect?**: Image file deletion\r\n\r\n### Source code / logs\r\n```\r\nprivate ImagePrediction ClassifySingleImage(MLContext mLContext, ITransformer model, string imagePath)\r\n{\r\n    var imageData = new ImageData()\r\n    {\r\n        ImagePath = imagePath\r\n    };\r\n    var predictor = mLContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(model);\r\n    var prediction = predictor.Predict(imageData);\r\n    predictor.Dispose();\r\n    System.IO.File.Delete(imagePath);  // throws a FileIO exception\r\n    return prediction;\r\n}\r\n```'"
539332343,4583,b'Prediction result with custom properties',"b'### System information\r\n\r\n- Windows 10 Fall\r\n- .NET Core 3.0\r\n\r\n### Issue\r\n\r\n- Tried to run the ""Detect anomalies in product sales with ML.NET"" sample in https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/sales-anomaly-detection\r\n- Could not associate the prediction result with business object id\r\n- As you can see, the ProductSalesPrediction object contains the prediction result. As end users, we often need to associate individual prediction result per business object id, for example, a particular sales date / sales id. \r\n\r\nI could have used array index to work out the associated input data, but that\'s not intuitive.\r\n\r\nI searched the documentation in GitHub and microsoft.com but could not find one.\r\n\r\nWould be nice if we allow user to define the prediction object like this:\r\n\r\n```\r\npublic class ProductSalesPrediction\r\n{\r\n   public string Month { get; set; }\r\n\r\n   public string SaleId { get; set; }\r\n\r\n    [VectorType(3)]\r\n    public double[] Prediction { get; set; }\r\n}\r\n```\r\n\r\n### Source code / logs\r\n\r\nExact same source code in the sample mentioned above.'"
538733642,4579,"b'In CodeGenerator, Recommendation scenario Training cause null reference Exception'","b""Just dig in a bit. The null reference exception is because, in the AutoML generated pipeline, one of the fields in the trainer node's property dictionary is null, which crashes CodeGenerator."""
537934897,4578,b'YOLOv3 shows ArgumentOutOfRangeException',"b'Hello\r\nI\'m working on the latest version of Visual Studio 2019 on Windows 10\r\nI have tried to work on object detection using yolov3 model. The yolov3.onnx file has been downloaded from [https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3](url)\r\n\r\nBelow is the snippet of the error shown on the console screen.\r\n![consoleError](https://user-images.githubusercontent.com/33253391/70851172-f9fa4b80-1eb7-11ea-857b-0c27402650f7.PNG)\r\n\r\nThis is the image of the output.\r\n![output error](https://user-images.githubusercontent.com/33253391/70851408-9d4c6000-1eba-11ea-8723-6861c5ef5755.PNG)\r\n\r\n\r\nThe code is similar as used for object detection using tiny-yolov2. Following are the changes made in the code.\r\n\r\n1.) ImageNetPrediction.cs file\r\npublic class ImageNetPrediction\r\n    {\r\n        [ColumnName(""yolonms_layer_1/ExpandDims_3:0"")]\r\n        public float[] PredictedLabels;\r\n    }\r\n\r\n2.) YoloOutputParser.cs\r\npublic const int ROW_COUNT = 13;\r\npublic const int COL_COUNT = 13;\r\npublic const int CHANNEL_COUNT = 125;\r\npublic const int BOXES_PER_CELL = 5;\r\npublic const int BOX_INFO_FEATURE_COUNT = 5;\r\npublic const int CLASS_COUNT = 80;\r\npublic const float CELL_WIDTH = 32;\r\npublic const float CELL_HEIGHT = 32;\r\n.\r\n.\r\n.\r\nprivate string[] labels = new string[]\r\n        {\r\n            ""person"", ""bicycle"", ""car"", ""motorbike"", ""aeroplane"", ""bus"", ""train"", ""truck"", ""boat"", ""traffic light"", ""fire hydrant"", ""stop sign"", ""parking meter"", ""bench"", ""bird"", ""cat"", ""dog"",\r\n            ""horse"", ""sheep"", ""cow"", ""elephant"", ""bear"", ""zebra"", ""giraffe"", ""backpack"", ""umbrella"", ""handbag"", ""tie"", ""suitcase"", ""frisbee"", ""skis"", ""snowboard"", ""sports ball"", ""kite"",\r\n            ""baseball bat"", ""baseball glove"", ""skateboard"", ""surfboard"", ""tennis racket"", ""bottle"", ""wine glass"", ""cup"", ""fork"", ""knife"", ""spoon"", ""bowl"", ""banana"", ""apple"", ""sandwich"", ""orange"",\r\n            ""broccoli"", ""carrot"", ""hot dog"", ""pizza"", ""donut"", ""cake"", ""chair"", ""sofa"", ""pottedplant"", ""bed"", ""diningtable"", ""toilet"", ""tvmonitor"", ""laptop"", ""mouse"", ""remote"", ""keyboard"",\r\n            ""cell phone"", ""microwave"", ""oven"", ""toaster"", ""sink"", ""refrigerator"", ""book"", ""clock"", ""vase"", ""scissors"", ""teddy bear"", ""hair drier"", ""toothbrush""\r\n        };\r\n\r\n3.) OnnxModelScorer.cs\r\npublic struct TinyYoloModelSettings\r\n        {\r\n            public const string ModelInput = ""input_1"";\r\n            public const string ModelOutput = ""yolonms_layer_1/ExpandDims_3:0"";\r\n        }\r\n.\r\n.\r\n.\r\nvar pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""image"", imageFolder: """", inputColumnName: nameof(ImageNetData.ImagePath))\r\n                            .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""image"", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: ""input_1""))\r\n                            .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""image""))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: modelLocation, outputColumnNames: new[] { TinyYoloModelSettings.ModelOutput }, inputColumnNames: new[] { TinyYoloModelSettings.ModelInput }));\r\n.\r\n.\r\n.\r\npublic static void Main()\r\n        {\r\n            var assetsRelativePath = @""../../../assets"";\r\n            string assetsPath = GetAbsolutePath(assetsRelativePath);\r\n            var modelFilePath = Path.Combine(assetsPath, ""Model"", ""yolov3.onnx"");\r\n            var imagesFolder = Path.Combine(assetsPath, ""images"");\r\n            var outputFolder = Path.Combine(assetsPath, ""images"", ""output"");\r\n\r\n\r\n\r\nAlso, how should I carry out the Preprocessing and Postprocessing steps?'"
537388411,4575,b'how to build DataViewSchema with Annotations?',"b'### System information\r\n\r\n- **OS version/distro**:\r\nwindows 7\r\n- **.NET Version (eg., dotnet --info)**: \r\n4.6.1\r\n### Issue\r\nhow to build DataViewSchema with Annotations?\r\n- **What did you do?**\r\nhow to build DataViewSchema with Annotations?\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
537387635,4574,"b""I am able to dynamically train and create my regression model just fine from a string[] of column names. However, when I try to pass in a dynamic object with the same Parameter names as Dictionary Key Pair properties it throw the error:  System.ArgumentOutOfRangeException: 'Could not find input column '<MyColumn>'' Where <MyColumn> is the first parameter that the model is looking for.""","b""### System information\r\n\r\n- **OS version/distro**:\r\nwindows 7\r\n- **.NET Version (eg., dotnet --info)**: \r\n4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am able to dynamically train and create my regression model just fine from a string[] of column names. However, when I try to pass in a dynamic object with the same Parameter names as for create CreatePredictionEngine\r\n- **What happened?**\r\nIt throw the error:\r\n\r\nSystem.ArgumentOutOfRangeException: 'Could not find input column '<MyColumn>\r\n\r\nSystem.ArgumentOutOfRangeException: Could not find input column 'Pressure'\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Data.OneToOneTransformerBase.CheckInput(DataViewSchema inputSchema, Int32 col, Int32& srcCol)\r\n   at Microsoft.ML.Data.OneToOneTransformerBase.OneToOneMapperBase..ctor(IHost host, OneToOneTransformerBase parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.ColumnCopyingTransformer.Mapper..ctor(ColumnCopyingTransformer parent, DataViewSchema inputSchema, ValueTuple`2[] columns)\r\n   at Microsoft.ML.Transforms.ColumnCopyingTransformer.MakeRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n\r\n- **What did you expect?**\r\nMLContextRef.Model.CreatePredictionEngine use dynamic created class or any other way i want to achive requirement.\r\n\r\n### Source code / logs\r\n\r\npredictionEngine = MLContextRef.Model.CreatePredictionEngine(dynamic created class obj, result)(loadedModel)\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
537302116,4572,b'FastTree regression samples use FastForest instead',"b'I noticed some FastTree samples using FastForest, namely:\r\nhttps://github.com/dotnet/machinelearning/blob/fa62c8196e345de82918469b56c2c6c3b16321c1/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/FastTree.cs#L30-L32\r\nand\r\nhttps://github.com/dotnet/machinelearning/blob/fa62c8196e345de82918469b56c2c6c3b16321c1/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/FastTreeTweedie.cs#L30-L32\r\nAppears to be a mistake introduced in PR #3948.'"
537273936,4571,b'Memory leak when featurizing text with the default settings',"b'When featurizing text with the default settings, references to the entire dataset rows are kept around'"
537154606,4568,"b""Tensorflow.RuntimeError: 'Current graph is not default graph. Default Graph Key""","b'We would like to be able to load multiple models from disk on startup, then infer against them without having to reload from disk each pass.\r\n\r\nIf I try to keep 2 models in memory at the same time, I get an error if not calling against the last one initialized from disk.\r\n\r\ni.e. this works - only including code needed to generate the error:\r\n```\r\n            MLContext context = new MLContext();\r\n\r\n            TensorFlowModel model1 = context.Model.LoadTensorFlowModel(""Model1"");\r\n\r\n            TensorFlowEstimator estimator1 = model1.ScoreTensorFlowModel(""serving_default_input_1"", ""StatefulPartitionedCall"");\r\n\r\n            TensorFlowModel model2 = context.Model.LoadTensorFlowModel(""Model2"");\r\n\r\n            TensorFlowEstimator estimator2 = model2.ScoreTensorFlowModel(""serving_default_input_1"", ""StatefulPartitionedCall"");\r\n```\r\n\r\n\r\nbut this throws an error like ""Tensorflow.RuntimeError: \'Current graph is not default graph"":\r\n```\r\n            MLContext context = new MLContext();\r\n\r\n            TensorFlowModel model1 = context.Model.LoadTensorFlowModel(""Model1"");\r\n\r\n            TensorFlowModel model2 = context.Model.LoadTensorFlowModel(""Model2"");\r\n            \r\n            TensorFlowEstimator estimator1 = model1.ScoreTensorFlowModel(""serving_default_input_1"", ""StatefulPartitionedCall"");\r\n\r\n            TensorFlowEstimator estimator2 = model2.ScoreTensorFlowModel(""serving_default_input_1"", ""StatefulPartitionedCall"");\r\n```\r\n\r\n\r\nI guess we could roll our own process to load from disk to stream 1x, then call context.Model.Load() but that still smells wrong - we\'re still initializing the model over and over just avoiding disk calls.  Is this a bug or are we doing something wrong?'"
537109238,4567,b'Incorrect transformer for TypeConvertingEstimator in summary description',b'Should be TypeConvertingTransformer\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 275f68f3-e68d-effc-a50d-f885902b3d70\n* Version Independent ID: 68b69288-3e30-9de2-e987-ccff3cd3f08b\n* Content: [TypeConvertingEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.typeconvertingestimator?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TypeConvertingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TypeConvertingEstimator.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'
536745718,4566,b'cache elapsedSeconds error',"b'Method\xef\xbc\x9aSamples.Dynamic.Cache.TimeToScanIDataView\r\nLine81\xef\xbc\x9areturn (lines, columnAverage, elapsed.Seconds);\r\n\r\nRecommend to:return (lines, columnAverage, elapsed.TotalMilliseconds);'"
535423004,4559,"b'How to use and pass runtime created class in .Model.CreatePredictionEngine(Of TRow, TDst)(loadedModel)'","b'i have created class and its field with assign value at run time and want to pass it in (of TRow)\r\nModel.CreatePredictionEngine(Of TRow, TDst)(loadedModel)\r\n'"
535419919,4558,b'ImageClassification training stops',"b""### System information\r\n\r\n- **.NET Version .NET Core 3.0**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to train MulticlassClassification with dataset of 2096 images and 8 classes\r\n- **What happened?**\r\nTraining just stops at one point in the Fit() method. It never exits the method.\r\nNo exeptions as well.\r\nWhen I reduce the number images for example to 1100, then training successfuly ends.\r\nAnd it doesn't seem to make any difference witch images I remove.\r\n\r\n### Source code / logs\r\nThis is the last log in the output window. After that CPU activity remains high for few seconds and \r\nthen drops to 0.\r\n\r\nPhase: Bottleneck Computation, Dataset used: Validation, Image Index: 405\r\nPhase: Bottleneck Computation, Dataset used: Validation, Image Index: 406\r\nPhase: Bottleneck Computation, Dataset used: Validation, Image Index: 407\r\n[Source=RowToRowMapperTransform; Cursor, Kind=Trace] Channel finished. Elapsed 00:00:11.0930351.\r\n[Source=RowToRowMapperTransform; Cursor, Kind=Trace] Channel disposed\r\n[Source=GenerateNumber; Cursor, Kind=Trace] Channel finished. Elapsed 00:00:11.0635798.\r\n[Source=GenerateNumber; Cursor, Kind=Trace] Channel disposed\r\n[Source=RangeFilter; Cursor, Kind=Trace] Channel finished. Elapsed 00:00:11.0637819.\r\n[Source=RangeFilter; Cursor, Kind=Trace] Channel disposed\r\n[Source=TextLoader; Binding, Kind=Trace] Channel started\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel started\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel finished. Elapsed 00:00:00.0109063.\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel disposed\r\n[Source=TextLoader; Binding, Kind=Trace] Channel finished. Elapsed 00:00:00.0332705.\r\n[Source=TextLoader; Binding, Kind=Trace] Channel disposed\r\n[Source=TextLoader; Binding, Kind=Trace] Channel started\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel started\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel finished. Elapsed 00:00:00.0050095.\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel disposed\r\n[Source=TextLoader; Binding, Kind=Trace] Channel finished. Elapsed 00:00:00.0168461.\r\n[Source=TextLoader; Binding, Kind=Trace] Channel disposed\r\n'ImageClassificationNetCore.exe' (CoreCLR: clrhost): Loaded 'C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\3.0.0\\System.Runtime.CompilerServices.Unsafe.dll'. Skipped loading symbols. Module is optimized and the debugger option 'Just My Code' is enabled.\r\n'ImageClassificationNetCore.exe' (CoreCLR: clrhost): Loaded 'C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\3.0.0\\System.Text.RegularExpressions.dll'. Skipped loading symbols. Module is optimized and the debugger option 'Just My Code' is enabled.\r\nThe thread 0x11e8 has exited with code 0 (0x0).\r\n[Source=TextLoader; ParseStats, Kind=Trace] Channel started\r\n[Source=TextLoader; Cursor, Kind=Trace] Channel started\r\n[Source=Shuffle; Cursor, Kind=Trace] Channel started\r\n"""
535000982,4555,"b""AutoML Nuget Package won't train against TSV""","b'### System information\r\n\r\n- **OS version/distro**: Win10 64bit\r\n- **.NET Version (eg., dotnet --info)**: \r\ndotnet core 3.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nInstalled AutoML nuget package. Setup sentiment analysis training. Selected correct labels and features columns. \r\n\r\nWent to train and... \r\n\r\n- **What happened?**\r\n\r\nI got a message almost immediately ""Failed. See more in Output pane"". \r\n\r\nThe output pane for ""Machine Learning"" is completely empty! \r\n\r\n- **What did you expect?**\r\nAt least an error... \r\n\r\nscreenshot:\r\n\r\n![image](https://user-images.githubusercontent.com/4026553/70447947-814e5600-1a97-11ea-8515-6c53bd2c77c7.png)\r\n\r\nHere\'s the input data pane: \r\n\r\n![image](https://user-images.githubusercontent.com/4026553/70448245-fe79cb00-1a97-11ea-8040-79b9deeccb83.png)\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
534813076,4554,b'BinaryClassification.Evaluate completely ignores the predicted labels',"b'Version: 1.4.0\r\n\r\nI\'m training a Binary LightGBM classifier and want to change the threshold of the model. This will change my predictions accordingly. Though, `BinaryClassification.Evaluate` will always return me the same precision/recall.\r\n\r\n```C#\r\n        var newModel = ctx.BinaryClassification.ChangeModelThreshold(model, -100_000);\r\n        var dataView = newModel.Transform(dv);\r\n        var labels = dataView.GetColumn<bool>(""PredictedLabel"").ToArray();\r\n\r\n        var numTrue = labels.Count(x => x == true); // All are true.\r\n        var numFalse = labels.Count(x => x == false); // 0\r\n\r\n        testPerformance = ctx.BinaryClassification.Evaluate(dataView);\r\n```\r\n\r\nWith the above threshold the labels are all `true`. '"
534800323,4553,b'Expose EvaluateWithPRCurve in BinaryClassificationCatalog',b'Version: 1.4.0\r\n\r\nThis was once available: 122c31952829338e9cfa91ca72246af6e572a618\r\n\r\nBut now there is no way to access `EvaluateWithPRCurve`.'
534432183,4542,"b'Format error in GetFormattedConfusionTable""'","b'Hey,\r\n\r\nI\'m trying to print a confusion matrix on a binary classification model using:\r\n\r\n`Console.WriteLine(""Confusion Matrix:\\n{0}"", metrics.ConfusionMatrix.GetFormattedConfusionTable());\r\n`\r\n\r\nI get:\r\n\r\n![image](https://user-images.githubusercontent.com/1317234/70378656-e3f8f380-18d7-11ea-8e96-e96fea095059.png)\r\n\r\nShouldn\xe2\x80\x99t there be a comma here instead of a space?\r\n\r\nCharles'"
534366723,4541,b'InvalidDataException: End of Central Directory record could not be found. Error when loading custom trained model from Azure Blob Storage in ASP.NET Core Web API ',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI have trained a regression model and I have uploaded it to a container in Blob Storage. This is the method that I use to upload the model to blob storage:\r\n\r\n`public async Task TrainAndUploadModelAsync(MLContext mlContext, string dataPath, CloudBlobContainer container)\r\n{\r\nIDataView dataView = mlContext.Data.LoadFromTextFile(dataPath, hasHeader: true, separatorChar: \',\');\r\n\r\n        var pipeline = mlContext.Transforms.CopyColumns(""Label"", ""FareAmount"")\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""VendorIdEncoded"", ""VendorId""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""RateCodeEncoded"", ""RateCode""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""PaymentTypeEncoded"", ""PaymentType""))\r\n            .Append(mlContext.Transforms.Concatenate(""Features"", ""VendorIdEncoded"", ""RateCodeEncoded"", ""PassengerCount"", ""TripTime"", ""TripDistance"", ""PaymentTypeEncoded""))\r\n            .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n        var model = pipeline.Fit(dataView);\r\n\r\n        using (var stream = new MemoryStream())\r\n        {\r\n            mlContext.Model.Save(model, dataView.Schema, stream);\r\n            stream.Position = 0;\r\n            await _azureStorageHelpers.UploadBlobToStorage(container, ""Model.zip"", stream);\r\n        }\r\n    }`\r\nNow I\'m trying to consume that model via a ASP.NET Core Web API like so:\r\n\r\nservices.AddPredictionEnginePool<TaxiTrip, TaxiTripFarePrediction>() .FromUri( modelName: ""TaxiTripFarePredictionModel"", uri: ""https://velidastorage.blob.core.windows.net/mlmodels/model.zip"", period: TimeSpan.FromSeconds(15));\r\n\r\nThen I\'m calling a POST Method to make a prediction on the following JSON payload\r\n\r\n{ ""VendorId"": ""VTS"", ""RateCode"": ""1"", ""PassengerCount"": 1, ""TripTime"": 1140, ""TripDistance"": 3.75, ""PaymentType"": ""CRD"", ""FareAmount"": 0 }\r\n\r\nAnd the POST Method:\r\n\r\n`[HttpPost]\r\npublic ActionResult Post([FromBody] TaxiTrip input)\r\n{\r\nif (!ModelState.IsValid)\r\n{\r\nreturn BadRequest();\r\n}\r\n\r\n        TaxiTripFarePrediction prediction = _predictionEnginePool.Predict(modelName: ""TaxiTripFarePredictionModel"", example: input);\r\n\r\n        string predictedFareAmount = prediction.FareAmount.ToString();\r\n\r\n        return Ok(predictedFareAmount);\r\n    }`\r\n\r\n\r\n- **What happened?**\r\n\r\nHowever, when I call the PredictionEnginePool.Predict() method, I get the following error:\r\n\r\nSystem.FormatException: \'Failed to open a zip archive\'. Inner Exception InvalidDataException: End of Central Directory record could not be found.\r\n\r\n- **What did you expect?**\r\n\r\nExpected the model to be consumed to make a prediction\r\n\r\nI\'m not sure where I am going wrong here. I\'m wondering whether or not the model has been uploaded correctly, or whether the Web API is having difficulty downloading the blob.\r\n\r\n\r\n### Source code / logs\r\n\r\nSource code for API and Model Trainer can be found here\r\n\r\nhttps://github.com/willvelida/PricePredictor'"
533958371,4528,b'PredictionEnginePool.GetPredictionEngine is not thread safe',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: Azure Functions Runtime 2.7.1948\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nInvoked `PredictionEnginePool.Predict(""MyModelName"", example)` from multiple threads.\r\n\r\n- **What happened?**\r\n`System.ArgumentException: \'An item with the same key has already been added. Key: MyModelName\'`\r\n\r\n- **What did you expect?**\r\nMethod is thread safe so that multiple named pools cannot be created simultaneously.\r\n\r\n### Source code / logs\r\n\r\n   at System.ThrowHelper.ThrowAddingDuplicateWithKeyArgumentException[T](T key)\r\n   at System.Collections.Generic.Dictionary`2.TryInsert(TKey key, TValue value, InsertionBehavior behavior)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.GetPredictionEngine(String modelName)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n\r\n'"
533787183,4527,b'Missing C# doc string for ChnageModelThreshold',b'Linky:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3f98485e887177f2082f027c22f46fd64ebbe246/src/Microsoft.ML.Data/TrainCatalog.cs#L261-L267'
533616068,4525,b'Image links broken',b'There are two broken image links on this page. One for each metric description.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: c1784ca5-56a4-75ea-ae35-ad29872348cf\n* Version Independent ID: 2084e039-fcb3-61b4-08ae-29f509b8cb30\n* Content: [RankingMetrics Class (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.rankingmetrics?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Data/RankingMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/RankingMetrics.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @natke\n* Microsoft Alias: **nakersha**'
533513959,4524,b'Model fit in Parallel.For is slower than For',"b""### System information\r\n\r\n- **OS version/distro**: Win10 64\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI'm trying to tune hyperparamater and see if I can implement grid search myself. In order to do that, I would like to fit the model in multiple threads by using Parallel.For\r\n\r\n- **What happened?**\r\nHowever, I realized that fitting the model multiple times using Parallel.For takes much longer than a single threaded for loop. In a for loop. my CPU utilization is at around 30% all the time, while using Parallel.For, it spikes to 100% at first, then drops down to 6% for quite some time, then jumps back to 30% and finishes. Am I not supposed to fit in parallel? If that is the case then what is the best way to do grid search?\r\n\r\n### Source code / logs\r\n\r\nSingle threaded for - takes 20 seconds\r\n\r\n```\r\nfor (var i = 0; i < 100; i++) {\r\n    var pipeline = CreatePipeline();\r\n    pipeline.Fit(dataView);\r\n}\r\n```\r\n\r\nParallel.For - takes 56 seconds\r\n\r\n```\r\nParallel.For(0, 100, i => {\r\n    var pipeline = CreatePipeline();\r\n    pipeline.Fit(dataView);\r\n});\r\n```"""
532659728,4520,b'[DNN Training] Cannot execute retrain DNN model(Tensorflow model) manually since ML.NET 1.4.0-stable',b'ref: https://github.com/dotnet/machinelearning/issues/4307\r\n\r\nWe cannot call `RetrainDnnModel` method publicly and manually because  of this commit ( https://github.com/dotnet/machinelearning/pull/4362 ).\r\n\r\nI think that regression tasks by TensorflowRetrain (RetrainDnnModel ) only can predict multiple-values.\r\nSo I think that Access-Modifiers of `RetrainDnnModel` should be public if no way for predicting multiple-values.'
532419251,4519,b'OneHotHashEncoding / OneHotEncoding transformer output',"b'### System information\r\n\r\n- **OS version/distro**: Win 10 \r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.0.100, ML.NET 1.4.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nInspected output of OneHotHashEncoding / OneHotEncoding\r\n\r\n- **What happened?**\r\nExpected vector different representations for different categories, however they were the same.\r\n\r\nIf the first category is `[1, 0, 0, 0]` then the second category should be different (i.e. `[0, 1, 0, 0]`). however it appears to be the same when inspecting it.\r\n\r\nInspected `IDataView` using `data.Preview(numRows)`.\r\n\r\n### Source code / logs\r\n\r\nCode:\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nnamespace cat\r\n{\r\n    class CatInput\r\n    {\r\n        [LoadColumn(0),ColumnName(""input"")]\r\n        public string cat;\r\n    }\r\n    class Program\r\n    {\r\n        static MLContext _mlContext = new MLContext();\r\n        static IDataView _data;\r\n        static void Main(string[] args)\r\n        {\r\n            _data = _mlContext.Data.LoadFromTextFile<CatInput>(path: ""cat"", hasHeader: false, separatorChar: \',\');\r\n            IEstimator<ITransformer> _pipeline = _mlContext.Transforms.Categorical.OneHotHashEncoding(\r\n                inputColumnName: ""input"",\r\n                outputColumnName: ""output"");\r\n            \r\n            var model = _pipeline.Fit(_data);\r\n            IDataView tData = model.Transform(_data);\r\n            var previewObject = tData.Preview(10);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\ninput data:\r\n```\r\n                input                 |\r\n---------------------------------------\r\n                 red                  |\r\n                 red                  |\r\n                 red                  |\r\n                 blue                 |\r\n                purple                |\r\n                yellow                |\r\n                 red                  |\r\n                 blue                 |\r\n                 blue                 |\r\n                purple                |\r\n```\r\nScreenshots of inspection and where the values should be different.\r\nRow 0 (""red""):\r\n![PreviewRow0](https://user-images.githubusercontent.com/27200279/70109206-45824d80-169f-11ea-9bb2-af28522283fd.png)\r\nRow 3 (""blue""):\r\n![PreviewRow1](https://user-images.githubusercontent.com/27200279/70109207-45824d80-169f-11ea-911d-535808367adc.png)\r\n'"
532336889,4518,"b""System.ArgumentOutOfRangeException in NimbusML's NGramFeaturizer2.py caused by CustomStopWordsRemover/Feature_extraction.text.stopwords in ML.NET""","b""As addressed in this [issue ](https://github.com/microsoft/NimbusML/issues/365) in the NimbusML repo, there is a bug with the ML.NET bindings of CustomStopWordsRemover, which is StopWordsRemovingTransformer.cs. \r\n\r\nThe specific error message is: \r\nRuntimeError: Error: *** System.ArgumentOutOfRangeException: 'dataFile is empty\r\nThe full error log can be found [here](https://dev.azure.com/aifx/public/_build/results?buildId=2089&view=logs&j=d0e8f4b8-2f67-5548-290c-4d6f15a1cbca&t=e5950cbb-cc45-5e54-16a6-7bfce2ad073d&l=8236)."""
531914671,4517,"b""PFI doesn't work with uncalibrated binary classifiers""","b'Some binary classification estimators automatically return a calibrated model (for example, FastTree and LogisticRegression), but some don\'t - for example, FastForest. When trying to pass such a model to PFI, there is an exception thrown saying that the probability column was not found.\r\n```\r\nvar ml = new MLContext();\r\nvar ff = ml.BinaryClassification.Trainers.FastForest();\r\nvar data = ml.Data.LoadFromTextFile(@""breast-cancer.txt"",\r\n                new[] { new TextLoader.Column(""Label"", DataKind.Boolean, 0),\r\n                            new TextLoader.Column(""Features"", DataKind.Single, 1, 9) });\r\nvar model = ff.Fit(data);\r\nvar pfi = ml.BinaryClassification.PermutationFeatureImportance(model, data);\r\n```\r\n\r\nThere are actually two issues here: The first is what I described above, and the second is that there is no workaround for this problem. I tried adding a calibrator manually:\r\n\r\n```\r\nvar ff = ml.BinaryClassification.Trainers.FastForest();\r\nvar ffmodel = ff.Fit(data);\r\nvar calibrator = ml.BinaryClassification.Calibrators.Platt();\r\nvar calibratormodel = calibrator.Fit(ffmodel.Transform(data));\r\nvar pfi = ml.BinaryClassification.PermutationFeatureImportance(calibratormodel, ffmodel.Transform(data));\r\n```\r\nThe reason I could not train these two models as a pipeline is because the resulting model is of type `TransformerChain` so I cannot pass it to PFI. However, this code doesn\'t work either, because even though `calibratormodel` is indeed an `ISingleFeaturePredictionTransformer`, the features column of `calibratormodel`, is the score column of the output of `ffmodel`, so PFI doesn\'t do the right thing. As far as I can tell, there is no way to pass a model where the calibrator was trained separately to PFI. It might be worth opening a separate issue for this, not sure.'"
531693256,4516,"b""GPU Training doesn't work with AutoML on Surface Book 2""",b'- **What did you do?**\r\nTried to train with GPU on a Surface Book 2\r\n- **What happened?**\r\nStalls after 3rd cross val ... I think\r\n- **What did you expect?**\r\n10 Cross Vals and best model.\r\n\r\n### Source code / logs\r\n\r\n[weather-small-train-logs-cpu.txt](https://github.com/dotnet/machinelearning/files/3914431/weather-small-train-logs-cpu.txt)\r\n[weather-small-train-logs-gpu.txt](https://github.com/dotnet/machinelearning/files/3914432/weather-small-train-logs-gpu.txt)\r\n[weather-small.zip](https://github.com/dotnet/machinelearning/files/3914434/weather-small.zip)\r\n'
530706490,4513,b'Multiclass classification - Prediction Output ',"b'Hi,\r\n\r\nThe following code helps to get the predicted label with score. Is there any way that I can get additional details (columns) of each prediction based on score. What are the columns that I could include as output in a multiclass prediction (other than Label and Score). Can I include additional columns from DataSet in my output?\r\n\r\n`\r\nprivate static Dictionary<string, float> GetScoresWithLabelsSorted(DataViewSchema schema, string name, float[] scores)\r\n        {\r\n            Dictionary<string, float> result = new Dictionary<string, float>();\r\n\r\n            var column = schema.GetColumnOrNull(name);\r\n\r\n            var slotNames = new VBuffer<ReadOnlyMemory<char>>();\r\n            column.Value.GetSlotNames(ref slotNames);\r\n            var x = slotNames.GetIndices();\r\n\r\n            var num = 0;\r\n            foreach (var denseValue in slotNames.DenseValues())\r\n            {\r\n                result.Add(denseValue.ToString(), scores[num++]);\r\n            }\r\n\r\n            return result.OrderByDescending(c => c.Value).ToDictionary(i => i.Key, i => i.Value);\r\n        }`'"
530439237,4511,b'Build problem',"b'HI,\r\nPlease help me with an install problem.  Here is my install script output:\r\n\r\n```\r\nPS H:\\ML.NET\\machinelearning-master> ./build.cmd\r\nTools are already initialized.\r\nRunning: H:\\ML.NET\\machinelearning-master\\Tools\\dotnetcli\\dotnet msbuild /nologo /verbosity:minimal /clp:Summary /maxcpucount /l:BinClashLogger,Tools\\Microsoft.DotNet.Build.Tasks.dll;LogFile=binclash.log /p:Configuration=Debug  /flp:v=normal  /flp2:warningsonly;logfile=msbuild.wrn  /flp3:errorsonly;logfile=msbuild.err  build.proj\r\n  fatal: Not a git repository (or any of the parent directories): .git\r\n  Restoring all projects...\r\n  Restore completed in 90.2 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj.\r\n  Restore completed in 6.32 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj.\r\n  Restore completed in 5.13 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DataView\\Microsoft.ML.DataView.csproj.\r\n  Restore completed in 127.06 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.Extensions.ML\\Microsoft.Extensions.ML.csproj.\r\n  Restore completed in 127.57 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.AutoML\\Microsoft.ML.AutoML.csproj.\r\n  Restore completed in 127.65 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj.\r\n  Restore completed in 127.75 ms for H:\\ML.NET\\machinelearning-master\\docs\\samples\\Microsoft.ML.Samples\\Microsoft.ML.Samples.csproj.\r\n  Restore completed in 127.59 ms for H:\\ML.NET\\machinelearning-master\\docs\\samples\\Microsoft.ML.AutoML.Samples\\Microsoft.ML.AutoML.Samples.csproj.\r\n  Restore completed in 127.87 ms for H:\\ML.NET\\machinelearning-master\\docs\\samples\\Microsoft.ML.Samples.GPU\\Microsoft.ML.Samples.GPU.csproj.\r\n  Restore completed in 135.73 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.CodeGenerator\\Microsoft.ML.CodeGenerator.csproj.\r\n  Restore completed in 16.42 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj.\r\n  Restore completed in 20.53 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet18\\Microsoft.ML.DnnImageFeaturizer.ResNet18.csproj.\r\n  Restore completed in 20.46 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj.\r\n  Restore completed in 24.78 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet50\\Microsoft.ML.DnnImageFeaturizer.ResNet50.csproj.\r\n  Restore completed in 25.59 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DnnImageFeaturizer.AlexNet\\Microsoft.ML.DnnImageFeaturizer.AlexNet.csproj.\r\n  Restore completed in 34.91 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet101\\Microsoft.ML.DnnImageFeaturizer.ResNet101.csproj.\r\n  Restore completed in 40.05 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.EntryPoints\\Microsoft.ML.EntryPoints.csproj.\r\n  Restore completed in 40.93 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj.\r\n  Restore completed in 42.72 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.DnnAnalyzer\\Microsoft.ML.DnnAnalyzer\\Microsoft.ML.DnnAnalyzer.csproj.\r\n  Restore completed in 12.1 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj.\r\n  Restore completed in 9.56 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj.\r\n  Restore completed in 26.51 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Experimental\\Microsoft.ML.Experimental.csproj.\r\n  Restore completed in 21.27 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj.\r\n  Restore completed in 16.34 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Mkl.Components\\Microsoft.ML.Mkl.Components.csproj.\r\n  Restore completed in 16.61 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.LightGbm\\Microsoft.ML.LightGbm.csproj.\r\n  Restore completed in 11.04 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.OnnxConverter\\Microsoft.ML.OnnxConverter.csproj.\r\n  Restore completed in 21.94 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.OnnxTransformer\\Microsoft.ML.OnnxTransformer.csproj.\r\n  Restore completed in 16.24 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj.\r\n  Restore completed in 12.7 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Recommender\\Microsoft.ML.Recommender.csproj.\r\n  Restore completed in 20.06 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.SamplesUtils\\Microsoft.ML.SamplesUtils.csproj.\r\n  Restore completed in 15.85 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj.\r\n  Restore completed in 23.91 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj.\r\n  Restore completed in 18.12 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.StandardTrainers\\Microsoft.ML.StandardTrainers.csproj.\r\n  Restore completed in 30.13 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj.\r\n  Restore completed in 23.27 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj.\r\n  Restore completed in 17.56 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj.\r\n  Restore completed in 36.79 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.Vision\\Microsoft.ML.Vision.csproj.\r\n  Restore completed in 86.71 ms for H:\\ML.NET\\machinelearning-master\\src\\Microsoft.ML.TimeSeries\\Microsoft.ML.TimeSeries.csproj.\r\n  Restore completed in 77.17 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.Extensions.ML.Tests\\Microsoft.Extensions.ML.Tests.csproj.\r\n  Restore completed in 58.66 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.AutoML.Tests\\Microsoft.ML.AutoML.Tests.csproj.\r\n  Restore completed in 35.71 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj.\r\n  Restore completed in 46.71 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Benchmarks.Tests\\Microsoft.ML.Benchmarks.Tests.csproj.\r\n  Restore completed in 29.64 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj.\r\n  Restore completed in 14.44 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj.\r\n  Restore completed in 62.28 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj.\r\n  Restore completed in 81.34 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.CpuMath.PerformanceTests\\Microsoft.ML.CpuMath.PerformanceTests.csproj.\r\n  Restore completed in 22.24 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.CodeGenerator.Tests\\Microsoft.ML.CodeGenerator.Tests.csproj.\r\n  Restore completed in 14.73 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.OnnxTransformerTest\\Microsoft.ML.OnnxTransformerTest.csproj.\r\n  Restore completed in 21.84 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.CpuMath.UnitTests\\Microsoft.ML.CpuMath.UnitTests.csproj.\r\n  Restore completed in 21.58 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Functional.Tests\\Microsoft.ML.Functional.Tests.csproj.\r\n  Restore completed in 36.2 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.NugetPackageVersionUpdater\\Microsoft.ML.NugetPackageVersionUpdater.csproj.\r\n  Restore completed in 16.37 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj.\r\n  Restore completed in 22.45 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj.\r\n  Restore completed in 23.95 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj.\r\n  Restore completed in 35.88 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.TimeSeries.Tests\\Microsoft.ML.TimeSeries.Tests.csproj.\r\n  Restore completed in 14.08 ms for H:\\ML.NET\\machinelearning-master\\tools-local\\Microsoft.ML.InternalCodeAnalyzer\\Microsoft.ML.InternalCodeAnalyzer.csproj.\r\n  Restore completed in 10.07 ms for H:\\ML.NET\\machinelearning-master\\test\\RemoteExecutorConsoleApp\\RemoteExecutorConsoleApp.csproj.\r\n  Restore completed in 29.37 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.TestFrameworkCommon\\Microsoft.ML.TestFrameworkCommon.csproj.\r\n  Restore completed in 83.45 ms for H:\\ML.NET\\machinelearning-master\\test\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj.\r\n  Restore completed in 20.63 ms for H:\\ML.NET\\machinelearning-master\\tools-local\\Microsoft.ML.StableApi\\Microsoft.ML.StableApi.csproj.\r\n  Building redist components...\r\n  Building native components...\r\n  H:\\ML.NET\\machinelearning-master\\src\\Native\\build.cmd Debug x64 --mkllibpath H:\\ML.NET\\machinelearning-master\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\native\r\n  **********************************************************************\r\n  ** Visual Studio 2019 Developer Command Prompt v16.4.0-pre.6.0\r\n  ** Copyright (c) 2019 Microsoft Corporation\r\n  **********************************************************************\r\n  **********************************************************************\r\n  ** Visual Studio 2019 Developer Command Prompt v16.4.0-pre.6.0\r\n  ** Copyright (c) 2019 Microsoft Corporation\r\n  **********************************************************************\r\n  [vcvarsall.bat] Environment initialized for: \'x86_x64\'\r\n  Commencing native build of dotnet/machinelearning\r\n\r\n  Calling ""H:\\ML.NET\\machinelearning-master\\src\\Native\\\\gen-buildsys-win.bat"" ""H:\\ML.NET\\machinelearning-master\\src\\Native\\"" ""16 2019"" x64\r\n  CMake Warning (dev) in CMakeLists.txt:\r\n    No project() command is present.  The top-level CMakeLists.txt file must\r\n    contain a literal, direct call to the project() command.  Add a line of\r\n    code such as\r\n\r\n      project(ProjectName)\r\n\r\n    near the top of the file, but after cmake_minimum_required().\r\n\r\n    CMake is pretending there is a ""project(Project)"" command on the first\r\n    line.\r\n  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n  -- The C compiler identification is MSVC 19.24.28314.0\r\n  -- The CXX compiler identification is MSVC 19.24.28314.0\r\n  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Preview/VC/Tools/MSVC/14.24.28314/bin/Hostx64/x64/cl.exe\r\n  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Preview/VC/Tools/MSVC/14.24.28314/bin/Hostx64/x64/cl.exe -- works\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Preview/VC/Tools/MSVC/14.24.28314/bin/Hostx64/x64/cl.exe\r\n  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Preview/VC/Tools/MSVC/14.24.28314/bin/Hostx64/x64/cl.exe -- works\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  CMAKE_C_FLAGS_DEBUG is /MDd /Zi /Ob0 /Od /RTC1\r\n  In a future version, if the CMake that ships with VS2019 no longer contains the /ZI flag, delete this message block and the two lines below.\r\n  -- Found OpenMP_C: -openmp (found version ""2.0"")\r\n  -- Found OpenMP_CXX: -openmp (found version ""2.0"")\r\n  -- Found OpenMP: TRUE (found version ""2.0"")\r\n  -- Configuring done\r\n  CMake Error at MatrixFactorizationNative/CMakeLists.txt:28 (add_library):\r\n    Cannot find source file:\r\n\r\n      libmf/mf.cpp\r\n\r\n    Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm\r\n    .hpp .hxx .in .txx\r\n\r\n\r\n  CMake Error at MatrixFactorizationNative/CMakeLists.txt:28 (add_library):\r\n    No SOURCES given to target: MatrixFactorizationNative\r\n\r\n\r\n  CMake Generate step failed.  Build files cannot be regenerated correctly.\r\n  Failed to generate native component build project!\r\nH:\\ML.NET\\machinelearning-master\\src\\Native\\build.proj(67,5): error MSB3073: The command """"H:\\ML.NET\\machinelearning-master\\src\\Native\\build.cmd"" Debug x64 --mkllibpath H:\\ML.NET\\machinelearning-master\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\native"" exited with code 1.\r\n\r\nBuild FAILED.\r\n\r\nH:\\ML.NET\\machinelearning-master\\src\\Native\\build.proj(67,5): error MSB3073: The command """"H:\\ML.NET\\machinelearning-master\\src\\Native\\build.cmd"" Debug x64 --mkllibpath H:\\ML.NET\\machinelearning-master\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\native"" exited with code 1.\r\n    0 Warning(s)\r\n    1 Error(s)\r\n\r\nTime Elapsed 00:00:56.68\r\nCommand execution failed with exit code 1.\r\nPS H:\\ML.NET\\machinelearning-master>\r\n```\r\n\r\nAny suggestions will be greatly apprecated.\r\n\r\nCharles\r\n'"
529580561,4508,b'AI - Machine Learning - Fuzzy Logic - Genetic Algos',"b""_This issue has been moved from [a ticket on Developer Community](https://developercommunity.visualstudio.com/content/idea/795363/ai-machine-learning-fuzzy-logic-genetic-algos.html)._\n\n---\n<p>Hello, I am looking for AI libraries while I can not find them through .Net</p><p>Would you add new libraries for using or I have to switch <strong><em>Matlab Software</em></strong>?</p> <p>Please replay clear answer to know what I should do? Because AI is most needed tool these days...</p>\n\n---\n### Original Comments\n\n#### Visual Studio Feedback System on 10/28/2019, 01:29 AM: \n\nThank you for taking the time to provide your suggestion. We will do some preliminary checks to make sure we can proceed further.  We'll provide an update once the issue has been triaged by the product team.\n#### Touraj Ostovari on 10/29/2019, 08:02 AM: \n\n<p>is there any new update??</p>\n"""
529522768,4506,"b'""Op type not registered \'FusedBatchNormV3\'"" exception when trying to use a TensorFlow 2.0 model'","b'### System information\r\n\r\nSDK .NET Core (refl\xc3\xa9tant tous les global.json) :\r\n Version:   3.0.100\r\n Commit:    04339c3a26\r\n\r\nEnvironnement d\'ex\xc3\xa9cution :\r\n OS Name:     Windows\r\n OS Version:  10.0.18362\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.0.100\\\r\n\r\nHost (useful for support):\r\n  Version: 3.0.0\r\n  Commit:  7d57652f33\r\n\r\n.NET Core SDKs installed:\r\n  3.0.100 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.13 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\nAnaconda Navigator 1.9.7 with TensorFlow 2.0.0\r\n\r\nVisual Studio 2019 Community Edition, version  16.3.10\r\nwith \r\n* Microsoft ML v1.4.0\r\n* TensorFlow.NET v0.12.0\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTaking inspiration from this [ML.Net project](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow), \r\nI trained a neural network with Tensorflow 2.0, saved it to disk (with python function `tf.saved_model.save`) and then tried to load it and use it in a custom .Net project in C#.\r\n\r\n- **What happened?**\r\nI expected my C# program to be able to load a picture, to push it through the Tensorflow model and to get an output vector corresponding to classification results.\r\n\r\nEverything is fine when I load my model with function *LoadTensorFlowModel*. Calling *GetInputSchema* or *GetModelSchema* on the model returns coherent information.\r\n\r\nFitting my pipeline with *Fit* also works fine. However, as soon as I try to push a picture in the pipeline, I get an exception `Op type not registered \'FusedBatchNormV3` (see below).\r\n\r\n- **What did you expect?**\r\nI didn\'t expect to get this strange exception during inference.\r\nObviously this exception seems to happen inside the TensorFlow library called by ML.NET. I have no idea if the bug is on the TensorFlow side, or on the ML.NET side, or if missed something.\r\n\r\nBelow you can find minimal code to reproduce the problem.\r\n\r\n### Exception\r\n2019-11-27 16:17:24.783604: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: D:\\training\\model\\\r\n2019-11-27 16:17:24.820727: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2019-11-27 16:17:25.045189: I tensorflow/cc/saved_model/loader.cc:182] Restoring SavedModel bundle.\r\n2019-11-27 16:17:25.954912: I tensorflow/cc/saved_model/loader.cc:132] Running initialization op on SavedModel bundle.\r\n2019-11-27 16:17:26.205591: I tensorflow/cc/saved_model/loader.cc:285] SavedModel load for tags { serve }; Status: success. Took 1421948 microseconds.\r\n2019-11-27 16:17:33.391938: W tensorflow/core/kernels/partitioned_function_ops.cc:197] Grappler optimization failed. Error: Op type not registered \'FusedBatchNormV3\' in binary running on AUTISTE. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n2019-11-27 16:17:33.409723: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at partitioned_function_ops.cc:118 : Not found: Op type not registered \'FusedBatchNormV3\' in binary running on AUTISTE. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\nOp type not registered \'FusedBatchNormV3\' in binary running on AUTISTE. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n\t [[{{node StatefulPartitionedCall}}]]\r\n\t [[{{node StatefulPartitionedCall}}]]\r\nException lev\xc3\xa9e : \'System.InvalidOperationException\' dans Microsoft.ML.Data.dll\r\nUne exception non g\xc3\xa9r\xc3\xa9e du type \'System.InvalidOperationException\' s\'est produite dans Microsoft.ML.Data.dll\r\n\r\n\r\n### Source code - TensorFlow side\r\n\r\n`import os`\r\n`import tensorflow as tf`\r\n`from tensorflow.keras.layers import Dense, GlobalAveragePooling2D`\r\n`from tensorflow.keras.models import Model`\r\n\r\n`base_model = tf.keras.applications.ResNet50 (include_top=False, weights=\'imagenet\', input_shape=(224, 224, 3))`\r\n`x = base_model.output`\r\n`x = GlobalAveragePooling2D (name=""top_avgpool2d"")(x)`\r\n`x = Dense (512, activation=\'relu\', name=""top_mlp"")(x)`\r\n`predictions = Dense (2, activation=\'softmax\', name=""top_gender"")(x)`\r\n`model = Model (inputs=base_model.input, outputs=predictions)`\r\n\r\n`tf.saved_model.save (model, \'D:\\\\training\\\\model\\\\\')`\r\n\r\n### Source code - Visual Studio side\r\nSee attached file\r\n[VS Code.txt](https://github.com/dotnet/machinelearning/files/3898390/VS.Code.txt)\r\n\r\n'"
529460918,4505,b'Version.txt should use file version from assembly custom attributes not FileVersionInfo',"b'The changes made in issue https://github.com/dotnet/machinelearning/issues/3132 have introduced a bug due to relying on a physical location for the assembly. If the Microsoft.ML.Core assembly is loaded from memory the assembly.location will be empty. Using **FileVersionInfo.GetVersionInfo** relies on a physical path - so an argument exception is thrown inside System.IO.Path since the supplied path is empty.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/37ed3361f330ed439c9bd477abcfe5a27e06c0a1/src/Microsoft.ML.Core/Data/Repository.cs#L308-L311\r\n\r\nInstead of using FileVersionInfo.GetVersionInfo the assembly custom attributes should be used, for example:\r\n`var productVersion = assembly.CustomAttributes.FirstOrDefault(a => a.AttributeType == typeof(AssemblyFileVersionAttribute)).ConstructorArguments.First();`\r\n\r\nThis will return the same product string version as the FileVersionInfo.GetVersionInfo does.'"
529052670,4504,b'[Image Classification] Low Accuracy on EuroSAT Dataset',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n- **ML.NET Version**: 1.4.0\r\n- **Model Builder Version**: 16.0.1911.1103\r\n\r\n### Issue\r\n\r\nThe [EuroSAT paper](https://www.researchgate.net/publication/319463676_EuroSAT_A_Novel_Dataset_and_Deep_Learning_Benchmark_for_Land_Use_and_Land_Cover_Classification), a geo-referenced aerial/satellite image dataset of 27,000 images categorized into 10 different classes is said to achieve 98.57% classification accuracy using CNNs. More specifically, using ResNet50, it achieves 96.37% accuracy using a 90/10 train/test split. Using ML.NET Image Classification API as well as Model Builder achieves 99%+ accuracy while training. However, when evaluating the model, both with and without cross validation, accuracy drops between 61-69% using only the CPU and 59% using the GPU. See performance comparisons in table below.\r\n\r\n| Method | Number of Images | Cross-Validation | Training Accuracy | Evaluation Accuracy | \r\n| --- | --- | --- | --- | --- |\r\n| API (CPU) | 20000 (18000 Train, 2000 Test) | No | 0.9946118 | 0.698\r\n| Model Builder (CPU) | 27000 | Yes | 0.9954983 | 0.6168\r\n| Model Builder (GPU) | 27000 | Yes | N/A | 0.5949\r\n\r\n### Source code / logs\r\n\r\nThe source code is at the following repo: https://github.com/luisquintanilla/EuroSATTrainSample\r\n\r\n[Dataset download link](http://madm.dfki.de/files/sentinel/EuroSAT.zip)\r\n\r\nOutput logs:\r\n\r\n[ImageClassificationTrainResultsModelBuilder.txt](https://github.com/dotnet/machinelearning/files/3894631/ImageClassificationTrainResultsModelBuilder.txt)\r\n[ImageClassificationTrainResultsAPI.txt](https://github.com/dotnet/machinelearning/files/3894632/ImageClassificationTrainResultsAPI.txt)\r\n\r\n\r\n'"
528071386,4502,b'Best algorithm to use (ML.Net 1.4.0)',"b'Hi,\r\nI have a dataset in the following format,\r\n\r\nItem (feature) |  Model (feature) |  Brand (feature) | ItemId (PredictedLabel)\r\nIphone X         | X MAX                |  Apple               | 1\r\nSamsung 10S | 10S                      | Samsung          | 2\r\nSamsung Note 9 | 9                      | Samsung          | 3\r\nLikewise.. \r\n\r\nBased on the Item, Model and Size given as test data, I wanted to predict the ItemId. How is this possible, and what algorithm should I use to achieve this. I tried using Multiclass classification, and since Label column contains unique sequential values, each is considered as a separate class, and even with few data, it takes a very long time to train, with 0% accuracy. I am using ML.Net 1.4.0. Would appreciate if a sample code is shared.\r\n\r\nThank you.\r\n\r\n'"
527600602,4501,b'Visual Designer tools for neural networks',b'It would be great if in VS it will be possible to create neural networks in a visual editor.'
527384658,4499,b'Out of Memory Exception In Model Builder',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 3.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to use a Model Builder (AutoML) with a 1 GB csv file. \r\n\r\n- **What happened?**\r\n\r\nOut of Memory Exception\r\n\r\n![image](https://user-images.githubusercontent.com/29760620/69455746-e840e080-0d1d-11ea-9932-4ea1ef8a1780.png)\r\n\r\n\r\n- **What did you expect?**\r\n\r\nThe file would get loaded. It looks like the Model Builder is trying to use  a StringBuilder here. That's naturally going to fall down after a certain size of csv. Stream?\r\n"""
526660716,4493,"b""model saving can't handle datetime columns""","b""@FranzBl commented on [Wed Nov 20 2019](https://github.com/dotnet/machinelearning-samples/issues/746)\n\nSorry I couldn't answer earlier. To change column type of database, I had to change the program that generates it (in many places) and to setup a new database.\r\nIndeed with data type real instead of float the program works incl. evaluating, training etc. With one exception: Trying to save the model to a zip file for later use on end fails. Reason: One table column is type datetime (in SQL). During generation of the data view this is converted into string, and training works. Saving the model attempts to change these column data back from string to datetime, so an exception is thrown.\r\nIs this as should be? If model saving tries to reconstruct the original data types, so I think it should be able to parse a string as datetime.\r\nIn fact I could store the timestamps as simple strings in the database. But many database queries use datetime arithmetics, e. g. retrieving all data between two timestamps (SQL can do this very easy, while the date arithmetics on strings would be a little tricky).\r\n\r\n_Originally posted by @FranzBl in https://github.com/dotnet/machinelearning-samples/issues/744#issuecomment-556653945_\n\n"""
526273043,4491,b'Ignore hidden columns in AutoML schema checks of validation data',"b'When the AutoML API consumes data, it validates schema consistency between the train and validation data.\r\n\r\nThere are two bugs in this logic:\r\n1. The API asserts that the count of columns in the train and validation data must be equal. This throws an exception if the two data views have the same number of active columns but a different number of hidden columns. This should be updated to assert that the # of active (not hidden) columns in the train and validation data are equal.\r\n\r\n2. If either the train or validation data has a hidden column with a type that differs from an active column of the same name, an exception is thrown. Type consistency checks should be restricted to active columns only.'"
525343749,4488,b'Error loading Tensorflow Session in Jupyter Notebooks',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 Home\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.0\r\n- **ML.NET Version**: v1.4.0.0\r\n### Issue\r\n\r\nI wasn't sure if this issue belonged in `/dotnet/try` or here, but I figured I start here as I think it may be ML.NET related.\r\n\r\n- **What did you do?** Ran a Transfer Learning sample in Jupyter Notebooks\r\n- **What happened?** Got an exception from Tensorflow loading the TF model\r\n- **What did you expect?** `.Fit()` to work as expected\r\n\r\n### Source code / logs\r\nSource code can be found here\r\nhttps://github.com/aslotte/mlnet-jupyter/blob/master/src/image%20classification.ipynb\r\n\r\nException:\r\n![image](https://user-images.githubusercontent.com/30201569/69198007-45ac1600-0b01-11ea-8500-76e5d3e2764d.png)\r\n\r\n"""
525111121,4487,b'QuestionL Handling Comma Separated List Of Ids Per Row',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  3.0.0\r\n\r\n### Issue\r\n\r\n**I\'m trying to use the FieldAwareFactorizationMachine for classification. One of my most important features is a list of comma separated ids e.g. ""3499430, 3499435, 34995430"" (these are ids of items in a shopping cart) that are passed in (as a single column) with each row in the dataset. \r\n\r\nI\'m struggling with the right transformations to use on this column so that the feature can have the proper effect during training. So far i\'ve only been able to use a OneHotHashEncoding but i\'m not sure if that\'s right.  Seems like i should be splitting up the list and converting the values to keys and then to vectors but the resulting vectors do not have fixed sizes (which FFM requires). \r\n\r\nThe general idea is to classify if some other item goes with this shopping cart.\r\n\r\nCan you please help with some ideas on how to proceed?**\r\n\r\n'"
524309265,4484,b'Command Timeouts While Using The Database Loader',"b'### System information\r\n\r\n- **Windows 10**:\r\n- **.NET Core 3.0**: \r\n\r\n### Issue\r\n\r\n- Loaded training data from SQL Server (1m rows)\r\n- SqlException Execution timeout in less than a minute\r\n- The query should complete even if it\'s slow (based on volume). There should also be a way to modify the sql command timeout.\r\n\r\n### Source code / logs\r\n\r\n`          string connectionString = _config[""Database.ConnectionString""];\r\n\r\n            string sqlCommand = await GetSql(""OrderHistory.sql"");\r\n\r\n            DatabaseSource dbSource = new DatabaseSource(SqlClientFactory.Instance, connectionString, sqlCommand);\r\n\r\n            return dbSource;`'"
523872970,4483,b'Unable to Load CpuMathNative',"b""Exception thrown: 'System.DllNotFoundException' in Microsoft.ML.CpuMath.dll\r\nAn exception of type 'System.DllNotFoundException' occurred in Microsoft.ML.CpuMath.dll but was not handled in user code\r\nUnable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n\r\nthe above error is shown at this line:\r\n            ModelOutput result = predEngine.Predict(input);\r\n\r\n\r\ntrying to implement sentimental analysis on input comments in ASP.NET WEB APPLICATION(.NET FRAMEWORK) but getting these error even though it is seen in solution explorer.\r\nSolution platform is AnyCPU.also tried x64,x86 but no change.\r\nIs there any other solution?\r\n\r\n_Originally posted by @samcode22 in https://github.com/dotnet/machinelearning/issues/3764#issuecomment-554657340_"""
523620077,4482,b'Replace usages of TPL DataFlow BufferBlock with Threading.Channels',"b'There are 2 places we are using `BufferBlock<T>` today:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b7db4fa475ba4bd52824eb98bbf5f5bf4a0a6f7a/src/Microsoft.ML.Data/Transforms/RowShufflingTransformer.cs#L486-L487\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b7db4fa475ba4bd52824eb98bbf5f5bf4a0a6f7a/src/Microsoft.ML.Sweeper/AsyncSweeper.cs#L171\r\n\r\n\r\nWe should consider replacing this dependency with https://www.nuget.org/packages/System.Threading.Channels/ instead. Channels are a bit simpler, and more performant than BufferBlock.\r\n\r\nSee:\r\n\r\n* https://github.com/dotnet/machinelearning/pull/4479#discussion_r346845557\r\n* https://github.com/dotnet/corefx/issues/24715\r\n'"
523274691,4480,b'LoadColumn should not be required when loading from a file with headers',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 (10.0.18362)\r\n- **.NET Version (eg., dotnet --info)**:  3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated a type anottated with `LoadColumnName`\r\nCreated a `TextLoader` from this type and `useHeaders` set to `true` and called the `Load` method\r\n\r\n- **What happened?**\r\nSystem.InvalidOperationException: \'Property \'IESCode\' is missing the LoadColumnAttribute attribute\'\r\n\r\n- **What did you expect?**\r\nThe Load method should map the properties from the file headers when available, not forcing the use of column index.\r\n\r\n### Source code / logs\r\n\r\n```fsharp\r\nSystem.InvalidOperationException: \'Property \'IESCode\' is missing the LoadColumnAttribute attribute\'\r\n```\r\n\r\n```fsharp\r\ntype EnadeMicrodata =\r\n    {\r\n        [<LoadColumnName(""CO_IES"")>]\r\n        IESCode: int\r\n\r\n        [<LoadColumnName(""CO_CATEGAD"")>]\r\n        AdministrativeCategory: int\r\n    }\r\n\r\nlet mlContext = MLContext ()\r\nlet _textLoader = mlContext.Data.CreateTextLoader<EnadeMicrodata>(hasHeader = true).Load(""MICRODADOS_ENADE_2017.txt"")\r\n```'"
522936921,4478,b'OnnxTransformer fails running on GPU',"b""I'm trying to detect objects in images by using an exported ONNX model from Custom Vision on GPU but getting the following exception:\r\n\r\nSystem.EntryPointNotFoundException: 'Unable to find an entry point named 'OrtSessionOptionsAppendExecutionProvider_CUDA' in DLL 'onnxruntime'.'\r\n\r\nBased on the documentation the ApplyOnnxModel method provides an overload for GPU:\r\npublic static Microsoft.ML.Transforms.Onnx.OnnxScoringEstimator ApplyOnnxModel (this Microsoft.ML.TransformsCatalog catalog, string modelFile, Nullable gpuDeviceId = null, bool fallbackToCpu = false);\r\n\r\nThe model works perfectly fine when using the CPU, but when the gpuDeviceID and fallbackToCpu parameters are provided it fails with the above execption. I understand that for the OnnxRuntime to support GPU you need to also install the ML.OnnxRuntime.GPU nuget package but i noticed that ML.OnnxTransformer has a dependency with ML.OnnxRuntime 0.5.1.\r\n\r\n**Enviroment:**\r\nOS Platform: Windows 10 professional build 1809\r\nONNX Runtime: 1.4.0 and has dependency with ML.OnnxRuntime 0.5.1, tried ML.OnnxRuntime.GPU 1.0.0 but need OnnxTransformer.\r\nPlatform: .NET Core 3.0\r\nVisual Studio version (if applicable): 2019\r\nCUDA/cuDNN version: CUDA 10.0.130, cuDNN 7.6.0.34\r\nGPU model and memory: NVidia Quadro P1000\r\n\r\n**Failing code:**\r\nvar pipeline = mlContext.Transforms.ResizeImages(resizing: ImageResizingEstimator.ResizingKind.Fill, outputColumnName: onnxModel.ModelInput, imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n.Append(mlContext.Transforms.ExtractPixels(outputColumnName: onnxModel.ModelInput))\r\n.Append(mlContext.Transforms.ApplyOnnxModel(onnxModel.ModelOutput, onnxModel.ModelInput, onnxModel.ModelPath, 1, true));\r\n"""
522029773,4473,b'Issue with Label Column (Prediction Label)  - ML 1.4',"b'Hi. When I try to train a dataset that consists a unique sequential number column as the Label (Predicted Label) column, the train model fails. But when I change the Label Column to non-unique column, the model train succeeds. Why is this happening. I am using AutoML feature of ML.Net to train the Model.\r\n\r\nThank you'"
521768164,4471,b'Is the TPE algo available in ML.NET?',b'Is the TPE algo available in ML.NET? Or is there any library available which implement TPE algo in C# to tune hyper params? Thanks!'
521684409,4470,b'ML.Net Type Load Exception',"b'### System information\r\n-Windows 10 1903\r\n-.Net Framework 4.7.x\r\n-Microsoft.ML v1.4.0\r\n-Microsoft.ML.DNN v0.16.0 - preview 2\r\n\r\n### Issue\r\nI was using the code found in this video: https://www.youtube.com/watch?v=bXTN-rnwDso to get a test project up and running and ran into this error:\r\n\r\nSystem.TypeLoadException: \'Method \'MakeRowMapper\' on type \'Microsoft.ML.Transforms.ImageClassificationTransformer\' from assembly \'Microsoft.ML.DNN, version 1.0.0.0, culture=neutral, Public Key Token=cc7b13ffcd2ddd51\' is overriding a method that is not visible from that assembly.\r\n\r\nThis occurs when using either a forms application or a console application, I have tried removing and re-adding the various NuGet packages and different verisons to try and get around this issue. It occurs on startup of the application.\r\n\r\n### Source code / logs\r\n\r\nclass Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var imagesFolder = Path.Combine(Environment.CurrentDirectory, "".."", "".."", "".."", "".."", ""images"");\r\n            var file = Directory.GetFiles(imagesFolder, ""*"", SearchOption.AllDirectories);\r\n            var images = file.Select(f => new ImageData\r\n            {\r\n                ImagePath = f,\r\n                Label = Directory.GetParent(f).Name\r\n            });\r\n\r\n            var context = new MLContext();\r\n\r\n            var imageData = context.Data.LoadFromEnumerable(images);\r\n            var imageDataShuffle = context.Data.ShuffleRows(imageData);\r\n            var testTrainData = context.Data.TrainTestSplit(imageDataShuffle, testFraction: 0.2);\r\n            var validateData = context.Transforms.Conversion.MapValueToKey(""LabelKey"", ""Label"", keyOrdinality: Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue).Fit(testTrainData.TestSet).Transform(testTrainData.TestSet);\r\n            var pipeline = context.Transforms.Conversion.MapValueToKey(""LabelKey"", ""Label"", keyOrdinality: Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue).Append(context.Model.ImageClassification(""ImagePath"", ""LabelKey"", arch: Microsoft.ML.Transforms.ImageClassificationEstimator.Architecture.ResnetV2101, epoch: 100, metricsCallback: Console.WriteLine, batchSize: 10, validationSet: validateData));\r\n            var model = pipeline.Fit(testTrainData.TestSet);\r\n            var predictions = model.Transform(testTrainData.TestSet);\r\n            var metrics = context.MulticlassClassification.Evaluate(predictions, labelColumnName: ""LabelKey"", predictedLabelColumnName: ""PredictedLabel"");\r\n\r\n            Console.WriteLine($""Log Loss - {metrics.LogLoss}"");\r\n\r\n            var predictionEngine = context.Model.CreatePredictionEngine<ImageData, Image_Prediction>(model);\r\n            var testImagesFolder = Path.Combine(Environment.CurrentDirectory, "".."", "".."", "".."", ""test"");\r\n            var testFiles = Directory.GetFiles(testImagesFolder, ""*"", SearchOption.AllDirectories);\r\n            var testImages = testFiles.Select(f => new ImageData\r\n            {\r\n                ImagePath = f\r\n            });\r\n            VBuffer<ReadOnlyMemory<char>> keys = default;\r\n            predictionEngine.OutputSchema[""LabelKey""].GetKeyValues(ref keys);\r\n            var originalLabels = keys.DenseValues().ToArray();\r\n            foreach (var image in testImages)\r\n            {\r\n                var prediction = predictionEngine.Predict(image);\r\n                var labelIndex = prediction.PredictedLabel;\r\n                Console.WriteLine($""Image: {Path.GetFileName(image.ImagePath)}, Score: {prediction.score.Max()}"" + $""$Predicted Label: {originalLabels[labelIndex]}"");\r\n                Console.ReadLine();\r\n            }\r\n        }\r\n'"
521641647,4469,b'problems with retraining model',"b'### System information\r\n\r\n- **Windows10**:\r\n- **Microsoft.NetCore.App(2.1.0)/Microsoft.ML(1.4.0)**: \r\n\r\n### Issue \r\nit is observed\r\n**System.ArgumentOutOfRangeException:** \'_Features column \'Feature\' not found by_  <mlContext.Model.CreatePredictionEngine> _call after retraining the model_\r\n \r\n- **What did you do?**\r\nWe need to retrain a model with small increment of data in comparison with previously retrained dataset based on the example project **TaxiFarePrediction** https://github.com/dotnet/machinelearning-samples based on the steps, described in on the page https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net\r\nWe have undertaken the following steps to retrain the model with small increment (10 rows addition, as example) of data:\r\n1) rewrite the function `BuildTrainEvaluateAndSaveModel` in order to save datapreparation pipeline and trained model\r\n` var dataPrepTransformer = trainingPipeline.Fit(trainingDataView);\r\nIDataView predictions = dataPrepTransformer.Transform(testDataView);\r\nvar sdcaEstimator = mlContext.Regression.Trainers.Sdca();\r\nRegressionPredictionTransformer<LinearRegressionModelParameters> trainedModel = sdcaEstimator.Fit(predictions);\r\nmlContext.Model.Save(dataPrepTransformer, trainingDataView.Schema, Data_PreparationModelPath);\r\n mlContext.Model.Save(trainedModel, predictions.Schema, ModelPath);\r\n`\r\n2) load pretrained model \r\n`var dataPrevPipeline = mlContext.Model.Load(Data_PreparationModelPath, out var dataPrepPipelineSchema);\r\nITransformer trainedModel = mlContext.Model.Load(ModelPath, out modelSchema);`\r\n\r\n3) Extract pretrained model parameters\r\n` LinearRegressionModelParameters originalModelParameters =\r\n                ((ISingleFeaturePredictionTransformer<object>)trainedModel).Model as LinearRegressionModelParameters;`\r\n4) and finally, retrain model just only with small obfuscated data. It doesn\'t matter what, but it matter the amount in comparison with the whole previous dataset \r\n```\r\nTaxiTrip[] newTaxiTripsData = new TaxiTrip[10];\r\n for (var i = 0; i < 10; i++)\r\n {\r\n      newTaxiTripsData[i] = new TaxiTrip()\r\n      {\r\n                    VendorId = ""VTS"",\r\n                    RateCode = ""1"",\r\n                    PassengerCount = 1,\r\n                    TripTime = 1140,\r\n                    TripDistance = 3.75f,\r\n                    PaymentType = ""CRD"",\r\n                    FareAmount = 0 // To predict. Actual/Observed = 15.5\r\n                };\r\n        }\r\n\r\nIDataView newData = mlContext.Data.LoadFromEnumerable<TaxiTrip>(newTaxiTripsData);            \r\n // Preprocess Data\r\n IDataView transformedNewData = dataPrevPipeline.Transform(newData);\r\n // Retrain model\r\n RegressionPredictionTransformer<LinearRegressionModelParameters> retrainedModel =\r\n mlContext.Regression.Trainers.OnlineGradientDescent(""Label"", featureColumnName: ""Features"")\r\n                .Fit(transformedNewData, originalModelParameters);\r\nmlContext.Model.Save(retrainedModel, modelSchema, ModelPathAfterRetrain);\r\n```\r\n\r\n- **What happened?**\r\nWhen we had a go at testing a single prediction, the call of creating prediction engine \r\n\r\n```\r\nITransformer trainedModel = mlContext.Model.Load(ModelPathAfterRetrain, out modelSchema);\r\n\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<TaxiTrip, TaxiTripFarePrediction>(trainedModel); \r\n```\r\n<---_this call_\r\n\r\nthrows a _System.ArgumentOutOfRangeException_ - Features column \'Feature\' not found by_  <mlContext.Model.CreatePredictionEngine>\r\n\r\nCould you ask what wrong I did with the retraining?\r\nThankful in advance,\r\nAlex\r\n\r\n- **guessworks**\r\n1) I have a feeling that something wrong with my trained model files  `model_after_retrain.zip` and the same `model.zip` which was saved after datapreparation pipeline and has significant smaller size `data_preparation_pipeline.zip`\r\nhttps://github.com/apilatau/retraining-example/tree/master/TaxiFarePrediction/MLModels\r\n2) Maybe, increment / ingection of small amount of data in previously trained  model is impossible at all and we have to retain the model every time from scratch with sufficient data set ( I have investigated the count is about thousands rows, but not 10 \r\n\r\n### Source code / logs\r\nhttps://github.com/apilatau/retraining-example/blob/master/TaxiFarePrediction/TaxiFarePredictionConsoleApp/Program.cs\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
521132417,4468,b'FeatureContribution transformation currently returns vector of all feature and their contribution while calling PredictionEngine.Predict method ',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFeatureContribution transformation currently returns vector of all feature and their contribution while calling PredictionEngine.Predict method\r\n\r\n- **What happened?**\r\nReturned vector of 8 million feature which degraded the overall service of prediction service\r\n- **What did you expect?**\r\nit should only return the feature contribution of feature top x or bottom y which were requested instead of returning contribution of all features.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
521105913,4467,b'Resolve warnings in API docs generation',b'Warnings listed here: https://opbuildstorageprod.blob.core.windows.net/report/2019%5C11%5C7%5C1a61acc2-fbc9-ceaf-75d3-cfca51e72d2c%5CCommit%5C201911071723275565-live%5Cworkflow_report.html?sv=2016-05-31&sr=b&sig=yltSQyLDqTJjXnrIiDqcLmJiQHS0zWN6WOn4PhKff%2FA%3D&st=2019-11-11T17%3A56%3A55Z&se=2019-12-12T18%3A01%3A55Z&sp=r'
521055619,4466,"b""Unhandled Exception Value cannot be null. (Parameter 'libraryPath')""","b""### System information\r\n\r\n\r\n- **OS version/distro**:Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.0.1 and 2.1.8 \r\n- **.NET Try Version**: Tool 'dotnet-try' (version '1.0.19553.4') and (version '1.0.19558.9')\r\n### Issue\r\nWhen I run training with LightGBM within Visual Studio evrything is ok. \r\nHowever, if I run the same code in .NET Juypter Notebook with version (`(version '1.0.19553.4')` or `(version '1.0.19558.9')`) got the following exception: \r\n```\r\nUnhandled Exception Value cannot be null. (Parameter 'libraryPath')\r\n```\r\n\r\n- **What did you do?** \r\nTried to execute the following code:\r\n```csharp\r\n// Define LightGbm algorithm estimator\r\nIEstimator<ITransformer> lightGbm = mlContext.MulticlassClassification.Trainers.LightGbm();\r\n//train the ML model\r\nTransformerChain<ITransformer> model = dataPipeline.Append(lightGbm).Fit(trainData);\r\n```\r\n\r\n- **What happened?**\r\nThe exception is thrown.\r\n- **What did you expect?**\r\nNormal execution without Exception.\r\n### Source code / logs\r\n```Unhandled Exception\r\nValue cannot be null. (Parameter 'libraryPath')\r\n   at System.Runtime.InteropServices.NativeLibrary.Load(String libraryPath)\r\n   at MLS.Agent.NativeAssemblyLoadHelper.Resolve(String libraryName, Assembly assembly, Nullable`1 searchPath) in F:\\workspace\\_work\\1\\s\\MLS.Agent\\NativeAssemblyLoadHelper.cs:line 47\r\n   at System.Runtime.InteropServices.NativeLibrary.LoadLibraryCallbackStub(String libraryName, Assembly assembly, Boolean hasDllImportSearchPathFlags, UInt32 dllImportSearchPathFlags)\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmInterface.DatasetCreateFromSampledColumn(IntPtr sampleValuePerColumn, IntPtr sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String parameters, IntPtr& ret)\r\n   at Microsoft.ML.Trainers.LightGbm.Dataset..ctor(Double[][] sampleValuePerColumn, Int32[][] sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String param, Single[] labels, Single[] weights, Int32[] groups)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Submission#17.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)\r\n\r\n```\r\n\r\n"""
520331757,4464,b'Error in ML.net training',"b""### System information\r\n- **Windows 10 Home**:\r\n- **.NET Core 2.1.802**: \r\n### Issue\r\n- **First time running ML.NET. Set the Database & started Training.\r\n- **What happened? \xe2\x80\x93 training stopped \xe2\x80\x9cFailed \xe2\x80\x93 See more in Output Pane.\xe2\x80\x9d\r\n- **What did you expect? \xe2\x80\x93 Training to Complete\r\n\r\n### Source code / logs\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\nSchema mismatch for score column 'Score': expected vector of two or more items of type Single, got Vector<Single, 1>\r\nParameter name: schema\r\nMust be at least 2.\r\nParameter name: numClasses\r\nSchema mismatch for score column 'Score': expected vector of two or more items of type Single, got Vector<Single, 1>\r\nParameter name: schema\r\nTraining failed with the exception: System.ArgumentOutOfRangeException: Schema mismatch for score column 'Score': expected vector of two or more items of type Single, got Vector<Single, 1>\r\nParameter name: schema\r\n   at Microsoft.ML.Data.MulticlassClassificationEvaluator.CheckScoreAndLabelTypes(RoleMappedSchema schema)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.CheckColumnTypes(RoleMappedSchema schema)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.MulticlassClassificationEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.MultiMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n\r\n"""
520252317,4461,b'ApplyOnnxModel Transform does not find method after upgrading to ONNXRuntime 1.0.0',"b""System information:\r\n- .NET Version\r\n Version:   3.0.100\r\n Commit:    04339c3a26\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.0.100\\\r\n\r\nIssue:\r\nApplyOnnxModel Transform in 1.4.0 does not find a method after updating OnnxRuntime to 1.0.0\r\n\r\nIt throws:\r\nMethod not found: 'Microsoft.ML.OnnxRuntime.SessionOptions Microsoft.ML.OnnxRuntime.SessionOptions.MakeSessionOptionWithCudaProvider(Int32)'.\r\n\r\nLooking at the library on iLSpy it seems that method is actually gone, but ML.NET still asumes is there. It does work when using OnnxRuntime 0.5.1\r\n\r\nStack Trace:\r\n   at Microsoft.ML.Transforms.Onnx.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, Boolean ownModelFile, IDictionary`2 shapeDictionary)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, Byte[] modelBytes) 220\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, String[] outputColumnNames, String[] inputColumnNames, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, IDictionary`2 shapeDictionary)\r\n   at Microsoft.ML.OnnxCatalog.ApplyOnnxModel(TransformsCatalog catalog, String outputColumnName, String inputColumnName, String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu)\r\n   at ***.***.***.TestModelTrainer.Load_Keras_Onnx_Mnist(String modelPath) in D:\\Source\\***\\MyProjectPath\\***\\TestModelTrainer.cs:line 756\r\n   at Microsoft.PS.Prediction.UnitTests.ML.NET.Tests.MLNetTests.Load_Test_Keras_Onnx_Mnist() in D:\\Source\\***\\MyProjectPath\\***\\ML.NET.Tests.cs:line 165\r\n"""
520180711,4460,"b""[AutoML v0.16.0] InferColumn doesn't work on tricky csv file""","b'For some csv file that contains double quotes in it\'s field, the `inferColumn` API can\'t work properly. It\'s probably because when guessing delimiter, AutoML takes the candidates inside double quote into consideration, which should be neglect. (Or when splitting lines, it uses \\n inside double quote)\r\n\r\nsteps to reproduce:\r\ndownload this [dataset](http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2019-09-14/visualisations/listings.csv)\r\n\r\n```\r\nMLContext mlContext = new MLContext();\r\nvar inputColumnInformation = new ColumnInformation();\r\ninputColumnInformation.LabelColumnName = @""review_scores_rating"";\r\nvar train = mlContext.Auto().InferColumns(TrainDataPath, inputColumnInformation);\r\n```\r\n\r\n#### Updated\r\nThe dataset actually works for latest AutoML/ModelBuilder, To reproduce the error, please uses this dataset:\r\n\r\n[jigsaw.txt](https://github.com/dotnet/machinelearning/files/4631129/jigsaw.txt)\r\n\r\n'"
519594624,4459,b'pipeline fails to load when I convert my project to a class',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWIN10\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\nML.NET 1.4.0\r\nFramework 4.7.2\r\n\r\n### Issue\r\nI have a full working console application using the framework. All access to ML.NET is in a separate class and I simply call on it. When I try to convert the project to a class DLL it starts showing: ""System.IO.FileNotFoundException: Could not load file or assembly \'System.Drawing.Common"".\r\n\r\n- **What did you do?**\r\nTry to convert to class DLL\r\n\r\n\r\n- **What happened?**\r\n""System.IO.FileNotFoundException: Could not load file or assembly \'System.Drawing.Common"". Error\r\n\r\n- **What did you expect?**\r\nshould work as the normal program.\r\n\r\n\r\n### Source code / logs\r\n\r\n`\r\nSystem.IO.FileNotFoundException: Could not load file or assembly \'System.Drawing.Common, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\' or one of its dependencies. The system cannot find the file specified.\r\nFile name: \'System.Drawing.Common, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\'\r\n   at Microsoft.ML.Transforms.Image.ImageDataViewType..ctor(Int32 height, Int32 width)\r\n   at Microsoft.ML.Transforms.Image.ImageResizingEstimator.ColumnOptions..ctor(String name, Int32 imageWidth, Int32 imageHeight, String inputColumnName, ResizingKind resizing, Anchor anchor)\r\n   at Microsoft.ML.ImageEstimatorsCatalog.ResizeImages(TransformsCatalog catalog, String outputColumnName, Int32 imageWidth, Int32 imageHeight, String inputColumnName, ResizingKind resizing, Anchor cropAnchor)\r\n   at MLQuickID.TFModelScorer.LoadModel(String tsvFile, String inceptionPb) in \\\\Mac\\Home\\Downloads\\QuickID-winforms-test4\\QuickID-winforms-test2\\TFModelScorer.cs:line 67\r\n\r\n=== Pre-bind state information ===\r\nLOG: DisplayName = System.Drawing.Common, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\r\n (Fully-specified)\r\nLOG: Appbase = file://Mac/Home/Downloads/QuickID-winforms-test4/client/bin/x64/Debug/\r\nLOG: Initial PrivatePath = NULL\r\nCalling assembly : Microsoft.ML.ImageAnalytics, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51.\r\n\r\nLOG: This bind starts in default load context.\r\nLOG: Using application configuration file: \\\\Mac\\Home\\Downloads\\QuickID-winforms-test4\\client\\bin\\x64\\Debug\\client.exe.Config\r\nLOG: Using host configuration file: \r\nLOG: Using machine configuration file from C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\config\\machine.config.\r\nLOG: Post-policy reference: System.Drawing.Common, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\r\nLOG: Attempting download of new URL file://Mac/Home/Downloads/QuickID-winforms-test4/client/bin/x64/Debug/System.Drawing.Common.DLL.\r\nLOG: Attempting download of new URL file://Mac/Home/Downloads/QuickID-winforms-test4/client/bin/x64/Debug/System.Drawing.Common/System.Drawing.Common.DLL.\r\nLOG: Attempting download of new URL file://Mac/Home/Downloads/QuickID-winforms-test4/client/bin/x64/Debug/System.Drawing.Common.EXE.\r\nLOG: Attempting download of new URL file://Mac/Home/Downloads/QuickID-winforms-test4/client/bin/x64/Debug/System.Drawing.Common/System.Drawing.Common.EXE.\r\n`\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
519021863,4452,b'[Image Classification API] Bottleneck phase values always computed',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 2.1\r\n- **ML.NET Version (eg., dotnet --info)**: 1.4.0\r\n\r\n### Issue\r\n\r\nSetting `ReuseTrainSetBottleneckCachedValues` and `ReuseValidationSetBottleneckCachedValues` parameters in `ImageClassificationTrainer.Options` to `true`, does the bottleneck computation on subsequent runs. I believe once the bottleneck values are computed on the first run, by setting both of those parameters to `true`, bottleneck computation should be skipped and the model should go directly into the training phase.  Is this no longer the case?\r\n\r\n### Source code / logs\r\n\r\nSee sample source code at this link: https://github.com/luisquintanilla/machinelearning-samples/blob/33f87d226f350fb36552dd8b1cee6a7c3f12da89/samples/csharp/getting-started/DeepLearning_ImageClassification_Binary/DeepLearning_ImageClassification_Binary/Program.cs#L53'"
518978102,4450,"b""LightGBMMulticlass doesn't normalize its Score column""","b""when I try AutoML v0.16.0 multi-classification, sometimes I get prediction score <0, and the summation of all scores doesn't equal to 1. which is unexpected. Maybe some trainer's output doesn't normalize.\r\n\r\n![image](https://user-images.githubusercontent.com/16876986/68351051-2a7be800-00b7-11ea-97fc-2622dcc659e3.png)\r\n\r\nI publish a mini-reproducible project in this [repo](https://github.com/LittleLittleCloud/AutoMLMultiClassificationBug) for facilitating debug."""
518968133,4449,b'System.FormatException: Tensorflow exception triggered while loading model.',"b""### System information\r\n\r\n- **OS version/distro**:\r\nWin10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.net core\r\n\r\n### Issue\r\nI upgraded from ML.NET 1.3.1 to 1.4.0. Everything worked fine in 1.3.1 but after upgrading I get the following error:\r\n\r\n```\r\nSystem.FormatException: Tensorflow exception triggered while loading model. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog catalog, String modelLocation)\r\n   at ImageClassification.ModelScorer.TFModelScorer.LoadModel(String dataLocation, String imagesFolder, String modelLocation) in \\\\Mac\\Home\\Downloads\\QuickID-netcore-sample\\ImageClassification\\ModelScorer\\TFModelScorer.cs:line 94\r\n   at ImageClassification.ModelScorer.TFModelScorer.Score() in \\\\Mac\\Home\\Downloads\\QuickID-netcore-sample\\ImageClassification\\ModelScorer\\TFModelScorer.cs:line 80\r\n   at ImageClassification.Program.Main(String[] args) in \\\\Mac\\Home\\Downloads\\QuickID-netcore-sample\\ImageClassification\\Program.cs:line 22\r\n```\r\n\r\n\r\n\r\n- **What did you do?**\r\nupgraded from ML.NET 1.3.1 to 1.4.0\r\n- **What happened?**\r\nError\r\n- **What did you expect?**\r\nThe program ran just fine before\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
518627588,4445,b'Hotlinking to blob store',b'We need aka.ms links to the CDN instead of direct links to blob store:\r\n* https://github.com/dotnet/machinelearning/blob/cc0b7869d50df819783f30b3f7da4d5c3725bb8f/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/TensorflowTests.cs#L1902-L1903\r\n* https://github.com/dotnet/machinelearning/blob/9215ba9e0ee8caa1e97e2666743644baf8c8139c/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/MulticlassClassification/ImageClassification/LearningRateSchedulingCifarResnetTransferLearning.cs#L263\r\n\r\n~~The unit test and sample will stop working in a month as we close down that blob store.~~ (update: found out this is no longer the case -- https://github.com/dotnet/machinelearning/issues/4445#issuecomment-552034148)\r\n\r\nWe should add a check-in test to ensure that no blob-store links are added in the future. All links should be an aka.ms link to the CDN.'
517961406,4442,b'TimeSeriesImputer to use multiple imputation strategies',"b'For imputed rows, this is a feature request for TimeSeriesImputer to be able to support multiple imputation strategies across different columns. For instance, numeric feature columns could be imputed by median, date feature columns by forward fill, and target column by median.'"
517960117,4441,b'TimeSeriesImputer to error if dataset has grains with different frequencies',"b'This is a feature request for TimeSeriesImputer to raise an error if a dataset has grains with different frequencies.\r\n\r\nFor instance, another time series imputer (one used by Azure AutoML) raises the error:\r\n\xe2\x80\x9cMore than one series is in the input data, and their frequencies differ. Please separate series by frequency and build separate models. If frequencies were incorrectly inferred, please fill in gaps in series.\xe2\x80\x9d\r\n\r\nAlso, in TimeSeriesImputer today, if grains grains have frequencies that are relatively prime, this appears to lead to odd behavior'"
517957259,4440,b'TimeSeriesImputer to accept datetime format',"b'This is a request for TimeSeriesImputer to accept datetime format for both:\r\n* time series column, and\r\n* input value columns to impute'"
516875652,4434,"b""Can't specify categorical columns""","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\nThe AutoML API Getting Started [documentation](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/how-to-use-the-automl-api) states:\r\n\r\n> Explore other overloads for Execute() if you want to pass in validation data, column information indicating the column purpose, or prefeaturizers.\r\n\r\nOne overload accepts `ColumnInformation`. However, most of the properties of that class including `CategoricalColumnNames` are get-only. If domain information dictates that a column contains categorical data, how do I provide that insight to AutoML?\r\n\r\n\r\n'"
516873493,4433,b'[Feature] Markov chains',"b""First of all, there aren't any libraries for text processing\r\nMaybe someone wants to deal with Markov chains for example.  Or it'll be better not to include some of these things to ml lib?"""
516374191,4431,b'Cleanup residual from passing validation set to ImageClassification API in AutoML',b'Pursuant to https://github.com/dotnet/machinelearning/pull/4430#discussion_r341755273\r\n\r\nCC: @justinormont '
516277052,4429,b'LoadImages not warning that input column is empty and ignoring imageFolder parameter in such a case',"b""I don't know if this is actually an issue, but it's something that I noticed when working with the LoadImages method, and perhaps it is necessary to warn the user that this could happen, whether at runtime, or in the documentation.\r\n\r\n### Issue\r\nAs I show in the source code I provide below, if all the values of the input column of a LoadImages transform are empty when fitting a pipeline, then the code will still run and not give any warning whatsoever, even though no image is actually loaded to train the model. The transform would also appear to work when transforming an input Data View which uses an empty column as input of the LoadImages, and, in the example I provide, the pipeline would still assign a predicted label to each row of the input data view bein transformed, even if no image was actually loaded.\r\n\r\nI show this by exemplifying two main cases in which this could happen:\r\n1. When the user loads its data through a method such as LoadFromTextFile, with an input file that only has 2 columns, but the user specifies that the ImagePath column (to be used as input column of the LoadImages method) is the 3rd column inside of the file.  This kind of scenario could happen if the user makes a typo in the ModelInput class, or if the user (perhaps mistakenly) passes an input file that doesn't contain an image path column.\r\n\r\n2. When the user loads its data through a method such as LoadFromEnumerable from an array where all of the objects provide either a null or an empty string value to the ImagePath column.\r\n\r\nAlso notice in my code that in both cases the LoadImages transform **also ignores whatever is passed as the imageFolder parameter**, since because there are actually no ImagePaths, it will never _try_ to load images. If there was at least one ImagePath in the input dataview, then LoadImages would actually try to load that image using the imageFolder parameter, and an exception is correctly thrown if the folder doesn't exist.\r\n\r\n### **Why is this a problem?**\r\n- I would understand this behavior happening if the input data view doesn't provide an image path for _some_ of the rows, specially when working with big datasets. But I think it becomes a problem if there's actually no image loaded, and the whole thing appears to work without a warning, like in the example I provided. If a user unknowingly makes a mistake that leads to this problem, then s/he might believe that the model was actually correctly trained with actual images, or that it actually transformed an input where no imagePath was provided. This problem might be harder to spot in more complex pipelines or input files.\r\n\r\n- Also the fact that the imageFolder parameter gets ignored in this case seems odd to me, as I would have expected an exception to be thrown if a user passes an inexistent folder path to the LoadImages transformer, regardless of the content of the ImagePath column.\r\n\r\n### Source code and input file\r\nDownload solution:\r\n[solution.zip](https://github.com/dotnet/machinelearning/files/4100381/solution.zip)\r\n\r\nOr look into the code in here:\r\nhttps://gist.github.com/antoniovs1029/997ca183411f173e81a131f09722b092\r\n"""
516267001,4428,b'[Image Classification] Very long time to warm-up when doing the first prediction',"b""I'd like to know if we can do anything to improve the first prediction's needed time when using the new Image Classification model based on DNN (TensorFlow).\r\n\r\nThis behavior/times happen when using the default DNN architecture which is **ResnetV250**.\r\n\r\nWhen using the CPU, the first prediction takes something in between 7 to 12 seconds depending on the model and environment.\r\nThen, upcoming predictions using the same PredictionEngine only need around 200 mlSecs if using CPU.\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/68045426-b09ec580-fc96-11e9-9a38-506089a32cc7.png)\r\n\r\nWhen using a GPU the difference is even larger. Around 15 secs for the first prediction, then a lot less for the next predictions (in this case, something in between 40 mlsecs and 100 mlSecs)\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/68045597-1e4af180-fc97-11e9-859e-66ef707f59fc.png)\r\n\r\nBasically, after the first prediction, it behaves good, with CPU and even better with GPU, but the first prediction needs a huge amount of time to probably initialize internally?\r\n\r\nCould that initialization be improved or happen before calling .Predict()?\r\nI'd like to know if we can do anything to improve the behavior/perf of the first prediction like initializing in advanced when creating the prediction engine instead of when predicting the first time?\r\n\r\n@codemzs - Thoughts?\r\n"""
515925439,4427,b'Duplicate lines in Microsoft.ML.StableApi.csproj',b'https://github.com/dotnet/machinelearning/blob/365ccf292789ba1f14d80b13e44daaf951517fff/tools-local/Microsoft.ML.StableApi/Microsoft.ML.StableApi.csproj#L26-L28\r\n\r\nLines 26 and 28 are duplicated.'
515781131,4426,b'[Image Classification] Error running Transfer learning example with InceptionV3 ',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nMicrosoft.ML: 1.4.0-preview3-28230-4\r\nMicrosoft.ML.ImageAnalytics : 1.4.0-preview3-28230-4\r\nMicrosoft.ML.Vision: 1.4.0-preview3-28230-4\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to run the ImageClassification.Train sample at https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_Training \r\nwith Architecture InceptionV3\r\n- **What happened?**\r\nException : \r\nTensorflow.TensorflowException\r\n  HResult=0x80131500\r\n  Message=NewRandomAccessFile failed to Create/Open: ./tfhub_modules/d765412e8955a7067e9c0031f60783359e0e5c3f/variables/variables.data-00000-of-00001 : The system cannot find the path specified.\r\n; No such process\r\n\t [[{{node checkpoint_initializer_32}}]]\r\n  Source=Microsoft.ML.TensorFlow\r\n  StackTrace:\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.Runner.Run()\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at ImageClassification.Train.Program.Main() in C:\\Users\\aibhanda\\luis-machinelearning-samples\\samples\\csharp\\getting-started\\DeepLearning_ImageClassification_Training\\ImageClassification.Train\\Program.cs:line 80\r\n\r\n\r\n- **What did you expect?**\r\nSample should run, as other architectures run without exception.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[1.4.0_RC-1_InceptionV3.log](https://github.com/dotnet/machinelearning/files/3796015/1.4.0_RC-1_InceptionV3.log)\r\n\r\n'"
515691361,4425,"b""CodeGenerator throws a bad error when StablePackageVersion isn't set""","b""With the addition of https://github.com/dotnet/machinelearning/pull/4391, we added two new string properties to `CodeGeneratorSettings`:\r\n\r\n* StablePackageVersion\r\n* UnstablePackageVersion\r\n\r\nThese properties are required to be set, if you don't code gen fails. But even worse, it fails in a way that isn't immediately obvious to what you did wrong.\r\n\r\nWe should make these properties required when creating a `CodeGeneratorSettings` object. That way callers of CodeGen know they need to set it."""
515117636,4423,b'UnauthorizedAccessException in UWP App',"b""### Issue\r\nSystem.Net.WebException: 'An exception occurred during a WebClient request.'\r\nwhen trying to create new mlContext.Model.ImageClassification() in **UWP App**\r\n\r\n### Source code / logs\r\n\r\n![image](https://user-images.githubusercontent.com/42332369/67914016-f5940080-fb9f-11e9-8af0-afedf07f6700.png)\r\n\r\n"""
515068630,4422,"b""ML.net doesn't exposes useOrderedHashing input parameter for Hash transformation""","b""### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsing Conversion Hash transform.\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.hash?view=ml-dotnet-1.0.0\r\n\r\n- **What happened?**\r\n\r\nIt doesn't exposes property useOrderedHashing \r\n\r\n- **What did you expect?**\r\n\r\nExpose useOrderedHashing  property as this is blocking us to move to ML.net.\r\n\r\n### Source code / logs\r\nSee link .\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.hash?view=ml-dotnet-1.0.0\r\n"""
514985132,4420,b'[Image Classification API] TensorFlow exception triggered while loading model',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 \r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1 \r\n- **NuGet Packages**\r\n\r\n  - Microsoft.ML (1.4.0-preview3-28230-5)\r\n  - Microsoft.ML.ImageAnalytics (1.4.0-preview3-28230-5)\r\n  - Microsoft.ML.Vision (1.4.0-preview3-28230-5)\r\n\r\n### Issue\r\n\r\nTried to train a model using Image Classification API and ResNetV2101 architecture.\r\n\r\n### Source code / logs\r\n\r\nSource Code: https://github.com/luisquintanilla/machinelearning-samples/blob/testing-1.4.0-samples/samples/csharp/getting-started/DeepLearning_ImageClassification_Binary/DeepLearning_ImageClassification_Binary/Program.cs\r\n\r\nStack Trace:\r\n\r\n```text\r\n   System.FormatException\r\n  HResult=0x80131537\r\n  Message=Tensorflow exception triggered while loading model.\r\n  Source=Microsoft.ML.TensorFlow\r\n  StackTrace:\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.LoadTensorFlowSessionFromMetaGraph(IHostEnvironment env, Architecture arch, String path)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.InitializeTrainingGraph(IDataView input)\r\n   at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at DLImageClassificationBinary.Program.Main(String[] args) in C:\\Users\\luquinta.REDMOND\\source\\repos\\DLImageClassificationBinary\\DLImageClassificationBinary\\Program.cs:line 60\r\n\r\nInner Exception 1:\r\nDllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n```\r\n"""
514897068,4418,b'Stop publishing nightly build nugets to private feed',"b'Currently there is a[ task](https://github.com/dotnet/machinelearning/blob/36fab9b6806260e64e50992450a219e869c7f74a/build/vsts-ci.yml#L259) that publishes nugets to a private feed whenever there is a change in the master branch of this repo. This private feed is of internal use for the members of the ML.net team.\r\n\r\nAfter [this discussion](https://github.com/dotnet/machinelearning/pull/4406#discussion_r339848534) on PR #4406  , and after discussing it offline with @codemzs , it was decided to stop publishing nugets to the private feed, because it will be unnecessary work now that PR #4406 added a task to publish the nugets to a [public feed](https://dev.azure.com/dnceng/public/_packaging?_a=feed&feed=MachineLearning).'"
514139113,4411,b'Getting RegressionTree from ITransformer model',"b'### System information\r\n\r\nWindows 10 & Visual Studio 2019\r\n\r\n### Issue\r\n\r\nHi, I want to know how to get RegressionTree object from a FastTree regression model because the RegressionTree is private and not available to access. (For your information, I have attached my code below. I got it from **https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/predict-prices)**\r\n\r\nAlso, due to the combination of left and right nodes, is it allowed to use binary splits, not multiple splits per node?\r\n\r\nFinally, how can I use the function in ""SaveAsCode"" in FastTree.cs? Is there any example to take a look at?\r\n\r\nThanks in advance.\r\n\r\nSincerely,\r\n\r\n### Source code / logs\r\n        static readonly string _trainDataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""taxi-fare-train.csv"");\r\n        static readonly string _testDataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""taxi-fare-test.csv"");\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            ITransformer model = Train(mlContext, _trainDataPath);\r\n            \r\n            \r\n        }\r\n\r\n        public static ITransformer Train(MLContext mlContext, string dataPath)\r\n        {\r\n            IDataView dataView = mlContext.Data.LoadFromTextFile<TaxiTrip>(dataPath, hasHeader: true, separatorChar: \',\');\r\n            var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: ""Label"", inputColumnName: ""FareAmount"")\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""VendorIdEncoded"", inputColumnName: ""VendorId""))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""RateCodeEncoded"", inputColumnName: ""RateCode""))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""PaymentTypeEncoded"", inputColumnName: ""PaymentType""))\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""VendorIdEncoded"", ""RateCodeEncoded"", ""PassengerCount"", ""TripTime"", ""TripDistance"", ""PaymentTypeEncoded""))\r\n                .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n            var model = pipeline.Fit(dataView);\r\n\r\n\r\n            return model;\r\n        }'"
514093594,4409,b'TensorFlowUtils should add the caught exception as an inner exception',"b'https://github.com/dotnet/machinelearning/blob/4c3be03282db29b65eb8f33888d8cb8c1a8dadac/src/Microsoft.ML.Dnn/DnnUtils.cs#L84-L87\r\n\r\nThis code is catching an exception and throwing a new one, but not using the caught exception as an inner exception. This loses the information of what the original exception was.\r\n\r\nSee https://github.com/dotnet/machinelearning/pull/4408#discussion_r340181047'"
513620169,4405,b'NuGet packages not being published to public feed',"b""It's desirable to have NuGets being published to a public feed as soon as the master branch of this repo gets updated.\r\n\r\nIn the past, this was tried to be done by publishing them to MyGet, but currently the lines of code that do this are commented out. https://github.com/dotnet/machinelearning/blob/f0fb7203d7597d2779a298662970b1f74b47f4b8/build/vsts-ci.yml#L237-L242\r\n\r\nAs discussed offline with @codemzs it would be better to instead publish them into this other public feed in Azure DevOps:\r\nhttps://dev.azure.com/dnceng/public/_packaging?_a=feed&feed=MachineLearning"""
513383048,4400,b'Error while publishing symbols during official build',"b'See the error here: https://devdiv.visualstudio.com/DevDiv/_build/results?buildId=3186964\r\n\r\n```\r\nE:\\A\\_work\\718\\s\\packages\\microsoft.symboluploader.build.task\\1.0.0-beta-62824-02\\build\\PublishSymbols.targets(29,7): warning : Invalid file type: LICENSE [E:\\A\\_work\\718\\s\\build\\publish.proj]\r\n  Processing input package E:\\A\\_work\\718\\s\\bin\\packages\\Microsoft.ML.CodeGenerator.symbols.0.16.0-preview3-28228-1.nupkg\r\n  Converting portable PDB lib/netstandard2.0/Microsoft.ML.CodeGenerator.pdb to Windows\r\n##[error]packages\\microsoft.symboluploader.build.task\\1.0.0-beta-62824-02\\build\\PublishSymbols.targets(29,7): Error : PDB0021: Document name doesn\'t match any pattern in Source Link: \'C:\\CodeHub\\machinelearning\\src\\Microsoft.ML.CodeGenerator\\Templates\\Console\\ConsumeModel.tt\'\r\nE:\\A\\_work\\718\\s\\packages\\microsoft.symboluploader.build.task\\1.0.0-beta-62824-02\\build\\PublishSymbols.targets(29,7): error : PDB0021: Document name doesn\'t match any pattern in Source Link: \'C:\\CodeHub\\machinelearning\\src\\Microsoft.ML.CodeGenerator\\Templates\\Console\\ConsumeModel.tt\' [E:\\A\\_work\\718\\s\\build\\publish.proj]\r\n##[error]packages\\microsoft.symboluploader.build.task\\1.0.0-beta-62824-02\\build\\PublishSymbols.targets(29,7): Error : PDB0021: Document name doesn\'t match any pattern in Source Link: \'C:\\CodeHub\\machinelearning\\src\\Microsoft.ML.CodeGenerator\\Templates\\Console\\Annotation.ttinclude\'\r\nE:\\A\\_work\\718\\s\\packages\\microsoft.symboluploader.build.task\\1.0.0-beta-62824-02\\build\\PublishSymbols.targets(29,7): error : PDB0021: Document name doesn\'t match any pattern in Source Link: \'C:\\CodeHub\\machinelearning\\src\\Microsoft.ML.CodeGenerator\\Templates\\Console\\Annotation.ttinclude\' [E:\\A\\_work\\718\\s\\build\\publish.proj]\r\n```\r\n\r\nTo fix this, we should be putting `linePragmas=""false""` in the .tt files:\r\n\r\n```\r\n<#@ template language=""C#"" linePragmas=""false"" #>\r\n```'"
513360653,4399,b'Memory leak in text classification pipeline',"b'### System information\r\n\r\n- **OS version/distro**: Microsoft Windows [Version 10.0.18362.418]\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0.100 04339c3a26\r\n\r\n### Issue\r\n\r\n- **What did you do?** Detected potential memory leak in production application, so I wrote simple application to see if problem persists.\r\n- **What happened?** Microsoft.ML 1.3.1 and 1.4.0-preview2 both appear to be leaking memory\r\n\r\n### Source code / logs\r\n\r\nMinimal code that consistently reproduces this problem:\r\n```\r\n    class ModelInput\r\n    {\r\n        [ColumnName(""TextColumn""), LoadColumn(0)]\r\n        public string ItemDescription { get; set; }\r\n        [ColumnName(""Label""), LoadColumn(1)]\r\n        public int ItemId { get; set; }\r\n    }\r\n\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Sleeping for 5 seconds. Collect initial memory snapshot..."");\r\n            while(true)\r\n            {\r\n                Thread.Sleep(5000);\r\n                BuildAndTrainModel();\r\n                Console.WriteLine(""Training done. Collect memory snapshot..."");\r\n            }\r\n        }\r\n\r\n        static void BuildAndTrainModel()\r\n        {\r\n            MLContext context = new MLContext(seed: 1);\r\n\r\n            var dataView = context.Data.LoadFromTextFile<ModelInput>(""input.csv"", separatorChar: \',\');\r\n\r\n            var trainingPipeline = context.Transforms.Conversion.MapValueToKey(new[] { new InputOutputColumnPair(""Label"", ""Label"") })\r\n                .Append(context.Transforms.Text.FeaturizeText(""TextColumn"", ""TextColumn""))\r\n                .Append(context.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: ""Label"", featureColumnName: ""TextColumn"", maximumNumberOfIterations: 1));\r\n\r\n            var model = trainingPipeline.Fit(dataView);\r\n        }\r\n    }\r\n```\r\nAfter each call to BuildAndTrainModel following objects appear to leak:\r\n![image](https://user-images.githubusercontent.com/22596768/67688033-de87bf80-f9a1-11e9-9d8b-79fc687e19e5.png)\r\n\r\nAmount of objects leaked appears to correlate with number of iterations (increasing maximumNumberOfIterations increases leaked object count).'"
513347051,4398,b'Image recognition rotation invariant',"b""After completing model training, prediction didn't recognize differences between rotated images. Let's assume I have an image of right hand and left hand. I'd like to classify it differently so right hand image should be classified as right hand, and left hand image respectively as left. Unfortunately my current model sees no differences between them and it constantly fluctuates between both labels. \r\nIs there any solution for this like turning off data augmentation, or changing some settings? Or maybe it's problem of insufficient data for training (I use around 33-35 images for one label)?"""
513065150,4397,b'TextCatalog.ApplyWordEmbedding to KMeans Trainer generates IndexOutOfRangeException',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 PRO 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: 3.1.100-preview1-014459\r\n\r\n### Issue\r\nI am trying to cluster a group of documents. For this sample, I used news articles short descriptions. If I run this sample with `FeaturizeText` the sample builds a model. If I try to apply `TextCatalog.ApplyWordEmbedding` I get a `System.IndexOutOfRangeException`.\r\n\r\n- **What did you do?** Applying Wordembedding to KMeans Trainer\r\n- **What happened?** IndexOutOfRangeException\r\n- **What did you expect?** For the ML.NET to build my model\r\n\r\n### Source code / logs\r\nSample code to reproduce the problem can be found [here](https://github.com/MaxAkbar/machinelearning-samples/tree/MachineLearningSampleBench/samples/csharp/getting-started/Clustering_NewsArticles).\r\n\r\nStackTrace: | \r\n------------ | \r\nSystem.AggregateException: One or more errors occurred. (Index was outside the bounds of the array.) (Index was outside the bounds of the array.) (Index was outside the bounds of the array.)\r\n ---> System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Trainers.KMeansBarBarInitialization.<>c__DisplayClass3_1.<Initialize>b__2(VBuffer`1& point, Int32 pointRowIndex, Single[] weights, Random rand)\r\n   at Microsoft.ML.Trainers.KMeansUtils.<>c__DisplayClass8_1`2.<ParallelMapReduce>b__0()\r\n   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot, Thread threadPoolThread)\r\n   --- End of inner exception stack trace ---\r\n   at System.Threading.Tasks.Task.WaitAllCore(Task[] tasks, Int32 millisecondsTimeout, CancellationToken cancellationToken)\r\n   at System.Threading.Tasks.Task.WaitAll(Task[] tasks)\r\n   at System.Threading.Tasks.Parallel.Invoke(ParallelOptions parallelOptions, Action[] actions)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw(Exception source)\r\n   at System.Threading.Tasks.Parallel.ThrowSingleCancellationExceptionOrOtherException(ICollection exceptions, CancellationToken cancelToken, Exception otherException)\r\n   at System.Threading.Tasks.Parallel.Invoke(ParallelOptions parallelOptions, Action[] actions)\r\n   at Microsoft.ML.Trainers.KMeansUtils.ParallelMapReduce[TPartitionState,TGlobalState](Int32 numThreads, IHost baseHost, Factory factory, RowIndexGetter rowIndexGetter, InitAction`1 initChunk, MapAction`1 mapper, ReduceAction`2 reducer, TPartitionState[]& buffer, TGlobalState& result)\r\n   at Microsoft.ML.Trainers.KMeansBarBarInitialization.Initialize(IHost host, Int32 numThreads, IChannel ch, Factory cursorFactory, Int32 k, Int32 dimensionality, VBuffer`1[] centroids, Int64 accelMemBudgetMb, Int64& missingFeatureCount, Int64& totalTrainingInstances)\r\n   at Microsoft.ML.Trainers.KMeansTrainer.TrainCore(IChannel ch, RoleMappedData data, Int32 dimensionality)\r\n   at Microsoft.ML.Trainers.KMeansTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at ClusteringNewsArticles.Train.Program.Main(String[] args) in C:\\Users\\maxim\\Source\\Repos\\machinelearning-samples\\samples\\csharp\\getting-started\\Clustering_NewsArticles\\ClusteringNewsArticles.Train\\Program.cs:line 54\r\n ---> (Inner Exception #1) System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Trainers.KMeansBarBarInitialization.<>c__DisplayClass3_1.<Initialize>b__2(VBuffer`1& point, Int32 pointRowIndex, Single[] weights, Random rand)\r\n   at Microsoft.ML.Trainers.KMeansUtils.<>c__DisplayClass8_1`2.<ParallelMapReduce>b__0()\r\n   at System.Threading.ExecutionContext.RunFromThreadPoolDispatchLoop(Thread threadPoolThread, ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot, Thread threadPoolThread)<---\r\n\r\n ---> (Inner Exception #2) System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Trainers.KMeansBarBarInitialization.<>c__DisplayClass3_1.<Initialize>b__2(VBuffer`1& point, Int32 pointRowIndex, Single[] weights, Random rand)\r\n   at Microsoft.ML.Trainers.KMeansUtils.<>c__DisplayClass8_1`2.<ParallelMapReduce>b__0()\r\n   at System.Threading.ExecutionContext.RunFromThreadPoolDispatchLoop(Thread threadPoolThread, ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot, Thread threadPoolThread)<--- |'"
512986116,4396,b'Cross validation with stratified folds',"b'\r\nThere does not appear to be a way to stratify data in ML.NET, is this likely to be implemented anytime soon?\r\n\r\nSay I have data that has an uneven predictor field split 90% / 10%, I would like to cross-validate the data with k folds so that each fold will produce an even predictor split of 50% / 50% (or any desired split setting value).\r\n\r\nThis does not seem possible yet but is a major feature that is required as part of ML modelling.'"
512908324,4394,b'ProviderFactory is null when using DatabaseLoader in Jupyter',"b'### System information\r\n\r\n- **OS version/distro**: Win 10 \r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n\r\nNuGet\r\n- ML.NET preview2\r\n- Microsoft.ML. Experimental 0.0.16-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI attempted to load data from a SQL Server DB using the DatabaseLoader from a Jupyter Notebook.\r\nI was first using System.Data.SqlClient as the ProviderFactory, but I got multiple re-direct issues in Jupyter. I moved to Microsoft.Data.SqlClient, which is supposed to work better with .NET Core and continued passed that issue. However, I instead run in to an issue where it says the provider factory is null. \r\n\r\nJust to make sure, I tested this in Visual Studio 2019. It works just fine there, this seems to be an issue with the Jupyter env.\r\n\r\n![image](https://user-images.githubusercontent.com/30201569/67628425-60a9a400-f83b-11e9-9a1e-93f45247c71e.png)\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
512785252,4392,b'Cannot use middleware dependencies when using custom ModelLoader on AddPredictionEnginePool',"b'If a custom `ModelLoader` is used for the `PredictionEnginePool` that has a dependency on a configured service, there is no possibility to add this dependency via `AddPredictionEnginePool` as it does not offer an overload that accepts an implementation factory, unlike `AddSingleton`, `AddScoped` and `AddTransient`.\r\n\r\nThis is how it should be expected to happen in `Startup`:\r\n\r\n```\r\nservices.AddPredictionEnginePool<Foo, Bar>(serviceProvider =>\r\n{\r\n    services.AddOptions<PredictionEnginePoolOptions<Foo, Bar>>().Configure(options =>\r\n    {\r\n        options.ModelLoader = new MyModelLoader(serviceProvider.GetService<IMyService>());\r\n    });\r\n    return new PredictionEnginePool<Foo, Bar>();\r\n});\r\n```\r\n\r\nSince this is not possible with the current code, the creation of a model via middleware is therefore very difficult.  The only option is to use `ServiceProvider.BuildServiceProvider` which causes a warning as it results in an additional copy of singleton services being created:\r\n\r\n```\r\nservices.AddPredictionEnginePool<Foo, Bar>()\r\nservices.AddOptions<PredictionEnginePoolOptions<Foo, Bar>>().Configure(options =>\r\n{\r\n    var serviceProvider = services.BuildServiceProvider();\r\n    options.ModelLoader = new MyModelLoader(serviceProvider.GetService<IMyService>());\r\n});\r\n```\r\n\r\nA new `AddPredictionEnginePool` overload should be added that accepts an implementation factory delegate to allow middleware services to be accessed via the `IServiceProvider`.'"
512692430,4389,b'Unit-test for older model versions that use multiclass scorer',b'https://github.com/dotnet/machinelearning/pull/4372#discussion_r339196504'
512658934,4387,b'Incorrect header comments in CodeGen template files',b'The auto generated files under `src/Microsoft.ML.CodeGenerator/Templates/` directory are creating incorrect header comments and need to be modified.\r\n\r\nRefer to:\r\nhttps://github.com/dotnet/machinelearning/pull/4365#discussion_r338733805\r\n\r\ncc: @JakeRadMSFT @LittleLittleCloud @rustd @eerhardt @sharwell '
512599912,4386,b'[Feature Request] ImageTypeAttribute',"b'Please consider exposing the int height, int width as getter properties; this will allow developers to use reflection to detect the image height, width from the supplied input model as apposed to having to supply configuration values that may not match via a separate model object class '"
512481166,4385,b'Create methods not being called when loading models from disk',"b'There are some classes that define a Create method which is supposed to be called when loading a model from disk, but the problem is that the method is not being called at all.\r\n\r\nFor example, I\'ve noticed this unexpected behavior in the following classes:\r\n1. [LinearBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.StandardTrainers/Standard/LinearModelParameters.cs#L473)\r\n2. [GamBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/GamClassification.cs#L233)\r\n3. [FastTreeBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/FastTreeClassification.cs#L87)\r\n4. [FastForestBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/RandomForestClassification.cs#L102)\r\n5. [PlattCalibrator](https://github.com/dotnet/machinelearning/blob/c922529e669d1c4dcb4d2bf8157a579b10a60cee/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1569)\r\n\r\nwhen loading a model that uses any of these classes, their Create method is expected to be called, but, as stated, the method is not being called.\r\n\r\nI also noticed this behavior in 3 other classes of the [Calibrator.cs](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1569) file (namely, the `ParameterMixingCalibratedModelParameters`, `ValueMapperCalibratedModelParameters`, and `FeatureWeightsCalibratedModelParameters` classes), but I\'ve fixed this problem for those specific classes in my recent PR #4306 (which, as of the moment of writing this, is still waiting to get approved). It was while working on that PR that I noticed this problem on these classes, and I commented about it [there](https://github.com/dotnet/machinelearning/pull/4306#discussion_r336139379)... but it is appropriate to open this separate issue to better document this, since it is a problem that affects different classes across different files.\r\n\r\nIn fact, as I will describe below, there\'s a certain code pattern that is related to this problem, and I\'ve seen this pattern in other classes of the Calibrator.cs file as well. So, the problem I describe here might be affecting even more classes than the ones I\'ve mentioned.\r\n\r\n### Cause of the problem\r\nThe [CreateInstanceCore](https://github.com/dotnet/machinelearning/blob/7c067854b564275b0d6387ca59c0ec83e8fc91b9/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L186) method in the `ComponentCatalog.cs` file is responsible to try to call the `Create` method of any class when loading a model from disk.\r\n\r\nThe current implementation of the method actually checks first if the class has a constructor with parameters `(IHostEnvironment env, ModelLoadContext ctx)` and invokes that constructor through reflection. If the class doesn\'t have such a constructor, then it checks if it has a `Create((IHostEnvironment env, ModelLoadContext ctx)` method, and it gets invoked through reflection.\r\n\r\nThis behavior is not desired for the classes I\'ve mentioned (and potentially other classes), since they define both a constructor and a Create method with those parameters, but in these cases it\'s actually expected that the Create method gets called instead of the constructor. Thus, if a class follows the pattern of having a private or internal constructor (with the `(env, ctx)` parameters) and also has a Create method, then this problem might also be affecting that class.\r\n\r\nSince the Create method typically only runs some security checks before calling the constructor, it turns out that the overall process of loading models doesn\'t seem affected by this issue. But the problem remains that these security checks are being missed along with whatever behavior the Create method adds to the process.\r\n\r\nAs explained by @yaeldekel in [her comment](https://github.com/dotnet/machinelearning/pull/4306#discussion_r337981820) on my recent PR #4306 (under ""Answer 1""), this problem might had been introduced before the official release of ML.net, when the `ComponentCatalog` method was modified in a way that permitted the `CreateInstanceCore` method to use private and internal constructors, which didn\'t use to happen... so before those changes were made, classes could have private or internal constructors and a Create method, and the latter would appropriately be called. But now the constructor gets called, and this is the case of all the classes mentioned in this issue.\r\n\r\nSince these changes were made while trying to internalize as many APIs as possible before the ML.net official release, many constructors where also made private or internal, and thus the changes in ComponentCatalog that permit using those constructors are also necessary.\r\n\r\nBecause of these, further investigation is needed to know for sure which classes are being affected by this problem, so to better find a way to fix this problem without affecting all of the other classes that doesn\'t present this situation.'"
512245563,4383,b'CreatePredictionEngine does not work after retrain the modal without column Transforms',"b'### System information\r\n\r\n- Win7\r\n- DotNet Core 2.1\r\n\r\n### Issue\r\n\r\n- after first training ,   \r\n```C#\r\ntransf = mlc.Transforms.Text.FeaturizeText(""Features"", ""TextData"")\r\n   .Append(mlc.BinaryClassification.Trainers.LbfgsLogisticRegression()).Fit(data);  \r\n```\r\n\r\nI saved the LinearBinaryModelParameters , and retrain the modal as :  \r\n\r\n```C#\r\ntransf = mlc.BinaryClassification.Trainers.LbfgsLogisticRegression().Fit(newdata, lbmparameters);\r\n```  \r\nand call  \r\n```C#\r\npe = mlc.Model.CreatePredictionEngine<ViewItem, ViewPred>(transf);\r\n```\r\n\r\n- for the first time of the training , PredictionEngine works . after retrain , PredictionEngine do not works and throws  \r\n`System.ArgumentOutOfRangeException: Features column \'Feature\' not found`\r\n\r\n- I expect the CreatePredictionEngine can pass the `mlc.Transforms.Text.FeaturizeText(""Features"", ""TextData"")`  so the TextData can be generated as Features  \r\nOr \r\n```\r\nmlc.Transforms.Text.FeaturizeText(""Features"", ""TextData"")\r\n   .Append(mlc.BinaryClassification.Trainers.LbfgsLogisticRegression()).Fit   \r\n```\r\nThe Fit function can pass LinearBinaryModelParameters \r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n```C#\r\nusing System;\r\nusing System.Linq;\r\nusing System.IO;\r\nusing Microsoft.ML;\r\nusing System.Collections.Generic;\r\n\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers;\r\n\r\nclass Program\r\n{\r\n\tstatic bool STUDY_CONTINUE_MODE = true;\r\n\r\n\tconst int MEM_SIZE = 9;\r\n\r\n\tstatic Random rand = new Random();\r\n\r\n\tstatic int total_study = 0;\r\n\r\n\tstatic List<ViewItem> happymem = new List<ViewItem>();\r\n\tstatic List<ViewItem> dangermem = new List<ViewItem>();\r\n\tstatic int GetTotalMemCount()\r\n\t{\r\n\t\treturn happymem.Count + dangermem.Count;\r\n\t}\r\n\r\n\tstatic string feeling = new string(\'0\', MEM_SIZE);\r\n\r\n\tstatic MLContext mlc = new MLContext();\r\n\r\n\tstatic long totalticks = 0;\r\n\r\n\tstatic long totalright = 0;\r\n\tstatic long totalwrong = 0;\r\n\r\n\tstatic void Main()\r\n\t{\r\n\r\n\t\twhile (true)\r\n\t\t{\r\n\t\t\tRunTick();\r\n\t\t\ttotalticks++;\r\n\t\t\tif (totalticks % 10000 == 0 && transf != null && totalright + totalwrong > 2)\r\n\t\t\t{\r\n\t\t\t\tConsole.Title = totalticks + "" - ""\r\n\t\t\t\t\t+ "" "" + 100 * safe_mem / totalmem + ""%""\r\n\t\t\t\t\t+ "" CV="" + 100 * totalright / (totalright + totalwrong) + ""%""\r\n\t\t\t\t\t+ "" "" + totalright + ""/"" + totalwrong\r\n\t\t\t\t\t+ "" PV="" + 100 * predright / Math.Max(1, predtimes) + ""%""\r\n\t\t\t\t\t+ "" "" + predright + ""/"" + (predtimes - predright)\r\n\t\t\t\t\t+ "" HQ="" + Hao_Qi.ToString(""00000"")\r\n\r\n\t\t\t\t\t+ "" ML="" + total_study + "" "" + (100 * dangermem.Count / GetTotalMemCount()) + ""%"" + "" "" + dangermem.Count + ""/"" + GetTotalMemCount()\r\n\t\t\t\t\t  ;\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}\r\n\r\n\tstatic ITransformer transf;\r\n\tstatic ITransformer firsttransf;\r\n\tstatic LinearBinaryModelParameters lbmparameters = null;\r\n\t\r\n\tstatic void StudyOnce(ViewItem[] items)\r\n\t{\r\n\t\tvar data = mlc.Data.LoadFromEnumerable(items);\r\n\r\n\t\tif (lbmparameters == null)\r\n\t\t{\r\n\t\t\tif (!STUDY_CONTINUE_MODE)\r\n\t\t\t\tmlc = new MLContext();\r\n\t\t\t\r\n\t\t\tvar mytransf = mlc.Transforms.Text.FeaturizeText(""Features"", ""TextData"")\r\n\t\t\t   .Append(mlc.BinaryClassification.Trainers.LbfgsLogisticRegression()).Fit(data);\r\n\r\n\t\t\tif (STUDY_CONTINUE_MODE)\r\n\t\t\t\tlbmparameters = mytransf.LastTransformer.Model.SubModel;\r\n\r\n\t\t\tfirsttransf = mytransf;\r\n\t\t\ttransf = mytransf;\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\t//TODO:\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b,\xe4\xbd\x86\xe6\x98\xaf\xe5\x9c\xa8\xe4\xbd\xbf\xe7\x94\xa8\xe4\xb8\x8a\xe5\xad\x98\xe5\x9c\xa8\xe9\x97\xae\xe9\xa2\x98.\r\n\t\t\t//\xe5\x9b\xa0\xe4\xb8\xba\xe4\xbd\xbf\xe7\x94\xa8\xe4\xba\x86.Fit(newdata, lbmparameters)\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84Transformer\xe4\xb8\x8d\xe5\x85\xb7\xe5\xa4\x87 mlc.Transforms.Text.FeaturizeText(""Features"", ""TextData"") \xe8\xbf\x99\xe4\xb8\xaa\xe6\xad\xa5\xe9\xaa\xa4.\r\n\t\t\t//\xe8\xbf\x99\xe4\xbc\x9a\xe5\xaf\xbc\xe8\x87\xb4 CreatePredictionEngine(transf) \xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xe6\x97\xa0\xe6\xb3\x95\xe6\x8a\x8aViewItem.TextData\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xbaFeatures \r\n\r\n\t\t\tvar newdata = firsttransf.Transform(data);\r\n\r\n\t\t\tvar mytransf = mlc.BinaryClassification.Trainers.LbfgsLogisticRegression().Fit(newdata, lbmparameters);\r\n\r\n\t\t\tif (STUDY_CONTINUE_MODE)\r\n\t\t\t\tlbmparameters = mytransf.Model.SubModel;\r\n\r\n\t\t\ttransf = mytransf;\r\n\t\t}\r\n\r\n\t}\r\n\r\n\r\n\tstatic void StudyOnce()\r\n\t{\r\n\t\tViewItem[] items = new ViewItem[GetTotalMemCount()];\r\n\t\thappymem.CopyTo(items, 0);\r\n\t\tdangermem.CopyTo(items, happymem.Count);\r\n\t\tStudyOnce(items);\r\n\t}\r\n\r\n\tclass ViewItem\r\n\t{\r\n\t\tpublic string TextData;\r\n\r\n\t\t[ColumnName(""Label"")]\r\n\t\tpublic bool IsDanger;\r\n\t}\r\n\tclass ViewPred\r\n\t{\r\n\t\tpublic bool PredictedLabel;\r\n\r\n\t\t[ColumnName(""Score"")]\r\n\t\tpublic float ScoreValue;\r\n\r\n\t\tpublic float Probability;\r\n\t}\r\n\r\n\tstatic int Hao_Qi = 100;\r\n\r\n\tstatic long totalmem = 0;\r\n\tstatic long safe_mem = 0;\r\n\r\n\tstatic bool feeling_isdanger;\r\n\r\n\tstatic void RunTick()\r\n\t{\r\n\t\ttotalmem++;\r\n\r\n\t\tfeeling = feeling.Remove(0, 1) + rand.Next(0, 10);\r\n\r\n\t\tfeeling_isdanger = feeling.Contains(""9"");\r\n\r\n\t\tif (!feeling_isdanger)\r\n\t\t\tsafe_mem++;\r\n\t\t\r\n\t\tHao_Qi += 10;\r\n\r\n\t\tif (Hao_Qi > 100)\r\n\t\t{\r\n\t\t\tfloat danger = GetDangerLevel();\r\n\t\t\tif (Hao_Qi > 20000 * danger)\r\n\t\t\t{\r\n\t\t\t\tDoClick();\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}\r\n\r\n\tstatic long predtimes = 0;\r\n\tstatic long predright = 0;\r\n\r\n\tstatic PredictionEngine<ViewItem, ViewPred> pe;\r\n\tstatic ITransformer petransf;\r\n\r\n\tstatic float GetDangerLevel()\r\n\t{\r\n\t\tif (transf == null)\r\n\t\t\treturn 0;\r\n\r\n\t\tif (pe == null || petransf != transf)\r\n\t\t{\r\n\t\t\tif (pe != null)\r\n\t\t\t\tpe.Dispose();//prevent memory leak ???\r\n\t\t\tpe = mlc.Model.CreatePredictionEngine<ViewItem, ViewPred>(transf);\r\n\t\t\tpetransf = transf;\r\n\t\t}\r\n\r\n\t\tViewPred pred = pe.Predict(new ViewItem() { TextData = feeling });\r\n\r\n\t\tbool isdanger = pred.PredictedLabel;\r\n\r\n\t\tpredtimes++;\r\n\t\tif (isdanger == feeling_isdanger)\r\n\t\t{\r\n\t\t\tpredright++;\r\n\t\t}\r\n\r\n\t\treturn pred.Probability;\r\n\t}\r\n\r\n\tstatic void DoClick()\r\n\t{\r\n\t\tif (!feeling_isdanger)\r\n\t\t{\r\n\t\t\tHao_Qi -= 40;\r\n\t\t\ttotalright++;\r\n\r\n\t\t\thappymem.Add(new ViewItem { TextData = feeling, IsDanger = feeling_isdanger });\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tHao_Qi -= 90;\r\n\t\t\ttotalwrong++;\r\n\r\n\t\t\tdangermem.Add(new ViewItem { TextData = feeling, IsDanger = feeling_isdanger });\r\n\t\t}\r\n\r\n\t\tif (happymem.Count > maxcount || dangermem.Count > maxcount)\r\n\t\t{\r\n\t\t\ttotal_study++;\r\n\t\t\tStudyOnce();\r\n\r\n\t\t\tif (happymem.Count > maxcount)\r\n\t\t\t\thappymem.RemoveRange(0, happymem.Count / 10);\r\n\t\t\tif (dangermem.Count > maxcount)\r\n\t\t\t\tdangermem.RemoveRange(0, dangermem.Count / 10);\r\n\t\t\tif (maxcount < 20000) maxcount = (int)(maxcount * 1.2);\r\n\t\t}\r\n\r\n\t}\r\n\r\n\tstatic int maxcount = 999;\r\n\r\n}\r\n```'"
512225213,4381,b'Incorrect code in BinaryModelParameters classes',"b""There is a problem with the code inside the Create method of the following classes:\r\n1. [LinearBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.StandardTrainers/Standard/LinearModelParameters.cs#L473)\r\n2. [GamBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/GamClassification.cs#L233)\r\n3. [FastTreeBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/FastTreeClassification.cs#L87)\r\n4. [FastForestBinaryModelParameters](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/RandomForestClassification.cs#L102)\r\n\r\nThe problem is that in those 4 cases, each Create method has a return statement that returns a `SchemaBindableCalibratedModelParameters<,>` object. Notice that these Create methods are supposed to load from disk, in each case, a BinaryModelParameters object of the appropriate type. So this doesn't make sense, since the SBCMP class is not supposed to be used as a BinaryModelParameter, and thus, **these classes shouldn't be loaded as SBCMP objects**.\r\n\r\nI pointed at this problem inside [this comment](https://github.com/dotnet/machinelearning/pull/4306#discussion_r336265838) (under question number 2) while working on my PR #4306 . There, @yaeldekel [responded](https://github.com/dotnet/machinelearning/pull/4306#discussion_r337981820) that these pieces of code seem 'very wrong' to her, and that they might be the result of some legacy code that is no longer valid. Specifically she mentioned that in the past Calibrators where a field of predictors, and predictors were responsible of loading them at deserialization time. This is no longer the case, and her guess is that the code that I've pointed to is no longer valid.\r\n\r\nEven more, she believes that the `return new SBCMP` statements I've mentioned are actually unreachable now, since they all appear in branches that only execute when there is _no calibrator_ to load inside the BinaryModelParameters (e.g. [this](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.FastTree/RandomForestClassification.cs#L110) 'if statement'). Since predictors are no longer in charge of loading calibrators, then those paths are unreachable, and then the Create methods I've mentioned, always return the predictor of the appropriate type anyway, without getting into creating `SBCMP` objects.\r\n\r\nIn the case of the `LinearBinaryModelParameters` Create method, a ParameterMixingCalibratedModelParameters<,> object could [also be returned](https://github.com/dotnet/machinelearning/blob/d531ea801a34a3018b8fa2a2f352902eb703cd25/src/Microsoft.ML.StandardTrainers/Standard/LinearModelParameters.cs#L484), but this also seems invalid and unreachable for the same reasons already described for SBCMP.\r\n\r\nPerhaps further investigation is needed to clarify all of this, and **if those pieces of code are truly unreachable and no longer valid, then it might be better to remove them**."""
512196996,4378,b'how to parse the ML.Net log file',"b""What is the logic behind the debug_log.txt, if one would like to parse it, how would one go at it. \r\nit's not documented as far as I can tell, I can find things  in it but I would like to load it using C# into a structured format.\r\n\r\nI have not seem to have found a clever way to do this. can some one point me at the right direction?"""
512143218,4376,b'mlnet command not found',"b'Problem encountered on https://dotnet.microsoft.com/learn/ml-dotnet/get-started-tutorial/train\r\nOperating System: macos Catalina 10.15.1 Beta (19B77a)\r\ndotnet version: 3.0.100\r\n\r\n```\r\ndev@iMac myMLApp % mlnet auto-train --task binary-classification --dataset ""wikipedia-detox-250-line-data.tsv"" --label-column-name ""Sentiment"" --max-exploration-time 10\r\nzsh: command not found: mlnet\r\ndev@iMac myMLApp % dotnet tool install -g mlnet         \r\nTool \'mlnet\' is already installed.\r\n```'"
511911889,4373,b'How to use String as a Predicted Column',"b'Goal:\r\nMake a prediction on PaymentType. The target name or predicted column is a string value.\r\n\r\nProblem:\r\nI retrieve a error message that is ""ArgumentOutOfRangeException: Training label column \'Label\' type isn\'t suitable for regression: Text. Type must be R4 or R8. Parameter name: data""\r\n\r\nWhar part from the source code am I missing?\r\n\r\nThank you!\r\n\r\nData:\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/data/taxi-fare-train.csv\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/data/taxi-fare-test.csv\r\n\r\nInfo:  \r\n*Win 10\r\n*Using .net Core 2.0 framework\r\n\r\nCode:\r\n\r\n```csharp\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Models;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\nusing System;\r\nusing System.Threading.Tasks;\r\n\r\nnamespace TaxiFarePrediction\r\n{\r\n    class Program\r\n    {\r\n        const string _datapath = @"".\\Data\\taxi-fare-train.csv"";\r\n        const string _testdatapath = @"".\\Data\\taxi-fare-test.csv"";\r\n        const string _modelpath = @"".\\Data\\Model.zip"";\r\n\r\n        static async Task Main(string[] args)\r\n        {\r\n            PredictionModel<TaxiTrip, TaxiTripFarePrediction> model = await Train();\r\n            Evaluate(model);\r\n\r\n            var prediction = model.Predict(TestTrips.Trip1);\r\n            Console.WriteLine(""Predicted fare: {0}"", prediction.PaymentType);\r\n\r\n            Console.ReadLine();\r\n        }\r\n\r\n        static async Task<PredictionModel<TaxiTrip, TaxiTripFarePrediction>> Train()\r\n        {\r\n            // Create learning pipeline\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                // Load and transform data\r\n                new TextLoader(_datapath).CreateFrom<TaxiTrip>(separator: \',\'),\r\n\r\n                 // Labeling\r\n                new ColumnCopier((""PaymentType"", ""Label"")),\r\n\r\n                // Feature engineering\r\n                new CategoricalOneHotVectorizer(""VendorId"",\r\n                    ""RateCode"",\r\n                    ""PaymentType""),\r\n\r\n                 // Combine features in a single vector\r\n                new ColumnConcatenator(""Features"",\r\n                    ""VendorId"",\r\n                    ""RateCode"",\r\n                    ""PassengerCount"",\r\n                    ""TripDistance"",\r\n                    ""FareAmount""),\r\n\r\n                // Add learning algorithm\r\n                new FastTreeRegressor()\r\n            };\r\n\r\n            // Train the model\r\n            PredictionModel<TaxiTrip, TaxiTripFarePrediction> model = pipeline.Train<TaxiTrip, TaxiTripFarePrediction>();\r\n\r\n            // Save the model to a zip file\r\n            await model.WriteAsync(_modelpath);\r\n\r\n            return model;\r\n        }\r\n\r\n        private static void Evaluate(PredictionModel<TaxiTrip, TaxiTripFarePrediction> model)\r\n        {\r\n            // Load test data\r\n            var testData = new TextLoader(_datapath).CreateFrom<TaxiTrip>(useHeader: true, separator: \',\');\r\n\r\n            // Evaluate test data\r\n            var evaluator = new RegressionEvaluator();\r\n            RegressionMetrics metrics = evaluator.Evaluate(model, testData);\r\n\r\n            // Display regression evaluation metrics\r\n            Console.WriteLine(""Rms="" + metrics.Rms);\r\n            Console.WriteLine(""RSquared = "" + metrics.RSquared);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n\r\n---------------------------------------------------------------------\r\n\r\n```csharp\r\nnamespace TaxiFarePrediction\r\n{\r\n    static class TestTrips\r\n    {\r\n        internal static readonly TaxiTrip Trip1 = new TaxiTrip\r\n        {\r\n            VendorId = ""VTS"",\r\n            RateCode = ""1"",\r\n            PassengerCount = 1,\r\n            TripDistance = 10.33f,\r\n            PaymentType = """", \r\n            FareAmount = 7,\r\n            //FareAmount = 0 // predict it. actual = 29.5\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n---------------------------------------------------------------------\r\n```csharp\r\n\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace TaxiFarePrediction\r\n{\r\n    public class TaxiTrip\r\n    {\r\n        [Column(""0"")]\r\n        public string VendorId;\r\n\r\n        [Column(""1"")]\r\n        public string RateCode;\r\n\r\n        [Column(""2"")]\r\n        public float PassengerCount;\r\n\r\n        [Column(""3"")]\r\n        public float TripTime;\r\n\r\n        [Column(""4"")]\r\n        public float TripDistance;\r\n\r\n        [Column(""5"")]\r\n        public string PaymentType;\r\n\r\n        [Column(""6"")]\r\n        public float FareAmount;\r\n    }\r\n\r\n}\r\n\r\n```\r\n\r\n-------------------------------------------------\r\n\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace TaxiFarePrediction\r\n{\r\n    public class TaxiTripFarePrediction\r\n    {\r\n\r\n        /*\r\n        [ColumnName(""Score"")]\r\n        public float FareAmount;\r\n\r\n        */\r\n        [ColumnName(""Score"")]\r\n        public string PaymentType;\r\n    }\r\n}\r\n\r\n```\r\n\r\n-------------------------------------\r\n\r\n\r\n![ml1](https://user-images.githubusercontent.com/14993569/67485473-613f1080-f66a-11e9-8c8a-c85b8355585c.png)\r\n![ml2](https://user-images.githubusercontent.com/14993569/67485474-613f1080-f66a-11e9-8442-05e08c37407f.png)\r\n\r\n\r\n\r\n\r\n\r\n'"
511364376,4369,b'Error during training tensorflow images recognition with ML.NET 1.4preview2',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.6, 4.6.2, CORE - 2.0, 2.1, 3.0\r\n\r\n### Issue\r\n\r\nError running sample: ImageClassification.Train with Ml.NET 1.4Preview2\r\n\r\n- **What did you do?** Tried to run sample  ImageClassification.Train\r\n- **What happened?** \r\ngot error on line  ITransformer trainedModel = pipeline.Fit(trainDataView); \r\n- **What did you expect?** Produce trained model\r\n\r\n### Source code / logs\r\nException:\r\n\r\nSystem.ArgumentOutOfRangeException: The size of input lines is not consistent\r\nParameter name: Source\r\n   at Microsoft.ML.Data.TextLoader.Bindings..ctor(TextLoader parent, Column[] cols, IMultiStreamSource headerFile, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.Data.TextLoader..ctor(IHostEnvironment env, Options options, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer.GetShuffledData(String path)\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer.TrainAndEvaluateClassificationLayer(String trainBottleneckFilePath, Options options, String validationSetBottleneckFilePath)\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer..ctor(IHostEnvironment env, Options options, DnnModel tensorFlowModel, IDataView input)\r\n   at Microsoft.ML.Transforms.ImageClassificationEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at ImageClassification.Train.Program.Main(String[] args) in C:\\Projekty\\Experimental\\v14\\DeepLearning_TensorFlowEstimator\\ImageClassification.Train\\Program.cs:line 78\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n\r\n'"
510989908,4367,b'LoadFromTextFile unable to correctly parse CSV file',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Home\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Loaded the following dataset: https://data.world/promptcloud/fashion-products-on-amazon-com/workspace/file?filename=amazon_co-ecommerce_sample.csv\r\n- **What happened?** The data was not correctly loaded. It looks like data from the same row is used in the following row etc. It may have something to do with the final column in the dataset.\r\n- **What did you expect?** Each row to load correctly as it does if opening the file in Excel\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
510972523,4366,"b""UWP: Compilation error - C:\\Users\\user\\.nuget\\packages\\microsoft.net.uwpcoreruntimesdk\\2.2.9\\tools\\CoreRuntime\\Microsoft.Net.CoreRuntime.targets(195,9): error : Framework resource extraction failed. Exception of type 'System.OutOfMemoryException' was thrown.""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have large UWP project:\r\n[https://www.microsoft.com/ru-ru/p/spider-intelligence/9phw2smp1hl7?activetab=pivot:overviewtab](url)\r\nI have added ML.NET and ML processing algorithms to the solution. \r\nOnce I did ""Clean solution"" and \xe2\x80\x9cRebuilt solution\xe2\x80\x9d....\r\n- **What happened?**\r\nBuilder have given me following error: ""C:\\Users\\user\\.nuget\\packages\\microsoft.net.uwpcoreruntimesdk\\2.2.9\\tools\\CoreRuntime\\Microsoft.Net.CoreRuntime.targets(195,9): error : Framework resource extraction failed. Exception of type \'System.OutOfMemoryException\' was thrown.""\r\n\r\nI have checked that the cause of the problem is ML.NET: I have removed ML.NET link and code from the solution, everything become fine. \r\n\r\nI have checked all versions of microsoft.net.uwpcoreruntimesdk, ML.NET, other libraries, building options. But error is still here. \r\nI have 48GB RAM so it is nor RAM issue.\r\n\r\n- **What did you expect?**\r\nAny way to build my UWP large enough project with ML.NET inside :) I think it is compiler or linker BUG somewhere.\r\n\r\n### Source code / logs\r\nCode is large... If it is needed, I can prepare code sample with error.\r\n\r\n'"
510796392,4364,b'Unable to find input colum on tensor flow model using C#',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core 3.0\r\n### Issue\r\n\r\n- **What did you do?**\r\nI created my own TensorFlow object detection model and tried to load it in a C# console application.\r\n- **What happened?**\r\nWhen I tried to create a model by using pipeline.fit I get this error System.ArgumentOutOfRangeException: \xe2\x80\x9dCould not find input column \xe2\x80\x98image_tensor\xe2\x80\x99 (Parameter \xe2\x80\x98inputSchema\xe2\x80\x99)\r\n- **What did you expect?**\r\nI would have been able to create the model and continue to create the prediction engine and test my TensorFlow.\r\n### Source code / logs\r\n\r\nI posted the question on the blog that showed how to load a pretrained TensorFlow model to ""Call out @yaeldekel in the issue. She might be able to help here.""  \r\n\r\n\r\nHere is what I see in Netron\r\n![image](https://user-images.githubusercontent.com/11445010/67310423-55651a00-f4c3-11e9-9fc6-53707cd1227c.png)\r\n\r\n\r\nHere is how I am loading the pipeline\r\n```C#\r\nvar pipeline = context.Transforms\r\n                .LoadImages(""input"", @""D:\\tensorflow1\\images"",nameof(ImageNetData.ImagePath))              \r\n                .Append(context.Transforms.ExtractPixels(outputColumnName: ""input"", interleavePixelColors: true))\r\n                .Append(context.Model.LoadTensorFlowModel(@""D:\\tensorflow1\\models\\research\\object_detection\\inference_graph\\PotatoDetector.pb"")\r\n              .ScoreTensorFlowModel(outputColumnNames: new[] { ""detection_boxes"",""detection_classes"",""detection_scores"", ""num_detections"" } },inputColumnNames: new[] { ""image_tensor"" }, addBatchDimensionInput: true));\r\n```\r\nWhen I try to load the model inPython like so it works just fine.\r\n```python\r\nimage_tensor = detection_graph.get_tensor_by_name(\'image_tensor:0\')\r\ndetection_boxes = detection_graph.get_tensor_by_name(\'detection_boxes:0\')\r\ndetection_scores = detection_graph.get_tensor_by_name(\'detection_scores:0\')\r\ndetection_classes = detection_graph.get_tensor_by_name(\'detection_classes:0\')\r\nnum_detections = detection_graph.get_tensor_by_name(\'num_detections:0\')\r\n\r\n\r\nimage = cv2.imread(PATH_TO_IMAGE)\r\nimage_expanded = np.expand_dims(image, axis=0)\r\n\r\nprint(""going to run the model now"")\r\n\r\n(boxes, scores, classes, num) = sess.run(\r\n    [detection_boxes, detection_scores, detection_classes, num_detections],\r\n    feed_dict={image_tensor: image_expanded})\r\n```\r\nAny ideas on how to find the input column that ML.NET wants?  \r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
510419323,4363,b'OnlineGradientDescent crash',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI ran the script:\r\n```C#\r\nvar mlContext = new MLContext();\r\nvar textLoader = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n{\r\n\tColumns = new TextLoader.Column[]\r\n\t{\r\n\t\tnew TextLoader.Column(""Label"", DataKind.Single, 0),\r\n\t\tnew TextLoader.Column(""0"", DataKind.String, 1),\r\n\t\tnew TextLoader.Column(""1"", DataKind.String, 2),\r\n\t\tnew TextLoader.Column(""2"", DataKind.Single, 3),\r\n\t\tnew TextLoader.Column(""3"", DataKind.Single, 4),\r\n\t\tnew TextLoader.Column(""4"", DataKind.Single, 5),\r\n\t\tnew TextLoader.Column(""5"", DataKind.Single, 5),\r\n\t},\r\n\tHasHeader = true,\r\n\tSeparators = new char[] {\',\'}\r\n});\r\nvar dataView = textLoader.Load(@""dataset.csv"");\r\nvar pipeline = mlContext.Transforms.Categorical.OneHotHashEncoding(""0"")\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""1"", ""3""))\r\n\t.Append(mlContext.Transforms.Concatenate(""Features"", ""0"", ""1"", ""2"", ""3"", ""4"", ""5""))\r\n\t.Append(mlContext.Transforms.NormalizeMinMax(""Features""))\r\n\t.Append(mlContext.Regression.Trainers.OnlineGradientDescent(new OnlineGradientDescentTrainer.Options()\r\n\t{\r\n\t\tLearningRate = 1.0f,\r\n\t\tDecreaseLearningRate = false,\r\n\t}));\r\npipeline.Fit(dataView);\r\n```\r\n(I can provide the data as requested)\r\n\r\n- **What happened?**\r\nI get the exception\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.\r\n  Source=Microsoft.ML.StandardTrainers\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.OnlineLinearTrainer`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at OnlineGradientDescentCrash.Program.Main(String[] args) in C:\\Users\\daholste\\source\\repos\\OnlineGradientDescentCrash\\OnlineGradientDescentCrash\\Program.cs:line 38\r\n```\r\n\r\n- **What did you expect?**\r\nSuccessful training'"
510340157,4361,b'Data file locked even after TextLoader goes out of context',"b'### System information\r\nMicrosoft Windows [Version 10.0.18363.418]\r\n.NET framework 4.8\r\nMicrosoft.ML- 1.4.0-preview2\r\nMicrosoft.ML.AutoML - 0.16.0-preview2\r\n\r\n### Issue\r\n\r\nIn the code attached, Trainset.csv is locked even after the MLTrain() method completes execution.\r\nsurprisingly, Testset.csv is not locked.\r\n\r\n[Program.txt](https://github.com/dotnet/machinelearning/files/3753250/Program.txt)\r\n'"
510273354,4359,b'Remove dependency on Newtonsoft.Json',"b""Now that we have https://www.nuget.org/packages/System.Text.Json/, we should remove our dependency on Newtonsoft.Json, at a minimum in our core Microsoft.ML nuget package.\r\n\r\nThis has the following advantages:\r\n\r\n1. Less assemblies to carry around/deploy on .NET Core, since `System.Text.Json` is part of the shared framework.\r\n2. It frees up the calling program to pick which version of Newtonsoft.Json it can use, instead of Microsoft.ML saying that it must use one `10.0.3` or higher.\r\n3. `System.Text.Json` is faster (although we don't really use JSON code on any critical path).\r\n4. In the core Microsoft.ML nuget package, this is the only 3rd party dependency. So removing it means ML.NET only depends on `System` packages."""
509644125,4354,b'[AutoML] Recommendation experiment got SMAC local search exception during training',"b""Hey folks\r\n\r\nI just try the Recommendation experiment API in the master branch. After I training for a period of time (like 300 sec), I got this error.\r\n\r\n```\r\nUnhandled Exception: System.AggregateException: One or more errors occurred. ---> System.InvalidOperationException: SMAC sweeper localSearch threw exception ---> System.MethodAccessException: Attempt by method 'Microsoft.ML.AutoML.SmacSweeper.ComputeForestStats(Double[][])' to access method 'Microsoft.ML.Trainers.FastTree.VectorUtils.GetMean(Double[])' failed.\r\n   at Microsoft.ML.AutoML.SmacSweeper.ComputeForestStats(Double[][] leafValues)\r\n   at Microsoft.ML.AutoML.SmacSweeper.LocalSearch(ParameterSet parent, FastForestRegressionModelParameters forest, Double bestVal, Double epsilon, Boolean isMetricMaximizing)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.AutoML.SmacSweeper.LocalSearch(ParameterSet parent, FastForestRegressionModelParameters forest, Double bestVal, Double epsilon, Boolean isMetricMaximizing)\r\n   at Microsoft.ML.AutoML.SmacSweeper.GreedyPlusRandomSearch(ParameterSet[] parents, FastForestRegressionModelParameters forest, Int32 numOfCandidates, IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.SmacSweeper.GenerateCandidateConfigurations(Int32 numOfCandidates, IEnumerable`1 previousRuns, FastForestRegressionModelParameters forest)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerWhitelist)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<>c__DisplayClass23_0`4.<InnerTrainModelAsync>b__4() in C:\\Users\\xiaoyuz\\Source\\Repos\\machinelearning-tools\\Microsoft.ML.ModelBuilder.AutoMLService\\AutoMLEngineService\\AutoMLEngine.cs:line 277\r\n   at System.Threading.Tasks.Task`1.InnerInvoke()\r\n   at System.Threading.Tasks.Task.Execute()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<InnerTrainModelAsync>d__23`4.MoveNext() in C:\\Users\\xiaoyuz\\Source\\Repos\\machinelearning-tools\\Microsoft.ML.ModelBuilder.AutoMLService\\AutoMLEngineService\\AutoMLEngine.cs:line 281\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__9.MoveNext() in C:\\Users\\xiaoyuz\\Source\\Repos\\machinelearning-tools\\Microsoft.ML.ModelBuilder.AutoMLService\\AutoMLEngineService\\AutoMLEngine.cs:line 107\r\n   --- End of inner exception stack trace ---\r\n   at System.Threading.Tasks.Task.ThrowIfExceptional(Boolean includeTaskCanceledExceptions)\r\n   at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\r\n   at System.Threading.Tasks.Task.Wait()\r\n   at ConsoleApp1.Program.Main(String[] args) in C:\\Users\\xiaoyuz\\Source\\Repos\\machinelearning-tools\\Microsoft.ML.ModelBuilder.AutoMLService\\Program.cs:line 36\r\n```\r\n\r\nthe dataset I use is this [one](https://raw.githubusercontent.com/dotnet/machinelearning-samples/master/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation/Data/recommendation-ratings-train.csv)\r\n\r\nI guess it's because of value error (like nan). But I'm not too sure about that, Please take a look, any suggestion will be helpful. Thanks\r\n\r\n## A minimal reproducable example [here](https://github.com/LittleLittleCloud/ReproducableExampleForIssue4354)"""
509603271,4353,b'Recognise specific noise through Spectrogram images',"b'Hi,\r\n\r\nSorry if not best place to ask for a general pointer, but I recon someone could be able to quickly point me in the right direction re models/training etc.\r\n\r\nI\'ve got a audio files in the format of spectrograms (png files), each about 2 seconds long (overlapping windows about .5 second) for a 10 minute audio file.\r\n\r\nThere is one specific noise that I want to identify in audio files, and treat all other noises as ""background"" or not interested in.\r\n\r\nI\'ve looked at using TensorFlow and the sample Image Classification (https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification) and taking a few dozen spectrograms of what I want and classified as ""true"" and then a randoms selection of spectrogram images of ""background"" noise (i.e. anything i don\'t care about) and classified as ""false"".\r\n\r\nIs this the best way to approach this with the .net ML libraries, or is there a better way to say, ""this is all I want and I don\'t care about anything else"", and not give it any samples of background noise images at all?\r\n\r\nThanks,\r\n\r\nRoss\r\n\r\n'"
509336351,4352,b'[Microsoft.Extensions.ML] Update Microsoft.Extensions.ML from 0.16.0-preview2 to 1.4',"b""@eerhardt \r\n\r\nWe need to update Microsoft.Extensions.ML from 0.16.0-preview2 to 1.4 so it'll be ready for 1.4 GA.\r\n\r\nThis is mostly related to the .NET Integration package implementing the PredictionEnginePool for multi-threaded apps such as ASP.NET Core apps/services.\r\n\r\n"""
509242925,4348,b'[Image Classification API] Error when running ResnetV2101 transfer learning sample with Cats Vs Dogs dataset.',"b""### Issue\r\n\r\n- **What did you do?**\r\nRan the ResnetV2101TransferLearningTrainTestSplit sample with the Cats Vs Dogs dataset at https://www.microsoft.com/en-us/download/details.aspx?id=54765.\r\n\r\n- **What happened?**\r\nWhen computing bottleneck values, run aborted with the error message:\r\n2 root error(s) found.\r\n  (0) Invalid argument: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM^\\357\\n\\000\\000\\000\\000\\0006\\000\\000\\000(\\000'\r\n         [[{{node DecodeJpeg}}]]\r\n         [[DecodeJpeg/_1]]\r\n  (1) Invalid argument: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM^\\357\\n\\000\\000\\000\\000\\0006\\000\\000\\000(\\000'\r\n         [[{{node DecodeJpeg}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\nTensorflow.TensorflowException: 2 root error(s) found.\r\n  (0) Invalid argument: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM^\\357\\n\\000\\000\\000\\000\\0006\\000\\000\\000(\\000'\r\n         [[{{node DecodeJpeg}}]]\r\n         [[DecodeJpeg/_1]]\r\n  (1) Invalid argument: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM^\\357\\n\\000\\000\\000\\000\\0006\\000\\000\\000(\\000'\r\n         [[{{node DecodeJpeg}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n   at Tensorflow.Status.Check(Boolean throwException)\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.Runner.Run() in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Dnn\\DnnUtils.cs:line 453\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer.ImageProcessor.ProcessImage(VBuffer`1& imageBuffer) in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Dnn\\ImageClassificationTransform.cs:line 244\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer.CacheFeaturizedImagesToDisk(IDataView input, String labelColumnName, String imageColumnName, ImageProcessor imageProcessor, String inputTensorName, String outputTensorName, String cacheFilePath, Dataset dataset, ImageClassificationMetricsCallback metricsCallback) in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Dnn\\ImageClassificationTransform.cs:line 284\r\n   at Microsoft.ML.Transforms.ImageClassificationTransformer..ctor(IHostEnvironment env, Options options, DnnModel tensorFlowModel, IDataView input) in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Dnn\\ImageClassificationTransform.cs:line 169\r\n   at Microsoft.ML.Transforms.ImageClassificationEstimator.Fit(IDataView input) in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Dnn\\ImageClassificationTransform.cs:line 1517\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 67\r\n   at Samples.Dynamic.ResnetV2101TransferLearningTrainTestSplit.Example() in C:\\Users\\aibhanda\\source\\repos\\ashbhandare-machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Dynamic\\ImageClassification\\ResnetV2101TransferLearningTrainTestSplit.cs:line 87\r\n\r\n- **What did you expect?**\r\nThere should be a way to either identify the bad images so that they can be removed, or the run should continue by skipping these images or both.\r\n\r\n### Source code / logs\r\n[ResnetV2101_CatsVDogs.txt.txt](https://github.com/dotnet/machinelearning/files/3745204/ResnetV2101_CatsVDogs.txt.txt)\r\n\r\n\r\n"""
508150229,4343,b'[Planning] Explore GAN (Generative Adversarial Networks) implementation in ML.NET + TensorFlow',"b""For future features planning it'd be worth to explore possibilities in ML.NET enabling GAN (Generative Adversarial Networks) implementation in ML.NET + TensorFlow.\r\n\r\nMost popular use cases are related to images generation, such as this cool prototype app:\r\n\r\nhttps://github.com/microsoft/GenStudio \r\nhttps://gen.studio/\r\n\r\nHowever, GAN can also be applied to data and very interesting cases are related to **synthetic data generation** from a generative adversarial network (GAN) designed to approximate any original training data distribution. For instance, you have a Time Series dataset of just a couple of years and want to generate a larger synthetic dataset, or any other synthetic data generation.\r\n\r\nMany more use cases:\r\nhttps://github.com/nashory/gans-awesome-applications \r\n \r\nQuestion for anyone in the community reading this issue, can you answer this issue with your thoughts about GAN (Generative Adversarial Networks), your own business scenarios and possibilities you might see in ML.NET?"""
507537183,4339,"b""Can't find label when file header start with #""","b'Using VS 2019 (16.2.5).\r\n\r\nI selected the multi-class classification scenario and used the [iris-train.txt dataset](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/MulticlassClassification_Iris/IrisClassification/Data/iris-train.txt). I had to change ""#Label"" column header to ""Label"" for it to Train properly.\r\n\r\n![image](https://user-images.githubusercontent.com/10437687/66523316-82b5cf00-eaa4-11e9-8ccd-654341964ed9.png)\r\n'"
506894336,4335,b'API for loading ONNX model lacks access to input schema and is not consistent with regular model loading API',"b""Current API for loading models is as follows:\r\n            ITransformer mlModel = mlContext.Model.Load(path, out DataViewSchema inputSchema);\r\n\r\nNote you have a transformer back and the input schema, plus transformer gives access to output schema as well.\r\nFor ONNX the same functionality will look something like this:\r\n            var estimator = mlContext.Transforms.ApplyOnnxModel(path);\r\n            var dataView = mlContext.Data.LoadFromEnumerable<ModelInput>(new ModelInput[] { });\r\n            // Fit() will check the input schema of the model against the input dataview you're passing in\r\n            var transformer = estimator.Fit(dataView);\r\n\r\nNote there's no way to get the input schema, you have to know it before you can do anything with the model.  Also Fit() call is confusing and inconsistent with the much cleaner API above, it doesn't actually do anything other than verify the [unavailable from public interface] input schema against the schema that got loaded with the model.\r\n\r\nThe fix is to bring ONNX model loading API in line with what we have for regular ML.NET models."""
506853848,4333,b'Appending to an empty estimator results in ArgumentOutOfRangeException during Evaluate',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n```\r\nvar mlContext = new MLContext(0);\r\nvar trainTestData = mlContext.Data.TrainTestSplit(mlContext.Data.LoadFromEnumerable(data));\r\nvar pipeline = new EstimatorChain<TransformerChain<RegressionPredictionTransformer<FastTreeRegressionModelParameters>>>();\r\n\r\npipeline.Append(mlContext.Transforms.CopyColumns(""Label"", ""Foo"")\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", ""Bar"", ""Baz""))\r\n    .Append(mlContext.Regression.Trainers.FastTree()));\r\n\r\nvar model = pipeline.Fit(trainTestData.TrainSet);\r\nmlContext.Regression.Evaluate(model.Transform(trainTestData.TestSet));\r\n```\r\n\r\n- **What happened?**\r\n`Evaluate` throws `ArgumentOutOfRangeException`:\r\n> Label column \'Label\' not found (Parameter \'schema\')\r\n\r\n- **What did you expect?**\r\nTo behave the same as this code:\r\n```\r\nvar mlContext = new MLContext(0);\r\nvar trainTestData = mlContext.Data.TrainTestSplit(mlContext.Data.LoadFromEnumerable(data));\r\n\r\nvar pipeline = mlContext.Transforms.CopyColumns(""Label"", ""Foo"")\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", ""Bar"", ""Baz""))\r\n    .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\nvar model = pipeline.Fit(trainTestData.TrainSet);\r\nmlContext.Regression.Evaluate(model.Transform(trainTestData.TestSet));\r\n```\r\n...which indeed of course doesn\'t throw an exception.  Instantiating a new `EstimatorChain` object should create an empty estimator chain as indicated by the summary for the default constructor.  I would then expect to just be able to append estimators to it as if I had started with creating one from a concrete estimator that I then appended further estimators to.'"
506717531,4332,b'How to update model in ml .net every day?',b'Hi every body.\r\nHow to update model in ml .net every day to increase accuracy?'
506652457,4331,"b'Not sample how to call this, also fit normaly takes only 1 argument...'","b'The following code does not allow to call fit using the pipeline\n            var dataProcessPipeline = GeneratePipelin(data, out var trainingDataView, out var testDataView );\n\n            var options = new LightGbmBinaryTrainer.Options\n            {\n                NumberOfIterations=100\n                , LearningRate=0.2281511\n                , NumberOfLeaves=46\n                , MinimumExampleCountPerLeaf=10\n                , UseCategoricalSplit=false\n                , HandleMissingValue=true\n                , MinimumExampleCountPerGroup=200\n                , MaximumCategoricalSplitPointCount=8\n                , CategoricalSmoothing=10\n                , L2CategoricalRegularization=0.5                \n                , EvaluationMetric = LightGbmBinaryTrainer.Options.EvaluateMetricType.Error\n                , LabelColumnName=nameof(BinaryModelInput.Trend)\n            };\n\n            var trainer = mlContext.BinaryClassification.Trainers.LightGbm(options);\n            //.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\n\n            var trainingPipeline =dataProcessPipeline.Append(trainer);\n            var model = trainingPipeline.Fit(trainingDataView,testDataView);\nthe training pipeline is of type \n EstimatorChain&lt;BinaryPredictionTransformer&lt;Microsoft.ML.Calibrators.CalibratedModelParametersBase&lt;LightGbmBinaryModelParameters, Microsoft.ML.Calibrators.PlattCalibrator&gt;&gt;&gt;\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: fb3687e4-d6ed-52df-b362-de76c9c302c5\n* Version Independent ID: cba9caf7-2b90-28c3-5cfe-ad1b34c3c5eb\n* Content: [LightGbmBinaryTrainer.Fit(IDataView, IDataView) Method (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmbinarytrainer.fit?view=ml-dotnet#Microsoft_ML_Trainers_LightGbm_LightGbmBinaryTrainer_Fit_Microsoft_ML_IDataView_Microsoft_ML_IDataView_)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
506484258,4330,b'Would be nice to know the defaults',"b""When tuning it's important to know something about the defaults as the number of possible combinations is rather large and not knowing where one starts is rather a poor first step trying to optimize a model\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: c16a2948-f15c-1e3a-d6c0-1cfaae544d57\n* Version Independent ID: 0447cd1a-a1a3-76da-2ea3-c9f9efc051c1\n* Content: [LightGbmMulticlassTrainer.Options Class (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmmulticlasstrainer.options?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmMulticlassTrainer+Options.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmMulticlassTrainer+Options.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
506463281,4329,b'If normalisation is required why does the sample not do this',"b'The trainer is stated to be needing normalisation, the sample does not show this in the pipeline, how is normalisation done?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 98e5fc20-effa-58e7-0271-2380fdb73bd9\n* Version Independent ID: 71cdb61f-ae25-9a4d-3c19-16d17ab81694\n* Content: [StandardTrainersCatalog.LinearSvm Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.standardtrainerscatalog.linearsvm?view=ml-dotnet#Microsoft_ML_StandardTrainersCatalog_LinearSvm_Microsoft_ML_BinaryClassificationCatalog_BinaryClassificationTrainers_Microsoft_ML_Trainers_LinearSvmTrainer_Options_)\n* Content Source: [dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
506334961,4328,b'How do I convert topics to words?',"b'The example is missing the step where the topics identified are converted to a high level word that describes the topics for each document. Can you add that bit to the example?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 87b08415-641d-4246-280f-b19e3baa8857\n* Version Independent ID: 30d278f5-27f7-eee4-141f-d05dc1d34bfa\n* Content: [TextCatalog.LatentDirichletAllocation(TransformsCatalog+TextTransforms, String, String, Int32, Single, Single, Int32, Int32, Int32, Int32, Int32, Int32, Int32, Boolean) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.textcatalog.latentdirichletallocation?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/TextCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TextCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
506062597,4326,b'Move the Image Classification from the Experimental package (0.16) to a stable package heading to 1.4 GA',"b'We want to mark the ImageClassification DNN based as a ""stable API"" when we ship 1.4 GA.\r\n\r\nHowever, it is currently in the Experimental package `Microsoft.ML.Dnn 0.16.0-preview2`, (**0.16**).\r\n\r\nWe should move the ImageClassification DNN to a stable package.\r\n\r\nOr we could also maintain the `Microsoft.ML.Dnn` package and simply change the version to 1.4. \r\n'"
506060969,4325,b'[Image Classification DNN based] Cannot use GPU with NuGet 0.16.0-preview2',"b""The NuGet package 'Microsoft.ML.Dnn 0.16.0-preview2' is including a dependency on the CPU-based `SciSharp.TensorFlow.Redist` package: \r\n\r\n![image](https://user-images.githubusercontent.com/1712635/66684962-1a93f400-ec30-11e9-96a2-fdb675fa9e20.png)\r\n\r\nTherefore the user cannot reference and use the `SciSharp.TensorFlow.Redist-Windows-GPU` package because the CPU version has preference, afaik.  \r\n\r\nThe NuGet package `Microsoft.ML.Dnn 0.16.0-preview2` must not reference any of those, so depending on what SciSharp TensorFlow redist (CPU vs. GPU) the user is referencing from his code, it'll use CPU or GPU.\r\n\r\nI know this is being fixed in the ML.NET source code repo with this PR after my heads-up:\r\nhttps://github.com/dotnet/machinelearning/pull/4324\r\n\r\n**But users mostly use the NuGet packages so we probably need to publish a new fix-patch-release for that package like the following?**:\r\n\r\n`Microsoft.ML.Dnn 0.16.1-preview2` ?\r\n\r\nAny other solution so users can try Image Classification with GPU when using the NuGet packages?"""
505538543,4323,b'Move DatabaseLoader from the Experimental package',"b'We want to mark the DatabaseLoader as a ""stable API"" when we ship 1.4. However, it is currently in the Experimental package, which will never be marked as stable.\r\n\r\nWe should move the DatabaseLoader to a stable package.\r\n\r\nIf I get a vote, my vote would be to add it to the core `Microsoft.ML` package, next to TextLoader. DatabaseLoader adds no extra dependencies, so I think it is completely fine to add it to the `Microsoft.ML` package.'"
505475143,4322,b'LDA Get Words for Topics',"b""### System information\r\n\r\n- **Win10\r\n- **.NET 4.7.2\r\n- **ML.NET 1.3.1\r\n\r\nI am trying to get the top N words for each topic after an LDA Transform but cannot seem to figure out how to do.  I've used Infer.Net and it returns the topics and top 20 words, is there a way to do it in ML.NET using the LDA Xform?  I've used relfection to look through almost everything in the xformer but cannot seem to find anything that would work?\r\n\r\nThe goal is to use the top N words to label a topic for display and to further determine if we need more/less topics based on repeating words.\r\n\r\n"""
504753469,4320,b'Export to ONNX',"b""What is the state of exporting to ONNX, I noticed it's missing from the latest documentation and only in the 0.15 docs.  Is it still supported?\r\n\r\nThanks."""
504747488,4319,b'[Image Classification API] Schema mismatch when loading images using file paths',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 \r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nUpdated from Microsoft.ML 1.4.0-preview to 1.4.0-preview2. Using code that worked, I ran into an issue when loading images.\r\n\r\n- **What happened?**\r\n\r\nAn ArgumentOutOfRangeException was thrown due to a schema mismatch.\r\n\r\n```text\r\nSystem.ArgumentOutOfRangeException: 'Schema mismatch for input column 'ImagePath': expected Vector<Byte>, got String\r\nParameter name: inputSchema'\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nThe model to train.\r\n\r\n### Source code / logs\r\n\r\n\r\nRepo with source code : https://github.com/luisquintanilla/DeppLearning_ImageClassification_API\r\n\r\nThis repo uses 1.4.0-preview and works in training a model. If the same code is used with 1.4.0-preview2, the error mentioned in this issue occurs."""
504697947,4318,b'Interop with C++ (from/to)',"b'### System information\r\n\r\n- **OS version/distro**:\r\nNot relevant\r\n- **.NET Version (eg., dotnet --info)**: \r\n.core 3.0\r\n\r\n### Issue\r\n\r\nIs there a way to interop from plain C++ with ml.net ? There is a lot of very useful ideas in ml.net (like DataView) and it would make sense to use them in a C++ project for example.  I know there is P/Invoke, but perhaps could we use a more streamlined way?'"
504564460,4317,b'how we can get number of row processed on each node to calculate score each node in decision tree for fasttree trainer?',b'@yaeldekel - how we can get number of row processed on each node \r\nto calculate score each node in decision tree for fasttree trainer?\r\nexample:- root node(5000 row processed) then splitting left child (3000 row processed)\r\n and right child(2000 row processed)  again splitting on left child one have leaf node and second node have decision node(1000 row processed) to split again.\r\nso that how we get how many row has been processed to each node?\r\n                                                    '
504360827,4316,b'AutoTrain issues on Mac',"b""When running auto-train I get errors like the following:\r\n\r\nI'm wondering how I can fix these errors.  Thanks.\r\n\r\n`\r\nmlnet auto-train --task binary-classification --dataset ./training_data_v2.csv --label-column-name Class --max-exploration-time 3600 --verbosity=diag --has-header true --name Model\r\n`\r\n\r\nSystem.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(liblib_lightgbm, 1): image not found\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmInterface.DatasetCreateFromSampledColumn(IntPtr sampleValuePerColumn, IntPtr sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String parameters, IntPtr& ret)\r\n   at Microsoft.ML.Trainers.LightGbm.Dataset..ctor(Double[][] sampleValuePerColumn, Int32[][] sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String param, Single[] labels, Single[] weights, Int32[] groups)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} xf=Normalizing{ col=Features:Features} tr=SymbolicSgdLogisticRegressionBinary{}  cache=+\r\n[Source=AutoML, Kind=Error] Pipeline crashed: xf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} xf=Normalizing{ col=Features:Features} tr=SymbolicSgdLogisticRegressionBinary{}  cache=+ . Exception: System.TypeInitializationException: The type initializer for 'Native' threw an exception. ---> System.DllNotFoundException: Unable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.ErrorMessage(Int32 status)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native..cctor()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(InputDataManager inputDataManager, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Span`1 weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, GCHandle stateGCHandle, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] 4\tNaN\t00:00:06.7512942\txf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} xf=Normalizing{ col=Features:Features} tr=SymbolicSgdLogisticRegressionBinary{}  cache=+\r\n|4    SymbolicSgdLogisticRegressionBinary       NaN      NaN      NaN       NaN       6.8          0             |\r\nSystem.TypeInitializationException: The type initializer for 'Native' threw an exception. ---> System.DllNotFoundException: Unable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.ErrorMessage(Int32 status)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native..cctor()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(InputDataManager inputDataManager, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Span`1 weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, GCHandle stateGCHandle, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} xf=Normalizing{ col=Features:Features} tr=LinearSvmBinary{}  cache=+\r\n[Source=AutoML, Kind=Trace] 5\t0.999542783117267\t00:00:10.1887405\txf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} xf=Normalizing{ col=Features:Features} tr=LinearSvmBinary{}  cache=+\r\n|5    LinearSvmBinary                        0.9995   1.0000   1.0000    0.9997      10.2          0             |\r\n[Source=AutoML, Kind=Trace] Evaluating pipeline xf=TextFeaturizing{ col=Title_tf:Title} xf=ColumnCopying{ col=Features:Title_tf} tr=FastTreeBinary{}  cache=-"""
504207567,4313,b'[LoadImages estimator] Set useImageType: false as by default value',"b""In the current preview, in the LoadImages estimator, the parameter useImageType is by default true meaning that it'd use ImageDataView type. false indicates we want the image as a VBuffer<byte>.\r\n\r\nSince the ImageClassification API needs the image as VBuffer<byte> (ImageDataView type is only used for other existing/older scenarios with transforms like resize image, extract pixels etc...) it makes sense to set the parameter useImageType to false as default (to use VBuffer<byte>). \r\n\r\nHowever, that change will be convenient for the new ImageClassification API but it would break older code using the LoadImages estimator. Right?\r\n\r\nWe might need to decide what scenarios we want to favor here for this default value..."""
504149555,4311,b'Documentation should state the default values',b'Knowing the default value of this option would be nice.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 68ab420f-a92f-61a5-6457-4434ec28fa31\n* Version Independent ID: c03e6492-9c30-c2bd-0014-7b9ab590864f\n* Content: [MatrixFactorizationTrainer.Options.ApproximationRank Field (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.matrixfactorizationtrainer.options.approximationrank?view=ml-dotnet-preview#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/MatrixFactorizationTrainer+Options.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/MatrixFactorizationTrainer+Options.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
503674384,4309,b'New LightGBM test fails only when running on CI build',"b'### Issue\r\nI tried adding a test case to test RankingEvaluator with Maml using the LightGBMRanking trainer. The testcase passed on my machine and other build configurations. However, it failed on those same configurations on the github build. The testcase was added in response to issue #4081. To unblock me, I used the FastRankRanking trainer instead, which does work as expected.   \r\n\r\n### Source code / logs\r\nThe test case I added looks like this\r\n```\r\n        public void EvaluateRankingWithMaml()\r\n        {\r\n            string _mslrWeb10k_Train = GetDataPath(TestDatasets.MSLRWeb.trainFilename);\r\n            string extraArgs = "" tr=LightGBMRanking"" +\r\n                "" eval=RankingEvaluator{t=10}"" +\r\n                "" k=2"";\r\n            string loaderArgs = "" loader=TextLoader{col=Label:R4:0 col=GroupId:TX:1 col=Features:R4:2-138 header=+}"" +\r\n                "" xf = HashTransform{col=GroupId}"" +\r\n                "" xf = NAHandleTransform{col=Features}"";\r\n            int digitsOfPrecision = 2;\r\n            TestCore(""cv"", _mslrWeb10k_Train, loaderArgs, extraArgs, digitsOfPrecision);\r\n            Done();\r\n\r\n        }\r\n```\r\n\r\n'"
503626428,4307,b'DnnCatalog methods should use a public Options class',"b""The two methods in `DnnCatalog`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c9f616fdc5a144250535949fc8c8f9c971cbab88/src/Microsoft.ML.Dnn/DnnCatalog.cs#L49-L63\r\n\r\nand\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c9f616fdc5a144250535949fc8c8f9c971cbab88/src/Microsoft.ML.Dnn/DnnCatalog.cs#L120-L143\r\n\r\nhave a lot of optional parameters, and users may get confused on which ones are important, and which aren't.\r\n\r\nI've seen comments from @terrajobst in the past saying:\r\n\r\n> In UX studies we have seen that many developers struggle with methods that have many optional arguments.\r\n\r\nIn ML.NET, the pattern we have established is that we have 2 overloads:\r\n\r\n1. An overload that takes the required parameters, and optionally the most important/common parameters to a method.\r\n2. An overload that takes an `Options` object, which contains all the options to the method - simple and advanced.\r\n\r\nWe should follow this pattern with these DNN APIs as well. See the discussions and related PRs to https://github.com/dotnet/machinelearning/issues/1798.\r\n\r\n/cc @ebarsoumMS @codemzs """
503613368,4305,b'ML.TensorFlow has a dependency on ML.Dnn',"b""I don't think the dependency from `ML.TensorFlow` to `ML.Dnn` is correct. My understanding of `ML.Dnn` is that it is a higher-level abstraction for deep neural networks, of which TensorFlow is the first one we are using. However, in the future, we may want to add more neural network libraries to `ML.Dnn` - for example, PyTorch. If that ever happens, now the `ML.TensorFlow` library will also be dependent on PyTorch, since it will have a transitive reference from `ML.Dnn` to PyTorch.\r\n\r\nWe should rethink the dependency structure here. If the only reason `ML.TensorFlow` has a dependency on `ML.Dnn` is for sharing internal code, we should come up with a different code sharing mechanism. For example, the way we solve this in dotnet/corefx is we use share the same source code, and compile it directly into multiple assemblies using source links in the .csprojs."""
503275449,4304,b'how we visualize output for ranking?',b'@eerhardt - how we visualize output for ranking?\r\ni.e. charts or heatmap and how?'
503268888,4303,b'why binning is importance in binary classification?',b'@eerhardt - when i have studied binning is one of the method to represent numeric data into the group of data.as per studied which numeric column have unique value that data taken into binning as consider.\r\nif this true then unique value is more then that numeric column does not consider as binning process.\r\nconsider heart attack prediction(for data:https://towardsdatascience.com/heart-disease-prediction-73468d630cfc)\r\nin that we calculate binning for age but we cannot calculate for Resting Blood Pressure\r\nhow we calculate number bins in numeric column and which numeric column has been consider for binning process?'
503263900,4302,b'how we visualize credit card fraud detection using anomaly detection trainer(PCA)?',"b'@eerhardt - how we represent best way credit card detection using anomaly detection method\r\ni.e. grid or charts.\r\nif grid then which column we added in that grid-\r\nexample-time,V1-V28,amount,probability,score as column\r\n\r\nand if charts then which column we take to draw the charts for x-axis and y-axis taken.\r\n\r\nplease helps us.'"
502875147,4299,b'Problems caused by ML.Samples and ML.Samples.GPU sharing the same Program.cs file',"b""### Issue\r\n\r\n**What did you do?**: I modified the Program.cs file in the ML.Samples project to run a sample that exists in the Samples.Dynamic.Trainers.Regression namespace.\r\n\r\n**What happened?**:\r\nSince ML.Samples and ML.Samples.GPU share the same Program.cs file, my changes in the Program.cs under ML.Samples had effects on the ML.Samples.GPU project.\r\n\r\nAn error appeared in the Program.cs file inside the ML.Samples.GPU project saying that the namespace Samples.Dynamic didn't have a name 'Trainers' and that I might have been missing an assembly reference. Also, while editing the Program.cs inside ML.Samples I received warning tooltips making reference to the errors in ML.Samples.GPU's Program.cs.\r\n\r\nAlthough this didn't prevent me to run the sample, it was odd to see that error messages. Also, later, when trying to run tests inside Visual Studio, I got a compiler errors because of this, and I couldn't run tests. I didn't use to have these compiler errors before, because ML.Samples.GPU was introduced in a recent commit to the master branch.\r\n\r\n**How to solve the problem?**\r\nEventhough ML.Samples has the correct settings to access the sample I was trying to run, ML.Samples.GPU doesn't. This problem might happen with other samples as well.\r\n\r\nSo to simply solve this problem, a new Program.cs file needs to be added to the ML.Samples.GPU project, that is independent to the one in ML.Samples."""
502698674,4296,b'Far more weights than features when obtaining PFI Metrics for Binary Classification',"b'Windows 10 v. 1809\r\n- NET Core SDK (3.0.100): \r\n\r\n\r\nI have used trained model with numerical features, and this has successfully returned PFI metrics, whereby the number of weights is equivalent to the number of features.\r\nHowever, the issue arises when  I pass a dataset without numerical features. When the features are categorical and strings, I use one hot encoding to convert the features into the appropriate vectors. \r\nIn both the former and present case, I use a FastForest trainer. \r\nWhen I follow the documentation for PFI, the model is trained fine, but when I run the code:\r\n\r\n` VBuffer<float> weights = default;\r\nlinearPredictor.Model.SubModel.GetFeatureWeights(ref weights);`\r\n\r\nI get over 80 weights when I only have 12 features in my data. And I cannot continue following the documentation since it matches the index of the weights against the index of the feature.\r\n\r\nIs there a way to get the PFI when using OneHotEncoding?\r\n'"
502657868,4295,b'How to Convert Transform Result into DataTable by dynamically ?',"b'@eerhardt - \r\n\r\nIDataView multiclassTransformer = model.Transform(trainTestData.TestSet);\r\n\r\nDataViewSchema columns = multiclassTransformer.Schema;\r\n\r\nDataViewSchema.Column? columnOrNull = multiclassTransformer.Schema.GetColumnOrNull(""Features"");\r\n                            VBuffer<ReadOnlyMemory<char>> slotNames = new VBuffer<ReadOnlyMemory<char>>();\r\n                            if (columnOrNull.HasValue)\r\n                                columnOrNull.GetValueOrDefault().GetSlotNames(ref slotNames);\r\n\r\n                            IList<string> featurenameCollection= (IList<string>)slotNames.Items(false).Select<KeyValuePair<int, ReadOnlyMemory<char>>, string>((Func<KeyValuePair<int, ReadOnlyMemory<char>>, string>)(kv => kv.Value.ToString())).ToList<string>();\r\n\r\n\r\nHow i can convert the output result into DataTable\r\n\r\nAs Many of example uses Hardcoded class like below example\r\n\r\npublic class MultiClassResultPrediction\r\n        {\r\n            // public uint GroupId { get; set; }\r\n\r\n            // public uint Label { get; set; }\r\n\r\n            // Prediction made by the model that is used to indicate the relative ranking of the candidate search results.\r\n            public float Score { get; set; }\r\n\r\n            // Values that are influential in determining the relevance of a data instance. This is a vector that contains concatenated columns from the underlying dataset.\r\n            // public float[] Features { get; set; }\r\n        }\r\n\r\n\r\nList<MultiClassResultPrediction> predictedResult = context.Data.CreateEnumerable<MultiClassResultPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nor \r\n\r\nelse dynamic class where we can access featurevalues,label values and output result schema\r\nlike PredictedLabel,Score\r\nlike below example :\r\n\r\nwhere we can return output in web.\r\n\r\n       IDictionary<string, object> flexibleJson = new ExpandoObject();\r\n        for (int i = 0; i < length; i++)\r\n        {\r\n           \r\n            flexibleJson.Add(colName, colValue);\r\n        }\r\n\r\n        var serialized = JsonConvert.SerializeObject(flexibleJson);\r\n\r\nSo my concern is how we can convert result into DataTable\r\n\r\nis there any way we can achieve the desired result by dynamically into DataTabel?'"
502370834,4294,b'Remove default constructor of OnnxSequenceType attribute on next major release',"b'Related to issue #4120 , the temp fix to add obsolete attribute on default constructor but the ideal fix should be remove the default constructor.\r\n\r\nAs this is break Public API change, we will do it on next major release.\r\n'"
502329197,4292,b'Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk',"b'In my last accepted pull request (#4262 ) I addressed issue #3976 and was able to provide working samples and tests for using PFI with models loaded from disk except for the case of Binary Prediction Transformer. Here I open this issue about that specific problem.\r\n\r\n### Problem\r\nIn the [sample using PFI with binary classification](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L40) the last transformer of the model (i.e. the linearPredictor) is of type `BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>`.\r\n\r\nProblem is that when saving and then loading that model from disk, a null reference is returned when trying to access the last transformer by casting it to the original type.\r\n```\r\n// linearPredictor is null:\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>; \r\n```\r\n\r\nHaving a null linearPredictor makes it unusable with PFI.\r\n\r\nIn version 1.3 of ML.Net the last transformer of the loaded model would actually be of type `BinaryPredictionTransformer<IPredictorProducing<float>>`\r\n\r\nWith the changes I made in my last PR (which will be available in version 1.4.0 preview 2) the loaded model\'s last transformer would be of type `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>>` which is a step forward in solving the problem, but is not yet enough.\r\n\r\nAs stated, in both cases, a cast to the original type would return null. In general, it would be expected that the user tries to make that cast in order to use PFI, failing to accomplish it.\r\n\r\nThis problem would be solved if the loaded model actually had a lastTransformer of the original type, or something castable to it.\r\n\r\n### Workaround\r\nBased on [this comment](https://github.com/dotnet/machinelearning/pull/4262#discussion_r330175774) made by @yaeldekel I\'ve just made [this working sample of using PFI with a binary prediction transformer loaded from disk](https://gist.github.com/antoniovs1029/e5fdd86d5b7c8b6adf34cb5481ee20dd). It is pretty much the same as the original sample, only that it works with a model loaded from disk.\r\n\r\nThe key of the workaround is that the user should cast the lastTransformer not into a binary prediction transformer but rather into a `ISingleFeaturePredictionTransformer<object>`, and then do a series of casts to get whatever other object s/he may want to get from inside the lastTransformer.\r\n\r\nIn the sample I\'ve just provided it works pretty much in this way:\r\n```\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as ISingleFeaturePredictionTransformer<object>;\r\nvar predictorModel = linearPredictor.Model as CalibratedModelParametersBase;\r\nvar predictorSubModel = predictorModel.SubModel as LinearBinaryModelParameters;\r\n```\r\n\r\nNotice that this workaround worked even in ML.Net 1.3, and also works with the changes that I introduced in 1.4.0 preview 2.\r\n\r\nNotice that a similar workaround might help a user that tries to use PFI with any kind of prediction transformer loaded from disk. This would come useful if the user, for whatever reason, can not extract the linearPredictor by casting to the same type used in the original model.\r\n\r\n### Cause of the Problem\r\nThere are 3 main points that are related to the cause of this problem, all of which pertain the `Calibrator.cs ` file and aren\'t related to the binary prediction transformer itself:\r\n1. Unexpectedly, when loading a `ParameterMixingCalibratedModelParameters<>` its [Create method](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) isn\'t called. I discovered this while debugging, and what actually happens is that, during loading, inside the [CreateInstanceCore method](https://github.com/dotnet/machinelearning/blob/7c067854b564275b0d6387ca59c0ec83e8fc91b9/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L197), it first looks for a constructor, and so it calls the constructor of `ParameterMixingCalibratedModelParameters<>` instead of the Create method.\r\n2. Currently, when loading a `ParameterMixingCalibratedModelParameters<>` model, a `ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>` is always loaded, no matter what the actual submodel and calibrator are. This doesn\'t change by fixing point 1). This point is similar to the [original problem found on the prediction transformers](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076), which I fixed in [my last pull request](https://github.com/dotnet/machinelearning/pull/4262); using a similar approach in this case would fix this point... that is, loading first the submodel and calibrator to then create a generic type at runtime with the correct parameter types.\r\n3. When fiting the model (i.e. before even saving it or loading it) the [SdcaLogisticRegressionBinaryTrainer ](https://github.com/dotnet/machinelearning/blob/46ede664e8cff585c450a7005c7069b64df5a6f1/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs#L1606)creates a predictor of type `ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>` (which I will now refer to as ""PMCMP"") but returns it as a `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>` (let\'s call it ""CMPB"") this then is what makes the last transformer of the model to be a `BinaryPredictionTransformer<CMPB>` whereas the internal model of the last transformer is actually a PMCMP. When saving it to disk, it\'s saved as a PMCMP (i.e. it\'s saved using a LoaderSignature of ""PMixCaliPredExec""), so when loading occurs, it calls the constructor of PMCMP but it doesn\'t cast it to a CMPB. This is different from the problem fixed in my last pull request; there, if a Regression prediction transformer was saved, then we expected to load a regression prediction transformer... whereas in here if a BPT<PMCMP> is saved we actually want to load a PMCMP with the correct type parameters, but actually create a BPT<CMPB> where the CMPB should also have the correct type parameters.\r\n\r\n### Trying to solve the problem\r\nSo far I\'ve been able to solve problems 1) and 2) described above, but after trying out different approaches I haven\'t been able to solve problem 3). To solve those problems I\'ve changed different things in the `Calibrator.cs` file. My attempt to solve this problem can be found in PR #4306\r\n\r\nWith those changes (along with the ones of my last PR), the loaded model\'s last transformer becomes a `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>>`. Notice that even here a cast to `BPT<CMPB>` would be null, so it doesn\'t solve the problem. Also notice that since PMCMP is an internal class the user wouldn\'t be able to cast the last transformer to `BPT<PMCMP>` either, since s/he wouldn\'t have access to that class.\r\n\r\n### Further problems\r\nHere I\'ve explained the specific case of loading a `BPT<CMPB>` with the specific problems that arise in CMPB and PMCMP classes because that is what is used in the sample of PFI with BPT, and in the tests of PFI with BPT. It could be possible that the problems here described are also present in other classes (for example in the other classes of [Calibrator.cs](https://github.com/dotnet/machinelearning/blob/18394c4f9e45b9c5ff41dfbabd30e31132ae4cdc/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1)) but they might not become a problem unless the user tries to access the last transformer of a model loaded from disk. In such a case the described workaround might help.'"
502260817,4288,b'ScoreTensorFlowModel fails with null reference exception',"b'### System information\r\n\r\n- Win10 64bit\r\n- .net 4.6.1\r\n- Microsoft.ML.TensorFlow 1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsed LoadTensorFlowModel and ScoreTensorFlowModel on a pretrained model\r\n- **What happened?**\r\nScoreTensorFlowModel fails with null reference exception\r\n- **What did you expect?**\r\npipeline object\r\n\r\n### Source code / logs\r\n```\r\nvar estimator = mlContext.Model.LoadTensorFlowModel(""saved_model.pb"");\r\nConsole.WriteLine(""Inputs: "" + string.Join("";"", estimator.GetInputSchema().Select(c => c.Name)));\r\nvar pipeline = estimator.ScoreTensorFlowModel(\r\n    new[] { ""denoised"" },\r\n    new[] { ""is_training"", ""noisy"" }, addBatchDimensionInput: true);\r\n```\r\n\r\n[saved_model.zip](https://github.com/dotnet/machinelearning/files/3687784/saved_model.zip)\r\n'"
502232611,4287,b'Model Builder | Selecting a file without file type crashes Visual Studio',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** I downloaded the data for spam detection (ML samples)\r\n- **What happened?** When I opened the Model Builder in Visual studio and selected the training file, Visual Studio hangs and eventually crashes. Setting the file type to .tsv makes it work.\r\n- **What did you expect?** A reasonable error message would be useful, e.g. ""Please indicate if this file is tab- or comma-separated""\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
502230174,4286,b'[Image Classification API] Wrong number of images processed in training. ',"b'- **What did you do?**\r\nRun the sample ""ResnetV2101TransferLearningTrainTestSplit"" with different batch sizes(10, 100, 300). Added logging in the training loop just before batch is processed.\r\n- **What happened?**\r\nFrom second epoch onwards, number of images processed is more than total number of images in dataset.\r\n- **What did you expect?**\r\nNumber of images processed per epoch should be same.\r\n\r\n### Source code / logs\r\n[master_10.txt](https://github.com/dotnet/machinelearning/files/3687548/master_10.txt)\r\n[master_100.txt](https://github.com/dotnet/machinelearning/files/3687549/master_100.txt)\r\n[master_300.txt](https://github.com/dotnet/machinelearning/files/3687550/master_300.txt)\r\n'"
502229981,4285,b'[Model management] Save/Load Model into a Relational Database (SQL Server)',"b'From feedback from a customer using SQL Server Functions and Stored Procedures implemented in C#:\r\n\r\nBasically, would be good to have an API like the following:\r\n\r\n.SaveModelToDb()\r\n.LoadModelFromDb()\r\n\r\nThe reasons and scenarios are because you run C# code only as code running within SQL Server such as a C# SQL Server Function or a Stored Procedure that is scoring an ML.NET model while doing a query or transactions.\r\n\r\nAnd not just for scoring but also for saving the model after training close to the database.. and since it is a table you could also have multiple model versions..\r\n\r\nAnother scenario would be for traditional client/server apps with the client apps directly accessing a database...\r\n\r\nDoing it that way everything would be held, and more importantly, **secured** in the database server without external dependencies.\r\n'"
502053943,4281,b'after every execution recommendation result is continuously changes?',"b'@eerhardt - after every execution of following code for Periodofstay-""Mar-May"" and\r\ntraveler_type-""Families"",recommendation result i.e. Score continuously changes.we need constant result not every time change score.\r\n\r\n var options = new Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer.Options\r\n                        {\r\n                            // MatrixColumnIndexColumnName = ""userIdEncoded"",\r\n                            // MatrixRowIndexColumnName = ""movieIdEncoded"",\r\n                            FeatureColumnName = ""Features"",\r\n\r\n                            NormalizeFeatures = false,\r\n                            LabelColumnName =""Label"",// labelColumnName,\r\n                            LambdaLatent = 0.01f,\r\n                            LambdaLinear = 0.001f,\r\n                            LatentDimension = 16,\r\n                            NumberOfIterations = 20,\r\n                            LearningRate = 0.5f\r\n\r\n                            // ApproximationRank = 100\r\n                        };\r\n\r\n\r\n                        //  context.ml.Trainers.MatrixFactorization(options);\r\n\r\n\r\n                        // columnNames, columnTypes\r\n                        IEstimator<ITransformer> datapipeLine = context.Transforms.CopyColumns(\r\n                                       inputColumnName: labelColumnName,\r\n                                       outputColumnName: ""Label"");\r\n                        //                context.Transforms.Categorical.OneHotEncoding(""TravelerTypeOneHot"", ""TravelerType"")\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(""HotelOneHot"", ""Hotel""))\r\n                        //.Append(context.Transforms.Concatenate(""Features"", ""TravelerTypeOneHot"", ""HotelOneHot""))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { ""Features"" }));\r\n\r\n\r\n\r\n\r\n                        List<string> featuresColumns = new List<string>();\r\n\r\n                        for (int index = 0; index < columnNames.Count; ++index)\r\n                        {\r\n\r\n                            if (columnNames[index] == labelColumnName|| columnNames[index]==""Time""|| columnNames[index]==""TimeStamp""|| columnNames[index]== ""IdPreservationColumn"")\r\n                                continue;\r\n\r\n\r\n                            Type type = columnTypes[index];\r\n\r\n                            if (type == typeof(string) || type == typeof(char) || type == typeof(byte[]) || type == typeof(bool))\r\n                            {\r\n\r\n                                if (datapipeLine == null)\r\n                                {\r\n\r\n                                    datapipeLine = context.Transforms.Categorical.OneHotEncoding(columnNames[index] + ""OneHot"", columnNames[index]);//""TravelerType""\r\n\r\n\r\n                                }\r\n                                else\r\n                                {\r\n                                    datapipeLine = datapipeLine.Append(context.Transforms.Categorical.OneHotEncoding(columnNames[index] + ""OneHot"", columnNames[index]));//""TravelerType""\r\n\r\n                                }\r\n\r\n                                featuresColumns.Add(columnNames[index] + ""OneHot"");\r\n                            }\r\n                            else\r\n                            {\r\n                                featuresColumns.Add(columnNames[index]);\r\n\r\n                            }\r\n\r\n\r\n\r\n                        }\r\n\r\n\r\n                        datapipeLine = datapipeLine.Append(context.Transforms.Concatenate(""Features"", featuresColumns.ToArray()));\r\n                        datapipeLine = datapipeLine.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options));// new string[] { ""Features"" }, labelColumnName));\r\n\r\n                        //        foreach (string name in columnNames)\r\n                        //{\r\n                        //    if(columnTypes)\r\n                        //    pipeline = context.Transforms.Categorical.OneHotEncoding(""TravelerTypeOneHot"", ""TravelerType"")\r\n\r\n                        //}\r\n\r\n\r\n\r\n\r\n\r\n                        //var pipeline = context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options);\r\n\r\n                        //                    var pipeline = context.Transforms.Categorical.OneHotEncoding(""TravelerTypeOneHot"", ""Traveler_type"")\r\n                        ////.Append(context.Transforms.Categorical.OneHotEncoding(""SeasonOneHot"", ""Season""))\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(""HotelOneHot"", ""Hotel_name""))\r\n                        //.Append(context.Transforms.Concatenate(""Features"", ""TravelerTypeOneHot"", ""HotelOneHot""))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { ""Features"" },labelColumnName));\r\n\r\n\r\n                        //                    var _model = pipeline.Fit(trainData);\r\n\r\n                        //                    var _transformedTrainingData = _model.Transform(inputtestData);\r\n\r\n\r\n                        // Train the model.\r\n                        var model = datapipeLine.Fit(trainData);\r\n\r\n\r\n\r\n                        // Run the model on training or test data set.\r\n                        var transformedTrainingData = model.Transform(trainData);\r\n\r\n\r\n                        // Measure the quality of the trained model.\r\n                        // var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,);\r\n\r\n                        var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,""Label"" , ""Score"", ""Probability"", ""PredictedLabel"");//labelColumnName//Prediction Data send\r\n\r\n\r\n\r\n                        //  _predictionEngine = context.Model.pr(FfmRecommendationData, FfmRecommendationPrediction>(_model);\r\n\r\n\r\n                        var predictions2 = context.Data.CreateEnumerable<RecommendationResult>(transformedTrainingData, reuseRowObject: false).ToArray();\r\n\r\n\r\nI have attached data also.\r\n[hotelrecommandation.xlsx](https://github.com/dotnet/machinelearning/files/3686131/hotelrecommandation.xlsx)\r\n\r\n'"
502045120,4280,b'we are getting more thane one score in spam detection?',"b'@eerhardt - please see this code,\r\n\r\n var dataProcessPipeline = context.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n                                                  .Append(context.Transforms.Text.FeaturizeText(""FeaturesText"", new Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.Options\r\n                                                  {\r\n                                                      WordFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 2, UseAllLengths = true },\r\n                                                      CharFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 3, UseAllLengths = false },\r\n                                                  }, ""Message""))\r\n                                                  .Append(context.Transforms.CopyColumns(""Features"", ""FeaturesText""))\r\n                                                  .Append(context.Transforms.NormalizeLpNorm(""Features"", ""Features""))\r\n                                                  .AppendCacheCheckpoint(context);\r\n\r\n                        // Set the training algorithm \r\n                        var trainer = context.MulticlassClassification.Trainers.OneVersusAll(context.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: ""Label"", numberOfIterations: 10, featureColumnName: ""Features""), labelColumnName: ""Label"")\r\n                                                  .Append(context.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n                        var trainingPipeLine = dataProcessPipeline.Append(trainer);\r\n\r\n\r\n                        //Console.WriteLine(""=============== Cross-validating to get model\'s accuracy metrics ==============="");\r\n                        //var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(data: data, estimator: trainingPipeLine, numberOfFolds: 5);\r\n                        //ConsoleHelper.PrintMulticlassClassificationFoldsAverageMetrics(trainer.ToString(), crossValidationResults);\r\n\r\n                        // Now let\'s train a model on the full dataset to help us get better results\r\n                        var model = trainingPipeLine.Fit(trainData);\r\n\r\n\r\n                        IDataView predictions = model.Transform(trainData);\r\n\r\n\r\n                        List<SpamPrediction> predictedResults = context.Data.CreateEnumerable<SpamPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nwe attached data also. then which one score we consider?\r\n[spamdata.xlsx](https://github.com/dotnet/machinelearning/files/3686067/spamdata.xlsx)\r\n'"
501375399,4276,b'Issues with ImageClassificationTransformer',"b""- The Options class contains two string array fields: one for input column names and one for output column names. However, it always uses exactly two input columns: a label column and a features column, and it always outputs exactly two output columns: score and predicted label. This discrepancy should be addressed.\r\n- The transformer has a field called `_labelColumnName` that is serialized and deserialized and otherwise does nothing. Since after deserialization we cannot rely on having data that has a label column anyway, this field should be removed.\r\n- `GetOutputSchema()` in the estimator does not check that the type of the label column is correct (what other types, if any, should be allowed other than key type?), and neither does the constructor (it doesn't check the type of the features column either).\r\n- I think the constructor of the transformer should not have a boolean flag to indicate whether the transformer is being instantiated from file or from the estimator. Instead, the estimator should do the required training (including figuring out the class count), and there should be one constructor for the transformer, that is called both from the estimator's `Fit()` method, and from the transformer's `Create(ModelLoadContext)` method.\r\n- The estimator has a `_transformer` field that is not needed.\r\n- The transformer ctor has an unused argument: `batchSize` - don't know if the error is in not using it or in not needing it."""
501263651,4275,b'how we draw tree using fast tree algorithm?',"b'as per suggestion given by @eerhardt, following link to @ganik @codemzs or @yaeldekel \r\nhttps://github.com/dotnet/machinelearning/issues/4264\r\n@ganik -  i have prepared sample on this below link.\r\nthis is Visualize sickit-learn decision trees with d3.js\r\nhttp://bl.ocks.org/fractalytics/raw/495b63cf671b4c487bc40801366384e0/\r\n\r\nwe do not know python script but we know C#. so that please helps us to draw above tree using fasttree ml.net using score,weights,bias.\r\nif any sample is their please share with us.'"
501207590,4274,b'[Image Classification API] No evaluation when batchSize parameter > # of instances in dataset',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n- **ML.NET Version**: 1.4.0-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to train an image classification model using the Image Classification API. The value set for `batchSize` parameter is 300. Meanwhile then number of data instances in the test set is 182.\r\n\r\n- **What happened?**\r\n\r\nNo evaluation takes place. 0 batches are processed. \r\n\r\n- **What did you expect?**\r\n\r\nThe model to train and for it to evaluate the number of instances provided. In this case since the number of data instances is less than the amount set for the `batchSize` parameter, it would process 1 batch instead of 0.\r\n\r\nThe model to evaluate\r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar trainingPipeline =\r\n                mapLabelTransform\r\n               .Append(mlContext.Model.ImageClassification(\r\n                   featuresColumnName: ""ImagePath"",\r\n                   labelColumnName: ""LabelAsKey"",\r\n                   arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n                   epoch: 100,\r\n                   batchSize: 300,\r\n                   testOnTrainSet: false,\r\n                   metricsCallback: (metrics) => Console.WriteLine(metrics),\r\n                   validationSet: transformedTestData,\r\n                   reuseTrainSetBottleneckCachedValues: true,\r\n                   reuseValidationSetBottleneckCachedValues: true));\r\n```\r\n\r\nOutput:\r\n\r\n```text\r\nNumber of rows 182\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  93, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  94, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  95, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  96, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  97, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  98, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  99, Accuracy:        NaN\r\n```\r\n\r\nWhen the `batchSize` is set equal to the number of rows (in this case 182), this is the output:\r\n\r\n```text\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  95, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  96, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  97, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  98, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  99, Accuracy:          1\r\n```'"
501176332,4271,b'How to process image with 1 channel?',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**:\r\n.NET Core 3.0 \r\n\r\n### Issue\r\nI have a model that is trained in keras that accept a input shape of 64x64x1, in this case an image in gray scale. But I don\'t found a way of pre-process image to send only one channel to model, in ML.NET only have a method that extract one channel, R, G, B or Alpha.\r\n- **What did you do?**\r\n`var pipeline = mlContext.Transforms.ResizeImages(resizing: ImageResizingEstimator.ResizingKind.Fill, outputColumnName: onnxModel.ModelInput, imageWidth: ImageSettings.imageWidth,\r\n                imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n                .Append(mlContext.Transforms.ConvertToGrayscale(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput, interleavePixelColors: true, \r\n                orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Red))\r\n                .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: onnxModel.ModelPath, outputColumnName: onnxModel.ModelOutput, inputColumnName: onnxModel.ModelInput));`\r\n\r\nMy image come from a input form, like onnx examples in samples repository\r\n- **What happened?**\r\nI\'m getting incorrect prediction, because I don\'t know how to reshape image to 64x64x1, in case that I send 64x64x3 format, I\'m getting the error ""Length of memory (12288) must match product of dimensions (4096).""\r\n- **What did you expect?**\r\nI expect that ML.NET provide a way to reshape my image to one channel image to get correct predictions\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
501034241,4269,b'TensorFlow based DNN models do not support the GPU on windows.',b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n### Issue\r\n\r\nCurrently the DNN TensorFlow based models do not support GPU training/inferencing. \r\n\r\nDNNs should be able to support the GPU.\r\n'
500451878,4266,b'Evaluate PFI on raw features',"b'Right now, the [PFI implementation](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/PermutationFeatureImportance.cs), permutes and evaluates feature importances on the slots of the feature vector. However, I may want to evaluate PFI on the raw features (instead of or in addition to) the slots of the feature vector.\r\n\r\nConsider this scenario: PCA transform or a ""hash"" transform e.g. Text Transform with NGram Hash or Categorical Hash has been applied to raw features and the corresponding slots have no name or are unintelligible names. PFI on these slots isn\'t very ""explainable"" for these slots. Some sense of ""importance"" can still be had if the initial column could be permuted.\r\n\r\nIn addition, PFI operates on the numerical features that were passed to the trainer. When the original features in the dataset are categorical or strings, this means that the trainer sees the output of the one-hot encoding transformer, which adds multiple columns for each individual input column. It is not always useful for the user to get feature importance on each slot of the featurized column, and there should be an option to evaluate PFI on the initial input columns.\r\n\r\nSee also #4296 #3895 '"
499922532,4264,b'how we plot decision tree using fast tree Trainer?',b'@eerhardt -  we got score and metrics but how we plot decision tree using trainer.'
499746780,4263,b'Duplicate column name exception when adding an Ignored column to AutoML framework',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: core 3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAdd a column that AutoML should ignore.\r\n\r\n- **What happened?**\r\nGet an exception that the column name is duplicated.\r\n\r\n- **What did you expect?**\r\nWhen you add a column to the ignored collection you don\'t have to remove it from another collection (there are more than one) because the columns are inferred from the dataset at runtime.\r\n\r\n### Source code / logs\r\nColumnInformation columnInformation = columnInference.ColumnInformation;\r\ncolumnInformation.NumericColumnNames.Remove(""payment_type""); \r\ncolumnInformation.IgnoredColumnNames.Add(""payment_type"");\r\n'"
499523755,4259,b'[Image Classification API] metricsCallback NullReferenceException when using custom function',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n- **ML.NET Version**: 1.4.0-preview\r\n\r\n### Issue\r\n\r\nTried to provide a custom function for the `metricsCallback` parameter. The documentation in IntelliSense says this method is only called during the *Training* phase. However, it does not appear to be the case. If the *Bottleneck* phase has to happen (training for first time or not using cached bottleneck values), a `System.NullReferenceException` is raised.\r\n\r\n```text\r\nSystem.NullReferenceException: \'Object reference not set to an instance of an object.\'\r\n\r\ntrainMetrics was null.\r\n```\r\n\r\nI suspect this is because the same callback is used for both the Bottleneck / Training phases. It would be good to either:\r\n\r\na) Have separate callbacks depending on whether it\'s Bottleneck / Training phase.\r\nb) Allow the user to check which phase is currently taking place so they can display the results accordingly in their `metricsCallback` method.\r\n\r\nNote that once a model is trained and the *Bottleneck* phase no longer needs to happen since the cached values are being used, no Exceptions are raised and the application works as expected. \r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar trainingPipeline =\r\n    mapLabelTransform\r\n   .Append(mlContext.Model.ImageClassification(\r\n       ""ImagePath"",\r\n       ""LabelAsKey"",\r\n       arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n       epoch: 100,\r\n       batchSize: 20,\r\n       metricsCallback: DisplayMetrics,\r\n       validationSet: transformedTestData\r\n       //reuseTrainSetBottleneckCachedValues: true,\r\n       /*reuseValidationSetBottleneckCachedValues: true*/));\r\n```\r\n\r\nMetrics Callback Method:\r\n\r\n```csharp\r\npublic static void DisplayMetrics(ImageClassificationMetrics metrics)\r\n{\r\n    TrainMetrics trainMetrics = metrics.Train;\r\n    Console.WriteLine($""Epoch: {trainMetrics.Epoch} | Accuracy {trainMetrics.Accuracy} | Loss: {trainMetrics.CrossEntropy}"");\r\n}\r\n```'"
499450711,4257,b'What is the input format required by the LDA transform?',"b'Ideally I would like the output of ApplyWordEmbedding transform as input to LDA for topic modeling but apparently that is not the case.\r\n\r\nSo I am not sure how to format the input to LDA.\r\n\r\nDocumentation says it should be a vector of single - which it is with after applying the embedding transform but then I see an error message when running LDA:\r\n\r\nThe specified documents are all empty in column \'Features\'.\r\n\r\nWhere ""Features"" is the output of the embedding.\r\n\r\n'"
499357959,4256,b'Incorrect constructor parameter type specified',"b""Constructor parameter 'columns' should be of type IEnumerable&lt;SchemaShape.Column&gt; instead of IEnumerable&lt;SchemaShape&gt;\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 52902231-74e7-53a0-1974-ab96d7963da1\n* Version Independent ID: ebf148b4-3861-d68a-33ca-f12d59e6e3ee\n* Content: [SchemaShape Class (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.schemashape?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/SchemaShape.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/SchemaShape.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
499166449,4254,b'An Autoencoder Sample',"b'This might not be an issue but more like a request.\r\n\r\nIs there a way to do an autoencoder? If so, can there be an example to achieve this?'"
499094871,4252,b'Jupyter + ML.NET | DataFrame vs Dataview',"b""While working with ML.NET in Jupyter, it can sometimes feel like double work to have to load the data first in to a DataFrame, and then also in to a IDataView to be able to use it in e.g. a training pipeline.\r\n\r\nIt would be ideal if the `.Fit` and/or `TrainTestSplit` methods could take a DataFrame as a parameter, or if there was other interoperability methods to leverage, so that the data wouldn't need to be loaded in two places.\r\n\r\n"""
499028344,4251,b'Jupyter + ML.NET | Plotly',"b""This may not be the correct forum for this question, and if not, I'm happy to close it.\r\n\r\nPlotly created very large graphs, greatly slowing down the browser, especially compared to it's Python counterparts. I created a simple Scatter plot based on a dataset of 30 Mb, and Google Chrome almost completely came to a halt. I've created similar plots in Python equivalents for 500+ Mb of data with the browser running smoothly. \r\n\r\nThis means that XPlot.Plotly will not be a feasible option for any real-life datasets. Are there any other alternatives for the .NET community that we can recommend? Or should I reach out to Plotly to see if this is just a bug?"""
499021022,4250,b'Jupyter + ML.NET | DataFrame | Identical to Pandas or more C# like?',"b'The DataFrame class currently bears a lot of resembles with the Python equivalent of Pandas. \r\n\r\nAs I don\'t have any API documentation in front of me, it\'s difficult to know the answer to this, so I thought I would ask, are there any efforts to make it more ""C# like""?\r\n\r\nE.g., I would like to do the following for example:\r\n```\r\nvar allFraudulentRowsByTransactionDate = dataFrame.Where(x => x.IsFraud).OrderBy(y => y.TransactionDate);\r\n```\r\n\r\n**or** \r\n```\r\nvar first10Rows = dataFrame.Take(10);\r\nvar first10Percent = dataFrame.Take(dataFrame.Count() * 0.1);\r\n```\r\n**or** \r\n\r\n```\r\nvar amountColumnForOnlyFraudulentCases = dataFrame.Where(y => y.IsFraud).Select(x => x.Amount);\r\n```'"
498994622,4249,b'Jupyter + ML.NET | DataFrame | Create a ToOutputFormat() function to output HTML table',"b""Registering the format of a DataFrame is currently a large code block that takes away from the ML problem we're trying to solve in the Notebook. \r\n\r\nWhat about creating a ToString() or ToOutputFormat() method that outputs the default table format which I believe most people would like to have from start. """
497291598,4244,b'[AutoML] Extend use of AutoML inferrence workflow for non-experiment types',"b""I've got a desire here to use some of the transformer inference and other cool things from AutoML but obviously doesn't fit as an experiment without a proper estimator.  I've mocked up adding anomaly detection as an experiment base by faking the estimator.  Looks like too much of AutoML is internal for me to extend it like this.  Any thoughts on how I should go about achieving the same results?  Maybe I should setup a pull request to change the appropriate protection levels for the items needed to implement the experimentbase class?\r\n"""
497255848,4243,b'ML.NET support in Azure Machine Learning Service',"b""First of all, big thanks for the initial support of ML.NET in Jupyter Notebooks. It's a fantastic addition.\r\n\r\nBased on this, I'm wondering if, when and how it will be possible to install the .NET kernel in Azure Machine Learning Service to be able to take full advantage of the cloud?"""
497032201,4241,b'Exception in AutoML regression experiment',"b'Windows 10 v. 1809\r\n\r\nUpgraded From v.0.14 v. 0.15 and got ArgumentOutOfRangeException in CrossValSummaryRunner.suggestedPipelineRunDetail.\r\nBestResultUtil.GetIndexOfBestScore returns -1. \r\n\r\nCode works as expected in v.0.14. tried to upgrade to v.0.15 and v0.16 preview and both fail with the Exception.\r\n\r\n> System.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  Message=Index was out of range. Must be non-negative and less than the size of the collection.\r\nParameter name: index\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument argument, ExceptionResource resource)\r\n   at System.Collections.Generic.List`1.get_Item(Int32 index)\r\n   at System.Linq.Enumerable.ElementAt[TSource](IEnumerable`1 source, Int32 index)\r\n   at Microsoft.ML.AutoML.CrossValSummaryRunner`1.Run(SuggestedPipeline pipeline, DirectoryInfo modelDirectory, Int32 iterationNum) in C:\\Data\\Dev\\machinelearning\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\CrossValSummaryRunner.cs:line 74'"
496816763,4240,b'[AutoML] Not Really a Issue | Any plans to include on AUTO a way to insert/change initial weights or retrain a model?using a experiment?',"b'Auto dont have a way to retrain a existing model or use a pre existing set of weights as starting point.  Its a suggestion, not really a issue. I think this is a wanted feature not only by me :-)'"
496801320,4239,b'Consuming a simple ONNX model for text classification',"b'I\'m trying to consume a trained scikit learn model that was converted to ONNX. Attempting to load the model with:\r\n\r\n```c#\r\nvar pipeline = ctx.Transforms.ApplyOnnxModel(\r\n    new[] { ""label"", ""probabilities"" }, new[] { ""input"" }, ""test.onnx"");\r\n```\r\n\r\nResults in the following exception:\r\n\r\n> System.ArgumentOutOfRangeException: \'dim (Parameter \'Dimension { } in ONNX tensor cannot exceed the maximum of 32-bit signed integer.\')\r\n> Actual value was 0.\'\r\n> \r\n\r\n**Update:**\r\n\r\nSaving the model with `target_opset = 9` results in:\r\n\r\n> [ErrorCode:Fail] Load model from ..\\..\\..\\..\\..\\Data\\MLModel\\test.onnx failed:Fatal error: StringNormalizer is not a registered function/op\r\n\r\n\r\n**Model creation in python:**\r\n\r\n```python\r\nimport os\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.svm import LinearSVC\r\nfrom skl2onnx import convert_sklearn\r\nfrom skl2onnx.common.data_types import StringTensorType\r\nimport pandas as pd\r\nfrom onnxmltools import save_model\r\n\r\ndata = pd.read_csv(\'training_data.csv\', sep=\'\\t\')\r\n\r\npipeline = Pipeline([\r\n  (\'tfidf\', TfidfVectorizer()),\r\n  (\'clf\', LinearSVC()),\r\n])\r\n\r\npipeline.fit(data[""Keywords""], data[""Label""])\r\n\r\nonnx = convert_sklearn(pipeline, name=\'test_predictor\',\r\n  initial_types=[(\'input\', StringTensorType([1, 1]))])\r\n\r\nsave_model(onnx, ""test.onnx"")\r\n\r\n```\r\n\r\n**Netron:**\r\n\r\n![image](https://user-images.githubusercontent.com/51688/65391096-6fe19180-dd65-11e9-965a-3eab334533a6.png)\r\n'"
496657603,4238,b'How to Draw Auto ML Statisctics Graph using XPlot.Plotly library in c#',b'Hi \r\n\r\nWe are using AutoML tool\r\n\r\nAs we got statistics of binary classification of\r\n\r\nAUC\r\nConfusion Matrix\r\nRoc\r\n\r\nHow we can draw the graph based on Matrix by using XPlot.plotly library in C#\r\n\r\nwe are not found any example in github in ML.net repository\r\n\r\nPlease provide sample\r\n\r\n'
496561537,4236,b'Need Early Stopping feature in Image Classification ',b'### Issue\r\nNeed the Early stopping feature in ML .NET so that number of epochs do not need to be set/predefined for Image Classification training.\r\nSaid feature available as a Keras callback: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n\r\n'
496504070,4235,b'Support for OpenAI Gym?',"b""I'm wondering if it'll be possible to have native support for OpenAI gym directly from ML.NET?\r\n"""
496483608,4234,b'[Image Classification API] TensorFlow exception triggered: input ended unexpectedly in the middle of a field',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to train an image classification DNN model using the Image Classification API on the [Intel Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification) dataset.\r\n\r\n- **What happened?**\r\n\r\nThe following exception was raised\r\n\r\n```text\r\nWhile parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nThe model to train.\r\n\r\n### Source code / logs\r\n\r\n#### Source Code\r\n\r\n```csharp\r\npublic static IEnumerable<ImageInput> LoadImagesFromDirectory(string folder, bool useFolderNameasLabel = true)\r\n{\r\n    var files = Directory.GetFiles(folder, ""*"",\r\n        searchOption: SearchOption.AllDirectories);\r\n\r\n    foreach (var file in files)\r\n    {\r\n        if ((Path.GetExtension(file) != "".jpg"") && (Path.GetExtension(file) != "".png""))\r\n            continue;\r\n\r\n        var label = Path.GetFileName(file);\r\n        if (useFolderNameasLabel)\r\n            label = Directory.GetParent(file).Name;\r\n        else\r\n        {\r\n            for (int index = 0; index < label.Length; index++)\r\n            {\r\n                if (!char.IsLetter(label[index]))\r\n                {\r\n                    label = label.Substring(0, index);\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n\r\n        yield return new ImageInput()\r\n        {\r\n            ImagePath = file,\r\n            Label = label\r\n        };\r\n\r\n    }\r\n}\r\n```\r\n\r\n```csharp\r\nMLContext mlContext = new MLContext();\r\n\r\nIEnumerable<ImageInput> train = LoadImagesFromDirectory(trainRelativePath, true).Take(10).ToArray();\r\nIEnumerable<ImageInput> test = LoadImagesFromDirectory(testRelativePath, true).Take(10).ToArray();\r\n\r\nIDataView trainSet = mlContext.Data.LoadFromEnumerable(train);\r\nIDataView testSet = mlContext.Data.LoadFromEnumerable(test);\r\n\r\nvar mapLabelTransform = mlContext.Transforms.Conversion.MapValueToKey\r\n  (outputColumnName: ""LabelAsKey"",\r\n   inputColumnName: ""Label"",\r\n   keyOrdinality: ValueToKeyMappingEstimator.KeyOrdinality.ByValue);\r\n\r\nvar trainingPipeline = \r\n    mapLabelTransform\r\n   .Append(mlContext.Model.ImageClassification(\r\n       ""ImagePath"",\r\n       ""LabelAsKey"",\r\n       arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n       epoch: 100,\r\n       batchSize: 150,\r\n       metricsCallback: (metrics) => Console.WriteLine(metrics)));\r\n\r\nITransformer trainedModel = trainingPipeline.Fit(trainSet);\r\n```\r\n\r\n#### Logs\r\n\r\n```text\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Tensorflow exception triggered while loading model.\r\n  Source=Microsoft.ML.Dnn\r\n  StackTrace:\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.DnnCatalog.ImageClassification(ModelOperationsCatalog catalog, String featuresColumnName, String labelColumnName, String scoreColumnName, String predictedLabelColumnName, Architecture arch, Int32 epoch, Int32 batchSize, Single learningRate, ImageClassificationMetricsCallback metricsCallback, Int32 statisticFrequency, DnnFramework framework, String modelSavePath, String finalModelPrefix, IDataView validationSet, Boolean testOnTrainSet, Boolean reuseTrainSetBottleneckCachedValues, Boolean reuseValidationSetBottleneckCachedValues, String trainSetBottleneckCachedValuesFilePath, String validationSetBottleneckCachedValuesFilePath)\r\n   at ImageClassificationAPIMLNETSample.Program.Main(String[] args) in C:\\Users\\luquinta.REDMOND\\source\\repos\\ImageClassificationAPIMLNETSample\\ImageClassificationAPIMLNETSample\\Program.cs:line 59\r\n\r\nInner Exception 1:\r\nInvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n```\r\n\r\nAdditional output to the console:\r\n\r\n```text\r\nGoogle.Protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n   at Google.Protobuf.CodedInputStream.RefillBuffer(Boolean mustSucceed)\r\n   at Google.Protobuf.CodedInputStream.ReadRawBytes(Int32 size)\r\n   at Google.Protobuf.CodedInputStream.ReadBytes()\r\n   at Tensorflow.TensorProto.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Tensorflow.AttrValue.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.FieldCodec.<>c__DisplayClass16_0`1.<ForMessage>b__0(CodedInputStream input)\r\n   at Google.Protobuf.Collections.MapField`2.Codec.MessageAdapter.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.Collections.MapField`2.AddEntriesFrom(CodedInputStream input, Codec codec)\r\n   at Tensorflow.NodeDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.FieldCodec.<>c__DisplayClass16_0`1.<ForMessage>b__0(CodedInputStream input)\r\n   at Google.Protobuf.Collections.RepeatedField`1.AddEntriesFrom(CodedInputStream input, FieldCodec`1 codec)\r\n   at Tensorflow.GraphDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Tensorflow.MetaGraphDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.MessageExtensions.MergeFrom(IMessage message, Byte[] data)\r\n   at Google.Protobuf.MessageParser`1.ParseFrom(Byte[] data)\r\n   at Tensorflow.saver._import_meta_graph_with_return_elements(String meta_graph_or_file, Boolean clear_devices, String import_scope, String[] return_elements)\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.<>c__DisplayClass5_0.<LoadMetaGraph>b__0(Graph graph)\r\n   at Tensorflow.Python.tf_with[TIn,TOut](TIn py, Func`2 action)\r\n```'"
496250715,4233,b'AutoML Fails due to FastTree GetProcessInformation UWP',"b'### Issue\r\n\r\n- **What did you do?**\r\nI used AutoML for a Forecast problem in an UWP App. newest version of ML.NET. Letting the training run for more than 2 Minutes. Even when trying to not include trainers named ""*Tree*"" in the ""RegressionExperimentSettings"" it still arises. No idea why it would try to get ProcessInformation. Can you please remove that ""GetProcessInfos"" from FastTree?\r\n\r\n- **What happened?**\r\nThis Exception arises: \r\n\r\n ```\r\n  at System.Diagnostics.NtProcessInfoHelper.GetProcessInfos(Predicate`1 processIdFilter)\r\n   at System.Diagnostics.ProcessManager.GetProcessInfo(Int32 processId, String machineName)\r\n   at System.Diagnostics.Process.EnsureState(State state)\r\n   at Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3.PrintMemoryStats(IChannel ch)\r\n   at Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3.TrainCore(IChannel ch)\r\n   at Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerWhitelist)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.ExecuteCrossValSummary(IDataView[] trainDatasets, ColumnInformation columnInfo, IDataView[] validationDatasets, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, String labelColumnName, String samplingKeyColumn, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at MLAtHome.Helpers.AutoMLHelper.<BuildTrainEvaluateAndSaveModel>d__8.MoveNext() in C:\\Users\\caasen\\source\\repos\\MLAtHome\\MLAtHome\\Helpers\\AutoMLHelper.cs:line 70\r\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n[...]\r\n```\r\n\r\n### Source code / logs\r\n\r\n```\r\n//Excluding ""FastTree"" here in the settings\r\n     RegressionExperiment experiment=  mlContext.Auto().CreateRegressionExperiment(experimentSettings);\r\n            \r\n            ExperimentResult<RegressionMetrics> experimentResult = experiment.Execute(myview, Statics.CurrentModel.LabelName, progressHandler: progressHandler);\r\n```\r\n'"
496077025,4231,b'Add Entry Point for Permutation Feature Importance',b'Needed to add PFI to NimbusML.\r\n\r\nmicrosoft/NimbusML#92'
495504223,4230,b'Error when retraining model',"b'### System information\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.0.100-preview8-013656\\\r\n\r\nHost (useful for support):\r\n  Version: 3.0.0-preview8-28405-07\r\n  Commit:  d01b2fb7bc\r\n\r\n.NET Core SDKs installed:\r\n  2.2.101 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.100-alpha1-009632 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.100-preview8-013656 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempted to retrain a linear regression model built in ML.NET\r\n- **What happened?**\r\nReceived the below error:\r\n```\r\nOptimizer unable to proceed with loss function yielding Infinity\r\n```\r\n\r\n### Source code / logs\r\nError occurred on the below code:\r\n```\r\nvar retrainedModel = context.Regression.Trainers.LbfgsPoissonRegression()\r\n                .Fit(newDataTransformed, originalModelParams);\r\n```\r\n\r\nFull code sample is [here](https://github.com/jwood803/MLNetExamples/blob/master/MLNetExamples/RetrainModel/Program.cs).\r\n'"
495298128,4227,"b'Using PFI with AutoML, possible?'","b"" I have a trained model and now trying to retrieve the feature weights. None of the objects returned expose a LastTransformer then I want to get the PFI information and I get stuck. There appears no way to get the LastTransformer object from the trainedModel.\r\n\r\nThe following cast lets me access the LastTransformer, however I cannot use it for PFI until I provide a better type for predictor. Debugging I can see it is of type Microsoft.ML.Data.RegressionPredictionTransformer<Microsoft.ML.IPredictorProducing> but I am unable to cast to that because Microsoft.ML.IPredictorProducing is not visible, so it seems like we're still stuck.\r\n\r\n//setup code similar to famschopman\r\nRegressionExperiment experiment = mlContext.Auto().CreateRegressionExperiment(experimentSettings);\r\n\r\nvar experimentResults = experiment.Execute(split.TrainSet, split.TestSet);\r\nvar predictor = ((TransformerChain)experimentResults.BestRun.Model).LastTransformer;\r\n\r\n//this will not compile.\r\nvar permutationMetrics = mlContext.Regression.PermutationFeatureImportance(predictor, transformedData, permutationCount: 30);\r\n\r\nThe following compile error is produced.\r\n\r\nThe type arguments for method 'PermutationFeatureImportanceExtensions.PermutationFeatureImportance(RegressionCatalog, ISingleFeaturePredictionTransformer, IDataView, string, bool, int?, int)' cannot be inferred from the usage. Try specifying the type arguments explicitly.\r\n\r\nhow we get bias and weight using PFI?"""
494878674,4226,b'`predictionEngine` breaks after saving/loading a Model',"b'### System information\r\n\r\n- **win 10**:\r\n- **1.3.1**: \r\n\r\nI was trying to create a PredictEngine using a saved model. I found out that if I directly use the `ITransformer` retrieve from `Pipeline.Fit`, the `CreatePredictionEngine` works well. But after I save/reload it, then it will give the following error\r\n![image](https://user-images.githubusercontent.com/16876986/65083420-5c958700-d95d-11e9-9b98-d4bf3d93736b.png)\r\n\r\nThe code for the pipeline is like this\r\n\r\n```\r\npublic static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)\r\n        {\r\n            // Data process configuration with pipeline data transformations \r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n                                      .Append(mlContext.Transforms.LoadImages(""ImagePath_featurized"", @""C:\\Users\\xiaoyuz\\Desktop\\machinelearning-samples\\datasets\\images"", ""ImagePath""))\r\n                                      .Append(mlContext.Transforms.ResizeImages(""ImagePath_featurized"", 224, 224, ""ImagePath_featurized""))\r\n                                      .Append(mlContext.Transforms.ExtractPixels(""ImagePath_featurized"", ""ImagePath_featurized""))\r\n                                      .Append(mlContext.Transforms.DnnFeaturizeImage(""ImagePath_featurized"", m => m.ModelSelector.ResNet18(mlContext, m.OutputColumn, m.InputColumn), ""ImagePath_featurized""))\r\n                                      .Append(mlContext.Transforms.Concatenate(""Features"", new[] { ""ImagePath_featurized"" }))\r\n                                      .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""))\r\n                                      .AppendCacheCheckpoint(mlContext);\r\n            // Set the training algorithm \r\n            var trainer = mlContext.MulticlassClassification.Trainers.OneVersusAll(mlContext.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: ""Label"", numberOfIterations: 10, featureColumnName: ""Features""), labelColumnName: ""Label"")\r\n                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            return trainingPipeline;\r\n        }\r\n```\r\n\r\nAnd `ModelInput` and `ModelOutput` class is like this\r\n```\r\n    public class ModelInput\r\n    {\r\n        [ColumnName(""Label""), LoadColumn(0)]\r\n        public string Label { get; set; }\r\n\r\n\r\n        [ColumnName(""Title""), LoadColumn(1)]\r\n        public string Title { get; set; }\r\n\r\n\r\n        [ColumnName(""Url""), LoadColumn(2)]\r\n        public string Url { get; set; }\r\n\r\n\r\n        [ColumnName(""ImagePath""), LoadColumn(3)]\r\n        public string ImagePath { get; set; }\r\n\r\n\r\n    }\r\n```\r\n\r\n```\r\npublic class ModelOutput\r\n    {\r\n        // ColumnName attribute is used to change the column name from\r\n        // its default value, which is the name of the field.\r\n        [ColumnName(""PredictedLabel"")]\r\n        public String Prediction { get; set; }\r\n        public float[] Score { get; set; }\r\n    }\r\n```\r\n\r\nIt\'s really wield though. And my description may not be that detailed. If you need further information, please let me know\r\n'"
494867997,4225,b'Porting scikit-learn text classification pipeline to ML.Net',"b""I'm trying to port the below scikit-learn pipeline to ML.Net and I have trouble with the `TruncatedSVD` transformer. Is there an equivalent for it in ML.Net and if not, would it be possible to just consume a pre-trained ONNX model?\r\n\r\n```python\r\nfrom sklearn.pipeline import Pipeline, FeatureUnion\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.decomposition import TruncatedSVD\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom xgboost import XGBClassifier\r\n\r\nclassifier = Pipeline([\r\n    ('features', FeatureUnion([\r\n        ('text', Pipeline([\r\n            ('colext', TextSelector('Text')),\r\n            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\r\n                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\r\n            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\r\n        ])),\r\n        ('words', Pipeline([\r\n            ('wordext', NumberSelector('TotalWords')),\r\n            ('wscaler', StandardScaler()),\r\n        ])),\r\n    ])),\r\n    ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\r\n    ])\r\n```"""
494827761,4224,b'Ignored columns appear in InputModel from CodeGenerator',"b'### System information\r\n\r\n- **OS version/distro**: Any\r\n- **.NET Version (eg., dotnet --info)**:  Any\r\n\r\n### Issue\r\nWhen the user specifies ignored columns for CodeGenerator, they should not appear in the InputModel (or PredictProgram output). If the user uses the generated code to train the model again, they will have a different input set and generated model than the first training session.'"
494733076,4222,b'Predict multiple rows',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100-preview9-014004\r\n\r\n### Issue\r\n\r\n- **What did you do?** Trained a simple K-Means model\r\n- **What happened?** I wanted to predict multiple rows, but `Predict` only takes 1 instance\r\n- **What did you expect?** An overload that gives this possiblity\r\n\r\n### Source code / logs\r\n\r\n```csharp\r\nvar pipeline = ...;\r\nvar model = pipeline.Fit(data);\r\nvar predictor = mlContext.Model.CreatePredictionEngine<PixelEntry, ClusterPrediction>(model);\r\n```\r\n'"
494510005,4221,b'ML.Net Source not building when build.cmd is executed',"b'### System information\r\n\r\n- **OS version/distro**:Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.0 Preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRun Build.cmd\r\n- **What happened?**\r\nD:\\SCM\\machinelearning\\src\\Native>build.cmd\r\n**********************************************************************\r\n** Visual Studio 2019 Developer Command Prompt v16.2.2\r\n** Copyright (c) 2019 Microsoft Corporation\r\n**********************************************************************\r\n[vcvarsall.bat] Environment initialized for: \'x86_x64\'\r\nCommencing native build of dotnet/machinelearning\r\n\r\nCalling ""D:\\SCM\\machinelearning\\src\\Native\\\\gen-buildsys-win.bat"" ""D:\\SCM\\machinelearning\\src\\Native\\"" ""16 2019"" x64\r\nCMake Error: The source directory ""D:/SCM/machinelearning/bin/obj/x64.Debug/Native/2019  -A x64 -B./ -HD:/SCM/machinelearning/src/Native"""" does not exist.\r\nSpecify --help for usage, or press the help button on the CMake GUI.\r\nFailed to generate native component build project!\r\n- **What did you expect?**\r\nSuccessful completion of build\r\n\r\n### Source code / log\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
494283836,4218,b'CopyColumns does not support saving to Onnx',"b""- **What did you do?**\r\nCreated a pipeline from with CopyColumns and tried to export it to Onnx with ConvertToOnnxProtobuf.\r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n"""
493955684,4217,b'exampleWeightColumn with separate weights for each feature',"b'Hi\r\n\r\nI have a model with 2 features. In my data, each of these features is a measurement with an uncertainty associated to it. I was hoping to be able to set the weights column so that each feature has its own weight based on the uncertainty, but it does not seem possible, since only 1 weight per data point is allowed. Is this something that could be possibly implemented?  \r\n'"
493792406,4216,b'PFI (Permutation Feature Importance) API needs to be simpler to use',"b'PFI (Permutation Feature Importance) API needs to be simpler to use\r\n\r\n**1. First**, it is awkward to need to access to the LastTransformer method from the model (Chain of Transformers). In addition, if you are using additional methods to structure your training, evaluation and PFI calculation and try to pass the model as an ITransformer (the usual way) you need to cast it back to the concrete type of transformer chain (such as `TransformerChain<RegressionPredictionTransformer<LightGbmRegressionModelParameters>>`), which then requires a hard reference to the type of algorithm used. \r\n\r\nThis is the code to calculate the PFI metrics:\r\n\r\n```\r\n// Make predictions (Transform the dataset)\r\nIDataView transformedData = trainedModel.Transform(trainingDataView);\r\n\r\n// Extract the trainer (last transformer in the model)\r\nvar singleLightGbmModel = (trainedModel as TransformerChain<RegressionPredictionTransformer<LightGbmRegressionModelParameters>>).LastTransformer;\r\n\r\n// or simpler if the trainedModel was \'var\' right after the call to Fit(): \r\n// var singleLightGbmModel = trainedModel.LastTransformer;\r\n\r\n//Calculate Feature Permutation\r\nImmutableArray<RegressionMetricsStatistics> permutationMetrics =\r\n                                mlContext\r\n                                    .Regression.PermutationFeatureImportance(predictionTransformer: singleLightGbmModel,\r\n                                                                                data: transformedData,\r\n                                                                                labelColumnName: ""fare_amount"",  \r\n                                                                                numberOfExamplesToUse: 100,\r\n                                                                                permutationCount: 1);\r\n```\r\n\r\nNeeding to only use/provide the last transformer feels a bit convoluted... \r\nThe API should be simpler to use here and make such a thing transparent to the user?\r\n\r\n**2. Second,** once you get the permutation metrics (such as `ImmutableArray<RegressionMetricsStatistics> permutationMetrics`), you only get the values based on the indexes, but you don\'t have the names of the input columns. It is then not straightforward to correlate it to the input column names since you need to use the indexes to be used across two separated arrays that , if sorted previously, it won\'t match...\r\n\r\nYou need to do something like the following or comparable loops driven by the indexes in the permutationMetrics array:\r\n\r\nFirst, obtain all the column names used in the PFI process and exclude the ones not used:\r\n\r\n```\r\nvar usedColumnNamesInPFI = dataView.Schema\r\n                    .Where(col => (col.Name != ""SamplingKeyColumn"") && (col.Name != ""Features"") && (col.Name != ""Score""))\r\n                    .Select(col => col.Name);\r\n```\r\n\r\nThen you need to correlate and find the column names based on the indexes in the permutationMetrics:\r\n\r\n```\r\n            var results = usedColumnNamesInPFI\r\n                .Select((t, i) => new FeatureImportance\r\n                {\r\n                    Name = t,\r\n                    RSquaredMean = Math.Abs(permutationMetrics[i].RSquared.Mean)\r\n                })\r\n                .OrderByDescending(x => x.RSquaredMean);\r\n```\r\n\r\nThis should be directly provided by the API and you\'d simply need to access it and show it.\r\nThe current code feels very much convoluted...\r\n'"
493438608,4213,b'Error when trying to execute a sample test - MLNET-CLI',"b""### System information\r\n\r\nSDK do .NET Core (refletindo qualquer global.json):\r\n Version:   2.1.508\r\n Commit:    9ba8583e91\r\n\r\nAmbiente de tempo de execu\xc3\xa7\xc3\xa3o:\r\n OS Name:     Windows\r\n OS Version:  10.0.18362\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.508\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.12\r\n  Commit:  ccea2e606d\r\n\r\n.NET Core SDKs installed:\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.508 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\nI tried to execute one sample using MLNET-CLI\r\n`mlnet auto-train --task regression --dataset taxi-fare-train.csv --test-dataset taxi-fare-test.csv --label-column-name fare_amount --max-exploration-time 1000`\r\n\r\nreturns a error:\r\n```\r\nBest quality(RSquared): 0,9440, Best Algorithm: LightGbmRegression, Last Algorithm: FastTreeTweedieRegression\r\n00:01:37 Exception occured while exploring pipelines:\r\nAll instances skipped due to missing features.\r\nPlease see the log file for more info.\r\n```\r\n\r\n### Source code / logs\r\nLog: \r\n[debug_log.txt](https://github.com/dotnet/machinelearning/files/3611149/debug_log.txt)\r\n\r\nDatasets: \r\n[teste.zip](https://github.com/dotnet/machinelearning/files/3611150/teste.zip)\r\n\r\n#Update\r\nI've also tryied using single datasets:\r\n\r\ncommands used:\r\n`mlnet auto-train --task regression --dataset taxi-fare-test.csv --label-column-name fare_amount --max-exploration-time 1000`\r\n\r\n`mlnet auto-train --task regression --dataset taxi-fare-train.csv --label-column-name fare_amount --max-exploration-time 1000`\r\n\r\nlogs:\r\n\r\n[train_dataset_debug_log.txt](https://github.com/dotnet/machinelearning/files/3611873/train_dataset_debug_log.txt)\r\n[test_dataset_debug_log.txt](https://github.com/dotnet/machinelearning/files/3611874/test_dataset_debug_log.txt)\r\n"""
493060897,4210,b'TensorFlow scoring sample should pass an empty dataview',"b'This sample is calling Fit() with a dataview generated from one sample: https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/TensorFlow/TextClassification.cs\r\n\r\nThe pipeline contains a pre-trained TensorFlow model, so there is not need (and is misleading) to call Fit with data.\r\n\r\nIn other places where no dataview is required, we generate an empty one.\r\n\r\nRelated to #3795 \r\n'"
492921853,4209,b'ImageType needs to be savable',b'ImageType does not implement codecs for saving/reading. Implement them so that image type can be used in model schemas for saving/loading models.'
492761084,4208,b'Question: Roadmap for JupyterNotebook + ML.NET',"b""This is a question/enhancement suggestion.\r\n\r\nAs there is now support for transfer learning of DNN's, that means training has become a lot more computational expensive. This may push users to have to provision a VM in Azure or other to be able to train their deep neural networks. \r\n\r\n**Question**: How does the road map look for adding support for ML.NET in a Jupyter Notebook? \r\nI know there is a C# kernel available to install, is it possible to use that in Azure Machine Learning Service? It would be neat to be able to run ML.NET in a Jupyter Notebook as we then can quickly provision a compute resource required. That would also open up the path to additional summary statistics and plotting etc. \r\n\r\n**If** Jupyter Notebooks are not in the plans, are there plans of creating a VM image or suggest other ways of training a deep neural network in ML.NET in the cloud, in case a user does not have a strong enough computer locally?"""
492758774,4207,b'Summary Statistics',"b""It would be great to have the possibility to add a data exploration API to quickly get a feel of the data, e.g.\r\n\r\n- Shape of the date\r\n- Do we have NaNs etc.\r\n- How balanced is the data?\r\n\r\nThis can certainly be done through LinQ queries on the IDataView I'm sure, but would be cool to wrap some common methods as an extension method on the IDataView"""
492757889,4206,b'Graphs/Plots of Evaluation Metrics',b'It would be beneficial to have some kind of plotting mechanism of sorts to display evaluation metrics after training.\r\n\r\n- Confusion matrix\r\n- ROC graph\r\n- Precision-recall graph\r\n\r\nIt would also be neat to have a default ToString() method to output the metrics object to the console.'
492480232,4204,b'Need to move from TF.NET version 0.10.10 to 0.11.3',"b'\r\n- ML.Net currently runs with Tensorflow.Net version 0.10.10, but there is a newer stable version of Tensorflow.Net 0.11.3 with improvements :https://www.nuget.org/packages/TensorFlow.NET/0.11.3\r\n- **What happened?**\r\nThere are build errors with TF.Net 0.11.3\r\n- **What did you expect?**\r\nNeed the required API changes to make ML.Net compatible with TF.Net 0.11.3\r\n'"
492467529,4203,b'App Store',"b'Hello, I\'m wondering if there\'s any intention of ML.NET working in Microsoft app store apps. I\'m getting this error message when I run the App Cert Kit.\r\n\r\nI believe that these DLLs have to do with ML.NET because the error goes away when I don\'t use ML.NET.  Thanks.\r\n\r\n      <MESSAGES>\r\n          <MESSAGE TEXT=""File C:\\Program Files\\WindowsApps\\AppName\\CpuMathNative.dll has failed the AppContainerCheck check."" />\r\n          <MESSAGE TEXT=""File C:\\Program Files\\WindowsApps\\AppName\\LdaNative.dll has failed the AppContainerCheck check."" />\r\n        </MESSAGES>\r\n'"
492461153,4202,b'RankingEvaluatorOptions has OutputGroupSummary as an internal field',b'- **What happened?**\r\nThe OutputGroupSummary field of RankingEvaluatorOptions is marked as an internal field and and related RankingMetrics class does not include data resulting from turning on that option. \r\n\r\n- **What did you expect?**\r\nRankingMetrics should include the data from OutputGroupSummary and the options should support turning on that option.'
492093533,4201,"b""InvalidOperationException: Invalid TValue in GetGetter: 'Microsoft.ML.Data.VBuffer`1[System.Single]'""","b""### System information\r\n\r\n- Windows 10:\r\n- netcoreapp 2.2\r\n \r\n### Packages\r\nMicrosoft.ML 1.4.0-preview\r\nMicrosoft.ML.OnnxRuntime 0.5.0\r\nMicrosoft.ML.OnnxTransformer 1.4.0-preview\r\n\r\n### Issue\r\n\r\n- Used onnx model to create a prediction engine.\r\n- I get an exception when creating the prediction engine: InvalidOperationException: Invalid TValue in GetGetter: 'Microsoft.ML.Data.VBuffer`1[System.Single]'\r\n- I was expecting it to work everything looks right, the exception doesn't make it clear what's actually wrong. I could not debug the source code because it's inside a lambda function. \r\n\r\n### Source Code: \r\nhttps://github.com/GerjanVlot/BERT-ML.NET\r\n\r\n### Callstack:\r\n```\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.GenerateSetter(DataViewRow input, Int32 index, Column column, Delegate poke, Delegate peek)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase..ctor(TypedCursorable`1 parent, DataViewRow input, String channelMessage)\r\n   at Microsoft.ML.Data.TypedCursorable`1.GetRow(DataViewRow input)\r\n   at Microsoft.ML.PredictionEngineBase`2.PredictionEngineCore(IHostEnvironment env, InputRow`1 inputRow, IRowToRowMapper mapper, Boolean ignoreMissingColumns, SchemaDefinition outputSchemaDefinition, Action& disposer, IRowReadableAs`1& outputRow)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at ML.BERT.TestApp.Onnx.OnnxModelConfigurator`1.GetMlNetPredictionEngine[T]() in ML.BERT.TestApp\\Onnx\\OnnxModelConfigurator.cs:line 34\r\n   at ML.BERT.TestApp.Program.Main(String[] args) in ML.BERT.TestApp\\Program.cs:line 22\r\n```\r\n"""
491868237,4200,b'[DNN Image Classification] Add the LoadFromDirectory() as convenient API',"b'We actually have a convenient _custom_ method named LoadFromDirectory() in sample apps which loads the images in a folder with one sub-folder per class (image type) so it is very straight forward for users to create/load the images with their related labels into a DataSet. See sample here:\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/DeepLearning_ImageClassification_Training/ImageClassification.Train/Program.cs#L129 \r\n\r\nThis method should work integrated with the upcoming approach that images themselves need also to be loaded as in-memory objects into a DataView, so the pipeline will train with in-memory images and when scoring with the generated model and using a PredictionEngine the user will also be able to classify an in-memory image. \r\n\r\nUser\'s feedback:\r\n\r\n_""A couple of methods such as LoadFromDirectory are so useful that they may actually be candidates to include in the framework. I actually have a specific use case, with the same approach, where I don\'t supply meta-data but use the folder structure for labels instead""_'"
491818341,4199,b'How to handle columns with mix DateTime and numeric values',"b'### System information\r\n\r\n- **OS version/distro**: .Net 4.6\r\n- **.NET Version (eg., dotnet --info)**:  ML.Net 1.1.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** We have a column with mix DateTime and numeric values\r\n- **What happened?**  The [PrimitiveDataViewType](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.primitivedataviewtype?view=ml-dotnet) does not have a type to specify our column type \r\n- **What did you expect?** Have a way to represent both `DateTime` and numeric values with a dateView type, most like a primitive data type.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nWe want to have a DataViewType to represent a column with a mix of DateTime and numeric types.\r\n             '"
491527109,4198,b'Process memory limit when using Scda trainer with regression task?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: .NET Core SDK (reflecting any global.json):\r\n Version:   2.2.401\r\n Commit:    729b316c13\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.401\\\r\n\r\nHost (useful for support):\r\n  Version: 2.2.6\r\n  Commit:  7dac9b1b51\r\n\r\n.NET Core SDKs installed:\r\n  2.1.801 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.401 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI started training a model with scda trainer - part of regression task.\r\n- **What happened?**\r\nIt is taking very long time and process memory seem to be fixed to...:\r\n\r\n![VIsualStudio](https://user-images.githubusercontent.com/42244983/64596652-98a47700-d3b4-11e9-8d61-dd2d71b9e3d0.png)\r\n\r\n165 MB - while the machine has 8 gb of ram.\r\n\r\n- **What did you expect?**\r\n\r\nI am expecting the process to take more ram.\r\n\r\n### Source code / logs\r\n.\r\n\r\nConclusions:\r\nAs it is now the training will not go much faster using a computer with better hardware (ram and cpu) - since trainer seem to be limited to 50% cpu and 165MB RAM?'"
491298821,4196,b'Automl: feature importance for regression models ',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\nHow do i extract the feature importances for the regression models that automl builds. Something similar to automlexplainer in azure maybe?\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
491121315,4195,b'[DatabaseLoader] Error when using attributes (i.e ColumnName)',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 18362\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to use `ColumnName` attribute in class that defines IDataView schema.  \r\n\r\n- **What happened?**\r\n\r\nWhen operating on the IDataView, I received the following error\r\n\r\n```text\r\nSystem.Reflection.TargetInvocationException: \'Exception has been thrown by the target of an invocation.\'\r\n \r\nInner Exception\r\nIndexOutOfRangeException: Features\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nNo error.\r\n\r\n### Source code / logs\r\n\r\nGiven the following data stored in a SQL Server DB\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/64536954-fb7c0c80-d2e7-11e9-8a5b-531ddd267aa8.png)\r\n\r\nThe data schema is defined as such\r\n\r\n```csharp\r\npublic class HouseData\r\n{\r\n    public float Size { get; set; }\r\n\r\n    public float Price { get; set; }\r\n}\r\n```\r\n\r\nThe following code works:\r\n\r\n```csharp\r\nstring connectionString = @""Connection-String"";\r\n\r\nstring sqlCommand = ""SELECT Size,Price FROM House"";\r\n\r\nMLContext mlContext = new MLContext();\r\n\r\nDatabaseLoader loader = mlContext.Data.CreateDatabaseLoader<HouseData>();\r\n\r\nDatabaseSource dbSource = new DatabaseSource(SqlClientFactory.Instance,connectionString,sqlCommand);\r\n\r\nIDataView data = loader.Load(dbSource);\r\n\r\n// Test Code\r\nIEnumerable<HouseData> housingData = mlContext.Data.CreateEnumerable<HouseData>(data, reuseRowObject: true);\r\n\r\nforeach (HouseData house in housingData)\r\n{\r\n    Console.WriteLine($""{house.Size} costs {house.Price}"");\r\n}\r\n\r\nConsole.ReadKey();\r\n```\r\n\r\nHowever, when attributes are added to the schema class, it produces an error.\r\n\r\n```csharp\r\npublic class HouseData\r\n{\r\n    [ColumnName(""Features"")]\r\n    public float Size { get; set; }\r\n\r\n    [ColumnName(""Label"")]\r\n    public float Price { get; set; }\r\n}\r\n```'"
490805302,4192,b'MissingValueIndicatorTransformer does not support exporting to onnx',"b""- **What did you do?**\r\nCreated a pipeline from with MissingValueIndicatorTransformer and tried to export it to Onnx with ConvertToOnnxProtobuf.\r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n"""
490774573,4191,b'[DNN Training] Failed save model in Microsoft.ML.Transforms.DnnTransformer.SaveModel',"b'### System information\r\n\r\n- **OS version/distro**: maxOS 10.14.6\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100-preview9-014004\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n  * Use `RetrainDnnModel` for training regression-based deep-neural-network model\r\n  * Try to save trained model\r\n\r\n- **What happened?**\r\n\r\nApplication throw unhandled exception: System.ArgumentNullException and crash\r\n\r\n- **What did you expect?**\r\n\r\nWe could save trained model\r\n\r\n### Source code / logs\r\n\r\n```\r\nUnhandled exception. System.ArgumentNullException: Value cannot be null. (Parameter \'value\')\r\n   at System.IO.BinaryWriter.Write(String value)\r\n   at Microsoft.ML.Transforms.DnnTransformer.SaveModel(ModelSaveContext ctx)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, Stream stream)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, String filePath)\r\n   at VoiceConversionStarter.Console.Program.Train(TrainMcapOptions opts) in /Users/yamachu/Projects/github.com/yamachu/VoiceConversionStarter/VoiceConversionStarter.Console/Program.cs:line 100\r\n   at VoiceConversionStarter.Console.Program.<>c.<Main>b__2_0(TrainMcapOptions opts) in /Users/yamachu/Projects/github.com/yamachu/VoiceConversionStarter/VoiceConversionStarter.Console/Program.cs:line 118\r\n   at CommandLine.ParserResultExtensions.MapResult[TSource,TResult](ParserResult`1 result, Func`2 parsedFunc, Func`2 notParsedFunc)\r\n   at VoiceConversionStarter.Console.Program.Main(String[] args) in /Users/yamachu/Projects/github.com/yamachu/VoiceConversionStarter/VoiceConversionStarter.Console/Program.cs:line 116\r\n```\r\n\r\nI think this issue is not to check null in this line\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8d51eee8047842ae72f5521bd55a9bec51460859/src/Microsoft.ML.Dnn/DnnTransform.cs#L1118-L1119\r\n\r\nThat field in my trained model is null\r\n<img width=""548"" alt=""\xe3\x82\xb9\xe3\x82\xaf\xe3\x83\xaa\xe3\x83\xbc\xe3\x83\xb3\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\x83\xe3\x83\x88 2019-09-09 1 21 42"" src=""https://user-images.githubusercontent.com/1955233/64491256-3e66c180-d2a1-11e9-967d-5501d6315d61.png"">\r\n\r\nfull source code: https://github.com/yamachu/VoiceConversionStarter/tree/pkg-update\r\n\r\n'"
490662881,4189,b'[DNN Training] Add API/support for Model Interpretability of DNNs',"b'Once we have the foundational DNN training API stabilized, we should add DNN Model Interpretability APIs such as methods of type Saliency Methods and Feature Attribution (FA). \r\n\r\nFor further details, this is a high level summary:\r\nhttps://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab'"
490566177,4186,b'PCA Transformer does not support exporting to Onnx',"b""- **What did you do?**\r\nCreated a pipeline from with PCATranfsform and tried to export it to Onnx with - ConvertToOnnxProtobuf.\r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n"""
490490534,4185,b'Checkpoint method should be renamed to SaveCheckpoint',"b'ML.NET 1.3\r\n\r\nWhen working with Time Series\\SSA Forecasting, the method that is used for saving a model is called ""Checkpoint"":\r\n\r\n```Csharp\r\nforecastEngine.CheckPoint(mlContext, outputModelPath);\r\n```\r\n\r\nInstead, this method would be more intuitive if it were named according to a verb\\action - such as SaveCheckpoint().\r\n\r\nNote that this is also feedback from Cesar.'"
490486888,4184,b'Time Series - SSA Forecasting: Need to add API for performing calculations for comparing real vs. forecasted values',"b""ML.NET 1.3\r\n\r\nCurrently ML.NET doesn't provide any methods in the API for calculating accuracy of forecasted values compared to real observed values - this is when doing Time Series forecasting using SSA.\r\n\r\nIn looking at the [existing TLC documentation](https://microsoft.sharepoint.com/teams/TLC/SitePages/Time-series/Methodology.aspx), it provided the following calculations - ML.NET should do something similar:\r\n\r\n\xe2\x80\x8bError Calculat\xe2\x80\x8bor\r\nOnce the expected value is produced by the time-series modeler component, it is compared against the actual observed value for the series at the time step to compute the amount of deviation. This calculation is done by the error calculator component and the result is called the Raw Score. The implicit assumption here is that the higher the absolute value of raw score at a timestamp, the more likely it is that the time-series is exhibiting an anomalous behavior at that timestamp. In TLC, we have implemented 5 error calculation functions that can be chosen by the user depending on the application.\xe2\x80\x8b\xe2\x80\x8b\r\n\r\nSigned Difference\r\nThe difference between the expected value and the observed value (this is the default error calculation function).\r\n \r\nAbsolute Difference\r\nThe absolute difference between the expected value and the observed value.\r\n\r\nSigned Proportion\r\nThe proportional difference between the expected value and the observed value.\r\n\r\nAbsolute Proportion\r\nThe absolute proportional difference between the expected value and the observed value.\r\n\r\nSquared Difference\r\nThe squared difference between the expected value and the observed value.\r\n"""
490440860,4183,b'Forced shutdown during DNN training',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 version 1803\r\n- **.NET Version (eg., dotnet --info)**: .NET Core v2.2\r\n\r\n### Issue\r\nWhen training a DNN on classifying sounds based on audio spectrograms, with the Resetnet architecture, my computer shutdown. This has happened twice, but not every time I'm training the model. I have a Dell XPS15 with 32 gb of RAM. The only thing I can think of is that my fan cannot keep up (CPU is hitting 100% for 20 min), but I wanted to log it here as an issue in case this is a theme.\r\n\r\n- **What did you do?** I was training a DNN using the MultiClassifier with the Resnet architecture of audio spectrograms\r\n- **What happened?** My computer shutdown (twice)\r\n- **What did you expect?** My computer not to shutdown\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
490440587,4182,b'[DatabaseLoader] Create higher level convenient methods for DatabaseLoader',"b""As mentioned by Diego, these additions would help by simplifying the API usage for users even further and it should be pretty easy to implement for us: \xf0\x9f\x91\x8d \r\n\r\n@divega commented: https://github.com/dotnet/machinelearning-samples/pull/617#pullrequestreview-284597248\r\n\r\n@CESARDELATORRE, I did a deferred review. The experience seems pretty good. \r\n\r\n1:\r\nAnd I agree with you that it could be even better with some sugar method that loads directly from the arguments of DatabaseSource.\r\n\r\n2:\r\nI can also see other possible shortcuts of similar nature. For example, although DbProviderFactory is the all encompassing root concept if you need everything from an ADO.NET provider, a DbConnection can give you everything but DbConnectionStringBuilder, and it is a much more familiar abstraction for most users than the DbProviderFactory. So, unless you need to manipulate connection strings in a provider agnostic way (not commonly an useful thing to do), you could make the sugar Load method generic on the provider's DbConnection type.\r\nAll in all, I would would love to meet with you and the devs and walk trough the product code and API. It is likely that more things like this will come up.\r\n """
490155239,4181,"b""Provided label column 'Status' was of type Single, but only type Boolean is allowed.""","b'Hi,\r\n\r\nI\'m using AutoML to auto-generate a model.\r\n\r\nInput file looks like the following:\r\n""V1"",""V2"",""V3"",""V4"",""Status""\r\n-86,-66,-66,4,0\r\n-84,-78,-61,65,0\r\n...\r\n\r\nOutput:\r\nFor further learning check: https://aka.ms/mlnet-cli\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration #Iteration             |\r\n[Source=AutoML, Kind=Trace] Channel started\r\nException occured while exploring pipelines:\r\nProvided label column \'Status\' was of type Single, but only type Boolean is allowed.\r\nSystem.ArgumentException: Provided label column \'Status\' was of type Single, but only type Boolean is allowed.\r\n   at Microsoft.ML.CLI.CodeGenerator.CodeGenerationHelper.GenerateCode()\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass1_0.<Main>b__0(NewCommandSettings options)\r\nPlease see the log file for more info.\r\nExiting ...\r\n\r\n\r\nIs this a bug?'"
490129313,4180,b'[Clustering] Create/Add an additional trainer for Clustering: Affinity Propagation',"b""In ML.NET we currently only have the [KMeansTrainer](https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks#clustering).\r\n\r\nThe main challenge with that clustering trainer is that you need to provide the number of clusters to use (numberOfClusters param also known as k), and that's a very difficult number to figure out. THere are methods that can help, like the Elbow method, but still it is a challenge.\r\n\r\nThere are other clustering algorithms that doesn\xe2\x80\x99t require in input the number of expected clusters like the **Affinity Propagation** algorithm. \r\nIt is relatively new (Presented in 2007) and it works by measuring the affinity between data items.\r\n\r\nFurther info about it:\r\nhttps://towardsdatascience.com/unsupervised-machine-learning-affinity-propagation-algorithm-explained-d1fef85f22c8 \r\n\r\nThe function that measures affinity between data items is one of the hyperparameters of the algorithm. \r\n\r\n**Affinity Propagation is an unsupervised machine learning algorithm that is particularly well suited for problems where we don\xe2\x80\x99t know the optimal number of clusters.**\r\n\r\nAs an additional note, consider that K-means was first proposed for application in the field of statistics back in 1955.\r\n\r\nI suggest that, when possible, we implement and offer this additional clustering algorithm, especially when we currently just have one algorithm for Clustering (KMeansTrainer)."""
489653381,4178,b'TfIdf setting in ProduceNGrams throws Exception',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: 3.0.0-preview8-28405-07\r\n\r\n### Issue\r\nProduceNGrams throws an InvalidOperationException ""The specified documents are all empty in column \'Tokens\'""\r\n\r\n- **What did you do?**\r\nChanged the parameter setting \'weighting\' of type \'WeightingCriteria\' from the standard \'WeightingCriteria.Tf\' to \'WeightingCriteria.TfIdf\' and then ran the code again.\r\n\r\n- **What happened?**\r\nThe exception gets thrown as described above\r\n\r\n- **What did you expect?**\r\nThe code, specifically the line \'var transformer = pipeline.Fit(dataview);\' to run just as it did with setting WeightingCriteria.Tf.\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar pipeline = _mlContext.Transforms.Text.NormalizeText(nameof(TransformedTextData.NormalizedText),\r\n                nameof(Profile.Text))\r\n                .Append(_mlContext.Transforms.Text.TokenizeIntoWords(nameof(TransformedTextData.Words),\r\n                    nameof(TransformedTextData.NormalizedText)))\r\n                .Append(_mlContext.Transforms.Text.RemoveDefaultStopWords(nameof(TransformedTextData.Words), nameof(TransformedTextData.Words), StopWordsRemovingEstimator.Language.German))\r\n                .Append(_mlContext.Transforms.Text.RemoveStopWords(nameof(TransformedTextData.Words), null, ""kontext"", ""&""))\r\n                .Append(_mlContext.Transforms.Conversion.MapValueToKey(nameof(TransformedTextData.Tokens), nameof(TransformedTextData.Words)))\r\n                .Append(_mlContext.Transforms.Text.ProduceNgrams(nameof(TransformedTextData.Tokens), weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf))\r\n                .Append(_mlContext.Transforms.Text.LatentDirichletAllocation(\r\n                    nameof(TransformedTextData.Features), nameof(TransformedTextData.Tokens), numberOfTopics: 10, numberOfSummaryTermsPerTopic:10));\r\n\r\n            // Fit to data.\r\n            var transformer = pipeline.Fit(dataview);\r\n```\r\n\r\nDoes ProduceNGrams not support the setting TfIdf as weighting? If it doesn\'t, which Transformer would one use to generate NGrams for LatentDirichletAllocation ?'"
489648560,4177,b'Change the DnnImageFeaturizers packages to use models from the ONNX model zoo',"b'We should use the models from the [model zoo](https://github.com/onnx/models) to ensure compatibility with future versions of ONNX runtime.\r\n\r\nWe should also add tests for these packages, to ensure they work correctly.\r\n\r\n\xe2\x80\xa2\tAlexNet\r\n\xe2\x80\xa2\tResNet101\r\n\xe2\x80\xa2\tResNet50\r\n\xe2\x80\xa2\tResNet18\r\n'"
489282428,4176,b'System.AccessViolationException -- Loading tensorflow model',"b'### System information\r\n\r\n- **Windows 10 Pro for Workstations - 1809**:\r\n- **3.0.100-preview3-010431**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am loading a tensorflow model using ML.NET Model.LoadTensorFlowModel method.\r\nReceived this exception:\r\n\r\n- **What happened?**\r\nSystem.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt. I am unable to locate the source of this exception. I only receive this error when running the application in debug mode.\r\n\r\n- **What did you expect?**\r\nMy model to successfully load and be able to make predictions.\r\n\r\n\r\n### Source code / logs\r\n\r\n      var pipline = context.Transforms.Conversion.MapValueToKey(""LabelKey"", ""Label"")\r\n        .Append(context.Transforms.LoadImages(""input"", ""images"", nameof(ImageData.ImagePath)))\r\n        .Append(context.Transforms.ResizeImages(""input"", GenderSettings.ImageHeight, GenderSettings.ImageWidth, ""input""))\r\n        .Append(context.Model.LoadTensorFlowModel(""./modelGender/tensorflow_gender__graph.pb"")\r\n          .ScoreTensorFlowModel(new[] {""cross_entropy""}, new[] {""input""}, addBatchDimensionInput: true))\r\n        .Append(context.Transforms.Conversion.MapKeyToValue(""PredictedLabelValue"", ""PredictedLabel""))\r\n        .AppendCacheCheckpoint(context);\r\n\r\n\r\nIt is not showing any stacktrace or log.\r\n'"
488860362,4175,"b""Don't create local SQL Database files inside the build workspace""","b'Code like this: https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170\r\n\r\n(where you\'re running tests as part of the build) has been leading to, when the build machine is reused, errors like:\r\n```\r\nMsg 5120, Level 16, State 101, Server <machine name>\\LOCALDB#<somehex>, Line 1\r\nUnable to open the physical file ""F:\\workspace.7\\_work\\1\\s\\bin\\AnyCPU.Release-netcoreapp3_0\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf"". Operating system error 3: ""3(The system cannot find the path specified.)"".\r\n```\r\n... this is because workspaces are automatically cleaned up (by deletion) but this leaves SQL server in a bad state.  Ideally this shouldn\'t happen at all, but if it must it\'d be good to use the current user\'s profile directory;  I don\'t care where other than the workspace folder is not a good place for it.  This happens even to other teams\' builds who also test using local SQL DBs \r\n\r\n### System information\r\n\r\n- **OS version/distro**:  Windows Client and Server\r\n- **.NET Version (eg., dotnet --info)**:  All (test bug)\r\n\r\n### Issue\r\n\r\n- **What did you do?** : Talk to other teams who need local SQL DBs to work\r\n- **What happened?** : I found the code creating MDF files in a guaranteed-to-be-deleted place\r\n- **What did you expect?** : Testing should occur outside builds.  Failing that, invariant cleanup should happen.  Failing that, put the files outside the workspace directory.\r\n\r\n### Source code / logs\r\n\r\nSee https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170.  When run as part of the build, the path this resolves is `bin\\Arch.Config-TargetFramework\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf` inside the workspace. '"
488769998,4173,b'Should use dll location instead of app domain in ResNet18/50/128 packages',"b""We find out that in  `Resnet18Extension.cs`, It uses `AppDomain.CurrentDomain` to get the DLL location, which could causes some unexpected behavior in Vsix packaging. (in Vsix AppDomain.CurrentDomain returns VS executables, which is `C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Preview\\Common7\\IDE`, so it won't be able to find the right onnx file). It's better to use `GetAssembly.Loaction` to get the DLL location. You can see the following PR to see the suggest fix\r\n\r\n#4174 """
488745561,4172,b'MulticlassClassification: different predict results depending on the environment the train took place',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10/Azure\r\n- **.NET Version (eg., dotnet --info)**: .NET Core v2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI extracted the code from the MulticlassClassification-GitHubLabeler into a Azure WebJob\r\n- **What happened?**\r\nFirst I run it on my local machine (Windows 10) and after I run it in an app service in Azure\r\n- **What did you expect?**\r\nEven though the ""seed"" param of the ""MLContext"" class is set, the predict results are not the same. The model trained on Windows 10 should be the same with the model trained in Azure. ML.NET takes decisions based on the environment (ProcessorCount , Is64BitProcess, etc.)? \r\n### Source code / logs\r\n\r\n[dotnet/machinelearning-samples MulticlassClassification-GitHubLabeler\r\n](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler/GitHubLabeler/GitHubLabelerConsoleApp/Program.cs)'"
488435937,4171,b'Error in Microsoft.ML.Extensions (Attempted to divide by zero.) when running in Azure',"b'### System information\r\n\r\n- Azure AppService\r\n- .NET Core 2.2, 64-bit\r\n\r\n### Issue\r\n\r\nDeploy the unmodified E2E sample https://github.com/dotnet/machinelearning-samples/tree/v1.2/samples/csharp/end-to-end-apps/DeepLearning_ObjectDetection_Onnx\r\ninto Azure AppService.\r\nNote that you must switch to 64-bit because the AppService will not even start (I suppose that this is a problem with Core 2.2 in-process hosting but I am not sure).\r\nAlso you must modifiy the relative path in the Get action in the ObjectDetectionController\r\n`string imageFileRelativePath = @""assets"" + url;`\r\n\r\n**The code stops at the unhandled division by zero exception** (""Attempted to divide by zero."") at line:\r\n`            var probs = model.Predict(imageInputData).PredictedLabels;`\r\nin the ObjectDetectionService in the DetectObjectsUsingModel method.\r\n\r\n**The application runs without problem when running locally.**\r\n\r\nStack trace:\r\n\r\n```\r\n   at Microsoft.ML.OnnxRuntime.NativeMethods.OrtRun(IntPtr session, IntPtr runOptions, String[] inputNames, IntPtr[] inputValues, UInt64 inputCount, String[] outputNames, UInt64 outputCount, IntPtr[] outputValues)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames, RunOptions options)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, String[] activeOutputColNames, OnnxRuntimeOutputCacher outputCache)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass11_0`1.<MakeTensorGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at OnnxObjectDetectionE2EAPP.Services.ObjectDetectionService.DetectObjectsUsingModel(ImageInputData imageInputData) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Services\\ObjectDetectionService.cs:line 29\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.DetectAndPaintImage(ImageInputData imageInputData, String imageFilePath) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 125\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.Get(String url) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 59\r\n```\r\n\r\nI am now clueless and I even don\'t know how .NET DivideByZeroException can be raised in the C interop call. Where does it come from?\r\n\r\n'"
488308696,4169,b'[Image Classification DNN Transfer Learning] - Use PredictedLabel as String/Value instead of an UInt32 (Index))',"b'I think it\'d be simpler for users and also consistent with other ML.NET APIs if the returned PredictedLabel is a string/value (categorial value) instead UInt32 (Index).\r\n\r\nThat way, simply by having a .MapKeyToValue() at the end of the pipeline, the user will have it as the value being looked for instead of an index which is what we currently get:\r\n\r\n```\r\n//pipeline code\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: ""Label"" , inputColumnName: ""LabelAsKey""));\r\n```\r\n\r\nAs currently implemented, when the user is simply predicting in an end-user app, you need to find out the real label value by using code based on the schema API, like this:\r\n\r\n```\r\nvar prediction = predictionEngine.Predict(imageToPredict);\r\n\r\nvar index = prediction.PredictedLabel;\r\n\r\n// Obtain the original label names to map through the predicted label-index\r\nVBuffer<ReadOnlyMemory<char>> keys = default;\r\npredictionEngine.OutputSchema[""LabelAsKey""].GetKeyValues(ref keys);\r\nvar originalLabels = keys.DenseValues().ToArray();\r\n\r\nConsole.WriteLine($""ImageFile : [{Path.GetFileName(imageToPredict.ImagePath)}], "" +\r\n                    $""Scores : [{string.Join("","", prediction.Score)}], "" +\r\n                    $""Predicted Label : {originalLabels[index]}"");\r\n```\r\n\r\nIf the PredictedLabel was already the string/value, the user won\'t usually need to use the additional `VBuffer `and `OutputSchema `APIs above.\r\n\r\nAlso, this way would be consistent with other multi-class classification algorithms in ML.NET.'"
488259360,4168,"b""I don't understand these predictions""","b'Hey, \r\n\r\nI\'m trying to compute the probabilities of the predictions on my dataset.\r\nI am using the 1.3.1 code at: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.calibratorscatalog.platt?view=ml-dotnet\r\nMy modified code is as follows:\r\n\r\n```\r\n    public static void Run() {\r\n      var mlContext = new MLContext(0);\r\n      var dataPoints = GetDataPoints(@""/HedgeTools/Datasets/rocket-train-classify.csv"");\r\n      var trainingData = mlContext.Data.LoadFromEnumerable(dataPoints);\r\n\r\n      var testDataPoints = GetDataPoints(@""/HedgeTools/Datasets/rocket-test-classify.csv"");\r\n      var testData = mlContext.Data.LoadFromEnumerable(testDataPoints);\r\n\r\n      var options = new FastTreeBinaryTrainer.Options {\r\n        EarlyStoppingMetric = EarlyStoppingMetric.L2Norm, // Use L2Norm for early stopping.\r\n        FeatureFirstUsePenalty = 0.1,  // Create a simpler model by penalizing usage of new features.\r\n        NumberOfTrees = 50\r\n      };\r\n\r\n      var pipeline = mlContext.BinaryClassification.Trainers.FastTree(options);\r\n\r\n      var model = pipeline.Fit(trainingData);\r\n      var transformedTestData = model.Transform(testData);\r\n      var outScores = mlContext.Data.CreateEnumerable<ScoreValue>(transformedTestData,\r\n                                                                  reuseRowObject: false);\r\n      var calibratorEstimator = mlContext.BinaryClassification.Calibrators.Platt();\r\n\r\n      // Convert IDataView object to a list.\r\n      var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedTestData, false).ToList();\r\n      var calibratorTransformer = calibratorEstimator.Fit(transformedTestData);\r\n      var finalData = calibratorTransformer.Transform(transformedTestData);\r\n      var outScoresAndProbabilities = mlContext.Data.CreateEnumerable<ScoreAndProbabilityValue>(finalData, false);\r\n\r\n      Console.WriteLine(""\\nFirst 10 acutals that are true"");\r\n      Console.WriteLine(""Actual Predicted     score   probability"");\r\n      Console.WriteLine(""------ --------- ----------  -----------"");\r\n      var loop = 1;\r\n      for (var index = 0; index < predictions.Count(); index++) {\r\n        var p1 = predictions.ElementAt(index);\r\n        if (!p1.Label) continue;\r\n        var p2 = outScoresAndProbabilities.ElementAt(index);\r\n        Console.WriteLine(""{0, 6} {1, 9} {2, 10}  {3, 11}"", p1.Label, p1.PredictedLabel, p2.Score, p2.Probability);\r\n        if (++loop > 10) break;\r\n      }\r\n\r\n      var metrics = mlContext.BinaryClassification.Evaluate(transformedTestData);\r\n      PrintMetrics(metrics);\r\n    }\r\n```\r\n\r\nThe results I get are as follows:\r\n\r\n\r\n```\r\nFirst 10 actuals that are true\r\nActual Predicted     score   probability\r\n------ --------- ----------  -----------\r\n  True     False  -6.288363   0.06514609\r\n  True     False  -7.417452   0.03533126\r\n  True     False  -6.883083    0.0473095\r\n  True      True   2.404708    0.9079463\r\n  True     False  -5.611444   0.09295245\r\n  True      True  0.2836371    0.7465712\r\n  True     False   -1.93054    0.4548629\r\n  True     False  -3.087828    0.3014578\r\n  True      True  0.2553135    0.7435061\r\n  True     False  -5.725763   0.08760489\r\n\r\nAccuracy.............0.912087912087912\r\nAUC..................0.748737797056458\r\nF1 Score.............0.147208121827411\r\nNegative Precision...0.913221503103949\r\nNegative Recall......0.997835185452446\r\nPositive Precision...0.794520547945205\r\nPositive Recall......0.0811188811188811\r\n\r\nTEST POSITIVE RATIO:    0.0935 (715.0/(715.0+6929.0))\r\nConfusion table\r\n          ||======================\r\nPREDICTED || positive | negative | Recall\r\nTRUTH     ||======================\r\n positive ||       58 |      657 | 0.0811\r\n negative ||       15 |    6 914 | 0.9978\r\n          ||======================\r\nPrecision ||   0.7945 |   0.9132 |\r\n\r\n```\r\nThe ""Actual"" column is a ""ground truth label"". \r\nWhy am I getting a False prediction when the probability is less than 0.5?\r\nI\'m obviously confused.  Please help.\r\n\r\nCharles\r\n\r\n'"
487955473,4167,b'Price PredictionML add projects adding namespaces with space',"b'when I try to add projects after training the price prediction Model. \r\n\r\nCheck the namespace here with auto generated code.\r\n\r\n\r\n`using Microsoft.ML.Data;\r\n\r\nnamespace **Price PredictionML.**Model.DataModels\r\n{\r\n    public class ModelInput\r\n{\r\n    [ColumnName(""vendor_id""), LoadColumn(0)]\r\n    public string Vendor_id { get; set; }\r\n\r\n\r\n    [ColumnName(""rate_code""), LoadColumn(1)]\r\n    public float Rate_code { get; set; }\r\n\r\n\r\n    [ColumnName(""passenger_count""), LoadColumn(2)]\r\n    public float Passenger_count { get; set; }\r\n\r\n\r\n    [ColumnName(""trip_time_in_secs""), LoadColumn(3)]\r\n    public float Trip_time_in_secs { get; set; }\r\n\r\n\r\n    [ColumnName(""trip_distance""), LoadColumn(4)]\r\n    public float Trip_distance { get; set; }\r\n\r\n\r\n    [ColumnName(""payment_type""), LoadColumn(5)]\r\n    public string Payment_type { get; set; }\r\n\r\n\r\n    [ColumnName(""fare_amount""), LoadColumn(6)]\r\n    public float Fare_amount { get; set; }\r\n\r\n\r\n}\r\n}`\r\n\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
487923285,4165,b'Please do an example',b'Please do an example of how the probability is computed and used.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 79a06280-21c8-0ae1-c5d0-17ef5d8d6774\n* Version Independent ID: 4047f033-7557-9533-7626-2c8aeafce38b\n* Content: [DatasetUtils.CalibratedBinaryClassifierOutput.Probability Field (Microsoft.ML.SamplesUtils)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.samplesutils.datasetutils.calibratedbinaryclassifieroutput.probability?view=ml-dotnet-preview)\n* Content Source: [dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
487642015,4164,b'[Object Detection] Internalize Model Pre/Post-Processing',"b""When doing object detection (especially on pre-trained models), there are some pre-processing and post-processing steps that are required to get the input in the format expected by the model as well as to make sense of the output. Ultimately, while these steps are required to prepare the data and interpret the outputs, they are not directly related to the training / prediction task. With state-of-the-art models, this process is mainly boiler-plate and writing the code is often left up to the user to implement every time. A good example of this can be seen when making predictions using the Tiny YOLOv2 pre-trained model. \r\n\r\n[Create Parser](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-onnx#create-a-parser-to-post-process-model-outputs)\r\n\r\nIn this tutorial, a significant portion is boilerplate code to create a parser that extracts the values output by the model (1-D Tensor into bounding box dimensions, confidence score and class probabilities). Internalizing some of these steps as part of a high-level API, especially for pre-trained state-of-the-art models where the inputs / outputs are well-defined would make it easier for users to use these types of models.  \r\n\r\n__Problem:__\r\n\r\n- Pre-Processing/Post-Processing boilerplate code is required when performing object detection to prepare input/output for the model. Although the process is model-specific, the expected inputs and outputs have already been pre-defined for state-of-the-art pre-trained models. Therefore, it doesn't make sense to keep re-writing the same code every time when it is already a solved problem.\r\n- No consistent way to interpret model outputs\r\n\r\n__Proposal:__\r\n\r\n- Internalize pre-processing/post-processing boiler plate code as part of high-level API\r\n\t- Provide option for user to select the model architecture (i.e. SSD, YOLO, Fast R-CNN) they're interested in using to train / score with. Based on the selection, the appropriate pre-processing/post-processing transformations will take place to produce a simple and consistent output for the user. \r\n- Provide a consistent way to interpret outputs\r\n\t- Currently, models like binary classification have output column names (i.e. PredictedLabel, Probability, Score) that the user can access to get the result of training/scoring. Something similar should exist for object detection models. Typical output features include the dimensions of the bounding boxes detected, the probabilities or labels of objects detected in the bounding boxes and the confidence that there is an object inside the bounding box. These could be made available as part of the output schema for the user to access once the scored output produced by the model is post-processed.\r\n\r\n__Resources:__\r\n\r\nTF provides an object detection API which allows the user to extract the class probabilities, bounding box dimensions and objectness scores from the model outputs. \r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nhttps://github.com/tensorflow/models/tree/master/research/object_detection\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n\r\nWindows ML uses LearningModelEvaluationResult which the user can extract the respective outputs from the model. In the case of ML.NET, this could expose the output schema for an object detection prediction.\r\n\r\nhttps://docs.microsoft.com/en-us/windows/ai/windows-ml/evaluate-model-inputs - \r\nhttps://docs.microsoft.com/en-us/uwp/api/windows.ai.machinelearning.learningmodelevaluationresult"""
487283571,4159,b'LpNormNormalizingTransformer does not support exporting to Onnx',"b""- **What did you do?**\r\nCreated a pipeline from NormalizeLpNorm and tried to export it to Onnx with ConvertToOnnxProtobuf. \r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n"""
487207612,4156,b'Create a tests database for the DatabaseLoader tests on macOS and Linux',"b'https://github.com/dotnet/machinelearning/pull/4138 added support for testing against an actual database by attaching a SQL mdf file. However, that functionality is only available on Windows.\r\n\r\nA database file that is supported on Linux and macOS should be created (likely MySQL) so that the tests can successfully run there as well.'"
486677148,4154,b'Is there a way to use `CreatePredictionEngine` dynamically',"b""To use `CreatePredictionEngine`, I need to define input and output class first. But what if I don't want to do that. ( because my data has too many dimensions, it's just painful to put it as class), is there a way to call into that `CreatePredictionEngine` method using data format like dictionary or dynamic object?"""
486673799,4153,b'[Image Classification DNN Transfer Learning] - Support training and scoring with in-memory images',"b'The new DNN-Transfer-Learning is very nicely simplified (and it\'ll be even more simplified), however, the way it is now doesn\'t support to train and score with in-memory images, therefore, if you train with image filepaths, the model for scoring also requires image paths...\r\n\r\nThat\'s limiting in-memory images scenarios that we really need to support.\r\n\r\nFor instance, in the code below, the API ImageClassification() is expecting image filepaths, only.\r\n\r\n```\r\n    public class ImageData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string ImagePath;\r\n\r\n        [LoadColumn(1)]\r\n        public string Label;\r\n    }\r\n\r\n//...\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""LabelAsKey"", \r\n                                                                inputColumnName: ""Label"",\r\n                                                                keyOrdinality: ValueToKeyMappingEstimator.KeyOrdinality.ByValue)\r\n            .Append(mlContext.Model.ImageClassification(""ImagePath"", ""LabelAsKey"",\r\n                            arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n                            epoch: 100,     //An epoch is one learning cycle where the learner sees the whole training data set.\r\n                            batchSize: 100, // batchSize sets the number of images to feed the model at a time. It needs to divide the training set evenly or the remaining part won\'t be used for training. Use 10 for hundreds of images, 100 for thousands of images                             \r\n                            metricsCallback: (metrics) => Console.WriteLine(metrics),\r\n                            reuseTrainSetBottleneckCachedValues: false,\r\n                            reuseValidationSetBottleneckCachedValues: false,\r\n                            validationSet: transformedValidationDataView));\r\n```\r\n\r\n'"
486664786,4152,"b'[Image Classification DNN] - Need to support additional image formats, not just JPEG'","b'The current implementation only supports JPEG images for the dataset since it only has `JpegDecoding `etc. internally.\r\n\r\nIdeally, we need to support the same image formats than the ones supported by each Architecture (InceptionV3, ResNet, etc.)\r\n\r\nSee in PR: https://github.com/dotnet/machinelearning/pull/4151/files#diff-37f2285ba1483af56ae20862631502ecR177'"
486179337,4150,"b'type and namespaces name ""xxx"" does not exist  in  Microsoft ML (1.3.0) '","b""### System information\r\n\r\n- Win7 Prof  OS version/distro  :\r\n- VS2017 NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\nhe type or namespace name 'Api' does not exist in the namespace 'Microsoft.ML.Runtime' (are you missing an assembly reference?)\r\n\r\n- **What did you do?**\r\nupdate ML version\r\n![ML v1 3](https://user-images.githubusercontent.com/16553358/63830128-f17c1480-c99d-11e9-9746-40069926d9b8.png)\r\n\r\n\r\n- **What happened?**\r\nupdate ML.net from 0.5 to 1.3 \r\n\r\n- **What did you expect?**\r\nAble to compile and run \r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n![image](https://user-images.githubusercontent.com/16553358/63829656-ba593380-c99c-11e9-991b-c6fa06b6bdb8.png)\r\n"""
485717714,4148,b'Please focus on stabilizing and consistency before adding more features',"b""This is a general observation that I want to share in hope of boosting the quality and adoptability of ML.net because I really think it has great potential. \r\n\r\nIn recent release I have seen various features being added while the basics are not there yet, e.g. not working correctly or operate in an inconsistent way. This becomes obvious once you go outside of the standard basic tutorials. \r\n\r\nThe breaking changes into ML.net concepts in its earlier stage also had a domino effect on documentation, examples and learning code available online that in many cases have not yet been adjusted to reflect the new situation, and in many case are not compatible anymore. So it is even more important to release features that operate correctly and consistently to build trust.\r\n\r\nSimple example, explainability of the model is crucial when you want to build confidence with end users of the analysis. However a feature like PFI does not work if you load the model from disk (you could mitigate by persisting the PFI outcome separately for future consumption but again, it is a workaround). It also doesn't work in combination with AutoML. \r\n\r\nMaking sure these features are working from A-Z across the various ways of interacting with ML.Net is crucial. It would for sure allow for much faster adoption of ML.Net because right now because it prevents you from moving forward as everything still feels very fragile with loose ends. And that is a shame because the potential is huge."""
485351126,4147,b'YOLOv3 shows ArgumentOutOfRangeException',"b""I'm working on the latest version of Visual Studio 2019 on Windows 10\r\nI have tried to work on object detection using yolov3 model. The yolov3.onnx file has been downloaded from [https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3]\r\n \r\nAfter making the necessary changes in the code, I am receiving the following output on building the solution.\r\n\r\n![yolov3 error](https://user-images.githubusercontent.com/33253391/63710555-0ef29680-c857-11e9-8f1c-eec6ecb7335d.jpeg)\r\n\r\nThe code is similar as used for object detection using tiny-yolov2. Necessary changes are made in the code.\r\n"""
484936839,4145,"b""mlnet's generated projects don't include the cs files""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.17763\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100-preview8-013656\r\n\r\n### Issue\r\n\r\n- **What did you do?** I built AutoML mlnet, went to  `AnyCPU.Debug/mlnet/netcoreapp2.1` and ran the following command:  `dotnet mlnet.dll auto-train --dataset analcatdata_germangss.csv --ml-task multiclass-classification --label-column-name ""Political_system"" --max-exploration-time 60 --name ""test"" --output-path tmp/blah2/`\r\n- **What happened?** mlnet successfully generated the solution, including the 2 projects along with everything needed, but, when opening the solution (or projects), the cs files don\'t show up and nothing can be built, either via VS or `dotnet build` until I explicitly include the .cs files.\r\n- **What did you expect?** For the solutions/projects to work out of the box, I\'m not sure why they don\'t pick up the cs file without being told to.\r\n'"
484629260,4143,b'LDA. Seed topic-words matrix',b'The widely used practice of LDA is the seeding of the matrix of topic-word\r\n\r\nex.\r\nhttps://github.com/vi3k6i5/GuidedLDA\r\n\r\nThis possibility required to:\r\n1. Have stable clustering (topics number remain if data is not changed significantly) when re-training the model\r\n2. Have semi-supervised model (when user define some words for topics)\r\n\r\nThis is a very common business requirement\r\n'
484549609,4142,b'Output type of ImageClassification using Microsoft.ML.Dnn',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 1903\r\n- **.NET Version (eg., dotnet --info)**: Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nImage classification using the new DNN package (0.15.1) with the InceptionV3 architecture.\r\n- **What happened?**\r\nThe output of `mlContext.Model.ImageClassification(""Image"", ""Label"", arch: DnnEstimator.Architecture.InceptionV3)` is of type `Int64`.\r\n- **What did you expect?**\r\nI expected the output for `""PredictedLabel""` to be of type `Key<Int32>`, so that `mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabelName"", ""PredictedLabel"")` would not throw an error.\r\n\r\n### Source code / logs\r\n\r\n```\r\n_System.ArgumentOutOfRangeException: \'Schema mismatch for input column \'PredictedLabel\': expected KeyType, got Vector<Single>\r\nParameter name: inputSchema\'_\r\n```'"
484239319,4141,b'Is it possible to use 64 bit floats when concatenating features?',"b'I\'m having trouble training a kmeans clustering pipeline. Even though all my features have the same type (double) the result is a Schema mismatch between double and single\r\n\r\nmy data structure class looks something like this:\r\n```csharp\r\npublic class Loja\r\n{\r\n    public double encrypted_5_zipcode { get; set; }\r\n    public double faturamento_total { get; set; }\r\n    public double transacoes_total { get; set; } \r\n    public static IEnumerable<Loja> ReadCsvSkipingErrors(string filePath)\r\n    {\r\n        //...\r\n    }\r\n}\r\n```\r\nand main program:\r\n```csharp\r\nvar lojas = Loja.ReadCsvSkipingErrors(fpath);\r\nMLContext mlContext = new MLContext(seed: 1);\r\nIDataView data = mlContext.Data.LoadFromEnumerable(lojas);            \r\n\r\nvar dataProcessPipeline = mlContext.Transforms.Concatenate(""Features"",\r\n                nameof(Loja.encrypted_5_zipcode),\r\n                nameof(Loja.faturamento_total),\r\n                nameof(Loja.transacoes_total)\r\n            );\r\n\r\nvar trainer = mlContext.Clustering.Trainers.KMeans(featureColumnName: ""Features"", numberOfClusters: 3);            \r\nvar trainigPipeline = dataProcessPipeline.Append(trainer);\r\nvar trainedModel = trainigPipeline.Fit(data);\r\n```\r\nthe result is:\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Schema mismatch for feature column \'Features\': expected Vector<Single>, got Vector<Double>\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n```\r\n\r\nIf I change the type of variables to float in class ""Loja"" it works normally. Is it possible to use a double in this case?'"
483229612,4137,b'How to deal with data that is not in the dataset in ML.NET machine learning model?',"b'I had created an answer grade prediction model in ML.NET(tried different regression algorithms and multi class classification algorithm). I have ID, question, answer and grade in my dataset. Inputs to the model are question and answer. Model predicts the grade for the answer. If we provide an input(answer) that is in the dataset, then the model predicts the grade accurately. But when the answer is completely incorrect and not matching with any of the answers in the dataset, then the model is not predicting the grade accurately.\r\n\r\nAny ideas on how to deal with this case?'"
483229100,4136,b'How to optimize a machine learning model in ML.NET?',b'I have created a machine learning model using ML.NET. The learning algorithm used is multiclass classification algorithm. I have tried regression algorithms also. But output of the model is not acccurate. Is there any optimization techniques in ML.NET to make the model more accurate?'
482998559,4135,"b'FastTree induced GC.Collect causing long pauses, high CPU'","b'### System information\r\n\r\n- **OS version/distro**:  Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Framework 4.7.2\r\n\r\n### Issue\r\n- **What did you do?**\r\nTraining using any trainers derived from Fast Trees\r\n- **What happened?**\r\nObserved fully blocking pauses of ~200ms and spikes in CPU usage caused by induced GC collection in Gen2\r\n- **What did you expect?**\r\nAn option to disable this behavior. According to the comment in the linked source, this is a workaround for .net 4.6.  \r\n\r\n### Source code / logs\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTree.cs#L152\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTree.cs#L352\r\n\r\n\r\n'"
482883874,4134,b'Memory leak in the latest ML.NET 1.3.1',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro 10.0.17763\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2.203 e5bab63eca\r\n\r\n### Issue\r\n\r\n- **What did you do?** Update the NuGet references to Microsoft.ML.* from `1.2.0` to `1.3.1`.\r\n- **What happened?** Memory leaking\r\n- **What did you expect?** Same behaviour as before\r\n\r\n### Source code / logs\r\n\r\nThe pipeline consists of a ValueToKey mapping, loading image, resizing and extracting pixels, input them into an tensorflow inception model and finally a LbfgsMaximumEntropy trainer.\r\n\r\nThis is a run training several models in `1.2.0`:\r\n![image](https://user-images.githubusercontent.com/8410877/63354071-0e906200-c364-11e9-8f98-e2a386efe7f9.png)\r\n\r\nThe same exact code, running in `1.3.1`:\r\n![image](https://user-images.githubusercontent.com/8410877/63354132-2a940380-c364-11e9-86be-1193457a6caa.png)\r\n\r\nObject count and heap size are more or less stable, my guess is something related to the tensorflow model not being cleared up.\r\n![image](https://user-images.githubusercontent.com/8410877/63354150-3253a800-c364-11e9-98eb-9fe0428c8528.png)\r\n\r\n'"
482590748,4133,b'CodeCov stopped',"b""We link to the CodeCov report in the repo's main README.md. The CodeCov report seems to have stopped ~3mo ago.\r\n\r\nhttps://codecov.io/gh/dotnet/machinelearning/commits:\r\n> ![image](https://user-images.githubusercontent.com/4080826/63308479-ba27ac80-c2a7-11e9-9052-b4c69abe59f0.png)\r\n\r\nDid we disable the CodeCov bot?"""
482565233,4132,b'Conversion.TryParse parses floats and doubles with empty/whitespace values as 0 instead of NaN',"b'This is done for historical reasons since there are clients that depend on this behavior, so it\'s not a bug.  Nevertheless, if we don\'t control the input dataset format this would produce signal loss since empty/whitespace values are now indistinguishable from value ""0"".  We can fix that in AutoML by inserting a transform that addresses the issue but a much better fix would be to change the loader behavior.'"
482455921,4131,"b""[AutoML] In CodeGenerator, remove .cs files that are generated from .tt's that are currently checked in""",b'We should avoid checking in auto-generated content.  Looks like it is officially supported by msbuild: https://docs.microsoft.com/en-us/visualstudio/modeling/code-generation-in-a-build-process?view=vs-2019\r\n'
482450432,4130,"b'[AutoML] Provide a Predict CLI command, similar to the mlnet-autotrain command'","b'Provide a Predict CLI command, similar to the mlnet-autotrain command'"
482423959,4129,b'[AutoML] make CodeGenerator component independent of AutoML internals',"b""Currently we have to use InternalsVisible in AutoML so CodeGenerator can use Pipeline object.  Need to refactor interfaces so that this is no longer the case, ideally such that CodeGenerator doesn't have a dependency on AutoML at all."""
482365047,4128,b'How to analyze sentiment comment of other language not english?',"b""### Issue\r\n\r\n- **What did you do?**\r\nLearned an [example analyze comment](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/sentiment-analysis), data for train is English comment.\r\n- **What happened?**\r\nI want to know how to use ML.NET to analyze comment but data for train is other language not English (in my case is vietnamese).\r\nWith my knowledge, I think have to step to preprocess data before use ML.NET to train, but I don't know how to code use ML.NET.\r\n- **What did you expect?**\r\nWant to know step to resolve my problem or any plan to support to do that.\r\n\r\n"""
482023169,4126,"b'Re-using the same Dataview with Bitmaps in memory, breaks when fitting different models or run cross validation on it'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI had a working pipeline for training image classification with cross-validation on the previous ML.NET version, using file paths as input. Now, being able to load Bitmaps, I am trying to setup a similar pipeline, but allowing training and predictions from in-memory bitmaps.\r\n- **What happened?**\r\nThe training works if I just Fit the data,\r\n`ITransformer mlModel = pipeline.Fit(trainData);`\r\n but it fails if I try to use CrossValidate\r\n`var cvResults = _mlContext.MulticlassClassification.CrossValidate(trainData, pipeline, numberOfFolds);`\r\n- **What did you expect?**\r\nI expected a pipeline that worked with Fit to work with CrossValidate, but it seems the internal multiple passes do something to the Bitmaps (they lose data).\r\n### Source code / logs\r\nMy current pipeline, based on [this sample](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/DeepLearning_ImageClassification_TensorFlow) is this:\r\n```C#\r\nvar pipeline = _mlContext.Transforms.Conversion.MapValueToKey(""Label"")               \r\n                .Append(_mlContext.Transforms.ResizeImages(outputColumnName: TensorFlowModelSettings.inputTensorName, imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image)))                \r\n                .Append(_mlContext.Transforms.ExtractPixels(outputColumnName: TensorFlowModelSettings.inputTensorName, interleavePixelColors: ImageSettings.channelsLast, offsetImage: ImageSettings.mean/*, inputColumnName: nameof(ImageInputData.Image)*/))                \r\n                .Append(_mlContext.Model.LoadTensorFlowModel(tensorFlowModelFilePath).\r\n                ScoreTensorFlowModel(outputColumnNames: new[] { TensorFlowModelSettings.outputTensorName },\r\n                                    inputColumnNames: new[] { TensorFlowModelSettings.inputTensorName }, addBatchDimensionInput: false))                \r\n                .Append(_mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: ""Label"", featureColumnName: TensorFlowModelSettings.outputTensorName))\r\n                .Append(_mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""))\r\n                .AppendCacheCheckpoint(_mlContext);\r\n```\r\n\r\nThe error log includes the following exceptions:\r\n\r\n```\r\nSystem.ArgumentException: Parameter is not valid.\r\n   at System.Drawing.Image.get_Height()\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass9_0.<SplitCore>b__1()\r\n```\r\n\r\n```\r\nSystem.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.ArgumentException: Parameter is not valid.\r\n   at System.Drawing.Image.get_Height()\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass9_0.<SplitCore>b__1()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n```\r\n\r\nThis is my first issue here, and I apologize if I overlooked something. I found no posts about this error anywhere.'"
481934642,4125,b'DetectIidSpike Fit() does not train the engine. Predict() does.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n- Microsoft.ML 1.3.1, Microsoft.ML.TimeSeries 1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI\'m trying to build amount anomaly detection. I want to be able to provide historical data as ""good value range"", and provide new record for prediction.\r\n\r\n- **What happened?**\r\nThe engine does not get trained when I call Fit(). It is trained only via Predict() call. I need to call Predict() for each training data. The result of Predict() is not used other than the new record\'s.\r\n\r\n- **What did you expect?**\r\nI expect Fit() will make the engine ready, and subsequent Predict() call will test the new record\'s anomaly.\r\n\r\n### Source code / logs\r\nHere is the snippet of my code.\r\n\r\n            var trainingData = data.Where(x => x.BusinessDate < businessDate).ToList();\r\n            var targetData = data.Where(x => x.BusinessDate == businessDate).ToList();\r\n\r\n            var mlContext = new MLContext();\r\n            var iidSpikeEstimator = mlContext.Transforms.DetectIidSpike(nameof(AnomalyPrediction.Prediction), nameof(CheckRecord.Amount), 98, trainingData.Count, AnomalySide.Positive);\r\n\r\n            IDataView trainingDataView = mlContext.Data.LoadFromEnumerable(trainingData);\r\n            ITransformer iidSpikeTransform = iidSpikeEstimator.Fit(trainingDataView);\r\n\r\n            var engine = iidSpikeTransform.CreateTimeSeriesEngine<CheckRecord,\r\n                AnomalyPrediction>(mlContext);\r\n\r\n            // without below, prediction will always be 0, with p-value 0.5. it behaves as if targetData is the very first sample.\r\n            trainingData.ForEach(x => engine.Predict(x));\r\n\r\n            var prediction = engine.Predict(targetData.Single());\r\n\r\n            return prediction.Prediction[0] == 1;\r\n\r\n### Referenced Source Code\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/TimeSeries/DetectIidSpike.cs\r\nThis one uses the data in Fit() call but example relies on calling engine.Predict().\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseriescatalog.detectiidspike?view=ml-dotnet\r\nThis one passes training data to both Fit() and Transform() calls. It does not provide a way to instruct past data as norm.'"
481422665,4122,b'Using the wrong type with OnnxSequenceType throws an non-helpful message',"b'We should give the user a better exception message when they use the wrong type in their class vs. the type in an ONNX model. The current exception doesn\'t help point them in the right direction and only confuses them.\r\n\r\nIf you pull the following code:\r\n\r\nhttps://github.com/sethjuarez/SeeSharp/tree/c864892252880d4ef87006008823dee3b29adf9c\r\n\r\nAnd change the code to be:\r\n\r\n```C#\r\n    public class ImagePrediction\r\n    {\r\n        [ColumnName(""classLabel"")]\r\n        [VectorType]\r\n        public string[] Prediction;\r\n\r\n        [OnnxSequenceType(typeof(IEnumerable<float>))]\r\n        public IEnumerable<float> loss;\r\n    }\r\n\r\n    public class ImageInput\r\n    {\r\n        [ImageType(224, 224)]\r\n        public Bitmap Image { get; set; }\r\n    }\r\n\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var modelFile = Directory.EnumerateFiles(""."", ""*.onnx"").FirstOrDefault();\r\n            Console.WriteLine($""Attempting to load {modelFile}..."");\r\n            var predictor = LoadModel(modelFile);\r\n\r\n\r\n            Console.WriteLine(""\\n\\nReading Folder..."");\r\n            foreach (var file in Directory.EnumerateFiles(""images"", ""*.jpg""))\r\n            {\r\n                Console.WriteLine(file);\r\n                var output = predictor.Predict(new ImageInput { Image = (Bitmap)Image.FromFile(file) });\r\n                Console.WriteLine($""Label: {output.Prediction[0]}"");\r\n                var loss = output.loss.FirstOrDefault();\r\n                Console.WriteLine($""\\t{loss}"");\r\n                Console.WriteLine(""------------------------------------\\n\\n"");\r\n            }\r\n            \r\n            Console.ReadKey();\r\n        }\r\n```\r\n\r\nYou get the following exception:\r\n\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Could not determine an IDataView type for member loss\r\nParameter name: rawType\r\n   at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(String name, Type rawType, IEnumerable`1 attributes, Boolean& isVector, Type& itemType)\r\n   at Microsoft.ML.Data.SchemaDefinition.Create(Type userType, Direction direction)\r\n   at Microsoft.ML.Data.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition)\r\n   at Microsoft.ML.PredictionEngineBase`2.PredictionEngineCore(IHostEnvironment env, InputRow`1 inputRow, IRowToRowMapper mapper, Boolean ignoreMissingColumns, SchemaDefinition outputSchemaDefinition, Action& disposer, IRowReadableAs`1& outputRow)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at SeeSharp.Program.LoadModel(String onnxModelFilePath) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 72\r\n   at SeeSharp.Program.Main(String[] args) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 38\r\n```\r\n\r\nWhen the error here is that the Onnx model expects the `loss` property to be \r\n```C#\r\n        [OnnxSequenceType(typeof(IDictionary<string, float>))]\r\n        public IEnumerable<IDictionary<string, float>> loss;\r\n```\r\n\r\nBut when you use the wrong type (like I did above), you get this unhelpful exception.\r\n\r\nInstead the message should tell you that ""The expected type `IEnumerable<IDictionary<string, float>>` does not match the type of the `loss` property: `IEnumerable<float>`. Please change the loss property to `IEnumerable<IDictionary<string, float>>`""\r\n\r\n/cc @wschin '"
481420620,4121,"b""Using OnnxSequenceType and ColumnName attributes together doesn't work""","b'If you have both `OnnxSequenceType` and `ColumnName` attributes on a property, ML.NET gets confused and throws an exception.\r\n\r\nFor example, if you pull the following code: \r\n\r\nhttps://github.com/sethjuarez/SeeSharp/tree/c864892252880d4ef87006008823dee3b29adf9c\r\n\r\nAnd change the ImagePrediction class to be:\r\n\r\n```\r\n    public class ImagePrediction\r\n    {\r\n        [ColumnName(""classLabel"")]\r\n        [VectorType]\r\n        public string[] Prediction;\r\n\r\n        [ColumnName(""loss"")]\r\n        [OnnxSequenceType(typeof(IDictionary<string, float>))]\r\n        public IEnumerable<IDictionary<string, float>> Loss;\r\n    }\r\n```\r\n\r\n(You will also need to change 1 place in the `Main` method to change from `output.loss.FirstOrDefault();` to `output.Loss.FirstOrDefault();` from the rename.)\r\n\r\nYou get an error:\r\n\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Could not determine an IDataView type for member Loss\r\nParameter name: rawType\r\n   at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(String name, Type rawType, IEnumerable`1 attributes, Boolean& isVector, Type& itemType)\r\n   at Microsoft.ML.Data.SchemaDefinition.Create(Type userType, Direction direction)\r\n   at Microsoft.ML.Data.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition)\r\n   at Microsoft.ML.PredictionEngineBase`2.PredictionEngineCore(IHostEnvironment env, InputRow`1 inputRow, IRowToRowMapper mapper, Boolean ignoreMissingColumns, SchemaDefinition outputSchemaDefinition, Action& disposer, IRowReadableAs`1& outputRow)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at SeeSharp.Program.LoadModel(String onnxModelFilePath) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 76\r\n   at SeeSharp.Program.Main(String[] args) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 39\r\n```\r\n\r\nThis should work. The program works if you remove the `ColumnName` attribute.  And fails with the above as soon as you add the `ColumnName` attribute.\r\n\r\n/cc @wschin '"
481418348,4120,b'Using default OnnxSequenceType attribute throws meaningless exception',"b'Pull the code at this commit and run the application - https://github.com/sethjuarez/SeeSharp/tree/b6a7e8a0094b99af05bc72528a2c6e306abbf7cd\r\n\r\nThe code of interest is:\r\n\r\n```C# \r\n    public class ImagePrediction\r\n    {\r\n        [ColumnName(""classLabel"")]\r\n        [VectorType]\r\n        public string[] Prediction;\r\n\r\n\r\n        [ColumnName(""loss"")]\r\n        [OnnxSequenceType]\r\n        public List<float> Loss;\r\n    }\r\n```\r\n\r\nYou get the following error:\r\n\r\n```\r\nUnhandled Exception: System.ArgumentNullException: Value cannot be null.\r\n   at System.RuntimeType.MakeGenericType(Type[] instantiation)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxSequenceTypeAttribute.Register()\r\n   at Microsoft.ML.Data.SchemaDefinition.Create(Type userType, Direction direction)\r\n   at Microsoft.ML.Data.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition)\r\n   at Microsoft.ML.PredictionEngineBase`2.PredictionEngineCore(IHostEnvironment env, InputRow`1 inputRow, IRowToRowMapper mapper, Boolean ignoreMissingColumns, SchemaDefinition outputSchemaDefinition, Action& disposer, IRowReadableAs`1& outputRow)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at SeeSharp.Program.LoadModel(String onnxModelFilePath) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 70\r\n   at SeeSharp.Program.Main(String[] args) in /Users/eerhardt/git/SeeSharp/SeeSharp/Program.cs:line 39\r\n```\r\n\r\nIt looks like the code here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/0c0789f8eba1e47f6fa759de01f99588e560935c/src/Microsoft.ML.OnnxTransformer/OnnxSequenceType.cs#L95-L100\r\n\r\nIs expecting `_elemType` to never be null.  However, that is exactly what happens when you use the default attribute:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/0c0789f8eba1e47f6fa759de01f99588e560935c/src/Microsoft.ML.OnnxTransformer/OnnxSequenceType.cs#L57-L64\r\n\r\nI don\'t think having a default constructor is right with this attribute - you can\'t use this sequence attribute without specifying an element type.\r\n\r\n/cc @wschin '"
481268942,4119,b'Does this only apply to numeric columns?',"b""It would be good to call out which column types this applies to and for each column type what could be considered a 'missing' value (empty string, 0, null, etc.)\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 3725a2c2-9121-a125-a2c1-ffa5bb799e17\n* Version Independent ID: d5e97e37-927e-5f3a-f219-78f972d6e371\n* Content: [DataOperationsCatalog.FilterRowsByMissingValues(IDataView, String\\[\\]) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.filterrowsbymissingvalues?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
480917982,4114,"b""[AutoML] refactor internal benchmarking so it doesn't need internalsvisible AutoML""","b'The reason we use internalsvisible currently is to be able to see what pipleline did an iteration run, including all the details like hyperparam values.  It is present in an internal AutoML structure.\r\n\r\nIdeal solution to this is if ML.NET starts supporting an interface that allows exploring an istantiated pipeline.\r\n\r\nSecond best, we can come up with some logging or ToString() solutions that will expose what we need.'"
480847294,4113,b'ML.NET API for Explainability and Interpretability targeting Deep Learning models',"b'Our current model explainability APIs targets ML classic algorithms in ML.NET.\r\n\r\nWe\'ll need something comparable for deep learning models where explainability and interpretability is a lot harder since deep learning models are much more ""black boxes"" than classic ML models. (Note that [explainability and interpretability are related but are not the same concepts](https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html))\r\n\r\nDeep Learning models can achieve high accuracy but at the expense of high abstraction (i.e.\xc2\xa0accuracy vs interpretability problem), however, modern research is enabling interpretability for deep learning models, see related article:\r\n\r\nhttps://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab \r\n\r\nAfter our deep learning training approaches are in place through transfer-learning, this is an area to explore and implement for the users.'"
480659002,4112,"b""Get Error when Loading Model. System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies""","b""- Azure Function App: runtime version 2.0.12625.0\r\n- .NET Core 2.1: \r\n\r\nITransformer trainedModel = mlContext.Model.Load(stream, out modelInputSchema);\r\nWhen loading Model into ITransformer I get the following error:\r\n\r\n\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n\r\n\r\n"""
480553841,4111,b'ImageDataViewType produces different outputs',"b'In one program I have\r\n```C#\r\nvar builder = new DataViewSchema.Builder();\r\n                builder.AddColumn(""Label"", TextDataViewType.Instance);\r\n                ImageDataViewType imDT = new ImageDataViewType();\r\n                builder.AddColumn(""Image"", imDT);\r\n                lSchema = builder.ToSchema();\r\n```\r\nand the imDT.Rawtype is {System.Drawing.Bitmap}. This works perfectly when the lSchema is used in  CreatePredictionEngine.\r\nIn another program I have\r\n```C#\r\n                DataViewSchema.Builder builder = new DataViewSchema.Builder();\r\n                builder.AddColumn(""Label"", TextDataViewType.Instance);\r\n                ImageDataViewType imDT = new ImageDataViewType();\r\n                builder.AddColumn(""Image"", imDT);\r\n                lSchema = builder.ToSchema();\r\n```\r\nwhere inDT RawType is {Name = ""Bitmap"" FullName = ""System.Drawing.Bitmap""}\r\nwhich preduces the error {""Could not determine an IDataView type for member Image\\r\\nParameter name: rawType""}.\r\nI am trying to eliminate the original exception of {""Could not determine an IDataView type for member Image\\r\\nParameter name: rawType""}\r\n\r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 78deb193-fc79-6814-c8e8-30ab50febfa9\r\n* Version Independent ID: 9c3da030-2aef-37b3-40da-c63ff9c85780\r\n* Content: [ImageDataViewType Class (Microsoft.ML.Transforms.Image)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.image.imagedataviewtype?view=ml-dotnet-1.0.0)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms.Image/ImageDataViewType.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms.Image/ImageDataViewType.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
480413666,4109,b'Enable loading TransformerChain models in EntryPoint graphs',"b'Related to microsoft/NimbusML#201\r\n\r\nThe new `TransformerChain` model format cannot be used to score a dataset in NimbusML. This is because this model format cannot be loaded by `TransformModelImpl`, which is a field of `PredictorModelImpl`, which in turn is used in constructing the inputs for the entry point  graph passed by NimbusML.\r\n\r\n cc: @eerhardt @ganik '"
480019528,4106,b'Cluster Documents',b'Is there a way to cluster documents\\text. Looking at the documentation [KMeansTrainer Class](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.kmeanstrainer?view=ml-dotnet) is using single as the input type. Is there a way to extend or perhaps something in a future version?\r\n\r\nI know that I can use classification but that requires a lot of work as I have many documents.\r\n\r\n'
479923367,4105,b'[ImageClassification Transfer Learning] Support additional DNN architectures',"b'Just a reminder that we\'ll need to support more powerful architectures and specialized architectures in order to cover most customer scenarios.\r\n\r\nFor instance, NASNet (notably nasnet_large and pnasnet_large), which can provide extra precision. Or for lighter models targeting slower processors,  MobileNet V1 or V2 architectures, or  nasnet_mobile.\r\n\r\nSee:\r\nhttps://www.tensorflow.org/hub/tutorials/image_retraining#other_model_architectures\r\n\r\nI wonder if we should try to make a generic catalog based on ""needs"" or ""image types"" instead of architecture names that most .NET developers won\'t be familiar with such as the previous names or Inceptionv3, ResNet, etc. Those names don\'t mean anything to most .NET developers.\r\n\r\nOPEN PRE-TRAINED MODEL:\r\nThe other feature is to be able for the user to provide their own model, but for that, we\'d probably need an API with many more details, such as tensor names?'"
479567857,4103,b'Load/save in  Microsoft.ML from 1.3.1',"b'### System information\r\n\r\n- **OS version/distro**:\r\nMicrosoft Windows 10 Enterprise\r\n10.0.17763 Build 17763\r\n- **.NET Version (eg., dotnet --info)**: \r\nMicrosoft Windows [Version 10.0.17763.379]\r\n(c) 2018 Microsoft Corporation. All rights reserved.\r\n\r\n>dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.508\r\n Commit:    9ba8583e91\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.508\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.12\r\n  Commit:  ccea2e606d\r\n\r\n.NET Core SDKs installed:\r\n  1.0.0-preview2-003131 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.505 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.507 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.508 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 1.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nSaved trained model\r\n context.Model.Save(model, data.Schema, modelLocation);\r\nin the same class\r\nITransformer model = context.Model.Load(modelLocation, out DataViewSchema schema);\r\nworks OK.\r\n\r\nIn a different class\r\nmodel = context.Model.Load(modelLocation, out DataViewSchema schema);\r\n- **What happened?**\r\nGot exception \r\nCould not load zip, something missing at the end of zip file, apparently.\r\n- **What did you expect?**\r\nA loaded model.\r\n### Source code / logs\r\nThen after 3 days I manually changed the csproj file as NuGet could not change the versions!\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n\r\n  <PropertyGroup>\r\n    <OutputType>Exe</OutputType>\r\n    <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    <LangVersion>7.1</LangVersion>\r\n  </PropertyGroup>\r\n\r\n  <ItemGroup>\r\n    <PackageReference Include=""Microsoft.ML"" Version=""1.3.1"" />\r\n    <PackageReference Include=""Microsoft.ML.CpuMath"" Version=""1.3.1"" />\r\n    <PackageReference Include=""Microsoft.ML.DataView"" Version=""1.3.1"" />\r\n    <PackageReference Include=""Microsoft.ML.Dnn"" Version=""0.15.1"" />\r\n    <PackageReference Include=""Microsoft.ML.ImageAnalytics"" Version=""1.3.1"" />\r\n    <PackageReference Include=""Microsoft.ML.TensorFlow"" Version=""1.3.1"" />\r\n    <PackageReference Include=""Microsoft.ML.TensorFlow.Redist"" Version=""0.14.0"" />\r\n    <PackageReference Include=""OpenCvSharp4"" Version=""4.1.0.20190416"" />\r\n    <PackageReference Include=""OpenCvSharp4.runtime.win"" Version=""4.1.0.20190416"" />\r\n  </ItemGroup>\r\n\r\nReplace 1.3.1 by 1.1.0\r\n\r\nRetest - all worked\r\nChanged them back to try to get the exact exception again.\r\nAll worked!\r\n\r\nIn a separate program, Loading the model originally saved before I changed the csproj file in the training program\r\nNodeDef mentions attr \'explicit_paddings\' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW""]; attr=dilations:list(int),default=[1, 1, 1, 1]>; NodeDef: {{node conv2d0_pre_relu/conv}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\nError during class instantiation\r\nException has been thrown by the target of an invocation.\r\n\r\nLoading the new model works fine.\r\nSo I could not reproduce the issue I have been tring to solve for ages.\r\nOh, be joyful!\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
479366523,4102,b' DnnEstimator.Architecture.InceptionV3  classification incorrect.',"b'The tensorflow_inception_graph.pb classification correct\xe3\x80\x82But image size only 224.\r\nI tested. DnnEstimator.Architecture.InceptionV3\r\nDrawString ""0"" to Graphics Save to file 0.gif, and The other is the same 1.gif,2.gif,3.gif .\r\n\r\n       public static IEnumerable<ImageNetDigData> LoadImagesFromDirectory(string folder)\r\n        {\r\n\r\n            var files = Directory.GetFiles(folder, ""*.gif"",\r\n    searchOption: SearchOption.TopDirectoryOnly);\r\n            foreach (var file in files)\r\n            {\r\n                //0.gif,1.gif,2.gif.3.gif      a0.gif,a1.gif, x1.gif,x2.gif\r\n                var name = Path.GetFileName(file).Split(new char[] { \'.\' })[0];\r\n                var label = name.Substring(name.Length - 1, 1);\r\n\r\n                var nd = new ImageNetDigData()\r\n                {\r\n                    ImagePath = file,\r\n                    Label = label\r\n                };\r\n                yield return nd;\r\n            }\r\n        }\r\n\r\nBut classification incorrect\xe3\x80\x82\r\nHow to configure parameters\xef\xbc\x9f\r\nGive me a sample.Thanks.'"
478948089,4101,b'[Question] access on TrainingLabelValues to display N-Best labels',"b'### System information\r\n\r\n- **Windows**:\r\n- **ML.Net version 1.3.1)**: \r\n\r\n### Issue\r\n\r\nHello,\r\n\r\nI\'m trying to display N-Best Label in mulitclass text classification.\r\nSo i was trying to access to TrainingLabelValues from score column annotations by doing \r\n`var trainedClassLabels = _predictionEngine.OutputSchema.GetColumnOrNull(""Score"").Value.Annotations.Schema.GetColumnOrNull(""TrainingLabelValues"");`\r\n\r\nI can\'t figure out how am i supposed to get labels from the string vector.\r\n\r\nA little bit later, i found sfilipi\'s example of accessing this field in https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/Scenarios/Api/Estimators/PredictAndMetadata.cs\r\n\r\ni was trying to do the same but AnnotationUtils is internal, and I can\'t access to `AnnotationUtils.Kinds.TrainingLabelValues`\r\n\r\n\r\nShould I Do something else to get this thing done ?\r\n\r\nThans a lot fro your time,\r\n\r\nLouis'"
478938095,4100,b'Everything is a var type',"b""You are trying to explain what an IDataView is, but all the variable are of type var.\nSo is\nvar dataView = new InputObjectDataView(inputArray);\nof type IDataView or what?\nGiven that VS easily converts to the correct type why is every example in the entire website filled with 'var's so we cannot determine what's going on.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: cebd0074-01d3-d048-305a-cfea8b4083de\n* Version Independent ID: 7f1aaf72-e345-e334-6237-d92abd3aa6d3\n* Content: [IDataView Interface (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/IDataView.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/IDataView.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
478927303,4099,"b'cannot extract MaximumEntropyModelParameters from pre-trained model, for using LbfgsMaximumEntropyMulticlassTrainer.Fit(IDataView, MaximumEntropyModelParameters) Method'","b'### System information\r\n\r\n- **OS version/distro**: windows 10 enterprise\r\n- **.NET Version (eg., dotnet --info)**:  .Net Core 2.2\r\n- **Microsoft.ML Version**:  1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI want to re-train multi-class (`LbfgsMaximumEntropyMulticlassTrainer`).\r\n- **What happened?**\r\nso, I train and load model, but i cannot extract `MaximumEntropyModelParameters`.\r\n- **What did you expect?**\r\nI want to extract `MaximumEntropyModelParameters` my pre-trained model.\r\nI want to sample code using `LbfgsMaximumEntropyMulticlassTrainer.Fit(IDataView, MaximumEntropyModelParameters)` method.\r\n\r\n### Source code / logs\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n**code:**\r\n```c#\r\nMLContext _mlContext = new MLContext(seed: 0);\r\nvar pipeline = _mlContext.Transforms.Conversion.MapValueToKey(inputColumnName: ""Area"", outputColumnName: ""Label"")\r\n    .Append(_mlContext.Transforms.Text.FeaturizeText(inputColumnName: ""Keyword"", outputColumnName: ""KeywordFeaturized""))\r\n    .Append(_mlContext.Transforms.Concatenate(""Features"", ""KeywordFeaturized""));\r\nvar trainingPipeline_LbfgsMaximumEntropy = pipeline\r\n    .Append(_mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(""Label"", ""Features""))\r\n    .Append(_mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\nvar trainingPipeline_LbfgsMaximumEntropy = pipeline\r\n    .Append(_mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(""Label"", ""Features""))\r\n    .Append(_mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nTrainTestData dataSplit = _mlContext.Data.TrainTestSplit(data, testFraction: 0.1);\r\nIDataView _trainingDataView = dataSplit.TrainSet;\r\nIDataView _testDataView = dataSplit.TestSet;\r\nITransformer _trainedModel2 = trainingPipeline_LbfgsMaximumEntropy.Fit(trainingDataView);\r\n_mlContext.Model.Save(_trainedModel2, _trainingDataView.Schema, _modelPath);\r\n\r\nDataViewSchema dataPrepPipelineSchema;\r\nvar dataPrepPipeline = _mlContext.Model.Load(_modelPath2, out dataPrepPipelineSchema);\r\nvar loadedModel2 = _mlContext.Model.Load(_modelPath2, out DataViewSchema modelInputSchema2);\r\nMaximumEntropyModelParameters originalModelParameters = ((IPredictionTransformer<object>)loadedModel2).Model as MaximumEntropyModelParameters;\r\n```\r\n\r\n**log:**\r\n```log\r\nSystem.InvalidCastException: Unable to cast object of type \'Microsoft.ML.Data.TransformerChain`1[Microsoft.ML.ITransformer]\' to type \'Microsoft.ML.Data.TransformerChain`1[Microsoft.ML.Transforms.KeyToValueMappingTransformer]\'.\r\n```'"
478914494,4097,b'Wrong example values in LogLossReduction documentation',"b'The RIG value given by the `LogLossReduction` would be `0.20` and not `20` in the example:\r\n\r\n`For example, if the RIG equals 20, it can be interpreted as ""the probability of a correct prediction is 20% better than random guessing"". `\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: be840507-df5f-8980-3d02-a7765eef1af3\r\n* Version Independent ID: 46c925d8-7d87-5f9c-5e3d-9d88bae26be1\r\n* Content: [MulticlassClassificationMetrics.LogLossReduction Property (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.loglossreduction?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
478654757,4095,b'[ImageClassification Transfer Learning] Training crashes with no clear exception but this error code from dotnet: dotnet.exe (process 11108) exited with code -1073740791',"b""When training a model with the new **'ImageClassification Transfer Learning'** component (v0.15.1) and only around **200 images**, after a couple of hours working/training, the program crashes and exist by only showing the following error (no any particular ML.NET exception to search for): \r\n\r\n`C:\\Program Files\\dotnet\\dotnet.exe (process 11108) exited with code -1073740791.`\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/62732281-d3437a00-b9d8-11e9-9129-3093c39e3eb9.png)\r\n\r\nIt might be related to a low level issue such as memory leaks, not sure..\r\n\r\nHere's the code (with image dataset) I'm running:\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/blob/migration/v1.3/samples/csharp/getting-started/DeepLearning_TensorFlow_TransferLearning/ImageClassification.Train/Program.cs\r\n"""
478396485,4094,b'Sparse',"b'No detail or example. \nWhat happens here? \npredictions = contextML.Data.CreateEnumerable&lt;DataBlobPrediction&gt;(\n                T.Transform(contextML.Data.LoadFromEnumerable(blobsList, schemaML)), false, true);\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 09dc1ab7-401c-68e7-3ab9-38f5afbc4fc6\n* Version Independent ID: c740981e-1bcd-c738-ad77-7dede76ed32b\n* Content: [ITransformer.Transform(IDataView) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.itransformer.transform?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/ITransformer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ITransformer.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
478244778,4093,b'[ImageClassification Transfer Learning] - API documentation should provide more meaningful descriptions',"b'Just to keep track of this. I understand we\'re in early preview and things can change, though. But since it is public preview, folks might review the reference in order to get any help.\r\n\r\nFor instance, the most ""unknown parameters"" for .NET developers have the following descriptions which don\'t ""tell you anything"":\r\n\r\n[dnncatalog.imageclassification reference](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dnncatalog.imageclassification?view=ml-dotnet-preview#Microsoft_ML_DnnCatalog_ImageClassification_Microsoft_ML_ModelOperationsCatalog_System_String_System_String_System_String_System_String_System_String_System_String_Microsoft_ML_Transforms_DnnEstimator_Architecture_Microsoft_ML_Transforms_DnnEstimator_DnnFramework_System_Int32_System_Int32_System_Single_)\r\n\r\nPARAMETER DESCRIPTIONS:\r\n```\r\nepoch\r\nInt32\r\nNumber of training epochs.\r\n\r\nbatchSize\r\nInt32\r\nThe batch size for training.\r\n\r\nlearningRate\r\nSingle\r\nThe learning rate for training.\r\n```'"
478195262,4092,b'How do I max out CPU cores with AutoML?',"b'I\'m using AutoML to find and train the ""best model possible"" for my set of data. This is awesome and works really well - thanks all!\r\n\r\nMy question/problem comes to trying to max out the CPU resources when doing this resource-intensive process. I have a workstation with 12 cores (24 threads) yet when I have AutoML hammering at my system for multiple minutes, I only see ~20-25% CPU usage with most of my cores sitting idle. Given that it is training many different models at once, shouldn\'t it be able to make use of every single core available, complete with SMT resources as well? Is this configurable somewhere?'"
478179523,4090,"b'[ImageClassification Transfer Learning] - Warning mesage: ""Allocation of 553190400 exceeds 10% of system memory.""'","b'Why are we getting this warning message (I get it multiple times) when training with a small set of images?\r\n\r\n""2019-08-07 09:49:52.642800: W tensorflow/core/framework/allocator.cc:107] Allocation of 553190400 exceeds 10% of system memory.""\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/62675361-9dac7b80-b95b-11e9-9afc-a6df5aedf4ca.png)\r\n\r\n'"
478178249,4089,"b'[ImageClassification Transfer Learning] - Warning mesage: ""Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2""'","b'When training with ImageClassifier/TransferLearning I get the following warning about the CPU instructions support (AVX2) from TF.NET or TensorFlow itself:\r\n\r\n`""2019-08-07 09:49:00.996153: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2""`\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/62665952-257f8f00-b936-11e9-8066-1bfe6aa70ee7.png)\r\n\t\t\r\nI get it from sample code directly written with Tensorflow.NET and code with ML.NET-Transfer-Learning (since it uses TF.NET)\r\n\r\nPossible actions to do:\r\n\r\n**1. Do not show this on the UI**\r\nIf possible, we shouldn\'t show this kind of warning as feedback on the UI (command line).but probably only in a log file. \r\n\r\nIt is a warning shown to the user but the user doesn\'t have anything actionable thing to do, so why showing it?\r\n\r\n**2. Research why and where this is happening and if we can avoid this warning with a different TensorFlow binary?**'"
478174763,4087,b'[ImageClassification Transfer Learning] Simplify/Hide steps and hyper-parameters in new ImageClassification - Transfer Learning ',"b'Since the new (early preview) \'ImageClassification - Transfer Learning\' is aimed to provide a high-level API per scenario (image classifciation in this case), we should simplify the API even further.\r\n\r\nHere\'s an example of a current training pipeline:\r\n\r\n```\r\n var pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                    .Append(mlContext.Transforms.LoadImages(""ImageObject"", null,\r\n                        ""ImagePath""))\r\n                    .Append(mlContext.Transforms.ResizeImages(""Image"",\r\n                        inputColumnName: ""ImageObject"", imageWidth: 299,\r\n                        imageHeight: 299))\r\n                    .Append(mlContext.Transforms.ExtractPixels(""Image"",\r\n                        interleavePixelColors: true))\r\n                    .Append(mlContext.Model.ImageClassification(""Image"",\r\n                        ""Label"", arch: DnnEstimator.Architecture.InceptionV3, \r\n                        epoch: 1, //an epoch is one learning cycle where the learner sees the whole training data set.\r\n                        batchSize: 20));  // batchSize sets then number of images to feed the model at a time\r\n```\r\n\r\nGood points to simplify are image transformations and ""technical"" hyper-paramenters:\r\n\r\n**1. Hide _image re-size_ step:** Since the image size is determined by the internal DNN model (TensorFlow model, currently) why don\'t we simply do it within the `ImageClassification` code?\r\n\r\n**2. Hide extract pixels step:** Same thing here. The extract pixels step should be hidden as part of the `ImageClassification` code. This is surfacing too much details. I expect the interleavePixelColors could also be determined by the info in the TF model .pb file, ot in the worst case based on the Architecture metadata that we could have per architecture (InceptionV3, etc.).\r\n \r\n**3. Hide EPOCH and BATCHSIZE:** These are also configuration details that, even when they currently have ""by default values"" (epoch=10 and batchSize=20), those values are not valid for *any* imageset and architecture and should vary depending on the specific image-set size and chosen architecture. I\'d be good to have them initialized dynamically within the `ImageClassification` code depending on the context instead of ""fixed default values"" and parameters that surface to the user who might not know what is an EPOCH or BATCH.\r\n\r\nAfter simplifying the above points, the example code could look like the following, which looks a lot simpler and clean: :)\r\n\r\n```\r\n var pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                    .Append(mlContext.Transforms.LoadImages(""ImageObject"", null, ""ImagePath""))\r\n                    .Append(mlContext.Model.ImageClassification(""ImageObject"", ""Label"", arch: DnnEstimator.Architecture.InceptionV3));  \r\n```\r\n\r\nEven the architecture should also be simplified and maybe letting the user select per type of images to be trained, such as: Photos vs. Numbers/Digits vs. other characteristics that make one or the other architecture advisable to be used. A regular .NET developer usually won\'t know if he/she should use InceptionV3 vs. ResnetV2101, etc.\r\n'"
478147052,4086,"b""Easy way to get model parameters of AutoML's best run ""","b""It seems like there is no straightforward way to let users exam AutoML best run's model parameters when using AutoML API in ML.NET at this point. \r\nThis is potentially important for uses who need to re-produce AutoML's best run in other platforms. \r\n"""
478128798,4085,b'YOLOv3 ApplyOnnxModel throws Protobuf exception',"b'### System information\r\n\r\n-  .NET Version: 2.2\r\n-  ML.NET Version: 1.2\r\n\r\n### Issue\r\n\r\nGiven the following pipeline for the YOLOv3 full ONNX model downloaded from the Model Zoo:\r\n\r\n```\r\nvar pipeline = _mlContext.Transforms.LoadImages(""input_1:01"", dataPath, ""ImagePath"")\r\n                .Append(_mlContext.Transforms.ResizeImages(""input_1:01"", 416, 416))\r\n                .Append(_mlContext.Transforms.ExtractPixels(""input_1:01""))\r\n                .Append(_mlContext.Transforms.ApplyOnnxModel(""concat_2:0"", ""input_1:01"", model\r\n```\r\n\r\nThe exception below is raised:\r\n\r\n```\r\nGoogle.Protobuf.InvalidProtocolBufferException: \'Protocol message was too large.  May be malicious.  Use CodedInputStream.SetSizeLimit() to increase the size limit.\'\r\n```'"
478117994,4084,"b'[ImageClassification Transfer Learning] Higher level API supporting image predictions based on image file paths and in-memory images, alternatively'","b'This is probably more for the long-term API of our ImageClassification Transfer Learning once the foundational features for our \'ImageClassification Transfer Learning\' are in place.\r\n\r\nHowever, this is the point:\r\n\r\nWe aim to design and implement a high level API which will provide a very straightforward way of training (transfer learning) image classification and other capabilities such as object detection, etc. That also means, and is equally important, to be able to score/predict very easily according to normal scenarios which for images are two scenarios:\r\n\r\n- A. Score based on a provided image file path.\r\n- B. Score based on an in-memory image.\r\n\r\nThe second choice (B) is even more common for many apps, even more when moving to OBJECT DETECTION and LIVE VIDEO/IMAGES coming as streaming.\r\n\r\n**CURRENT STATE IN ML.NET API**\r\n\r\nThe issue is with the current API design of ML.NET where the ML.NET model scoring API completely depends on the way you created its original pipeline and what schema you were using, meaning:\r\n\r\n- If you trained an ML.NET model with image file paths, your ML.NET model expects an image  file path for scoring.\r\n\r\n- If you trained an ML.NET model with in-memory images (not a common/straightforward approach), your ML.NET model expects an in-memory image (Bitmap) when scoring.  \r\n\r\nHowever, that\'s not the typical scenario for a user where the easiest way for training is using image filepaths (that\'s the way you usually have image sets, right?), but then when scoring/predicting the user should be able to provide either a file path or an in-memory image (in-memory is more common for end-user apps vs. filepaths for batch processes) and anything else should be transparent for him.\r\n\r\n**CURRENT WORKAROUND:**\r\n\r\nSure, you can always go deeper and deep dive in the TensorFlow .pb model that was also generated by our ""ImageClassification Transfer Learning"", find out the input and output tensor names, implement a different ML.NET pipeline that accepts in-memory images, create that ML.NET model by running that pipeline once (it is not really training, it is just creating the needed transformers for scoring later on) and finally writing a more specific and not very straightforward code for scoring with in-memory images.\r\n\r\nThat process is what I wrote in the second part of this BLOG POST and related sample app which is using an in-memory image coming through HTTP and was provided by the end-user for predicting its class:\r\n\r\nhttps://devblogs.microsoft.com/cesardelatorre/run-with-ml-net-c-code-a-tensorflow-model-exported-from-azure-cognitive-services-custom-vision/\r\n\r\nBut that code for scoring a TF model with in-memory images is not straightforward to implement.\r\n\r\n**INITIAL SOLUTION: Load images from files but convert them into in-memory image objects before loading it into the IDataView, so the schema would match for training and scoring**\r\n\r\nAn initial good solution is to Load images from files but convert them into in-memory image objects before loading it into the IDataView, so the data class for the schema would be something like the following:\r\n\r\nInstead of the following:\r\n\r\n```\r\n    public class ImageData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string ImagePath;\r\n\r\n        [LoadColumn(1)]\r\n        public string Label;\r\n    }\r\n```\r\n\r\nWe want to have something like this being used by the initial IDataView:\r\n\r\n```\r\n    public class ImageInputData\r\n    {\r\n        public Bitmap Image { get; set; }\r\n        \r\n        public string Label;\r\n    }\r\n```\r\n\r\nThat way, the ML.NET model\'s schema that we have when training would match the schema data class needed when scoring by only having an in-memory image without the user needing to go deeper and use the TensorFlow model .pb and creating his own pipeline for scoring, that I explin in this blog post but it is too complex if we want users to use a high-level API:\r\n\r\nhttps://devblogs.microsoft.com/cesardelatorre/run-with-ml-net-c-code-a-tensorflow-model-exported-from-azure-cognitive-services-custom-vision/\r\n\r\n**POSSIBLE FUTURE HIGH LEVEL API for Image Classification, ObjectDetection and other high level SCENARIOS**\r\n\r\nThe point is that we want to create high level APIs targeting SCENARIOS (Image Classification, ObjectDetection, etc.). That means the API to use for the mentioned use cases (training and scoring) should also be very simple. It is not acceptable to have such as complexity (see BLOG POST above) if you want to score with an in-memory image.\r\n\r\nSomehow we should solve the conflict between the current ML.NET pipeline API requirements (you score with the same schema you trained) and the points I explained above.\r\nWe probably will need to create a higher level API on top of the current pipelines API which would be more oriented to SCENARIOS (ImageClassification, Object Detection). The current API in the ML.NET pipelines doesn\'t probably allow what I\'m explaining.. \r\n\r\nAlso, that approach doesn\'t make our solution transparent to the underneath DNN architecture/framework (TensorFlow/Torch, etc.) since it needs the user to have specific code depending if he/she is using TensorFlow or Torch, because the user needs to take the ""under the covers"" TF .pb model and implement code for scoring which might also be specific for TensorFlow vs. Torch in the future. \r\n\r\nMoving forward, this discussion will be even more important for OBJECT DETECTION where in-memory image scoring is critical (streaming live video/images) while users might want to train based on image paths which is simpler.\r\n'"
478103897,4083,b'[ImageClassification Transfer Learning] Need simplified API for obtaining the List of predicted labels with their related scoring',"b'In the current implementation of ImageClassification Transfer Learning (but this also happens when scoring regular TensorFlow models) the list of predicted labels (usually categorical data of type string/text) with their related scoring (probability) is not straightforward to get. \r\n\r\nWe need a very simple and straightforward way of getting the best predicted values (such as categorical data) with their related probability.\r\n\r\nCurrently, in a typical ImagePrediction class you might have (such as in the sample link):\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bbb6b1560dbd67640cf9c4b41640e26769ee664d/docs/samples/Microsoft.ML.Samples/Dynamic/ImageClassification/InceptionV3TransferLearning.cs#L101\r\n\r\n```\r\n    public class ImagePrediction\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public float[] Score;\r\n\r\n        [ColumnName(""PredictedLabel"")]\r\n        public Int64 PredictedLabel;\r\n    }\r\n```\r\n\r\n1. First of all, the predicted label you get is a number (Int64) which is an **index**, not the value itself such as a categorical value. How is the user supposed to easily find out the text/categorical predicted label? - Sure, we might be able to find out through the schema API, but that is not straightforward.\r\n\r\n2. With the `PredictedLabel` field we\'re only getting **one** predicted label (so far, its index), but the user would  probably like to get an array with the ""best"" or even ""all"" predicted labels plus their correlated score/probability.\r\n\r\n3. The float[] array `Score` is precisely getting the probabilities for all the labels. But, how is the user supposed to easily be able to correlate those scores with their related labels (categorical values, for instance)?\r\n\r\n**ACTIONS MOVING FORWARD:**\r\n\r\n1. As initial step, the sample code above (or new sample) should show on the console output the list of all labels in their original form (categorical/text), or at least the best three predicted labels and their related score/probability. This should be done in the sample with the current API capabilities even if it is not straightforward to code for a user.\r\n\r\n2. Moving forward, since our goal is to create a simplified and high-level API for ImageClassification Transfer Learning, we should provide a way where such information is straightforward and **directly provided by the ""Prediction class""**.  '"
478091103,4082,b'Support stratify in TrainTestSplit() API',"b""Afaik, there's now way in ML.NET to split an original datasetset and create the two train/test datasets that are both balanced based on the LABEL/TARGET-CLASS or any other column (STRATIFICATION COLUMN). Am I right? \r\n\r\nI think this scenario is important so it is a lot easier to create balanced datasets that will provide a more reliable metrics when evaluating/testing a model.\r\n\r\n**Currently in Scikit-Learn:**\r\n\r\nFor instance, in  **ScitKit-Learn** you can do stratified\xc2\xa0sampling by\xc2\xa0splitting\xc2\xa0one data set so that each\xc2\xa0split\xc2\xa0are similar with respect to something. In a classification setting, it is often chosen to ensure that the train\xc2\xa0and\xc2\xa0test\xc2\xa0sets have approximately the same percentage of samples of each target class as the complete set.\r\n\r\nThis can be done in **ScitKit-Learn** with the stratify argument from **train_test_split()** where you can specify any column:\r\n\r\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\r\n\t\t\t\t\r\n```\r\nstratify\xc2\xa0:\xc2\xa0array-like or None (default=None)\r\nIf not None, data is split in a stratified fashion, using this as the class labels.\r\n```\r\n\t\r\n**Currently in ML.NET:**\r\n\t\t\t\t\r\nIn ML.NET in the [TrainTestSplit() API](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.traintestsplit?view=ml-dotnet) we have the **samplingKeyColumnName**, but that's kind of the opposite to 'Stratification column': \r\n\r\n_Name of a column to use for **grouping rows**. If two examples share the same value of the samplingKeyColumnName, they are guaranteed to appear in the same subset (train or test). This can be used to ensure no label leakage from the train to the test set. If null no row grouping will be performed._\r\n\r\nIt would be a good improvement for ML.NET to support a **stratify** feature in the [TrainTestSplit() API](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.traintestsplit?view=ml-dotnet)\r\n\r\nRELATED ISSUES:\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/2536 (In reality we didn't have stratification column, that was a wrong name. It was the current samplingKeyColumnName)\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/1204 (Here Pete was wrong by calling stratification column to a sampling Key Column Name or 'GroupPreservationColumn')"""
478079221,4080,b'[ImageClassification Transfer Learning] Need to improve training perf/time',"b""I know we're on the work for this issue but I just wanted to create an issue to track it down. \xf0\x9f\x91\x8d \r\n\r\nOur current performance/time needed for training when using the new [ImageClassification Transfer Learning](https://github.com/dotnet/machinelearning/pull/4057) is kind of huge compared to other frameworks, probably due to wrong approaches taken in the training process that can be solved soon.\r\n\r\nOn top of that we'll support GPU pretty soon, so that will improve training performace/time even further.\r\n\r\nHere are some comparisons with **TensorFlow.NET** vs. the new **ImageClassification Transfer Learning (Early preview)**:\r\n\r\n_A. ML.NET ImageClassification Transfer Learning training with 80 photo Files, 2 Folders/Categories_ --> It took 1,067 seconds --> **18 minutes**\r\n\r\n _b. TensorFlow.NET training with the same 80 photo Files, 2 Folders/Categories_ --> It took only **54 seconds (around 1 minute)**\r\n\r\nMeaning it was around 1,800% worse in training time (18 times worse).\r\n\r\nAnother test was:\r\nTF.NET training with 3,671 photo Files, 5 Folders/Categories (Flowers image set) --> It took 1,010 seconds (**16 minutes**) - I didn't test that with ML.NET ImageClassification Transfer Learning training since it would have taken hours.\r\n\r\n---\r\n\r\nDiscussing about it with Zeeshan, the issues and solutions for it have been identified and we expect to fix it pretty soon. \xf0\x9f\x91\x8d """
478015193,4078,b'Not possible to do object detection in UWP app due to lack of support for SoftwareBitmap image type',"b'ML.NET 1.3.0\r\n\r\nCurrently it\'s not possible to do object detection using ML.NET with live streamed video frames within a UWP app.  The issue is that the live streamed video frames are stored as SoftwareBitmap types in UWP - for example:\r\n\r\n```Csharp\r\nSoftwareBitmap softwareBitmap = SoftwareBitmap.Convert(e.VideoFrame.SoftwareBitmap, BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied);\r\n```\r\n\r\nWhen attempting to use ML.NET to setup a model, the input schema for the image must instead be System.Drawing.Bitmap.  For example:\r\n\r\n```Csharp\r\n var dataView = _mlContext.Data.LoadFromEnumerable(new List<ImageInputData>());\r\n\r\n            var pipeline = _mlContext.Transforms.ResizeImages(resizing: ImageResizingEstimator.ResizingKind.Fill, outputColumnName: ""image"", imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n                            .Append(_mlContext.Transforms.ExtractPixels(outputColumnName: ""image""))\r\n                            .Append(_mlContext.Transforms.ApplyOnnxModel(modelFile: onnxModelFilePath, outputColumnNames: new[] { TinyYoloModelSettings.ModelOutput }, inputColumnNames: new[] { TinyYoloModelSettings.ModelInput }));\r\n\r\n            var mlNetModel = pipeline.Fit(dataView);\r\n\r\n\xe2\x80\xa6.\r\n\r\n{\r\n    public class ImageInputData\r\n    {\r\n        [ImageType(416, 416)]\r\n        public Bitmap Image { get; set; }\r\n    }\r\n```\r\n\r\nIf you attempt to use SoftwareBitmap for the image type in the ImageInputData class, you get the following exception:\r\n\r\nException thrown: \'System.ArgumentOutOfRangeException\' in System.Private.CoreLib.dll\r\nCould not determine an IDataView type for member Image\r\n\r\nThe issue here is that ML.NET only supports System.Drawing.Bitmap.  However, System.Drawing.Bitmap isn\'t available in UWP - instead, UWP uses SoftwareBitmap.\r\n\r\n\r\n'"
477950724,4077,"b""Can't pass TransformerChain to AnomalyDetection.ChangeModelThreshold ""","b""ML.NET v1.3.1\r\n\r\n[AnomalyDetectionCatalog.ChangeModelThreshold](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/TrainCatalog.cs#L715-L721) was [added](https://github.com/dotnet/machinelearning/pull/4039) to fix issue [3990](https://github.com/dotnet/machinelearning/issues/3990).  However, I believe it should also support passing in an `ITransformerChain` where the LastTransformer is a `AnomalyPredictionTransformer` in addition to a single `AnomalyPredictionTransformer`.\r\n\r\nBecause `ChangeModelThreshold` must be [called after](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/AnomalyDetectionTests.cs#L197-L199) `Fit`, in most real-world scenarios users will likely have a [`TransformerChain` instead of a single `ITransformer`](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection/CreditCardFraudDetection.Trainer/Program.cs#L143).  But as `ChangeModelThreshold` is currently implemented, it can't be used in this context."""
477941567,4076,"b""RandomizedPcaChangeThreshold test doesn't test threshold change""","b""The [RandomizedPcaChangeThreshold](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/AnomalyDetectionTests.cs#L82-L110) test doesn't actually test changing the `Threshold`.  I believe [line 109](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/AnomalyDetectionTests.cs#L109) shoule be [`ExecuteRandomizedPcaTrainerChangeThreshold`](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/AnomalyDetectionTests.cs#L179) instead of `ExecutePipelineWithGivenRandomizedPcaTrainer`.\r\n"""
477933115,4075,b'alexnet fails with exception',"b'I am using ML.NET to get features for images using AlexNet. It was working a few month back but when I try it with the latest ML.NET bits it fails . There were some API changes that I tried to address but the most recent error I am getting is:\r\n\r\n>  \'[ErrorCode:Fail] Load model from ...\\DnnImageModels\\AlexNetOnnx\\AlexNet.onnx failed:[ShapeInferenceError] Attribute pads has incorrect size\'\r\n\r\n\r\nHere is the code snippet:\r\n\r\n```\r\n        static string _Run(string imagesCatalog, string imagesFolder)\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n \r\n\r\n            var cols = new[] {\r\n                        new TextLoader.Column(""ImagePath"", DataKind.String, 0),\r\n                        new TextLoader.Column(""Label"", DataKind.Int32, 1),\r\n                };\r\n\r\n \r\n\r\n            var data = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = cols\r\n            }).Load(imagesCatalog);\r\n\r\n \r\n\r\n            var pipeline = mlContext.Transforms.LoadImages(imageFolder:imagesFolder, outputColumnName: ""ImageReal"", inputColumnName: ""ImagePath"")\r\n            .Append(mlContext.Transforms.ResizeImages(outputColumnName:""ImageObject"", inputColumnName:""ImageReal"", imageWidth: 227, imageHeight: 227))\r\n            .Append(mlContext.Transforms.ExtractPixels(""Pixels"", ""ImageObject""))\r\n            .Append(mlContext.Transforms.DnnFeaturizeImage(""FeaturizedImage"", m => m.ModelSelector.AlexNet(mlContext, m.OutputColumn, m.InputColumn), ""Pixels""));\r\n\r\n      var transformedData = pipeline.Fit(data).Transform(data);\r\n\r\n```\r\n     the exception is fired in     \r\n\r\n> AlexNet(mlContext, m.OutputColumn, m.InputColumn), ""Pixels""))   \r\n\r\n \r\n\r\n       \r\n\r\n### System information\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.302\r\n Commit:    9048955601\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.14393\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.302\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.2\r\n  Commit:  811c3ce6c0\r\n\r\n.NET Core SDKs installed:\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.302 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n\r\n'"
477655042,4074,"b'French stopword ""les"" is misspelled'","b'The word ""les"" is a stopword in French, but it is misspelled ""l\xc3\xa8s"" in the [French.txt](https://github.com/dotnet/machinelearning/blob/a802127883c0020516aa573436029cabed65d591/src/Microsoft.ML.Transforms/Text/StopWords/French.txt#L27) file. I\'d have fixed it directly there, but the repo is configured to only take changes on a branch.'"
477560950,4072,b'[AutoML] AutoML.NET API/CLI cross val fails when one the scores is -infinity.',b'\r\n'
477074513,4065,b'TensorFlow exception triggered while loading model',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10.0.17763 Enterprise (version: 1809) (x64)\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Framework 4.7.2 (.NET Core 3.0.0-preview3-27503-5)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have tried to load the custom tensorflow model of YoloV2 full.\r\n- **What happened?**\r\nLoading of tensorflow model failed with an generic error.\r\n- **What did you expect?**\r\nModel to be succesfully loaded and used for object detection. As my model was converted via DarkFlow without any errors.\r\n\r\n### Source code / logs\r\n ```\r\n      // Create IDataView from empty list to obtain input data schema\r\n      var data = mlContext.Data.LoadFromEnumerable(new List<ImageNetData>());\r\n\r\n      // Define scoring pipeline\r\n      var pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""input"", imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath))\r\n                      .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""input"", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: ""input""))\r\n                      .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""input""))\r\n                      .Append(mlContext.Model.LoadTensorFlowModel(modelLocation)\r\n                      .ScoreTensorFlowModel(outputColumnNames: new[] { ""output"" }, inputColumnNames: new[] { ""input"" }, addBatchDimensionInput: true));\r\n\r\n      // Fit scoring pipeline\r\n      var model = pipeline.Fit(data);\r\n```\r\n\r\nTensorFlow exception triggered while loading model from \'C:\\Users\\Peter\\source\\repos\\NeuralLink\\NeuralLink\\bin\\Debug\\XXXX.pb\'\r\n\r\n   at Microsoft.ML.Transforms.TensorFlow.TensorFlowUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   at Microsoft.ML.TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog catalog, String modelLocation)\r\n   at NeuralLink.Core.TensorFlowModelScorer.LoadModel() in C:\\Users\\Peter\\source\\repos\\NeuralLink\\NeuralLink\\Core\\TensorFlowModelScorer.cs:line 46\r\n   at NeuralLink.Pages.Analyze.<UserControl_Initialized>d__7.MoveNext() in C:\\Users\\Peter\\source\\repos\\NeuralLink\\NeuralLink\\Pages\\Analyze.xaml.cs:line 156\r\n\r\n_This is a seriouse flaw in ML.NET, I was expecting that it can load any VALID tensorflow model. I can post my model and some training images in case you want to investigate._\r\n'"
477013757,4064,b'[AutoML] Take dependency on ML utilities from ML.Core instead of a copy in AutoML using BestFriends',"b""Due to historical reasons we have copies of utility classes from ML.Core in AutoML.  I removed some of them and the system is set up to use ones from ML.Core, but some had non-trivial changes and I left them as-is to derisk current release.  In addition, some of them are used in the test project and we're not currently set up to take those references from tests."""
476882020,4063,b'What type is the input model file',"b'The model input file is\nMicrosoft.ML.SamplesUtils.DatasetUtils.DownloadTensorFlowSentimentModel().\nIs this a zip, a graph , or what? \nDoes it contain pretrained weights?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 3459698d-76c3-c04b-de13-edafd11d8859\n* Version Independent ID: 0aa1e091-1935-850b-af62-c1f14a7bc6fc\n* Content: [TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog, String) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.tensorflowcatalog.loadtensorflowmodel?view=ml-dotnet#Microsoft_ML_TensorflowCatalog_LoadTensorFlowModel_Microsoft_ML_ModelOperationsCatalog_System_String_)\n* Content Source: [dotnet/xml/Microsoft.ML/TensorflowCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TensorflowCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
476827872,4062,b'Tensorflow Input Shape Mismatch',"b'### System information\r\n\r\n- **OS version/distro**: Linux Mint 19.1 Cinnamon\r\n- **.NET Version (eg., dotnet --info)**: 2.2.401\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to run tensorflow image detection model which retrained by ""faster_rcnn"" or ""ssd_mobilenet_v2"".\r\n\r\n- **What happened?**\r\n But i got ""Input Shape Mismatch"" error. I considered this error is about PixelExtractor and i tried changing some parameters of it.\r\n\r\n- **What did you expect?**\r\nI expected get a float array of predicted boxes, or number of detection.\r\n\r\n### Source code / logs\r\n- My code:\r\n```c#             \r\nvar pipeline =mlContext.Transforms.ResizeImages(outputColumnName: TensorFlowModelSettings.inputTensorName, imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n.Append(mlContext.Transforms.ExtractPixels(outputColumnName: TensorFlowModelSettings.inputTensorName, interleavePixelColors: ImageSettings.channelsLast, offsetImage: ImageSettings.mean,outputAsFloatArray:false,colorsToExtract: ImagePixelExtractingEstimator.ColorBits.All))\r\n.Append(mlContext.Model.LoadTensorFlowModel(modelPath).\r\nScoreTensorFlowModel(outputColumnNames: new[] { TensorFlowModelSettings.outputTensorName },\r\n                     inputColumnNames: new[] { TensorFlowModelSettings.inputTensorName }, addBatchDimensionInput: false));\r\n\r\n\r\n            var model = pipeline.Fit(CreateEmptyDataView());\r\n            return model;\r\n```\r\n- The error message:\r\n> System.InvalidOperationException: Input shape mismatch: Input \'image_tensor\' has shape [?, ?, ?, 3], but input data is of length 206116.\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper..ctor(TensorFlowTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.MakeRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.GetOutputSchema(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.TensorFlowEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n\r\n> ### Annotation: When i was try an image classification model,  got an output successfully.'"
476273919,4058,b'DetectSpikeBy(Ssa|Iid) confidence param should be double',"b'This one is pretty simple. Confidence parameter in `DetectIidSpike` & `DetectSpikeBySsa` should be of type `double`. It makes no sense that it is of type `Int32` since it is being cast to `double` when creating `SsaSpikeDetector.Options()` anyway.\r\n\r\nSame thing goes for `DetectChangePointBySsa`, `DetectIidChangePoint` and possibly others.\r\n\r\nRight now it is not possible to search only for ""extreme spikes"" (confidence = ~99.9 or even more) using these extension methods.\r\n\r\nThanks\r\nEsso'"
475976200,4055,b'Make Microsoft.ML.Ensemble internals visible to NimbusML DotNetBridge',"b'Required for adding Ensemble trainers to NimbusML, which is required by Azure ML.'"
475935552,4053,b'Torch support in ML.NET',"b""As ML.NET increases it's support for deep learning, we should add support for PyTorch models.\r\n[TorchSharp](https://github.com/xamarin/TorchSharp) has bindings for LibTorch (PyTorch's C++ frontend) and offers the following functionality:\r\n\r\n- Score models that were previously defined and trained in PyTorch's python API\r\n- Define and train models directly in C#\r\n\r\nWe could have a scoring functionality similar to the TensorFlow scoring. We could also add training of Torch models defined in C#. """
475908260,4052,b'Possible new feature: Support Azure Data Lake Storage as source of datasets for training a model',"b""For Big Data customers using Azure Datalake Storage it would be very interesting to be able to use their data directly from their sources in Azure Datalake Storage when in need to train with large datasets. See:\r\n\r\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction\r\n\r\nThis feature would be another type of 'Loader' in ML.NET."""
475638693,4051,b'LightGBM is producing different multiclass scores after loading saved model',"b'### System information\r\n\r\nWindows 10\r\nMicrosoft.ML (1.2.0)\r\nMicrosoft.ML.LightGbm (1.2.0)\r\n.NET Core 2.2\r\n\r\n### Issue\r\n\r\nAfter training a lightgbm model, the model is producing multiclass scores between [0, 1] which totals 1, as expected. \r\n\r\nHowever, after saving the model, then loading it into a new trainedModel object - the scores are now not probabilities, but decimal values. \r\n\r\nI have tested the saving and loading with other model types and I cannot replicate the results. It is only the case with the lightgbm model.\r\n\r\nPlease advise. I am now attempting to rollback library versions to see if it\'s still an issue\r\n\r\n### Source code / logs\r\n\r\n**Before saving model...**\r\n0.003305528\r\n0.01293249\r\n0.01907223\r\n0.9646355\r\n5.421485E-05\r\n3.556848E-08\r\n\r\n**After saving model...**\r\n-3.623514\r\n-2.259367\r\n-1.870877\r\n2.05264\r\n-7.733911\r\n-15.06316\r\n\r\n![image](https://user-images.githubusercontent.com/7580312/62291047-bcda7300-b45a-11e9-8918-1ab8bbb17d98.png)\r\n\r\n\r\nSource code\r\n\r\n\r\nmlContext.Model.Save(trainedModel, dataView.Schema, _modelPath);\r\n\r\n            // Save Data Prep transformer\r\n            //mlContext.Model.Save(pipeline, dataView.Schema, ""data_preparation_pipeline.zip"");\r\n\r\n            schema = dataView.Schema;\r\n\r\n            Console.WriteLine(""Before saving model..."");\r\n            TestModelOutput(mlContext, trainedModel);\r\n\r\n            // Load trained model\r\n            trainedModel = mlContext.Model.Load(_modelPath, out schema);\r\n            //trainedModel = mlContext.Model.LoadWithDataLoader()\r\n\r\n            Console.WriteLine(""After saving model..."");\r\n            TestModelOutput(mlContext, trainedModel);\r\n\r\n private static void TestModelOutput(MLContext mlContext, ITransformer model)\r\n        {\r\nIDataView batchData = mlContext.Data.LoadFromEnumerable(testActions);\r\n\r\n            IDataView predictions = model.Transform(batchData);\r\n\r\n            IEnumerable<PredictionData> predictedResults = mlContext.Data\r\n                .CreateEnumerable<PredictionData>(predictions, reuseRowObject: false);\r\n\r\n            foreach (var item in predictedResults)\r\n            {\r\n                foreach (var score in item.Score)\r\n                {\r\n                    Console.WriteLine(score);\r\n                }\r\n                \r\n            }\r\n}\r\n\r\n'"
474568845,4048,"b""System.ArgumentOutOfRangeException : Could not find input column 'SamplingKeyColumn'""","b'### System information\r\n\r\n- **Win10/distro**:\r\n- **.NET Version Core 2.1**: \r\n\r\n### Issue\r\n\r\nWhen I am running my RefitBestPipeline function. i.e my function to run my model over the entire data I got this error.\r\n\r\nMessage: System.ArgumentOutOfRangeException : Could not find input column \'SamplingKeyColumn\'\r\nParameter name: inputSchema\r\n\r\nThis is some internal error I am calling the same load and transfer function that I used to build my model.\r\n\r\n### Source code / logs\r\nprivate ITransformer RefitBestPipeline(ExperimentResult<RegressionMetrics> experimentResult)\r\n        {\r\n            DebugHelper.WriteHeader(""=============== Re-fitting best pipeline ==============="");\r\n            //var textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n            //_trainDataView = _mlContext.Data.LoadFromEnumerable<T>(trainingCollection);\r\n            //_testDataView = _mlContext.Data.LoadFromEnumerable<T>(testCollection);\r\n\r\n            //IEnumerable<T> allData = trainingCollection.Concat(testCollection);\r\n            //IDataView allDataView = _mlContext.Data.LoadFromEnumerable<T>(testCollection);          \r\n            // Generate the dataview for all of the data\r\n            LoadData(_modelInput.TrainingCollection);\r\n            TransformData();\r\n\r\n            //var combinedDataView = textLoader.Load(new MultiFileSource(TrainDataPath, TestDataPath));\r\n            RunDetail<RegressionMetrics> bestRun = experimentResult.BestRun;\r\n\r\n            return bestRun.Estimator.Fit(_trainDataView); // pass in the data view for all of the data.\r\n        }\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
474287345,4047,"b'Improve ""Invalid TValue"" error message'","b'When throwing ""Invalid TValue"" runtime errors, we tell users which type they entered, but don\'t tell the user the type that is needed. We tell them their current type is wrong, but not the right type.\r\n\r\nThere are current [23 places](https://github.com/dotnet/machinelearning/search?q=%22Invalid+TValue%22&unscoped_q=%22Invalid+TValue%22) we throw this error. Our most common is when calling a `GetGetter()`.\r\n\r\nThe one I\'m hitting at the moment:\r\nhttps://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.Data/Data/DataViewUtils.cs#L1128\r\n\r\n## Task:\r\nTo make this more actionable, we should tell the user which type is needed for the column type.'"
474172450,4046,b'CMake error during build if path contains spaces',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan **build.cmd** in root folder in a VS 2019 developer command prompt.\r\n\r\n- **What happened?**\r\nBuild failed with error:\r\n\r\n> EXEC : CMake error : The following variables are used in this project, but they are set to NOTFOUND. [C:\\Users\\micro\\OneDrive - X-treem Software\\Development\\Repos\\General\\Frameworks\\ML.NET\\src\\Native\\build.proj]\r\n>   -- Configuring incomplete, errors occurred!\r\n>   See also ""C:/Users/micro/OneDrive - X-treem Software/Development/Repos/General/Frameworks/ML.NET/bin/obj/x64.Debug/Native/CMakeFiles/CMakeOutput.log"".\r\n>   Please set them or make sure they are set and tested correctly in the CMake files:\r\n>   MKL_LIBRARY\r\n>       linked by target ""SymSgdNative"" in directory C:/Users/micro/OneDrive - X-treem Software/Development/Repos/General/Frameworks/ML.NET/src/Native/SymSgdNative\r\n>       linked by target ""MklProxyNative"" in directory C:/Users/micro/OneDrive - X-treem Software/Development/Repos/General/Frameworks/ML.NET/src/Native/MklProxyNative\r\n\r\nIf I move the code to a path without spaces such as C:\\Users\\micro\\OneDrive\\ML.NET, it builds successfully.  This problem was also described by [another user](https://github.com/dotnet/machinelearning/issues/28#issuecomment-480867654) on issue #28 and @eerhardt described the solution in [his reply](https://github.com/dotnet/machinelearning/issues/28#issuecomment-480911525).\r\n\r\n- **What did you expect?**\r\nBuild to succeed regardless of spaces in path.\r\n\r\n### Source code / logs\r\n[build.log](https://github.com/dotnet/machinelearning/files/3774335/build.log)'"
474128196,4045,"b'Common issue Only supported feature column types are Boolean, Single, and String. '","b""### System information\r\n\r\n\r\n- **OS version Windows 10 /distro**:\r\n- **.NET Version (.NET Core 2.1)**: \r\n\r\n### Issue\r\nI have removed the unsupported column types in my data but I am still getting this message\r\n\r\nMessage: System.ArgumentException : Only supported feature column types are Boolean, Single, and String. Please change the feature column IntMonth of type Int32 to one of the supported types.\r\nParameter name: trainData\r\nThe problem is that the conversions and drop columns are not converting and dropping the columns as they are not operating on the correct object.\r\nHow can I get the int32 and double columns removed?\r\nHow can I do this please?\r\nHere is some example code that \r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nprivate void TransformData()\r\n        {\r\n            var dataProcessPipeline = _mlContext.Transforms.DropColumns(_modelInput.KeyFeatureToIgnore);\r\n            PropertyInfo propertyInfo;\r\n\r\n            foreach (string feature in _includedFeatureNames)\r\n            {\r\n                propertyInfo = _allFeaturesPropertyInfo.Find(x => x.Name == feature);\r\n                if (typeof(Double) == propertyInfo.PropertyType)\r\n                {\r\n                    dataProcessPipeline.Append(_mlContext.Transforms.Conversion.ConvertType(feature, feature, DataKind.Single));\r\n                }\r\nelse if (typeof(Int32) == propertyInfo.PropertyType)\r\n                {\r\n                    dataProcessPipeline.Append(_mlContext.Transforms.Conversion.ConvertType(feature, feature, DataKind.Single));\r\n                }\r\n                dataProcessPipeline.Append(_mlContext.Transforms.NormalizeMeanVariance(feature, useCdf: false));\r\n            }\r\n\r\n            // Now we can transform the data and look at the output to confirm the\r\n            // behavior of the estimator. This operation doesn't actually evaluate\r\n            // data until we read the data below.\r\n            var tansformer = dataProcessPipeline.Fit(_trainDataView);\r\n\r\n            _trainDataView = tansformer.Transform(_trainDataView);\r\n\r\n            var trainDataViewSchemaTest = _trainDataView.Schema;\r\n            \r\n            \r\n        }\r\n"""
473719092,4044,b'AutoML execute with preFeaturizer should accept Int32 and so',"b""### System information\r\n\r\nMicrosoft.ML.AutoML (0.14.0)\r\n\r\n### Issue\r\n\r\n**TL;DR:** `ExperimentBase.Execute` with non-null `preFeaturizer` argument should check the schema types **after** transforming the `preFeaturizer`.\r\n\r\n----\r\n\r\nI have a flattened object with `long` and `int` fields that I load it to an `IDataView`.\r\nIf I want to `Execute` an experiment for this `dataView`, I get this expeption:\r\n\r\n> **System.ArgumentException:** 'Only supported feature column types are Boolean, Single, and String. Please change the feature column Feature1 of type Int64 to one of the supported types.\r\nParameter name: trainData'\r\n\r\nSo, I have to create an `EstimatorChain` to `ConvertType` from `long` to `Single`, and `Fit` then `Transform` the `dataView`.\r\n\r\nLet's say I have this `EstimatorChain` to transform these types. Now I have two options:\r\n\r\n 1. Transform the `dataView` **before** passing it to the `Execute` method.  \r\nWith this option, the problem is that I have to create a class that fit to the new schema, if I want to save the model and use it latter.  \r\n(The first generic type in `CreatePredictionEngine` must be appropriated to the `inputSchema`)\r\n 2. Pass this `EstimatorChain` as `preFeaturizer` argument in the `Execute` method.  \r\nBut this is not a real solution because the `Execute` method **still throws the exception above!**"""
473464013,4042,b'Consider adding machinelearning-samples ConsoleHelper funcitonality ',"b'Several of the samples in the [machinelearning-samples](https://github.com/dotnet/machinelearning-samples) repo make extensive use of a shared [ConsoleHelper](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/common/ConsoleHelper.cs) to visualize the data or metrics.  Consider exposing the functionality provided by the ConsoleHelper class inside ML.NET itself.  For example, expose as static methods on the corresponding metrics objects returned by Evaluate, as well as IDataView and Preview.'"
473460332,4041,"b'Need clarity on concept of key type, including info on using Hashing to create the key type'","b'When learning about machine learning in general, I didn\'t see reference to a \'key type\' outside of ML.NET - as a result, this concept was difficult for me to understand from the current description provided in the docs.\r\n\r\nIt would be better to provide an example that clarifies how and why a key type is needed.  The example that someone shared with me and that I found to be helpful, is this:\r\n* When you use MapValueToKey, it ""learns"" the keys based on the training set.\r\n* Using the U.S. States as an example, it ""learns"" that ND maps to 1, MN to 2, SD to 3, etc.\r\n* And, when you see a new value in the test set that isn\'t in the training set, it will map it to an ""unknown"" key (e.g. 0)\r\n\r\nAnother way to make a KeyType is to use Hashing.  This should also be mentioned and explained in the docs alongside the description of KeyTypes.'"
472768699,4038,"b'Microsoft.ML.Transforms.TensorFlow.TFException: ""Expected image (JPEG, PNG, or GIF), got unknown format starting with \'2552162552240167\' \t [[{{node map/while/DecodePng}}]]"" when trying to use Attention-OCR model'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Issue\r\n\r\nGetting `Microsoft.ML.Transforms.TensorFlow.TFException: ""Expected image (JPEG, PNG, or GIF)` error when trying to predict with OCR model created with the [Attention-OCR Github Repository](https://github.com/emedvedev/attention-ocr) (written in Tensorflow).\r\n\r\n### Source code / logs\r\n\r\nModelUtils.cs:\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing OCRWithMLNET.ImageDataStructures;\r\nusing System.Diagnostics;\r\nusing System.IO;\r\nusing System.Drawing;\r\nusing System.Drawing.Imaging;\r\n\r\nnamespace OCRWithMLNET\r\n{\r\n    public static class ModelUtils\r\n    {\r\n\r\n        public struct ImageSettings\r\n        {\r\n            public const int imageHeight = 224;\r\n            public const int imageWidth = 224;\r\n            public const float mean = 117;\r\n            public const bool channelsLast = true;\r\n        }\r\n\r\n        public struct TensorFlowModelSettings\r\n        {\r\n            // input tensor name\r\n            public const string inputTensorName = ""input_image_as_bytes"";\r\n\r\n            // output tensor name\r\n            public const string outputTensorName = ""prediction"";\r\n        }\r\n\r\n        public static PredictionEngine<ImageInputData, ImageLabelPredictions> loadModel(string modelLocation)\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n            var data = CreateEmptyDataView(mlContext);\r\n\r\n            var pipeline = mlContext.Transforms.Concatenate(""input_image_as_bytes"", new string[] { ""input_image"" })\r\n                            .Append(mlContext.Model.LoadTensorFlowModel(modelLocation).\r\n                            ScoreTensorFlowModel(outputColumnNames: new[] { ""prediction"" },\r\n                                                inputColumnNames: new[] { ""input_image_as_bytes"" }, addBatchDimensionInput: false));\r\n\r\n            ITransformer model = pipeline.Fit(data);\r\n\r\n            var predictionEngine = mlContext.Model.CreatePredictionEngine<ImageInputData, ImageLabelPredictions>(model);\r\n\r\n            return predictionEngine;\r\n        }\r\n\r\n        private static IDataView CreateEmptyDataView(MLContext mlContext)\r\n        {\r\n            //Create empty DataView. We just need the schema to call fit()\r\n            List<ImageInputData> list = new List<ImageInputData>();\r\n            IEnumerable<ImageInputData> enumerableData = list;\r\n            var dv = mlContext.Data.LoadFromEnumerable(enumerableData);\r\n            return dv;\r\n        }\r\n\r\n        public static void makePredictions(PredictionEngine<ImageInputData, ImageLabelPredictions> model, string[] imgPaths)\r\n        {\r\n            int i = 0;\r\n            foreach (var path in imgPaths)\r\n            {\r\n                ImageInputData sample = new ImageInputData()\r\n                {\r\n                    input_image = string.Join("""", File.ReadAllBytes(path))\r\n                    //input_image = Convert.ToBase64String(File.ReadAllBytes(path))\r\n                };\r\n                Stopwatch sw = new Stopwatch();\r\n                sw.Start();\r\n                model.Predict(sample);\r\n\r\n                //Console.WriteLine(prediction.PredictedLabels);\r\n\r\n                i++;\r\n\r\n                sw.Stop();\r\n\r\n                Console.WriteLine(""Elapsed={0}"", sw.Elapsed.TotalMilliseconds);\r\n            }\r\n        }\r\n\r\n        public static string ImageToString(this Image image)\r\n        {\r\n            if (image == null)\r\n                return String.Empty;\r\n\r\n            var stream = new MemoryStream();\r\n            image.Save(stream, image.RawFormat);\r\n            var bytes = stream.ToArray();\r\n\r\n            return Convert.ToBase64String(bytes);\r\n        }\r\n    }\r\n}\r\n```\r\nImageInputData.cs:\r\n```\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\n\r\nnamespace OCRWithMLNET.ImageDataStructures\r\n{\r\n    public class ImageInputData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string input_image;\r\n    }\r\n}\r\n```\r\n\r\nImageLabelPredictions.cs\r\n```\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace OCRWithMLNET.ImageDataStructures\r\n{\r\n    public class ImageLabelPredictions\r\n    {\r\n        [ColumnName(ModelUtils.TensorFlowModelSettings.outputTensorName)]\r\n        public string[] PredictedLabels;\r\n    }\r\n}\r\n```\r\n\r\nProgramm.cs\r\n```\r\nusing System;\r\nusing Microsoft.ML;\r\nusing OCRWithMLNET.ImageDataStructures;\r\n\r\nnamespace OCRWithMLNET\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            PredictionEngine<ImageInputData, ImageLabelPredictions>  model = ModelUtils.loadModel(""<path>/frozen_graph.pb"");\r\n\r\n            string[] inputArr = new string[1] { ""img.png"" };\r\n\r\n            ModelUtils.makePredictions(model, inputArr);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n### Additional Information\r\n\r\nIt suspect that it has to do with the way I load in the image. I also tried loading it in with base64 encoding but this didn\'t work either.\r\n\r\nIn Python I can load the image in like this:\r\n```\r\nwith open(filename, \'rb\') as img_file:\r\n    img_file_data = img_file.read()\r\n```\r\n\r\n'"
472378150,4036,b'Need to explicitly call out that the IEnumerable needs to be thread-safe',"b""See the conversation starting at https://github.com/dotnet/machinelearning/issues/2159#issuecomment-513271843 and continuing from there.\n\nML.NET supports multiple threads reading from the same IDataView instance. For example, when using an SDCA trainer, by default it will train on multiple threads on a machine with more than 2 processors. When using `LoadFromEnumerable` on an IEnumerable that doesn't support multiple threads (like in the issue - using an EF query), ML.NET will still try to access the IDataView from multiple threads, and the underlying IEnumerable can throw, or have some other undefined behavior.\n\nWe should explicitly call this limitation out in the docs, and inform users of this method that the IEnumerable being returned needs to be thread-safe.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 10e8d5aa-2038-a382-ec86-cf8ad031f996\n* Version Independent ID: 81198dc9-ddf4-cef1-c178-82f50f0e7a46\n* Content: [DataOperationsCatalog.LoadFromEnumerable Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.loadfromenumerable?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
471710154,4034,b'Onnx Support for String Tensors?',"b'### System information\r\n\r\nWindows 10 - \r\n.NET Core 2 - ML.NET 1.2\r\n\r\n### Issue\r\n\r\nIs there any timeline for allowing string tensors to be used in Onnx models within ML.NET?  Tried both InferenceSession and pipeline ApplyOnnxModel and keep hitting in the \r\n\r\npublic static NamedOnnxValue CreateNamedOnnxValue<T>(string name, ReadOnlySpan<T> data, OnnxShape shape)\r\n        {\r\n            if (!_onnxTypeMap.Contains(typeof(T)))\r\n                throw new NotImplementedException($""Not implemented type {typeof(T)}"");\r\n            return NamedOnnxValue.CreateFromTensor<T>(name, new DenseTensor<T>(data.ToArray(), shape.Select(x => (int)x).ToArray()));\r\n        }\r\n\r\nBecause onnxTypeMap does not support string.\r\n\r\nMy OnnxModel takes input of string and output of long+float.\r\n'"
471602591,4033,b'Unable to infer column types of the file provided',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 / Visual Studio Professinal 2017 15.9.14\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\nI would like to thank all of you for your excellent work\r\n\r\n- **What did you do?** I'm trying to load a csv file from my desktop to ML Model Builder\r\n- **What happened?** An error appears (snapshot attached)\r\n- **What did you expect?** I loaded the csv file correctly from RStudio (snapshot attached)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are \r\n![0](https://user-images.githubusercontent.com/53216682/61702396-041c8180-ad40-11e9-93e3-de705569cd62.PNG)\r\n![1](https://user-images.githubusercontent.com/53216682/61702398-041c8180-ad40-11e9-8803-e4213f2e5945.PNG)\r\n\r\n"""
471033680,4032,b'Integrate with LibSVM',"b'The LibSVM library supports multiple kinds of SVMs, including anomaly detection, binary and multiclass classification, and regression.\r\nhttps://www.csie.ntu.edu.tw/~cjlin/libsvm/\r\n'"
471032313,4031,b'Add a Local Deep Kernel Learning trainer',b'http://manikvarma.org/pubs/jose13.pdf\r\n'
471031438,4030,b'Integrate with Bonsai/ProtoNN',b'Integrate with the EdgeML package:\r\nhttps://github.com/microsoft/EdgeML\r\n'
470680797,4028,b'Upsampling with IDataView',"b""Upsampling is a common practice for unbalanced data sets. The best practice for upsampling is to upsample the training set AFTER splitting into train and test sets, because if you duplicate rows before splitting, you'll get identical rows in the train and test set.  This is data leakage from the train to the test set, and if you overfit the training set it will be partially hidden by the identical rows in the test set pumping up the scores.\r\n\r\nThere is no Upsampling transformer, so far as I can find.  If I use the built-in TrainTestSplit method, I get two IDataViews back.  Now I can't upsample by adding/duplicating rows in the training set because IDataView is immutable.\r\n\r\nSo basically I have to load from text file myself, because if I use TextLoader I get an IDataView which puts me in the same predicament.  Next, I have to reproduce the functionality in TrainTestSplit(), in order to split my original dataset myself into train and test split.  Next, I have to upsample the training set myself, and then remember to separately run both the train and test split through the regular data pipeline I've created.  \r\n\r\nI can't see how the CustomTransform can be used to Upsample.  How would you suggest is the correct way to upsample a data set with ML.Net?  Like a nice, convenient way.  Not an arduous solution like I mentioned above, which will just drive people back to python instead."""
470679264,4027,b'InvalidProtocolBufferException: Protocol message was too large.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro v1803, build 17134.885\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2.108\r\n\r\n### Issue\r\n\r\n- **What did you do?** Attempted to load an ONNX model\r\n- **What happened?** It failed: InvalidProtocolBufferException: Protocol message was too large. May be malicious. Use CodedInputStream.SetSizeLimit() to increase the size limit.\r\n- **What did you expect?** For the model to load successfully.\r\n\r\n### Source code / logs\r\n\r\nThe model is a pre-trained resnet34 trained on the MNIST handwritten digits database. The model was exported from pytorch.\r\n\r\nI assume the .onnx file is valid, as I can view it without any issues at https://lutzroeder.github.io/netron/\r\n\r\nI\'d attach the file itself but github won\'t allow me, the filesize is 83.3MB; 73MB zipped.\r\n\r\n`var modelPath = $""{Directory.GetCurrentDirectory()}/Models/mnist_digits.onnx"";`\r\n`var pipeline = mlContext.Transforms.LoadImages(""image"", """", nameof(ImageNetData.ImagePath));`\r\n`pipeline.Append(mlContext.Transforms.ResizeImages(""image"", ImageNetSettings.imageWidth, ImageNetSettings.imageHeight, ""image""));`\r\n`pipeline.Append(mlContext.Transforms.ExtractPixels(""image""));`\r\n`pipeline.Append(mlContext.Transforms.ApplyOnnxModel(modelPath));`\r\n\r\nException occurs on the final line above.\r\n\r\n### Stacktrace\r\n\r\nInvalidProtocolBufferException: Protocol message was too large. May be malicious. Use CodedInputStream.SetSizeLimit() to increase the size limit.\r\nGoogle.Protobuf.CodedInputStream.RefillBuffer(bool mustSucceed)\r\nGoogle.Protobuf.CodedInputStream.get_IsAtEnd()\r\nGoogle.Protobuf.CodedInputStream.ReadTag()\r\nGoogle.Protobuf.CodedInputStream.PeekTag()\r\nGoogle.Protobuf.Collections.RepeatedField<T>.AddEntriesFrom(CodedInputStream input, FieldCodec<T> codec)\r\nMicrosoft.ML.Model.OnnxConverter.OnnxCSharpToProtoWrapper+GraphProto.MergeFrom(CodedInputStream input)\r\nGoogle.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\nMicrosoft.ML.Model.OnnxConverter.OnnxCSharpToProtoWrapper+ModelProto.MergeFrom(CodedInputStream input)\r\nGoogle.Protobuf.MessageExtensions.MergeFrom(IMessage message, Stream input)\r\nGoogle.Protobuf.MessageParser<T>.ParseFrom(Stream input)\r\nMicrosoft.ML.Transforms.Onnx.OnnxModel..ctor(string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu, bool ownModelFile)\r\nMicrosoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, byte[] modelBytes)\r\nMicrosoft.ML.Transforms.Onnx.OnnxScoringEstimator..ctor(IHostEnvironment env, string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu)\r\nMicrosoft.ML.OnnxCatalog.ApplyOnnxModel(TransformsCatalog catalog, string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu)\r\nONNX_backend.Services.OnnxService.LoadHandwrittenDigitsModel(MLContext mlContext) in OnnxService.cs\r\n+\r\n            pipeline.Append(mlContext.Transforms.ApplyOnnxModel(modelPath));\r\nONNX_backend.Services.OnnxService.Start() in OnnxService.cs\r\n+\r\n            var model = LoadHandwrittenDigitsModel(_mlContext);\r\nONNX_backend.Controllers.ValuesController.Get() in ValuesController.cs\r\n+\r\n            _onnxService.Start();\r\nlambda_method(Closure , object , object[] )\r\nMicrosoft.Extensions.Internal.ObjectMethodExecutor.Execute(object target, object[] parameters)\r\nMicrosoft.AspNetCore.Mvc.Internal.ActionMethodExecutor+SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, object controller, object[] arguments)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextResourceFilter()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResourceExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeFilterPipelineAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeAsync()\r\nMicrosoft.AspNetCore.Routing.EndpointMiddleware.Invoke(HttpContext httpContext)\r\nMicrosoft.AspNetCore.Routing.EndpointRoutingMiddleware.Invoke(HttpContext httpContext)\r\nMicrosoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)'"
470509330,4026,b'Getting bestfit hyper-parameters from AutoML',"b'When using the model builder, the generated code contains interesting hyper-parameters. \r\n\r\nIs there a way to get these when using the AutoML API? I debugged the bestfit but couldnt find anything that resembles this.\r\n\r\nExample:\r\nvar trainer = mlContext.BinaryClassification.Trainers.SdcaLogisticRegression(new SdcaLogisticRegressionBinaryTrainer.Options() { **L2Regularization = 0.0001f, L1Regularization = 1f, ConvergenceTolerance = 0.2f, MaximumNumberOfIterations = 20, Shuffle = false, BiasLearningRate = 0f**, LabelColumnName = ""Attrition"", FeatureColumnName = ""Features"" });\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n'"
470507435,4025,b'Getting algorithm',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
470383482,4024,b'Anomaly Detection Task output should include PredictedLabel',"b'\r\nThe [Inputs and Output Columns](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet#input-and-output-columns) section should have [`PredictedLabel` in addition to `Score`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.PCA/PcaTrainer.cs#L381-L385).  Note: There is an [issue](https://github.com/dotnet/machinelearning/issues/3990) with the current release of ML.NET where `PredictedLabel` always evaluates to `true`.\r\n\r\nAdditionally, the description for `Score` reads:\r\n> The non-negative, unbounded score that was calculated by the anomaly detection model.\r\n\r\nThis does not indicate how the value returned by the model for `Score` should be interpreted.  Should higher scores be interpreted as anomalies, or scores closer to zero?\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 8b318bcc-48ff-eb63-9952-e811a283eb90\r\n* Version Independent ID: 1810a47c-da4c-8a3a-f5a0-61b31069f083\r\n* Content: [RandomizedPcaTrainer Class (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/RandomizedPcaTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/RandomizedPcaTrainer.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
470369216,4023,"b""Interpreting a pipeline's resulting Schema and/or .Preview()""","b""\r\nGoing over this article to be able to inspect data after the preprocessing pipeline:\r\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/inspect-intermediate-data-ml-net\r\n\r\nComing from python where you have a dataframe and you can just do dataframe.show(), this is quite an ordeal.  The CreateEnumerable() is pretty impractical because your original POCO won't fit the schema any more if you've done one-hot-encoding etc.  The one-hot-encoding creates multiple columns with the same name, how can that ever map back to a POCO? \r\n\r\nAnd there's a mandatory Features column at the end of the row, that repeats all the values in the row.  And if you then NormalizeMinMax the Features column, you get ANOTHER Features column with the same name.  Then you're trying to look at that in a Preview() and it's very confusing to see what's going on. \r\n\r\nThen there's DataViewRowCursor, where you need to specify reflection-style getters for each column.  So each time you tweak the pipeline you have to rewrite the code that lets you see the results of your pipeline?  It defeats the ability to quickly tweak and look, tweak and look, in the way that python does it so simply with dataframe.show().\r\n\r\nSo assuming this is how we have to inspect our data, I've got two questions:\r\n\r\n1) When a Transform (like OneHotEncoding) creates multiple columns with the same name, what's going on?  Is the training algorithm going to look at all of them?  Is the IsHidden how it's deciding what to use?  If so, can there be some official documentation on how all of this works?\r\n\r\n2) Why is it our responsibility to create a Features column at all?  Can't the algorithms just run on the IDataView we created, like in python?  It seems like a complicated and unnecessary step.  Also does it seem like good OO design to have a Features field at the end of a row that repeats all the values in said row? If you need to make this Features vector for performance reasons, why not create it once Fit() is called, keep it out of our data table, and hide this implementation detail from the user?\r\n\r\n"""
469934177,4020,b'What is TModel?',"b'Given that the examples do not use type parameters, it would extremely helpful to include documentation of TModel especially for creating a function. \n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_MulticlassClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_)\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
469646332,4019,b'Add a stratified trainer to ML.NET',"b'Add a trainer that splits the data according to a specified categorical column, and trains a model for each category, as well as a ""default"" model on the whole dataset. At scoring time, the model corresponding to the example\'s category is used, unless the category was not present in the training set, in which case the default model is used.'"
469642403,4018,b'Add left join transformer',b''
469640840,4017,b'Integrate with Vowpal Wabbit',b'https://github.com/VowpalWabbit/vowpal_wabbit\r\n'
469637175,4016,"b'Add a ""learning with counts"" transformer'","b'This transformation is a simple way to handle categorical features, and is explained here: https://blogs.technet.microsoft.com/machinelearning/2015/02/17/big-learning-made-easy-with-counts/\r\n'"
469623733,4015,b'Add an expression transformer',"b'The expression transformer takes the expression in the form of text using syntax of a simple expression language, and performs the operation defined in the expression on the input columns in each row of the data. The transformer supports having a vector input column, in which case it applies the expression to each slot of the vector independently. The expression language is extendable to user defined operations. '"
469619889,4014,b'Add a loader/saver for SVMLight file format',"b'Many datasets are saved in the SVMLight format, describe in this page: http://svmlight.joachims.org/.\r\n\r\nIt would be useful for ML.NET to support loading data directly from files in this format.'"
469165064,4011,b'Score column contains square of Euclidean distance?',"b'The column ""Score"" appears to contain square of Euclidean distance. Is that correct?\r\n\r\nE.g., for centroid coordinates [0,0,0] and a prediction coordinate [2,0,0], the ""Score"" would be 4, and NOT 2.\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: d93c6f58-e726-7734-06ed-c3b8f87c6a6e\r\n* Version Independent ID: bcd37e78-d924-c5c2-f5d5-745a8d586330\r\n* Content: [KMeansTrainer Class (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.kmeanstrainer?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/KMeansTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/KMeansTrainer.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
468421139,4008,b'[AutoML] bring AutoML API code into master from feature branch',b'We have been working out of a features/automl branch.  CLI is going to stay there for now but we want to bring API nuget into master.'
468318774,4005,b'Provide a way to append\\concatentate multiple IDataViews',"b""### System information\r\n\r\n- ML.NET - 1.2.0: \r\n\r\n### Issue\r\n\r\nThere should be a way to append or concatenate multiple IDataViews together.\r\n\r\nHere's the scenario:\r\nThe [new ranking sample](https://github.com/dotnet/machinelearning-samples/pull/549) needs the ability to train the model using two datasets that are each loaded from a separate text file and have the same schema - specifically, there is a (1) Training dataset and (2) Validation dataset, that need to be combined.  For example, refer to step #3 in the steps outlined below which the sample is based on.\r\n\r\nHere's the steps shown in the sample - generally, the pattern to train, validate, and test a model includes the following steps:\r\n1. The model is trained on the **training** dataset.  The model's metrics are then evaluated using the **validation** dataset.\r\n2. Step #1 is repeated by retraining and reevaluating the model until the desired metrics are achieved.  The outcome of this step is a pipeline that applies the necessary data transformations and trainer.\r\n3. The pipeline is used to train on the combined **training** + **validation** datasets.  The model's metrics are then evaluated on the **testing** dataset (exactly once) -- this is the final set of metrics used to measure the model's quality.\r\n4. The final step is to retrain the pipeline on **all** of the combined **training** + **validation** +  **testing** datasets.  This model is then ready to be deployed into production.\r\n\r\nToday to achieve this, the sample has to first load the data from a text file, then create an enumerable so that the datasets can be concatenated - this process would be greatly simplified if you could append/concatenate two IDataViews together:\r\n\r\n```\r\n\r\n//Load training data (has a header)\r\nIDataView trainData = mlContext.Data.LoadFromTextFile<SearchResultData>(TrainDatasetPath, separatorChar: '\\t', hasHeader: true);\r\n\r\n//Load validation data (has a header)\r\nIDataView validationData = mlContext.Data.LoadFromTextFile<SearchResultData>(ValidationDatasetPath, separatorChar: '\\t', hasHeader: false);\r\n\r\n// Combine the training and validation datasets.\r\nvar validationDataEnum = mlContext.Data.CreateEnumerable<SearchResultData>(validationData, false);\r\nvar trainDataEnum = mlContext.Data.CreateEnumerable<SearchResultData>(trainData, false);\r\nvar trainValidationDataEnum = validationDataEnum.Concat<SearchResultData>(trainDataEnum);\r\nIDataView trainValidationData = mlContext.Data.LoadFromEnumerable<SearchResultData>(trainValidationDataEnum);\r\n```\r\n\r\nNOTE: I also considered creating a text loader to load multiple text files (as described [here])(https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.textloader.load?view=ml-dotnet#Microsoft_ML_Data_TextLoader_Load_Microsoft_ML_Data_IMultiStreamSource_); however, one of the data files included a header while the other didn't.  It looks like to create a TextLoader for multiple files, that the file headers must be consistent across files.\r\n\r\n### Source code / logs\r\n\r\nNote that there is a method today that provides the ability to append rows - we should consider exposing this publicly:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/DataView/AppendRowsDataView.cs#L23-L31\r\n\r\n\r\n"""
468266314,4004,"b'TypeConvertingTransformer requires ""Experimental"" onnx version.'","b'When exporting a NimbusML pipeline which contains a predictor to ONNX, a `TypeConvertingTransformer` is sometimes inserted in the pipeline. The `TypeConvertingTransformer` currently requires the `Experimental` ONNX flag to be set in order for it to be converted to ONNX (see line 390 in `src\\Microsoft.ML.Data\\Transforms\\TypeConverting.cs`). Can this be updated to no longer require the `Experimental` flag?'"
468254487,4003,b'Create from enumerable after registering new type',"b""I think I'm missing something.\r\n\r\nWe have the Type System in `DataViewTypeManager`, and we can register a new type to map it to one of the system types. But even I register a new type to the system, when I try to load from enumerable I getting exception because the next `if`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/02a857a7646188fec2d1cba5e187a6c9d0838e23/src/Microsoft.ML.Data/DataView/InternalSchemaDefinition.cs#L194-L195\r\n\r\nEven if I add a new type, the first condition `!itemType.TryGetDataKind(out _)` will return `!false` = `true` because my type will never be in the next code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c3bdaaa2a29f88a85dd91cde3fbb805001011903/src/Microsoft.ML.Core/Data/DataKind.cs#L293-L337"""
468131415,4000,b'Invalid code and missing variables in SchemaComprehension docs',"b""The documentation for https://github.com/dotnet/machinelearning/blob/master/docs/code/SchemaComprehension.md has invalid code (I'm assuming it worked in previous versions of the framework) and the texts reference variables that don't exist anymore in the code snippets (removed in previous commits).\r\n\r\nWas partially fixed in #2054 and #2039, but still missing some minor things."""
467696100,3999,b'Possibility to specify the algorithm in AutoML',"b'There are scenarios where you know in advance the algorithms that will work better under certain data. In these cases, it would be very useful to specify through parameters what algorithms we want to test AutoML with different configuration parameters, so the time spent would be used to find better configurations of the specified algorithms, instead of trying algorithms that are known in advance to be to give worse results.\r\n'"
467636492,3998,b'Support saving to ONNX for the OptionalColumnCreator transform',"b'When NimbusML creates pipelines for regressors, classifiers and rankers, it prepends an OptionalColumnCreator transform to the pipeline. These pipelines can not be exported in their entirety in the ONNX format because the OptionalColumnCreator is not exportable to ONNX.\r\n\r\n'"
467541066,3997,b'Misleading error message when using Global Contrast Normalizer',"b'When attempting to fit a global contrast normalizer using NimbusML and providing a column of type float32 produces this error message:\r\n\r\n> Expected Single or known-size vector of Single, got Single\r\n\r\nThis error message seems to imply that using a column of type Single (float32) is valid. There are two places in `src\\Microsoft.ML.Transforms\\GcnTransform.cs` where this message is used. In either case a column of type vector is expected.\r\n\r\nShould this message be updated to be more clear about requiring a vector column?'"
467385182,3996,b'How we load data in ml.net from sql server table?',"b'right now, we are loading data in ml.net from csv file. but we want to load data in ml.net through sql server table or how we load data from datatable in ml.net. '"
467200962,3995,b'Exception messages need to be richer\\clearer',"b'Many exception messages thrown are unclear - as a result, when an exception occurs, it\'s challenging to identify whether the issue in with the ML.NET code, with the underlying data, with how the algorithm is being applied, etc.  Often it takes stepping through the ML.NET fwk in attempt to get further context.\r\n\r\nI logged this as a single issue because I think there would be benefit in looking at all places where exceptions are being thrown\\rethrown to ensure that default exception messages aren\'t provided and that the messages are as clear\\rich as possible.  Let me know if you would like these broken into separate issues rather than having them combined in one.  \r\n\r\nHere are some specific examples:\r\n\r\n\r\n\xc2\xa0 | Trainer | Scenario | Actual Message | Suggested   Message\r\n-- | -- | -- | -- | --\r\n|1. | N/A | Occurs when invalid field index is provided to the LoadColumn   attribute.\xc2\xa0    \xc2\xa0   For example:<br>``` [LoadColumn(100)]   public uint Label { get; set; }```<br>In the above code, the value of 100 is an invalid index value since   the underlying data has less than 100 columns. | System.ArgumentNullException: \'Value cannot be null.   Parameter   name: items\' | Message should indicate which column has the issue; the reference to   parameter \xe2\x80\x98items\xe2\x80\x99 is unclear.|\r\n|2. | N/A | Occurs when Feature column is of some other type than float\\single.    \xc2\xa0   For example: <br>``` [ColumnName(""Test""), LoadColumn(135)]   public uint Test { get; set; }``` | System.InvalidOperationException:   \'Column \xe2\x80\x98Test\xe2\x80\x99 has values of UInt32, which is not the same as earlier   observed type of Single.\' | It\xe2\x80\x99s unclear what \xe2\x80\x9csame as earlier observed type\xe2\x80\x9d means.\xc2\xa0 Consider rewording to state that the   Feature columns must all be of a certain type (e.g. Single).\r\n|3. | LightGbm | Occurs when custom gains are specified without providing a group id   column.   \xc2\xa0   For example:<br>```var customGains = new LightGbmRankingTrainer.Options();\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0   customGains.CustomGains = new int[] { 0,   1, 2, 3 };IEstimator<ITransformer> trainer = mlContext.Ranking.Trainers.LightGbm(customGains);IEstimator<ITransformer> trainerPipeline =   dataPipeline.Append(trainer);```<br>Notice that in the above code, the Group Id isn\xe2\x80\x99t being explicitly   set as follows:<br> ```customGains.RowGroupColumnName = ""GroupId"";``` | System.ArgumentOutOfRangeException: \'Need a group column.   Parameter   name: data\' | ArgumentOutOfRangeException is confusing; instead, throw ArgumentNullException   or InvalidOperationException.   \xc2\xa0   Message should also indicate the \xe2\x80\x98Group Id\xe2\x80\x99 column is missing\\null;   the reference to parameter \xe2\x80\x98data\xe2\x80\x99 is unclear.\r\n|4. | LightGbm | Occurs when custom gains cardinality doesn\xe2\x80\x99t match the cardinality of  the relevance label values. \xc2\xa0   \xc2\xa0   For example:<br>```var customGains = new LightGbmRankingTrainer.Options(); customGains.CustomGains  = new int[] { 0, 1, 2 };   \xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0\xc2\xa0   customGains.RowGroupColumnName = ""GroupId"";```<br>In the underlying data, the relevance label values are: {0, 1, 2, 3,   4 } \xe2\x80\x93 in other words, the cardinality of the relevance label values is   greater than the specified custom gains. | System.InvalidOperationException:   \'LightGBM Error, code is -1, error message is \'label (0) excel the max range   3\'.\' | There appears to be a typo \xe2\x80\x93 \xe2\x80\x9cexcel\xe2\x80\x9d should say \xe2\x80\x9cexceeds\xe2\x80\x9d.\xc2\xa0 Also, the message should state that the   cardinality of the relevance label values must less than or equal to the   cardinality of the custom gains.   \xc2\xa0   Note: Refer to similar issue logged directly against LightGBM: https://github.com/Microsoft/LightGBM/issues/1090\r\n\r\n\r\n\r\n\r\n'"
467191139,3994,b'Docs show using VectorType instead of concatenating features',"b""Numerous places in the docs, we show to store features as a VectorType.  However, this isn't ideal because it doesn't allow you to easily do feature engineering where you pick\\choose the most influential features to include when training a model.  Instead, to easily support feature engineering, it's recommended to concatenate your features as part of the pipeline. \r\n\r\nFor example, here are a few places where we show using a VectorType:\r\n1.) https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/load-data-ml-net#create-the-data-model\r\n2.) https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-do-i-load-data-from-a-text-file\r\n\r\nInstead, we should show feature concatenation and explain why this is a preferred approach - for example:\r\n```\r\n   IEstimator<ITransformer> dataPipeline = mlContext.Transforms.Concatenate(FeaturesVectorName, featureCols)\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(nameof(SearchResultData.Label)))\r\n                .Append(mlContext.Transforms.Conversion.Hash(nameof(SearchResultData.GroupId), nameof(SearchResultData.GroupId), numberOfBits: 20));\r\n```\r\nAlso, why is there a VectorType attribute?  Are there ever benefits to using this?  If not, we should consider removing.\r\n\r\n\r\n"""
467170942,3993,b'Exception is thrown if NDCG > 10 is used with LightGbm for evaluating ranking',"b'- Version: ML.NET 1.2.0\r\n\r\nThe current code in the RankingEvaluator.cs file has the MaxTruncationLevel for NDCG (Normalized Cumulative Gain Metric) set to 10.  Also, the code currently throws an exception if the NDCG is set to a value > 10.  This is a blocking issue for ranking because it prevents the ability to measure the quality of ranking with result sets > 10.  For example, if you were attempting to rank a group of 100 results, with the MaxTruncationLevel of 10, you could only measure whether the first 10 results were ranked correctly.\r\n\r\nHere\'s the code:\r\n\r\n```\r\n         public RankingEvaluator(IHostEnvironment env, Arguments args)\r\n            : base(env, LoadName)\r\n        {\r\n            // REVIEW: What kind of checking should be applied to labelGains?\r\n            if (args.DcgTruncationLevel <= 0 || args.DcgTruncationLevel > Aggregator.Counters.MaxTruncationLevel)\r\n                throw Host.ExceptUserArg(nameof(args.DcgTruncationLevel), ""DCG Truncation Level must be between 1 and {0}"", Aggregator.Counters.MaxTruncationLevel);\r\n            Host.CheckUserArg(args.LabelGains != null, nameof(args.LabelGains), ""Label gains cannot be null"");\r\n...\r\n}\r\n```\r\nIt appears from the //Review comment in the above code that this functionality hasn\'t been fully completed.  \r\n\r\nWhile I\'m unsure what the MaxTruncationLevel value should be, I have seen on a ranking contest\\example on Kaggle.com where one contest was measuring NDCG with a truncation level of up to 38.  \r\n\r\nI also noticed that in other parts of this file, the code indicates that a value between 0-100 should be allowed:\r\n\r\n```\r\n public Transform(IHostEnvironment env, IDataView input, string labelCol, string scoreCol, string groupCol,\r\n                int truncationLevel, Double[] labelGains)\r\n                : base(env, input, labelCol, scoreCol, groupCol, RegistrationName)\r\n            {\r\n                Host.CheckParam(0 < truncationLevel && truncationLevel < 100, nameof(truncationLevel),\r\n                    ""Truncation level must be between 1 and 99"");\r\n...\r\n}\r\n```\r\n\r\nAlso, refer to the linked bug since it is related to this scenario: [Ranker Evaluate doesn\'t allow you specify metric parameters.] (https://github.com/dotnet/machinelearning/issues/2728)'"
467103110,3992,b'FeaturizeText should allow only outputColumnName to be defined',"b'One of the extension methods for `FeaturizeText` needs both the `outputColumnName` and the `inputColumnNames` to be provided.\r\n\r\nThere is no compile error if `inputColumnNames` is not provided, only a runtime error.\r\n\r\nWe should fix the error so that when `inputColumnNames` is not provided, it is set to `new[] { outputColumnName }` as we do everywhere else in the code base.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c3bdaaa2a29f88a85dd91cde3fbb805001011903/src/Microsoft.ML.Transforms/Text/TextCatalog.cs#L60-L65'"
467100591,3991,b'Need advanced filtering for downsampling',"b""- Version: ML.NET 1.2.1\r\n\r\nTo filter rows in a performance-friendly way and load the data into an IDataView, I attempted to use:\r\n```\r\n mlContext.Data.FilterRowsByColumn(...)\r\n```\r\nHowever, this method only supports the ability to filter on the values of a single column.  There are cases where you need to do more advanced filtering scenarios - for example, filter based on multiple column values, nest queries, etc.  It would be helpful in general to have the ability to provide a linq expression to support a variety of filtering scenarios.\r\n\r\nHere's more information on my specific scenario - as I said, it would be helpful to have advanced filtering capabilities provided since this is a useful way to do down-sampling before training on the data.\r\n\r\n-----------------------------------------------------------------------\r\n**Scenario:**\r\n\r\nMy scenario uses a large hotel result dataset for ranking (1,000,000+ records).  \r\nHere is simple example of the data:\r\n\r\nGroupId | HotelId | Srch_Result_Clicked | Srch_Result_Booked\r\n----------|----------|----------------------|-------------------------|\r\n1 | 12 | 0 | 0 |\r\n1           |       24     |              1                 |             0 |\r\n1           |       45     |              1                 |             1 |\r\n1           |       55     |              0                 |             0 |\r\n\r\nNotice that in the above data, the GroupId corresponds to the query or search id.  There are multiple hotel results then tied to the GroupId since these are the results corresponding to a given query.  Each hotel result may have the following values:\r\n* Srch_Result_Clicked == 1 if the user clicked the hotel search result\r\n* Srch_Result_Booked == 1 if the user both clicked and booked the hotel search result\r\n* Or, the above values are 0 if the user neither clicked nor booked the result\r\n\r\nIn this scenario, I needed to perform down-sampling so that I only trained on hotel search queries where that had been either clicked or booked.  Here's an example of the type of query that I was trying to achieve:\r\n\r\n```\r\n//Get those group\\query ids that have at least one hotel result that was either clicked or booked\r\nvar groupIds = hotelData.Where(h => h.Srch_Result_Clicked == 1 || h.Srch_Result_Booked == 1).Select(h => h.GroupId).Distinct();\r\n\r\n//Down sample retrieve all hotel results for a group\\query matching the above criteria\r\nIDataView downSampleData = hotelData.Where(h => groupIds.Contains(h.GroupId));\r\n\r\n//Train the model\r\n var model = trainingPipeline.Fit(downSampleData);\r\n```\r\n"""
467076166,3990,b'PredictedLabel is always true for Anomaly Detection',"b'### System information\r\n\r\n- **OS version/distro**: macOS & Windows\r\n- **.NET Version (eg., dotnet --info)**:  .Net Core\r\n\r\n### Issue: PredictedLabel is always true for Anomaly Detection\r\n\r\nIn my experience, and as demonstrated by [this sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), predictions from models trained with the `RandomizedPcaTrainer` always set the value for `PredictedLabel` to `true`.\r\n\r\n_Note: I\xe2\x80\x99m very new to machine learning, I am not a data scientist, nor am I very familiar with this code base, but I\xe2\x80\x99ve taken a crack at figuring out why..._\r\n\r\nThe `BinaryClassifierScorer` is [used for scoring anomaly detection models](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L295-L297), specifically those trained using the `RandomizedPcaTrainer`. Which I _think_ makes sense, as with binary classification the `PredictedLabel` in anomaly detection will be one of two values, `true` or `false`.  \r\n\r\nHowever, when using binary classification, `PredictiveLabel` is set to `true` if the prediction\'s `Score` is a positive value and set to `false` if the `Score` is negative. This is one place it seems to break down with anomaly detection, as the `Score` is going to be a value between one and zero.  So, the current implementation of `BinaryClassifierScorer` is going to return a value of true for any prediction that does not have a `Score` of zero or NAN.\r\n\r\nAdditionally, it\xe2\x80\x99s my understanding that in anomaly detection it is up to the user to set the threshold of the model that indicates whether a `Score` is considered an anomaly or a normal value.  (Or at least this is the case for supervised training).  From what I can tell, the implementation of `BinaryClassifierScorer` used by anomaly detection, does have a `Threshold` property which [it compares the `Score` value to, to get the value for `PredictedLabel`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/BinaryClassifierScorer.cs#L259-L263).  It would seem the `BinaryClassifierScorer` could be used for anomaly detection if the user was able to manually set a value for `Threshold`, or if the scorer could intelligently set the value based on the distribution of `Score`s.  However, the [`Threshold` property is by default set to zero](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L270), with no public way of changing its value.\r\n\r\nThus, based on my understanding, the Scorer compares the prediction\xe2\x80\x99s `Score` to zero, and the value for `PredictedLabel` will always be set to `true`, with the exception of the edge case where score is zero or NAN.\r\n\r\nDuring my research, I did find that `BinaryClassificationCatalog` has a method [`ChangeModelThreshold`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/TrainCatalog.cs#L261-L267) to manually override the value of the scorer\xe2\x80\x99s `Threshold` property.  Unfortunately, this functionality is is not exposed on the `AnomalyDetectionCatalog`, so can\xe2\x80\x99t be used with anomaly detection.\r\n\r\n---\r\n\r\nFinally, and this may need to be moved to a separate issue, but I\'ve found contradictory information on how to interpret the `Score` value of an anomaly detection prediction.  For example [this sample](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/AnomalyDetection/RandomizedPcaSample.cs#L92) indicates that outliers (or anomalies) will have a **smaller** value for `Score` than will normal values.  However, [this documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet#training-algorithm-details) states _""If the error is close to 0, the instance is considered normal (non-anomaly).""_  This matches the results I\'m getting from [my sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), where anomalies have a **higher** value for `Score` than normal values.\r\n\r\n'"
466937119,3989,b'Multiple trainers in one pipeline',"b'First of all, I would like to thank you for ML.NET as I have waited for **the** C# machine learning library for such a long time (been using Accord.NET and CNTK) and right now I am having a great time with ML.NET.\r\n\r\nAs for my question, I am trying to create a strong classifier for multiclass classification consisting of more weaker classifiers, to do this I need to train different models. Is it possible to train multiple models in one pipeline? Or do I need to create separate pipelines and then even predictor engines for each model?\r\n\r\n```\r\nvar estimatorChain = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy())\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nvar transformerChain = estimatorChain.Fit(trainDataMemory);\r\n\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<DataItem, DataItemPrediction>(transformerChain, inputSchemaDefinition: inputSchemaDefinition);\r\n```\r\n\r\nI would like to append more trainers into the pipeline which is actually possible to do, but I have no idea what it does because the result of training and of prediction is not very transparent in this regard... Also did not find anything about this in the documentation.\r\n\r\nSo is it possible or do I have to create multiple pipelines which need to be used separately?'"
466926699,3988,b'Troubles with CustomMappingEstimator after save/load because InputSchemaDefinition is not being saved.',"b'### System information\r\n\r\n- **ML.Net v1.2.0**\r\n\r\n### Issue\r\nI try to use CustomMapping with specified column names. It works fine, but after save/load model I get exception:\r\n**System.ArgumentOutOfRangeException: ""Could not find  column \'Words\'"".** \r\n\'Words\' - the original name of property, not specified by me.\r\n\r\nWhat am i doing wrong?\r\n\r\nI can fix it by using only original names, it is not comfortable in some cases.\r\n\r\n### Source code\r\n```C#\r\n// --- Test method ---\r\nvar ml = new MLContext();\r\nvar descriptions = new[]\r\n{\r\n\tnew { Description = ""Painted, Painting, Painter"" }\r\n};\r\nvar dataView = ml.Data.LoadFromEnumerable(descriptions);\r\n\r\nvar pipeline = ml.Transforms.Text.NormalizeText(""Normalized"", ""Description"")\r\n\t.Append(ml.Transforms.Text.TokenizeIntoWords(""Tokens"", ""Normalized""))\r\n     // (Extension method) CustomMapping with specified column names\r\n\t.Append(ml.Transforms.StemText(""Stemmed"", ""Tokens""));\r\n\r\nvar model = pipeline.Fit(dataView);\r\nvar preview = model.Transform(dataView).Preview();  // everything is ok\r\n\r\n// Save model\r\nMemoryStream stream = new MemoryStream();\r\nml.Model.Save(model, dataView.Schema, stream);\r\nstream.Position = 0;\r\n\r\n// Load model in the new context\r\nvar ml2 = new MLContext();\r\n// Register custom action\r\nml2.ComponentCatalog.RegisterAssembly(typeof(StemmerCustomAction).Assembly);\r\nvar loadedModel = ml2.Model.Load(stream, out var schema);\r\n\r\n// Exception:\r\n// System.ArgumentOutOfRangeException: ""Could not find  column \'Words\'\r\nvar preview2 = loadedModel.Transform(dataView).Preview();\r\n\r\n\r\n//--- Classes ---\r\n\r\npublic class StemmerInput\r\n{\r\n\tpublic string[] Words { get; set; }\r\n}\r\n\r\npublic class StemmerOutput\r\n{\r\n\tpublic string[] Stemmed { get; set; }\r\n}\r\n\r\n[CustomMappingFactoryAttribute(""StemText"")]\r\npublic class StemmerCustomAction : CustomMappingFactory<StemmerInput, StemmerOutput>\r\n{\r\n\tpublic static void StemAction(StemmerInput input, StemmerOutput output)\r\n\t{\r\n\t\tvar stemmer = new EnglishStemmer();\r\n\t\toutput.Stemmed = new string[input.Words.Length];\r\n\t\tfor (int i = 0; i < input.Words.Length; i++)\r\n\t\t{\r\n\t\t\toutput.Stemmed[i] = stemmer.Stem(input.Words[i]);\r\n\t\t}\r\n\t}\r\n\r\n\tpublic override Action<StemmerInput, StemmerOutput> GetMapping() => StemAction;\r\n}\r\n\r\nstatic class StemmerTransformHelper\r\n{\r\n\tpublic static CustomMappingEstimator<StemmerInput, StemmerOutput> StemText(this TransformsCatalog catalog,\r\n\t\tstring outputColumnName, string inputColumnName = null)\r\n\t{\r\n\t\tvar inputSchema = SchemaDefinition.Create(typeof(StemmerInput), SchemaDefinition.Direction.Read);\t\t\r\n\t\tvar outSchema = SchemaDefinition.Create(typeof(StemmerOutput), SchemaDefinition.Direction.Write);\t\t\r\n\t\t// specify column names\r\n\t\tinputSchema[0].ColumnName = inputColumnName ?? outputColumnName;\r\n\t\toutSchema[0].ColumnName = outputColumnName;\r\n\t\treturn catalog.CustomMapping(new StemmerCustomAction().GetMapping(), ""StemText"", inputSchema, outSchema);\r\n\t}\r\n}\r\n```'"
466727956,3987,b'After packing and install ML.NET Project with Setup installer throws exceptions',"b""### System information\r\n\r\n-Windows 10(18362)\r\n- NET Framework 4.6.1: \r\n\r\n### Issue\r\n\r\n- Try Pack ML.NET Project with Windows Setup Installer\r\n- Installed and run Program throw an exception\r\n\r\n\r\nSimple Example:\r\n```\r\n    public partial class Form1 : Form\r\n    {\r\n        public Form1()\r\n        {\r\n            InitializeComponent();\r\n        }\r\n\r\n        private void button1_Click(object sender, EventArgs e)\r\n        {\r\n                try\r\n                {\r\n                    HousingData[] inMemoryCollection = new HousingData[]\r\n                    {\r\n                new HousingData\r\n                {\r\n                    Size =700f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        100000f, 3000000f, 250000f\r\n                    },\r\n                    CurrentPrice = 500000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size =1000f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        600000f, 400000f, 650000f\r\n                    },\r\n                    CurrentPrice=700000f\r\n                }\r\n                    };\r\n\r\n                    MLContext mlContext = new MLContext();\r\n\r\n                    IDataView data = mlContext.Data.LoadFromEnumerable<HousingData>(inMemoryCollection);\r\n                }\r\n                catch (Exception ex)\r\n                {\r\n                    MessageBox.Show(ex.Message);\r\n                }\r\n            }\r\n\r\n        }\r\n```\r\nIf i Run the program and push the button it throws that exception:\r\n\r\n![Exception](https://user-images.githubusercontent.com/13287806/61032695-3635f700-a3c2-11e9-9107-7f150e33cd8c.png)\r\n\r\nAnd if i attach the process with VS 2017 it throws that exception\r\n\r\nException thrown: 'System.BadImageFormatException' in Microsoft.ML.Data.dll"""
466474428,3985,b'Add FieldAwareFactorizationMachine to AutoML',"b""FieldAwareFactorizationMachine is good for large dataset like the Criteo 1TB dataset. \r\n\r\nCurrently FieldAwareFactorizationMachine is not swept over in AutoML. \r\n\r\nTask:\r\n* Add trainer to default list of binary learners to try\r\n* Add sweep range\r\n* Add to CLI's C# CodeGen\r\n\r\nShould be easy to just replicate an existing trainer like SDCA:\r\nhttps://github.com/dotnet/machinelearning/blob/d518b587b06ac3896a48646622b0f2169a230855/src/Microsoft.ML.AutoML/TrainerExtensions/BinaryTrainerExtensions.cs#L150-L169"""
466435561,3984,b'Renaming column',"b'### Issue\r\n\r\nI try to convert column type to another type by using [ConversionsExtensionsCatalog.ConvertType](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.converttype). After the transform, I have duplicated columns with the same name but another type. I want to keep with the same name.\r\n\r\nSo, I convert to a new name, drop the old name, copy the new name to the old name and drop the new name.\r\n\r\nWAT???\r\n\r\nWhy it is so complicated?\r\n\r\nI think we need to add an option to transform ""inplace"", or combine `Drop` & `Copy` to `Rename`.\r\n\r\n### Source code / logs\r\n\r\n```csharp\r\nvar intTypes = new[]\r\n{\r\n        DataKind.Int16,\r\n        DataKind.Int32,\r\n        DataKind.Int64\r\n};\r\nvar intColumnsNames = columns\r\n    .Where(c => intTypes.Contains(c.DataKind))\r\n    .Select(c => c.Name).ToList();\r\nconst string addedName = ""single_"";\r\n\r\nAddPipelineStage(_mlContext.Transforms.Conversion.ConvertType(\r\n    intColumnsNames.Select(c =>\r\n        new InputOutputColumnPair(addedName + c, c)).ToArray(),\r\n    DataKind.Single));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.ToArray()));\r\nintColumnsNames.ForEach(c => AddPipelineStage(_mlContext.Transforms.CopyColumns(c, addedName + c)));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.Select(c => addedName + c).ToArray()));\r\n```\r\n'"
465943872,3982,b'Need More Detail regarding feature',"b'\r\nis feature columns consider as complex variable that means all are consider as object when processes in ml.net?\r\n\r\nex.\r\nif consider label is Purchased Bike\r\nand feature are Commute Distance,Gender,Age,Cars.\r\n\r\nso all feature columns consider as object in ml.net?\r\n\r\nmeans like all column data convert into vector array.\r\n\r\n\r\n\r\n'"
465922355,3980,b'Update API Compat after 1.2 release',"b'We should update the API Compat tool after the 1.2 release. There are two updates that need to be made.\r\n\r\n1. Update the current projects to point to point to the 1.2 nugets\r\nhttps://github.com/dotnet/machinelearning/blob/78bfecb4c5999e1d675255544e2032f29c5fd621/tools-local/Microsoft.ML.StableApi/Microsoft.ML.StableApi.csproj#L10-L16\r\n\r\n2. Activate API Compat on the new stable projects (Onnx, TensorFlow and TimeSeries) and make the stable version point to the 1.2 nugets.'"
465852280,3978,b'Identifying dropped features by AutoML after training',"b""Apparently AutoML automatically will drops features during training if needed.\r\n\r\nIs there a way to retrieve the actual list of features that was included in the final model, e.g. determine which features were dropped and didn't improve the accuracy of the model?\r\n\r\nWhen I inspect the final model, the OutputSchema tends to always include all the features based on the initial training data."""
465819663,3977,b'[AutoML/CLI] Error in running a multiClass training for a datasets',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  3.0.0-preview6-27804-01\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRunning the command `mlnet auto-train --task multiclass-classification --dataset ""SampleTrainDataset.txt"" --label-column-name ""label"" --has-header true --max-exploration-time 60 -V diag` for this \r\n[dataset](https://github.com/dotnet/machinelearning/files/3373418/SampleTrainDataset.txt)\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/36833304/60896587-9ac34b80-a234-11e9-8804-da562ba5d093.png)\r\nThe ColumnConcatenating set only contains 4 columns. It ignores the first ""dataValue"" column for no reason. \r\n- **What did you expect?**\r\nI tried to debug it by the source code. I found out that after the `mlContext.Auto().InferColumns(SampleTrainDatasetPath, ""label"", separatorChar: \'\\t\')` function, the first column (""dataValue"") went into the `IgnoredColumnNames` collection. I want to know why,,,\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[debug_log.txt](https://github.com/dotnet/machinelearning/files/3373536/debug_log.txt)\r\n'"
465783476,3976,b'It is not possible to use PermutationFeatureImportance from a model loaded from disk in F#',"b'I am trying to use PermutationFeatureImportance (PFI)  with F# but the F# type system is not resolving ITransformer to ISingleFeaturePredictionTransformer - which is required by PFI.\r\n\r\nI believe it is due to  IPredictorProducing (and related interfaces) being marked as ""internal"".\r\n\r\nF# supports explicit interfaces and maybe that is the reason for this issue.\r\n\r\nHere is a snippet of code that shows what I am trying to do\r\n(I am using the latest bits - v 1.2.0 at the time of this post)\r\n\r\n```F#\r\nlet mutable schema = null\r\nlet mdl = ctx.Model.Load(@""F:\\fwaris\\data\\t\\analysis\\model_cv_LightGbmBinary.bin"", &schema) \r\nlet mdlt =  mdl :?> TransformerChain<ITransformer>\r\nlet m1 =  mdlt.LastTransformer //debugger shows it is Microsoft.ML.Data.BinaryPredictionTransformer<Microsoft.ML.IPredictorProducing<float>>\r\nlet scored = mdl.Transform(trainView)\r\nscored.Preview()\r\nctx.BinaryClassification.PermutationFeatureImportance(m1 :?> _,scored)\r\n```\r\n\r\n@dsyme \r\n'"
465620979,3975,b'Add Product recommendation sample that will suggest k best related products to subject product',"b""Provided sample it's not quite useful in real word scenarios. As basically the problem stated as pick k best-suited products to the subject product. Using the current approach I should recalculate scoring for all universe of products from N total products. So to form recommendations for whole store I should recalculate n*n scores and sort to pick the best recommendation, which looks too compute intensive even if this is quite parallelizable computations for several thousand products it's quite expensive.\r\n\r\nAs per @wschin suggestion, we can try and implement \r\n\r\n> There are some approximated solutions (**approximated maximum inner product search and approximated nearest neighbor search usually via K-D tree**) but ML.NET doesn't support any of them."""
465476473,3974,b'SaveOnnxCommand appears to ignore predictors when saving a model to ONNX format.',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Steps To Recreate The Issue\r\n\r\n1. Create and save a PredictorModel to disk using the entry point api.\r\n2. Try and convert the model to ONNX format using the entry point api.\r\n3. Notice that `SaveOnnxCommand.GetPipe` only cycles through the transforms and never encounters the logistic regression node.\r\n\r\n    This might be happening because `ExecuteGraphCommand.GetOutputToPath` saves a `TlcModule.DataKind.PredictorModel` to disk in step (1). And then, `ExecuteGraphCommand.SetInputFromPath` loads a `TlcModule.DataKind.TransformModel` from disk in step (2) (apparently a consequence of `SaveOnnxCommand.Arguments.Model` being of type `TransformModel`). `PredictorModelImpl` and `TransformModelImpl` don't appear to be compatible from a serialization point of view.\r\n\r\n### Source code / logs\r\n\r\nSee [here](https://github.com/pieths/dotnet_machinelearning/commit/1058abc7086d58a76000717b284a5b115931c70e) for an ml.net test which demonstrates the issue.\r\n"""
465466145,3973,b'Converting from ml.net pipeline to ONNX fails.',b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Issue\r\n\r\nI created an ml.net pipeline using onnx exportable transforms and a logistic regression node. It trains and predicts as expected but exporting the pipeline using `ConvertToOnnxProtobuf` fails with the following error:\r\n\r\n```console\r\nSystem.InvalidOperationException : The targeted pipeline can not be fully converted into\r\na well-defined ONNX model. Please check if all steps in that pipeline are convertible\r\nto ONNX and all necessary variables are not dropped (via command line arguments).\r\n```\r\n\r\n### Source code / logs\r\n\r\nSee [here](https://github.com/pieths/dotnet_machinelearning/commit/5335349756c50e54b8cb221484f6c56fd9805d49) for an ml.net test which demonstrates the issue.\r\n'
465458248,3972,"b'Using PFI with AutoML, possible?'","b'Playing with AutoML and so far having much fun with it. \r\n\r\nI have a trained model and now trying to retrieve the feature weights. None of the objects returned expose a LastTransformer object that I need to \r\n\r\nCode snippet:\r\n\r\n```\r\nvar mlContext = new MLContext();\r\nvar _appPath = AppDomain.CurrentDomain.BaseDirectory;\r\n var _dataPath = Path.Combine(_appPath, ""Datasets"", ""dataset.csv"");\r\nvar _modelPath = Path.Combine(_appPath, ""Datasets"", ""TrainedModels"");\r\n\r\n\r\nColumnInferenceResults columnInference = mlContext.Auto().InferColumns(_dataPath, LabelColumnName, groupColumns: false);\r\n            ColumnInformation columnInformation = columnInference.ColumnInformation;\r\n\r\n            TextLoader textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n            IDataView data = textLoader.Load(_dataPath);\r\n\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            var cts = new CancellationTokenSource();\r\n            var experimentSettings = CreateExperimentSettings(mlContext, cts);\r\n\r\n            var progressHandler = new BinaryExperimentProgressHandler();\r\n\r\n            ExperimentResult<BinaryClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateBinaryClassificationExperiment(experimentSettings)\r\n                .Execute(trainData, labelColumnName: ""Attrition"", progressHandler: new BinaryExperimentProgressHandler());\r\n\r\n            RunDetail<BinaryClassificationMetrics> bestRun = experimentResult.BestRun;\r\n            ITransformer trainedModel = bestRun.Model;\r\n            var predictions = trainedModel.Transform(testData);\r\n            var metrics = mlContext.BinaryClassification.EvaluateNonCalibrated(data: predictions, labelColumnName: ""Attrition"", scoreColumnName: ""Score"");\r\n\r\n            mlContext.Model.Save(trainedModel, trainData.Schema, _modelPath);\r\n```\r\n\r\nThen I want to get the PFI information and I get stuck. There appears no way to get the LastTransformer object from the trainedModel.\r\n\r\n\r\n```\r\n            var transformedData = trainedModel.Transform(trainData);\r\n            var linearPredictor = model.LastTransformer; \r\n\r\n            var permutationMetrics = mlContext.BinaryClassification.PermutationFeatureImportance(\r\n                linearPredictor, transformedData, permutationCount: 30);\r\n```\r\n\r\nHope someone can help me with some guidance.'"
465138521,3970,b'What about the constructors?',b'How can I initialize this type?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 7366dd71-3899-63fb-690e-5e0d11a5bf13\n* Version Independent ID: 4e44da94-51eb-2617-135a-eb71186b4da9\n* Content: [TensorFlowEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowestimator?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
465135177,3969,b'Use Vector<Byte> as Features',"b'Can I use bytes in the Futures vector for binary classification?\r\n\r\nI tried to make scheme like this\r\n```\r\n            var scheme = SchemaDefinition.Create(typeof(PredictionData));\r\n            scheme[""Preview""].ColumnType = BooleanDataViewType.Instance;\r\n            scheme[""Preview""].ColumnName = ""Label"";\r\n            scheme[""Probability""].ColumnType = NumberDataViewType.Single;\r\n            scheme[""Features""].ColumnType = new VectorDataViewType(NumberDataViewType.Byte, size);\r\n```\r\n\r\nBut after calling trainingPipeline.Fit I get an exception\r\n`System.ArgumentOutOfRangeException: \'Schema mismatch for feature column \'Features\': expected Vector<Single>, got Vector<Byte>`\r\n\r\nIf I use Single, it will take 4 times more memory for the data.\r\n\r\n'"
464117076,3967,b'We are not getting submodel for LinearBinaryModelParameters after loading model',"b'Hi \r\n\r\nAfter loading model for binary classification we are trying to get submodel and calibrator\r\n\r\nbut if you see after loading model we write below code\r\n```\r\n((Microsoft.ML.Calibrators.CalibratedModelParametersBase)((Microsoft.ML.Data.PredictionTransformerBase<Microsoft.ML.IPredictorProducing<float>>)((Microsoft.ML.Data.TransformerChain<Microsoft.ML.ITransformer>)mlModel).LastTransformer).Model).SubModel\r\n```\r\n but failed to getting sub model which is required for us for\r\nLinearBinaryModelParameters\r\n\r\nif you see in CreateModel method we easily get SubModel by writing below code\r\n```\r\nLinearBinaryModelParameters linearBinaryModelParameters = ((Microsoft.ML.Data.TransformerChain<Microsoft.ML.Data.BinaryPredictionTransformer<Microsoft.ML.Calibrators.CalibratedModelParametersBase<Microsoft.ML.Trainers.LinearBinaryModelParameters, Microsoft.ML.Calibrators.PlattCalibrator>>>)mlModel).LastTransformer.Model.SubModel;\r\n```\r\nbut same code if we writer after loading model the we got exception of casting\r\n\r\nplease guide us.\r\n\r\n\r\n\r\n[mlApp_ex.zip](https://github.com/dotnet/machinelearning/files/3358212/mlApp_ex.zip)\r\n'"
463980232,3966,b'Simplify include repo configuration in ml-api-docs repo',"b'The current config in https://github.com/dotnet/ml-api-docs is:\r\n\r\n.openpublishing.publish.config.json\r\n\r\n    ""dependent_repositories"": [\r\n     ...\r\n        {\r\n          ""path_to_root"": ""docs/samples"",\r\n          ""url"": ""https://github.com/dotnet/machinelearning"",\r\n          ""branch"": ""master"",\r\n          ""branch_mapping"": {}\r\n        }\r\n      ],\r\n\r\nThis means that the includes have to be specified like this:\r\n\r\n    [!code-csharp[OrdinaryLeastSquares](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/OrdinaryLeastSquares.cs)]\r\n\r\nand\r\n\r\n    [!include[algorithm](~/../docs/samples/docs/api-reference/tree-featurization-prediction.md)]\r\n\r\nIf we change it to\r\n\r\n.openpublishing.publish.config.json\r\n\r\n    {\r\n        ""path_to_root"": ""dotnet/machinelearning"", <-- ~ is relative to the docfx root dir i.e. dotnet\r\n        ""url"": ""https://github.com/dotnet/machinelearning"",\r\n        ""branch"": ""master"",\r\n        ""branch_mapping"": {}\r\n    } \r\n\r\nthen we can specify the includes as:\r\n\r\n    [!code-csharp[OrdinaryLeastSquares](~/machinelearning/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/OrdinaryLeastSquares.cs)]\r\n\r\n    [!include[algorithm](~/machinelearning/docs/api-reference/tree-featurization-prediction.md)]\r\n\r\n\r\n'"
463877098,3965,b'LightGbm Warning after upgrading to LightGBM v1.2 ([LightGBM] [Warning] Unknown parameter metric=)',"b'### System information\r\n\r\n- **OS version/distro**: Windows Server 2016\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Updated to ML.NET/LightGBM v1.2\r\n- **What happened?** Warning started appearing.\r\n- **What did you expect?** No warning\r\n\r\n### Source code / logs\r\n\r\nSource code is located here:\r\nhttps://github.com/bartczernicki/MLDotNet-BaseballClassification\r\n\r\nFit method that throws the warning...\r\nhttps://github.com/bartczernicki/MLDotNet-BaseballClassification/blob/28143bb71d962bcb919393db258e7e458480f071/MLDotNet-BaseballClassification/Program.cs#L113\r\n\r\n_Error: [LightGBM] [Warning] Unknown parameter metric=_'"
463870772,3964,b'Missing or incorrect dependencies in generated code',"b""### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAdded machine learning to a .net core console project.\r\nFollowed the training to generate a model and added the projects to my solution.\r\n(Note: when I created the solution I opted for solution and project in same folder)\r\n- **What happened?**\r\nMany Build Errors:\r\n2>MLConsoleL1ML.ConsoleApp\\ModelBuilder.cs(11,17,11,19): error CS0234: The type or namespace name 'ML' does not exist in the namespace 'Microsoft' (are you missing an assembly reference?)\r\n\r\n- **What did you expect?**\r\n1. Generated code to build.\r\n2. Generated code to work.\r\n\r\n- **What I tried to resolve it**\r\nInstalled nuget package Microsoft.ML\r\n\r\n- **Then what happened?**\r\nEven more errors:\r\n2>MLConsoleL1ML.Model\\obj\\Debug\\netcoreapp2.1\\MLConsoleL1ML.Model.AssemblyInfo.cs(14,12,14,54): error CS0579: Duplicate 'System.Reflection.AssemblyCompanyAttribute' attribute\r\n\r\nin addition to the previous errors\r\n\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
463719476,3962,b'Version mismatch for Microsoft.ML.TensorFlow.Redist',"b'The NuGet shows v0.14.0. But when I download and install, it actually v0.13.1.\r\n\r\n![image](https://user-images.githubusercontent.com/1705364/60590780-811c9280-9d62-11e9-9ef9-4930a047b281.png)\r\n\r\nhttps://github.com/dotnet/machinelearning/tree/master/src/Redist/Microsoft.ML.TensorFlow.Redist.\r\n\r\n![image](https://user-images.githubusercontent.com/1705364/60590824-9ee9f780-9d62-11e9-8a7a-8f8cbdafac45.png)\r\n'"
463563176,3960,b'Update AutoML dependency to ML.NET 1.2.0',b'ML.NET has released a new version (1.2.0). \r\n\r\nUpdate:\r\n* AutoML API\r\n* CLI & CodeGen'
463561677,3959,b'Bump AutoML API & CLI version to 0.14.0',"b'To match the existing pre-release version of ML.NET, bump AutoML API and CLI nugets to 0.14.0. Currently the version is 0.4.0, and we will fast forward to 0.14.0.\r\n\r\nThis provides a uniform versioning across ML.NET. '"
463262045,3952,b'Remove Static API code',"b'Since we are closing Static API issues with ""no development is being done on static API"" (ex. https://github.com/dotnet/machinelearning/issues/1153#issuecomment-507014868), we should just remove the Static API code from the repo. If we need it again in the future, we can get it out of source control history. But there is no reason to build and maintain this code anymore.'"
462836656,3938,b'MathJax Formatting in Section Scoring Function',b'The details on the scoring function for this trainer are unreadable as it appear the mathjax is not escaped properly\n\n\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 67778f5f-ee9e-25b6-c869-fc6e6d24453b\n* Version Independent ID: 53f718e9-ebcc-70ea-29af-1f626700c6e1\n* Content: [SdcaMaximumEntropyMulticlassTrainer Class (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcamaximumentropymulticlasstrainer?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/SdcaMaximumEntropyMulticlassTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/SdcaMaximumEntropyMulticlassTrainer.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
462472431,3935,"b""ML.NET Features column 'Feature' not found \xe5\xa6\x82\xe4\xbd\x95\xe5\xb0\x86\xe9\xa2\x84\xe8\xae\xad\xe6\x95\xb0\xe6\x8d\xae\xe6\xa8\xa1\xe5\x9e\x8b \xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\xa8\xa1\xe5\x9e\x8b""","b'### System information\r\n\r\n- **OS version/distro**:Win10\r\n- **.NET Version (eg., dotnet --info)**: .net core 3.0 preview-6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nhttps://social.msdn.microsoft.com/Forums/en-US/a9a45553-d26f-4964-9b84-81a6f1806754/mlnet-features-column-feature-not-found?forum=2212\r\n- **What happened?**\r\nhttps://social.msdn.microsoft.com/Forums/en-US/a9a45553-d26f-4964-9b84-81a6f1806754/mlnet-features-column-feature-not-found?forum=2212\r\n- **What did you expect?**\r\nML.NET Features column \'Feature\' not found \xe5\xa6\x82\xe4\xbd\x95\xe5\xb0\x86\xe9\xa2\x84\xe8\xae\xad\xe6\x95\xb0\xe6\x8d\xae\xe6\xa8\xa1\xe5\x9e\x8b \xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\xa8\xa1\xe5\x9e\x8b\r\n\r\n\xe6\x80\x8e\xe4\xb9\x88\xe4\xbd\xbf\xe7\x94\xa8\xe5\x8d\x95\xe7\x8b\xac\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\x92\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xae\xa1\xe9\x81\x93\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b On ML.NET, how to use eparate data preparation and model pipelines Predict(forcast)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nclass Program\r\n    {\r\n\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Hello World!"");\r\n\r\n\r\n            HousingData[] housingData = new HousingData[]\r\n            {\r\n                new HousingData\r\n                {\r\n                    Size = 600f,\r\n                    HistoricalPrices = new float[] { 100000f ,125000f ,122000f },\r\n                    CurrentPrice = 170000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 200000f, 250000f, 230000f },\r\n                    CurrentPrice = 225000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 126000f, 130000f, 200000f },\r\n                    CurrentPrice = 195000f\r\n                }\r\n            };\r\n\r\n            // Create MLContext\r\n            MLContext mlContext = new MLContext();\r\n\r\n            // Load Data\r\n            IDataView data = mlContext.Data.LoadFromEnumerable<HousingData>(housingData);\r\n\r\n            //\xe4\xbd\xbf\xe7\x94\xa8\xe5\x8d\x95\xe7\x8b\xac\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\x92\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe7\xae\xa1\xe9\x81\x93\r\n            {\r\n                // Define data preparation estimator\r\n                IEstimator<ITransformer> dataPrepEstimator =\r\n                    mlContext.Transforms.Concatenate(""Features"", new string[] { ""Size"", ""HistoricalPrices"" })\r\n                        .Append(mlContext.Transforms.NormalizeMinMax(""Features""))\r\n                        ;\r\n                // Create data preparation transformer\r\n                ITransformer dataPrepTransformer = dataPrepEstimator.Fit(data);\r\n                // Pre-process data using data prep operations\r\n                IDataView transformedData = dataPrepTransformer.Transform(data);\r\n \r\n                // Define StochasticDualCoordinateAscent regression algorithm estimator\r\n                var sdcaEstimator = mlContext.Regression.Trainers.Sdca();//labelColumnName: ""Label"", featureColumnName: ""Features""\r\n\r\n                //Console.WriteLine(""\xe6\xad\xa3\xe5\x9c\xa8\xe8\xae\xad\xe7\xbb\x83"");\r\n                // Train regression model\r\n                RegressionPredictionTransformer<LinearRegressionModelParameters> trainedModel = sdcaEstimator.Fit(transformedData);\r\n\r\n                // Save Data Prep transformer\r\n                mlContext.Model.Save(dataPrepTransformer, data.Schema, ""data_preparation_pipeline.zip"");\r\n\r\n                // Save Trained Model\r\n                mlContext.Model.Save(trainedModel, transformedData.Schema, ""model11.zip"");\r\n                //Console.WriteLine(""\xe4\xbf\x9d\xe5\xad\x98\xe5\xae\x8c\xe6\x88\x90"");\r\n\r\n                // Define data preparation and trained model schemas\r\n                DataViewSchema dataPrepPipelineSchema, modelSchema;\r\n\r\n                // Load data preparation pipeline and trained model\r\n                ITransformer dataPrepPipeline = mlContext.Model.Load(""data_preparation_pipeline.zip"", out dataPrepPipelineSchema);\r\n                ITransformer predictionPipeline = mlContext.Model.Load(""model11.zip"", out modelSchema);\r\n\r\n                // Create PredictionEngines\r\n                PredictionEngine<HousingData, HousingPrediction> predictionEngine = mlContext.Model.CreatePredictionEngine<HousingData, HousingPrediction>(predictionPipeline);\r\n                // Input Data\r\n                HousingData inputData = new HousingData\r\n                {\r\n                    Size = 900f,\r\n                    HistoricalPrices = new float[] { 155000f, 190000f, 220000f }\r\n                };\r\n\r\n                // Get Prediction\r\n                HousingPrediction prediction = predictionEngine.Predict(inputData);\r\n                Console.WriteLine($""Size={inputData.Size} and HistoricalPrices= {inputData.HistoricalPrices} Predict-> PredictedPrice={prediction.PredictedPrice}"");\r\n            }\r\n\r\n\r\n\r\n            while (true)\r\n            {\r\n                Console.Write(""\xe6\x8c\x89\xe4\xbb\xbb\xe6\x84\x8f\xe9\x94\xae\xe9\x80\x80\xe5\x87\xba\xef\xbc\x81"");\r\n                Console.ReadKey();\r\n                break;\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n-error log:ML.NET Features column \'Feature\' not found\r\n'"
462389276,3934,b'Requisites of the data set used in recommendation task with matrixfactorization trainer?',"b'I have a question regarding the data used in recommendation task with matrixfactorization.\r\nHere the data used in the examples consists of `userId` and `productId`.\r\n\r\nCan I use recommendation task when the users in my data all have purchased 1 unique product each - so they are mapped `1 - 1`, `2 - 2`, `3 - 3` - (userId - productId)? Or do it have to be mapped differently - like in the examples where one user might have bought the same product as someone else? And one user have bought N products: `1 - 2`, `2 - 2` ,`3 - (3, 1, 4, 5, 1)` (user 1  bought product 2 which also user 2 bought. user 4 bought 5 products in total)?\r\n\r\nWill I get unreliable and unusefull recommendation score with my original data setup?'"
462171983,3933,b'OneVsAllClassifier fits two trainers for binary classification task',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\nI expected OneVsAll to identify there are only two classes and train a single learner.\r\n\r\n### Source code / logs\r\n\r\nInternally the OneVersusAllTrainer will always instantiate as many binary classifiers as the number of classes. This is inefficient for binary classification, as just a single trainer is needed. I understand that I can just use an out of the box binary classification for this, but it will simplify the usage.\r\n'"
461887867,3932,b'cannot use fasterrcnn onnx model in c# ap',"b'steps:\r\ndownload https://github.com/onnx/models/tree/master/faster_rcnn\r\ntry to run model in .net\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing AlexNet.DataStructures;\r\nusing Microsoft.ML.Transforms.Image;\r\n\r\nnamespace SomeNet\r\n{\r\n    public class ImageClassifier\r\n    {\r\n        private readonly string dataLocation;\r\n        private readonly string labelsLocation;\r\n        private readonly string imagesLocation;\r\n        private readonly string modelLocation;\r\n        private readonly MLContext mLContext;\r\n\r\n        public ImageClassifier(string dataLocation, string imagesLocation, string labelsLocation, string modelLocation)\r\n        {\r\n            this.dataLocation = dataLocation;\r\n            this.labelsLocation = labelsLocation;\r\n            this.imagesLocation = imagesLocation;\r\n            this.modelLocation = modelLocation;\r\n            mLContext = new MLContext();\r\n        }\r\n\r\n        public struct ImageSettings\r\n        {\r\n            public const int imageHeight = 224;\r\n            public const int imageWidth = 224;\r\n        }\r\n\r\n        public struct OnnxModelSettings\r\n        {\r\n            public const string ModelInput = ""image"";\r\n        }\r\n\r\n        public void Score()\r\n        {\r\n            var model = LoadModel(dataLocation, imagesLocation, modelLocation);\r\n\r\n            var predictions = PredictData(dataLocation, imagesLocation, labelsLocation, model).ToArray(); \r\n        }\r\n\r\n        private PredictionEngine<ImageData, ImagePrediction> LoadModel(string dataLocation, string imagesLocation, string modelLocation)\r\n        {\r\n            var data = mLContext.Data.LoadFromTextFile<ImageData>(dataLocation, hasHeader: false);\r\n\r\n            var pipeline = mLContext.Transforms.LoadImages(outputColumnName: ""loadedimage"", imageFolder: imagesLocation, inputColumnName: nameof(ImageData.ImagePath))\r\n                .Append(mLContext.Transforms.ResizeImages(outputColumnName: ""resizedimage"",inputColumnName:""loadedimage"", imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight))\r\n                .Append(mLContext.Transforms.ExtractPixels(outputColumnName: ""image"", inputColumnName:""resizedimage"", orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ABGR))\r\n                .Append(mLContext.Transforms.ApplyOnnxModel(modelFile: modelLocation, outputColumnNames: new[] { ""6379"", ""6381"", ""6383"" }, inputColumnNames: new[] { ""image""}));\r\n            var model = pipeline.Fit(data);\r\n\r\n            var predictionEngine = mLContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(model, ignoreMissingColumns:false);\r\n\r\n            return predictionEngine;\r\n        }\r\n\r\n        protected IEnumerable<ImageData> PredictData(string imageLocation, string imageFolder, string labelsLocation, PredictionEngine<ImageData, ImagePrediction> model)\r\n        {\r\n            var labels = labelsLocation;\r\n            var p = model.Predict(new ImageData{\r\n                ImagePath = ""/home/snake/aspose/anton.perhunov/AlexNet/AlexNet/assets/Data/html.jpg""\r\n            });\r\n            var im =  new ImageData{\r\n                ImagePath = imageFolder + ""/e5725c32f8be4da8b6a27375fc7669ae_html.jpg""\r\n            };\r\n            yield return im;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nwhen inference any image you will get\r\nUnhandled Exception: System.ArgumentException: Length of memory (150528) must match product of dimensions (3).\r\nat System.Numerics.Tensors.DenseTensor1..ctor(Memory1 memory, ReadOnlySpan1 dimensions, Boolean reverseStride) at Microsoft.ML.Transforms.Onnx.OnnxUtils.CreateNamedOnnxValue[T](String name, ReadOnlySpan1 data, List1 shape) at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.NamedOnnxValueGetterVec1.GetNamedOnnxValue()\r\nat Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, String[] activeOutputColNames, OutputCache outputCache)\r\nat Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass13_01.<MakeGetter>b__0(VBuffer1& dst)\r\nat Microsoft.ML.Data.TypedCursorable1.TypedRowBase.<>c__DisplayClass8_01.b__0(TRow row)\r\nat Microsoft.ML.Data.TypedCursorable1.TypedRowBase.FillValues(TRow row) at Microsoft.ML.PredictionEngineBase2.Predict(TSrc example)\r\n\r\nit seems that .net api does not support dynamic input sizes(-1 in dimension), it just treat them as 1, model supports inputs with (3, -1,-1), however onnx value size become (3,1,1).'"
461821356,3931,"b""An unhandled exception of type 'System.InvalidOperationException' occurred in Microsoft.ML.Data.dll: 'Incompatible features column type: 'Vector<Single, 12>' vs 'Vector<Single, 13>''""","b'Training And Save isOK\r\n```csharp\r\npublic static void BinaryClassify(List<TrainRecord> training_dataset,\r\n                                      string labelColumnName = nameof(TrainRecord.rebuy_same_item))\r\n    {\r\n        var mlContext = new MLContext(seed: 2019);\r\n        var trainingDataView = mlContext.Data.LoadFromEnumerable<TrainRecord>(training_dataset);\r\n        //\xe7\x89\xb9\xe5\xbe\x81\xe9\xa1\xb9\xe7\x9b\xae\r\n        var CreateFeature = mlContext.Transforms.Concatenate(""Features"", nameof(TrainRecord.featur_rebuy_item_cnt),\r\n                                                                               nameof(TrainRecord.featur_rebuy_store_cnt),\r\n                                                                               nameof(TrainRecord.featur_rebuy_cate_cnt),\r\n\r\n                                                                               nameof(TrainRecord.featur_price_mean),\r\n                                                                               nameof(TrainRecord.featur_price_sdv),\r\n                                                                               nameof(TrainRecord.featur_price_var),\r\n\r\n                                                                               nameof(TrainRecord.featur_item_cnt),\r\n                                                                               nameof(TrainRecord.featur_cate_cnt),\r\n                                                                               nameof(TrainRecord.featur_store_cnt),\r\n\r\n                                                                               nameof(TrainRecord.featur_cate_share),\r\n                                                                               nameof(TrainRecord.featur_cate_share_country),\r\n\r\n                                                                               ""feature_country_id""\r\n                                                                               );\r\n        var dataProcessPipeline = mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""feature_country_id"", inputColumnName: nameof(TrainRecord.buyer_country_id)).Append(CreateFeature);\r\n\r\n        var DataTransformer = dataProcessPipeline.Fit(trainingDataView);\r\n        trainingDataView = DataTransformer.Transform(trainingDataView);\r\n\r\n        DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(trainingDataView, testFraction: 0.2);\r\n        IDataView trainData = dataSplit.TrainSet;\r\n        IDataView testData = dataSplit.TestSet;\r\n        var LightGBMEstimator = mlContext.BinaryClassification.Trainers.LightGbm(numberOfIterations: 2000,\r\n                                                                                 learningRate: 0.1,\r\n                                                                                 labelColumnName: labelColumnName);\r\n        Console.WriteLine();\r\n        Console.WriteLine(""\xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83 - "" + labelColumnName + ""\xef\xbc\x88LightGBM\xe4\xba\x8c\xe5\x85\x83\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x89 learningRate:"" + 0.1 + "" numberOfIterations:"" + 2000);\r\n        var LightGBMTransformer = LightGBMEstimator.Fit(trainData);\r\n        testData = LightGBMTransformer.Transform(testData);\r\n        var metrics = mlContext.BinaryClassification.Evaluate(testData, labelColumnName: labelColumnName);\r\n        ConsoleHelper.PrintBinaryClassificationMetrics(""Database Example"", metrics);\r\n        mlContext.Model.Save(LightGBMTransformer, trainData.Schema, ModelPath + labelColumnName + "".zip"");\r\n        Console.WriteLine(""\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbf\x9d\xe5\xad\x98\xe8\xb7\xaf\xe5\xbe\x84:"" + ModelPath + labelColumnName + "".zip"");\r\n        Console.WriteLine(""\xe7\xbb\x93\xe6\x9d\x9f\xe8\xae\xad\xe7\xbb\x83:Accuracy "" + metrics.Accuracy);\r\n        Console.WriteLine();\r\n    }\r\n```\r\n\r\nBut ,when I load the model, exception happened\xef\xbc\x9a\r\n\r\n```csharp\r\npublic static void Predict(List<TrainRecord> test_dataset, string labelColumnName = nameof(TrainRecord.rebuy_same_item))\r\n    {\r\n        var mlContext = new MLContext(seed: 2019);\r\n        DataViewSchema Schema;\r\n        var LightGBMTransformer = mlContext.Model.Load(ModelPath + labelColumnName + "".zip"", out Schema);\r\n        var trainingDataView = mlContext.Data.LoadFromEnumerable<TrainRecord>(test_dataset);\r\n\r\n        //\xe7\x89\xb9\xe5\xbe\x81\xe9\xa1\xb9\xe7\x9b\xae\r\n        var CreateFeature = mlContext.Transforms.Concatenate(""Features"", nameof(TrainRecord.featur_rebuy_item_cnt),\r\n                                                                               nameof(TrainRecord.featur_rebuy_store_cnt),\r\n                                                                               nameof(TrainRecord.featur_rebuy_cate_cnt),\r\n\r\n                                                                               nameof(TrainRecord.featur_price_mean),\r\n                                                                               nameof(TrainRecord.featur_price_sdv),\r\n                                                                               nameof(TrainRecord.featur_price_var),\r\n\r\n                                                                               nameof(TrainRecord.featur_item_cnt),\r\n                                                                               nameof(TrainRecord.featur_cate_cnt),\r\n                                                                               nameof(TrainRecord.featur_store_cnt),\r\n\r\n                                                                               nameof(TrainRecord.featur_cate_share),\r\n                                                                               nameof(TrainRecord.featur_cate_share_country),\r\n\r\n                                                                               ""feature_country_id""\r\n                                                                               );\r\n\r\n        //OneHotEncoding \xe5\xad\x97\xe6\xae\xb5\xe5\xa6\x82\xe6\x9e\x9c\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xbd\xac\xe7\x9a\x84\xe8\xaf\x9d\xef\xbc\x8c\xe5\x9c\xa8\xe5\x81\x9a\xe6\x95\xb4\xe4\xbd\x93CreateEnumerable\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe4\xbc\x9a\xe5\x8f\x91\xe7\x94\x9f\xe9\x94\x99\xe8\xaf\xaf\xef\xbc\x81\xef\xbc\x81\r\n        var dataProcessPipeline = mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""feature_country_id"", inputColumnName: nameof(TrainRecord.buyer_country_id)).Append(CreateFeature);\r\n        var DataTransformer = dataProcessPipeline.Fit(trainingDataView);\r\n        trainingDataView = DataTransformer.Transform(trainingDataView);\r\n\r\n        var predictions = LightGBMTransformer.Transform(trainingDataView);\r\n        IEnumerable<BuyerPrediction> predictedResults = mlContext.Data.CreateEnumerable<BuyerPrediction>(predictions, reuseRowObject: false);\r\n        foreach (var item in predictedResults)\r\n        {\r\n            Console.WriteLine(item.buyer_admin_id + "","" + item.Prediction + "","" + item.Probability);\r\n        }\r\n    }\r\n```\r\n'"
461648715,3927,b'Distinguish between Calibrated and NonCalibrated methods',"b'When would I use one versus the other?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: b147624e-e01f-679a-900c-37f48f9d9e15\n* Version Independent ID: 55d26134-c3a9-3a4f-5833-2f9b1dc8e0b1\n* Content: [BinaryClassificationCatalog.CrossValidateNonCalibrated(IDataView, IEstimator&lt;ITransformer&gt;, Int32, String, String, Nullable&lt;Int32&gt;) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.crossvalidatenoncalibrated?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/BinaryClassificationCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/BinaryClassificationCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
461647190,3926,b'Move official build yaml from phases to jobs',"b'We need to make the same change as #3908 to the official build yaml file:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/build/vsts-ci.yml\r\n\r\n""phases"" in AzDO yaml files are the old schema. We should be using ""jobs"", which is the ""new"" schema.\r\n\r\nSee https://github.com/dotnet/arcade/blob/master/Documentation/AzureDevOps/PhaseToJobSchemaChange.md for more info.'"
461522572,3921,b'Exception has been thrown by the target of an invocation on loading saved model',"b""When loading a saved model it throw the exception `Exception has been thrown by the target of an invocation` on the `Load` method. This method is simply wrapped into a separated library so it's easy to move around. Depending on the project i use it, it either works all the time with no exception, or never works. Here my current testing code :\r\n\r\n   ```\r\npublic void TestLoadSolver(Stream solverStream)\r\n{\r\n    // create context\r\n    var context = new MLContext();\r\n\r\n    // temp schema\r\n    DataViewSchema sch;\r\n\r\n    try\r\n    {\r\n        // load context,schema and transformation\r\n        var transformer = context.Model.Load(solverStream, out sch);\r\n\r\n        // store schema\r\n        var schema = sch;\r\n    }\r\n    catch (Exception ex)\r\n    {\r\n\r\n    }\r\n}\r\n```\r\n\r\nThe stream is simply a read from the zip file on the disk.\r\nThe error happen on the line `var transformer = context.Model.Load(solverStream, out sch);`\r\nAll projects are on .Net 4.8, 64 bits debug, using NuGet for packages which are the same as the DLL that has this code uses. The DLL are all the same in the bin folders and i verified for the bug with Lightgbm that doesn't copy and the DLL and EXE are there is all projects.\r\n\r\nWhat could be the cause of failure but only in some project."""
461521839,3920,b'Stuck on evaluate',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: ML.NET 1.1.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated ML model with Model Builder, given 1000 seconds, it was able to evaluate 2 models and returned the best one.\r\nAfterwards I tried to rerun the modelbuilder class to recreate the model.\r\nThe csv from where I take the data is around 8 MB, with 70k rows\r\n- **What happened?**\r\nIt has been stuck on Evaluate for so long, ~48 mins~. EDIT: now 82 mins.\r\n- **What did you expect?**\r\nHave some feedback on the evaluation process or create the new model.\r\n\r\nMy suggestion is to have some logs on the screen while it is evaluating.\r\n### Source code / logs\r\n![Proof](https://user-images.githubusercontent.com/20186579/60268902-c4ec4380-98ed-11e9-9ab5-910ee5583629.png)\r\n\r\n'"
461400663,3919,b'DLLNotFoundException (32/64 bits problem with the DLL probably)',"b'### System information\r\n\r\n- **OS version/distro**: windows 10 (64 bits) and windows server 2012 R2 (64 bits)\r\n- **.NET Version (eg., dotnet --info)**: .Net Framework 4.7.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** I copied the project from my computer (windows 10) to a server (windows server 2012 R2) and I started to have problems with ""DLLNotFoundException"".\r\n\r\n- **What happened?** When I copy the project from my computer ( ...\\Desktop\\ICN) to the server, the path of the project became ""\\\\nameOfServer\\...\\ICN"" (the Network Path) and when I debug, on my computer (windows 10), that same project I get ""DLLNotFoundException"".\r\n\r\n- **What did you expect?** I expected to run on the two computers equaly.\r\n\r\n### Source code / logs\r\n\r\nAs a side note, my solution has 3 projects: ""DataCollection"", ""RS_WebApp"" (where is the method that uses ML.NET) and ""NetworkGraph"".\r\n\r\nImage of the problem:\r\nhttps://imgur.com/a/SMBmPPW (first image)\r\n\r\nMy projects it\'s on ""Any CPU"" when I debug and with the project, ASP.NET Web Application (.NET Framework), ""RS_WebApp"" on 64 bits that ML.NET requires and the other 2 projects on ""Any CPU"".\r\n\r\nhttps://imgur.com/a/SMBmPPW (second image)\r\n\r\nI am using the ""mlContext.Recommendation().Trainers.MatrixFactorization(options)"" and when I build the application it generates the ""MatrixFactorizationNative.dll"" on ""\\ICN\\RS_WebApp\\bin"".\r\n\r\nThe only way that I put to work fine, when debug, was putting this dll on the ""C:\\Windows\\SysWOW64"" (in my computer) (ML.NET requires 64 bits) but the problem is that it doesn\'t work when it\'s the server calling that method because it doesn\'t have that file in its folder ""C:\\Windows\\SysWOW64"" (or similar to that in windows server) and I can\'t put that file in the server.\r\n\r\nI already tried to put the dll on the project with ""Copy to Output Directory: Copy if newer"" and it didn\'t work.\r\n\r\nhttps://imgur.com/a/SMBmPPW (third image)\r\n\r\nI also put manually the dll on ""\\ICN\\RS_WebApp\\bin\\x64"" and it didn\'t work.\r\n\r\nI also tried to ""Add Reference"" on the project (that have the web service with the web method that calls ML.NET ""RS_WebApp"") the dll but this error happen.\r\n\r\nhttps://imgur.com/a/SMBmPPW (fourth image)\r\n\r\n**I don\'t know what folder I can put the dll on, to correctly load that dll.**\r\n\r\nMy thoughts on this are the following:\r\n- something related with debugging a solution with 1 project 64 bits and 2 projects 32 bits, and it ""misses"" where was the dll for the 64 bits project.\r\n- ML.NET (web API) can have some problem with files in a computer and running on other.\r\n\r\nIf you need more information, feel free to ask, and a huge thanks if someone can address this problem.\r\n'"
461341573,3917,b'AutoML TextLoader should Sweep TrimWhiteSpace',"b'We should iterate over the options for TrimWhitespace in the TextLoader.\r\n\r\nAs diagnosed by @daholste, the MSLR-WEB10K dataset ([train](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTrain720kRows.tsv), [validate](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KValidate240kRows.tsv), [test](https://aka.ms/mlnet-resources/benchmarks/MSLRWeb10KTest240kRows.tsv), [zip](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/MSLR-WEB10K.zip), [README](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/README.md), [LICENSE](https://express-tlcresources.azureedge.net/datasets/MSLR-WEB10K/LICENSE.md)) has an extra tab at the end of each data row, though not the header row. \r\n\r\nThis causes the AutoML TextLoader to fail w/ the following error: \r\n```\r\nAn Error occured during inferring columns\r\nUnable to split the file provided into multiple, consistent columns.\r\nPlease see the log file for more info.\r\nExiting ...\r\n```\r\n\r\nWork:\r\n* Have AutoML sweep over the [TrimWhitespace](https://github.com/dotnet/machinelearning/blob/429f8cc7764769fcf8c7f3668cc0a27619ec9531/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1449) option\r\n* Fix above error message -- spelling of ""occured""'"
460978084,3909,"b'Add feature request, Multilabel classification and predict_proba'","b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 2.1.602\r\n- **ML.NET Version**: 1.1.0\r\n\r\nHi everyone,\r\nI'm looking for help. I developed some ML models in Python and I'm now trying to import them in ML.NET because my final app is in .NET Core. \r\n\r\nI started reading some tutorials and follow step-by-step tutorials from Microsoft. But I can't find out if there is a simple way to implement some features, like:\r\n- **multilabel classification**: I need to predict a label which can have different values that can be right. \r\n- **predict probabilities of classes**: in multiclass I can't find a way to implement the `predict_proba()` of sklearn, where I get in return the probabilities of every class. So that I can show the first two or three most probable classes.\r\n\r\nIf anyone has some tutorials on how to do this things, or knows if they are planned in the next updates of the library.\r\n\r\nOtherwise is there a way to easily implements my python models in a .NET core app?\r\n\r\nThanks,\r\nAlessandro\r\n"""
460673068,3907,b'PredictionEngine.Predict returns null',"b'Is there any reason that my PredictionEngine would be returning a null result when trying to predict a value in a multi-class classification smiliar to the GitHub Labeler? That sample works perfectly, by the way, because I tested it. I cannot release the code at this time, I understand this will not be helpful to you and I am sorry.'"
460667731,3906,b'AutoML: Misspelling in user-visible error...',"b'Not a huge deal, but an external customer did see this.  \r\n\r\nIn \\machinelearning\\src\\Microsoft.ML.Data\\Evaluators\\AucAggregator.cs...\r\n\r\nContracts.CheckParam(PosSample.Any(), nameof(PosSample), ""AUC is not definied when there is no positive class in the data"");\r\nContracts.CheckParam(NegSample.Any(), nameof(NegSample), ""AUC is not definied when there is no negative class in the data"");\r\n\r\n""defined"" is misspelled. '"
460288853,3905,b'ImageEstimators.ExtractPixels using an array for offsetImage and scaleImage',"b'Hello,\r\nfor this moment, when we use ExtractPixels, we could provide only a single number for offsetImage and scaleImage, which will be applied for all RGB channels. But sometimes, as for [this model](https://github.com/onnx/models/tree/master/ssd), we should use different normalization across the channels. Perhaps, this functionality could be added in the future?\r\nThe same proposition for ImageEstimator.ResizeImages, perhaps, different interpolations for ResizingKind could be added as in PIL python library?'"
459764260,3904,b'Error while creating PredictionEngine for SSD model in ONNX format',"b'### System information\r\n\r\n- **OS version/distro**: macOS 10.13.6\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2.4 \r\n\r\n### Issue\r\n\r\n- I trying to use SSD model in ONNX format for object detection from [ONNX model zoo](https://github.com/onnx/models/tree/master/ssd) ML.NET\r\n- I got the following error: `Can\'t bind the IDataView column \'labels\' of type \'Vector<Int64, 1, 1>\' to field or property \'PredictedLabels\' of type \'System.Int32[,]\'.` while creation of prediction engine\r\n- I was able to run successfully tiny YOLO model ONNX model zoo, here I expect the same result\r\n\r\n### Source code / logs\r\n\r\nHere is the definition of outputs of model:\r\n```C#\r\nnamespace SSD_onnx.DataStructures\r\n{\r\n    public class ImagePredictions\r\n    {\r\n        [ColumnName(SSDDetector.SSDSettings.SSDBoxesOutput)]\r\n        public float[,,] PredictedBoxes;\r\n\r\n        [ColumnName(SSDDetector.SSDSettings.SSDLabelsOutput)]\r\n        public int[,] PredictedLabels;\r\n\r\n        [ColumnName(SSDDetector.SSDSettings.SSDScoresOutput)]\r\n        public float[,] PredictedScores;\r\n    }\r\n}\r\n```\r\n\r\nHere is the function that creates prediction engine:\r\n\r\n```C#\r\nnamespace SSD_onnx\r\n{\r\n    public class SSDDetector\r\n    {\r\n        private readonly string modelLocation;\r\n        private readonly string labelsLocation;\r\n        private readonly string imagesLocation;\r\n        private readonly string tagsLocation;\r\n\r\n        private IList<SSDBox> SSDBoxes = new List<SSDBox>();\r\n        private readonly SSDPredictions ssdPredictions = new SSDPredictions();\r\n        private readonly MLContext mLContext;\r\n\r\n        public SSDDetector(string modelLocation,\r\n                           string labelsLocation,\r\n                           string imagesLocation,\r\n                           string tagsLocation)\r\n        {\r\n            this.modelLocation = modelLocation;\r\n            this.labelsLocation = labelsLocation;\r\n            this.imagesLocation = imagesLocation;\r\n            this.tagsLocation = tagsLocation;\r\n\r\n            mLContext = new MLContext();\r\n        }\r\n\r\n        public struct ImageSettings\r\n        {\r\n            public const int ImageWidth = 1200;\r\n            public const int ImageHeight = 1200;\r\n        }\r\n\r\n        public struct SSDSettings\r\n        {\r\n            public const string SSDInput = ""image"";\r\n            public const string SSDBoxesOutput = ""bboxes"";\r\n            public const string SSDLabelsOutput = ""labels"";\r\n            public const string SSDScoresOutput = ""scores"";\r\n        }\r\n\r\n        public PredictionEngine<ImageData, ImagePredictions> LoadModel(string modelLocation,\r\n                                                                       string imagesLocation,\r\n                                                                       string tagsLocation)\r\n        {\r\n            IDataView data = mLContext.Data.LoadFromTextFile<ImageData>(path: tagsLocation,\r\n                                                                        hasHeader: false);\r\n            var pipeline = mLContext.Transforms.LoadImages(outputColumnName: ""image"",\r\n                                                           imageFolder: imagesLocation,\r\n                                                           inputColumnName: nameof(ImageData.ImagePath))\r\n                   .Append(mLContext.Transforms.ResizeImages(outputColumnName: ""image"",\r\n                                                             imageWidth: ImageSettings.ImageWidth,\r\n                                                             imageHeight: ImageSettings.ImageHeight,\r\n                                                             inputColumnName: ""image""))\r\n                   .Append(mLContext.Transforms.ExtractPixels(outputColumnName: ""image""))\r\n                   .Append(mLContext.Transforms.ApplyOnnxModel(modelFile: modelLocation,\r\n                                                               outputColumnNames: new[] { SSDSettings.SSDBoxesOutput,\r\n                                                                                          SSDSettings.SSDLabelsOutput,\r\n                                                                                          SSDSettings.SSDScoresOutput },\r\n                                                               inputColumnNames: new[] { SSDSettings.SSDInput }));\r\n\r\n            var model = pipeline.Fit(data);\r\n\r\n            var predictionEngine = mLContext.Model.CreatePredictionEngine<ImageData, ImagePredictions>(model);\r\n            return predictionEngine;\r\n        }\r\n```'"
459560647,3903,"b""Unable to load shared library 'MklImports' or one of its dependencies.""","b""### System information\r\n\r\n- Mac 0S Mojave 10.14.3:\r\n- dotnet --version\r\n   2.2.300\r\n- Project references\r\n - Microsoft.ML\r\n - Microsoft.ML.Mkl.Redis\r\n - Microsoft.ML.TimeSeries\r\n\r\n### Issue\r\n- Possible that this is of the same origin as #3694 but in case it is a separate case I have posted this issue.\r\n\r\n- **What did you do?**\r\nFollowed new forecasting tutorial for ML.Net 1.1\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/TimeSeries/Forecasting.cs\r\n- **What happened?**\r\nDll not found exception\r\n- **What did you expect?**\r\nProgram to run successfully\r\n\r\n### Source code / logs\r\n\r\nUnable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found\r\n\r\n at Microsoft.ML.Transforms.TimeSeries.EigenUtils.Dsytrd(Layout matrixLayout, Uplo uplo, Int32 n, Double[] a, Int32 lda, Double[] d, Double[] e, Double[] tau)\\n   at Microsoft.ML.Transforms.TimeSeries.EigenUtils.MklSymmetricEigenDecomposition(Single[] input, Int32 size, Single[]& eigenValues, Single[]& eigenVectors)\\n   at Microsoft.ML.Transforms.TimeSeries.TrajectoryMatrix.ComputeSvd(Single[]& singularValues, Single[]& leftSingularvectors)\\n   at Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModeler.AdaptiveSingularSpectrumSequenceModelerInternal.TrainCore(Single[] dataArray, Int32 originalSeriesLength)\\n   at Microsoft.ML.Transforms.TimeSeries.AdaptiveSingularSpectrumSequenceModeler.AdaptiveSingularSpectrumSequenceModelerInternal.Train(RoleMappedData data)\\n \r\n"""
459521313,3902,b'Ensure Sanitized Column Names are Unique in AutoML',"b'When creating sanitized column names, we have to ensure the column names are distinct.\r\n\r\n### Error\r\nWe generate non-compilable C# code when there are naming collisions.\r\n\r\nExample build error:\r\n`/private/tmp/out/CivicHonesty/CivicHonesty.Model/DataModels/ModelInput.cs(23,23): Error CS0102: The type \'ModelInput\' already contains a definition for \'Country\' (CS0102) (CivicHonesty.Model)`\r\n\r\n### Repro\r\nIn the [Civic Honesty dataset](https://dataverse.harvard.edu/api/access/datafile/3451248?format=original&gbrecs=true) (CSV), we cause a naming collision in the generated C# code:\r\n```C#\r\nnamespace CivicHonesty.Model.DataModels\r\n{\r\n    public class ModelInput\r\n    {\r\n        [ColumnName(""id""), LoadColumn(0)]\r\n        public float Id { get; set; }\r\n\r\n        [ColumnName(""country""), LoadColumn(1)]\r\n        public float Country { get; set; }\r\n\r\n        [ColumnName(""Country""), LoadColumn(2)]\r\n        public string Country { get; set; }\r\n\r\n        [ColumnName(""city""), LoadColumn(3)]\r\n        public float City { get; set; }\r\n```\r\n\r\nYou\'ll note the two variables both called `Country`.\r\n\r\nThis comes from the dataset using ""country"" and ""Country"":\r\n> ![image](https://user-images.githubusercontent.com/4080826/59969829-60f00680-950c-11e9-8eeb-141981ae43c3.png)\r\n\r\nDataset: https://dataverse.harvard.edu/api/access/datafile/3451248?format=original&gbrecs=true\r\n\r\nCLI command:\r\n`mlnet auto-train --dataset ""behavioral data (csv file).csv""  --label-column-name response --mltask multiclass-classification --ignore-columns responsetime,id --max-exploration-time 60 --output-path /tmp/out/ --name CivicHonesty`\r\n\r\n### Cause\r\nCurrently, we have no detection for duplicate column names. \r\n\r\nThe above ""country"" vs. ""Country"" is a rather direct example. This will occur less directly and more often due to our name sanitization where we map, for example, ""$ spent"" and ""% spent"" both to ""__spent"":\r\nhttps://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/mlnet/Utilities/Utils.cs#L67-L83\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/mlnet/Utilities/Utils.cs#L47-L50\r\n\r\n\r\n\r\n### Work\r\nTodo:\r\n* Check that sanitized column names are unique\r\n* Check that when converted to C# variable names, the sanitized column names will be unique and valid C# variables'"
459480261,3901,b'Why does using statement need to be included?',"b'I was struggling to use the instance of MLContext to create a trainer by writing context.MulticlassClassification.Trainers because the methods were not appearing at the end of Trainers. As soon as I put ""using Microsoft.ML"" at the top of my code after loads of fiddling about, it worked. Can someone please explain why?'"
459444265,3900,"b'""Onnx Type not supported"" error while importing Custom Vision ONNX model'","b'### System information\r\n\r\n- **OS version/distro**: Win 10 Pro Build 17763.503\r\n- **.NET Version (eg., dotnet --info)**: .Net FrameWork 4.7.2\r\n- **ML.NET Version**:1.1.0\r\n- **ONNX Version::** 1.0 / 1.2 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nExported a image classification(General(Compact)) ONNX model from Custom Vision and attempted to generate a ONNX Estimator in ML.NET\r\n\r\n- **What happened?**\r\nThe model loading failed with error ""Onnx type not supported"".\r\nThis happens with all image classification ONNX models exported from Custom Vision.\r\nCorresponding Tensorflow models work well in ML.NET.\r\n\r\n- **What did you expect?**\r\nIt is possible to load ONNX models exported from Tensorflow/Scikit-learn. ML.NET should be able to accept ONNX models from Custom Vision.\r\n\r\n### Source code / logs\r\n\r\nvar onnxEstimator = mLContext.Transforms.ApplyOnnxModel(OutputColumnNames, InputColumnNames, OnnxModelPath);\r\n\r\n### Files\r\n[onnx12.zip](https://github.com/dotnet/machinelearning/files/3316591/onnx12.zip)\r\n\r\n'"
459402053,3898,b'Unresolved crefs using new API build and render (SDP)',b'Errors on the following pages:\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.valuemappingestimator-2?branch=SDPTest&view=ml-dotnet\r\n - `xref:Microsoft.ML.ConversionsExtensionsCatalog.MapValue%60%602(Microsoft.ML.TransformsCatalog.ConversionTransforms%2cSystem.Collections.Generic.IEnumerable%7bSystem.Collections.Generic.KeyValuePair%7b%60%600%2c%60%601%7d%7d%2cMicrosoft.ML.InputOutputColumnPair%5b%5d)`\r\n\r\n- `xref:Microsoft.ML.ConversionsExtensionsCatalog.MapValue%60%602(Microsoft.ML.TransformsCatalog.ConversionTransforms%2cSystem.Collections.Generic.IEnumerable%7bSystem.Collections.Generic.KeyValuePair%7b%60%600%2c%60%601%5b%5d%7d%7d%2cMicrosoft.ML.InputOutputColumnPair%5b%5d)`\r\n\r\n- Generated from: https://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.Data/Transforms/ValueMapping.cs#L164\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.approximatedkernelmappingestimator?branch=SDPTest&view=ml-dotnet\r\n\r\n- `xref:Microsoft.ML.KernelExpansionCatalog.ApproximatedKernelMap(Microsoft.ML.TransformsCatalog%2cMicrosoft.ML.Transforms.ApproximatedKernelMappingEstimator.ColumnOptions%5b%5d)`\r\n\r\n- Generated from https://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.Transforms/RandomFourierFeaturizing.cs#L627\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.columncopyingestimator?branch=SDPTest&view=ml-dotnet\r\n\r\n- `xref:Microsoft.ML.TransformExtensionsCatalog.CopyColumns(Microsoft.ML.TransformsCatalog%2cMicrosoft.ML.InputOutputColumnPair%5b%5d)`\r\n\r\n- Generated from https://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.Data/Transforms/ColumnCopying.cs#L54'
459383486,3897,b'Guidance on simple binaryclassification',"b'Trying to get a very simple binary classification to work. And while I feel I am just touching on the ABC\'s I am running into various issues. This shouldn\'t be rocket science.\r\n\r\nThe issue I get is ""Schema mismatch for feature column \'Features\': expected Vector<Single>, got Vector<String>\r\nParameter name: inputSchema""\r\n\r\nTo make sure the classification would work I made sure the Label column that I want to eventually predict is a boolean type. (I couldn\'t find clear docs on why the label column was needed but I assumed the training requires a single potential target for predictions which is the label, and if you want to predict other properties you need to train a model specifically for that property).\r\n\r\nI also made sure I transformed the string property first. \r\n\r\n```csharp\r\n        public class Employee\r\n        {\r\n            [LoadColumn(0)]\r\n            public float Age { get; set; }\r\n            [LoadColumn(1), ColumnName(""Label"")]\r\n            public bool Attrition { get; set; }\r\n            [LoadColumn(2)]\r\n            public string BusinessTravel { get; set; }\r\n            [LoadColumn(3)]\r\n            public float DailyRate { get; set; }\r\n        }\r\n\r\n        public ActionResult Turnover()\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n\r\n            var _appPath = AppDomain.CurrentDomain.BaseDirectory;\r\n            var _dataPath = Path.Combine(_appPath, ""Datasets"", ""attrition_small_dataset.csv"");\r\n            IDataView dataView = mlContext.Data.LoadFromTextFile<Employee2>(_dataPath, separatorChar: \',\', hasHeader: true);\r\n\r\n            var categoricalEstimator = mlContext.Transforms.Categorical.OneHotEncoding(""BusinessTravel"");\r\n            IDataView transformedData = categoricalEstimator.Fit(dataView).Transform(dataView);\r\n            \r\n            string[] featureColumnNames =\r\n                dataView.Schema\r\n                    .Select(column => column.Name)\r\n                    .Where(columnName => columnName != ""Label"").ToArray();\r\n\r\n            IEstimator<ITransformer> dataPrepEstimator = mlContext.Transforms.Concatenate(""Features"", featureColumnNames);\r\n            IDataView preprocessedTrainData = dataPrepEstimator.Fit(dataView).Transform(dataView);\r\n\r\n            var sdcaEstimator = mlContext.BinaryClassification.Trainers.SdcaLogisticRegression();\r\n            var sdcaModel = sdcaEstimator.Fit(preprocessedTrainData);\r\n\r\n            return View(""Turnover"");\r\n        }\r\n```'"
459154707,3895,b'PermutationFeatureImportance returns more features than model provides',"b'I have a model, with 35 features. After transforming the string values into vectors, I end up with a transformed model with 54 features.\r\n\r\nAfter training I want to evaluate the feature weight, however I end up with much more features (104, so twice) than available. An ""index out of bounds"" on finding the corresponding feature column is the result.\r\n\r\nIs this an issue with ML.net or case of \'incompatible user\'?\r\n\r\n```\r\npublic class Employee\r\n        {\r\n            [LoadColumn(0)]\r\n            public float Age { get; set; }\r\n            [LoadColumn(1)]\r\n            [ColumnName(""Label"")]\r\n            public float Attrition { get; set; }\r\n            [LoadColumn(2)]\r\n            public string BusinessTravel { get; set; }\r\n            [LoadColumn(3)]\r\n            public float DailyRate { get; set; }\r\n            [LoadColumn(4)]\r\n            public string Department { get; set; }\r\n            [LoadColumn(5)]\r\n            public float DistanceFromHome { get; set; }\r\n            [LoadColumn(6)]\r\n            public float Education { get; set; }\r\n            [LoadColumn(7)]\r\n            public string EducationField { get; set; }\r\n            [LoadColumn(8)]\r\n            public float EmployeeCount { get; set; }\r\n            [LoadColumn(9)]\r\n            public float EmployeeNumber { get; set; }\r\n            [LoadColumn(10)]\r\n            public float EnvironmentSatisfaction { get; set; }\r\n            [LoadColumn(11)]\r\n            public string Gender { get; set; }\r\n            [LoadColumn(12)]\r\n            public float HourlyRate { get; set; }\r\n            [LoadColumn(13)]\r\n            public float JobInvolvement { get; set; }\r\n            [LoadColumn(14)]\r\n            public float JobLevel { get; set; }\r\n            [LoadColumn(15)]\r\n            public string JobRole { get; set; }\r\n            [LoadColumn(16)]\r\n            public float JobSatisfaction { get; set; }\r\n            [LoadColumn(17)]\r\n            public string MaritalStatus { get; set; }\r\n            [LoadColumn(18)]\r\n            public float MonthlyIncome { get; set; }\r\n            [LoadColumn(19)]\r\n            public float MonthlyRate { get; set; }\r\n            [LoadColumn(20)]\r\n            public float NumCompaniesWorked { get; set; }\r\n            [LoadColumn(21)]\r\n            public string Over18 { get; set; }\r\n            [LoadColumn(22)]\r\n            public string OverTime { get; set; }\r\n            [LoadColumn(23)]\r\n            public float PercentSalaryHike { get; set; }\r\n            [LoadColumn(24)]\r\n            public float PerformanceRating { get; set; }\r\n            [LoadColumn(25)]\r\n            public float RelationshipSatisfaction { get; set; }\r\n            [LoadColumn(26)]\r\n            public float StandardHours { get; set; }\r\n            [LoadColumn(27)]\r\n            public float StockOptionLevel { get; set; }\r\n            [LoadColumn(28)]\r\n            public float TotalWorkingYears { get; set; }\r\n            [LoadColumn(29)]\r\n            public float TrainingTimesLastYear { get; set; }\r\n            [LoadColumn(30)]\r\n            public float WorkLifeBalance { get; set; }\r\n            [LoadColumn(31)]\r\n            public float YearsAtCompany { get; set; }\r\n            [LoadColumn(32)]\r\n            public float YearsInCurrentRole { get; set; }\r\n            [LoadColumn(33)]\r\n            public float YearsSinceLastPromotion { get; set; }\r\n            [LoadColumn(34)]\r\n            public float YearsWithCurrManager { get; set; }\r\n        }\r\n        public class EmployeeTransformed\r\n        {\r\n            public float Age { get; set; }\r\n            [ColumnName(""Label"")]\r\n            public float Attrition { get; set; }\r\n            public float[] BusinessTravel { get; set; }\r\n            public float DailyRate { get; set; }\r\n            public float[] Department { get; set; }\r\n            public float DistanceFromHome { get; set; }\r\n            public float Education { get; set; }\r\n            public float[] EducationField { get; set; }\r\n            public float EmployeeCount { get; set; }\r\n            public float EmployeeNumber { get; set; }\r\n            public float EnvironmentSatisfaction { get; set; }\r\n            public float[] Gender { get; set; }\r\n            public float HourlyRate { get; set; }\r\n            public float JobInvolvement { get; set; }\r\n            public float JobLevel { get; set; }\r\n            public float[] JobRole { get; set; }\r\n            public float JobSatisfaction { get; set; }\r\n            public float[] MaritalStatus { get; set; }\r\n            public float MonthlyIncome { get; set; }\r\n            public float MonthlyRate { get; set; }\r\n            public float NumCompaniesWorked { get; set; }\r\n            public float[] Over18 { get; set; }\r\n            public float[] OverTime { get; set; }\r\n            public float PercentSalaryHike { get; set; }\r\n            public float PerformanceRating { get; set; }\r\n            public float RelationshipSatisfaction { get; set; }\r\n            public float StandardHours { get; set; }\r\n            public float StockOptionLevel { get; set; }\r\n            public float TotalWorkingYears { get; set; }\r\n            public float TrainingTimesLastYear { get; set; }\r\n            public float WorkLifeBalance { get; set; }\r\n            public float YearsAtCompany { get; set; }\r\n            public float YearsInCurrentRole { get; set; }\r\n            public float YearsSinceLastPromotion { get; set; }\r\n            public float YearsWithCurrManager { get; set; }\r\n\r\n        }\r\n\r\n        public ActionResult Turnover()\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n\r\n            var _appPath = AppDomain.CurrentDomain.BaseDirectory;\r\n            //var _dataPath = Path.Combine(_appPath, ""Datasets"", ""WA_Fn-UseC_-HR-Employee-Attrition.csv"");\r\n            var _dataPath = Path.Combine(_appPath, ""Datasets"", ""attrition_small_dataset.csv"");\r\n\r\n            // Load data from file\r\n            IDataView dataView = mlContext.Data.LoadFromTextFile<Employee>(_dataPath, separatorChar: \',\', hasHeader: true);\r\n            var a = mlContext.Data.CreateEnumerable<Employee>(dataView, true).ToList();\r\n\r\n            // Define categorical transform estimator\r\n            var categoricalEstimator = mlContext.Transforms.Categorical.OneHotEncoding(""BusinessTravel"")\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Department""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""EducationField""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Gender""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""JobRole""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""MaritalStatus""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Over18""))\r\n            .Append(mlContext.Transforms.Categorical.OneHotEncoding(""OverTime""));\r\n            IDataView transformedData = categoricalEstimator.Fit(dataView).Transform(dataView);\r\n\r\n            // Split into train and test dataset\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(transformedData, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            // Get the column names of input features.\r\n            string[] featureColumnNames =\r\n                trainData.Schema\r\n                    .Select(column => column.Name)\r\n                    .Where(columnName => columnName != ""Label"").ToArray();\r\n\r\n            // Define estimator with data pre-processing steps\r\n            IEstimator<ITransformer> dataPrepEstimator =\r\n                mlContext.Transforms.Concatenate(""Features"", featureColumnNames)\r\n                    .Append(mlContext.Transforms.NormalizeMinMax(""Features""));\r\n\r\n            IDataView preprocessedTrainData = dataPrepEstimator.Fit(trainData).Transform(trainData);\r\n            var e = mlContext.Data.CreateEnumerable<EmployeeTransformed>(preprocessedTrainData, true).ToList();\r\n\r\n            /*\r\n            //  Define Stochastic Dual Coordinate Ascent machine learning estimator\r\n            //var sdcaEstimator = mlContext.Regression.Trainers.Sdca(labelColumnName: ""Age"", featureColumnName: ""Features"");\r\n            //var sdcaEstimator = mlContext.Regression.Trainers.Sdca(labelColumnName: ""Attrition"", maximumNumberOfIterations: 100);\r\n            //var sdcaEstimator = mlContext.BinaryClassification.Trainers.FastTree(labelColumnName : ""Attrition"", featureColumnName : ""Features"", numberOfLeaves: 50, numberOfTrees: 50, minimumExampleCountPerLeaf: 20);\r\n            */\r\n            var sdcaEstimator = mlContext.Regression.Trainers.Sdca();\r\n\r\n            // Train machine learning model\r\n            var sdcaModel = sdcaEstimator.Fit(preprocessedTrainData);\r\n\r\n            // Explain the model with Permutation Feature Importance (PFI)\r\n            ImmutableArray<RegressionMetricsStatistics> permutationFeatureImportance =\r\n            mlContext\r\n                .Regression\r\n                .PermutationFeatureImportance(sdcaModel, preprocessedTrainData, permutationCount: 3);\r\n\r\n            // Order features by importance\r\n            var featureImportanceMetrics =\r\n                permutationFeatureImportance\r\n                    .Select((metric, index) => new { index, metric.RSquared })\r\n                    .OrderByDescending(myFeatures => Math.Abs(myFeatures.RSquared.Mean));\r\n\r\n            var line = ""Feature\\tPFI <br>"";\r\n\r\n            var z = featureColumnNames;\r\n            foreach (var feature in featureImportanceMetrics)\r\n            {\r\n                line += $""{featureColumnNames[feature.index],-20}|\\t{feature.RSquared.Mean:F6} <br>"";\r\n            }\r\n\r\n            return Content(line);\r\n        }\r\n```'"
458913689,3893,b'Visual Studio 2019 Building Problem',"b'I got a clean machine and installed the latest Visual Studio 2019. After calling `.\\build.cmd`, I got the following error message.\r\n```\r\n  ""Repos\\machinelearning\\bin\\obj\\x64.Debug\\Native\\INSTALL.vcxproj"" (rebuild target) (1) ->\r\n  ""Repos\\machinelearning\\bin\\obj\\x64.Debug\\Native\\ALL_BUILD.vcxproj"" (default target) (3:2) ->\r\n  ""Repos\\machinelearning\\bin\\obj\\x64.Debug\\Native\\SymSgdNative\\SymSgdNative.vcxproj"" (default target) (10:2) ->\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(429,5): error MSB6006: ""CL.exe"" exited with code 2. [Repos\\machinelearning\\bin\\obj\\x64.Debug\\Native\\SymSgdNative\\SymSgdNative.vcxproj] [Repos\\machinelearning\\src\\Native\\build.proj]\r\n```\r\nDid I do something na\xc3\xafve? To resolve that bug, I remove one line below the it works.\r\n```\r\ndiff --git a/src/Native/CMakeLists.txt b/src/Native/CMakeLists.txt\r\nindex a814277e..87b0606c 100644\r\n--- a/src/Native/CMakeLists.txt\r\n+++ b/src/Native/CMakeLists.txt\r\n@@ -21,8 +21,6 @@ if(WIN32)\r\n     add_compile_options($<$<CONFIG:Debug>:/MTd>) # /MT will static link the VC runtime library, so it doesn\'t need to be installed on the target machine\r\n     add_compile_options($<$<CONFIG:Release>:/MT>)\r\n     add_compile_options($<$<CONFIG:RelWithDebInfo>:/MT>)\r\n-    add_compile_options(/guard:cf)\r\n     add_compile_options(/d2Zi+) # make optimized builds debugging easier\r\n     add_compile_options(/nologo) # Suppress Startup Banner\r\n     add_compile_options(/W3) # set warning level to 3\r\n     add_compile_options(/WX) # treat warnings as errors\r\n@@ -46,9 +44,6 @@ if(WIN32)\r\n```'"
458736735,3891,b'Examples need high-level explanation/summary',"b""The examples look well written, but there are a few things I would like to see:\n\n1. There should be a high-level explanation of each one, what is it doing and why. There are 5 different examples here. The first 2 and the last 2 appear to be duplicates - I can't tell the difference between them by reading them.  Even between the first 2, it is subtle what the difference is (the first one you can't save and load the model, the second you can). It would be great to explicitly call this out before each example.\n2. The 3rd example is fairly complicated, but with no explanation of what is happening. What defines a super alien? What is the overall scenario being achieved? What are the attributes for? It takes quite a bit to try to figure all these things out from the code without a high-level summary of the scenario.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 2af85725-9d23-0cff-c8ca-f915a94663bd\n* Version Independent ID: 8afa2992-aa5b-4bb1-7841-6dcf26151288\n* Content: [CustomMappingCatalog.CustomMapping(TransformsCatalog, Action&lt;TSrc,TDst&gt;, String, SchemaDefinition, SchemaDefinition) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.custommappingcatalog.custommapping?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/CustomMappingCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/CustomMappingCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
458393354,3890,b'some questions about PredictionEngine and others',"b'### System information\r\n\r\n- Win7:\r\n- NetCore 3.0 Preview6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTry to create PredictionEngine\r\n\r\n- **What happened?**\r\n\r\nAn unhandled exception of type \'System.ArgumentOutOfRangeException\' occurred in Microsoft.ML.Core.dll: \'Features column \'Feature\' not found\'\r\n\r\n```CSharp\r\nPredictionEngine<Survey, SurveyPrediction> predictionFunction =\r\n             mlContext.Model.CreatePredictionEngine<Survey, SurveyPrediction>\r\n\r\n```\r\n- **What did you expect?**\r\n\r\npredictionFunction is create \r\n\r\n### Source code / logs\r\n\r\n```Csharp\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers.LightGbm;\r\n\r\nnamespace Happiness\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext(seed: 2019);\r\n            var trainingDataView = mlContext.Data.LoadFromTextFile<Survey>(@""F:\\Happiness\\data\\happiness_train_abbr.csv"", hasHeader: true, separatorChar: \',\');\r\n            var SubmitDataView = mlContext.Data.LoadFromTextFile<SurveyTest>(@""F:\\Happiness\\data\\happiness_test_abbr.csv"", hasHeader: true, separatorChar: \',\');\r\n\r\n            //\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\r\n            //\xe7\x89\xb9\xe5\xbe\x81\xe9\xa1\xb9\xe7\x9b\xae\r\n            var dataProcessPipeline = mlContext.Transforms.Concatenate(""Features"", nameof(Survey.birth),\r\n                                                                                   nameof(Survey.car),\r\n                                                                                   nameof(Survey.class_1),\r\n                                                                                   nameof(Survey.county)\r\n                                                                                   );\r\n\r\n            var DataTransformer = dataProcessPipeline.Fit(trainingDataView);\r\n            trainingDataView = DataTransformer.Transform(trainingDataView);\r\n            SubmitDataView = DataTransformer.Transform(SubmitDataView);\r\n\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(trainingDataView, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            IEnumerable<Survey> HappinessDataEnumerable =\r\n                mlContext.Data.CreateEnumerable<Survey>(trainData, reuseRowObject: true);\r\n\r\n            int MaxCnt = 10;\r\n            int Current = 0;\r\n            // Iterate over each row\r\n            foreach (Survey row in HappinessDataEnumerable)\r\n            {\r\n                // Do something (print out Size property) with current Housing Data object being evaluated\r\n                Console.WriteLine(row.id + "":"" + row.height_cm + "","" + row.happiness);\r\n                Current++;\r\n                if (Current == MaxCnt) break;\r\n            }\r\n\r\n\r\n            // Define trainer options.\r\n            var options = new LightGbmRegressionTrainer.Options\r\n            {\r\n                LabelColumnName = nameof(Survey.happiness),\r\n                FeatureColumnName = ""Features"",\r\n                // How many leaves a single tree should have.\r\n                NumberOfLeaves = 64,\r\n                NumberOfIterations = 100,\r\n                EvaluationMetric = LightGbmRegressionTrainer.Options.EvaluateMetricType.RootMeanSquaredError,\r\n                LearningRate = 0.001,\r\n                Booster = new Microsoft.ML.Trainers.LightGbm.GossBooster.Options()\r\n                {\r\n                    TopRate = 0.3,\r\n                    OtherRate = 0.2\r\n                }\r\n            };\r\n\r\n            var LightGBMEstimator = mlContext.Regression.Trainers.LightGbm(options);\r\n            var LightGBMTransformer = LightGBMEstimator.Fit(trainData);\r\n            testData = LightGBMTransformer.Transform(testData);\r\n            var metrics = mlContext.Regression.Evaluate(testData, labelColumnName: nameof(Survey.happiness));\r\n            Common.ConsoleHelper.PrintRegressionMetrics(LightGBMEstimator.ToString(), metrics);\r\n\r\n            PredictionEngine<Survey, SurveyPrediction> predictionFunction =\r\n             mlContext.Model.CreatePredictionEngine<Survey, SurveyPrediction>(LightGBMTransformer);\r\n            var Submit = LightGBMTransformer.Transform(SubmitDataView);\r\n            HappinessDataEnumerable =\r\n                mlContext.Data.CreateEnumerable<Survey>(Submit, reuseRowObject: true);\r\n\r\n            Current = 0;\r\n            foreach (Survey row in HappinessDataEnumerable)\r\n            {\r\n                // Do something (print out Size property) with current Housing Data object being evaluated\r\n                var predictions = predictionFunction.Predict(row);\r\n                Console.WriteLine(predictions.id + "":"" + predictions.height_cm + "","" + predictions.Prediction);\r\n                Current++;\r\n                if (Current == MaxCnt) break;\r\n            }\r\n\r\n\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n\r\n\r\nThe LightGBM look can work and I get the Metrics,so I think the model is no problem...\r\n```shell\r\n*************************************************\r\n*       Metrics for Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer regression model      \r\n*------------------------------------------------\r\n*       LossFn:        1.09\r\n*       R2 Score:      0.02\r\n*       Absolute loss: .61\r\n*       Squared loss:  1.09\r\n*       RMS loss:      1.04\r\n*************************************************\r\n```'"
458305426,3889,b'How to set Chinese RemoveDefaultStopWords? ',b'How to set Chinese RemoveDefaultStopWords? \r\nI Guess I can load a stop word list form a external file.'
458195107,3888,b'exampleWeightColumnName parameter name and description may be confusing',"b'The purpose or use of this parameter may be confusing for users as to what the intent of it is based on the name and description. \r\n\r\n- It would be good to keep the name inline with the other column names (i.e. featureColumnName, labelColumnName). \r\n- Adding what type is expected by the column in the description would help as well (The column data must be Single). \r\n- Finally, it would help to describe the function of this parameter. Is this applying a weight to the individual observation, is it meant to set the initial weights of the features, or is it meant to set the importance of the features? To my knowledge this is to set the importance of the individual observation but clarification would help.\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: ca42bd00-b107-5a38-06c2-5b33e5e361fc\r\n* Version Independent ID: 9eceb504-86f7-3e71-7ddd-97e21254c026\r\n* Content: [StandardTrainersCatalog.Sdca Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.standardtrainerscatalog.sdca?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
458182738,3887,b'SymSGD IndexOutOfRangeException',"b'I get an error when using OVA-SymSGD on an internal dataset. Other learners, like SDCA and OVA-AveragedPerceptron work successfully (though LightGBM dies due to https://github.com/dotnet/machinelearning/issues/1625).\r\n\r\n## Error:\r\n```md\r\nException: System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(InputDataManager inputDataManager, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Span`1 weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, GCHandle stateGCHandle, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.TrainOne(IChannel ch, ITrainerEstimator`2 trainer, RoleMappedData data, Int32 cls)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n```\r\n\r\n## Pipeline\r\nBelow is the same pipeline but using SDCA, which runs successfully.\r\n```C#\r\nvar dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""label_col"", ""label_col"")\r\n                  .Append(mlContext.Transforms.Categorical.OneHotEncoding(new[] { new InputOutputColumnPair(""col1"", ""col1""), new InputOutputColumnPair(""col2"", ""col2""), new InputOutputColumnPair(""col3"", ""col3""), new InputOutputColumnPair(""col4"", ""col4""), new InputOutputColumnPair(""col5"", ""col5"") }))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col6_tf"", ""col6""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col7_tf"", ""col7""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col8_tf"", ""col8""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col9_tf"", ""col9""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col10_tf"", ""col10""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col11_tf"", ""col11""))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(""col12_tf"", ""col12""))\r\n                  .Append(mlContext.Transforms.Concatenate(""Features"", new[] { ""col1"", ""col2"", ""col3"", ""col4"", ""col5"", ""col6_tf"", ""col7_tf"", ""col8_tf"", ""col9_tf"", ""col10_tf"", ""col11_tf"", ""col12_tf"", ""col13"", ""col14"", ""col15"", ""col16"", ""col17"", ""col18"", ""col19"", ""col20"", ""col21"" }))\r\n                  .Append(mlContext.Transforms.NormalizeMinMax(""Features"", ""Features""))\r\n                  .AppendCacheCheckpoint(mlContext);\r\n\r\n            // Set the training algorithm \r\n            var trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: ""label_col"", featureColumnName: ""Features"")\r\n                  .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n```'"
458151759,3886,b'Fit endlessly loop if code in a form',"b""I have create a small winform project. made a very basic SDCA regression for one property of an object. So far the code has been in the program.cs Main() method. Now i created an empty new form called Form1. There is no control yet and i just copied the code from the program.cs Main() directly into the Form1_Load().\r\n\r\nThe problem is that the code endless loop on the `IEstimator<ITransformer>.Fit(IDataView Input)`.\r\n\r\nin program.cs the code takes about 3 seconds to complete every single time and CPU reach about 75%. When it run from the form the code run indefinitely (longest i waited was 45 min while away on lunch break). Tried couple hundreds of time on 2 different PC and we both have the same issue. It never completes.\r\n\r\nI tried removing [STAThread] on the program.cs Main() just for the fun and the code still runs fine there so it's not necessary (anyway not for the Fit() method)."""
458133705,3885,b'Rationalize Infinity handling in Normalizers',"b""A while back, I looked in to how can we handle values of Infinity & -Infinity in our normalizers. We should standardize the handling of +/- Infinity in our normalizers.\r\n\r\n## Background\r\nValues of Infinity are rather hard for users to handle as NAHandle ignores the Infinity & -Infinity values. I believe you would need a custom mapping transform to deal with these values.\r\n\r\nThe comes up in a dataset where I'm calculating pairwise features, eg: { x+y, x*y, x*y*y, x*e^y, ... }. I am overflowing into Infinity. This leads to FastTree ignoring rows, and SDCA dying w/ Infinite bias terms. \r\n\r\n## Summary\r\nMinMaxNormalizer+NAHandleTransform seems to be the best option to handle data values of \xc2\xb1Infinity. This option isn't perfect, as it is slow (causes an additional full pass of the data), and doubles your number of features.  \r\n\r\nCurrently, when a user applies normalization which replaces Infinity data values with NA we then silently skips rows. This is confusing to users and hard to debug.\r\n\r\n## Recommendation\r\n* Have MinMaxNormalizer replace +/- Infinity w/ 0.00 (default on with option to disable). \r\nThis will cause the (recommended to add before many learners) normalization to no longer replace Infinity with NA, which currently causes the learners to ignore the rows. \r\n* Modify the other normalization transforms to have consistent handling of Infinity data values.\r\n \r\n## Transforms' handling of Infinity\r\n\r\n**NAHandleTransform:**\r\n\xf0\x9f\x94\xb4 Bad: Ignores Infinity (maps Infinity => Infinity). \r\nAll learners work, but some skip rows w/ Infinity\r\n\r\n \r\n\r\n**MinMaxNormalizer:**\r\n\xf0\x9f\x93\x92 Not good: Replaces Infinity w/ NA. But this transform is recommended to add just before linear learners, which causes the learner to see NA, and drop the row (for either training or prediction). \r\nAll learners work, but skips rows w/ NA in it. \r\n\r\n \r\n\r\n**MeanVarNormalizer:**\r\n\xf0\x9f\x94\xb4 Bad: Ignores Infinity (maps Infinity => Infinity), but normalizes the other numbers correctly. \r\nAll learners work, but some skip rows w/ Infinity in it.\r\n\r\n \r\n\r\n**LogMeanVarNormalizer:**\r\n\xe2\x9c\x85 Good: Replaces Infinity w/ 0. Could be better w/ an indicator column for the imputing. \r\nAll learners work. \r\n\r\n \r\n\r\n**BinNormalizer:**\r\n\xf0\x9f\x94\xb4 Very bad: Replaces Infinity w/ 1, but replaces all other values in the column w/ 0 also. Effectively wipes out the column. \r\nNo learners die, but the column is wiped out.\r\n\r\n \r\n\r\n**SupervisedBinNormalizer:**\r\n\xf0\x9f\x94\xb4 Very bad: Replaces Infinity w/ 0, but replaces all other values in the column w/ 0 also. Effectively wipes out the column. \r\nNo learners die, but the column is wiped out.\r\n\r\n \r\n\r\n**MinMaxNormalizer+NAHandleTransform:**\r\n\xe2\x9c\x85 Very good: Replaces Infinity w/ 0 (NA then 0), and also adds an indicator column for the imputing. Double the size of the feature column though and causes a full pass of the data (trainable transform).\r\nAll learners work great.\r\n\r\n------\r\n\r\nThe above analysis is on the internal version of ML.NET, but I don't expect there has been changes to the behavior. """
457887633,3884,b'How to set metric for lightgbm?',"b'I compare the python lightgbm and ml.net,some parm can\'t set.\r\n```python\r\nparams = {\r\n    ""boosting_type"": ""gbdt"",\r\n    ""objective"": ""binary"",\r\n    ""metric"": ""binary_logloss"",\r\n    ""num_leaves"": 32,\r\n    ""learning_rate"": 0.05,\r\n    ""feature_fraction"": 0.9,\r\n    ""bagging_fraction"": 0.8,\r\n    ""bagging_freq"": 5,\r\n    ""verbose"": 1,\r\n}\r\n```\r\nmetric is one of miss parm.\r\n\r\nBy the way,how to display the progress of training lightgbm at console like python?\r\n'"
457885125,3883,"b""Schema mismatch for label column '': expected Single, got Key<UInt32> Parameter name: labelCol""","b'I am trying to create my first ML regression model using ML.Net (.net core 2.1), getting above error message when fitting the pipeline with data view. Could you please help with correct solution. please find the code which I was trying, here I have to predict the Name result based on Name and Duplicate name values.\r\n```c#\r\n public class FeatureData\r\n    {\r\n        [LoadColumn(3)]\r\n        public string Name;\r\n\r\n        [LoadColumn(20)]\r\n        public string DuplicateName;\r\n        [LoadColumn(31)]\r\n        public string NameResult;\r\n    }\r\n    public class LabelData\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public string NameResult;\r\n    }\r\n\r\n      IDataView dataView = mlContext.Data.LoadFromTextFile<FeatureData>(dataPath, hasHeader: true, separatorChar: \',\',allowQuoting:true);\r\n   \r\n            var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: ""Label"", inputColumnName: ""NameResult"")\r\n .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""NameEncoded"", inputColumnName: ""Name""))\r\n.Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: ""DuplicateNameEncoded"", inputColumnName: ""DuplicateName""))\r\n.Append(mlContext.Transforms.Concatenate(""Features"", ""NameEncoded"", ""DuplicateNameEncoded""))\r\n.Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n            var model = pipeline.Fit(dataView); ///getting above error here\r\n```'"
457736707,3879,b'Improving column purpose detection for sparse datasets',"b'AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n\r\nThis is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n\r\n**To fix:** \r\nWe need to detect the column purpose only on the set (non-blank) values.\r\n\r\nRecommend subtracting the blank values from `data.Count`:\r\nhttps://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n\r\nCurrently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.'"
457658265,3878,b'Multiclass LightGBM bug',"b'LightGBM trainer has two non-readonly fields called `_numClass` and `_tlcNumClass`. The second one is used to determine the number of predictors in the OVA predictor. However, the value of `_tlcNumClass` is only updated once, so if `Fit` is called again on the same estimator, it might give the wrong number of classes.'"
457603180,3877,b'DLL not found',"b""I have this problem : https://stackoverflow.com/questions/56654046/system-dllnotfoundexception-unable-to-load-dll-the-specified-module-could-not\r\n\r\nAnd I think that can be something related with a problem on this web API, or else I woudn't post here."""
457564793,3876,b'Object reference not set to an instance of an object.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 1903\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRun the following Examples with ONNX model from Azure Custom Vision service.\r\n\r\nhttps://docs.microsoft.com/ja-jp/dotnet/api/microsoft.ml.onnxcatalog.applyonnxmodel?view=ml-dotnet-preview#Microsoft_ML_OnnxCatalog_ApplyOnnxModel_Microsoft_ML_TransformsCatalog_System_String_System_Nullable_System_Int32__System_Boolean_\r\n\r\n- **What happened?**\r\nFailed in ApplyOnnxModel with the following message.\r\nObject reference not set to an instance of an object.\r\n\r\n\r\n### Source code / logs\r\n```cs\r\nusing System;\r\nusing System.Linq;\r\nusing System.IO;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace Samples.Dynamic\r\n{\r\n    public static class ApplyOnnxModel\r\n    {\r\n        public static void Main()\r\n        {\r\n            string strCurDir = System.Environment.CurrentDirectory;\r\n            Console.WriteLine(strCurDir);\r\n            // Download the squeeznet image model from ONNX model zoo, version 1.2\r\n            // https://github.com/onnx/models/tree/master/squeezenet or use\r\n            // Microsoft.ML.Onnx.TestModels nuget.\r\n            var assetsRelativePath = @""../../../squeezenet"";\r\n            string assetsPath = GetAbsolutePath(assetsRelativePath);\r\n\r\n            var modelPath = Path.Combine(assetsPath, ""catdog.onnx"");\r\n\r\n            // Create ML pipeline to score the data using OnnxScoringEstimator\r\n            var mlContext = new MLContext();\r\n\r\n            // Generate sample test data.\r\n            var samples = GetTensorData();\r\n            // Convert training data to IDataView, the general data type used in ML.NET.\r\n            var data = mlContext.Data.LoadFromEnumerable(samples);\r\n            // Create the pipeline to score using provided onnx model.\r\n            //var pipeline = mlContext.Transforms.ApplyOnnxModel(modelPath);\r\n            var pipeline = mlContext.Transforms.ApplyOnnxModel(""classLabel"",""data"", modelPath);\r\n            // Fit the pipeline and get the transformed values\r\n            var transformedValues = pipeline.Fit(data).Transform(data);\r\n            // Retrieve model scores into Prediction class\r\n            var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedValues, reuseRowObject: false);\r\n\r\n            // Iterate rows\r\n            foreach (var prediction in predictions)\r\n            {\r\n                int numClasses = 0;\r\n                foreach (var classScore in prediction.classLabel.Take(5))\r\n                {\r\n                    Console.WriteLine($""Class #{numClasses++} score = {classScore}"");\r\n                }\r\n                Console.WriteLine(new string(\'-\', 10));\r\n            }\r\n\r\n            // Results look like below...\r\n            // Class #0 score = 4.544065E-05\r\n            // Class #1 score = 0.003845858\r\n            // Class #2 score = 0.0001249467\r\n            // ----------\r\n            // Class #0 score = 4.491953E-05\r\n            // Class #1 score = 0.003848222\r\n            // Class #2 score = 0.0001245592\r\n            // ----------\r\n        }\r\n\r\n        // inputSize is the overall dimensions of the model input tensor.\r\n        private const int inputSize = 224 * 224 * 3;\r\n\r\n        // A class to hold sample tensor data. Member name should match  \r\n        // the inputs that the model expects (in this case, data_0)\r\n        public class TensorData\r\n        {\r\n            [VectorType(inputSize)]\r\n            public float[] data_0 { get; set; }\r\n        }\r\n\r\n        // Method to generate sample test data. Returns 2 sample rows.\r\n        public static TensorData[] GetTensorData()\r\n        {\r\n            // This can be any numerical data. Assume image pixel values.\r\n            var image1 = Enumerable.Range(0, inputSize).Select(x => (float)x / inputSize).ToArray();\r\n            var image2 = Enumerable.Range(0, inputSize).Select(x => (float)(x + 10000) / inputSize).ToArray();\r\n            return new TensorData[] { new TensorData() { data_0 = image1 }, new TensorData() { data_0 = image2 } };\r\n        }\r\n        public static string GetAbsolutePath(string relativePath)\r\n        {\r\n            FileInfo _dataRoot = new FileInfo(typeof(ApplyOnnxModel).Assembly.Location);\r\n            string assemblyFolderPath = _dataRoot.Directory.FullName;\r\n\r\n            string fullPath = Path.Combine(assemblyFolderPath, relativePath);\r\n\r\n            return fullPath;\r\n        }\r\n\r\n        // Class to contain the output values from the transformation.\r\n        // This model generates a vector of 1000 floats.\r\n        class Prediction\r\n        {\r\n            [VectorType(1000)]\r\n            //public float[] softmaxout_1 { get; set; }\r\n            public float[] classLabel { get; set; }\r\n\r\n        }\r\n    }\r\n}\r\n```\r\n[catdog.zip](https://github.com/dotnet/machinelearning/files/3302363/catdog.zip)\r\n'"
457221787,3874,b'Time series Sequential Transform RowImpl needs to have a binding mechanism',"b'We need to keep track of bindings when GetGetter is called in the case of DataTransformer, these bindings will be used to map column id to relative column id of the transformer.'"
457098169,3872,"b'Got ""Bad allocation"" exception when training 10gb data on database using Light GBM trainer'",b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample on using large datasets on database. The dataset I have used is criteo dataset for URL click prediction. I have imported the file into local SQL database and the size of local database is around 10GB. \r\n\r\nI am using LightGBM to do Binary classification. While training the model I got the below exception. Is there any issue with LightGBM to train Large datasets?\r\n\r\n```\r\n[LightGBM] [Warning] bad allocation\r\n\r\nC:\\Program Files\\dotnet\\dotnet.exe (process 2692) exited with code -1073740791.\r\nPress any key to close this window . . .\r\n```\r\n![image](https://user-images.githubusercontent.com/22335043/59629020-c8feb100-90f6-11e9-8f75-04b204d75ac7.png)\r\n\r\n\r\n### Source code / logs\r\n\r\nThe dataset file is taken from here \\\\ct01\\data\\Criteo\\Spark\\day_0-23_withHeader.tsv\r\n\r\nThe source code is available here  https://github.com/prathyusha12345/machinelearning-samples/tree/SQLDbSample/samples/csharp/getting-started/LargeDatasetsInSqlServer\r\n'
456834266,3871,b'Randomised PCA anomaly detection not detecting anomalies',"b'### System information\r\n\r\nWindows 10, .NET Core 2.2 console app, VS2019\r\n\r\n### Issue\r\n\r\n# SETUP\r\n\r\nGood morning. I am encountering some issues with the RPCA trainer and was hoping someone could help me out here. I\'m not really sure what I\'m doing wrong but I am not getting the results I would expect.\r\n\r\nI\'ve made a toy model to test out the ML.NET anomaly detection funtionality. I manufacture two random numbers for each data point, and call them gene one and gene two. They are constrained to lie in a particular range: gene one lies between .8 and .9, and gene two lies between .1 and .5. \r\n\r\nUsing a sample from this data (with the same seed each time),  I apply an RPCA pipeline. then I call fit, then transform the training data. \r\n\r\nI then make a gene entry with a ludicrous score (10000, 25000), and transform that to see where it lies. ML.Net claims this is not an anomaly.\r\n\r\n# PROBLEM\r\n\r\nI expect to see an anomaly. I\'ve tried this with less silly values, more silly values, with or without all the available kinds of normalisation, and reducing the rank of the PCA trainer.\r\n\r\n# LOGS\r\n\r\nHere\'s the output of the program. It shows the score, whether data is an inlier, and the transform of the data points.\r\n\r\nHere\'s the pipeline:\r\n\r\n```\r\nvar rpcaProjection = ct.Transforms.Concatenate(""Features"", ""GeneOneScore"", ""GeneTwoScore"")\r\n                  .Append(ct.Transforms.NormalizeMeanVariance(""NormalisedFeatures"", ""Features""))\r\n.Append(ct.AnomalyDetection.Trainers.RandomizedPca(featureColumnName: ""NormalisedFeatures"", rank: 2));\r\n```\r\n\r\nResults from transforming first 20 training data: Predicted, score, PCA co-ordinates\r\n\r\nTrue, 0.005851699, 0.7284454, 0.6617603\r\nTrue, 0.002783414, 1.028686, 0.7808771\r\nTrue, 0.004348077, 0.9824907, 1.543225\r\nTrue, 0.004398529, 1.021341, 0.510879\r\nTrue, 0.003683135, 1.005801, 1.091905\r\nFalse, NaN, 0.9997306, 1.01117\r\nTrue, 0.003618588, 1.004708, 0.8854353\r\nTrue, 0.004349507, 0.9971809, 1.588225\r\nTrue, 0.004412429, 1.018427, 0.4791145\r\nTrue, 0.003997049, 1.008593, 1.246756\r\nTrue, 0.004217377, 1.00574, 1.322197\r\nTrue, 0.004192073, 0.9794555, 1.412197\r\nTrue, 0.004289094, 1.019702, 1.569695\r\nTrue, 0.005468629, 1.021341, 1.083963\r\nTrue, 0.003488006, 1.007865, 0.7861712\r\nFalse, NaN, 1.025348, 0.9171998\r\nTrue, 0.004403637, 1.020734, 1.508814\r\nFalse, NaN, 0.9888039, 0.9224939\r\nTrue, 0.004757768, 1.009807, 0.8113181\r\nTrue, 0.004348857, 1.011143, 0.4394088\r\n\r\nResults from transforming the ""anomaly"": Predicted, score, PCA co-ordinates\r\nTrue, 0.006252703, **121407.6, 82720.04**\r\n\r\nI\'ve put this repo on github here:\r\n\r\nhttps://github.com/LDWDev/MLWoes/blob/master/MLtestapp/Program.cs\r\n\r\nCould anyone point out what is going on here? I would not expect the score to be the value it is.\r\n\r\nDo I need to give the trainer anomalous data? Why does the scorer think such distant values should be considered \'normal\'? I have had trouble finding useful documentation/tutorials on this.'"
455987251,3870,b'Need a way to predict a batch of examples in one call to Tensorflow',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Using Tensorflow extension, there's no support to predict a batch of examples in one call to Tensorflow.\r\n- **What happened?** This functionality is not supported at this time.\r\n- **What did you expect?** It would be good to support this functionality to improve efficiency in model prediction.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
455973386,3869,b'Getting OutOfMemory exception while training model on large datasets in file',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample  https://github.com/dotnet/machinelearning-samples/pull/520 to train a model on large datasets that are stored in a **file**. I am using BinaryClassification trainer. While training the model I am getting the OutOfMemory exception at the Fit() method as shown below.\r\n\r\n var model = trainingPipeLine.Fit(trainTestData.TrainSet);           \r\n\r\n![image](https://user-images.githubusercontent.com/22335043/59470767-99496380-8ded-11e9-9adb-3eb9d1d3ea43.png)\r\n\r\ncomplete details of error \r\n\r\n```\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Parsing failed with an exception: Stream reading encountered exception\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Data.TextLoader.Cursor.<ParseParallel>d__33.MoveNext()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.LinkedRowFilterCursorBase.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer.Train(IHostEnvironment env, IChannel ch, ColInfo[] infos, IDataView keyData, ColumnOptionsBase[] columns, IDataView trainingData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer..ctor(IHostEnvironment env, IDataView input, ColumnOptionsBase[] columns, IDataView keyData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingTransformer..ctor(ValueToKeyMappingEstimator term, IEstimator`1 toVector, IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at LargeDatasetsInSqlServer.Program.Main() in C:\\GitRepos\\Fork\\ML-samples\\ML-samples-LargeDataInFile\\samples\\csharp\\getting-started\\LargeDatasetsInFile\\LargeDatasetsInFile\\Program.cs:line 107\r\n\r\nInner Exception 1:\r\nFormatException: Stream reading encountered exception\r\n\r\nInner Exception 2:\r\nOutOfMemoryException: Insufficient memory to continue the execution of the program.\r\n\r\n\r\n```\r\nThe data set is copied from shared folder **\\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv**.\r\n\r\n### Source code / logs\r\n\r\nPlease find the entire source code from the  https://github.com/prathyusha12345/machinelearning-samples/tree/LargeDatasetsInFile/samples/csharp/getting-started/LargeDatasetsInFile\r\n'"
455967713,3868,b'Training 10gb of data in local SQL database is taking more than 14 hours',b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI tried to create  a sample  https://github.com/dotnet/machinelearning-samples/pull/498 to train data stored in local sql database. I tried to execute the sample . The training is not at all completing. I have started executing the sample since **14 hours** back. The model sis till showing as training.\r\n\r\nI wonder how long this training takes to execute 10gb of data. The data base contains 32 millions of records.\r\n\r\nI have copied the file from shared location \\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv. The actual file size is of **42 gb**. I imported the file manually into local SQL database which can have around **10gb** of data.\r\n\r\nCould anyone please let me know how long do I/user need to wait to train 10gb of data? I wanted to see when it will complete training.\r\n'
455945890,3867,b'Nonlinear Regression with Custom Target Function',"b""Is there a nonlinear regression or curve fitting class that supports custom functions of at least two independent variables and at least 5 parameters?\r\n\r\nI have a nonlinear regression problem that I need to solve using C#. I have a transfer function defined as:\r\n\r\nZ = A+1/(1/(X/256*B+3*C)+1/(Y/1024*D+2*E))\r\n\r\nWhere X and Y are my independent variables, Z is the output data I have to train from, and A-E are the parameters I need to the regression technique to solve. I have initial guesses for these parameters:\r\n\r\nA = 20\r\n\r\nB = 10000\r\n\r\nC = 50\r\n\r\nD = 50000\r\n\r\nE = 60\r\n\r\nI don't want to use generic regression models to estimate Z as I am specifically using the estimated parameters later on in the program. Any help would be greatly appreciated."""
455876099,3866,"b'Document what\'s supported in ""ONNX-ML.NET""'","b'@wschin, @codemzs \r\nRelated to ONNX. Can we have documented what is supported when using ONNX from ML.NET? - Either for both scenarios: 1. Export/convert model scenario and 2. Load ONNX model scenario.\r\n\r\nFor instance:\r\n\r\n- 1. When exporting ML.NET models to ONNX with [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview), will any type of ML.NET model work as ONNX model executed later on by the ONNX runtime from any other framework? **In ML.NET preview versions only certain ML.NET models could be exported to the ONNX-ML format. Is that still the case?** \r\n\r\n- 2. Can any type of loaded ONNX model run on ML.NET?\r\n\r\nFor instance, in the reference for [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview) it doesn\'t say what\'s supported and what\'s not.\r\n\r\n**Do we have any documentation stating what\'s supported and what\'s not supported in ""ONNX-ML.NET""?**\r\n\r\nIn addition to that, performance/accuracy comparison should also be covered due to issues like this:\r\n[ONNX Exports are Lossy](https://github.com/dotnet/machinelearning/issues/3206)'"
455846204,3865,b'Sanity check APIs from Microsoft.ML.OnnxTransfomer nuget',b'We plan to GA Microsoft.ML.OnnxTransfomer nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.'
455844908,3864,b'Sanity check APIs from Microsoft.ML.TimeSeries nuget',b'We plan to GA Microsoft.ML.TimeSeries nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.'
455843842,3863,b'Sanity check APIs from Microsoft.ML.Tensorflow nuget',b'We plan to GA Microsoft.ML.Tensorflow nuget in 1.2 release. Lets do a final pass on the binary and make sure we are only exposing relevant API.'
455842337,3862,b'Create forecasting prediction engine and conform time series forecasting API to estimator standards.',"b'Currently time series forecasting framework and API is a standalone entity. We must change that to be an estimator so that it fit seamlessly into the training pipeline. Do the following:\r\n\r\n1) Make SSA forecasting an estimator API.\r\n2) Create a fit(Idataview) that is used for training the forecasting model.\r\n3) Create a fit(IDataView, SSAModel) that is used for updating the forecasting model from a column in the IDataView\r\n4) Create a Transform(IDataView) that forecasts values up a horizon that is read from a column-row in the IDataView. Here forecasted values are represented as a variable sized vector in the column.\r\n5) Create a Transform() that forecasts values as a new IDataView where each forecasted value is its own row.\r\n\r\n**on 6/21 myself, @eerhardt  and @ganik agreed on the below design which @artidoro also agrees with**\r\n\r\n1) Make SSA forecasting an estimator API that trains on an input column and produces output columns for forecast and min/max confidence intervals.\r\n2) Transform(IDataView) call will forecast values while reading values from the input column and updating the forecast model. This means ""I forecast values after having seen this new value in the input column."" this is good for say real-time stock prediction. While the forecast model gets updated in real time but it cannot be saved to disk for later use with updated values. This will be useful for rolling-CV time series elevator. \r\n~~3) Expose forecasting prediction engine from time series prediction that allows to forecast values and also allows changing forecasting model parameters such as horizon and confidence intervals. It allows to forecast values without feeding in any value, allows to update the model with new observations and saving the updated the model to disk at any time.~~\r\n3) Enhance TimeSeriesPrediction to handle anomaly detection and forecasting seamlessly and provide experience very close to that of regular prediction engine. This can by achieved by creating following variants of Predict()\r\n   1) TDst Predict(int? horizon = null, float? confidenceLevel = null): Forecasts based on output columns specified in TDst.\r\n   2) TDst Predict(TSrc input, int? horizon = null, float? confidenceLevel = null): Updates the model with input and then predicts on TDst, here predict could be anomaly detection or forecasting. \r\n   3) void Predict(TSrc input, ref TDst output,  int? horizon = null, float? confidenceLevel = null) : if input is null it means its a forecasting task, if output is null it means it is an update, both are null nothing is done, if both are present, model is updated and prediction is made on the output columns. This function is used to override the void Predict(TSrc input, ref TDst output) that is exposed by base prediction engine class.\r\n\r\nCC: @ganik @artidoro @yaeldekel @CESARDELATORRE @eerhardt '"
455446582,3858,b'AutoML 0.3.0 does not generate namespace properly when solution name contains space',"b'### System information\r\n\r\n- **OS version/distro**: \r\nOS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n- **.NET Version (eg., dotnet --info)**: \r\n Version:   3.0.100-preview5-011568\r\n Commit:    b487ff10aa\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFollowed the tutorial on using AutoML from https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial/scenario but used a project name as ""AutoML Sentiment"". Note: It contains a space.\r\n- **What happened?**\r\nAutoML did not consider the space in the project name. Generated code below gives a compile error.\r\n```\r\n//*****************************************************************************************\r\n//*                                                                                       *\r\n//* This is an auto-generated file by Microsoft ML.NET CLI (Command-Line Interface) tool. *\r\n//*                                                                                       *\r\n//*****************************************************************************************\r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing AutoML SentimentML.Model.DataModels;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace AutoML SentimentML.ConsoleApp\r\n{\r\n    public static class ModelBuilder\r\n    {\r\n............\r\n    }\r\n}\r\n```\r\n- **What did you expect?**\r\nI expected that AutoML should replace the space with ""_"" in order to compile as shown below:\r\n\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing AutoML_SentimentML.Model.DataModels;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace AutoML_SentimentML.ConsoleApp\r\n{\r\n    public static class ModelBuilder\r\n    {\r\n............\r\n    }\r\n}\r\n```'"
455352795,3856,b'Multi class LR behaves differently on .NetCore 3.0',b'Four tests are failing on the .NetCore 3.0 builds:\r\n`EnsemblesMultiAveragerTest`\r\n`EnsemblesMultiClassBootstrapSelectorTest`\r\n`EnsemblesMultiVotingCombinerTest`\r\n`EnsemblesMultiStackCombinerTest`\r\n\r\nThe difference in the baselines is something like this:\r\n`L1 regularization selected 13 of 15 weights.` vs.\r\n`L1 regularization selected 11 of 15 weights.`\r\n\r\n'
455317777,3855,b'ARIMA with linear regressors time series modelling',b'This was mentioned in some other issues that have now been closed following the first release of time series functionality.\r\n\r\nWe currently use ARIMA with linear regressors. There may be better algorithms but it works well for us and is fairly simple to understand and implement.\r\n\r\nIf you can add basic models like this and somebody produces a C#/F# equivalent of the [Forecasting Principles and Practices e-book](https://otexts.com/fpp2/intro.html) then you might be able to support quite a few people who are just getting started with time series forecasting.'
454287849,3849,b'MlNetCookBook is not up to date with latest API',"b'For example, here:\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#i-want-to-look-at-my-models-coefficients\r\n\r\nit has this line\r\n```\r\nmlContext.MulticlassClassification.Trainers.SdcaCalibrated()\r\n```\r\nbut `SdcaCalibrated` has been renamed to `SdcaMaximumEntropy`.\r\n\r\n(related to issue #3847).'"
454276445,3848,b'Integration of time series nuget with NimbusML',"b'This will require creation of missing entry points and testing, including, time series prediction engine and forecasting API.'"
453959866,3847,b'Question: Feature weights (importance) for LightGBM',"b'The documentation https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#i-want-to-look-at-my-models-coefficients shows a way to get the feature importance, but when I try to use the code samples I got an error in the ""LastTransformer"" saying it was not found in the TTransformer class. \r\n\r\nI looked at the samples but I could not find a code example. I am using LightGBM.   \r\nThe issue https://github.com/dotnet/machinelearning/issues/576 is related but the replies did not helped as well.\r\n\r\nAny hints? \r\n'"
453740725,3846,b'ML.NET support for CNTK',"b'Does ML.NET support CNTK? I see support for Tensorflow, what about the MS initiative for CNTK. Is that abandon now?'"
453664353,3845,b'Equivalent of SVM.SVC of slkearn',"b""We use the following from sklearn for training our model for multi-class text classification\r\nWhat would be the equivalent in ML.Net ?\r\n\r\nclfsvm = Pipeline([('vect', CountVectorizer(tokenizer=tokenize, lowercase=True, stop_words=stop_words, ngram_range=(2,2))),\r\n                          ('tfidf', TfidfTransformer(use_idf = False)),\r\n                             ('clf', SVC(kernel = 'linear', probability = True)),])\r\nclfsvm.fit(df_train, df_label)\r\n\r\nhttps://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\r\n"""
453661554,3844,b'Porting algorithm - Multinomial NB',"b""\r\n@codemzs Not finding multinomial NB as part of the ML.Net algorithms which we use for intent detection.\r\n\r\n\r\nFrom nb sci kit learn libraries:\r\nhttps://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\r\n\r\nclfnb = Pipeline([('vect', CountVectorizer(tokenizer=None, lowercase=True, stop_words=None, ngram_range=(1,2))), \r\n                  ('tfidf', TfidfTransformer(use_idf = True)),\r\n                  ('clf', MultinomialNB()),])\r\nclfnb.fit(df_train, df_label)\r\n\r\n\r\n"""
453654650,3843,b'Missing algorithms - SGD modified_huber',"b'@codemzs \r\nI am from the marketing automation team at MSFT and doing intent detection on lead emails. We use the SGD and SVM in sci-kit learn in production and find it missing in ML.Net. Could you look into adding\r\nSGD with following loss function:\r\nloss=""hinge"": (soft-margin) linear Support Vector Machine,\r\nloss=""modified_huber"": smoothed hinge loss,\r\nloss=""log"": logistic regression,\r\n\r\nWe are getting 10%+ points increase in accuracy using modified_huber rather than hinge or log loss function. All the loss functions would be important for us priority would be\r\n1. Modified_huber\r\n2. hinge\r\n3. log\r\n\r\nhttps://scikit-learn.org/stable/modules/sgd.html#classification\r\n'"
453624657,3841,b'CreateTextLoader documentation is missing details',"b""The following parameters of CreateTextLoader API are missing detailed explanation and proper example:\r\n\r\n* allowSparse: what is the sparse format?  + example\r\n* allowQuoting: what does this exactly mean? does quoting cause the separator within quotes to be skipped? Is it single quotes or double quotes?\r\n* hasHeader: seems like hasHeader only causes the header line to be skipped, but it doesn't help with automatic detection of column names. Is that the case?\r\n * dataSample: needs sample\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: a745f3b1-1356-0888-4804-f6141496da18\r\n* Version Independent ID: 0a2d7c9e-9319-8393-bb4a-058bf72450ba\r\n* Content: [TextLoaderSaverCatalog.CreateTextLoader Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.textloadersavercatalog.createtextloader?view=ml-dotnet#Microsoft_ML_TextLoaderSaverCatalog_CreateTextLoader_Microsoft_ML_DataOperationsCatalog_Microsoft_ML_Data_TextLoader_Column___System_Char_System_Boolean_Microsoft_ML_Data_IMultiStreamSource_System_Boolean_System_Boolean_System_Boolean_)\r\n* Content Source: [dotnet/xml/Microsoft.ML/TextLoaderSaverCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TextLoaderSaverCatalog.xml)"""
453305449,3838,b'Enable Binary Classification Metric Calculation on Huge Datasets',"b""From experimenting, it seems like calculating binary classification metrics does not scale to huge datasets. Taking a heap dump to examine the high memory usage (before the program runs out of memory), I see a list of floats used by `UnweightedAucAggregator`. It looks like, to calculate AUC, every prediction is kept in memory. It also looks like there is already substantial logic to account for this scenario -- there's logic to reservoir sample predictions, and then calculate AUC on the sample. However, it looks like the size of the internal parameter `MaxAucExamples` to control the size of this reservoir sample is always set to -1, and not exposed to the end user?https://github.com/dotnet/machinelearning/blob/610ffcb67083c2e5e6e1a14884ba24b1da0384c7/src/Microsoft.ML.Data/Evaluators/BinaryClassifierEvaluator.cs#L45 \r\nPerhaps we should somehow expose this parameter to enable binary metric calculation on huge datasets, or set the parameter to some reasonable default\r\n@justinormont, @vinodshanbhag """
453293411,3836,b'ONNXTransformer can be upgraded',"b'ONNXRuntime has released 0.4.0 version, so ML.NET needs to be upgraded to include newly added features.\r\n\r\nWorking items:\r\n- Add new types to enable ONNX dictionary and sequence.\r\n- Enrich tests.'"
453168427,3833,"b'Move Time Series, TensorFlow and OnnxConverter nugets to stable API.'",b'We plan to GA them in 1.2 release.'
452731072,3832,"b""Add an example for key type's missing value""","b""Related to #3831. Add an in-memory example to explain key type's missing value 0.\r\n\r\n"""
452659656,3830,b'SDCA .Fit() never returns when running in an ASP.NET MVC Full .NET Framework 4.6.1 / 4.7.2',b'When running the sentiment analysis sample this line never returns. No exception is thrown.\r\n`// STEP 4: Train the model fitting to the DataSet\r\n            ITransformer trainedModel = trainingPipeline.Fit(trainingData);`\r\n\r\nThis is not the case in .net core web apps or .NET Framework 4.6.1 console apps. Only MVC.\r\n\r\nYou can recreate the issue by creating a brand new ASP.NET MVC .NET Framework 4.6.1 Web Application. Changing to target x64. Installing the Microsoft.ML nuget and running the sentiment analysis code.\r\n\r\nThanks.\r\n\r\n\r\n'
452587012,3829,b'Support dynamic types when working with IDataView',"b'### Issue\r\n\r\nI want to read my data from the `.csv` file. I think it may be done without strongly-typing my objects. In C#, we have two potential abilities: [_Anonymous Types_](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/anonymous-types) and [_Dynamic Types_](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/using-type-dynamic). \r\n\r\nI tried to check how the existing code could be adapted, but I could not fully understand the code.\r\n'"
452399201,3828,b'Provide access to eigenvalues used for PCA transformation',"b'In PcaTransformer.cs, class TransformInfo has an eigenvectors field. I assume it stores the eigenvectors retrieved from the SVD decomposition. Can we have access to the eigenvalues that the SVD provided.\r\n\r\nI think it might be useful to store and provide the eigenvalues used during the PCA. Is this possible?\r\ni.e I see in Accord you can do something like pca.Eigenvalues. \r\nhttp://accord-framework.net/docs/html/T_Accord_Statistics_Analysis_PrincipalComponentAnalysis.htm\r\n\r\nThank you!\r\n\r\n\r\n\r\n'"
452259513,3826,b'String column being getting converted to int',"b'My dataset looks something like this\r\n\r\n```\r\nID\tArea\tTitle\tDescription\r\n""7""\tarea-System.Runtime.InteropServices\t""Splitting XLinq classes into separate files, after rebasing the commits.""\t""""\r\n""12""\tarea-System.Runtime.InteropServices\t""Remove or cache some unnecessary allocations""\t""I noticed a few places where allocations were occurring unnecessary: - Across several of the immutable and XML collection types, the ICollection.CopyTo implementations were calling Array.SetValue in a loop; the second parameter to SetValue is a params array, so each iteration of the loop was resulting in allocating a new array... I\'ve lifted that implicit allocation out to be an explicit one before the loop. - In a couple of places in the XML library and the metadata reader, string.Trim\\* was being used, either with an array of the same characters unnecessarily being allocated each time, or an implicitly allocated array of constant chars to fill a params array parameter.  I\'ve replaced those with statically cached arrays. - In a couple of places in the XML library, a string was being constructed around a single character via creating a new char array; I\'ve replaced that with usage of string\'s ctor that takes a character and a count, avoiding the unnecessary char[] allocation. ""\r\n""13""\tarea-System.Runtime.InteropServices\t""Remove unnecessary unsafe code flag.""\t""The Immutable PCL targets platforms that include those that don\'t support unsafe code. Opening the solution in VS2015 results in a warning in the error list about this. But features that required unsafe code were recently removed so we don\'t need this flag any more. ""\r\n""17""\tarea-System.Xml\t""Some XPath.XDocument tests are failing""\t""Some XPath.XDocument queries have different results than other XPath navigators. This might be an old behavior or newly introduced bug.  Failing tests: build /p=IncludeTraits=ActiveIssue=17 ""\r\n""20""\tarea-System.Xml\t""2 XPath.XDocument tests fail because of lacking feature""\t""XPath.XDocument navigator doesn\'t support MoveToId(string).  Verify if this was ever supported. If it was, verify if we want to support it in the future. If it wasn\'t move the tests to a different file and remove them from XPath.XDocument.Tests project.  Failing tests: NodeSetFunctionsTest2267 MatchesTest2352  <!--- @huboard:{""order"":20.0,""milestone_order"":20,""custom_state"":""""} --> ""\r\n""22""\tarea-System.Numerics\t""Two Numerics Tests are failing only on our CI server""\t""Two of the tests in our System.Numerics.Vectors suite are failing only on our CI build server, and potentially only intermittently:  Vector2NormalizeTest1 Vector4NormalizeTest2  Given that these are very similar to other tests which cover a similar edge-case (especially the Vector3 normalization tests, which aren\'t failing), we will need to investigate why these tests in particular are failing on our build server. This may have been a point-in-time issue as we brought up our build infrastructure, and may not re-surface again. ""\r\n""36""\tarea-System.Numerics\t""SIMD test failures on non-ENU configurations.""\t""After pulling both of @adamralph \'s pull requests #31 and #32, I\'m continuing to see test failures for SIMD on a DEU (German) test environment.  Here\'s a representative error: d:\\oss\\corefx\\src\\System.Numerics.Vectors\\tests\\GenericVectorTests.cs(545): error : System.Numerics.Tests.GenericVe ctorTests.ToStringCurrencySByte: Assert.Equal() Failure\\r\\nPosition: First difference is at position 8\\r\\nExpected:  <97,00 ?, -108,00 ?, 22,00 ?, 29,00 ?, 49,00 ?, 60,00 ?, 103,00 ?, 58,00 ?, -62,00 ?, -124,00 ?, -117,00 ?, 48,00 ?, 15,00 ?, -35,00 ?, -13,00 ?, -34,00 ?>\\r\\nActual:   <97,00 ?. -108,00 ?. 22,00 ?. 29,00 ?. 49,00 ?. 60,00 ?. 103 ,00 ?. 58,00 ?. -62,00 ?. -124,00 ?. -117,00 ?. 48,00 ?. 15,00 ?. -35,00 ?. -13,00 ?. -34,00 ?> [D:\\oss\\corefx\\bin\\ tools\\fxbuild.proj]  Observe that expected separates elements with a comma, actual separates elements with a dot. ""\r\n""41""\tarea-System.Numerics\t""Quaternion operator overloads should be using the respective methods""\t""Quaternion declares a handful of methods to perform addition, subtraction and multiplication, and provides the respective overloads for these operations.  However, instead of re-using the `Add`, `Multiply` etc. methods, the code is re-written in the operator overloads. The operators should be using their respective methods rather than re-declaring the same code.  This is under the assumption that the JIT inlines the methods when they are used in the operator overloads. ""\r\n""49""\tarea-Infrastructure\t""Add Linux/Mac build script""\t""A `build.sh` should be added alongside `build.cmd` to build corefx on Linux/Mac. ""\r\n```\r\n\r\n\r\nI want the auto-ml bot to consider the first column as a string but it is always converting it to float column\r\nIt would be nice to have some way of specifying the column types.\r\n\r\ncc @danmosemsft @eerhardt @daholste '"
452216686,3822,b'LightGbm default evaluation metrics in ML.NET do not conform to standalone LightGbm',"b'Found while investigating fix for #3761 \r\n\r\nIn ML.NET LightGbm wrapper, the default EvaluationMetric is set to EvaluateMetricType.Error for multiclass, EvaluationMetricType.LogLoss for binary, and so on. On the other hand, in standalone LightGbm, the default evaluation metric is """", which means that LightGbm will automatically select the default metric for the given objective function.\r\n\r\nThis leads to inconsistent behavior from the user\'s perspective: If a user specified EvaluationMetric = EvaluateMetricType.Default, the parameter passed to LightGbm would be the empty string """" but if they do not specify EvaluationMetric at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on.\r\n\r\nWe need to investigate whether these metrics are indeed the defaults for the respective objective functions in LightGbm, and if they are not, then change the defaults in ML.NET to conform to standalone LightGbm. Note that this would be a breaking change.'"
452151473,3818,"b'NativeAssemblyReference Include ""MklProxyNative"" in Samples project.'",b'Need to the above dependency to have some timer series samples work that use MKL '
452037688,3817,b'how will you know this at the time of coding...',b'I guess it would be appropriate to set this value at runtime as a developer can hardly know what runtime value will be in effect without knowing the data.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 8d7b6ec7-078a-9f61-3250-ceba1a3a1846\n* Version Independent ID: 13902a2a-592f-a075-a68e-b09002f8e714\n* Content: [LightGbmBinaryTrainer.Options.WeightOfPositiveExamples Field (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmbinarytrainer.options.weightofpositiveexamples?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer+Options.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer+Options.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
451946297,3816,"b""System.ArgumentException: 'Length of memory  must match product of dimensions.""","b'- windows 10\r\n- 4.7.NET Version  \r\n- ML dotnet 1.0\r\n- Visual Studio 15.9.12\r\n\r\nIssue:\r\n\r\nI\'m quite new to .net, however I\'m trying to replicate CRNN model developed on keras to ML dotnet. I successfully converted the model to onnx format. But when I try to make a prediction I\'m getting this:\r\n _System.ArgumentException: \'Length of memory (9600) must match product of dimensions (3200).\'_\r\nI didn\'t find any issue or something so that is way I\'m writing here.\r\n\r\nI can assume that the problem might be somewhere in image transformation. My model is built for grayscale images with the shape of (1, 1, 32, 100) and there I have this conflict between:\r\n1x32x100 = 3200 (should be)  vs  3x32x100 = 9600 (actually is)\r\n\r\nI\'ve tried to transform images to grayscale, but it doesn\'t work (perhaps I do it in a wrong way).\r\n\r\nThis is my snipped code for building the pipeline:\r\n\r\n`\r\n\r\n        int imageHeight = 32;\r\n        int imageWidth = 100;\r\n        bool ChannelsLast = false;\r\n        string ModelInput = ""conv2d_1_input_01"";\r\n        string ModelOutput = ""dense_1_add_0"";\r\n\r\n\r\n        var pipeline = mLContext.Transforms.LoadImages(outputColumnName: ""conv2d_1_input_01"",\r\n                                                           imageFolder: imagesLocation,\r\n                                                           inputColumnName: nameof(ImageData.ImagePath))\r\n            .Append(mLContext.Transforms.ResizeImages(outputColumnName: ""conv2d_1_input_01"",\r\n                                                            imageWidth: imageWidth,\r\n                                                            imageHeight: imageHeight))\r\n            .Append(mLContext.Transforms.ConvertToGrayscale(outputColumnName:\r\n                                                            ""conv2d_1_input_01""))\r\n            .Append(mLContext.Transforms.ExtractPixels(outputColumnName: ""conv2d_1_input_01"", interleavePixelColors: ImageSettings.ChannelsLast))\r\n            .Append(mLContext.Transforms.ApplyOnnxModel(modelFile: modelLocation,\r\n                                                            outputColumnNames: new[] { ModelOutput },\r\n                                                            inputColumnNames: new[] { ModelInput }));\r\n`\r\n\r\nI would appreciate any help or comments.'"
451719517,3813,b'Can we make NeedCalibration property of TrainerInfo public?',b'Could we make the `NeedCalibration` property in `TrainerInfo` public?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7ca768a8740c5c873c7f26f2c71e0fa3ea28ea40/src/Microsoft.ML.Core/Prediction/TrainerInfo.cs#L30\r\n\r\nThis would help AutoML know when & when not to calibrate'
451702484,3811,"b""CreateTextLoader isn't respecting the KeyType attribute""","b""### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.503\r\n Commit:    4c506e0f35\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.14393\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.503\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.7\r\n  Commit:  cca5d72d48\r\n\r\n.NET Core SDKs installed:\r\n  2.1.503 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\nI used LoadFromTextFile to load data where the loaded poco object has the KeyType attribute applied as follows:\r\n\r\n   private class DataPoint\r\n        {\r\n            [LoadColumn(0), KeyType(5)]\r\n            public uint Label { get; set; }\r\n            [LoadColumn(1), KeyType(100)]\r\n            public uint GroupId { get; set; }\r\n            [LoadColumn(2,52), VectorType(50)]\r\n            public float[] Features { get; set; }\r\n        }\r\n\r\nWhen I call Fit using the LightGbm algorithm, I see the following exception because the KeyType attribute isn't being respected when loading from a text file:\r\n\r\nSystem.ArgumentOutOfRangeException  HResult=0x80131502\r\n  Message=Schema mismatch for label column 'Label': expected Single or Key, got UInt32\r\nParameter name: labelCol\r\n  Source=Microsoft.ML.LightGbm\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer.<>c__DisplayClass9_0.<CheckLabelCompatible>b__0() in E:\\A\\_work\\449\\s\\src\\Microsoft.ML.LightGbm\\LightGbmRankingTrainer.cs:line 240\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer.CheckLabelCompatible(Column labelCol) in E:\\A\\_work\\449\\s\\src\\Microsoft.ML.LightGbm\\LightGbmRankingTrainer.cs:line 246\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n\r\nInstead, the KeyType attribute should be respected when loading from a text file.\r\n\r\n### Source code / logs\r\nRun the attached code which uses the attached data.\r\n[SampleKeyRepro.txt](https://github.com/dotnet/machinelearning/files/3249574/SampleKeyRepro.txt)\r\n\r\n[MyTestData.txt](https://github.com/dotnet/machinelearning/files/3249578/MyTestData.txt)\r\n\r\n\r\n\r\n"""
451661805,3810,b'why sampling key column is being added while Loading IDataView from Dataset stored Database ',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n### Issue\r\n\r\n- I am trying to create a sample to load data stored in SQL Server database. while loading data from database using mlContext.Data.TrainTestSplit(dataView) method, it adds a column called **SamplingKeyColumn**.  But this column is not added while **loading data from file**. \r\n\r\nI want to understand why this **SamplingKeyColumn** column is being added while loading from **Database**  but not while loading from file.\r\n'"
451611014,3808,b'TreeFeaturizer w/ Subsampling',"b'To support TB+ scale datasets, we should have a row sub-sampling parameter in the Tree Featurizer.\r\n\r\nWhy `TreeFeat`? The Tree Featurizer learns the feature interactions on a sub-set of the dataset. The `leaves` output of Tree Featurizer is then sent to a linear model (SDCA/AP/etc) which is scalable to TB scale datasets.\r\n\r\n**Gain**:\r\nThis provides an end-to-end solution for scalable learning. You get the accuracy of the Tree model plus the streamability of the linear model.\r\n\r\n**Request**:\r\n* Provide a `subsample` parameter for `TreeFeat`\r\n* Inside `TreeFeat` run the `TrainTestSplit` to get the correct subsample percent\r\n\r\n**Other solutions**:\r\n* TrainTest split to create a sub-sample of the dataset before `TreeFeat`, and train `TreeFeat` on this subsample. This fails in CV since you need a singular dataview to train on.\r\n* Shuffle + Take. This fails since our shuffle is block-wise; the 1st 4k rows are shuffled against each other, then the next 4k rows are independently shuffled against each other. This leads to the Take only receiving rows from the top of the file. Also fails in CV.\r\n* Generate + RangeFilter. We hid our Generate transform. Also fails in CV. \r\n\r\nWe would like to use the `TreeFeat` plus a streamable Linear model in AutoML to provide a good model to the user on datasets larger than RAM.'"
451595334,3807,b'csv files with colums containing commas are not splitted correctly',"b'I am trying to train a model on a github issue dataset. \r\n The dataset contains 4 columns ID, Title, Descriptions and label\r\n\r\n```\r\n7,""Splitting XLinq classes into separate files, after rebasing the commits."","""",area-System.Runtime.InteropServices\r\n12,""Remove or cache some unnecessary allocations"",""I noticed a few places where allocations were occurring unnecessary: - Across several of the immutable and XML collection types, the ICollection.CopyTo implementations were calling Array.SetValue in a loop; the second parameter to SetValue is a params array, so each iteration of the loop was resulting in allocating a new array... I\'ve lifted that implicit allocation out to be an explicit one before the loop. - In a couple of places in the XML library and the metadata reader, string.Trim\\* was being used, either with an array of the same characters unnecessarily being allocated each time, or an implicitly allocated array of constant chars to fill a params array parameter.  I\'ve replaced those with statically cached arrays. - In a couple of places in the XML library, a string was being constructed around a single character via creating a new char array; I\'ve replaced that with usage of string\'s ctor that takes a character and a count, avoiding the unnecessary char[] allocation. "",area-System.Runtime.InteropServices\r\n13,""Remove unnecessary unsafe code flag."",""The Immutable PCL targets platforms that include those that don\'t support unsafe code. Opening the solution in VS2015 results in a warning in the error list about this. But features that required unsafe code were recently removed so we don\'t need this flag any more. "",area-System.Runtime.InteropServices\r\n17,""Some XPath.XDocument tests are failing"",""Some XPath.XDocument queries have different results than other XPath navigators. This might be an old behavior or newly introduced bug.  Failing tests: build /p=IncludeTraits=ActiveIssue=17 "",area-System.Xml\r\n20,""2 XPath.XDocument tests fail because of lacking feature"",""XPath.XDocument navigator doesn\'t support MoveToId(string).  Verify if this was ever supported. If it was, verify if we want to support it in the future. If it wasn\'t move the tests to a different file and remove them from XPath.XDocument.Tests project.  Failing tests: NodeSetFunctionsTest2267 MatchesTest2352  <!--- @huboard:{""order"":20.0,""milestone_order"":20,""custom_state"":""""} --> "",area-System.Xml\r\n22,""Two Numerics Tests are failing only on our CI server"",""Two of the tests in our System.Numerics.Vectors suite are failing only on our CI build server, and potentially only intermittently:  Vector2NormalizeTest1 Vector4NormalizeTest2  Given that these are very similar to other tests which cover a similar edge-case (especially the Vector3 normalization tests, which aren\'t failing), we will need to investigate why these tests in particular are failing on our build server. This may have been a point-in-time issue as we brought up our build infrastructure, and may not re-surface again. "",area-System.Numerics\r\n36,""SIMD test failures on non-ENU configurations."",""After pulling both of @adamralph \'s pull requests #31 and #32, I\'m continuing to see test failures for SIMD on a DEU (German) test environment.  Here\'s a representative error: d:\\oss\\corefx\\src\\System.Numerics.Vectors\\tests\\GenericVectorTests.cs(545): error : System.Numerics.Tests.GenericVe ctorTests.ToStringCurrencySByte: Assert.Equal() Failure\\r\\nPosition: First difference is at position 8\\r\\nExpected:  <97,00 ?, -108,00 ?, 22,00 ?, 29,00 ?, 49,00 ?, 60,00 ?, 103,00 ?, 58,00 ?, -62,00 ?, -124,00 ?, -117,00 ?, 48,00 ?, 15,00 ?, -35,00 ?, -13,00 ?, -34,00 ?>\\r\\nActual:   <97,00 ?. -108,00 ?. 22,00 ?. 29,00 ?. 49,00 ?. 60,00 ?. 103 ,00 ?. 58,00 ?. -62,00 ?. -124,00 ?. -117,00 ?. 48,00 ?. 15,00 ?. -35,00 ?. -13,00 ?. -34,00 ?> [D:\\oss\\corefx\\bin\\ tools\\fxbuild.proj]  Observe that expected separates elements with a comma, actual separates elements with a dot. "",area-System.Numerics\r\n41,""Quaternion operator overloads should be using the respective methods"",""Quaternion declares a handful of methods to perform addition, subtraction and multiplication, and provides the respective overloads for these operations.  However, instead of re-using the `Add`, `Multiply` etc. methods, the code is re-written in the operator overloads. The operators should be using their respective methods rather than re-declaring the same code.  This is under the assumption that the JIT inlines the methods when they are used in the operator overloads. "",area-System.Numerics\r\n49,""Add Linux/Mac build script"",""A `build.sh` should be added alongside `build.cmd` to build corefx on Linux/Mac. "",area-Infrastructure\r\n50,""Made Quarternion\'s operator overloads use their respective methods"",""Operator overloads of Quaternion now utilize their respective methods, and removed redundant ""this"" qualifiers in Quaternion constructor. "",area-System.Numerics\r\n52,""ReferenceSource repo license incorrect for individual files"",""some of the files I looked up, it has header comment with Apache 2.0 license. which license should apply for those files? MIT or Apache 2.0 "",area-Meta\r\n54,""Remove always true ""if"" and unreachable code in System.Xml.Linq.XObject.SkipNotify method."",""This: if (o.Annotations<XObjectChangeAnnotation>() != null)  is always true because the above while can finish only in two conditions: when o != null or when o.annotations == null. The first condition will be catched by "" if (o == null)"" and if the second one is true, ""o.Annotations<XObjectChangeAnnotation>() != null"" will also always be true i think. "",area-System.Xml\r\n55,""[Issue 54] Removed always-true if and unreachable code in XObject.cs"",""Removed always-true if and unreachable code in XObject.cs "",area-System.Xml\r\n58,""System.Xml.sln fails to build on Mono, error CS0433"",""**I know that cross-platform support is coming later, I just thought it might make sense to document this here in case someone else tries the same**  Building System.Xml.sln with xbuild on Mono doesn\'t work (the other solutions build fine), it throws the following errors:  ``` Build FAILED. Errors:  /home/alexander/dev/corefx/src/System.Xml.sln (default targets) -> (Build target) -> /home/alexander/dev/corefx/src/System.Xml.XPath.XDocument/System.Xml.XPath.XDocument.csproj (default targets) -> /usr/lib/mono/4.5/Microsoft.CSharp.targets (CoreCompile target) ->      System/Xml/XPath/XAttributeExtensions.cs(10,56): error CS0433: The imported type `System.Xml.Linq.XAttribute\' is defined multiple times     System/Xml/XPath/XAttributeExtensions.cs(10,78): error CS0433: The imported type `System.Xml.Linq.XNamespace\' is defined multiple times     System/Xml/XPath/XDocumentExtensions.cs(22,61): error CS0433: The imported type `System.Xml.Linq.XNode\' is defined multiple times     System/Xml/XPath/XObjectExtensions.cs(10,23): error CS0433: The imported type `System.Xml.Linq.XContainer\' is defined multiple times     System/Xml/XPath/XObjectExtensions.cs(10,49): error CS0433: The imported type `System.Xml.Linq.XObject\' is defined multiple times     System/Xml/XPath/XNodeNavigator.cs(48,9): error CS0433: The imported type `System.Xml.Linq.XElement\' is defined multiple times     System/Xml/XPath/XNodeNavigator.cs(784,35): error CS0433: The imported type `System.Xml.Linq.XText\' is defined multiple times ```  It looks like it runs into a conflict with the System.Xml.Linq library in the Mono GAC. Needs further investigation. "",area-System.Xml\r\n69,""build.cmd does not build solution on HP laptop (when Platform=MCD is pre-set)"",""I\'ve got HP laptop with windows 7. When I run build.cmd, I\'ve got the error ""configuration is invalid""  ``` C:\\Projects\\dotnet\\corefx>build.cmd C:\\Projects\\dotnet\\corefx\\src\\System.Collections.Immutable.sln.metaproj : error MSB4126: \xd1\x83\xd0\xba\xd0\xb0\xd0\xb7\xd0\xb0\xd0\xbd\xd0\xbd\xd0\xb0\xd1\x8f \xd0\xba\xd0\xbe\xd0\xbd\xd1\x84\xd0\xb8\xd0\xb3\xd1\x83\xd1\x80\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xd1\x80\xd0\xb5\xd1\x88\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f ""Release|MCD"" \xd0\xbd\xd0\xb5\xd0\xb4\xd0\xbe\xd0\xbf\xd1\x83\xd1\x81\xd1\x82\xd0\xb8\xd0\xbc\xd0\xb0. \xd0\xa3\xd0\xba\xd0\xb0\xd0\xb6\xd0\xb8\xd1\x82\xd0\xb5 \xd0\xb4\xd0\xbe\xd0\xbf\xd1\x83\xd1\x81\xd1\x82\xd0\xb8\xd0\xbc\xd1\x83\xd1\x8e \xd0\xba\xd0\xbe\xd0\xbd\xd1\x84\xd0\xb8\xd0\xb3\xd1\x83\xd1\x80\xd0\xb0\xd1\x86 \xd0\xb8\xd1\x8e \xd1\x80\xd0\xb5\xd1\x88\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd1\x81 \xd0\xbf\xd0\xbe\xd0\xbc\xd0\xbe\xd1\x89\xd1\x8c\xd1\x8e \xd1\x81\xd0\xb2\xd0\xbe\xd0\xb9\xd1\x81\xd1\x82\xd0\xb2 Configuration \xd0\xb8 Platform (\xd0\xbd\xd0\xb0\xd0\xbf\xd1\x80\xd0\xb8\xd0\xbc\xd0\xb5\xd1\x80, MSBuild.exe Solution.sln /p:Configuration=Debug /p:Platform=""Any CPU"") \xd0\xb8\xd0\xbb\xd0\xb8 \xd0\xbe\xd1\x81\xd1\x82\xd0\xb0\xd0\xb2\xd1\x8c\xd1\x82\xd0\xb5 \xd1\x8d\xd1\x82\xd0\xb8 \xd1\x81\xd0\xb2\xd0\xbe\xd0\xb9\xd1\x81\xd1\x82\xd0\xb2\xd0\xb0 \xd0\xbf\xd1\x83\xd1\x81\xd1\x82\xd1\x8b\xd0\xbc\xd0\xb8, \xd1\x87\xd1\x82\xd0\xbe\xd0\xb1\xd1\x8b \xd0\xb8\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd1\x8c\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd1\x8c \xd0\xba\xd0\xbe\xd0\xbd\xd1\x84\xd0\xb8\xd0\xb3\xd1\x83\xd1\x80\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8e \xd1\x80\xd0\xb5\xd1\x88\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xd0\xbf\xd0\xbe \xd1\x83\xd0\xbc\xd0\xbe\xd0\xbb\xd1\x87\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x8e. [C:\\Projects\\dotnet\\corefx\\src\\System.Collections.Immutable.sln] ```  The reason of this error is that environment variable `Platform` is set to `MCD` on the laptop by default. I have to change build command in the build.cmd by adding `/p:Platform=""Any CPU""` to compile the project.  Build script should check for allowed platforms and generate user-friendly error message, which says what to do to successfully compile the project when the platform is not supported.  "",area-Infrastructure\r\n70,""""Hello, World!"" sample"",""Feature request: please add ""Hello, World!"" sample, which shows how to use .NET Core with user applications. "",area-Meta\r\n71,""Behaviour of `Quaternion.CreateFromAxisAngle` when axis is not a unit vector"",""The resulting quaternion depends on the length of `axis`. This does not describe a rotation and thus does not match the documentation.  There are a few ways to handle this issue: 1. Normalize `axis`, but this incurs a performance hit 2. Add a precondition that `axis.Length()` \xe2\x89\x88 1.        But enforcing that pre-condition is about as expensive as 1), so it\'d probably need to be a documentation-only precondition. Unfortunately this means that consumers will rely on the current behaviour even if it\'s undocumented, so I don\'t think that this is a good solution. 3. Document the current behaviour  ---  Just for convenience, the relevant source code:  ``` /// <summary> /// Creates a Quaternion from a vector and an angle to rotate about the vector. /// </summary> /// <param name=""axis"">The vector to rotate around.</param> /// <param name=""angle"">The angle, in radians, to rotate around the vector.</param> /// <returns>The created Quaternion.</returns> public static Quaternion CreateFromAxisAngle(Vector3 axis, float angle) {     Quaternion ans;      float halfAngle = angle * 0.5f;     float s = (float)Math.Sin(halfAngle);     float c = (float)Math.Cos(halfAngle);      ans.X = axis.X * s;     ans.Y = axis.Y * s;     ans.Z = axis.Z * s;     ans.W = c;      return ans; } ``` "",area-System.Numerics\r\n72,""`Equals` with NaN values (IEEE vs. reflexivity)"",""The built in floating point types compare `NaN` as unequal when using `==` and `!=` (following IEEE semantics) but compare it as equal when using the `Equals` method.  Your floating point based types currently use IEEE semantics even for `Equals`. I suggest using the same behaviour as the built in types in your floating point based types like vectors or quaternions.  The  MSDN documentation of `Equals` contains an exception that allows `A.Equals(A)` to return false on floating point types, so you don\'t strictly violate its contract. But returning false still breaks hash tables and does not match the behaviour of the built in types, so I consider it a bad idea.  This can be avoided by calling `Equals` on the members instead of `==` in the implementation of `Equals` but not in `==` and `!=`.  For example with quaternion,  replace  ``` public bool Equals(Quaternion other) {     return (X == other.X &&             Y == other.Y &&             Z == other.Z &&             W == other.W); } ```  with  ``` public bool Equals(Quaternion other) {     return (X.Equals(other.X) &&             Y.Equals(other.Y) &&             Z.Equals(other.Z) &&             W.Equals(other.W)); } ```  You might want to add tests that check that `==` and `!=` compare all the above cases as unequal, so that they match the IEEE specification.  Replace:  ``` // Counterintuitive result - IEEE rules for NaN comparison are weird! Assert.False(a.Equals(a)); Assert.False(b.Equals(b)); Assert.False(c.Equals(c)); Assert.False(d.Equals(d)); ```  with:  ``` // Equals does not follow IEEE semantics since many consumers rely on equality being reflexive. // This includes collections like `Dictionary<K,V>` or `HashSet<T>` Assert.True(a.Equals(a)); Assert.True(b.Equals(b)); Assert.True(c.Equals(c)); Assert.True(d.Equals(d));  // Counterintuitive result - IEEE rules for NaN comparison are weird! Assert.False(a == a); Assert.False(b == b); Assert.False(c == c); Assert.False(d == d);  Assert.True(a != a); Assert.True(b != b); Assert.True(c != c); Assert.True(d != d); ``` "",area-System.Numerics\r\n77,""Some Xml encoding tests lost their encoding"",""Some of Xml tests were testing problematic characters in different Encoding (like Russian characters). At some point few years back the encoding was lost while moving between different repos. Tests pass because .cs files lost their encoding too. Tests need to be rewritten since there is no trace of original copy "",area-System.Xml\r\n81,""Add test coverage for XPath and XDocument"",""- Adding test coverage for XPath implementations (XPath.XPathDocument, XPath.XmlDocument, XPath.XDocument) - Adding some tests for XDocument (more coming later) "",area-System.Xml\r\n94,""Necessary bits for Mono.Posix"",""I tried to build [Mono.Posix](https://github.com/mono/mono/tree/master/mcs/class/Mono.Posix) against aspnetcore50 and found a lot of API that mono uses to be missing from .NET Core most prominently in the Interop-domain (like CustomMarshaler).  Please add Mono.Posix to your list of scenarios that can benefit from the API surface of .NET Core. "",area-Meta\r\n110,""Add async document/element loading for XLinq."",""Adds XElement.LoadAsync and XDocument.LoadAsync. Code from the sync versions has been largely lifted out so they can share an implementation as much as possible. "",area-System.Xml\r\n116,""Quaternion and public fields"",""Is there a reason that the Quaternion struct has public exposed fields versus read only properties? Seems to be against the general guidelines for structs and immutability. Why would you want to allow X, Y, Z and W to be set outside of the ctor? "",area-System.Numerics\r\n118,""Matrix4x4 - more useful public properties"",""Forward, Backward, Up, Down, Left, Right public properties for Matrix4x4 "",area-System.Numerics\r\n119,""Vector3 - more public static properties"",""Up, Down, Left, Right, Forward, Backward vector public static properties "",area-System.Numerics\r\n121,""Matrix4x4 - more useful public properties"",""Added Forward, Backward, Up, Down, Left, Right vectors public properties for Matrix4x4.  Fix #118 "",area-System.Numerics\r\n129,""Add XmlReader"",""System.Xml.XmlReader is currently missing. "",area-System.Xml\r\n\r\n```\r\n\r\nThis Is shorter version of the dataset. The title and body are in quotes and columns are comma separated.\r\n\r\nWhen I try to use auto-ml on this \r\n```c#\r\nInferring Columns ...\r\nAn Error occured during inferring columns\r\nUnable to split the file provided into multiple, consistent columns.\r\nMicrosoft.ML.AutoML.InferenceException: Unable to split the file provided into multiple, consistent columns.\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns)\r\n   at Microsoft.ML.CLI.CodeGenerator.AutoMLEngine.InferColumns(MLContext context, ColumnInformation columnInformation)\r\n   at Microsoft.ML.CLI.CodeGenerator.CodeGenerationHelper.GenerateCode()\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass1_0.<Main>b__0(NewCommandSettings options)\r\nPlease see the log file for more info.\r\nExiting ...\r\n```\r\n\r\nMy guess is we are not respecting the quotes and just splitting the string on commas.\r\n\r\nThe dataset works if I separate the columns using tabs\r\n\r\n\r\n\r\ncc @eerhardt @danmosemsft @codemzs \r\n'"
451537555,3806,b'LearningPipeline was not found',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  2.1.602\r\n### Issue\r\n\r\nHello,\r\nmy issue is that when I want to use ""var pipeline = new LearningPipeline();"" I get an error by ""LearningPipeline()""\r\n\r\nA picture: http://prntscr.com/nx29zl\r\n\r\nThe error says: ""The type or namespace name ""LearningPipeline"" was not found""\r\nCode: CS0246\r\n\r\n- **What did you do?**\r\nI found nothing.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n\r\nusing System.Threading.Tasks;\r\n\r\nnamespace Test {\r\n    class Program {\r\n        static void Main(string[] args) {\r\n            var pipeline = new LearningPipeline(); \r\n        }\r\n    }\r\n}\r\n```\r\n'"
451322268,3804,b'Add overload for time series checkpoint API that takes a stream',"b""This is needed is scenarios where the user is running the time series prediction on a blob where they don't have files but memory streams. """
451289076,3803,b'Race condition in creation of AutoML temp folders',"b""**tldr;** recommend a GUID based folder name: `Temp\\Microsoft.ML.AutoML\\experiment_9bdaa79e-8ceb-4103-988b-9d73aefd53c2\\...`\r\n\r\nUser reported bug by @markusmobius in https://github.com/dotnet/machinelearning/issues/3749\r\n\r\n## Bug\r\nAutoML stores the trained models from the sweeping process on disk to avoid ever growing RAM usage. We currently ensure the folder is named uniquely by checking if it exists, and if so, incrementing a counter at the end. This process has a race condition where multiple processes will test for the folder's existence, see nothing, and both create and begin to work in the same folder. \r\n\r\n## Background\r\n@markusmobius was running multiple instances of the AutoML CLI, and the various processes were clobbering each others' temporary folders. See https://github.com/dotnet/machinelearning/issues/3749#issuecomment-495259293\r\n\r\nAs said by @daholste in https://github.com/dotnet/machinelearning/issues/3749#issuecomment-495407319:\r\n> Re: writing models to the temp folder -- when initializing experiments one after the other on a machine, each experiment would have its own unique model folder:\r\n> ![image](https://user-images.githubusercontent.com/43974253/58290281-0c6f3500-7d6e-11e9-8790-d8a4077dab21.png)\r\n> However, when initializing many experiments in parallel on the same machine, it is definitely possible to have a race condition that causes conflict here. Thanks for pointing this out \r\n\r\nReply by @justinormont in https://github.com/dotnet/machinelearning/issues/3749#issuecomment-495426783 / https://github.com/dotnet/machinelearning/issues/3749#issuecomment-495448847: \r\n> I believe we used a named mutex in the word embedding's model downloader to ensure only one copy of the model is being downloaded per machine. \r\n\r\n> I found the word embedding's named mutex: https://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs#L237-L246\r\n> \r\n> The lock is in the downloader class (resource manager).\r\n> \r\n> Plus the `finally` unlock:\r\n> https://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs#L287-L291\r\n> \r\n> We could do the same for the temp folder; if I recall I thought it was race free when the storage is local, but not for network shares due to lack of a remote atomic rename. \r\n> \r\n> More simple approach is to use a GUID: `Temp\\Microsoft.ML.AutoML\\experiment_9bdaa79e-8ceb-4103-988b-9d73aefd53c2\\...`"""
450909708,3800,b'Issue training',"b'I have tried creating a simple data and performing the training like so\r\n\r\n```\r\ndotnet .\\mlnet.dll auto-train --task binary-classification\r\n --dataset ""logons.csv"" --label-column-index 0 \r\n--has-header true --max-exploration-time 10\r\n```\r\n\r\nHere is an example of the data set which is reduced from my original, but shows the format:\r\n\r\n```\r\nValid\t Data\r\n0\t 09:00\r\n0\t 09:01\r\n0\t 09:02\r\n0\t 09:03\r\n0\t 09:04\r\n0\t 09:05\r\n0\t 09:06\r\n0\t 09:07\r\n1\t 12:08\r\n0\t 09:09\r\n0\t 09:10\r\n0\t 09:00\r\n0\t 09:01\r\n0\t 09:02\r\n0\t 09:03\r\n0\t 09:04\r\n0\t 09:05\r\n0\t 09:06\r\n0\t 09:07\r\n1\t 13:08\r\n0\t 09:09\r\n0\t 09:10\r\n0\t 09:00\r\n0\t 09:01\r\n0\t 09:02\r\n0\t 09:03\r\n0\t 09:04\r\n0\t 09:05\r\n0\t 09:06\r\n0\t 09:07\r\n1\t 14:08\r\n0\t 09:09\r\n0\t 09:10\r\n```\r\n\r\nEvery time I try and run the command I get the following error:\r\n\r\n```\r\nException occured while exploring pipelines:\r\nTraining failed with the exception: \r\nSystem.ArgumentOutOfRangeException: AUC is not definied \r\nwhen there is no positive class in the data\r\nParameter name: PosSample\r\n```\r\n\r\nI originally tried it via VS2019 and the latest version of ML.Net, but that failed, so I tried it using the binary directly'"
450681236,3799,b'Add SrCnn Anomaly Detection algorithm',"b'### New Algorithm\r\n\r\nImplement SrCnn anomaly detection algorithm of KDD 2019 paper ""Time-Series Anomaly Detection Service at Microsoft"". Onboard Spectral Residual(SR) step firstly.\r\n### Benchmark report\r\n#### 1. Dataset\r\nWe evaluate on the Yahoo timeseries dataset, which has 367 timeseries and 572966 points in total.\r\n#### 2. Evaluation method\r\nWe calculate the Precision, Recall, and F1 score using the method of\xef\xbc\x9a [https://github.com/iopsai/iops/tree/master/evaluation](https://github.com/iopsai/iops/tree/master/evaluation)\r\n#### 3. Score and Latency:\r\nWe ran the three algorithms on a machine with Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz, 16GB memory, x64 operating system.\r\n\r\nAlgo | Precision | Recall | F1 | #TruePositive | #Positives | #Anomalies | Average latency to   predict the whole dataset | Fine tuned   parameters\r\n-- | -- | -- | -- | -- | -- | -- | -- | --\r\nSSA (need   training) | 0.582 | 0.585 | 0.583 | 2290 | 3936 | 3915 | 5595ms (training   time not included) | Confidence=99,   PValueHistoryLength=32, Season=11, and use half the data of each series to do   the training.\r\nIID | 0.668 | 0.491 | 0.566 | 1924 | 2579 | 3915 | 6163ms | Confidence=99,   PValueHistoryLength=56\r\nSR | 0.601 | 0.670 | 0.634 | 2625 | 4370 | 3915 | 20930ms | WindowSize=64,   BackAddWindowSize=5, LookaheadWindowSize=5, AveragingWindowSize=3,   JudgementWindowSize=64, Threshold=0.45\r\n#### 4. Some experiences for parameter tuning.\r\n<strong>SSA:</strong> Sensitive to the season value, need to find the period of timeseries if seasonality exists. Very sensitive to confidence, we keep it above 98.\r\n<strong>IID:</strong> Very sensitive to confidence, we keep it above 98.\r\n<strong>SR:</strong> WindowSize and Threshold are the most important parameters, you can focus on adjusting these two parameters to get a good score. And then tuning JudgementWindowSize will also help.\r\n'"
450569299,3798,b'Release daily-drop preview packages on MyGet or any public feed',b'I think it would be good to release the daily-drop preview packages on MyGet or any public feed.\r\n\r\nThoughts?'
450553933,3797,b'TextFeaturizer to save specific features',b'User scenario:\r\nTrained learner on top of TextFeaturizer.\r\nLearner uses only several ngram features.\r\nStill the combined model file is huge due to the fact the TextFeaturizer save dictionary counts for all ngrams extracted. \r\n\r\nFeature request: add ability for TextFeaturizer to save its model with specified features / ngrams only'
450522222,3795,b'Alternate Fit() with no IDataView parameter for cases where data is not needed (i.e. Scoring a Tensorflow model)',"b'The following is a typical case when you prepare a pipeline only for scoring with a TensorFlow model:\r\n\r\n```\r\nprivate ITransformer SetupMlnetModel(string imagesFolderPath, string tensorFlowModelFilePath)\r\n{\r\n    var pipeline = _mlContext.Transforms.LoadImages(outputColumnName: TensorFlowModelSettings.inputTensorName, imageFolder: imagesFolderPath, inputColumnName: nameof(ImageInputData.ImagePath))\r\n        .Append(_mlContext.Transforms.ResizeImages(outputColumnName: TensorFlowModelSettings.inputTensorName, imageWidth: ImageSettings.imageWidth, imageHeight: ImageSettings.imageHeight, inputColumnName: TensorFlowModelSettings.inputTensorName))\r\n        .Append(_mlContext.Transforms.ExtractPixels(outputColumnName: TensorFlowModelSettings.inputTensorName, interleavePixelColors: ImageSettings.channelsLast, offsetImage: ImageSettings.mean))\r\n        .Append(_mlContext.Model.LoadTensorFlowModel(tensorFlowModelFilePath).\r\n        ScoreTensorFlowModel(outputColumnNames: new[] { ""loss"" },\r\n                            inputColumnNames: new[] { ""Placeholder"" }, addBatchDimensionInput: false));\r\n\r\n    ITransformer mlModel = pipeline.Fit(CreateEmptyDataView());\r\n    return mlModel;\r\n}\r\nprivate IDataView CreateEmptyDataView()\r\n{\r\n    //Create empty DataView. We just need the schema to call fit()\r\n    List<ImageInputData> list = new List<ImageInputData>();\r\n    list.Add(new ImageInputData() { ImagePath = """" });\r\n    IEnumerable<ImageInputData> enumerableData = list;\r\n\r\n    var dv = _mlContext.Data.LoadFromEnumerable<ImageInputData>(list);\r\n    return dv;\r\n}\r\n```\r\n\r\nThe issue with that API is that Fit(IDataView idv) always requires an IDataView as parameter, but in this case, data is not needed, it just needs the IDataView schema. \r\n\r\nCurrently you just create an ""Empty DataView"" and from there, the schema will be taken. \r\nThis seems like a workaround but it doesn\'t make sense for the user to create an empty structure/DataView:\r\n\r\nPossible proposal:\r\n\r\nAllow a parameter-less for the ""Fit()"" method and by simply providing as a generic what\'s the data type to use as the base to generate the IDataView schema, such as:\r\n\r\n` .Fit<ImageInputData>();`\r\n\r\nBasically, internally it would run the code I have in the `CreateEmptyDataView()` method. \r\n\r\nAdditional solutions or thoughts to improve this API?\r\n'"
450377894,3791,b'What data to be fed into PermutationFeatureImportance?',"b""In general I know that the data should be transformed by the trained model before being fed into PermutationFeatureImportance, but should it be transformed training data or test data, assuming I have both? and why?\r\nI've been reading documents and related issues but couldn't find the answer. Thanks"""
450090276,3790,"b""[Bug/issue] Prediction Engine using TensorFlow model doesn't close the used image files?""","b""Looks like when I provide an image file to the prediction engine which is using a TensorFlow model, after predicting and getting the result, it never closes the image file and you cannot even delete those image files (in my case, those image files are temp files that I need to delete from the code)\r\n\r\nOnly when the app using the prediction engine is finished, then the image files are closed and I can delete them (manually). But that is not the desired behavior. \r\n\r\nHere's an app with a repro:\r\nhttps://github.com/CESARDELATORRE/TensorFlowImageClassificationWebApp/tree/master/WebApp\r\n"""
449810140,3787,"b'Prediction multiclass only transmit score Label and label index are """" and 0'","b""### System information\r\n\r\n- **OS version/distro**: \r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.Net Core 3.0, Microsoft.ML 1.0.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI created a pipline like so:\r\n```\r\nvar sdcaPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: DefaultColumnNames.KeyColumn, inputColumnName: DefaultColumnNames.Label,keyOrdinality:ValueToKeyMappingEstimator.KeyOrdinality.ByOccurrence)\r\n    .Append(mlContext.Transforms.Concatenate(DefaultColumnNames.RawFeatures, MSBar2.GetColumnNames(DataKind.Single)))\r\n    .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName: DefaultColumnNames.Features,inputColumnName:DefaultColumnNames.RawFeatures))\r\n    .AppendCacheCheckpoint(mlContext)\r\n    .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName : DefaultColumnNames.KeyColumn ,featureColumnName: DefaultColumnNames.Features))\r\n    .Append(mlContext.Transforms.CopyColumns(inputColumnName: KeyColumn, outputColumnName: DefaultColumnNames.PredictedLabelIndex))\r\n    .Append(mlContext.Transforms.Conversion.MapKeyToValue(inputColumnName: DefaultColumnNames.KeyColumn ,outputColumnName: DefaultColumnNames.PredictedLabel));                      \r\n\r\nvar model=  sdcaPipeline.Fit(trainingDataView);\r\n```\r\n\r\n- **What happened?**\r\nWhen performing a single prediction the score property is placed. However the DefaultColumnNames.PredictedLabel and DefaultColumnNames.PredictedLabelIndex are always populated with the .net default values of empty string and 0\r\n\r\n- **What did you expect?**\r\nI'd expect the values to be mapped as it is configured in the pipeline\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
449804898,3786,b'Replace LangVersion=latest with a specific version',"b'https://github.com/dotnet/machinelearning/blob/9a80b78d7aba8463859975119e697afb72f91c09/Directory.Build.props#L94\r\n\r\nThis property means ""vary the build environment for each individual developer, and break teams when possible"". It should be avoided in all circumstances outside of the dotnet/roslyn test suite. Currently this project appears to use C# 7.3, so I would recommend replacing the current value with:\r\n\r\n```xml\r\n<LangVersion>7.3</LangVersion>\r\n```\r\n\r\n\xf0\x9f\x93\x9d While the compile-time behavior can be locked to a specific version by referencing the Microsoft.Net.Compilers NuGet package, the IDE features triggered by specific language versions will not be able to correctly determine the effective language version in all cases and the experience will still vary across users. Using a specific version resolves all issues and ensures the experience is consistent.'"
449300715,3784,b'Bitmap data',"b'What is (I assume a variable) Enumerable and how do you get it from a Bitmap or Image, neither of which is Enumerable? Two loops to examine the pixels and put it into a linear array?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 8b9c0132-7901-8114-b8bc-faa09ad74797\n* Version Independent ID: 8274abb2-6952-674b-e8bc-1e314aeee4cc\n* Content: [TensorFlowModel.ScoreTensorFlowModel Method (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowmodel.scoretensorflowmodel?view=ml-dotnet-preview#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowModel.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowModel.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
448787407,3783,b'[AutoML]  feature request Include PFI statistics',"b'Users of AutoML would probably appreciate having templating injected PFI for the ""best"" model as described in the online [documentation](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/explain-machine-learning-model-permutation-feature-importance-ml-net)\r\n\r\nI guess one could add it after the training dialogue as well. Nice for those that like to spin the data. perhaps start training again after the user excludes some of the ""noisy features""'"
448743119,3782,b'Cookbook could use a sample of tweeking schema for training',b'At the moment the [cook book](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md) is the best kick starter for using the model and explains the getting started concepts of the API. \r\n\r\nMissing though I feel is how to manipulate the pipeline when it comes to adding bias and or techniques for dealing with under and overfitting. \r\n\r\n'
448720019,3781,"b""Error message 'Could not find feature column' in Fit() method""","b'### System information\r\n\r\n- **Windows7x64**:\r\n- **.NET Version 2.1.502**: \r\n\r\n### Issue\r\n\r\n- I try to create my first sample of Microsoft.ML and my program fails with message \'Could not find feature column \'X\'\', but type contains the field.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1849690/58404863-d03e1c00-806e-11e9-9845-2e43e2fcbf1e.png)\r\n\r\n\r\n### Source code / logs\r\n\r\n```c#\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Numerics;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace ML.NET\r\n{\r\n    public class FormulaData{\r\n        [ColumnName(""Label"")]\r\n        public float Y;\r\n        [ColumnName(""Features"")]\r\n        public float X;\r\n        public FormulaData(double x, double y){\r\n            X = Convert.ToSingle(x);\r\n            Y = Convert.ToSingle(y);\r\n        }\r\n    }\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Hello World!"");\r\n\r\n            List<FormulaData> pointsValues = Enumerable\r\n                .Range(-1, 8)\r\n                .Select(value => {return new FormulaData(value, value*2-1);})\r\n                .ToList();\r\n\r\n            // Create MLContext\r\n            var mlContext = new MLContext(1);\r\n\r\n            // Load Data\r\n            IDataView data = mlContext.Data.LoadFromEnumerable<FormulaData>(pointsValues);\r\n\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            // Define trainer options.\r\n            var options = new SdcaRegressionTrainer.Options\r\n            {\r\n                LabelColumnName = nameof(FormulaData.Y),\r\n                FeatureColumnName = nameof(FormulaData.X),\r\n                // Make the convergence tolerance tighter. It effectively leads to more training iterations.\r\n                ConvergenceTolerance = 0.02f,\r\n                // Increase the maximum number of passes over training data. Similar to ConvergenceTolerance,\r\n                // this value specifics the hard iteration limit on the training algorithm.\r\n                MaximumNumberOfIterations = 30,\r\n                // Increase learning rate for bias.\r\n                BiasLearningRate = 0.1f            \r\n            };\r\n\r\n            // Define StochasticDualCoodrinateAscent regression algorithm estimator\r\n            var sdcaEstimator = mlContext.Regression.Trainers.Sdca(options);\r\n\r\n            // Build machine learning model\r\n            var trainedModel = sdcaEstimator.Fit(trainData);\r\n\r\n            // Use trained model to make inferences on test data\r\n            IDataView testDataPredictions = trainedModel.Transform(testData);\r\n\r\n            // Extract model metrics and get RSquared\r\n            RegressionMetrics trainedModelMetrics = mlContext.Regression.Evaluate(testDataPredictions);\r\n            double rSquared = trainedModelMetrics.RSquared;\r\n\r\n            Console.WriteLine($""rSquared: {rSquared}"");\r\n        }\r\n    }\r\n}\r\n\r\n```'"
448621429,3780,b'Bias value gets changed every run at 100th place',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I run sample code on given document (Using full data as Traning data)\r\n\r\n- **What happened?** Bias value gets changed every run at 100th place\r\n1st try result -\r\n2nd try result -\r\n3rd try result -\r\n\r\n- **What did you expect?**\r\nSame value, because of using same sample data at every run.\r\n\r\n### Source code / logs\r\nSample code I tried - https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/train-machine-learning-model-ml-net\r\n\r\n`HousingData[] housingData = new HousingData[]\r\n            {\r\n                new HousingData\r\n                {\r\n                    Size = 600f,\r\n                    HistoricalPrices = new float[] { 100000f ,125000f ,122000f },\r\n                    CurrentPrice = 170000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 200000f, 250000f, 230000f },\r\n                    CurrentPrice = 225000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 126000f, 130000f, 200000f },\r\n                    CurrentPrice = 195000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 850f,\r\n                    HistoricalPrices = new float[] { 150000f,175000f,210000f },\r\n                    CurrentPrice = 205000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 900f,\r\n                    HistoricalPrices = new float[] { 155000f, 190000f, 220000f },\r\n                    CurrentPrice = 210000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 550f,\r\n                    HistoricalPrices = new float[] { 99000f, 98000f, 130000f },\r\n                    CurrentPrice = 180000f\r\n                }\r\n            };\r\n\r\n            MLContext mlContext = new MLContext();\r\n            IDataView trainingData = mlContext.Data.LoadFromEnumerable(housingData);\r\n\r\n            // Define Data Prep Estimator\r\n            // 1. Concatenate Size and Historical into a single feature vector output to a new column called Features\r\n            // 2. Normalize Features vector\r\n            IEstimator<ITransformer> dataPrepEstimator =\r\n                mlContext.Transforms.Concatenate(""Features"", ""Size"", ""HistoricalPrices"")\r\n                    .Append(mlContext.Transforms.NormalizeMinMax(""Features""));\r\n\r\n            // Create data prep transformer\r\n            ITransformer dataPrepTransformer = dataPrepEstimator.Fit(trainingData);\r\n\r\n            // Apply tranforms to training data\r\n            IDataView transformedTrainingData = dataPrepTransformer.Transform(trainingData);\r\n\r\n            var UserDefinedColumnSdcaEstimator = mlContext.Regression.Trainers.Sdca(labelColumnName: ""CurrentPrice"", featureColumnName: ""Features"");\r\n            // Define StochasticDualCoodrinateAscent regression algorithm estimator\r\n            var sdcaEstimator = mlContext.Regression.Trainers.Sdca();\r\n\r\n            // Build machine learning model\r\n            var trainedModel = sdcaEstimator.Fit(transformedTrainingData);\r\n\r\n            var trainedModelParameters = trainedModel.Model as LinearRegressionModelParameters;\r\n            var bias = trainedModelParameters.Bias;`\r\n'"
448599254,3779,b'[AutoML] Add dataset statistics that indicate whether or not a shuffle transform could be helpful',"b'Thanks @justinormont for pointing this out\r\n\r\nThanks also for brainstorming that a snazzy way to do this could be to append row #s from the original dataset to the reservoir sample from https://github.com/dotnet/machinelearning/issues/3778, and then calculate correlation between row # and label'"
448598514,3778,b'[AutoML] Reservoir sample dataset statistics',"b'Currently dataset statistics within AutoML are calculated from the first 1,000 rows of a dataset. Instead, we should be calculating statistics from a random sample of 1,000 rows. (First 1,000 rows could be biased if they are sorted by label, any other column, time of collection, etc.) We can use reservoir sampling to obtain a random sample of a fixed size in a single pass over the dataset'"
448402582,3775,b'An Exception about using CustomMappingFactory',"b'Hello there,\r\nI am learning about CustomMappingFactory, I found the following code: \r\nmachinelearning/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/CustomMappingSaveAndLoad.cs\r\nThis code runs normally, but if I create a new MLContext before loading the model (line 36), as follows: \r\n\r\nmlContext = new MLContext();\r\nvar loadedTransform = mlContext.Model.Load(""customTransform.zip"", out var inputSchema);\r\n\r\nThen the system will report an error: \r\nInvalidOperationException: Unable to locate an extension for the contract \'IsUnderThirty\'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a \'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute\'.\r\n\r\nI think creating a new MLContext before loading the model should be a necessary operation. Is this a bug?'"
448145353,3773,b'Incorrect metrics when the order of labels do not correspond to the indices in multiclassification',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2, ML.1.0.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Train a trainingset with LightGbm and then evaluate a test set\r\n- **What happened?** The printed metrics are incorrect if the labels are not ordered from 0 -> n\r\n- **What did you expect?** A correct confusion matrix and LogLoss, ... metrics\r\n\r\nConfusion matrix when I add the labels ascending (0 -> n)  of the samples (e.g 0,1,2,3,4,0,1,2,3,4,...). This is the correct evaluation.\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||    58 |     0 |     1 |    19 |     0 |     0 |     1 |     1 |     2 |     0 |     2 | 0,6905\r\n        1 ||     0 |    79 |     0 |     0 |     0 |     5 |     0 |     0 |     0 |     0 |     0 | 0,9405\r\n        2 ||     0 |     0 |    79 |     3 |     0 |     0 |     0 |     0 |     2 |     0 |     0 | 0,9405\r\n        3 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 1,0000\r\n        4 ||     0 |     0 |     0 |     0 |    81 |     0 |     0 |     0 |     3 |     0 |     0 | 0,9643\r\n        5 ||     0 |     8 |     0 |     0 |     0 |    71 |     5 |     0 |     0 |     0 |     0 | 0,8452\r\n        6 ||     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 | 1,0000\r\n        7 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |    82 |     0 |     0 |     0 | 0,9762\r\n        8 ||     0 |     0 |     0 |     8 |     0 |     0 |     0 |     1 |    72 |     0 |     3 | 0,8571\r\n        9 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 | 1,0000\r\n       10 ||     0 |     0 |     0 |     0 |     0 |     2 |     1 |     0 |     0 |     0 |    81 | 0,9643\r\n          ||========================================================================================\r\nPrecision ||1,0000 |0,9080 |0,9875 |0,7368 |1,0000 |0,8875 |0,9231 |0,9762 |0,9114 |1,0000 |0,9419 |\r\n\r\n************************************************************\r\n```\r\nNow when I do OrderByDescending to reverse the labels and run it again, I get:\r\n\r\nConfusion matrix when I reverse the labels (n -> 0)  of the samples (e.g 4,3,2,1,0,4,3,2,1,0,...)\r\n\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||     3 |     0 |     3 |     1 |     0 |     6 |     0 |    14 |     0 |     0 |    57 | 0,0357\r\n        1 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 | 0,0000\r\n        2 ||     0 |     0 |     3 |     0 |     0 |     0 |     0 |     8 |    73 |     0 |     0 | 0,0357\r\n        3 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 | 0,0000\r\n        4 ||     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 |     0 |     0 |     0 | 0,0000\r\n        5 ||     0 |     0 |     0 |     0 |     3 |    74 |     0 |     0 |     0 |     7 |     0 | 0,8810\r\n        6 ||     0 |     0 |     0 |     0 |    83 |     0 |     0 |     0 |     0 |     0 |     1 | 0,0000\r\n        7 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n        8 ||     2 |     0 |    76 |     0 |     0 |     0 |     0 |     6 |     0 |     0 |     0 | 0,0000\r\n        9 ||     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n       10 ||    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n          ||========================================================================================\r\nPrecision ||0,0337 |0,0000 |0,0357 |0,0000 |0,0000 |0,9024 |0,0000 |0,0000 |0,0000 |0,0000 |0,0000 |\r\n```\r\n\r\nI think there is an expectation somewhere that the label == the label index.\r\n\r\n### Source code / logs\r\n```\r\n            var trainingDataView = mlContext.Data.LoadFromEnumerable(trainingDataArray, schemaDef);\r\n            var testDataView = mlContext.Data.LoadFromEnumerable(testDataArray, schemaDef);\r\n\r\n            var featureNames = typeof(RecordFeatures).GetProperties().Where(p => p.Name != nameof(RecordFeatures.Label)).Select(p => p.Name).ToArray();\r\n\r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""KeyColumn"", inputColumnName: nameof(RecordFeatures.Label))\r\n                                                                       .Append(mlContext.Transforms.Concatenate(""Features"", featureNames))\r\n                                                                       .AppendCacheCheckpoint(mlContext);\r\n\r\n            var trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: ""KeyColumn"", featureColumnName: ""Features"");\r\n          \r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            Console.WriteLine(""=============== Training the model ==============="");\r\n            var trainedModel = trainingPipeline.Fit(trainingDataView);\r\n\r\n            Console.WriteLine(""===== Evaluating Model\'s accuracy with Test data ====="");\r\n            var predictions = trainedModel.Transform(testDataView);\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(predictions, ""Label"", ""Score"");\r\n\r\n            PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);\r\n```\r\n'"
447665443,3771,b'Are there any algorithms that are independent of native libraries and can run in xamarin forms?',b'Are there any algorithms that are independent of native libraries and can run in xamarin forms?'
447593748,3770,b'AutoML feature request for TensorFlow',"b""Would be nice to see some TensorFlow integration in AutoML.\r\nOne find nice Multiclass Iris prediction with TensorFlow in Python in the web. \r\nWould be nice to see it implemented in AutoMl as I guess it's a good _bootstrap'er_  for those that would like to implement it. """
447498029,3769,b'ConfusionMatrix.GetFormattedConfusionTable() sorts on arbitrary in order found on disk ',"b'\r\n[Enter feedback here]\r\nWhen training a MultiClass you will/can discover the classes in a random order.\r\nThe ""random"" order is then indexed and repeated in the labels. \r\nOne can influence the order using keyOrdinality in MlContext.Transforms.Conversion.MapValueToKey \r\n\r\n```\r\n//     How items should be ordered when vectorized. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByOccurrence\r\n//     chosen they will be in the order encountered. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue,\r\n```\r\n\r\nThe Y axis does map the index to a label, this helps but it would be better to allow users to sort on the label to get a consistent layout as well as allow the user to use cast the labels back to enumerable classes (if this is what is used for the labels) and sort in order of the enumerable.   \r\n\r\nTo ""fix"" report formatting one should not have to alter the learning pipeline, these are 2 separate concerns. \r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: a65b98b6-bd97-8615-8f5f-827305a203c1\r\n* Version Independent ID: 6975eed6-3d30-cb7d-295d-edce198c2e43\r\n* Content: [ConfusionMatrix.GetFormattedConfusionTable Method (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.confusionmatrix.getformattedconfusiontable?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(Microsoft.ML.Data.ConfusionMatrix.GetFormattedConfusionTable);k(SolutionItemsProject);k(TargetFrameworkMoniker-.NETFramework,Version%3Dv4.7.2);k(DevLang-csharp)%26rd%3Dtrue&view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
447344339,3767,b'OneHotEncoder on array of strings',"b'I couldn\'t find an example to run OneHotEncoder on an array of strings. From the sample code at https://github.com/dotnet/machinelearning/issues/2678 is it just as simple as ctx.Transforms.Categorical.OneHotEncoding(""A"")? Preview function is yet to be fixed in ml.net 1.0.0 so I can\'t tell if it gives the desired result.\r\n\r\nThanks'"
447108222,3766,b'Does GetFeatureWeights support categorical splits?',"b""Version: 1.0\r\n\r\nI'm training my multi class LightGBM with mostly categorical features (which works great). But when I want to get the `GetFeatureWeights` from the binary predictors I get huge values for feature of index `-1`. Though, just inspecting the models in the debugger the trees almost exclusively use categorical features for the splits. It seems that the `GainMap` doesn't actually consider any categorical splits and just assigns all those gains to the index `-1` which makes the feature weights vector completely useless in my case.\r\n\r\nIs this something that will be supported? Or am I wrong here?\r\n"""
447097534,3765,b'How to get LightGBM multiclass calibrated',"b'Version: 1.0\r\n\r\nAfter training the a multi class LightGBM predictor it seems the Platt calibrator on each model has the fixed parameter of 0, and -0.5:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3798bf8b73a2ce83a526326e05639d54a331fbdd/src/Microsoft.ML.LightGbm/LightGbmMulticlassTrainer.cs#L185-L191\r\n\r\nIs that on purpose? How can I get a calibrated predictor?'"
447048620,3764,"b""Unable to load DLL 'CpuMathNative'""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 x64 (1809 17763.503) and x86 (1809 17763.503)\r\n- **.NET Version (eg., dotnet --info)**:\r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.700-preview-009597\r\n Commit:    96b18bcb5c\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.700-preview-009597\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.9\r\n  Commit:  dcedc87d22\r\n\r\n.NET Core SDKs installed:\r\n  2.1.601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009597 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**: \r\nCreated a new .net standard project, added ML.NET from nuget and added the project  to my existing solution (.net Framework 4.7.2). Both are set to Any CPU, as I [read that ML.NET also supports x86](https://devblogs.microsoft.com/dotnet/announcing-ml-net-0-7-machine-learning-net/#x86-support-in-addition-to-x64). The DLL Microsoft.ML.CpuMath.dll is present in the release folder.\r\n- **What happened?**: When creating the model I get the exception as shown below in ""logs""\r\n- **What did you expect?**: Creating the model as expected.\r\n\r\n### Source code / logs\r\n\r\n```\r\n05/21/2019 16:15:32: Runtime terminating: True\r\n05/22/2019 11:58:37: System.InvalidOperationException: Shuffle input cursor reader failed with an exception ---> System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.DllNotFoundException: Unable to load DLL \'CpuMathNative\': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Transforms.LpNormNormalizingTransformer.Mapper.<>c__DisplayClass6_0.<MakeGetter>b__5(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.<LoopProducerWorker>d__31.MoveNext()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n```'"
447025185,3762,b'Perhaps not a popular question but why are you not using the sample Gighub labeler',"b""Hi\r\n\r\nI don't want to poke but why are the items not getting labeled by something like the [github labeler](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) sample found in the samples solution?\r\n\r\nWould help finding similar issues and re-use the answers provided (if still applicable in the current API)"""
446949741,3761,"b""The given key 'metric' was not present in the dictionary""","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\nWindows 2012\r\nWindows 2019\r\n- **.NET Version (eg., dotnet --info)**: \r\nCore 3.0                          Version 3.0.100-preview5-011568\r\nMicrosoft.ML.LightGbm  Version 1.0.0.0, Culture=neutral\r\nMicrosoft.ML                   Version 1.0.0.0\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoad csv file as and train model loading by all floats in single vector \r\nsee code bellow\r\n\r\n- **What happened?**\r\nGet error _The given key \'metric\' was not present in the dictionary_ during the training \r\n\r\n- **What did you expect?**\r\nNot sure why I get the error, also I do not mention a key metric.\r\n\r\n### Source code / logs\r\nThe error:\r\n```\r\n[Source=LightGBMMulticlass; Training with LightGBM, Kind=Trace] Channel disposed. Elapsed 00:00:04.0970203\r\n.57.erLeaf = 5059.0337420.\r\nError stack    at System.Collections.Generic.Dictionary`2.get_Item(TKey key)r_6_MinTicks_In_15Sec_B_ND.tsv\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmTraining.Train(IChannel ch, IProgressChannel pch, Dictionary`2 param\r\neters, Dataset dtrain, Dataset dvalid, Int32 numIteration, Boolean verboseEval, Int32 earlyStoppingRound)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainCore(IChannel ch, IProgressChannel pch, Dataset dtrain,\r\nCategoricalMetaData catMetaData, Dataset dvalid)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredic\r\ntor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Cats.DeepBookTrainer.Infrastructure.Trainer.ExecuteLightGbm(ITransformer& transformer, Nullable`1 maxIterations, N\r\nullable`1 maxThreads) \r\n```\r\n\r\nData Loading:\r\n```\r\npublic static IDataView GetDataViewAsVector(MLContext mlContext, FileInfo trainingFile, int labelIndex=1, char[] separators = null, long? maxRows = null, bool makeBin=false)\r\n{\r\n    if (separators is null)\r\n        separators = new[] { \'|\' };\r\n\r\n    var loader = mlContext.Data.CreateTextLoader(options: new TextLoader.Options()\r\n    {\r\n        Columns = new[] {\r\n            new TextLoader.Column(name:""Label"", dataKind: DataKind.String, index: labelIndex),\r\n            new TextLoader.Column(name:""RawFeatures"",dataKind:DataKind.Single,minIndex:2,maxIndex:40732)\r\n        },\r\n        HasHeader = false,\r\n        Separators = separators,\r\n        UseThreads = false,\r\n        MaxRows=maxRows\r\n    });\r\n    var dv = loader.Load(trainingFile.FullName);\r\n    return dv;\r\n}\r\n```\r\n\r\n\r\nPipeline:\r\n```\r\nhorizonDataset = mlContext.Data.TrainTestSplit(DataViewUtils.GetDataViewAsVector(mlContext, trainingFile, labelIndex: 1, separators: new[] {\'|\'}));\r\n\r\nvar options = new LightGbmMulticlassTrainer.Options\r\n{\r\n    LabelColumnName = ""KeyColumn"",\r\n    FeatureColumnName = Features,\r\n    Silent = false,\r\n    Verbose = true,\r\n    EvaluationMetric = LightGbmMulticlassTrainer.Options.EvaluateMetricType.Default,\r\n    UseSoftmax       = true,\r\n    NumberOfThreads  = 1,                \r\n};\r\n\r\nvar featureColumns = Mapper.GetFieldNames();\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""KeyColumn"", inputColumnName: ""Label"")\r\n        .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName: ""Features"", inputColumnName: ""RawFeatures""))\r\n        .AppendCacheCheckpoint(mlContext)\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName: ""KeyColumn"", outputColumnName: nameof(PredictedResult.PredictedLabelIndex)))\r\n```\r\nLine throwing the error \r\n`var model = pipeline.Fit(horizonDataset.TrainSet);`'"
446911675,3760,b'Implement Doc2vec text featurization',b'This was brought up in issue #3743 .'
446876120,3759,b'Support custom mapping without type parameters',"b'ML.NET supports [custom mappings](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.custommappingcatalog.custommapping?view=ml-dotnet) if a source and destination type are specified statically.\r\n\r\nWould it also be possible to support this in a dynamic setting, i.e., doing custom mappings from IDataView to IDataView?'"
446813574,3757,b'KeyToVectorMappingTransformer: Index was outside the bounds of the array.',"b'### System information\r\n\r\n- **OS version/distro**: 1.0.0\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Apply Normalization superviseBin and OneHot, \r\n- **What happened?** Got ""Index was outside the bounds of the array.""\r\n- **What did you expect?** No error\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = ""test1.csv"";\r\n            var featureName = ""Features"";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(""int1"", DataKind.Int64, 0),\r\n                new TextLoader.Column(""int2"", DataKind.Int64, 1),\r\n                new TextLoader.Column(""Label"", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: \',\');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(""int1"", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(""int2"", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { ""int1"", ""int2"" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: ""Label""))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```\r\n\r\n```\r\nint1, int2, label\r\n301, 2000, true\r\n450, 3000, true\r\n-300, 4000, true\r\n300, 2000, false\r\n115, 2000, false\r\n115, 2000, false\r\n```\r\n\r\nI think it is related to [issue 1751](https://github.com/dotnet/machinelearning/issues/1751) And based on the discussion for this issue,  I tried \r\n- adding MapKeyToValue() but no help.\r\n- OneHotEncode cannot be easily removed, we want to treat binning as categorical feature. \r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = ""test1.csv"";\r\n            var featureName = ""Features"";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(""int1"", DataKind.Int64, 0),\r\n                new TextLoader.Column(""int2"", DataKind.Int64, 1),\r\n                new TextLoader.Column(""Label"", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: \',\');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(""int1"", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(""int2"", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Conversion.MapValueToKey(""Label""))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { ""int1"", ""int2"" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: ""Label""))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator))\r\n                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(""Label""));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```'"
446778780,3756,b'Potential memory leak when training?',"b'I modified a project in the samples repo to repro:\r\n\r\nhttps://github.com/daholste/machinelearning-samples/commit/577946224747959759ca1b4da9fd86f77eea81a9\r\n\r\nIf breakpoint at https://github.com/daholste/machinelearning-samples/blob/577946224747959759ca1b4da9fd86f77eea81a9/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis/SentimentAnalysis/SentimentAnalysisConsoleApp/Program.cs#L52 , each model that is trained, the memory usage of the process consistently increases by about 80 MB (especially after the first few iterations of the loop).\r\n\r\nWhen the model is compressed & saved to disk, the size of the model file is only about 4.5 MB.\r\n\r\nWhen loading the saved model back into memory, memory of the process appears to jump by around 50 MB. (When loading the model several times back from disk to memory in the same process, average size of the model appears to be around 40 MB in memory. Not sure why. Perhaps string pooling? Not sure.)\r\n\r\nIs this a memory leak? \r\n80 MB of memory taken up by training model - 50 MB megabytes of same model serialized / deserialized = 30 MB of leakage?\r\nOr, does serializing / deserializing the model potentially restructure the data structures to use memory more efficiently?'"
446776675,3755,b'Model summary to show tree details for FastTree',b'Currently model summary doesnt show trees and split points for FastTree models.\r\nFastTree model needs to implement ICanGetSummaryAsIDataView that would dump this info.'
446765034,3754,"b'some Binary Classification trainers are giving excception ""Probability column not found""'","b'### System information\r\n\r\n- **OS version/distro**: Winows\r\n\r\n### Issue\r\n\r\nI am trying to do binary classification on dataset  at url  ""https://archive.ics.uci.edu/ml/datasets/URL+Reputation"" to classify an URL is malicious or not.\r\nI am trying to use different binary classification trainer to see which one gives better metrics. while doing that I am getting exception **Probability column  \'Probability\' not found\r\nParameter name: schema**  with some trainers below.\r\n-SDCANonCalibrated\r\n-SgdNonCalibrated\r\n-AveragedPerceptron\r\n-LinearSvm\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/58121421-44cf1180-7bbc-11e9-98cb-bf111af73956.png)\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\n class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            string dataReltivePath = @""Data/url_svmlight/"";\r\n            //string dataPath = GetAbsolutePath(dataReltivePath);\r\n            string dataPath = ""../../../url_svmlight/*"";\r\n            string testDataRelativePath = @""../../../Data/test/Day21.svm"";\r\n            string testDataPath = GetAbsolutePath(testDataRelativePath);\r\n\r\n            //STEP 1: Create MLContext to be shared across the model creation workflow objects \r\n            MLContext mlContext = new MLContext();\r\n\r\n            //STEP 2: Read the trained data using TextLoader by defining the schema for reading the product co-purchase dataset\r\n            //        Do remember to replace amazon0302.txt with dataset from https://snap.stanford.edu/data/amazon0302.html\r\n            var traindata = mlContext.Data.LoadFromTextFile(path: dataPath,\r\n                                                      columns: new[]\r\n                                                                {\r\n                                                                    new TextLoader.Column(""Label"", DataKind.Boolean, 0),\r\n                                                                    new TextLoader.Column(name:nameof(UrlData.FeatureVector), dataKind:DataKind.Single, source: new [] { new TextLoader.Range(1, 3231961) }),\r\n                                                                },\r\n                                                      hasHeader: true,\r\n                                                      separatorChar: \' \',\r\n                                                      allowSparse:true);\r\n\r\n            var testDataView = mlContext.Data.LoadFromTextFile(testDataPath,\r\n                columns: new[]\r\n                                                                {\r\n                                                                    new TextLoader.Column(""Label"", DataKind.Boolean, 0),\r\n                                                                    new TextLoader.Column(name:nameof(UrlData.FeatureVector), dataKind:DataKind.Single, source: new [] { new TextLoader.Range(1, 3231961) }),\r\n                                                                },\r\n\r\n                hasHeader: true, separatorChar: \' \', allowSparse: true);\r\n\r\n            var est = mlContext.BinaryClassification.Trainers.SgdCalibrated(labelColumnName: ""Label"", featureColumnName: ""FeatureVector"");\r\n         \r\n            Console.WriteLine(""====Training the model====="");\r\n\r\n            var model = est.Fit(traindata);\r\n   }\r\n}\r\n```\r\n'"
446394095,3752,b'How to get training progress info?',"b'Hi\xef\xbc\x8cSuppose I have 10,000 training data. When I run Fit method, it takes a long time. During this period, how can I get real-time training progress information?\r\nThank You!'"
446361548,3751,b'Model is predicting null when a user used CustomModel in TensorFlow Image Classification',"b'User has reported issue in Machine Learning samples https://github.com/dotnet/machinelearning-samples/issues/468 \r\n\r\n I have used the custom model and labels.txt provided by user in [TensorFlow image classification sample](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow) and changed the model pipeLine for Tensor input and output as shown below.\r\n\r\n```\r\nvar pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""Placeholder"", imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath))\r\n                           .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""Placeholder"", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: ""Placeholder""))\r\n                           .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""Placeholder"", interleavePixelColors: ImageNetSettings.channelsLast, offsetImage: ImageNetSettings.mean))\r\n                           .Append(mlContext.Model.LoadTensorFlowModel(modelLocation).\r\n                           ScoreTensorFlowModel(outputColumnNames: new[] { ""loss"" },\r\n                                               inputColumnNames: new[] { ""Placeholder"" }, addBatchDimensionInput: true));\r\n```\r\n\r\nWhile predicting an image using the prediction engine, the model is not predicting anything and its giving predictedLabels value as null.\r\n\r\n`var probs = model.Predict(sample).PredictedLabels;`\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/58059536-38967600-7b22-11e9-91e2-ec6263e3ceba.png)\r\n\r\n\r\nCould any one let me know why the model is not predicting any label?'"
446292589,3750,b'AutoML Code generation generates failing code if the CSV provided have a header named Label',"b'### System information\r\n\r\n- **OS version/distro**:\r\nwindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nAutoMl Wizard Rel 0.3.0\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated a CSV file for the wizard with a column that it needed to predict with the name Label\r\n- **What happened?**\r\nThe code generation created a KeyValue mapper with Label =>Label and PredictedLabel=>PredictedLabel \r\n\r\n\r\n```\r\npublic static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)\r\n{\r\n\t// Data process configuration with pipeline data transformations \r\n\tvar dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n\t\t\t\t\t\t\t  .Append(mlContext.Transforms.Concatenate(""Features"", new[] { ""F1"", ""F2"", ""F3""}));\r\n\r\n\t// Set the training algorithm \r\n\tvar trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: ""Label"", featureColumnName: ""Features"")\r\n\t\t\t\t\t\t\t  .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"", ""PredictedLabel""));\r\n\tvar trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n\treturn trainingPipeline;\r\n}\r\n```\r\nWhen executing the training the code fails here\r\n\r\n![sample fails](https://user-images.githubusercontent.com/44400822/58049408-15cd8700-7b4d-11e9-989c-5d7c430f581c.PNG)\r\n\r\n\r\n\r\n- **What did you expect?**\r\nWriting code that covers all possible issues is hard however as MapValueToKey goes to an internal field and MapKeyToValue cpmes from that internal field it might help not using the same name.\r\nWould be nice if the starter project would work, gives those that give the project a spin a positive vibe.\r\n\r\nPerhaps warn the user that he may needs to change the code, if this occurs, better would be if the issue doesn\'t happen.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
446271599,3749,b'maxExperimentTimeInSeconds - possible to make it deterministic across machines',"b""We started using AutoML to classify about 15000 daily news articles into 50 topics (our early results with AutoML are excellent). We get a training set from a different pipeline that identifies with high precision topics (a community detection algorithm which works well in identifying natural daily topics but has poor recall). We use AutoML to train a multiclass classifier using the output from the first pipeline as the training set. We found that we get best recall by running AutoML a number of times (right now we use 9 times) and only use articles which are assigned to the same topic in a majority of cases with a threshold for the max score (our training set covers about 15% of articles in the daily corpus, a single run of Automl increases to about 25% and the multiple-run hack increases it to 35%).\r\n\r\nOne thing which we don't understand is the maxExperimentTimeInSeconds parameter when calling: \r\nCreateMulticlassClassificationExperiment\r\n\r\nWe are running AutoML across different machines on Windows and Linux with different cores etc. We found that the depth of the experiment pipeline varies a lot across machines - maybe because things take longer on less powerful servers.\r\n\r\nIt would be great if one could control the depth of the AutoML search by another way than maxExperimentTimeInSeconds. \r\n\r\nPossibly related issue: we found that when running AutoML as part of process that consumes about 60GB of memory the experiment take double as long as when we run it with the same data on its own. Moreover, when calling autoML successively (even when creating a new mlContext) the runtimes becomes longer and longer and the depth of the AutoML search becomes shorter (even with maxExperimentTimeInSeconds constant).\r\n\r\nWe therefore now run the AutoML pipeline in a separate child process (one run at a time, then destroy the child process and start fresh; memory consumption is about 2G per run) which produces similar runtimes and depth across runs. But it would be nice to avoid this."""
445992438,3748,b'Add sample for use with Binary dataset',"b'\r\n[Enter feedback here]\r\n\r\nWould be nice to show how a binary file can be used (and re-used) to use strong typed data\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: d77f7787-449e-9eeb-9dc8-e7ca22091538\r\n* Version Independent ID: 2dca3efe-4be8-72c3-0e71-226c2183cc89\r\n* Content: [DataOperationsCatalog.CreateEnumerable(IDataView, Boolean, Boolean, SchemaDefinition) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.createenumerable?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(Microsoft.ML.DataOperationsCatalog.CreateEnumerable%60%601);k(SolutionItemsProject);k(DevLang-csharp)%26rd%3Dtrue&view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
445962127,3747,b'Feels like an endless loop',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows Server 2019, \r\nWindows Server 2012, \r\nWindows 10\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\nDot net Core 3.0\r\nML 1.0.0\r\n[Dump header.txt](https://github.com/dotnet/machinelearning/files/3196652/Dump.header.txt)\r\n\r\n\r\n\r\n### Issue\r\n- **What did you do?**\r\nApplied the following training against a binary dataset of 77.7 Gb\r\n\r\n```\r\nvar featureColumns = Mapper.GetFieldNames();\r\nvar pipeline = mlContext.Transforms.Concatenate(outputColumnName: RawFeatures, inputColumnNames: featureColumns)\r\n        .Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label))\r\n        .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName:Features,inputColumnName: RawFeatures))\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName: KeyColumn, outputColumnName: nameof(PredictedResult.PredictedLabelIndex)));\r\nvar model = pipeline.Fit(horizonDataset.TrainSet);\r\n```\r\nCreated the data set from a Tab Separated file size 398 GB\r\n\r\n- **What happened?**\r\n After some time the trainer seems to loop in memory and CPU performance idles at bellow 20% \r\n![Attached Debugger](https://user-images.githubusercontent.com/44400822/58003126-6955bb80-7ae0-11e9-8f5b-d572f7f86bf2.PNG)\r\n\r\n\r\n![Attached Debugger2](https://user-images.githubusercontent.com/44400822/58003354-df5a2280-7ae0-11e9-9fc6-a36030517221.PNG)\r\n\r\n\r\n- **What did you expect?**\r\nExpect the model to train in a linear manner in the same way as a smaller dataset does, where each GB takes a approximate time, multiply the GB and you get a projected finish time.\r\n\r\nI have reported this several times already, it is hard to discover if the system is ""alive"" or looping this becomes problematic after a few days of no feedback. if you need to access my process perhaps we do a live share session\r\n\r\n### Source code / logs\r\n\r\n[MLContext Log](https://github.com/dotnet/machinelearning/files/3196620/2019.05.19.102043_log.rpt.zip)'"
445523066,3744,"b'Why do I need to have the Lable field in the CreatePredictionEngine<TSrc,> class'","b""Hi,\r\n\r\nI am wondering why shoeld TSrc in MLContext.Model.CreatePredictionEngine<TSrc, TDst> contain the Label fields as it should not need it to make a prediction. I get it why the other fields needs to be there but the one fields if's supposed to predict is the one it should be able to do without. \r\nOmitting the fields in your class however would cause an exception when calling CreatePredictionEngine().\r\n\r\nIs this intentional? """
445363969,3743,b'Question: Deep Learning and Doc2Vec',"b'Hi, \r\n\r\nI was wondering if there are any plans to allow modeling deep neural networks. I know that it is possible to consume Tensorflow models. I am interested in creating and training models directly in ml.net\r\n\r\nUnrelated to the first question: Are there any plans to implement Doc2vec as an alternative to the current FeaturizeText feature.\r\n\r\nIn case this issue tracker is the wrong place to ask questions, please point me to the site you might be using for questions.\r\n\r\nThanks, \r\n\r\nLars'"
445189592,3740,b'Missing requirement in building guidelines for Linux',b'Using the given commands I am not able to build on Ubuntu 18.04 because of missing libomp-dev.'
445181624,3739,b'Unable to build ML.NET from source with Visual Studio 2019',"b'### Issue\r\n\r\n- **What did you do?**: I tried to build ML.NET from the developer\'s guide using Visual Studio 2019\r\n- **What happened?**: The build failed\r\n\r\n`Error: Visual Studio 2015 or 2017 required.`\r\n\r\nIn src/Native/build.cmd at line 64:\r\n`:VS2019`\r\n`:: Setup vars for VS2019`\r\n`set __PlatformToolset=v142`\r\n`set __VSVersion=15 2017`\r\n`if NOT ""%__BuildArch%"" == ""arm64"" (`\r\n`    :: Set the environment for the native build`\r\n`    call ""%VS160COMNTOOLS%..\\..\\VC\\Auxiliary\\Build\\vcvarsall.bat"" %__VCBuildArch%`\r\n`)`\r\n\r\nNeeds to be `set __VSVersion=16 2019`\r\n\r\nAlso cmake needs to be of version 3.14 or higher as it contains the generator for Visual Studion 2019\r\n\r\n\r\n\r\n\r\n'"
445175244,3737,b'Unable to train model if the Label of the training dataset are always the same',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: dotnet core 2.2, ML.NET 1.0\r\n\r\n### Issue\r\n\r\nI want to train a model using this class:\r\n\r\n```\r\n    public class TagData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string Label;\r\n\r\n        [LoadColumn(1)]\r\n        public string Text;\r\n\r\n        [LoadColumn(2)]\r\n        public string CustomerId;\r\n    }\r\n```\r\nAnd my pipeline is written as follow:\r\n\r\n```\r\nvar dataView = mlContext.Data.LoadFromEnumerable(tagDatas);\r\n\r\n var pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"", ""Label"")\r\n                            .Append(mlContext.Transforms.Text.FeaturizeText(""TextFeaturized"", nameof(TagData.Text)))\r\n                            .Append(mlContext.Transforms.Text.FeaturizeText(""CustomerIdFeaturized"", nameof(TagData.CustomerId)))\r\n                            .Append(mlContext.Transforms.Concatenate(""Features"", ""TextFeaturized"", ""CustomerIdFeaturized""))\r\n                            .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy())\r\n                            .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nvar model = pipeline.Fit(dataView);\r\n\r\n```\r\n\r\n**My first test**\r\n\r\nTagDatas is a collection of 3 objects where:\r\n- `CustomerId` is identical in all objects\r\n- `Text` is always different\r\n- `Label` (the value I want to predict in the future) is always **different**\r\n\r\nEverything woks fine.\r\n\r\n**My second test**\r\n\r\nTagDatas is a collection of 3 objects where:\r\n- `CustomerId` is identical in all objects\r\n- `Text` is always different\r\n- `Label` (the value I want to predict in the future) is always **identical**\r\n\r\nProblem: The instruction `pipeline.Fit(dataview);` never ends (and the process keeps consuming a lot of memory & CPU)\r\n\r\n\r\n'"
445120031,3736,b' Source code / logs',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
444894978,3734,b'[Model Builder] Best accuracy not found in Top 5 models',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362 x64\r\n- **.NET Version (eg., dotnet --info)**:  2.1.507\r\n- **ML.NET Model Builder version**: 16.0.1905.641\r\n- **Visual Studio 2017 version**: 15.9.12\r\n\r\n### Issue\r\n\r\n- **What did you do?** Ran ML.NET Model Builder in Visual Studio and trained a binary classification model for 120 seconds\r\n- **What happened?** The _Best Model Accuracy_ was given as 80.65% but the best model in the Top 5 models was listed as having 75.00% accuracy. See picture below for an example\r\n- **What did you expect?** I would expect the _Best Model Accuracy_ to match the best model's  accuracy perfectly.\r\n\r\n### Source code / logs\r\n\r\n![image](https://user-images.githubusercontent.com/4928988/57849473-4a4ee500-77d3-11e9-988a-8bbcfe73b88c.png)\r\n\r\nDo let me know if you need any logs or otherwise."""
444873476,3733,b'WithOnFitDelegate test coverage and code samples',"b'### System information\r\n\r\n- **OS version/distro**: \r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nRelease 1.0.0.0. \r\n\r\n### Issue\r\n- **Related**\r\n#3732  \r\n\r\n- **What did you do?**\r\nLooked for implementations of any samples or tests in regards of how to use the WithOnFitDelegate. I have found none, no unit tests, no samples and not much documentation even though it looks like all networks cal on fit in one way or another. \r\n\r\n- **What did you expect?**\r\nI expect to find some documentation on the method as it allows on looking at the progress of the model being build\r\n'"
444869499,3732,b'Mising code sample',"b'\r\n[Enter feedback here]\r\nThere is no code sample for the use of this method. \r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 64513161-127f-5e7a-b518-9a769f318b62\r\n* Version Independent ID: ce31be65-31c5-df38-73f2-c1d5cca46396\r\n* Content: [LearningPipelineExtensions.WithOnFitDelegate(IEstimator&lt;TTransformer&gt;, Action&lt;TTransformer&gt;) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.learningpipelineextensions.withonfitdelegate?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/LearningPipelineExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/LearningPipelineExtensions.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
444564610,3729,b'CLI does not support other cultures besides en-US',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100-preview-5-011568\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan CLI auto-train on a TSV file with culture set to Finnish.\r\n1. Set Windows Regional format to Finnish.\r\n    - Download the Finnish language pack from the Microsoft store (it\'s called suomi): https://www.microsoft.com/store/productId/9MW3PQ7SD3QK\r\n    - Change the format to ""Finnish (Finland)"" in `Windows settings -> Time & Language -> Region -> Regional format`\r\n2. Run CLI:\r\n    - `mlnet auto-train --task regression --dataset taxi-fare-train.csv --label-column-name fare_amount -- max-exploration-time 10`\r\n    - File: https://github.com/dotnet/machinelearning-samples/blob/master/samples/CLI/Regression_CLI/taxi-fare-train.csv\r\n\r\n- **What happened?**\r\nError:\r\n```\r\nException occured while exploring pipelines:\r\nProvided label column \'fare_amount\' was of type String, but only type Single is allowed.\r\nPlease see the log file for more info.\r\nExiting ...\r\n```\r\n- **What did you expect?**\r\nSuccessful model training. Switching the regional format back to ""English (United States)"" allows training to complete successfully.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
444294558,3728,b'documentation for the correct implmementation ExperimentResult progress handler for Multiclass',b'Haling a look at the AutoML API I have noted that documentation for [Multiclass experiment](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.automl.multiclassclassificationexperiment?view=automl-dotnet) does not document a progress handler. \r\n\r\nWould be nice if there is a way to get this documented as I feel that this can be usefull'
444217445,3726,b'What is the CLR bug mentioned in Div64Core',"b'I notice this in the code. Does anyone know where the mentioned CLR issue is tracked? I am curious whether we are fixing it.\r\n```\r\n        [MethodImpl(MethodImplOptions.AggressiveInlining)]\r\n        private static ulong Div64(ulong lo, ulong hi, ulong den, out ulong rem)\r\n        {\r\n            if (den == 0)\r\n                throw new DivideByZeroException();\r\n            if (hi >= den)\r\n                throw new OverflowException();\r\n            return Div64Core(lo, hi, den, out rem);\r\n        }\r\n\r\n        // REVIEW: on Linux, the hardware divide-by-zero exception is not translated into\r\n        // a managed exception properly by CoreCLR so the process will crash. This is a temporary fix\r\n        // until CoreCLR addresses this issue.\r\n        [DllImport(Thunk.NativePath, CharSet = CharSet.Unicode, EntryPoint = ""Div64""), SuppressUnmanagedCodeSecurity]\r\n        private static extern ulong Div64Core(ulong lo, ulong hi, ulong den, out ulong rem);\r\n#endif\r\n```\r\n\r\n@TomFinley @eerhardt  @tannergooding '"
444176056,3723,b'IDataView Type System needs to be extensible to support Image scenarios properly',"b""### The Problem\r\nCurrently it is impossible make prediction from images if they do not come from file.  PredictionEngine<IT,OT> and IEnumerable<T> to IDV is impossible if T contains images/\r\n\r\n### The Root Cause\r\nThe fundamental issue is that in several places in our system,  our types are hardcoded and limited to a small set. Actual IDataView type system IS open, so it should be possible to support any type. However, some of our machinery is not so extensible.   For example, if we need to add full support of images, we would need to update:\r\n- converters between IEnumerable<T> <-> IDataView, \r\n- PredictionEngine<> \r\n- API Utils, \r\n- Schema utils \r\n- etc.\r\n\r\nWhat we need is a dependency-injection mechanism to allow component developers to inject definitions of types supported by our IDV machinery.  Such mechanism should be flexible and extensible.  For an example of hard-coded implementation, check #3263.  It is illustrative but incorrect as it is not flexible.  Note @TomFinley's comment on different options on how to do this properly.  We need to define a mechanism that is extensible, so that a dev can add new transforms to work on new data types, such as sound and enjoy all benefits of ML.NET\r\n\r\n### Definition of Done:\r\n- Mechanism to register additional IDV types so that they are supported by PredictionEngine and IEnumerable converters.\r\n- Add such registration for images and date types\r\n- Ensure that the registration (at least for images)  occurs automatically whenever appropriate component is used (for example, if image resizing transform is used, the image type is registered automatically )\r\n- Ensure that prediction engine, conversion to and from IEnumerable work correctly with tests.\r\n\r\n### The following issues will also be solved by this issue:\r\n#3369, #3460, #3582, #2121, #2495, #3582, #3274\r\nIn addition, this work is needed to properly support ONNX and TF scenarios for structured data such as image, speech, video, or Audio."""
444175916,3722,b'libomp 8.0.0 version has dependencies that do no exist on macOS build machines',b'It seems brew installing latest libomp has dependencies that do not exist on build machines. Investigate what those dependencies are by taking a trace and install them.\r\n\r\nRelated to #3694 '
444112532,3720,"b""Sse math doesn't contain `Div64` and `TryMulDiv64Core`""","b'These are used in `IntUtils.cs` [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.CpuMath/IntUtils.cs#L76) and [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.CpuMath/IntUtils.cs#L314), but they are not in the native code.'"
444093178,3718,b'Exception: When previewing data',"b""\r\nAn exception is generated within the following function:\r\n\r\n`public static void PeekDataViewInConsole(MLContext mlContext, IDataView dataView, IEstimator<ITransformer> pipeline, int numberOfRows = 4)\r\n        {\r\n          \r\n            var transformer = pipeline.Fit(dataView);\r\n            var transformedData = transformer.Transform(dataView);\r\n\r\n            // 'transformedData' is a 'promise' of data, lazy-loading. call Preview  \r\n            //and iterate through the returned collection from preview.\r\n\r\nException:\r\n            var preViewTransformedData = transformedData.Preview(maxRows: numberOfRows);\r\n\r\nThis is because the data that is read contains a Datatime format column. Is there a way to remove this column from the Preview call?\r\n\r\nThanks\r\n\r\n"""
444017162,3717,b'Add LoadableClassAttribute to DNNImageFeaturizer ',b'Needed so it can be used in the TLC GUI/command line\r\n\r\n@yaeldekel '
444016628,3716,b'Fixes to Permutation Feature Importance',b'Permutation Feature Importance needs some fixes to enable it for internal repo\r\n\r\n@yaeldekel '
444016012,3715,b'Add \xe2\x80\x98InternalsVisibleTo\xe2\x80\x99 attributes to some projects',"b'- Microsoft.ML.StandardLearners \r\n  - expose internals to SequencePrediction \r\n\r\n- Microsoft.ML.Transforms  \r\n  - expose internals to TMSNLearnPrediction (enable Dracula Transform)\r\n\r\n(SequencePrediction, SLibWrapper and TestSequence.cs were removed and need to be added back, same for CountTableTransform.cs, DraculaTransform.cs).\r\n\r\n@yaeldekel \r\n'"
443860407,3714,b'Question: Timeseries analysis',"b'Hi all,\r\n\r\nI wish to reach out to you concerning the best approach to use for time series based analysis. \r\n\r\nI appreciate that the platform at present does not have support for many deep learning features such as LSTM. But with release 1.0 in mind, are there any examples or resources to illustrate an approach to analysis?\r\n\r\nIf not it would be great to see this on the future release roadmap.\r\n\r\nTa, best wishes'"
443796975,3713,b'Benchmark package to collect and compare hardware performance with API',"b'**Problem**\r\nSizing server infrastructure for production deployments is an issue as hardware specialists have no clue how a system will perform and there is hardly any documentation available unlike with SQL Server, Exchange etc.\r\n\r\nML is becoming such a important feature in IT that it will/has gotten get it\'s own dedicated teams just like the above mentioned systems however there is BPA / IO Stress test available for the workload.\r\n\r\n**Proposal**\r\nCreate a benchmark project/ application that will run a workflow cycle on a larger dataset and show a ""score"" much like [UserBenchmark](https://cpu.userbenchmark.com/). Provide the source code as well as a executable so users can compare to the reference system and compare why their system scores a given value.\r\n\r\n**Solves**\r\nAllows for proper sizing a system be it Azure of physical and projects a duration of a reference system based on the underlying system. I guess it will find community support as it helps all of us.'"
443652245,3712,b'Anomaly detection evaluator throws',"b'Issue number #2644 was fixed in pr #2692, but now there is an exception thrown when the dataset contains only positive examples.\r\nIn my opinion, it makes more sense to report an AUC of NaN than to throw - the other metrics can still be computed, so there is no need to throw.\r\n'"
443651044,3711,b'Getting unablanced (or empty) folds when running CV with a SamplingKeyColumn (such as when running CV with Ranking)',"b'The change in KeyDataViewType to disallow unknown cardinality keys, fixed a silent bug in CV that caused the group column to not be used for stratification (causing label leakage between the training and test sets), but now that it is fixed there is a new bug.\r\nCV now uses the GroupId column for stratification, but the values in the GroupId column may not be distributed evenly, causing all the examples to be in one fold, and the others would be empty.\r\nFor example: Assume that the values in the GroupId column are `10,11,...,19`, and that they are loaded with `TextLoader` as a key type column. The key type would be of cardinality 20, and if there are 2 folds, then CV will try to create one fold with all the examples with values `0,...,9` and the other fold with all the examples with values `10,...,19`.\r\n '"
443648700,3710,b'LightGBMRankingTrainer bug',"b'The `LightGBMRankingTrainer` `CustomGains` option needs to have `AllowMultiple` in its `ArgumentAttribute`, since it is an array.'"
443647828,3709,"b""Ensembles don't work""","b'The trainer argument of Ensembles is of type `IComponentFactory<ITrainer<IPredictorProducing<>>>`.\r\n\r\nHowever, none of the trainers in ML.NET implement `ITrainer<IPredictorProducing<>>`, they just implement `ITrainer<IPredictor>`, so there is no way to specify a different trainer in the arguments\r\n(when running the maml command line).'"
443643562,3708,"b'Custom gain argument for ranking: double[] in trainer, string in evaluator'","b'The argument was recently changed to double[] in the ranking trainers, but is still a string in the ranking evaluator. We should be consistent.'"
443642940,3707,b'BinaryLoader throws exception when a dataset contains 0 rows',"b'BinaryLoader tries to create a `KeyDataViewType` with count equal to the number of rows [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Binary/BinaryLoader.cs#L1208), but with the recent change to `KeyDataViewType` `count=0` is not allowed.\r\n'"
442981365,3705,"b""Context.Data.CreateTextLoader<T> throws error Can't determine the number of source columns without valid data""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nAutoML 0.3.0\r\nMicrosoft.ML 1.0.0.0\r\n\r\n### Issue\r\nI thought one can map a class and load it with the annotation but get an error when calling it on a parameter that\'s not available for me.\r\n\r\n- **What did you do?**\r\nI wrote a little test to play with Microsoft.ML.AutoML and test it against a label and a vector\r\nI add my litle [Program](https://github.com/dotnet/machinelearning/files/3168931/Program.zip)\r\nwhere I call in the ticket\r\n\r\nbasically I cal:\r\n```\r\npublic static IDataView GetDataView<T>(MLContext mlContext, FileInfo trainingFile)\r\n{\r\n    var loader = mlContext.Data.CreateTextLoader<T>(separatorChar: \'|\', hasHeader: false);\r\n    return loader.Load(trainingFile.FullName);\r\n            \r\n}\r\npublic class Data\r\n{\r\n     [LoadColumn(0)]\r\n     public string Label { get; }\r\n\r\n     [LoadColumn(1, 40_731)]\r\n     [VectorType(40_730)]\r\n     public float[] Features { get; }\r\n}\r\n```\r\n\r\n- **What happened?**\r\nI get an error stating\r\n> System.ArgumentOutOfRangeException: \'Can\'t determine the number of source columns without valid data\r\n> Parameter name: Source\'\r\n\r\nStack\r\n```\r\n   at Microsoft.ML.Data.TextLoader.Bindings..ctor(TextLoader parent, Column[] cols, IMultiStreamSource headerFile, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.Data.TextLoader..ctor(IHostEnvironment env, Options options, IMultiStreamSource dataSample)\r\n   at Microsoft.ML.Data.TextLoader.CreateTextLoader[TInput](IHostEnvironment host, Boolean hasHeader, Char separator, Boolean allowQuoting, Boolean supportSparse, Boolean trimWhitespace, IMultiStreamSource dataSample)\r\n   at ConsoleMLWizard.Program.GetDataView[T](MLContext mlContext, FileInfo trainingFile) in C:\\Users\\W2307\\source\\repos\\ConsoleMLWizard\\Program.cs:line 99\r\n   at ConsoleMLWizard.Program.Main(String[] args) in C:\\Users\\W2307\\source\\repos\\ConsoleMLWizard\\Program.cs:line 37\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nI expected the anotations to work, I can load the data fine using:\r\n```\r\nvar loader = context.Data.CreateTextLoader(options: new TextLoader.Options()\r\n{\r\n    Columns = new[] {\r\n        new TextLoader.Column(name:""Label"", dataKind: DataKind.String, index: 0),\r\n        new TextLoader.Column(name:""Features"",dataKind:DataKind.Single,minIndex:0,maxIndex:40731)\r\n    },\r\n    HasHeader = false,\r\n    Separators = new[] { \',\' },\r\n                \r\n});\r\nvar data = loader.Load(dataFile.FullName);\r\n```\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n\r\n'"
442862772,3704,b'Fix all code that has //REVIEW against it',"b'C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\ColumnInference\\ColumnTypeInference.cs(20):        // REVIEW: revisit this requirement. Either work for arbitrary number of columns,\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\ColumnInference\\PurposeInference.cs(228):            // REVIEW: could be improved.\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\ColumnInference\\TextFileSample.cs(18):        // REVIEW: consider including multiple files via IMultiStreamSource.\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\ColumnInference\\TextFileSample.cs(20):        // REVIEW: right now, it expects 0x0A being the trailing character of line break.\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\ColumnInference\\TextFileSample.cs(110):            // REVIEW: CreateFromHead still truncates the file before the last 0x0A byte. For multi-byte encoding,\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(205):            // REVIEW: this condition can be relaxed if we change the math below to deal with it\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(212):        // REVIEW: Is Float accurate enough?\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(218):                // REVIEW: review the math below, it only works for positive Min and Max\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(248):                    // REVIEW: review the math below, it only works for positive Min and Max\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(331):            // REVIEW: this condition can be relaxed if we change the math below to deal with it\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(338):        // REVIEW: Is Float accurate enough?\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(344):                // REVIEW: review the math below, it only works for positive Min and Max\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(366):                // REVIEW: review the math below, it only works for positive Min and Max\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\Parameters.cs(451):        // REVIEW: Is Float accurate enough?\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Sweepers\\SmacSweeper.cs(15):    //REVIEW: Figure out better way to do this. could introduce a base class for all smart sweepers,\r\n  C:\\code\\MLNet\\src\\Microsoft.ML.Auto\\Utils\\MLNetUtils\\ArrayDataViewBuilder.cs(229):                    // REVIEW: Implement cursor set support.\r\n  C:'"
442857636,3703,b'[AutoML] Column inferencing is limited to 10000 Columns',b'Looks like when a dataset has more than 10000 columns. The column inferencing API is failing in AutoML and hence CLI also fails\r\n\r\nSystem information\r\nOS version/distro: Any OS\r\nML.NET CLI\r\n\r\nWhat did you do?\r\nGave the CLI a csv file more than 10000 columns\r\nWhat happened?\r\nCLI fails to run and throws an exception while inferring columns\r\n\r\nWhat did you expect?\r\nTo infer columns and produce a model and console project.'
442844696,3702,b'ML.Net tutorial inside Win32 RunFullTrust process gives inconsistent results',"b'### System information\r\nOS Name\tMicrosoft Windows 10 Enterprise\r\nVersion\t10.0.17763 Build 17763\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n:\\Users\\v-pauls>dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.2.202\r\n Commit:    8a7ff6789d\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.202\\\r\n\r\nHost (useful for support):\r\n  Version: 2.2.3\r\n  Commit:  6b8ad509b6\r\n\r\n.NET Core SDKs installed:\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.500 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.502 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.503 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.504 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.505 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.202 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI created a Win32 ""FullTrustProcess"" version of the Iris tutorial, callable from a UWP app.\r\n- **What happened?**\r\nThe app made no predictions under ML.Net 0.11.  When updated to ML.Net 1.0, the app does provide predictions, but these are only ""Correct"" some of the time, in other words, they only match the tutorial output sometimes.\r\n\r\nAdditionally, ML.Net 1.0 seems to throw EETypeLoad exception on loading AppContract.DLL.  Don\'t know if its your code or a dependency.\r\n\r\n- **What did you expect?**\r\nConsistent results.\r\n\r\n### Source code / logs\r\n\r\nA complete sample project, screenshots, debug output, and a explanatory REAME.md may be found at my GitHub repository at https://github.com/PaulaScholz/MLDotNetUWP'"
442585590,3701,b'How to inspect OneVersusAll models',"b""Version: 1.0\r\n\r\nSince 2b417bb9f30c249d1267eeace8f0af82890f3c6e made `SubModelParameters` private, there is no chance to get any of the sub models which would be needed for feature importance.\r\n\r\nHow do I inspect OVA models? In particular, how to get feature importance?\r\n\r\nFWIW, I have no chance of using PFI feature importance. It would take day to run. It's 1000x slower than training any of my models."""
442537932,3699,b'TransfromWrapper should only apply the last transform in some cases',"b'Consider the pipeline generated from NimbusML that adds OptionalColumnTransform automatically to make sure label column is of correct type, i.e key type. When this model is loaded in ML.NET, OptionalColumnTransform is executed as TransformWrapper that is instantiated with an IDataView containing the entire pipeline until that point. Unfortunately transform wrapper applies the entire chain of transforms when it should just apply the last transformer in the chain, this holds true if we had a IDataTransform preceded by RowToRowMapperTransfom.\r\n\r\nCC: @yaeldekel '"
442508232,3698,"b'DataViewSchema not validated for null on training, but is required for creating PredictionEngine'","b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10 Pro 1806 (also happens in Azure web app)\r\n- **.NET Version (eg., dotnet --info)**: \r\n2.2.104\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nSaved a model passing null for the DataViewSchema.\r\n\r\n- **What happened?**\r\nWhen you save a model with a using mlContext.Model.Save and pass null for the DataViewSchema, the model trains fine, but when you attempt to consume the model, a null reference exception is thrown:\r\n\r\n""at Microsoft.ML.Data.DataViewConstructionUtils.GetSchemaDefinition[TRow](IHostEnvironment env, DataViewSchema schema)""\r\n\r\n- **What did you expect?**\r\nThe mlContext.Model.Save method should throw on null DataViewSchema input parameter.\r\n\r\n### Source code / logs\r\n\r\n""at Microsoft.ML.Data.DataViewConstructionUtils.GetSchemaDefinition[TRow](IHostEnvironment env, DataViewSchema schema)""\r\n'"
442486096,3697,b'[CLI] auto-generated file by Microsoft ML.NET CLI (Command-Line Interface) tool seems to be of not recomended format',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: ML.Net Model Builder (Preview) version 16.0.1905.641\r\n\r\n### Issue\r\n- **What did you do?**\r\nGave the model a csv file with 600 floats and a  header with a label column and some random names\r\n- **What happened?**\r\nModel got build and a Model input file got generated\r\n- **What did you expect?**\r\nThe model input file could load all fields but the label field in a single vector but it did not it made a class with single properties and not a features column with a single vector as is recommended here in the issues comments.\r\n\r\nWich is it, what's best practice?\r\n \r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
442367336,3694,b'MacOS CI legs throwing DllNotFoundException for MklImports',"b""Related to #3722 \r\n\r\nThe MacOS CI legs in multiple PRs are throwing `DllNotFoundException` for MklImports.dll.\r\n\r\nE.g. #3676 #3682 #3693\r\n\r\n\r\nError Message:\r\n System.TypeInitializationException : The type initializer for 'Microsoft.ML.TestFramework.BaseTestClass' threw an exception.\r\n---- System.DllNotFoundException : Unable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found\r\nStack Trace:\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.RuntimeType.CreateInstanceImpl(BindingFlags bindingAttr, Binder binder, Object[] args, CultureInfo culture, Object[] activationAttributes)\r\n   at ReflectionAbstractionExtensions.<>c__DisplayClass0_0.<CreateTestClass>b__0() in C:\\Dev\\xunit\\xunit\\src\\xunit.execution\\Extensions\\ReflectionAbstractionExtensions.cs:line 42\r\n   at ReflectionAbstractionExtensions.CreateTestClass(ITest test, Type testClassType, Object[] constructorArguments, IMessageBus messageBus, ExecutionTimer timer, CancellationTokenSource cancellationTokenSource) in C:\\Dev\\xunit\\xunit\\src\\xunit.execution\\Extensions\\ReflectionAbstractionExtensions.cs:line 42\r\n----- Inner Stack Trace -----\r\n   at Microsoft.ML.Internal.Internallearn.Test.GlobalBase.Mkl.PptrfInternal(Layout layout, UpLo uplo, Int32 n, Double[] ap)\r\n   at Microsoft.ML.Internal.Internallearn.Test.GlobalBase.AssemblyInit() in /Users/vsts/agent/2.150.3/work/1/s/test/Microsoft.ML.TestFramework/GlobalBase.cs:line 30\r\n   at Microsoft.ML.TestFramework.BaseTestClass..cctor() in /Users/vsts/agent/2.150.3/work/1/s/test/Microsoft.ML.TestFramework/BaseTestClass.cs:line 22"""
442276483,3692,b'Question : Exploration through Fsharp + DataFrame types',"b'Will ML.NET have an API for data exploration ?\r\n\r\nBy data exploration i mean statistics, selections, filters of dataframe like objects.'"
442143417,3690,"b""SDCA's L1Regularization is badly named since rename""","b""A lot of the constants of various learners got renamed to `L1Regularization`. But, in SDCA this isn't actually the `L1Regularization` as the doc also states. It's the ratio of `L1/L2`.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5d9e88083a21163258bbeb45597a5f1a95039bc8/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs#L167-L175\r\n\r\n"""
442139476,3689,b'System.InvalidOperationException when loading tensorflow model',"b""### System information\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nVisual Studio 2017\r\n.NET Core 2.1\r\nMicrosoft.ML v1.0.0 NuGet package\r\n\r\n### Issue\r\n- **What did you do?**\r\nBased on the example on [https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow](url) I tryed to load a tensorflow model using for image segmentation into Microsoft.ML\r\nThe model it self was created using keras and then converted to tensorflow using an adapted version of the [https://github.com/amir-abdi/keras_to_tensorflow](url) \r\n- **What happened?**\r\n\r\n\r\nSystem.InvalidOperationException when calling LoadTensorFlowModel function\r\n- **What did you expect?**\r\nExcepted the model to be loaded.\r\n\r\n### Source code / logs\r\n\r\n`   at Microsoft.ML.Transforms.TensorFlow.TensorFlowUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   at Microsoft.ML.TensorflowCatalog.LoadTensorFlowModel(ModelOperationsCatalog catalog, String modelLocation)\r\n   at ImageClassification.Score.ModelScorer.TFModelScorer.LoadModel(String dataLocation, String imagesFolder, String modelLocation) in C:\\Users\\me1cme\\repos\\ml.net-learning\\samples\\csharp\\getting-started\\DeepLearning_ImageClassification_TensorFlow\\ImageClassification\\ModelScorer\\TFModelScorer.cs:line 67\r\n   at ImageClassification.Score.ModelScorer.TFModelScorer.Score() in C:\\Users\\me1cme\\repos\\ml.net-learning\\samples\\csharp\\getting-started\\DeepLearning_ImageClassification_TensorFlow\\ImageClassification\\ModelScorer\\TFModelScorer.cs:line 50\r\n   at ImageClassification.Program.Main() in C:\\Users\\me1cme\\repos\\ml.net-learning\\samples\\csharp\\getting-started\\DeepLearning_ImageClassification_TensorFlow\\ImageClassification\\Program.cs:line 27`\r\n\r\nMessage\r\n`TensorFlow exception triggered while loading model from '../../../assets/inputs/final.pb'`\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n"""
442124029,3688,b'LightGBM: IsUnbalanced is relevant for OVA multi class',"b'Version: 1.0\r\n\r\nSetup:\r\n\r\n- LightGBM Multiclass trainer\r\n- NOT softmax (thus: ""objective"" = ""mutliclassova"").\r\n\r\nBefore 1.0 we had `UnbalancedSets` available for the three booster configs, but this option was removed it seems.\r\n\r\nThough, that option very much had an effect on performance in this case.\r\n\r\nYou can see that the OVA objective just calls the binary one:\r\n\r\nhttps://github.com/microsoft/LightGBM/blob/0a4a7a86f5a1d3146c36c7d8c082154a193d4893/src/objective/multiclass_objective.hpp#L173-L182\r\n\r\nwhich will happily use the config parameter:\r\n\r\nhttps://github.com/microsoft/LightGBM/blob/0a4a7a86f5a1d3146c36c7d8c082154a193d4893/src/objective/binary_objective.hpp#L20-L36\r\n\r\n'"
442110732,3687,b'LightGBM option MaximumCategoricalSplitPointCount has wrong doc',"b'See:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8b1b14f916428967dc0066b956485c35a0090fe3/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L189-L196\r\n\r\nand\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8b1b14f916428967dc0066b956485c35a0090fe3/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L49-L59\r\n\r\nand\r\nhttps://lightgbm.readthedocs.io/en/latest/Parameters.html#max_cat_threshold :\r\n\r\n```\r\nmax_cat_threshold, default = 32, type = int, constraints: max_cat_threshold > 0\r\n- used for the categorical features\r\n- limit the max threshold points in categorical features\r\n```\r\n\r\nIt got mixed up with:\r\n\r\nhttps://lightgbm.readthedocs.io/en/latest/Parameters.html#max_cat_to_onehot\r\n\r\n```\r\nwhen number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\r\n```'"
442100510,3686,b'ML.NET Domain does not belong to microsoft',"b'In marketing / newsletter emails from microsoft, ML.NET is interpreted by my email client (gmail) as an hyperlink. However, ML.NET leads to a sales inquiry for the domain.'"
442092085,3685,b'Nice feature however better to have a Event with an EventArgs to manage this in production code',"b'\r\n[Enter feedback here]\r\nThis is an important feature however there are several different ways one could come to a conclusion to early stop the training. \r\n\r\nAt the moment the training iteration goes to a fixed number 100 if I\'m not mistaken. Although that number is nice it would be better to provide a early stopping rule, providing a rule would in my opinion override/enhance the NumberOfIterations property. \r\n\r\nsome simple generic rules would help\r\n    - Minimum improvement\r\n    - MaxDuration (TimeSpan)\r\n    - Number of Iterations\r\n \r\nProposed delegate\r\n    - Iteration Nr => (get)\r\n    - Maximum Iteration=> (get)\r\n    - Pref Score/ Improvement =>(get)\r\n    - Current Score/ Improvement => (get)   \r\n   -  Auto-configured [Trainer].Options specific values related to fitting\r\n    - StopNow => (get/set)\r\n    - GetMetrics(validationdata)\r\n    - GetCurrentModel()\r\n\r\nThis would allow us to early adjust the training to stop if Iteration/ time passed is not improving as per expected value. \r\n\r\nSome use cases: \r\n1. Speed up training and quality by make better use of trainer options\r\n   - understand the auto - discovered properties and how they are adjusted by \r\n     the trainer so that one can better understands what to specify in the \r\n     [Trainer].Options like  LearningRate etc NumberOfLeaves.\r\n \r\n2. Reporting: \r\n    - allows to generate charts showing progress of training (real-time and as log).\r\n    - allows joining machine resources with progress in training in reporting/ logging.\r\n\r\n3. In Multi-class:\r\n    - Additional train a specific class (under over fitting).\r\n    - Store ""sub models"" for specific classes.\r\n\r\n4. Generative adversarial network (GAN)\r\n    - Hook for joining [N] networks together allowing them. \r\n       to improve the other network in a more efficient way.\r\n\r\n5. Adversarial machine learning (spam filter\'s, vulnerability testing etc)\r\n     - hook for additional training on specific exploits and or \r\n       make/ save specific models for specific set of exploits/ classes.  \r\n\r\nThe above list is not a complete set of use cases, just some use cases that would be greatly improve usability of the framework that pop in mind. \r\n\r\nI know of no way, at the moment, how this can be done with the current framework without massive waist of resources and time. Training with our in-house framework has this and some of my models train for days big server so iterating / poking around (and waiting) with values is not really an option. \r\n\r\nWhen playing with Iris sample size of data this feature might sound silly as it\'s done before one can sip a cup of coffee, production development is a bit different. \r\n \r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 1ee559b0-04b6-5280-ed68-6291d1e2f7cf\r\n* Version Independent ID: abe34fa0-63f1-7501-165b-20b55190dc0b\r\n* Content: [LightGbmTrainerBase&lt;TOptions,TOutput,TTransformer,TModel&gt;.OptionsBase.EarlyStoppingRound Field (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmtrainerbase-4.optionsbase.earlystoppinground?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmTrainerBase`4+OptionsBase.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmTrainerBase`4+OptionsBase.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
442079812,3684,b'[AutoML] Allow to use serialized IDataView as an input',"b'ML.NET support at least two types of `IDataView` serializations out of the box - text and binary files.\r\n\r\nSo I can use [one of two](https://github.com/dotnet/machinelearning/issues/3661#issuecomment-489996753) to prepare my data set for AutoML\r\n```csharp\r\nusing (var stream = File.Create(textFileName))\r\n    mlContext.Data.SaveAsText(data, stream);\r\n\r\nusing (var stream = File.Create(binFileName))\r\n    mlContext.Data.SaveAsBinary(data, stream);\r\n```\r\n\r\nBut when I try to use serialized file as an input for AutoML (both CLI and GUI version) it unable to parse them. \r\n\r\n### Binary format\r\nUsing binary format \r\n> mlnet auto-train --task binary-classification --dataset ""data-bin.idv"" --label-column-name IsCS --cache on --max-exploration-time 60  --verbosity diag\r\n\r\nI see following error\r\n```\r\nInferring Columns ...\r\nAn Error occured during inferring columns\r\nUnable to split the file provided into multiple, consistent columns.\r\nMicrosoft.ML.AutoML.InferenceException: Unable to split the file provided into multiple, consistent columns.\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns)\r\n   at Microsoft.ML.CLI.CodeGenerator.AutoMLEngine.InferColumns(MLContext context, ColumnInformation columnInformation)\r\n   at Microsoft.ML.CLI.CodeGenerator.CodeGenerationHelper.GenerateCode()\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass1_0.<Main>b__0(NewCommandSettings options)\r\nPlease see the log file for more info.\r\nExiting ...\r\n```\r\n\r\n### Text format\r\n\r\nWith `--verbosity diag` it stuck on the line \r\n```\r\nInferring Columns ...\r\nCreating Data loader ...\r\nLoading data ...\r\nExploring multiple ML algorithms and settings to find you the best model for ML task: binary-classification\r\nFor further learning check: https://aka.ms/mlnet-cli\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration #Iteration             |\r\n[Source=AutoML, Kind=Trace] Channel started\r\n```\r\n\r\nwith default verbosity \r\n> mlnet auto-train --task binary-classification --dataset ""data-txt.tsv"" --label-column-name IsCS --cache on --max-exploration-time 60 \r\n\r\nit return an error of type mismatch\r\n```\r\nxploring multiple ML algorithms and settings to find you the best model for ML task: binary-classification\r\nFor further learning check: https://aka.ms/mlnet-cli\r\n\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\nWaiting for the first iteration to complete ...                                                                                                                                       00:00:00\r\nException occured while exploring pipelines:\r\nProvided label column \'IsCS\' was of type Single, but only type Boolean is allowed.\r\nPlease see the log file for more info.\r\n```\r\n\r\nbut data file looks correct (it serialized by ML.NET). \r\nThis is the header and first lines of dataset\r\n```\r\n#@ TextLoader{\r\n#@   header+\r\n#@   sep=tab\r\n#@   col=IsCS:BL:0\r\n#@   col=Features:R4:1-19\r\n#@ }\r\nIsCS\t19\t0:""""\r\n0\t2\t0.259255171\t0\t0\t0\t1.41421354\t0\t1.41421354\t0\t1.41421354\t0\t1.41421354\t0\t3\t6\t0\t0\t1\t1192\r\n0\t6\t0.259255171\t0\t0\t0\t1.41421354\t0\t1.41421354\t0\t1.41421354\t0\t1.41421354\t0\t3\t6\t0\t0\t1\t1192\r\n```'"
442065313,3683,b'CategoricalSmoothing & Fitting model data',"b'\r\n[Enter feedback here]\r\n\r\nIs this a feature that helps with solving the issue of unbalanced data in regards to class occurrence (under-fitting)? if so than it would help in high-lighting this. explaining this a bit more would help.\r\n\r\nusefull for the user of the documentation is categorizing the properties so that those new to the topic understand what to look for and where to look for it\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: d3179776-5939-ad12-68ae-0f3bd489bae0\r\n* Version Independent ID: 0f25c6ac-d961-87c0-029a-8303211acc6c\r\n* Content: [LightGbmTrainerBase&lt;TOptions,TOutput,TTransformer,TModel&gt;.OptionsBase.CategoricalSmoothing Field (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmtrainerbase-4.optionsbase.categoricalsmoothing?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmTrainerBase`4+OptionsBase.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmTrainerBase`4+OptionsBase.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
441965015,3680,b'Max File Size Limits for Model Builder',"b'Issue:\r\n\r\nUsing the ML.NET Model Builder, there is a max file size limit of 1 GB per the GUI:\r\n\r\n![image](https://user-images.githubusercontent.com/12853868/57413374-c11f2900-71a8-11e9-94ce-617f8d17babe.png)\r\n\r\nNo documentation on the limit available to my knowledge. If there is, can someone provide me the link?\r\n\r\nIs there a way to change the limit?\r\n\r\nAnd, is this a limit also using the AutoML CLI?'"
441777694,3679,b'Please add support for Visual Basic.Net',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\nIt looks like this Visual Studio extension does not currently work in Visual Basic .Net projects.\r\n\r\n- **What did you do?**\r\nInstalled the ML.Net Model Builder extension in Visual Studio 2019.\r\nCreated a new VB.Net project and a new C# project.\r\n\r\n- **What happened?**\r\nThe ML.Net Model Builder extension worked in the C# project (Add - Machine Learning opened the ML.Net Model Builder tab). Pass for C#.\r\n\r\nThe ML.Net Model Builder extension did not work in the VB.Net project (Add - Machine Learning was not even available). FAIL for VB.Net.\r\n\r\n- **What did you expect?**\r\nIt would be nice for this extension to work in VB.Net projects as well.\r\nYou would more than double your audience!\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
441580476,3678,"b'Cannot load a trained model: ""A local file header is corrupt""'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: Microsoft.NETCore.App 3.0.0-preview4-27615-11\r\n\r\n### Issue\r\nCannot load a trained model.\r\n\r\n- **What did you do?**\r\nTrained a model with AutoML, saved it to ""model.zip"" (see attached) and then I tried to load it via:\r\n`\r\nvar mlContext = new MLContext();\r\nvar mlModel = mlContext.Model.Load(""model.zip"", out _);\r\n`\r\n- **What happened?**\r\nAn exception is thrown: ""A local file header is corrupt""\r\n- **What did you expect?**\r\nThe model to be loaded so I can make a prediction.\r\n### Source code / logs\r\n[model.zip](https://github.com/dotnet/machinelearning/files/3155902/model.zip)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
441354172,3675,b'Predict() cannot find file on disk even though it exists',"b'### System information\r\n\r\n- **OS version/distro**: macOS\r\n- **.NET Version (eg., dotnet --info)**: 2.2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan the ObjectDetection example from https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ObjectDetection_Onnx\r\n\r\n- **What happened?**\r\nThe Predict() method of the model produced an IO error that the file could not be found\r\n\r\n- **What did you expect?**\r\nFor the sample to properly classify the images.\r\n\r\n---\r\nI also confirmed that the file does exist on disk and that the file is readable. I did this by passing sample.ImagePath to File.ReadAllText() in an additional line I added above the Predict() line.\r\n\r\n![image](https://user-images.githubusercontent.com/1551020/57320674-0e29cf00-70c5-11e9-8d45-5ee2b655560b.png)\r\n\r\n### Source code / logs\r\n\r\n![image](https://user-images.githubusercontent.com/1551020/57320303-37962b00-70c4-11e9-8d25-be019e95dd98.png)\r\n\r\n'"
441252235,3674,b'Permutation Feature Importance on Text Data',"b'This question/issue is related to dotnet/docs#12216\r\n\r\nUsing data that looks like the following (ignore accuracy, this was generated data for demo purposes):\r\n\r\nAudienceReview|CriticReview|Rating\r\n|---|---|---|\r\nIt was a true masterpiece|I hated it |2\r\nWorst movie ever|I did not like it|1\r\nIt was nice|It was nice|1\r\n\r\nI created the data model `InputData`:\r\n\r\n```csharp\r\npublic class InputData\r\n{\r\n    [LoadColumn(0)]\r\n    public string AudienceReview { get; set; }\r\n    [LoadColumn(1)]\r\n    public string CriticReview { get; set; }\r\n    [LoadColumn(2)]\r\n    [ColumnName(""Label"")]\r\n    public float Rating { get; set; }\r\n}\r\n```\r\n\r\nAnd used the following pipeline:\r\n\r\n```csharp\r\nDataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data);\r\nIDataView trainData = dataSplit.TrainSet;\r\nIDataView testSet = dataSplit.TestSet;\r\n\r\nvar trainingPipeline = mlContext.Transforms.Text.FeaturizeText(""AudienceReview"")\r\n    .Append(mlContext.Transforms.Text.FeaturizeText(""CriticReview""))\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", new string[] { ""AudienceReview"", ""CriticReview"" }))\r\n    .Append(mlContext.Regression.Trainers.Sdca());\r\n\r\nvar trainedModel = trainingPipeline.Fit(trainData);\r\n\r\nvar pfi = mlContext.Regression.PermutationFeatureImportance(trainedModel.LastTransformer, trainedModel.Transform(testSet), permutationCount: 3);\r\n```\r\n\r\nI would expect the result of using PFI to contain metrics for two features, `AudienceReview` and `CriticReview`. Instead, I get 268 features.  I believe this is because it is taking the result of `FeaturizeText` and treating each element in the vector as a feature as opposed to the entire vector. Is that the intent?'"
441130850,3673,b'Restore trainer code from model.zip ',"b'How can I restore the code that was used to create `model.zip`? Is model archive is self-containing?\r\n\r\n### Use case:\r\nLet\'s say I have 10 models in production, created by few engineers. \r\nAfter some time (1 year) I find out that one model does not perform as good as it was before and I want to retrain it using the same algorithms but with more training data.\r\n\r\nShould I maintain all version of trainers (code & params) and their relationships with generated model files separately or I will be able to restore code in the future?\r\n\r\nSomething like\r\n```\r\nmlnet gen-proj ""model.zip"" --lang C#\r\n```   \r\n\r\n### Note\r\n\r\nAlso may be useful to have AutoML logs packed inside (optionally)\r\nIf model is trained and saved by Azure ML it may be useful to know how many minutes was spend on training and what models was tried...'"
441128194,3672,b'Perhaps show how to understand what class has what score',"b'One gets an set of scores only no documented way to map the value to class.  \n\nPerhaps add some samples like:\nvar predEngine = mlContext.Model.CreatePredictionEngine&lt;IrisData, IrisPrediction&gt;(trainedModel);\nVBuffer&lt;float&gt; keys = default;\npredEngine.OutputSchema[""PredictedLabel""].GetKeyValues(ref keys);\nvar labelsArray = keys.DenseValues().ToArray();\nfor (var i = 0; i &lt; keys.Length; i++)\n    Console.WriteLine($""key {labelsArray[i]} = {metrics.PerClassLogLoss[i]:P4}"");\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 3a185e45-64a6-62d0-14ce-98dcb476c011\n* Version Independent ID: 2e425649-9cc1-3aff-a82c-59b04ae34702\n* Content: [MulticlassClassificationMetrics.PerClassLogLoss Property (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.perclasslogloss?view=ml-dotnet#Microsoft_ML_Data_MulticlassClassificationMetrics_PerClassLogLoss)\n* Content Source: [dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
441106929,3671,b'The Metrics documentation does not help',"b'\r\n[Enter feedback here]\r\nHi,\r\n\r\nI feel that this level of documentation doesn\'t really help those that are reading it. It\'s okay that you provide the formulas of how you calculate the properties however 95% of those that would open help to read about it it will likely be more confused than helped.  One should document/ explain what a property means in relation to the accuracy of the model tested.\r\n\r\nLogLossReduction has one sentence that is confusing but helps \r\n\r\n> For example, if the RIG equals 20, it can be interpreted as ""the probability of a correct prediction is 20% better than random guessing.\r\n\r\nSo when executing the samples, I take the Iris clustering sample, it returns LogLossReduction of  0.9967811419606234, you and I know that this is 99.67% and not 0.99% however **RIG equals 20** is ambiguous and could be reworded as. \r\n\r\n> For example, if the LogLossReduction equals 0.20, it can be interpreted as ""the probability of a correct prediction is 20% better than random guessing.\r\n\r\n\r\nAlso, testing the metrics of N rows will not pass a ""confidence"" that a ""flip of a coin"" prediction is accurate, simply stating that a % of data must be used also doesn\'t help as 20% of 10 rows is not representative. \r\n\r\nIdeally one would also mention how the number can be influenced so that the users can understand how to improve the models accuracy, perhaps have links to [Feature Importance](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/explain-machine-learning-model-permutation-feature-importance-ml-net). \r\n\r\nIdeally those that give the framework a spin should be able to understand the results generated model as well as how to improve it.\r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: db0c3c11-e826-253d-983d-bc64f22bb609\r\n* Version Independent ID: db553462-9f1c-789d-caf2-408edc18d7d1\r\n* Content: [MulticlassClassificationMetrics.LogLoss Property (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.logloss?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
440911538,3670,b'Shuffle input cursor reader failed with an exception',"b""### System information\r\n\r\n- **OS version/distro**: Mac OS Mojave 10.14.4 (18E226)\r\n- **.NET Version (eg., dotnet --info)**:  \r\n```\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.14\r\n OS Platform: Darwin\r\n RID:         osx.10.14-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/3.0.100-preview3-010431/\r\n\r\nHost (useful for support):\r\n  Version: 3.0.0-preview5-27606-03\r\n  Commit:  39eb528ff8\r\n\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI'm loading my dataset using the 'CsvLoad' in the following way: [CsvFile.Load](https://github.com/samueleresca/LyricsClassifier/blob/76143426e515be5a5cb6808cb4fa599325b9ddd2/LyricsClassifier/Program.fs#L143)\r\n\r\nThe data pass through the following features engineering process:  [dataProcessPipeline](https://github.com/samueleresca/LyricsClassifier/blob/76143426e515be5a5cb6808cb4fa599325b9ddd2/LyricsClassifier/Program.fs#L69)\r\n\r\nThe runtime throws an exception at the [Fit step](https://github.com/samueleresca/LyricsClassifier/blob/76143426e515be5a5cb6808cb4fa599325b9ddd2/LyricsClassifier/Program.fs#L110)\r\n\r\n- **What happened?**\r\nThe runtime throws the following exception:\r\n```\r\nUnhandled Exception: System.AggregateException: One or more errors occurred. (Shuffle input cursor reader failed with an exception) (Shuffle input cursor reader failed with an exception) ---> System.InvalidOperationException: Shuffle input cursor reader failed with an exception ---> System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.FormatException: Input string was not in a correct format.\r\n   at System.Number.StringToNumber(ReadOnlySpan`1 str, NumberStyles options, NumberBuffer& number, NumberFormatInfo info, Boolean parseDecimal)\r\n   at System.Number.ParseInt32(ReadOnlySpan`1 s, NumberStyles style, NumberFormatInfo info)\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nThe runtime throws a `System.FormatException`, but Is not clear which specific input refers.\r\n\r\n### Source code / logs\r\n\r\n[LyricsClassifier/LyricsClassifier/Program.fs](https://github.com/samueleresca/LyricsClassifier/blob/76143426e515be5a5cb6808cb4fa599325b9ddd2/LyricsClassifier/Program.fs)"""
440899720,3669,b'Powershell Integration - getting errors',"b'### System information\r\n\r\n- **Windows 10, Linux (Ubuntu)**:\r\n- **netstandard2, core 2**:\r\n- **ML version 1.0.0-preview**:\r\n\r\n### Issue\r\n\r\nI\'m trying to integrate ML.NET with powershell. I\'m using [Sentiment Analysis sample](https://github.com/dotnet/samples/tree/master/machine-learning/tutorials/SentimentAnalysis) for testing. Sample code runs just fine as a console app, but throws errors if executed as Powershell Cmdlet. It doesn\'t matter if it\'s binary cmdlet  (C#, using same exact code as console app) or pure PS. It doesn\'t work even if I save sample as a class library (and calling static methods via PS).\r\n\r\n- **Shuffle input cursor reader failed with an exception**\r\nIf disabling shuffling, getting this:\r\n- **Splitter/consolidator worker encountered exception while consuming source data**\r\n\r\nThis happens when calling fit method after trainer is added to the pipeline (I can call fit on estimator with no error). I tried Log regression and Fast Tree trainers (getting same errors)\r\n\r\nNot sure if there is any fundamental blocker, but I think it would be extremely useful to get it work with PowerShell \r\n\r\n### Source code / logs\r\n\r\n```PowerShell\r\n\r\n<# Downloading assemblies and data set\r\n\r\n# download nuget if needed\r\n# iwr ""https://dist.nuget.org/win-x86-commandline/latest/nuget.exe"" -OutFile ""nuget.exe""\r\n\r\nnuget install Microsoft.ML -version 1.0.0-preview\r\n\r\nmkdir bin\r\n\r\ngci ""*\\lib\\netstandard*\\*.dll"" | copy-item -Destination "".\\bin""\r\n\r\n$url = ""https://raw.githubusercontent.com/lucasalexander/mlnet-samples/master/sentiment-analysis/data/yelp_labelled.txt""\r\nInvoke-WebRequest -Uri $url -OutFile ""yelp_labelled.txt""\r\n\r\n#>\r\n\r\n\r\nAdd-Type -Path ""$pwd\\bin\\*.dll"" \r\n\r\n\r\n$dataPath = ""$pwd\\yelp_labelled.txt""\r\n\r\n$mlCOntext = [Microsoft.ML.MLContext]::new()\r\n\r\n$columns = [System.Collections.Generic.List``1[Microsoft.ML.Data.TextLoader+Column]]::new()\r\n\r\n$columns.Add([Microsoft.ML.Data.TextLoader+Column]::new(""SentimentText"", ""String"", 0))\r\n$columns.Add([Microsoft.ML.Data.TextLoader+Column]::new(""Label"", ""Boolean"", 1))\r\n\r\n$columns.Add([Microsoft.ML.Data.TextLoader+Column]::new(""PredictedLabel"", ""Boolean"", 2))\r\n$columns.Add([Microsoft.ML.Data.TextLoader+Column]::new(""Probability"", ""Single"", 3))\r\n$columns.Add([Microsoft.ML.Data.TextLoader+Column]::new(""Score"", ""Single"", 4))\r\n\r\n$opt = [Microsoft.ML.Data.TextLoader+Options]::new()\r\n$opt.Separators = ""`t""\r\n$opt.Columns = $columns\r\n$opt.HasHeader = $false\r\n\r\n\r\n$dataView = [Microsoft.ML.TextLoaderSaverCatalog]::LoadFromTextFile($mlCOntext.Data, $dataPath, $opt)\r\n\r\n# preview data\r\n# [Microsoft.ML.DebuggerExtensions]::Preview($dataView).rowview | foreach { $_.Values.Value -join "" | "" }\r\n\r\n\r\n$splitDataView =  $mlCOntext.Data.TrainTestSplit($dataView, 0.2)\r\n$trainSet = $splitDataView.TrainSet\r\n$testSet = $splitDataView.TestSet\r\n\r\n\r\n$estimator = [Microsoft.ML.TextCatalog]::FeaturizeText($mlCOntext.Transforms.Text, ""Features"", ""SentimentText"")\r\n\r\n\r\n$optTrain = [Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer+Options]::new()\r\n$optTrain.FeatureColumnName = ""Features""\r\n$optTrain.LabelColumnName = ""Label""\r\n\r\n\r\n# this will avoid \'Shuffle input cursor\' error, but raise \'Splitter/consolidator\' error\r\n$optTrain.Shuffle = $false  \r\n\r\n$trainer = [Microsoft.ML.StandardTrainersCatalog]::SdcaLogisticRegression($mlCOntext.BinaryClassification.Trainers, $optTrain)\r\n\r\n<# fast tree trainer, but getting Splitter/consolidator error again\r\n$topt = [Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer+Options]::new()\r\n$topt.FeatureColumnName = ""Features""\r\n$topt.LabelColumnName = ""Label""\r\n$trainer = [Microsoft.ML.TreeExtensions]::FastTree($mlCOntext.BinaryClassification.Trainers, $topt)\r\n#>\r\n\r\n\r\n$pipe = [Microsoft.ML.LearningPipelineExtensions]::Append($estimator, $trainer, ""Everything"")\r\n\r\n\r\n$model = $pipe.Fit($trainSet)  # ERROR OCCURS HERE !!!\r\n\r\n# if apply fit on estimator no error will occur and predict/evaluate block will work (with some dummy results)\r\n\r\n# $model = $estimator.Fit($splitDataView.TrainSet)\r\n\r\n$predict = $model.Transform($TestSet)\r\n\r\n$mlCOntext.BinaryClassification.Evaluate($predict, ""Label"")\r\n```\r\n'"
440808269,3666,b'Official build failure due to the API Compat tool PR',b'PR #3623 breaks the official tool.\r\n\r\n![image](https://user-images.githubusercontent.com/11949572/57243531-393ff000-6feb-11e9-8b29-8f2e29d9beb0.png)\r\n'
440557595,3665,b'Pipeline Lazy loading csv files looks to be not all that lazy and loading vectors still gives issues',"b'### System information\r\n\r\n- **OS version/distro**: Server 2019, 3TB Ram\r\n- **.NET Version (eg., dotnet --info)**:  Core 3.0, ML.Net 1.0.0.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nGenerated data for training model based on 12 monthly training files as CSV (6TB).\r\nGenerate data for training CSV model based on 1 year data input then save it a binary file (604GB). I can\'t work with loading all fields in a single vector as the vector starts at position 1 and not position 0. If I would have the trained lable at the end of the CSV column then perhaps, at the moment I get a runtime error stating that the trained model has 1 more column than the provided vector of 40730 fields.  \r\n\r\n- **What happened?**\r\nThe training the CSV file takes 99.99% of available ram on the PC, the binary file does no such thing. The issue with the vector definition in the csv file seems to be still an issue.\r\n\r\n- **What did you expect?**\r\nAs the documentation states it does lazy loading I\'d expect it to not take all memory and loading all fields as a vector, train and predict still doesn\'t work.\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar options =new LightGbmMulticlassTrainer.Options {\r\n                  LabelColumnName   = KeyColumn,\r\n                  FeatureColumnName = Features,\r\n                  Silent= false,\r\n                  Verbose=true,\r\n                  NumberOfThreads=8\r\n              };\r\n\r\n\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n              .Append(MLContext.Transforms.Concatenate(Features, Mapper.GetFieldNames()))\r\n              .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))                          \r\n              .Append(mlContext.Transforms.CopyColumns(inputColumnName: KeyColumn, outputColumnName: nameof(PredictedResult.PredictedLabelIndex)))\r\n     \r\n```\r\nLoading this class will cause the trained model to fail accepting the features. not sure if it includes the label in the training, not sure if the error is due to the column count.\r\n```\r\npublic static IDataView GetDataViewAsVector(MLContext mlContext, FileInfo trainingFile, long? maxRows = null, bool asBinary=false)\r\n{\r\n    var loader = mlContext.Data.CreateTextLoader(options: new TextLoader.Options()\r\n    {\r\n        Columns = new[] {\r\n       new TextLoader.Column(name:""Label"", dataKind: DataKind.String, index: 0),\r\n       new TextLoader.Column(name:""Features"",dataKind:DataKind.Single,minIndex:1,maxIndex:40731),\r\n    },\r\n        HasHeader = false,\r\n        Separators = new[] { \'|\' },\r\n        UseThreads = true,\r\n    });\r\n    var dv = loader.Load(trainingFile.FullName);\r\n     if (asBinary)\r\n     {\r\n         using(var fs= new FileStream(path:trainingFile.FullName.Replace("".csv"","".bin""),mode:FileMode.CreateNew))\r\n             mlContext.Data.SaveAsBinary(dv,fs);\r\n     }\r\n    return dv;\r\n}\r\n\r\n\r\npublic class DataBase\r\n    {\r\n        [LoadColumn(0)]     \r\n        public string Label { get; set; }\r\n\r\n         //error in column definition\r\n        [LoadColumn(1,40731),VectorType(40730)]  \r\n        public float[] Features { get; set; }\r\n\r\n        public DataBase()\r\n        {\r\n            Features = new float[220];\r\n        }\r\n    }\r\n```\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
440489493,3664,b'How can I use FaceNet Tensorflow model with ML.Net?',"b'I studied the sample code to use TensorFlow model to classsify image. Now I am trying to use FaceNet model created at https://github.com/davidsandberg/facenet, but I am not clear on how to proceed.\r\n\r\nAny suggestions?'"
440215004,3663,b'[Extensions.ML] AddPredictionEnginePool should support models as embedded resources',"b""Today AddPredictionEnginePool supports `FromFile` and `FromUri`. Another scenario is to add the ML model as an embedded resource in a project, so you don't have to worry about copying and finding a file - it will always be in the code assembly. Or potentially you may have different models for different languages, and you can replace the resource depending on the current culture.\r\n\r\nWe should add suport for embedded resource files to Extensions.ML."""
440034105,3661,b'Better docs/samples for Data.SaveAsText & Data.SaveAsBinary',"b'I do classification of MS Office document, in my case `feature generation` is relatively slow process, that why I want to do in once and save my data set to file like `data.tsv` and then experiment with different models and parameters.\r\n\r\nLet\'s say we I defined model class\r\n```csharp\r\nprivate class IrisInputAllFeatures\r\n{\r\n    [ColumnName(""Label""), LoadColumn(4)]\r\n    public string IgnoredLabel { get; set; }\r\n\r\n    [LoadColumn(0, 3)]\r\n    public float Features { get; set; }\r\n}\r\n```\r\n\r\nthen I wrote the code that generate / export data\r\n\r\n```csharp\r\nvar dataSet = new [] {\r\n   new IrisInputAllFeatures() { ... },\r\n   new IrisInputAllFeatures() { ... } \r\n}\r\n```\r\n\r\nthe next thing that I expect is to be able to save all my data in file in format supported by `LoadFromTextFile` method (to be able reuse `IrisInputAllFeatures` class in both places),  like\r\n\r\n```csharp\r\nData.SaveToTextFile(""DataSet.tsv"", dataSet);\r\n```\r\n\r\nIs there a way to save data to the file based on `ColumnName`, `LoadColumn` attributes?'"
440031596,3660,b'No Wiki. Lack of documentation.',b'### System information\r\n\r\nany\r\n\r\n### Issue\r\n\r\nNo Wiki. \r\nLack of documentation.\r\n\r\n\r\n'
439943132,3659,b'LightGBM error when using UseCat with count Feature selection',"b""### Issue\r\n\r\nversion: 0.11\r\n\r\n- **What did you do?**\r\n1. I trained a LightGBM multi-class classifier with `UseCat` to `true`.\r\n1. I added a `SelectFeaturesBasedOnCount` on the final `Features`.\r\n\r\nIf it matters: I also use early stopping (does this prune some trees?).\r\n\r\n- **What happened?**\r\n\r\nI got an exception after training was done (successfully) and ML.NET tries to construct the `InternalRegressionTree`:\r\n```\r\nSystem.InvalidOperationException: 'Categorical split features is zero length'\r\n```\r\n\r\nStack\r\n```\r\n>\tMicrosoft.ML.Core.dll!Microsoft.ML.Contracts.Check(bool f, string msg) Line 491\tC#\r\n \tMicrosoft.ML.FastTree.dll!Microsoft.ML.Trainers.FastTree.InternalRegressionTree.CheckValid(System.Action<bool, string> checker) Line 471\tC#\r\n \tMicrosoft.ML.FastTree.dll!Microsoft.ML.Trainers.FastTree.InternalRegressionTree.InternalRegressionTree(int[] splitFeatures, double[] splitGain, double[] gainPValue, float[] rawThresholds, float[] defaultValueForMissing, int[] lteChild, int[] gtChild, double[] leafValues, int[][] categoricalSplitFeatures, bool[] categoricalSplit) Line 224\tC#\r\n \tMicrosoft.ML.FastTree.dll!Microsoft.ML.Trainers.FastTree.InternalRegressionTree.Create(int numLeaves, int[] splitFeatures, double[] splitGain, float[] rawThresholds, float[] defaultValueForMissing, int[] lteChild, int[] gtChild, double[] leafValues, int[][] categoricalSplitFeatures, bool[] categoricalSplit) Line 188\tC#\r\n \tMicrosoft.ML.LightGBM.dll!Microsoft.ML.LightGBM.Booster.GetModel(int[] categoricalFeatureBoudaries) Line 257\tC#\r\n \tMicrosoft.ML.LightGBM.dll!Microsoft.ML.LightGBM.LightGbmTrainerBase<Microsoft.ML.Data.VBuffer<float>, Microsoft.ML.Data.MulticlassPredictionTransformer<Microsoft.ML.Trainers.OvaModelParameters>, Microsoft.ML.Trainers.OvaModelParameters>.TrainCore(Microsoft.ML.IChannel ch, Microsoft.ML.IProgressChannel pch, Microsoft.ML.LightGBM.Dataset dtrain, Microsoft.ML.LightGBM.LightGbmTrainerBase<Microsoft.ML.Data.VBuffer<float>, Microsoft.ML.Data.MulticlassPredictionTransformer<Microsoft.ML.Trainers.OvaModelParameters>, Microsoft.ML.Trainers.OvaModelParameters>.CategoricalMetaData catMetaData, Microsoft.ML.LightGBM.Dataset dvalid) Line 375\tC#\r\n \tMicrosoft.ML.LightGBM.dll!Microsoft.ML.LightGBM.LightGbmTrainerBase<Microsoft.ML.Data.VBuffer<float>, Microsoft.ML.Data.MulticlassPredictionTransformer<Microsoft.ML.Trainers.OvaModelParameters>, Microsoft.ML.Trainers.OvaModelParameters>.TrainModelCore(Microsoft.ML.TrainContext context) Line 117\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Trainers.TrainerEstimatorBase<Microsoft.ML.Data.MulticlassPredictionTransformer<Microsoft.ML.Trainers.OvaModelParameters>, Microsoft.ML.Trainers.OvaModelParameters>.TrainTransformer(Microsoft.Data.DataView.IDataView trainSet, Microsoft.Data.DataView.IDataView validationSet, Microsoft.ML.IPredictor initPredictor) Line 148\tC#\r\n \tMlnEval.exe!ConsoleApp1.MlNetSpecific.MlNetLightGbmMultiClassTrainer.TrainAndEval(ConsoleApp1.Dev.AppState app) Line 107\tC#\r\n \tMlnEval.exe!ConsoleApp1.Program.Main(string[] args) Line 116\tC#\r\n\r\n```\r\n\r\nUnfortunately I failed to come up with a minimal reproducible example. Seems this requires a certain data setup.\r\n\r\n### Partial analysis\r\n\r\nIt looks like here:\r\nhttps://github.com/dotnet/machinelearning/blob/c5aab770622f1f56bddf8bbaf96f7798762c45ff/src/Microsoft.ML.LightGbm/WrappedLightGbmBooster.cs#L236-L251\r\n\r\n`cats` array is actually 0 length but `categoricalSplit[node]` is still set to true.\r\n\r\nwhich then later on will throw here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c5aab770622f1f56bddf8bbaf96f7798762c45ff/src/Microsoft.ML.FastTree/TreeEnsemble/InternalRegressionTree.cs#L465-L469\r\n"""
439789900,3654,b'Add AVX intrinsics implementation for Factorization Machine',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 version 1709\r\n- **.NET Version (eg., dotnet --info)**: 3.0.100-preview-010184\r\n\r\n### Issue\r\n\r\nI\'m trying to add C++ AVX intrinsics implementation for Factorization Machine and doing a dynamic dispatch from `FactorizationMachineInterface.cs`. I\'m using `Avx.IsSupported` to check for AVX support and then call the `CalculateGradientAndUpdateNativeAVX/SSE` function declared as an extern.\r\n\r\nThe build fails with the following error for netcoreapp3.0. Would appreciate your suggestions to fix this.\r\n\r\n![buildfail](https://user-images.githubusercontent.com/22417834/57106643-cd0b7680-6ce2-11e9-855a-3d763580a535.PNG)\r\n\r\n\r\n### Source code / logs\r\n\r\nHere is the Microsoft.ML.StandardTrainers.csproj snippet I\'m using:\r\n\r\n```\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n\r\n  <PropertyGroup>\r\n    <TargetFramework Condition=""\'$(UseIntrinsics)\' != \'true\'"">netstandard2.0</TargetFramework>\r\n    <TargetFrameworks Condition=""\'$(UseIntrinsics)\' == \'true\'"">netstandard2.0;netcoreapp3.0</TargetFrameworks>\r\n    <IncludeInPackage>Microsoft.ML</IncludeInPackage>\r\n    <AllowUnsafeBlocks>true</AllowUnsafeBlocks>\r\n    <LangVersion>7.3</LangVersion>\r\n    <DebugType>pdbonly</DebugType>\r\n  </PropertyGroup>\r\n\r\n  <ItemGroup>\r\n    <ProjectReference Include=""..\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj"" />\r\n    <ProjectReference Include=""..\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj"" />\r\n    <ProjectReference Include=""..\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj"" />\r\n  </ItemGroup>\r\n\r\n  <ItemGroup Condition=""\'$(TargetFramework)\' == \'netcoreapp3.0\'"">\r\n    <Compile Remove=""FactorizationMachine/FactorizationMachineInterface.netstandard.cs"" />\r\n    <PackageReference Include=""System.Runtime.CompilerServices.Unsafe"" Version=""4.5.2"" />\r\n  </ItemGroup>\r\n\r\n  <ItemGroup Condition=""\'$(TargetFramework)\' == \'netstandard2.0\'"">\r\n    <Compile Remove=""FactorizationMachine/FactorizationMachineInterface.netcoreapp.cs"" />\r\n    <PackageReference Include=""System.Memory"" Version=""$(SystemMemoryVersion)"" />\r\n  </ItemGroup>\r\n\r\n</Project>\r\n```\r\nFYI: \r\nThe build fails when targeting to netcoreapp3.0 even with no modifications to the source code. i.e. \r\n```<TargetFramework>netstandard2.0</TargetFramework>```\r\nto\r\n``` <TargetFrameworks>netstandard2.0;netcoreapp3.0</TargetFrameworks>```\r\n\r\n@glebuk @singlis '"
439716132,3650,b'Azure badges stopped working on Readme.md',"b""The azure badges links on the readme  seems to be broken.\r\n\r\nThe problem seem to be in the last ``` Configuration parameter``` because links are working if we remove the last query parameter.\r\n\r\neg https://dnceng.visualstudio.com/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobname=Ubuntu_x64_Netcoreapp21\r\n\r\ngives the correct output but \r\nhttps://dnceng.visualstudio.com/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=master&jobname=Ubuntu_x64_Netcoreapp21&configuration=Debug_Build\r\n\r\ndoesnt give the desired output.\r\n\r\n\r\nThey were working earlier and there hasn't been any change in the .yml files or readme during that time.\r\n\r\n\r\n@safern @chcosta @eerhardt any suggestions on what could be the problem here ?\r\n\r\ncc @shauheen """
439552334,3648,b'Softmax implementation in OneVersusAllModelParameters returns NaN even for scores of ~90.0f',"b""version: 0.11\r\n\r\nThis implementation:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.StandardTrainers/Standard/MulticlassClassification/OneVersusAllTrainer.cs#L741-L752\r\n\r\nwill result in `NaN` as the output even for moderate scores of around 90f:\r\n\r\n```C#\r\n      var foo = new[] { 90f, 2, -2f };\r\n      NormalizeSoftmax(foo, 3);\r\n```\r\n\r\nSeen very easily in the debugger (the float cast will result in `Inf`). I'm getting back a score of roughly 102 for some of my data sets and models. Though they're extremely rare."""
439545569,3647,b'LightGBM Save/Load round trip loses Softmax OneVersusAllModelParameters',"b'version: 0.11\r\n\r\nRelated: #1424\r\n\r\nWhen training a softmax Multi classifier with LightGBM a save/load will lose the softmax it seems:\r\n\r\nAlso inspecting the model we can see it doesn\'t use `ImplSoftmax` but `ImplRaw`.\r\n\r\nReproduce:\r\n\r\n```C#\r\n    public class GenericSample\r\n    {\r\n      public string A { get; set; }\r\n      public string Label { get; set; }\r\n    }\r\n    public static void ReproduceLightGbmPersistanceBug()\r\n    {\r\n      var data = Enumerable.Range(1, 100).Select(x => new GenericSample { A = $""{x % 20}"", Label = $""{x % 10}"" });\r\n      var ctx = new MLContext();\r\n\r\n      var options = new Options {\r\n        UseSoftmax = true,\r\n      };\r\n      var pipe = ctx.Transforms.Categorical.OneHotEncoding(""A"")\r\n        .Append(ctx.Transforms.Concatenate(""Features"", ""A""))\r\n        .Append(ctx.Transforms.Conversion.MapValueToKey(""Label""))\r\n        .Append(ctx.MulticlassClassification.Trainers.LightGbm(options));\r\n      var dataView = ctx.Data.LoadFromEnumerable(data);\r\n      ITransformer model = pipe.Fit(dataView);\r\n      var scores = model.Transform(dataView).GetColumn<float[]>(ctx,""Score"");\r\n\r\n      Console.WriteLine($""Min: {scores.Select(x => x.Min()).Min()}"");\r\n      Console.WriteLine($""Max: {scores.Select(x => x.Max()).Max()}"");\r\n\r\n      var memoryStream = new MemoryStream();\r\n      ctx.Model.Save(model, memoryStream);\r\n      model = ctx.Model.Load(memoryStream);\r\n\r\n      scores = model.Transform(dataView).GetColumn<float[]>(ctx,""Score"");\r\n      Console.WriteLine($""Min: {scores.Select(x => x.Min()).Min()}"");\r\n      Console.WriteLine($""Max: {scores.Select(x => x.Max()).Max()}"");\r\n    }\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nMin: 0.001027671\r\nMax: 0.9907509\r\nMin: -4.843706\r\nMax: 2.027462\r\n```'"
439528223,3646,b'Score Range',"b'Hi,  '"
439279497,3638,b'Download files only if they are not present on disk.',b'In addition to wastage of network and other computing resources this also causes issues when an a Bitmap object is holding a write lock on an image and download tries to overwrite that image and results in file in use exception.'
439002892,3631,b'Image transformers such as Resize and Pixel extractor should print warning message when converting unsupported pixel type to supported pixel type.',"b'Often images contain pixel formats that is not supported by the transformers. Instead of throwing exceptions we currently convert them to supported types. It would be nice if we also printed a warning line in logs that indicated the name of the image, its current pixel format and the new pixel format the code is converting to.'"
439001996,3630,b'ImageLoader loader transform should not hold the lock on image',"b'Currently ImageLoader transformer holds the lock on the image by opening it using Bitmap(string filepath) and this causes bitmap class to take a lock that prevents writing to image location since Bitmap class also has a Save function. We can instead open the image using Bitmap(stream) and create stream in Read only mode. Since bitmap class expects us to keep the stream open until the lifetime of the bitmap class so we will first create a file stream, copy the contents over to in memory and pass the reference to in memory stream to the bitmap class. Whenever bitmap object is disposed GC will clean up the in memory image data. This is of course not a great solution as it will increase GC pressure but this is the best we can do given the limitations of bitmap class. This will prevent ML.NET code creating a lock over the input image files because there is no good reason to do that and instead it creates issues if another process wants to rewrite to that image location.'"
438994675,3627,"b'Consider removing references to ""needCol"" and explaining what ""rand"" is in GetRowCursor'","b""I realize this is still in preview, but I'm just putting a note here since I just spent an hour or so referring to this. Feel free to ignore if this is too early\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: cebd0074-01d3-d048-305a-cfea8b4083de\n* Version Independent ID: 7f1aaf72-e345-e334-6237-d92abd3aa6d3\n* Content: [IDataView Interface (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/IDataView.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/IDataView.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**"""
438989732,3626,"b""ML.FastTree nuget package doesn't work with packages.config""","b""Try using Microsoft.ML.FastTree on .NET Framework using `packages.config`.\r\n\r\nYou get an exception:\r\n\r\n```\r\nUnhandled Exception: System.AggregateException: One or more errors occurred. ---> System.DllNotFoundException: Unable to load DLL 'FastTreeNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Trainers.FastTree.DenseIntArray.C_Sumup_double(Int32 numBits, Byte* pData, Int32* pIndices, Double* pSampleOutputs, Double* pSampleOutputWeights, Double* pSumTargetsByBin, Double* pSumTargets2ByBin, Int32* pCountByBin, Int32 totalCount, Double totalSampleOutputs, Double totalSampleOutputWeights)\r\n   at Microsoft.ML.Trainers.FastTree.DenseIntArray.SumupCPlusPlusDense(SumupInputData input, FeatureHistogram histogram, Byte* data, Int32 numBits)\r\n   at Microsoft.ML.Trainers.FastTree.Dense8BitIntArray.Sumup(SumupInputData input, FeatureHistogram histogram)\r\n   at Microsoft.ML.Trainers.FastTree.FeatureHistogram.SumupWeighted(Int32 numDocsInLeaf, Double sumTargets, Double sumWeights, Double[] outputs, Double[] weights, Int32[] docIndices)\r\n```\r\n\r\nThis is because we aren't copying the `FastTreeNative.dll` to the output folder.\r\n\r\nWe should be including https://github.com/dotnet/machinelearning/blob/master/pkg/common/CommonPackage.props in the nuget package, and this would start working.\r\n\r\n@shauheen @glebuk @TomFinley """
438459351,3615,"b""LightGmb exception  with an error code -1 and an error message of 'bad allocation'.""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 64 bit\r\n- **.NET Version (eg., dotnet --info)**: .net core 3.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated a file with a label and a vector and trained against it.\r\n- **What happened?**\r\nGet an exception  with an error code -1 and an error message of \'bad allocation\'.\r\nI can\'t find the error code in the source code so not sure what causes it. it happens after it releases about 30gb of memory. looks like right on \r\n29.04.2019 20:20:01: [Source=**LightGBMMulticlass; Loading data for LightGBM**, Kind=Trace] Channel finished. Elapsed 01:52:28.7166971.\r\n\r\n- **What did you expect?**\r\nI\'d expect this to work as it works with a smaller file.\r\n\r\n[Crash.txt](https://github.com/dotnet/machinelearning/files/3128797/Crash.txt)\r\n\r\n\r\n### Source code / logs\r\nLoading the data\r\n```\r\n public static IDataView GetDataViewAsVector(MLContext mlContext, FileInfo trainingFile, long? maxRows = null)\r\n        {\r\n            var loader = mlContext.Data.CreateTextLoader(options: new TextLoader.Options()\r\n            {\r\n                Columns = new[] {\r\n                    new TextLoader.Column(name:""Label"", dataKind: DataKind.String, index: 0),\r\n                    new TextLoader.Column(name:""Features"",dataKind:DataKind.Single,minIndex:1,maxIndex:40731)\r\n                },\r\n                HasHeader = false,\r\n                Separators = new[] { \'|\' },\r\n                UseThreads = true,\r\n                MaxRows=maxRows\r\n            });\r\n            var dv = loader.Load(trainingFile.FullName);\r\n            return dv;\r\n        }\r\n```\r\nMaking the model\r\n```\r\nvar dataView = DataViewUtils.GetDataViewAsVector(mlContext, trainingFile, null);\r\ndataset = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.1);\r\n\r\nvar start = DateTime.Now;\r\n(long? training, long? validating) = ((dataset.TrainSet.GetColumn<string>(Label).LongCount(), dataset.TestSet.GetColumn<string>(Label).LongCount()));\r\n\r\nthis.OnUpdate?.Invoke($""Start training LightGBM on {training.Value:N0} rows of data"");\r\nthis.OnUpdate?.Invoke($""Testing LightGBM wil be on {validating.Value:N0} rows of data"");        \r\n\r\nvar options =new LightGbmMulticlassTrainer.Options {\r\n                    LabelColumnName   = KeyColumn,\r\n                    FeatureColumnName = Features,\r\n                    Silent= false,\r\n                    Verbose=true,\r\n                    NumberOfThreads=8\r\n                };\r\n\r\n\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n                // .Append(mlContext.Transforms.Concatenate(outputColumnName: Features, inputColumnNames: Mapper.GetFieldNames()))\r\n                .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))                          \r\n                .Append(mlContext.Transforms.CopyColumns(inputColumnName: KeyColumn, outputColumnName: nameof(PredictedResult.PredictedLabelIndex)))                         \r\n                ;\r\n           \r\n// Train the model.\r\nvar model = pipeline.Fit(dataset.TrainSet);\r\n```'"
437895394,3611,b'Resize image transformer cannot handle images with unknown pixel format.',"b'This results in an exception thrown by Resize transform and the entire pipeline is cancelled and user training stops. Ideally there should be a way to continue training on error, where by, we ignore the row that has an invalid data.\r\n\r\nAlternatively, when resizing an image with unknown pixel format we can create the resized image with known pixel format such as Format32bppArgb, the same way we handled Index Pixel Format image in #3601 '"
437751619,3604,b'Ensure that we warn in the documentation that models should be treated as code from security point of view',b'Issue:\r\nRunning ML.NET models from untrusted sources can be a security issue as there is a potential that they might lead to arbitrary code execution.\r\nEnsure that in topical help we mention that models should be treated as code from the security point of view.'
437612289,3603,b'How to append estimator after a LightGBM trainer with early stopping',"b'Version: 0.11\r\n\r\nWhen using early stopping (which is fantastic) with LightGBM you have to use:\r\n\r\n```C#\r\nvar trainer = ctx.MulticlassClassification.Trainers.LightGbm(options);\r\nvar model = trainer.Fit(trainEncodedDv, testEncodedDv);\r\n```\r\n\r\nHowever, I need to append other estimators after the trainer. Like:\r\n\r\n```C#\r\ntrainer = trainer.Append(ctx.Transforms.Conversion.MapKeyToValue(DefaultColumnNames.PredictedLabel))\r\n  .Append(ctx.Transforms.Conversion.MapKeyToValue((nameof(MlNetPrediction.OriginalLabelData), DefaultColumnNames.Label)));\r\n```\r\n\r\nWhich of course I cannot do since then I cannot call the *two*-arity `fit` method anymore.\r\n\r\nHow can I solve this issue?\r\n\r\nBtw: I think early stopping is absolutely crucial for any machine learning and IMO all iterative algorithms should support it.'"
437526444,3602,b'Need to add API breaking change definition and enforce it',b'With version `1.0.0` release we need to formally adopt the API breaking change definitions similar to [CoreFx](https://github.com/dotnet/corefx/blob/master/Documentation/coding-guidelines/breaking-change-definitions.md) and [here](https://github.com/dotnet/corefx/blob/master/Documentation/coding-guidelines/breaking-changes.md). We also need to add a test to run [APICompat](https://github.com/dotnet/arcade/tree/master/src/Microsoft.DotNet.ApiCompat) tool to enforce these rules. @eerhardt @TomFinley @glebuk '
437457751,3600,b'Image Resize Transform does not handle Indexed Pixel Format images correctly.',"b'It tries to Graphics.DrawImage when resizing images that are of Indexed Pixel Format as evident from the below code. This will throw an exception ""A Graphics object cannot be created from an image that has an indexed pixel format."" This bug seems to affects images converted to `.gif` format as well.\r\n\r\n```csharp\r\ndst = new Bitmap(info.ImageWidth, info.ImageHeight, src.PixelFormat);\r\n\r\nvar srcRectangle = new Rectangle(sourceX, sourceY, sourceWidth, sourceHeight);\r\nvar destRectangle = new Rectangle(destX, destY, destWidth, destHeight);\r\nusing (var g = Graphics.FromImage(dst))\r\n {\r\n    g.DrawImage(src, destRectangle, srcRectangle, GraphicsUnit.Pixel);\r\n|\r\n                        \r\n```\r\n\r\nInstead of Indexed Pixel Format the images should be resized in the below manner:\r\n\r\n```csharp\r\nif (src.PixelFormat == PixelFormat.Format1bppIndexed ||\r\n    src.PixelFormat == PixelFormat.Format4bppIndexed ||\r\n    src.PixelFormat == PixelFormat.Format8bppIndexed)\r\n {\r\n   dst = new Bitmap(info.ImageWidth, info.ImageHeight);\r\n}\r\nelse\r\n   dst = new Bitmap(info.ImageWidth, info.ImageHeight, src.PixelFormat);\r\n\r\nvar srcRectangle = new Rectangle(sourceX, sourceY, sourceWidth, sourceHeight);\r\nvar destRectangle = new Rectangle(destX, destY, destWidth, destHeight);\r\nusing (var g = Graphics.FromImage(dst))\r\n{\r\n    g.DrawImage(src, destRectangle, srcRectangle, GraphicsUnit.Pixel);\r\n}\r\n```\r\nTo read more refer to https://stackoverflow.com/questions/17313285/graphics-on-indexed-image and specifically the last answer is the most accurate.\r\n'"
437431622,3596,b'Ensure samples auto-generated .cs files are in-sync with .tt files',"b""For trainers' samples, we're using T4 templates to reduce boilerplate code. This creates a problem when devs directly modify the autogenerated .cs files, which will make the .tt and .cs files out of sync. We need a way to check that auto-generated .cs files don't have any manual changes.\r\n\r\n"""
437418219,3589,b'Change baseline tests to use the new NumberParseOption.UseSingle',"b""A lot of our tests use baseline files that have serialized numbers in them. We've had a lot of issues in the past comparing these baselines files because of minor changes in how floating point values are written to the output file (sometimes changes in which .NET we are running on, or Windows vs. Linux, etc. cause the values to slightly change).\r\n\r\nOne cause of these issues is because we are writing `float` (32-bit floating points) to the file, but when we are parsing the values, we are using `double` (64-bit floating points).\r\n\r\nAt times, we've decreased the `digitsOfPrecision` low enough to tolerate these differences. However, there are cases where `digitsOfPrecision` isn't enough, specifically when we have large values that differ by a digit in the exponential form, for example:\r\n\r\n```\r\n3.40282347E+38\r\n```\r\nvs\r\n```\r\n3.4028235E+38\r\n```\r\n\r\nTo solve this issue, I've added a new option - to parse the numbers using `float.Parse` instead of `double.Parse`.\r\n\r\nSee the solution added in https://github.com/dotnet/machinelearning/pull/3532.\r\n\r\nWe should go through the tests where we use a lowered `digitsOfPrecision`, and see if using `float.Parse` fixes the test on all platforms. This may allow us to remove the `digitsOfPrecision` parameter altogether if all these places can be converted to `UseSingle`.\r\n\r\ncc @tannergooding """
437411327,3587,"b""Fast Tree Nuget 1.0.0-preview doesn't set PackageReference""","b'### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**:  Dot Net 4.7.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Added Fast Tree NUGET\r\n- **What happened?** DLL Not Found Error On Execute\r\n- **What did you expect?** No DLL Not Found Error\r\n\r\n### Source code / logs\r\n\r\nTo use Fast Tree you must manually add `<PackageReference Include=""Microsoft.ML.FastTree"" Version=""1.0.0-preview"" />` to the project file otherwise it won\'t copy the fast tree dll to the output folder.'"
437321774,3584,b'Delete SamplsUtils project',"b'We stopped using SamplesUtils, as discussed in #2979. So SamplesUtils is unused code and can be removed.'"
437156886,3582,b'Realtime image classification using pretrained onnx model',"b'i am using this sample https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ObjectDetection_Onnx, but its loading images from folder , is there way/api to load image directly from memory and apply preprocess transformation? '"
436940478,3573,b'The Binary and Multiclass samples should print the confusion matrix together with the other metrics',b'The Binary and Multiclass samples should print the confusion matrix together with the other metrics\r\n'
436473924,3562,b'Making a prediction from ONNX model in ML.net',"b""### System information\r\n\r\n- **OS version: window 10\r\n- Ml.Net verison: 0.11\r\n\r\n### Issue\r\nHi, everyone. I am a newbie of using ML.net to implement my classification problem. I already trained a model from CIFA 10 datasets based on Keras library and that model has been transferred to ONNX model. My goal is to display the image's prediction task on WindowForm, so I am going to use ML.net integrated with ONNX model, but right now I am getting stuck on how to use the ONNX model on ML.net and how to define the label and get the prediction result by the model. Do you have any suggestion to me? Thank you a lot in advance.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
436416855,3556,b'FastTree and LightGbm base class is specific to Ranking',"b'The only training task that requires a `RowGroupColumn` is ranking. However, the base class of FastTree, FastForest and LightGbm requires it:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs#L176\r\n\r\nThe same is true for the options classes in FastTree, FastForest and LightGbm:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/Training/TrainerInputBase.cs#L98-L111\r\n\r\nWe should fix the class hierarchy so that the base classes become `TrainerEstimatorBase` instead of `TrainerEstimatorBaseWithGroupId` and `TrainerInputBaseWithWeight` instead of `TrainerInputBaseWithGroupId`. This is a breaking API change.\r\n\r\nThis related to #3365.'"
436373396,3547,b'Feature selection catalog xml doc should be fixed',b'Feature selection catalog does not mention the input output types in the extensions.\r\nThere is a missing Seealso reference in one of the estimators.'
436372430,3544,b'Fix the ApproximatedKernelMappingEstimator XML doc',b'The mathematical expression for the kernel functions is written in XML and the input and output types should be mentioned in the extension.'
436370804,3542,b'Fix the Onnx XML doc and the DNN featurizer XML doc',b'The xml doc can be improved. There are some comments that were meant to be code documentation rather than user facing documentation.\r\n\r\nThe documentation for an estimator is on the transformer.'
436369141,3540,b'Fix the XML documentation of GcNorm and LpNorm',b'It is missing the part of the template that mentions the estimator:  Create <estimator>.'
436323935,3531,"b""Prediction does not match score and is always en empty string while score gets filled. Like CopyColumns isn't working""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nCore 3.0, \r\n\r\n### Issue\r\nThe pipeline is mis configured somehow as it doesn\'t perform a CopyColumns eventhough I defined it.\r\n\r\n- **What did you do?**\r\nAdded following packages\r\n![Packages](https://user-images.githubusercontent.com/44400822/56603692-7c1fc200-6600-11e9-87fc-73eb15bb9832.PNG)\r\ninterestingly it does not directly contain Microsoft.ML 1.0.0-preview, nor can I add the package. the output directory however does contain it.\r\n\r\nI then used the following pipeline :\r\n```\r\n//create pipeline\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n        .Append(mlContext.Transforms.Concatenate(outputColumnName:RawFeatures,inputColumnNames: Mapper.GetFieldNames()))\r\n        .Append(mlContext.Transforms.Normalize(outputColumnName:Features,inputColumnName:RawFeatures,mode: NormalizingEstimator.NormalizationMode.MinMax))\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: KeyColumn, featureColumnName: Features))\r\n        .Append(mlContext.Transforms.Conversion.MapKeyToValue(inputColumnName: KeyColumn, outputColumnName: PredictedLabel))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName:KeyColumn, outputColumnName:""PredictedLabelIndex""))\r\n        .Append(mlContext.Transforms.CopyColumns(outputColumnName: Scores, inputColumnName: Score));\r\n\r\n\r\n// Train the model.\r\nvar model = pipeline.Fit(dataset.TrainSet);\r\n```\r\n- **What happened?**\r\nWhen I call \r\n`predictor.Predict(poco, ref prediction);`\r\nThe only value that get\'s populated with meaning full values when calling Predict is my Scores array of floats. \r\n\r\nThe PredictedLabelIndex always gets assigned 0 the `default` as well as the PredictedLabel who gets an empty string, again the default.\r\n\r\nIt\'s sets them just not with meaning full data..\r\n\r\n\r\n\r\n- **What did you expect?**\r\nI expect that the output columns get populated with the uint of KeyColum as well as the string label that is the class that was supposed to be predicted.\r\n\r\nAfter the training I call:\r\n```\r\nvar dataWithPredictions = model.Transform(dataset.TestSet);\r\nvar metrics = mlContext.MulticlassClassification.Evaluate(dataWithPredictions, KeyColumn, Scores);\r\n```\r\nand I get back:\r\n```\r\n{\r\n  ""LogLoss"": 0.5089806627554087,\r\n  ""LogLossReduction"": 0.06001707470227809,\r\n  ""MacroAccuracy"": 0.14749680832299408,\r\n  ""MicroAccuracy"": 0.8824768437255273,\r\n  ""TopKAccuracy"": 0.0,\r\n  ""TopKPredictionCount"": 0,\r\n  ""PerClassLogLoss"": [ 0.10911017602616903\r\n                                 , 6.4401884370896285\r\n                                , 3.159759951705061\r\n                                , 3.5237513486559044\r\n                                , 3.183197354861199\r\n                                , 3.5517723122073446\r\n                               , 6.775013273027178 ]\r\n}\r\n```\r\nI have 7 classes in the training file so that adds up\xe2\x80\xa6. \r\n\r\n### Source code / logs\r\nthe Log event doesn\'t get triggered on the MLContext when predicting so I can\'t add that.\r\nIt does however add different scores each time...\r\n\r\n```\r\n/*Data structure used for the prediction*/\r\nclass DataPrediction\r\n{    \r\n    public string PredictedLabel { get; set;}\r\n    public uint PredictedLabelIndex { get; set;}    \r\n    public float[] Scores { get; set;}\r\n}\r\n[sample input schema.txt](https://github.com/dotnet/machinelearning/files/3108984/sample.input.schema.txt)\r\n\r\n```\r\n\r\n[Training_log.txt](https://github.com/dotnet/machinelearning/files/3108988/Training_log.txt)\r\n'"
436319469,3529,b'Make Key types consistent.',b'It seems in transformers we have used [Key](link) type and in Trainers we have used [key](link) type. Make it consistent everywhere by using [Key](link) type everywhere. \r\n\r\nCC: @Ivanidzo4ka  @shmoradims @natke '
436259047,3527,b'Trainer documentation fixes',"b'**MatrixFactorizationTrainer** \r\n* [x] collaborative filtering needs to link to an explanation.\r\n* [x] key-typed should be ""key type"". \r\n* [ ] low-rank factor matrix needs a link. \r\n\r\n**OlsTrainer** \r\n* [x] ordinary least squares needs a link. \r\n\r\n**OnlineGradientDescentTrainer** \r\n* [x] Online Gradient Descent (OGD) needs a link. \r\n* [x] ""// This trainer is not numerically stable. Please see issue #2425. ""Should no appear twice in the example. \r\n\r\n**LinearSvm** \r\n* [x] Has no samples. \r\n* [x] Has no proper description of what it does. \r\n\r\n**LbfgsMaximumEntropyMulticlassTrainer** \r\n* [ ] errors in equations\r\n* [x] ""no reource"" typo\r\n\r\n**SdcaMaximumEntropyMulticlassTrainer** \r\n* [x] Scoring function has ill rendered equations.\r\n* [x] The SdcaMulticlassTrainerBase in the ""Training Algorithm Details"" has a broken link, that tries to search for an app in the store upon clicking. \r\n\r\n**SdcaMulticlassTrainerBase**\r\n* [x] equations are not properly rendered. '"
435924975,3519,"b""SdcaNonCalibratedBinaryTrainer: markdown isn't rendered properly""","b'The section title displays as ""### Training Algorithm Details"".'"
435921518,3518,"b'OVA, Pairwise Coupling, NaiveBayes xml fix'","b'Adhere to template, fixing typos, and adding more clarity.\r\n'"
435920393,3517,b'Time series documentation should follow transform template',b'As title.\r\n'
435916522,3515,b'PcaModelParameters class documentation',"b""PcaModelParameters class documentation doesn't follow the template for other model parameters classes, and contains remarks that are usually on the trainer class.\r\n\r\nAlso, the name of the class doesn't match its trainer's name: RandomizedPcaTrainer.\r\n\r\n_Originally posted by @yaeldekel in https://github.com/dotnet/machinelearning/issues/3512#issuecomment-485571762_"""
435914643,3514,b'KmeansTrainer sasys use itself to create itself',"b""A trainer should be created by its public API, not itself.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56535819-75fee800-6511-11e9-8515-a0c5e03b283b.png)\r\n\r\nThis trainer's documentation also has formatting problems such as missing space."""
435913463,3513,b'SDCA Regression Documentation Misses Type of Input Feature Vector',"b'I am not sure if we need to mention input feature type, vector of Single, in that document.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56535123-e6a50500-650f-11e9-8a8f-dbb9a632c1f6.png)\r\n'"
435911586,3512,b'OneVersusAllModelParameters class documentation',"b'Doesn\'t follow the template other model parameters classes use:\r\n""The model parameters class for <trainer name>"".\r\n\r\nThe OlsModelParameters class also doesn\'t follow this template.'"
435903740,3511,"b""Broken xref link when referencing trainer API in its option's document""",b'The xref to the second trainer API is not an actual link.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56533345-531e0500-650c-11e9-86c4-9f748b049828.png)\r\n'
435899784,3510,b'Documentation of ModelParametersBase<TOutput> class',"b'""A base class for predictors producing TOutput. Note: This provides essentially no value going forward. New predictors should just derive from the interfaces they need.""\r\n\r\nIf we are moving away from the word ""predictor"" we should remove it here. Also, I am not sure the ""note"" provides any value to the reader.\r\n'"
435896363,3509,b'Fixes for the DataCatalog ',"b'* [x] FilterRowsByKeyColumnFraction  example is too noisy, no need fr two columns, and especially such a busy one as the second. \r\n* [x] Example data chosen in FilterRowsByMissingValues  should be simplified as well. \r\n* [ ] ShuffleRows - shuffleSource needs better documentation. (Artidoro)'"
435893838,3508,b'LinearModelParameterStatistics class documentation issue',"b'The documentation says ""statistics for linear predictor"", should instead say ""statistics for linear model parameters"".'"
435886370,3507,"b""Inheritance of LbfgsLogisticRegressionBinaryTrainer.Options class doesn't have links""",b'Inheritance\r\nMicrosoft.ML.Trainers.LbfgsTrainerBase`3+OptionsBaseLbfgsLogisticRegressionBinaryTrainer.Options\r\n'
435885856,3506,b'OneHotHashIndicator has the parameter descriptions under outputColumnName',b'Not displaying the descriptions correctly.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.categoricalcatalog.onehothashencoding?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_CategoricalCatalog_OneHotHashEncoding_Microsoft_ML_TransformsCatalog_CategoricalTransforms_System_String_System_String_Microsoft_ML_Transforms_OneHotEncodingEstimator_OutputKind_System_Int32_System_UInt32_System_Boolean_System_Int32_'
435884283,3505,b'Bias term is usually missing in scoring rules of linear models',b'SymbolicSgdLogisticRegressionBinaryTrainer returns a linear model with bias but the bias term is not included in the scoring discussion shown below.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56528639-5f05c900-6504-11e9-8486-0eee911be59d.png)\r\n'
435880701,3503,b'SdcaNonCalibratedBinaryTrainer document has formatting error and is hard to read',"b'In addition to some formatting errors, all details are shown in a huge paragraph.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56527933-4812a700-6503-11e9-9449-a1b58dfe459f.png)\r\n'"
435880007,3502,b'LpNorm and GcNorm doc math equations',b'Math display error in the LpNormNormalizingEstimator:\r\n$y = \\frac{x - \\mu(x)}{L(x)}$\r\n\r\nAs well as in the GlobalContrastNormalizingEstimator.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.lpnormnormalizingestimator?view=ml-dotnet&branch=smoke-test-preview\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.globalcontrastnormalizingestimator?view=ml-dotnet&branch=smoke-test-preview\r\n'
435879802,3501,b'SdcaLogisticRegressionBinaryTrainer documentation is hard to read',"b""The discussion of algorithm and regularization are mixed into a big paragraph. It'd nicer to split them into different sections.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/56527695-e5211000-6502-11e9-99a2-4d42e039f14a.png)\r\n\r\n"""
435878744,3499,b'improve see also reference in documentation',"b'documentation in multiple pages has: ""See the See Also section"", which does not sound good. We should change that to perhaps: ""Check the see also""'"
435876145,3498,"b""AveragedPerceptronTrainer's output schema is not correct""","b'It should be\r\n```\r\n        private protected override SchemaShape.Column[] GetOutputColumnsCore(SchemaShape inputSchema)\r\n        {\r\n            return new[]\r\n            {\r\n                // REVIEW AP is currently not calibrating. Add the probability column after fixing the behavior.\r\n                new SchemaShape.Column(DefaultColumnNames.Score, SchemaShape.Column.VectorKind.Scalar, NumberDataViewType.Single, false, new SchemaShape(AnnotationUtils.GetTrainerOutputAnnotation())),\r\n                new SchemaShape.Column(DefaultColumnNames.PredictedLabel, SchemaShape.Column.VectorKind.Scalar, BooleanDataViewType.Instance, false, new SchemaShape(AnnotationUtils.GetTrainerOutputAnnotation()))\r\n            };\r\n        }\r\n```\r\nbut we accidentally added `Probability` at https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.averagedperceptrontrainer?view=ml-dotnet&branch=smoke-test-preview.'"
435866893,3496,b'Missing details in LinearSvmTrainer',b'There is only one short description for the mentioned trainer: `Linear SVM that implements PEGASOS for training. See: http://ttic.uchicago.edu/~shai/papers/ShalevSiSr07.pdf`. We should extend it to actually connect symbols in referenced paper and our implementation.'
435860752,3495,b'KMeansTrainer InitializationAlgorithm documentation is confusing',"b'From the ""Training Algorithm Details"" section in `KMeansTrainer` documentation, it seems that the difference between regular KMeans and KMeans++ is that the former uses random initialization of clusters, and the latter uses the Yinyang method. However, in the `Options` class there is an \'InitializationAlgorithm\' enum for the initialization algorithm that contains three members: \'KMeansPlusPlus\', \'KMeansYinYang\' and \'Random\'. So which is which?\r\n\r\nAlso, the fields in the in the `KMeansTrainer.InitializationAlgorithm` enum page are not in order.\r\n'"
435858457,3494,"b""KMeansTrainer documentation doesn't reference the extension methods that create it""","b'The remarks say ""To create this trainer, use KMeansTrainer"", with a link to the same page.\r\nIt should instead give two links to the two extension methods in `KMeansClusteringExtensions`.'"
435855203,3493,b'Warning on the KMeansModelParameters class page',"b'There is a warning message in the Examples section:\r\n\r\n""It looks like the sample you are looking for has moved! Rest assured we are working on resolving this.""\r\n'"
435852742,3492,"b""xref link in some Options classes isn't displayed correctly""","b'AveragedPerceptronTrainer.Options:\r\nOptions for the AveragedPerceptronTrainer as used in [AveragedPerceptron(Options)](xref:Microsoft.ML.StandardTrainersCatalog.AveragedPerceptron(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,Microsoft.ML.Trainers.AveragedPerceptronTrainer.Options)'"
435850447,3491,b'Fixes for the documentation of the TextCatalog ',"b'**TokenizeIntoCharactersAsKeys**:\r\n* [x] The description of TokenizingByCharactersEstimator should be corrected to:\r\n  ""Create a TokenizingByCharactersEstimator, which tokenizes **words** by splitting text into sequences of \r\n characters using a sliding window.""\r\n* [x] outputColumnName description should state that the outputs are Uints rather than keys? I think it might confuse the users that those are KeyDataViewTypes. Or should the name of this method be changed? @artidoro @Ivanidzo4ka @zeahmed ? \r\n  ""Name of the column resulting from the transformation of inputColumnName. This column\'s data type will be a variable-sized vector of **Uint**"".\r\n* [x] useMarkerCharacters needs a better description. \r\n\r\n**RemoveStopWords**\r\n* [x] inputColumnName,:\r\n  ""This estimator operates over **a** vector of text.\r\n\r\n**CustomStopWordsRemovingEstimator**\r\n* [x] Output column data type\r\n  ""Variable-sized vector of Text""\r\n   Replace Unknown-sized vector with Variable-sized vector. \r\n* [x] xref not resolving:\r\n  <xref:Microsoft.ML.Transforms.Text.CustomStopWordsRemovingTransformer/> \r\n\r\n**WordHashBagEstimator**\r\n* [x] Output column data type\r\n    **Known-size** vector of  of Single\r\n* [x] Replace metadata with annotations in the documentation references. \r\n\r\n**NgramHashingEstimator**\r\n* [x] broken <xref:Microsoft.ML.Transforms.Text.NgramHashingTransformer/> link. \r\n* [x] casing: ""in a way that **t**he former takes ""\r\n\r\n**NormalizeText** \r\n* [x] outputColumnName\r\n   ""This column\'s data type **is a** scalar of text or ""\r\n\r\nWordEmbeddingEstimator\r\n* [ ] Add links for Glove50D, dimensionality of the embedding model used. \r\n* [x] Re-phrasehere and everywhere: See the See Also section for links to **usage example**s.'"
435850229,3490,b'Issues with FieldAwareFactorizationMachineTrainer documentation',"b'The Latex is not being rendered correctly in the ""Scoring Function"" section.'"
435849323,3489,b'Issues with FeatureContributionCalculatingEstimator  documentation',"b""https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.featurecontributioncalculatingestimator?view=ml-dotnet&branch=smoke-test-preview\r\n\r\nWould be nice to have link to `FeatureContributionCalculatingTransformer ` somewhere.\r\n\r\n>Feature Contribution Calculation is currently supported for the following models:\r\n\r\nThey need to be links.\r\n\r\nI don't see clear difference in description for \r\n`CalculateFeatureContribution<TModelParameters,TCalibrator>(TransformsCatalog, ISingleFeaturePredictionTransformer<CalibratedModelParametersBase<TModelParameters,TCalibrator>>, Int32, Int32, Boolean)` and `CalculateFeatureContribution(TransformsCatalog, ISingleFeaturePredictionTransformer<ICalculateFeatureContribution>, Int32, Int32, Boolean)`\r\nWould be nice to write for first one what it's for calibrated models.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.isinglefeaturepredictiontransformer-1?view=ml-dotnet&branch=smoke-test-preview\r\n\r\n>The Microsoft.ML.IPredictor \r\n\r\nNeed to be updated."""
435844987,3488,b'MissingValueIndicator doc link error',b'The xref is not correct and does not render:\r\n\r\n> <xref:Microsoft.ML.Transfroms.MissingValueIndicatorTransformer/>\r\n'
435844506,3487,b'Issues with BootstrapSample documentation',"b""https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.bootstrapsample?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_DataOperationsCatalog_BootstrapSample_Microsoft_ML_IDataView_System_Nullable_System_Int32__System_Boolean_\r\n\r\n>Take an approximate bootstrap sample of input.\r\n\r\nThat's a really bad description of that it does.\r\n\r\n>IEnumerable<Microsoft.ML.SamplesUtils.DatasetUtils.BinaryLabelFloatFeatureVectorFloatWeightSample> enumerableOfData = Microsoft.ML.SamplesUtils.DatasetUtils.GenerateBinaryLabelFloatFeatureVectorFloatWeightSamples(5);\r\n\r\nWould be nice to replace SampleUtils with something in sample itself.\r\n\r\n>Whether this is the out-of-bag sample, that is, all those rows that are not selected by the transform. Can be used to create a complementary pair of samples by using the same seed.\r\n\r\nAm I only one who struggling with this description?\r\n"""
435842796,3486,b'Issues with CreateEnumerable',"b'https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.createenumerable?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_DataOperationsCatalog_CreateEnumerable__1_Microsoft_ML_IDataView_System_Boolean_System_Boolean_Microsoft_ML_Data_SchemaDefinition_\r\n\r\nSample need to be updated to work with defined classes, rather than working on top of unknown classes.'"
435842770,3485,b'All transform estimator documentation should point the user that the See Also section contains the example',"b'Make sure:\r\n\r\n""Check the See Also section for links to examples of the usage."" is in all transform estimator documentation. '"
435842622,3483,b'Custom mapping doc link bugs',"b'There is a broken reference link in custom mapping extension:\r\n\r\n> Microsoft.ML.Runtime.ComponentCatalog.RegisterAssembly(System.Reflection.Assembly,System.Boolean)\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.custommappingcatalog.custommapping?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_CustomMappingCatalog_CustomMapping__2_Microsoft_ML_TransformsCatalog_System_Action___0___1__System_String_Microsoft_ML_Data_SchemaDefinition_Microsoft_ML_Data_SchemaDefinition_\r\n\r\nAs well as in the estimator description:\r\n\r\n> <xref:Microsoft.ML.Transforms.CustomMappingTransformer>\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.custommappingestimator-2?view=ml-dotnet&branch=smoke-test-preview#estimator-characteristics'"
435842114,3482,b'Issues with LoadFromEnumerable documentation',"b""https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.loadfromenumerable?view=ml-dotnet&branch=smoke-test-preview\r\n\r\n>IEnumerable<DatasetUtils.SampleTemperatureData> enumerableOfData = DatasetUtils.GetSampleTemperatureData(5);\r\n\r\nWe should show how original class looks like. We should show what we can work on properties and fields. Which current sample is lacking. It's also doesn't show how to use `SchemaDefinition`\r\n\r\n>LoadFromEnumerable<TRow>(IEnumerable<TRow>, DataViewSchema)\r\n\r\nThat method lacks sample.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataviewschema.column.tostring?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_DataViewSchema_Column_ToString\r\n\r\nWould be nice to document.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.schemadefinition.create?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_Data_SchemaDefinition_Create_System_Type_Microsoft_ML_Data_SchemaDefinition_Direction_\r\n`SchemaDefinition` is quite lacking documentation.\r\n"""
435841586,3481,b'The transforms that are not part of the Microsoft.ML package need to state so in the documenation',"b'Similar to the trainers, the transforms that are not part of Microsoft.ML should suggest the package they are part of in the documentation of the estimator. '"
435841369,3480,b'IClassificationLoss implementations should be documented',"b'There are a few implementations of `IClassificationLoss`, most have them have little or no documentation. For example, the documentation of `ExpLoss` says:\r\nExponential Loss\r\n\r\n\r\n'"
435839746,3479,b'Incorrect link in ComputeLogisticRegressionStandardDeviation class documentation',"b'It recommends using the implementation in Microsoft.ML.Mkl.Components, but it links to the page of the abstract class `ComputeLogisticRegressionStandardDeviation`. '"
435834253,3478,b'Samples width: they need to be formatted at 85 characters or less.',b'Also add rule in VS settings file to throw error.\r\n\r\nCC: @natke @shmoradims '
435832764,3477,b'Input column type description for regression',"b""It mentions that it needs a `System.Single` label, but doesn't mention anything about the features."""
435832462,3476,b'Issues with KeyToVectorMappingEstimator ',"b'https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.keytovectormappingestimator?view=ml-dotnet&branch=smoke-test-preview\r\n\r\n>Input column data type | key\r\n\r\nI would prefer capital Key.\r\n\r\n>Estimator for KeyToVectorMappingTransformer. Converts the key types back to their original vectors.\r\n\r\nI don\'t think this is good description. It implies my original value was vector, which not always the true.\r\n\r\n>The input and output columns. The new column\'s data type is a vector of Single representing the original value.\r\n\r\nIt\'s not original value. \r\n\r\nin sample we have following:\r\n>mlContext.Transforms.Conversion.MapKeyToVector(""CategoryVector"", ""Category"", outputCountVector: true\r\nWhether to combine multiple indicator vectors into a single vector of counts instead of concatenating them. This is only relevant when the input column is a vector of keys.\r\n\r\nWhy we turn this option if it\'s pointless for single key which Category column contains?\r\n\r\n'"
435831367,3475,b'RandomizedPcaTrainer documentation states no normalization is required',"b""Shouldn't it be?"""
435829118,3474,b'fix paths in documentation',"b'# Incorrect sample path\r\n\r\nFile | Message | Fix\r\n-- | -- | --\r\ndotnet/api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/BinaryClassification/Calibrators/Isotonic.cs\' relative to \'api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/BinaryClassification/Calibrators/Naive.cs\' relative to \'api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/BinaryClassification/Calibrators/FixedPlatt.cs\' relative to \'api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/BinaryClassification/Calibrators/Platt.cs\' relative to \'api/Microsoft.ML.BinaryClassificationCatalog.CalibratorsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.NormalizingTransformer.AffineNormalizerModelParameters-1.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Normalizer.cs\' relative to \'api/Microsoft.ML.Transforms.NormalizingTransformer.AffineNormalizerModelParameters-1.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.NormalizingTransformer.CdfNormalizerModelParameters-1.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Normalizer.cs\' relative to \'api/Microsoft.ML.Transforms.NormalizingTransformer.CdfNormalizerModelParameters-1.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversions/MapKeyToBinaryVector.cs\' relative to \'api/Microsoft.ML.ConversionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsExtensionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversions/MapKeyToVectorMultiColumn.cs\' relative to \'api/Microsoft.ML.ConversionsExtensionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsExtensionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversions/MapKeyToVector.cs\' relative to \'api/Microsoft.ML.ConversionsExtensionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsExtensionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversion/MappValueIdvLookup.cs\' relative to \'api/Microsoft.ML.ConversionsExtensionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsExtensionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversion/MappValueToArray.cs\' relative to \'api/Microsoft.ML.ConversionsExtensionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ConversionsExtensionsCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversions/MapValueToKeyMultiColumn.cs\' relative to \'api/Microsoft.ML.ConversionsExtensionsCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.StandardTrainersCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/MulticlassClassification/LbfgsPoissonMaximumEntropyWithOptions.cs\' relative to \'api/Microsoft.ML.StandardTrainersCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.StandardTrainersCatalog.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/MulticlassClassification/LbfgsPoissonMaximumEntropy.cs\' relative to \'api/Microsoft.ML.StandardTrainersCatalog.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.KMeansModelParameters.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/KMeans.cs\' relative to \'api/Microsoft.ML.Trainers.KMeansModelParameters.yml\'. | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.TensorFlowModel.yml | Cannot resolve \'~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/TensorFlowTransform.cs\' relative to \'api/Microsoft.ML.Transforms.TensorFlowModel.yml\'. | \xc2\xa0\r\n\r\n# Incorrect xref link\r\n\r\nFile | Message | fix\r\n-- | -- | --\r\ndotnet/api/Microsoft.ML.Transforms.CountFeatureSelectingEstimator.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transforms.SlotsDroppingTransformer>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.CustomMappingEstimator-2.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transforms.CustomMappingTransformer>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.MissingValueIndicatorEstimator.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transfroms.MissingValueIndicatorTransformer/>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.Text.CustomStopWordsRemovingEstimator.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transforms.Text.CustomStopWordsRemovingTransformer/>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.Text.NgramHashingEstimator.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transforms.Text.NgramHashingTransformer/>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.Text.StopWordsRemovingEstimator.yml | 1 invalid cross reference(s) """"<xref:Microsoft.ML.Transforms.Text.StopWordsRemovingTransformer/>"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.yml | 2 invalid cross reference(s) ""Microsoft.ML.Transforms.TextFeaturizingEstimator.Options.WordFeatureExtractor"", ""<xref:Microsoft.ML.Transforms.TextFeaturizingEstimator.Options>"". | \xc2\xa0\r\n\r\n# Incorrect cref link\r\n\r\nFile | Message | \xc2\xa0\r\n-- | -- | --\r\ndotnet/api/Microsoft.ML.Calibrators.FixedPlattCalibratorEstimator.yml | 3 invalid cross reference(s) ""Microsoft.ML.Data.DefaultColumnNames.Probability"", ""Microsoft.ML.Data.DefaultColumnNames.Score"", ""Microsoft.ML.Data.AnnotationUtils.GetTrainerOutputAnnotation(System.Boolean)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Calibrators.IsotonicCalibratorEstimator.yml | 3 invalid cross reference(s) ""Microsoft.ML.Data.DefaultColumnNames.Probability"", ""Microsoft.ML.Data.DefaultColumnNames.Score"", ""Microsoft.ML.Data.AnnotationUtils.GetTrainerOutputAnnotation(System.Boolean)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Calibrators.NaiveCalibratorEstimator.yml | 3 invalid cross reference(s) ""Microsoft.ML.Data.DefaultColumnNames.Probability"", ""Microsoft.ML.Data.DefaultColumnNames.Score"", ""Microsoft.ML.Data.AnnotationUtils.GetTrainerOutputAnnotation(System.Boolean)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Calibrators.PlattCalibratorEstimator.yml | 3 invalid cross reference(s) ""Microsoft.ML.Data.DefaultColumnNames.Probability"", ""Microsoft.ML.Data.DefaultColumnNames.Score"", ""Microsoft.ML.Data.AnnotationUtils.GetTrainerOutputAnnotation(System.Boolean)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.CustomMappingCatalog.yml | 1 invalid cross reference(s) ""Microsoft.ML.Runtime.ComponentCatalog.RegisterAssembly(System.Reflection.Assembly,System.Boolean)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Data.ConfusionMatrix.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.ConfusionMatrix.PredictedClassesIndicators"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Data.IRowToRowMapper.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.ISchemaBoundRowMapper"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Data.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.ISchemaBoundRowMapper"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.ModelSaveContext.yml | 1 invalid cross reference(s) """"Microsoft.ML.ICanSaveInBinaryFormat"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.StandardTrainersCatalog.yml | 1 invalid cross reference(s) """"Microsoft.ML.Calibrators.PlattCalibratorTrainer"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.StandardTrainersCatalog.yml | 1 invalid cross reference(s) """"Microsoft.ML.Calibrators.PlattCalibratorTrainer"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer.Options.yml | 1 invalid cross reference(s) """"Microsoft.ML.TreeExtensions.FastTree(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer.Options)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer.yml | 1 invalid cross reference(s) """"Microsoft.ML.TreeExtensions.FastTree(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer.Options)"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.FastTreeRankingModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.FastTreeRegressionModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.FastTreeTweedieModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.FastTree.yml | 5 invalid cross reference(s) """"Microsoft.ML.TreeExtensions.FastTree(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer.Options)"", ""Microsoft.ML.Trainers.FastTree.InternalQuantileRegressionTree"", ""Microsoft.ML.Trainers.FastTree.InternalRegressionTree"", ""Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnQuantileRegressionTree.CreateTreeEnsembleFromInternalDataStructure"", ""Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParametersBasedOnRegressionTree.CreateTreeEnsembleFromInternalDataStructure"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.DartBooster.Options.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.LightGbm.Booster"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.GossBooster.Options.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.LightGbm.Booster"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.GradientBooster.Options.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.LightGbm.Booster"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.LightGbmBinaryModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.LightGbmRankingModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.LightGbmRegressionModelParameters.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.LightGbm.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.LightGbm.Booster"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.MatrixFactorizationTrainer.yml | 1 invalid cross reference(s) """"""""Microsoft.ML.Trainers.MatrixFactorizationTrainer.LossFunctionType.SquareLossOneClass"""""""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.OnlineLinearOptions.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.OnlineLinearOptions.InitialWeights"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.SdcaMulticlassTrainerBase"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer.yml | 1 invalid cross reference(s) """"Microsoft.ML.Trainers.SdcaMulticlassTrainerBase"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.BinaryPredictionTransformer"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.BinaryPredictionTransformer"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.KeyToValueMappingEstimator.yml | 1 invalid cross reference(s) """"Microsoft.ML.Data.AnnotationInfo"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.KeyToVectorMappingEstimator.yml | 1 invalid cross reference(s) """"Microsoft.Ml.Data.KeyDataViewType"""". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.TensorFlowModel.yml | 2 invalid cross reference(s) ""Microsoft.ML.Transforms.TensorFlowModel.ModelPath"", ""Microsoft.ML.Transforms.TensorFlowModel.Session"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.Transforms.TensorFlowModel.yml | 2 invalid cross reference(s) ""Microsoft.ML.Transforms.TensorFlowModel.ModelPath"", ""Microsoft.ML.Transforms.TensorFlowModel.Session"". | \xc2\xa0\r\ndotnet/api/Microsoft.ML.yml | 3 invalid cross reference(s) ""Microsoft.ML.TrainContext"", ""Microsoft.ML.Data.CatalogUtils"", ""Microsoft.ML.IPredictor"". | \xc2\xa0\r\n\r\n'"
435828637,3473,"b""K-means documentation doesn't explain outputs' meanings""","b""The only explanation of K-means outputs is:\r\n\r\nOutput Column Name | Column Type | Description\r\n-- | -- | --\r\nScore | Single | The unbounded score that was calculated by the trainer to determine the prediction.\r\nPredictedLabel | Int32 | The cluster id predicted by the trainer.\r\n\r\nI don't feel they are clear enough to users."""
435827989,3472,b'Issues with KeyToBinaryVectorMappingEstimator',"b""https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog?view=ml-dotnet&branch=master\r\n\r\nIt doesn't shows up as method on `ConversionsExtensionsCatalog` https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog?view=ml-dotnet&branch=master because it's part of `ConversionsCatalog`\r\nwhich I found weird.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionscatalog.mapkeytobinaryvector?view=ml-dotnet&branch=master#Microsoft_ML_ConversionsCatalog_MapKeyToBinaryVector_Microsoft_ML_TransformsCatalog_ConversionTransforms_System_String_System_String_\r\n\r\n>Convert the key types back to binary vector.\r\n\r\nWould be nice to have better explanation.\r\n\r\nNo table with input/output types.\r\n\r\nno examples...\r\n\r\n"""
435826522,3471,b'Math not being rendered in documentation of AveragedPerceptronTrainer',"b'In the remarks, the math expressions are not written in Latex:\r\n\r\nf0, f1,..., f_D-1\r\nsigma[0, D-1] (w_i * f_i)\r\n\r\netc.'"
435823809,3470,b'Issues with ValueToKeyMappingEstimator documentation',"b""https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.valuetokeymappingestimator?view=ml-dotnet&branch=master\r\n>Converts input values (words, numbers, etc.) to index in a dictionary.\r\n\r\nIt converts data to KeyDataViewType.\r\n\r\n>but can be defined through other means: either with the mapping defined directly on the command line, or as loaded from an external file.\r\n\r\nPress 'X' to doubt. I don't see such methods, and that line was clearly taken from TLC documentation. Well maybe that  `Microsoft.ML.IDataView keyData = null` in sample, but that sentence need more polishing.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.valuetokeymappingtransformer?view=ml-dotnet&branch=master\r\n\r\n>The TextToKeyConverter transform builds up term vocabularies (dictionaries). The TextToKeyConverter and the Microsoft.ML.Transforms.HashConverter\r\n\r\nWhat is TextToKeyConverter?\r\n\r\nMethods table looks weird.\r\n\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.mapvaluetokey?view=ml-dotnet&branch=master\r\n\r\nExamples is absent.\r\n> Warning It looks like the sample you are looking for has moved! Rest assured we are working on resolving this.\r\n"""
435818294,3469,"b'Word ""Options"" missing in link to constructor with options '","b'https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmbinarytrainer?view=ml-dotnet&branch=smoke-test-preview\r\n\r\nThe above is one example, check for all trainers for similar issue.\r\n'"
435817838,3468,b'LightGBM documentation has incorrect additional nuget information',b'Change it from Microsoft.ML.FastTree to Microsoft.ML.LightGbm'
435816837,3467,b'Issues with KeyToValueMappingEstimator  documentation',"b'https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.keytovaluemappingestimator?view=ml-dotnet&branch=smoke-test-preview\r\n\r\n>Utilizes KeyValues Microsoft.ML.Data.AnnotationInfo \r\n\r\nthat part looks broken, no links, not sure what `KeyValues` means...\r\n\r\n>Zero values of the KeyDataViewType\r\n\r\nMissing values probably.\r\n\r\n>Input column data type | key\r\n\r\nI would prefer capital Key.\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.mapkeytovalue?view=ml-dotnet&branch=smoke-test-preview\r\n> /// It is possible to have multiple values map to the same category.\r\n\r\nPress `X` to doubt. I\'m not sure we can have value ""A"" and ""B"" be mapped on key 1. Even if that\'s the case, what would happened if `MapKeyToValue` encounter key with value 1, would it be ""A"" or ""B""?\r\n\r\n>// at this point, the Label colum is tranformed from strings, to DataViewKeyType and\r\n\r\nCapital letter. DataViewKeyType  need to be `<see cref>` (it\'s KeyDataViewType btw).\r\n>  // the transformation has added the PredictedLabel column, with \r\n\r\nSome one just drop the sentence.\r\n\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.mapkeytovalue?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_ConversionsExtensionsCatalog_MapKeyToValue_Microsoft_ML_TransformsCatalog_ConversionTransforms_System_String_System_String_\r\n\r\n>// Get a small dataset as an IEnumerable and load it into ML.NET data set.\r\n            IEnumerable<DatasetUtils.SampleTopicsData> data = DatasetUtils.GetTopicsData();\r\n\r\nAre we ok with SamplesUtils?\r\n\r\nIn general that samples looks like it need some rewriting. Python_Names, printHelper in the middle of sample, GetColumn operates over `VBuffer`\r\n\r\n\r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.mapvaluetokey?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_ConversionsExtensionsCatalog_MapValueToKey_Microsoft_ML_TransformsCatalog_ConversionTransforms_Microsoft_ML_InputOutputColumnPair___System_Int32_Microsoft_ML_Transforms_ValueToKeyMappingEstimator_KeyOrdinality_System_Boolean_Microsoft_ML_IDataView_\r\n\r\n> Warning \r\nIt looks like the sample you are looking for has moved! Rest assured we are working on resolving this.\r\n\r\nThis does\'t looks right.\r\n'"
435816056,3465,"b'""Predicted label"" type needs to be KeyType and not UInt32 in IO-Columns-Multiclass MD file'",b'https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmmulticlasstrainer?view=ml-dotnet&branch=smoke-test-preview'
435806775,3463,b'InputOutputColumnPair is confusing',"b""So I'm looking on this class and it's constructor\r\n\r\nInputOutputColumnPair(String, String) | Specifies input and output column names for a transformation.\r\n-- | --\r\n\r\n\r\nAnd I automatically assume it's Input column first, and output column second.\r\nWhich we all know not the true.\r\n\r\nShall we rename it to `OutputInputColumnPair`? """
435767747,3462,b'Unable to load the Model by Stream',"b'### System information\r\n\r\nI have used my model as an embedded resource in one of my projects.\r\n\r\n### Issue\r\n\r\nI tried to load the model using Stream and it gives me an error below;\r\n\r\nSystem.ArgumentOutOfRangeException: \'filePath cannot be null or empty\r\nParameter name: filePath\'\r\n\r\n### Source code / logs\r\n\r\nMy below code snippet;\r\n\r\n var assembly = Assembly.GetExecutingAssembly();\r\n            using (var stream = assembly.GetManifestResourceStream(""SentimentAnalyzer.MLModels.SentimentModel.zip""))\r\n            {\r\n                //Create MLContext to be shared across the model creation workflow objects \r\n                //Set a random seed for repeatable/deterministic results across multiple trainings.\r\n                var mlContext = new MLContext(seed: 1);\r\n                Sentiment sampleStatement = new Sentiment { Text = text };\r\n                ITransformer trainedModel = mlContext.Model.Load(stream, out var modelInputSchema);\r\n...\r\n...\r\n}'"
435732099,3460,b'Is there any way to pass pre-loaded image into MLContext pipeline?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2.202\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nMy intention was to implement object detection in video. Please see attached code sample and explanation below.\r\n- **What happened?**\r\nI wasn\'t able to find proper API methods for configuring MLContext pipeline.\r\n- **What did you expect?**\r\nI expected it should be possible to pass individual in-memory representation of image(as a Bitmap object for example) into pipeline. \r\n\r\n### Source code / logs\r\n\r\nLet\'s pretend we have a task to run object detection model on frames coming from video stream. \r\nIt seems natural to pass 1 frame one by one as they arriving from camera. \r\n\r\nI can\'t find such possibility with current MLContext pipeline and API available. \r\n\r\nHere\'s example pipeline from [machinelearning-samples](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/DeepLearning_ObjectDetection_Onnx/ObjectDetectionConsoleApp/OnnxModelScorer.cs#L61) :\r\n\r\n```\r\n            var pipeline = mlContext.Transforms.LoadImages(outputColumnName: ""image"", imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath))\r\n                            .Append(mlContext.Transforms.ResizeImages(outputColumnName: ""image"", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: ""image""))\r\n                            .Append(mlContext.Transforms.ExtractPixels(outputColumnName: ""image""))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: modelLocation, outputColumnNames: new[] { TinyYoloModelSettings.ModelOutput }, inputColumnNames: new[] { TinyYoloModelSettings.ModelInput }));\r\n```\r\n\r\nHaving LoadImages extension method overload accepting in-memory image representation (Bitmap or whatever) would definetly solve a problem:\r\n\r\n`public static ImageLoadingEstimator LoadImages(this TransformsCatalog catalog, params Bitmap[] images);`\r\n\r\nAm I missing some way implement this without storing frames onto the disk? Or does it mean ML.NET wasn\'t designed for realtime video processing?\r\n\r\nThanks in advance.'"
435499502,3450,b'I always get null when calling IDataView.GetRowCount()',"b'\r\n[Enter feedback here]\r\nThe documentation states that the value sometimes returns null, well, in my case it always returns null. My code:\r\n```\r\n\r\nvar dataset = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.1);\r\n//create pipeline\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n//... more stuff\r\n.Append(mlContext.Transforms.CopyColumns(outputColumnName: Scores, inputColumnName: Score));\r\n\r\n// Train the model.\r\nvar model = pipeline.Fit(dataset.TrainSet);\r\n\r\n//get rations for coverage\r\n(long? training, long? validating) montecarlo = ( dataset.TrainSet.GetRowCount(), dataset.TestSet.GetRowCount());\r\n\r\n```\r\nIs there no way to validate how much data was in the data based on the split in each of the datasets\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 4406a379-022a-e834-8e40-886c28ea39b8\r\n* Version Independent ID: afb85da3-f749-2f1b-668a-ae33b5df97f8\r\n* Content: [IDataView.GetRowCount Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview.getrowcount?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/IDataView.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/IDataView.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
435311356,3443,b'Default and missing values for each type should be documented',"b'In some of our documentation, like in #3424 we reference the ""non-default"" values or the ""default"" values of the parameters. Those values need to be documented together with the APIs using them. \r\n\r\n'"
435258953,3439,b'Mathmatical operation needs mathmatical equations for documentation',"b""I feel we should follow Pytorch to add equations to APIs --- for example, https://pytorch.org/docs/stable/nn.html#torch.nn.Conv1d. I personally believe that is how a math library's documentation should look like. Also, debugging ML models is quite different from debugging typical code --- debugging ML model (such as figuring why it doesn't work) requires knowledge of the underlying mathematical models."""
435237377,3437,"b'For compound transforms, there should be a setting that allows the user to see the intermediate columns'","b'When the users use compound transforms, like `FeaturizeText`, the intermediate columns like: `*_TextNormalizer`, `*_TextNormalizer_WordTokenizer` etc are not part of the output schema. \r\n\r\nI think it would be really useful for debugging and tunning purposes to be able to see how the text transforms step by step. \r\n\r\nThere should be an option to make those intermediate columns part of the output. '"
435221006,3436,b'Normalizers multicolumn samples',b'All transform extension APIs have been documented as part of #1209. \r\nThe only samples left to be created are the ones about normalizer extensions operating on multiple columns. \r\n\r\nReplicate PR #3435 for the other normalizer APIs'
434946493,3407,b'Improve clarity of Reference Documentation for METRICS',"b'I\'m finding that most metrics have very little explanation in the reference.\r\nOther times, it just tells what\'s the formula for that metric.\r\n\r\nFor example:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.regressionmetrics.rootmeansquarederror?view=ml-dotnet\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.logloss?view=ml-dotnet\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/56386721-6f9e0280-61d7-11e9-8231-d1162cf50ca1.png)\r\n\r\nFrom a developer point of view, what we need to explain is:\r\n\r\n- Very short summary of what is that metric (not a formula. The formular is nice to have but not the fundamental thing to understand the metric)\r\n- What to look for with that metric: ""The closer to 1.00 the better?"", viceversa?, basically, when the model is better or worse when looking at that metric.\r\n\r\nOther samples where there\'s very little explanation about the metric:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.microaccuracy?view=ml-dotnet\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.regressionmetrics.rsquared?view=ml-dotnet\r\n![image](https://user-images.githubusercontent.com/1712635/56392485-610b1780-61e6-11e9-9940-151725f714b2.png)\r\n\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.regressionmetrics.meanabsoluteerror?view=ml-dotnet'"
434612189,3393,b'Build failed on master : commit 32bd0e2c8967ddbc2e3b8a01f7af4fadc5ce45d8',"b'### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n> .NET Core SDK (reflecting any global.json):\r\n>  Version:   2.2.103\r\n>  Commit:    8edbc2570a\r\n> \r\n> Runtime Environment:\r\n>  OS Name:     Windows\r\n>  OS Version:  10.0.17134\r\n>  OS Platform: Windows\r\n>  RID:         win10-x64\r\n>  Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.103\\\r\n> \r\n> Host (useful for support):\r\n>   Version: 2.2.1\r\n>   Commit:  878dd11e62\r\n> \r\n> .NET Core SDKs installed:\r\n>   2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.1.302 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.1.401 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.1.500 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.1.505 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n>   2.2.103 [C:\\Program Files\\dotnet\\sdk]\r\n> \r\n> .NET Core runtimes installed:\r\n>   Microsoft.AspNetCore.All 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n>   Microsoft.AspNetCore.All 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n>   Microsoft.AspNetCore.All 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n>   Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n>   Microsoft.AspNetCore.All 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n>   Microsoft.AspNetCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n>   Microsoft.AspNetCore.App 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n>   Microsoft.AspNetCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n>   Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n>   Microsoft.AspNetCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n>   Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n>   Microsoft.NETCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n>   Microsoft.NETCore.App 2.1.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n>   Microsoft.NETCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n>   Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n>   Microsoft.NETCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n> \r\n\r\n\r\n### Issue\r\n\r\n- `git clone https://github.com/dotnet/machinelearning.git`\r\n- open `Developper Command Prompt for VS2017 ` as administrator\r\n- go to the machinelearning directory: `build.cmd`\r\n- What happened: build failed\r\n- Expected: build passed\r\n\r\n### Source code / logs\r\n\r\nError:\r\n\r\n>   Calling ""c:\\Development\\libs\\machinelearning\\src\\Native\\\\gen-buildsys-win.bat"" ""c:\\Development\\libs\\machinelearning\\src\\Native\\"" ""15 2017"" x64\r\n>   CMake Error in CMakeLists.txt:\r\n>   -- Configuring incomplete, errors occurred!\r\n>   See also ""C:/Development/libs/machinelearning/bin/obj/x64.Debug/Native/CMakeFiles/CMakeOutput.log"".\r\n>   Failed to generate native component build project!\r\n>     Generator\r\n> \r\n>       Visual Studio 15 2017 Win64\r\n> \r\n>     could not find any instance of Visual Studio.\r\n> \r\n> \r\n\r\nCMakeOutput contains:\r\n\r\n> The system is: Windows - 10.0.17134 - AMD64\r\n'"
434545131,3390,b'Increase Native build warning level to W3 and fix build warnings ',"b'Before, we actually only reported W1 warning level during native build.\r\nNow we warn on L3 warnings\r\nFixed three warnings from downcasting variables. In all cases the downcasting was deemed safe and replaced with static_cast<>\r\nNote that all those warnings were deemed required to fix for compliance criteria.\r\n'"
434451508,3382,b'Documentation missing on prepairing training data',"b'### Issue\r\n\r\nThe cookbook has plenty of samples of how to do steps, there is however no documentation that I found on how to approach the configuring a pipeline. \r\nThere is no mention on the the choices of:\r\n- Is it better to load all columns of a csv in separate named fields or in a single vector\r\n- Should one normalize each field, when should one normalize it\r\n- Should one combine all in one vector and normalize the whole vector\r\n- how many fields are supported, \r\n\r\n**Error:**\r\nI tried and played a Little with it and found that  when loading data as a vector or when loading the data via individual fieldnames one gets different metrics on the same data (tested against 1.6m rows).\r\nWhen loading via a vector. no issue\r\nwhen loading via fields, no issue\r\nwhen loading it via properties the frameworks complains at the loader with a message stating that there are to many properties and it\'s not supported. \r\n\r\n**Expect**\r\nI expect that all 3 would cause the same error, or all 3 would work as the resulting vector has the same size (35,630 elements). \r\n\r\nI would hope that the documentation gets updated reflecting the above points.\r\n\r\n**Code*\r\n\r\n```\r\nIDataView GetDataView(MLContext mlContext, FileInfo trainingFile)\r\n{\r\n    var loader = mlContext.Data.CreateTextLoader<Mapper>(separatorChar:\'|\',hasHeader:false);\r\n    return loader.Load(trainingFile.FullName);\r\n}\r\n\r\n\r\npublic void ExecuteSDCA()\r\n{\r\n    var file = new FileInfo(@""data\\Rows_100_.data"");\r\n    var dataView = GetDataView(mlContext, file);           \r\n\r\n\r\n    var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n            .Append(mlContext.Transforms.Concatenate(Features, Mapper.GetFieldNames()))\r\n            //.Append(mlContext.Transforms.NormalizeMinMax(outputColumnName:Features, inputColumnName:RawFeatures))\r\n            .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: KeyColumn, featureColumnName: Features, maximumNumberOfIterations:1))\r\n            .Append(mlContext.Transforms.Conversion.MapKeyToValue(inputColumnName: KeyColumn, outputColumnName: PredictedLabel))\r\n            .Append(mlContext.Transforms.CopyColumns(outputColumnName: Scores, inputColumnName: Score));\r\n    //.AppendCacheCheckpoint(mlContext);\r\n\r\n    var model = pipeline.Fit(dataView);           \r\n\r\n}         \r\n\r\n```\r\nI have added the data and auto-generated class as well\r\n\r\n[Mapper.zip](https://github.com/dotnet/machinelearning/files/3091256/Mapper.zip)\r\n\r\n\r\n[Rows_100_.zip](https://github.com/dotnet/machinelearning/files/3091223/Rows_100_.zip)\r\n'"
434441572,3381,b'No readme / guidance in Microsoft.ML.Samples',b'Samples in https://github.com/dotnet/machinelearning/tree/master/docs/samples/Microsoft.ML.Samples\r\nshould have readme explaining available samples and how to use'
434439843,3380,"b'Relationship between SchemaShape from IEstimator and DataViewSchema from its ITransformer, and resulting fallout'","b'I was attempting to write documentation for `IEstimator`  and `ITransformer`. One of the core responsibilities of these is, as expressed in #581, schema propagation, so as to, among other benefits, do the sort of ""pre-fit validation"" scenario that has proven so troublesome to us in the past (this w.r.t. #267).\r\n\r\nHowever, what I find is that I struggled to detect a meaningful unifying ""principle"" behind `IEstimator` and `ITransformer`. I think the people that worked on it thought there was a principle, but when I encountered what people though tit was (something about annotations being a \'subset\' of one or the other), it seemed like there were numerous ""exceptions"" that made the principle meaningless. . Indeed, I\'m starting to suspect that there was no scenario by the original designer aside from ""work until things compile and run on what we have so far,"" which is not really an acceptable state for something like `IEstimator` and `ITransformer` which are core concepts of this API, especially if we hope to describe them in such a way that people can implement these interfaces on their own.\r\n\r\nIn this issue I outline the trouble that I have observed. The points here are ***subtle***, but they are important insofar as resolving them is, I think, crucial for us to define the relationship between `IEstimator` and the `ITransformer` returned by fitting that estimator.\r\n\r\nCCing @artidoro, @shauheen since I know they had some interest in this problem... going to mark as the unusual step of both bug and code-sanitation, since it both touches upon our need to have a consistent architectural story among these key structures, as well as there having been some genuine bugs that have been uncovered.\r\n\r\n# A Troublesome Example\r\n\r\nSo, I\'ll start with the same seemingly innocuous code that led me to think there is something architecturally wrong at stake here: Consider the `IsNormalized` annotation, in the `KeyToVectorMappingEstimator`, here is the condition where this annotation is mentioned as coming:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73e29c8acf63418ce1f89ef78296d52d775dafe3/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L803-L804\r\n\r\nMeanwhile, the resulting transformer has subtly different logic. If the input source value count is `1`, which of course happens when something is scalar, but also happens when the input is vector and happens to have vector size of one. (A concept that has no meaning in `SchemaShape`, and is basically unknowable.)\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73e29c8acf63418ce1f89ef78296d52d775dafe3/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L339-L345\r\n\r\nThis leads to an interesting decision, because from a certain perspective, the addition of the metadata in the `ITransformer` code is correct (and, at the time it was originally written, some years I believe before the concept of `IEstimator` and `SchemaShape` was introduced, was in fact unambiguously correct, since there was no concept as we have now of pre-`Fit` schema validation.) But in the world of `IEstimator`, we are using some information that in some cases could be used *post*-`Fit` in the sense that it can only be expressed in a `DataViewSchema`, not a `SchemaShape` -- that this is a vector type that happens to have length exactly one -- and that in many cases could not even be known pre-`Fit` under some circumstnaces. (E.g., consider a value-to-key mapping estimator that winds up finding only one value.)\r\n\r\nSo, the `IEstimator` makes no claim that the `IsNormalized` data is there, but due to runtime logic that had existed prior to this time, it *is* in fact there.\r\n\r\nThis was known, I believe, the originators of the concept of `IEstimator` and `SchemaShape`, which at one point was deliberately made as, ""all right, we consider the claim in `SchemaShape` to be, in the area of annotations specifically, a *subset* of what is actually present among the non-hidden columns of `DatavViewSchema`. This is in fact what the relevant method called from `TestEstimatorCore` does. (Though, it is reversed from what is actually in the comment -- what it actually tests is that what is delivered is a superset of what is promised).\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3b576fe058ed4f4331018bbc3eabc1ac26219644/test/Microsoft.ML.TestFramework/DataPipe/TestDataPipeBase.cs#L151-L163\r\n\r\nThis notion of ""subsetting"" being the requirement is mentioned in the documentation and testing I could find on the relationship between `IEstimator` and `ITransformer` (see also here). But is superset actually the right thing? Let\'s consider another very important transformer: key-to-value. In that case, the estimators *relies* on a complete description of the `KeyValue` annotation to detect what the input type is! So in that case this mere talk of superset and subset becomes increasingly complex, because sometimes it is necessary, and sometimes it is not.\r\n\r\nIf we want an `ITransformer` and `IEstimator` to be paired, this suggests a mutuality of information. One of the core tenants of `IDataView` is composability, but the foundation of that composibility isn\'t because we\'ve just created a system that works to just accomodate the set of components we ourselves wrote. (Indeed, this is [one thing that I argue](https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewImplementation.md#urgency-in-adhering-to-invariants) in one of our documents about the `IDataView` system and why it works.)\r\n\r\nSo right now we have this system where *sometimes* annotations are subsets, but possibly not, depending on whether we consider a combination of annotations and estimators and transformers valuable. But, that seems like a pretty ad hoc way of engineering a system. How is it possible at all to make any meaningful statements about such a thing like, ""we have this requirement, but possibly not, it only depends on if we\'ve written anything yet that cares.""\r\n\r\nWhat does that mean? Are we prepared to make as part of the contract of `IEstimator` and `ITransformer` that some sorts of annotations are allowed to impact the schema (`KeyValues` must!), but that some are not (we effectively were having the assumption in a few places that `SlotNames` and `IsNormalized` could not, based on our uneven propagation of them)? That doesn\'t seem like a good idea. Are we allowed to evolve that definition in any way? So I wanted something much simpler, which leads me to this:\r\n\r\n# Proposed Schema Relationship Between an Estimator and its Transformer\r\n\r\nEdit: This principle is wrong, see [this comment](https://github.com/dotnet/machinelearning/issues/3380#issuecomment-484722270). But I still think enforcing the principle on our own tests with our own components makes sense and does way more help than harm, but we can\'t insist on it as a principle of the estimators and transformers themselves.\r\n\r\nSo, to make the proposed relationship concrete, I\'ll consider the following code (for any `est` and `data`):\r\n\r\n```csharp\r\nIEstimator est = ...;\r\nIDataView data = ...;\r\nvar schema = data.Schema;\r\n\r\nvar promisedShape = est.GetOutputSchema(SchemaShape.Create(schema));\r\nvar deliveredShape = SchemaShape.Create(est.Fit(data).GetOutputSchema(schema));\r\n```\r\n\r\n1. If both constructions of `promisedShape` and `deliveredShape` succeed, they should be the same, that is, the two constructed `SchemaShape` objects should be indistinguishable (besides, of course, say, tests on reference equality).\r\n\r\n2. If the construction of `deliveredShape` would succeed, then the construction of `promisedShape` should succeed as well. (That is, the schema-propagation logic of an estimator should be no more strict than the schema-propagation logic of its produced transformer.)\r\n\r\nBoth represent a somewhat more ""restrictive"" view of the relationship of paired `IEstimator` and `ITransformer`. The previous state was sort of an ad hoc free for all. I have not yet\r\n established that it will be completely possible to do this; I know it will require some changes of behavior of some `ITransformer`s, *especially* around their annotations, but so far I have not seen any ""show stoppers."" Maybe I will though.\r\n\r\n# Bugs\r\n\r\nUnfortunately due to the fact that this ""requirement"" is meaningless unless we test for it, it is best if I introduce the stricter test, *and* test for this, all at the same time. Doing so results in several test failures -- some were due to stricter requirements, but some were due to the fact that some `IEstimator` implementations were just plain wrong. I will outline in comments below those bugs that I have found, since I have not completed that work yet. (I have only fixed two tests so far, and each takes me a few hours. Regrettably, given the subtlety of the issues at stake, this is one of those situations that requires more finesse and consideration than other changes.)/+\r\n+\r\n'"
434428466,3378,b'Should I provide the schemas when creating a prediction engine?',"b'\r\n[Enter feedback here]\r\ncurrently, it takes quite a while to generate a prediction engine (56,863 ms). \r\nWould serialize and providing the schemas generated by the training improve the load times?\r\n\r\nA single prediction takes 1,452 ms. I have an I7 CPU with sufficient ram, is there a way to speed it up?\r\n\r\nI have added the input class. \r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 992ff2a9-37e1-54ce-947b-67103207ce8e\r\n* Version Independent ID: 584449fa-50f6-85af-4c4c-3fb33cdedfbd\r\n* Content: [ModelOperationsCatalog.CreatePredictionEngine Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.modeloperationscatalog.createpredictionengine?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/ModelOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ModelOperationsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
434406673,3375,b'Add OnnxTransform test for variable length vectors',"b""## Issue\r\nWe need a test for OnnxTransform that uses variable length vectors as input.\r\n\r\n## Details\r\nThe OnnxTransform does not allow for input that is of variable length vector type, however variable length vectors are supported in ONNX. This check could be removed if we have tests that use a model that has a variable length vector. \r\n\r\nI initially tried via sci-kit learn to create an onnx model using the CountVectorizer which would result in variable length vectors, however loading this model in ml.net failed due to missing string support. \r\n\r\nNext attempt is to create a simple ONNX model using argmax and have it take multiple inputs, script is here for reference:\r\n\r\n```\r\nimport onnx\r\nfrom onnx import helper\r\nfrom onnx import AttributeProto, TensorProto, GraphProto\r\n\r\nheight=1\r\nwidth=1\r\nisize = height * width\r\n\r\ninput = helper.make_tensor_value_info('input', TensorProto.FLOAT , [-1, -1])\r\nargmax = helper.make_tensor_value_info('argmax', TensorProto.INT64, [-1])\r\nnodea = helper.make_node(\r\n\xc2\xa0 \xc2\xa0 'ArgMax', \xc2\xa0# node name\r\n\xc2\xa0 \xc2\xa0 ['input'], \xc2\xa0# inputs\r\n\xc2\xa0 \xc2\xa0 ['argmax'], \xc2\xa0# outputs\r\n\xc2\xa0 \xc2\xa0 axis = 1,\r\n\xc2\xa0 \xc2\xa0 keepdims = 0\r\n)\r\n\r\n# Create the graph (GraphProto)\r\ngraph_def = helper.make_graph(\r\n\xc2\xa0 \xc2\xa0 [nodea],\r\n\xc2\xa0 \xc2\xa0 'argmax',\r\n\xc2\xa0 \xc2\xa0 [input],\r\n\xc2\xa0 \xc2\xa0 [argmax]\r\n)\r\n\r\n# Create the model (ModelProto)\r\nmodel_def = helper.make_model(graph_def, producer_name='AIInfra')\r\n#\r\n#print('The model is:\\n{}'.format(model_def))\r\nonnx.save(model_def, 'test_unknowndimensions_float.onnx')\r\n```\r\n\r\nIf this does work, we will need to add the ONNX model to https://github.com/dotnet/machinelearning-testdata\r\n\r\nAs this generates the nuget file that contains our onnx test models.\r\n\r\nCC @jignparm """
434020866,3369,b'Example code on how to load in-memory images into ONNX models and TensorFlow models',"b""I'm reviving these issues. Basically, we need example code on how  to load in-memory images into pipeline (for ONNX and TensorFlow models):\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/2495\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/2121\r\n\r\nThere are many scenarios that require that way instead of loading from image files on the drive.\r\n\r\nScenarios:\r\n- Live-streaming images coming from a laptop camera for object detection ONNX models\r\n- Web/Service Http apps where images come through HTTP and need to be processed directly\r\n\r\nCan the team create example code of ONNX model and a second for a TensorFlow model where in-memory images are provided instead of loading from files on the drive?\r\n """
434011822,3366,b'Microsoft.ML.DataView metadat needs to be fixed',"b'In #2974 we moved IDataView back to Microsoft.ML, but did not update the logo for the nuget back to ML.NET'"
434007827,3365,b'RowGroupColumnName of ranking trainers options class defaults to null',b'The `Options` class of the ranking trainers (`FastTree` and `LightGbm`) defaults to `RowGroupColumnName = null`.\r\n\r\nThis is:\r\n1. Inconsistent with the simple constructor where `RowGroupColumnName` defaults to `GroupId`\r\n2. Not desirable as in ranking the row group is very important for correct training\r\n\r\nHere are the lines where the row group column name is set:\r\nhttps://github.com/dotnet/machinelearning/blob/738e5d5a5b90f8c3a93c391bb8b2e0bcdad35cd0/src/Microsoft.ML.Data/Training/TrainerInputBase.cs#L106-L110\r\n\r\nWe need to update the default and align it with the simple constructor.'
433978177,3361,b'MFNative Utility::malloc_aligned_float() can overflow on 32-bit systems',"b'### ISSUE\r\nIn MF Native, the function malloc_aligned_float() can underallocate, creating a potential for buffer overlow in Matrix Factorization algorithm.\r\nThe function ```Utility::malloc_aligned_float(mf_long size)``` takes an input ```size``` which is a 64 bit signed integer.  Later in the function we do a static cast to ```size_t```.  \r\n```_aligned_malloc(static_cast<size_t>(size * sizeof(mf_float))```\r\nNote that on 32-bit platform size_t is 32 bit.  As a result, the outcome of the cast result in loss of data (size will be <max uint)).  The funciton will succeed and the algo will assume that the array is bigger vs what it actually is. Then you this can potentially lead to an exploitable buffer overflow.\r\n\r\n### EXPECTED\r\nWe must validate and ensure that there is no cast issues for all platforms.  we should validate all inputs and do NOT use static casting.  In addition, consider changing the type of ```size``` to ```size_t```'"
433965526,3360,b'Samples templates could be improved and use TrainTestSplit',"b""Our samples templates for trainers usually call the `GenerateDataPoints` method twice, once to generate the test data and once to generate the training data. Furthermore, the two calls are not symmetrical.\r\n\r\nSee here the template for binary classification trainers:\r\nhttps://github.com/dotnet/machinelearning/blob/5538ccfcd8b0ad89146cf428dcfae6f25b179703/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/BinaryClassification.ttinclude#L21-L25\r\nand\r\nhttps://github.com/dotnet/machinelearning/blob/5538ccfcd8b0ad89146cf428dcfae6f25b179703/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/BinaryClassification.ttinclude#L49-L50\r\n\r\nIt would be more educationally useful to replace this with a single call to the data generation method and combine it with a call to `TrainTestSplit`.\r\n\r\nSee @rogancarr's motivating comment: https://github.com/dotnet/machinelearning/pull/3338#discussion_r275909222"""
433922291,3358,b'lack of feedbak from the ITrainer api becomes an issue',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: Core 3.0, preview 1.0 of ML\r\n\r\n### Issue\r\nWorking larger datasets it becomes important to get a progress on what the system is doing.\r\nI am testing the framework against a smaller set of production data (21 days@23:45:00 per day), The smaller training file is ~300 GB and 35630 columns, depending on the multiclass label to predict. \r\n\r\nThere is not only no documentation in regards to sizing there is also no progress report or early stopping method that one can hook into, or is there?. \r\n\r\nOne can limit the amount of iterations, however it would be far cooler to be able to hooking to an Iteration have an event that states the current metric as well as a ""Cancel"" property. there are several events that use such hooks like Form.OnClosing. \r\n\r\nHaving a cancel would ideally have the model fitted in such a state that one can save it. Ideally I would suggest to have ""duration of training"" as well as ""Iteration performed""  in the event. this would nicely hook into progress reporting tools. \r\n\r\nI guess it could be a part of IProgressChannel? \r\nWould be nice if this could be considered\r\n   \r\n'"
433717983,3356,b'L1 and L2 Regularization',"b'[Enter feedback here]\r\nI would provide a reason as for the use of the parameter. if L1 stands for Lasso Regression (Least Absolute Shrinkage and Selection Operator) than one could mention that:\r\n\r\n> The value L1 helps by adding an absolute value for the magnitude of coefficients as a ""penalty"" for the loss function. The Lasso will reduce/shrink the weight of the less important features and works well with models that have a large set of features (the value should be higher than 0 and less than or equal to 1, Based on the trainer used the L1 value is inferred based on steps of 0.25f starting at 0f ends at 1f. If you would like to avoid ""discovery"" and use your own scale than you could enter one here. \r\n---\r\nRight now the property adds no value to the API also it provides an automatically inferred based on data set. without telling the user.\r\n\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: c1d926eb-6385-aae6-78f8-88410472625c\r\n* Version Independent ID: 5a58a60a-7ba0-8ef9-3537-05bb28678113\r\n* Content: [SdcaTrainerBase&lt;TOptions,TTransformer,TModel&gt;.OptionsBase.L1Regularization Field (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcatrainerbase-3.optionsbase.l1regularization?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/SdcaTrainerBase`3+OptionsBase.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/SdcaTrainerBase`3+OptionsBase.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'"
433636658,3354,b'Comment typo',"b""https://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L22\r\n\r\n'can contain column' --> 'can contain columns'"""
433582178,3350,b'Stop using Preview structure and API in samples.',"b'From PR #3307 and @TomFinley \'s [comment ](https://github.com/dotnet/machinelearning/pull/3307#pullrequestreview-225891973) it was learnt that samples should be rewritten to not use ""preview"" structure because we\'re writing sample code using a structure expressly and clearly intended purely for debugging in a preview window anyway. There are a number of samples that use preview structure, I will start converting these samples in batches and replace the usage of preview API/structure with something more appropriate like IDataView + getter or Enumerable(with class). We definitely don\'t want to be educating our users the wrong thing.\r\n\r\nCC: @TomFinley @shmoradims @natke @shauheen '"
433490616,3342,b'Inconsistency between package versioning',b'There there [ML.NET nuget](https://www.nuget.org/packages/Microsoft.ML/0.11.0) 0.11 and 1.0.0. There are [ML.Recommender](https://www.nuget.org/packages/Microsoft.ML.Recommender/0.12.0-preview) nuget 0.11 and 0.12. How should user know 0.12 is equivalent to 1.0.0? Other nugets (such as time series and fast tree) look ok but we might want to double-check.'
433432052,3340,"b""LightGBM Error, code is -1, error message is 'bad allocation'""","b""### System information\r\n\r\n- **Windows 10 **:10.0.18362 Build 18362\r\n- **.NET**: Version 4.7.3, Microsoft.ML 1.0 preview\r\n-** Microsoft.ML.LightGMB**: 0.11.27505.13@build By dlab -14DDVS...\r\n### Issue\r\n\r\n- **What did you do?**\r\nStarted training using following code:\r\n```\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: nameof(PredictedResult.LabelIndex) , inputColumnName: nameof(Data.Label), sort: ValueToKeyMappingEstimator.SortOrder.Value)\r\n                       .Append(mlContext.Transforms.Normalize(mode: NormalizingEstimator.NormalizerMode.MinMax, outputColumnName: nameof(Data.Features)))\r\n                       .Append(mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName:nameof(Data.LabelIndex),  featureColumnName:nameof(Data.Features)))\r\n                       .Append(mlContext.Transforms.Conversion.MapValueToKey(nameof(PredictedResult.PredictedLabelIndex), nameof(PredictedResult.PredictedLabel)))\r\n                       .Append(mlContext.Transforms.CopyColumns(outputColumnName: nameof(PredictedResult.Scores), inputColumnName: DefaultColumnNames.Score));\r\n            // Train the model.\r\n            var model = pipeline.Fit(dataset.TrainSet);\r\n```\r\n\r\n- **What happened?**\r\nReceived error on log line:\r\n```\r\nException(s): LightGBM Error, code is -1, error message is 'bad allocation'.\r\nLog: 18:20:52:[Source=LightGBMMulticlass; Loading data for LightGBM, Kind=Trace] Channel disposed. Elapsed 02:24:12.0168791.6010992.81611.0110556.\r\n```\r\n\r\n- **What did you expect?**\r\nA error message that makes sense that I can understand what the issue is.\r\n\r\n### Source code / logs\r\n\r\nNo additional logs recorded, \r\n"""
433407876,3337,b'Math equations in docs',b'We need a formal way to write equations used in trainers and transforms. I personally like [Latex syntax](https://www.overleaf.com/learn/latex/Aligning_equations_with_amsmath). Any other comments please?\r\n\r\nExample:\r\n```latex\r\n\\sum_{i=1}^{\\infty} \\frac{1}{n^s}\r\n```\r\n\r\n[Example where this is needed in docs](https://github.com/dotnet/machinelearning/blob/059c761ca3b4f46a40d36c434c32733f063e7dab/src/Microsoft.ML.StandardTrainers/Standard/Online/AveragedPerceptron.cs#L46)'
433124981,3336,b'Cannot build the source code using Visual Studio 2019',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 1809\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n- **Visual Studio version** VS2019\r\n\r\n### Issue\r\n\r\n- I am trying to build the source code using Visual Studio 2019. I have downloaded the source code and followed the [developer guide ](https://github.com/dotnet/machinelearning/blob/master/docs/project-docs/developer-guide.md), and run the following ``build.cmd -Release -TargetArchitecture:x64``, the following errors appeared:\r\n```\r\n  **********************************************************************\r\n  ** Visual Studio 2019 Developer Command Prompt v16.0.1\r\n  ** Copyright (c) 2019 Microsoft Corporation\r\n  **********************************************************************\r\n  [vcvarsall.bat] Environment initialized for: \'x86_x64\'\r\n  Commencing native build of dotnet/machinelearning\r\n\r\n  Calling ""C:\\sc\\github\\machinelearning\\src\\Native\\\\gen-buildsys-win.bat"" ""C:\\sc\\github\\machinelearning\\src\\Native\\"" ""15\r\n 2017"" x64\r\n  CMake Error in CMakeLists.txt:\r\n  -- Configuring incomplete, errors occurred!\r\n  See also ""C:/sc/github/machinelearning/bin/obj/x64.Release/Native/CMakeFiles/CMakeOutput.log"".\r\n  Failed to generate native component build project!\r\n    Generator\r\n\r\n      Visual Studio 15 2017 Win64\r\n\r\n    could not find any instance of Visual Studio.\r\n\r\nC:\\sc\\github\\machinelearning\\src\\Native\\build.proj(67,5): error MSB3073: The command """"C:\\sc\\github\\machinelearning\\src\\\r\nNative\\build.cmd"" Release x64 --mkllibpath C:\\sc\\github\\machinelearning\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\n\r\native"" exited with code 1.\r\n\r\nBuild FAILED.\r\n\r\nC:\\sc\\github\\machinelearning\\src\\Native\\build.proj(67,5): error MSB3073: The command """"C:\\sc\\github\\machinelearning\\src\\\r\nNative\\build.cmd"" Release x64 --mkllibpath C:\\sc\\github\\machinelearning\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\n\r\native"" exited with code 1.\r\n    0 Warning(s)\r\n    1 Error(s)\r\n```\r\nSeems the build scripts are not updated in order to support Visual Studio 2019'"
432846916,3335,b'Splitter/consolidator worker encountered exception',"b'### System information\r\n\r\nOS version/distro: Windows 10\r\n.NET Version (eg., dotnet --info):  dotnet core 2.2\r\nVersion : ML.NET v1.0.0-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nI used tensorflow model + SDCA sample to train my own data\r\n- **What happened?**\r\n when i have 800 labels it gives this error, but work when there are 100 labels in tags.tsv file.\r\n\r\n\r\n### Source code / logs\r\nTraining classification model\r\n#############################\r\n\r\nEXCEPTION\r\n#########\r\nSplitter/consolidator worker encountered exception while consuming source data\r\n\r\nPress any key to finish.\r\n\r\n\r\n'"
432829391,3334,"b""Documentation enhancement on the pipeline's impack on output schema""","b'I am looking over the various samples provided in the Cookbook as well as the sample projects. \r\nnone of them are actually going into the detail of how powerful the creation of the training pipeline is when it comes to generating and populating a prediction.\r\n\r\nPerhaps one could add some Dokumentation as to the differences between the networks as well as the population and addressing the naming. One could, with a multiclass state the accuracy of the predicted class as one does now, one could also show the nearest neighbour and the combined weight of both. The patient could have both diseases, the client could like both products with a ""likely hood"" in ""that order"" with that ""accuracy"".  \r\n\r\nI\'d think that the [Cookbook ](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md)would be an ideal location for this. in a section with a title say ""**how do I Interpret a generated single prediction**""'"
432789801,3327,"b""Image transfomers don't dispose source image.""","b""Image transformers such as grayscale and resize have images as input. After they process input images to produce output image they should dispose the input image because if they don't then we are at mercy of garbage collector cleaning the bitmap objects and if the GC has not done that and some code in the same process tries to open the same image referenced by the bitmap object that is not disposed then we get file in use exception."""
432783609,3323,b'Multiclass Classification catalog does not contain EvaluateNonCalibrated',"b""The Multiclass Classification catalog has non calibrated trainers (`SdcaNonCalibratedMulticlassTrainer`) along with many calibrated trainers. \r\n\r\nCurrently there is only one `Evaluate` method, which assumes that the model is calibrated, and therefore produces `LogLoss` metrics. These metrics don't makes sense for the non calibrated trainers.\r\n\r\nWe should therefore add an evaluation method named `EvaluateNonCalibrated` for the non calibrated trainers."""
432774419,3320,b'AutoML feature request: Provide hooks to enable more usable APIs',b'Current AutoML APIs look like this\r\nmlContext.Auto.CreateRegressionExperiment() \r\nmlContext.Auto.InferColumns() \r\n\r\nThis makes us like we are shipping organization boundaries!\r\nSo we propose we ship the following.\r\nmlContext.Regression.CreateAutoExperiment()\r\nmlContext.Data.AutoInferColumns()\r\n\r\nThe problem with implementing this is that an extension method needs to be implemented on RegressionCatalog and not MLContext -- this means that automl code cant have have access to mlContext - but it needs access to mlContext. Please enable same.\r\n\r\n'
432369846,3308,b'Standalone app to run all samples to catch run time exceptions',b'We need an app that run as a build step to verify samples not only compile but also execute with no exceptions. We have recently seen as evident by #3187 that samples are being checked-in that when run by a user will not produce any meaningful output but instead cause runtime exception and leave a very bad user experience. '
432368660,3306,"b""Image samples don't dispose bitmap object after use causes exceptions.""","b""When running samples all at once there is an exception between image samples because image transforms open and return image as a Bitmap object, however our samples don't dispose the bitmap object due to this when the next sample opens the same image it gets an exception saying the file is in use by the same or another process. Even though it is a new pipeline, we see this exception because garbage collector has not yet disposed the Bitmap object. The correct way to fix this problem is to dispose all bitmap objects after a sample has executed, this will not only solve the issue when running all samples at once in the same process but will also educate the user on disposing the bitmaps after use and make our samples better.\r\n\r\n"""
432333292,3304,b'Runtime exception in MapKeyToVectorMultiColumn sample',b'Due to cast exception between float and uint. The scheme has column type float but the output class for enumerating the data has the type uint.'
432312277,3301,b'Simple IDataView Sample',"b""Though we have many methods or samples to create data views from existing structures, like files, databases, enumerables, lists, and so on, we can't possibly handle everything, so a sample as to how to create a data view may be desirable.\r\n\r\nIn this first simple sample, my goal would be to show a fairly minimal `IDataView` implementation but from absolute scratch, one that is very simple without being, I hope, simplistic. I might however stick to scalar inputs for that first simple example, and definitely avoid anything having to do with enabling shuffling or parallel cursor evaluation.\r\n\r\nRelated to #1209, but given that this does not describe a sample for anything *directly* related to `MLContext`, it was thought best to have a separate issue for it."""
432250545,3299,b'Probability is missing from the prediction Output schema of BinaryClassification.Trainers.AveragedPerceptron',"b""### Issue\r\nUsing the Averaged Perceptron Binary Classifier in the Pipeline:\r\n~~~~\r\nvar pipeline =\r\n//Other things in the pipeline\r\n.Append(mlContext.BinaryClassification.Trainers.AveragedPerceptron(learningRate: lr, numIterations: 5));\r\n\r\n//Fit Model steps\r\n//Save Model steps\r\n//Load Model steps\r\n\r\nvar predictions = loadedModel.Transform(data);\r\nvar metrics = mlContextTest.BinaryClassification.Evaluate(predictions);\r\n~~~~\r\n\r\nLeads to the following error.\r\n~~~~\r\n'Probability column 'Probability' not found\r\nParameter name: schema'\r\n~~~~\r\n### What Happened \r\nLooking at the outputSchema of the predictions IDataView, the probability column is absent.\r\n\r\n### Expected Behavior\r\nThe Probability column should be available in the predictions IDataView based on reply by @zeahmed here- https://github.com/dotnet/machinelearning/issues/376#issuecomment-399282699\r\n\r\nLooking at other binary classifiers like fast tree, that column is present in their output schema.\r\n\r\n**System information**\r\n* Product: dotnet-ml-api\r\n* GitHub Login: @bsoman3\r\n* Microsoft Alias: bhsoman\r\n\r\n- **OS version/distro**:Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1"""
432177694,3294,b'Prior Trainer sample throws an exception and the output comments do not match the actual output',b'Prior trainer used to take label type of float but this was changed to take label type of boolean to make it consistent with other binary trainers. Update the sample to change the schema of the data loader to accept label type of boolean and also update the comments to be consistent with the actual output from ML.NET'
432080719,3290,b'Operation is not valid due to the current state of the object',"b'### System information\r\n\r\n- **Windows 10 64 bit**:\r\n- **.NET Core 3.0 preview, \r\n- Microsoft.ML.LightGbm (1.0.0-preview)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsed the LightGbm sample \r\n- **What happened?**\r\nGot 2 strange errors, \r\n1: one the feature vector is off by 1, hardcoding the wrong number will make it work\r\n2: can\'t generate a single Prediction without the api throwing exception ""Operation is not valid due to the current state of the object.""\r\n- **What did you expect?**\r\nI\'d expect this to work, the faulty vector size looks like it takes the column index into account and as for the operation not valid exception... not sure as what that is especially after it generated native predictions\r\n\r\n### Source code / logs\r\n\r\n\r\nExtract, full project with test data Attached\r\n```\r\n\r\n\r\n            // Create a pipeline. \r\n            //  - Convert the string labels into key types.\r\n            //  - Apply LightGbm multiclass trainer.\r\n            var pipeline = mlContext.Transforms.Conversion.MapValueToKey(""LabelIndex"", ""Label"",maximumNumberOfKeys:3,keyOrdinality: Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue)\r\n                        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: ""LabelIndex""))\r\n                        .Append(mlContext.Transforms.Conversion.MapValueToKey(""PredictedLabelIndex"", ""PredictedLabel""))\r\n                        .Append(mlContext.Transforms.CopyColumns(""Scores"", ""Score""));\r\n\r\n            // Split the static-typed data into training and test sets. Only training set is used in fitting\r\n            // the created pipeline. Metrics are computed on the test.\r\n            var split = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.5);\r\n\r\n            // Train the model.\r\n            var model = pipeline.Fit(split.TrainSet);\r\n```\r\n\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Operation is not valid due to the current state of the object.\r\n  Source=Microsoft.ML.StandardTrainers\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.OneVersusAllModelParameters.ImplDist.<>c__DisplayClass11_0.<GetMapper>b__0(VBuffer`1& src, VBuffer`1& dst)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, DataViewRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Data.MulticlassClassificationScorer.<>c__DisplayClass16_0.<GetPredictedLabelGetter>b__0(UInt32& dst)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer.BoundTermMap.Base`1.<>c__DisplayClass3_0.<GetMappingGetter>b__0(UInt32& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass10_0`1.<CreateDirectSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at Microsoft.ML.Samples.LightGbm.Example() in D:\\Deepbook\\Microsoft.ML.Samples\\LightGbm.cs:line 148\r\n   at Microsoft.ML.Samples.Program.Main(String[] args) in D:\\Deepbook\\Microsoft.ML.Samples\\Program.cs:line 9\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting. (added the trained model that goes with the data)\r\n[Microsoft.ML.LightGbm.Samples.zip](https://github.com/dotnet/machinelearning/files/3069341/Microsoft.ML.LightGbm.Samples.zip)\r\n[Model.zip](https://github.com/dotnet/machinelearning/files/3070530/Model.zip)\r\n'"
431789518,3286,b'MapKeyToValue sample throws exception',b'Seems like the issue is cast exception between vector of float to vector of uint.'
431781132,3284,b'TT file contains reference to SampleUtils without Microsoft.ML prefix',b'Upon running custom tool this will cause build failures.'
431777392,3283,b'Prior Trainer does not accept bool label column',"b'The template for our binary classification samples uses a bool label column. This template is used by a number of our binary classification trainers.\r\n\r\n`PrriorTrainer` does not however accept a boolean label column. It only accepts a float label column. Here is the code that checks that the label column is of type float:\r\nhttps://github.com/dotnet/machinelearning/blob/55d911dc5f50bf45bfffe50bf9f0ee3ffb14c369/src/Microsoft.ML.StandardTrainers/Standard/Simple/SimpleTrainers.cs#L233\r\n\r\nIn order to be consistent with the rest of the binary classification trainers, we should allow the label column to be of boolean type for `PriorTrainer`.'"
431754211,3280,b'Samples for GAM are needed',"b""The current samples for GAM don't go into a lot of detail and binary classification samples are missing."""
431735996,3279,b'Remove Console.Readline at the end of the samples',"b'There are two samples that have ReadLine() in the end, presumably to prevent the window from closing but this is not needed because VS prevents the window from closing and also this pattern is inconsistent from rest of the samples. This interferes with the test that runs all the samples to ensure samples are working and not throwing any runtime exceptions.'"
431714037,3277,b'Samples for time series prediction engine and general clean up of all time series samples',b'It seems time series samples related to prediction engine were deleted by PR #2900. This is unfortunate because time series has its own prediction engine that allows for state to be updated and saved at prediction time. By deleting the samples we have no way to show to the user how the checkpoint() API of prediction engine is used. We need to add the samples back and clean up all time series samples so that the format is consistent with rest of samples.'
431654978,3276,b'Tokenizer option for Wordbag Transforms',"b'### Issue\r\nTrying to import the following functionality from TLC:\r\n~~~~\r\nxf=WordBagTransform{    \r\n    col=Features:CatFeatures    \r\n    tok=WordTokenizeTransform{      sep=comma    }    \r\n    max=1000000000    \r\n    weighting=TfIdf  } \r\n~~~~\r\n\r\nI would have expected this to work:\r\n~~~~\r\nvar pipeline =\r\n    mlContext.Transforms.Text.TokenizeWords(""CatTokens"", ""CatFeatures"", separator) //comma only\r\n    .Append(mlContext.Transforms.Text.ProduceWordBags(""Features"", ""CatFeatures"", \r\n        ngramLength: 1, allLengths: true, maxNumTerms: 1000000000, \r\n        weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf))\r\n    ;\r\n~~~~\r\n### What Happened \r\nIt seems that ProduceWordBags is tokenizing under the hood. [link] (https://github.com/dotnet/machinelearning/blob/fc89745fd9d5d7dcca875570bd3b9ffc981f2184/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Text/ProduceWordBags.cs)\r\nThe user does not have any option to specify the separator. TLC uses space by default, but provides the option to change that.\r\n\r\n### Expected Behavior\r\nThe user should be able to produce bag of counts of ngrams on tokens such that they select how the tokenization is done.\r\n\r\nI would expect either TokenizeCharacters() + ProduceNgrams() or TokenizeWords + ProduceWordbags to provide this functionality\r\n\r\n\r\n**System information**\r\n* Product: dotnet-ml-api\r\n* GitHub Login: @bsoman3\r\n* Microsoft Alias: bhsoman\r\n\r\n- **OS version/distro**:Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1'"
431620607,3274,"b'IDataView Type system needs to be extensible to properly support image, date, and other types'","b'To support loading `Image` from `IDataView` (as shown in #3263), user must modify ML.NET code, which means our type system is not extensive. Do we want to invest on the extensibility of ML.NET type system?\r\n'"
431617112,3273,b'NaiveBayes needs better documentation on a range of input values',b'Related to #3226 \r\n\r\nCurrently its not obvious that NaiveBayes acceots ony binary values. This should be both documented and gracefully handled in the trainer'
431612368,3272,b'Exception on using LightGBM trainer with FeatureContributionCalculation and OneHotEncoding',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI used FeatureContributionCalculation with LightGbm trainer. My data pipeline contains OneHotEncoding features.\r\n- **What happened?**\r\nWhen I try to get feature contribution calculation I get the following exception\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Splitter/consolidator worker encountered exception while consuming source data\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.ColumnCursorExtensions.<GetColumnArrayDirect>d__3`1.MoveNext()\r\n   at System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at ConsoleApp1.Program.BuildTrainEvaluateAndSaveModel(MLContext mlContext) in C:\\Users\\vladimir.kuryshev\\source\\repos\\ConsoleApp1\\ConsoleApp1\\Program.cs:line 150\r\n   at ConsoleApp1.Program.Main(String[] args) in C:\\Users\\vladimir.kuryshev\\source\\repos\\ConsoleApp1\\ConsoleApp1\\Program.cs:line 45\r\n\r\nInner Exception 1:\r\nArgumentOutOfRangeException: Specified argument was out of the range of valid values.\r\nParameter name: slot\r\n\r\n   at Microsoft.ML.Data.VBuffer`1.GetItemOrDefault(Int32 slot)\r\n   at Microsoft.ML.Trainers.FastTree.InternalRegressionTree.AppendFeatureContributions(VBuffer`1& src, BufferBuilder`1 contributions)\r\n   at Microsoft.ML.Trainers.FastTree.InternalTreeEnsemble.GetFeatureContributions(VBuffer`1& features, VBuffer`1& contribs, BufferBuilder`1& builder)\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParameters.<>c__DisplayClass30_0`2.<Microsoft.ML.Model.IFeatureContributionMapper.GetFeatureContributionMapper>b__0(VBuffer`1& src, VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n```\r\n### Source code / logs\r\nMy code example\r\n```\r\n   IDataView trainingDataView = mlContext.Data.LoadFromTextFile<TaxiTrip>(TrainDataPath, hasHeader: true, separatorChar: \',\');\r\n   var dataProcessPipeline = mlContext.Transforms.CopyColumns(outputColumnName: DefaultColumnNames.Label, inputColumnName: nameof(TaxiTrip.FareAmount))\r\n                            .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: VendorIdEncoded, inputColumnName: nameof(TaxiTrip.VendorId)))\r\n                            .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: RateCodeEncoded, inputColumnName: nameof(TaxiTrip.RateCode)))\r\n                            .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: PaymentTypeEncoded, inputColumnName: nameof(TaxiTrip.PaymentType)))\r\n                            .Append(mlContext.Transforms.Normalize(outputColumnName: nameof(TaxiTrip.PassengerCount), mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n                            .Append(mlContext.Transforms.Normalize(outputColumnName: nameof(TaxiTrip.TripTime), mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n                            .Append(mlContext.Transforms.Normalize(outputColumnName: nameof(TaxiTrip.TripDistance), mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n                            .Append(mlContext.Transforms.Concatenate(DefaultColumnNames.Features, VendorIdEncoded, RateCodeEncoded, PaymentTypeEncoded, nameof(TaxiTrip.PassengerCount)\r\n                            , nameof(TaxiTrip.TripTime), nameof(TaxiTrip.TripDistance)));\r\n\r\n   var trainer = mlContext.Regression.Trainers.LightGbm(labelColumnName: DefaultColumnNames.Label, featureColumnName: DefaultColumnNames.Features);\r\n   var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n   var trainedModel = trainingPipeline.Fit(trainingDataView);\r\n   IDataView predictions = trainedModel.Transform(testDataView);\r\n\r\n   var featureContributionCalculation = mlContext.Model.Explainability.FeatureContributionCalculation(trainedModel.LastTransformer.Model);\r\n   var featureContributionData = featureContributionCalculation.Fit(predictions).Transform(predictions);\r\n   var contributions = featureContributionData.GetColumn<float[]>(mlContext, DefaultColumnNames.FeatureContributions).ToList();\r\n```\r\nI used standard data from ""taxi-fare-train.csv"" file from ML.Net examples.\r\n\r\n- **Note** Issue can\'t be reproduced If i remove OneHotEncoding from pipeline or change trainer to FastTree for example.'"
431606555,3271,b'Default NuGet page goes to older preview instead the latest version (RC)',"b'At the NuGet site, when you try to go to https://www.nuget.org/packages/Microsoft.ML/\r\nit redirects to an older version (0.11) instead of the latest version (1.0.0-preview).\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/55897527-8a3c0000-5b75-11e9-8b22-e68206f393b2.png)\r\n\r\n'"
431421527,3270,b'Expected vector<R4> Got R4',"b'Hi, I am currently trying to create a Model with a regression trainer\r\n\r\nHowever it seems I am loading my data incorrectly how should I proceed to load my ""YearsExperience"" as a Vector<R4> instead of a regular R4\r\n\r\nSample of data: \r\nYearsExperience;Salary\r\n1.1;39343.00\r\n\r\nThe way I load the data as an IDataView object\r\n`   IDataView trainingDataView = mlContext.Data.LoadFromTextFile<SalaryData>\r\n               (\r\n                   path: ""Data/SalaryData.csv"", hasHeader: true, separatorChar: \';\'\r\n               );\r\n`\r\n\r\nAlso I wonder is my pipeline correctly built? I am not sure about the mlContext.Transforms.Normalize(""YearsOfExperience"") at the start\r\n\r\n`var pipeline = mlContext.Transforms.Normalize(""YearsExperience"")\r\n                    .Append(mlContext.Transforms.Concatenate\r\n                    (\r\n                      ""Features"", ""YearsExperience""  \r\n                    ))\r\n                    .AppendCacheCheckpoint(mlContext)\r\n                    .Append(mlContext.Regression.Trainers.StochasticDualCoordinateAscent(labelColumnName: ""Salary"", featureColumnName: ""YearsExperience""));\r\n`'"
431390219,3269,b'Reading data files is possibly to restrictive',"b""### Issue\r\nReading a input file blocks a file from other processes from reading the same file.\r\n\r\nI'd suggest that the framework uses minimum restriction as to the codes least obtrusive available option. At the moment the interface does not allow the user to specify locking intention.\r\n\r\nThis may cause issues with those that train/ Analyse in parallel when there is no need for it. \r\n\r\n### Source code / logs\r\nA simle search shows FileStream Read locks without having specified the locking intend using the FileShare enumerator.\r\n\r\n\r\n```\r\n\\src\\Microsoft.ML.Core\\CommandLine\\CmdParser.cs(979):                using (FileStream file = new FileStream(fileName, FileMode.Open, FileAccess.Read))\r\n\\src\\Microsoft.ML.Core\\CommandLine\\CmdParser.cs(1050):                using (FileStream file = new FileStream(path, FileMode.Open, FileAccess.Read))\r\n\\src\\Microsoft.ML.Core\\Data\\IFileHandle.cs(192):                var stream = new FileStream(_fullPath, FileMode.Open, FileAccess.Read);\r\n\\src\\Microsoft.ML.Core\\Data\\Repository.cs(507):                stream = new FileStream(pathAbs, FileMode.Open, FileAccess.Read);\r\n\\src\\Microsoft.ML.Core\\Data\\Repository.cs(527):                    stream = new FileStream(pathTemp, FileMode.Open, FileAccess.Read);\r\n\\src\\Microsoft.ML.Core\\Utilities\\HybridMemoryStream.cs(166):            _overflowStream = new FileStream(overflowPath, FileMode.Open, FileAccess.ReadWrite,\r\n\\src\\Microsoft.ML.Data\\Utilities\\StreamUtils.cs(20):            return new FileStream(fileName, FileMode.Open, FileAccess.Read, FileShare.Read);\r\n\\src\\Microsoft.ML.ResultProcessor\\ResultProcessor.cs(468):                    using (Stream strm = new FileStream(testArgs.InputModelFile, FileMode.Open, FileAccess.Read))\r\n\\src\\Microsoft.ML.FastTree\\Dataset\\FileObjectStore.cs(105):            this.objectCacheMemoryMappedFile = MemoryMappedFile.CreateFromFile(this.fileStreamName, FileMode.OpenOrCreate);\r\n\\src\\Microsoft.ML.FastTree\\Dataset\\FileObjectStore.cs(219):            this.objectCacheFileStream = new FileStream(this.fileStreamName, FileMode.OpenOrCreate, FileAccess.ReadWrite, FileShare.ReadWrite);\r\n\\src\\Microsoft.ML.FastTree\\TreeEnsembleFeaturizer.cs(583):                    using (Stream strm = new FileStream(args.TrainedModelFile, FileMode.Open, FileAccess.Read))\r\n\\src\\Microsoft.ML.TensorFlow\\TensorflowTransform.cs(667):                        using (var fs = new FileStream(fullPath, FileMode.Open))\r\n```\r\n\r\n"""
431225243,3266,b'Remove Microsoft.ML prefix from namespaces in Samples binary',b'This forces the samples to include Microsoft.ML namespace.'
431096074,3260,b'Add a .vsconfig file',b'Visual Studio 2019 allows for a new mechanism to communicate requirements for the build: `.vsconfig` files. They contain information about which workloads and features of Visual Studio must be installed for a given project. You can tread more about them in ths [this blog post](https://devblogs.microsoft.com/setup/configure-visual-studio-across-your-organization-with-vsconfig/).\r\n\r\nIt would be nice to have such a file in the ML.NET repository to make it easier for people to check out & build the code.'
431083614,3258,b'Fix runtime exception in SDCA sample',b'Throws exception because it cannot find features and probability column. '
431061343,3256,b'LightGBM Ranking sample runtime exception',b'LightGBM ranking sample throws an exception because group column name is not specified. '
431057383,3255,b'Complete term review of all sources',b'Need to ensure that source content complies to term policies '
430821002,3254,"b'expected Expected float or float vector of known size, got Vec<R4>'","b""### System information\r\n\r\n```\r\n dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.0.100-preview3-010431\r\n Commit:    d72abce213\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.14\r\n OS Platform: Darwin\r\n RID:         osx.10.14-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/3.0.100-preview3-010431/\r\n\r\nHost (useful for support):\r\n  Version: 3.0.0-preview5-27606-03\r\n  Commit:  39eb528ff8\r\n```\r\n### Issue\r\n\r\n- **What did you do?**\r\nI've implemented the project by following the [GitHubLabeler](https://github.com/dotnet/machinelearning-samples/tree/master/samples/fsharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) sample. \r\n- **What happened?**\r\nWhen I run the code, I'm getting the following error:\r\n\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Schema mismatch for input column 'ArtistFeaturized_CharExtractor': expected Expected float or float vector of known size, got Vec<R4>\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Transforms.LpNormalizingTransformer.CheckInputColumn(DataViewSchema inputSchema, Int32 col, Int32 srcCol)\r\n   at Microsoft.ML.Data.OneToOneTransformerBase.OneToOneMapperBase..ctor(IHost host, OneToOneTransformerBase parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.LpNormalizingTransformer.Mapper..ctor(LpNormalizingTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Transforms.LpNormalizingTransformer.MakeRowMapper(DataViewSchema schema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.MakeDataTransform(IDataView input)\r\n   at Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.TrainCatalogBase.<>c__DisplayClass7_0.<CrossValidateTrain>b__0(Int32 fold)\r\n   at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n   at Microsoft.ML.MulticlassClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numFolds, String labelColumn, String samplingKeyColumn, Nullable`1 seed)\r\n   at Program.buildAndTrainTheModel(String dataSetLocation, String modelPath) in /Users/samuele.resca/Projects/LyricsClassifier/LyricsClassifier/Program.fs:line 72\r\n   at Program.main(String[] _argv) in /Users/samuele.resca/Projects/LyricsClassifier/LyricsClassifier/Program.fs:line 130\r\n```\r\n\r\n- **What did you expect?**\r\nIt seems that the training model expects only ` float or float vector of known size`.\r\n Why in the case of the  [GitHubLabeler](https://github.com/dotnet/machinelearning-samples/tree/master/samples/fsharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) \r\nwhich almost has the same data schema, doesn't perform any data transformation?\r\n\r\n### Source code / logs\r\n[LyricsClassifier](https://github.com/samueleresca/LyricsClassifier)"""
430685471,3248,b'Fix runtime exception in Image classification sample.',"b'This sample throws an exception for two reasons 1) model not found, should download the mode and unzip 2) even if the model exist it needs to set addBatchDimensionInput to true.'"
430655782,3243,b'SchemaShape.Column constructor is internal???',"b'`IEstimator` is a public interface that allows to create new estimators in ML.NET using NuGet only. The interface is public which defines two methods `Fit` and `GetOutputSchema`.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/1724da898d8cff88543fcf9e7b356ef0989b7bf7/src/Microsoft.ML.Core/Data/IEstimator.cs#L301\r\n\r\nThe `GetOutputSchema` method takes `SchemaShape` as input. The only way to create `SchemaShape` is through its constructor that takes `SchemaShape.Column` as input.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/1724da898d8cff88543fcf9e7b356ef0989b7bf7/src/Microsoft.ML.Core/Data/IEstimator.cs#L129\r\n\r\nHowever, the only constructor of `SchemaShape.Column`  is internal which blocks external user to create new estimators.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/1724da898d8cff88543fcf9e7b356ef0989b7bf7/src/Microsoft.ML.Core/Data/IEstimator.cs#L62\r\n\r\nHow can I create a new estimator using NuGet only?'"
430653508,3242,b'Clean up PFI Documentation',"b'The current documentation for Permutation Feature Importance does not cover a few use cases, and uses an old style.\r\n\r\nRelated to #1209'"
430627192,3239,b'Make it easier to use ML.NET in an ASP.NET app/service',"b'## Problem\r\nWith `1.0.0-preview` bits, it is currently harder than it needs to be to use ML.NET inside an ASP.NET service or application. The first problem users hit is whether they can cache a `PredictionEngine` statically and reuse it for multiple requests. As described in #1789, you cannot use a PredictionEngine on multiple threads at the same time. Doing so will cause problems in your application.\r\n\r\nThus the recommendation is to use a pooling technique, but writing one from scratch is rather hard and potentially error prone.\r\n\r\nAlso, by default the MLContext\'s Log operation is not aware of any logging infrastructure currently used by ASP.NET apps/services. Thus the log goes nowhere, and is lost.\r\n\r\n## Proposal\r\nWe propose to add a new library (`Microsoft.ML.Extensions?`, `Microsoft.Extensions.ML?`) that is aware of both `Microsoft.ML` and `Microsoft.Extensions.DependencyInjection`/`Microsoft.Extensions.Logging` and glues the two together. This should make it much easier to consume ML.NET models inside ASP.NET apps/services, as well as any other app model that integrates with the `Microsoft.Extensions.*` libraries.\r\n\r\n### Usage\r\nAdding a new ML.NET model into an ASP.NET application could be as simple as two steps:\r\n\r\n1. Add a PredictionEnginePool in your Startup.cs:\r\n\r\n```C#\r\n    // This method gets called by the runtime. Use this method to add services to the container.\r\n    public void ConfigureServices(IServiceCollection services)\r\n    {\r\n        services\r\n            .AddPredictionEnginePool<SentimentIssue, SentimentPrediction>(""SentimentModel.zip"");\r\n\r\n        // other service configuration\r\n    }\r\n```\r\n\r\n2. In any controller that needs to make a prediction, inject the PredictionEngine pool in the constructor, and use it where necessary:\r\n\r\n```C#\r\n[ApiController]\r\npublic class PredictionController : ControllerBase\r\n{\r\n    private PredictionEnginePool<SentimentIssue, SentimentPrediction> _predictionEnginePool;\r\n\r\n    public PredictionController(PredictionEnginePool<SentimentIssue, SentimentPrediction> predictionEnginePool)\r\n    {\r\n        _predictionEnginePool = predictionEnginePool;\r\n    }\r\n\r\n    [HttpGet()]\r\n    public ActionResult<SentimentPrediction> GetSentiment([FromQuery]SentimentIssue input)\r\n    {\r\n        return _predictionEnginePool.Predict(input);\r\n    }\r\n}\r\n```\r\n\r\n### Other potential scenarios\r\n1. Being able to add a model `.zip` file from sources other than a file path\r\n    1. Azure Blob Storage\r\n    2. A SQL Database\r\n    3. Any URL\r\n2. Being able to automatically reload an updated model, if the file/URL changes (using FileWatcher or ETag or some other mechanism).\r\n3. Being able to have different ""named"" models for scenarios like A/B testing where you want 90% of users to get Model A and 10% to get Model B.\r\n\r\n@glennc @CESARDELATORRE @glebuk @TomFinley '"
430599088,3238,b'GetNormalizerModelParameters would be nice to accept name of column instead of index',"b'```\r\nvar normalize = mlContext.Transforms.NormalizeMinMax(new InputOutputColumnPair[] { new InputOutputColumnPair(""ANorm"", ""A""), new InputOutputColumnPair(""BNorm"", ""B"") }, fixZero: false);\r\n```\r\n\r\nSo right now in order to get parameters for `BNorm` column I need to do this:\r\n```\r\n (normalizeTransform.GetNormalizerModelParameters(1) as Microsoft.ML.Transforms.NormalizingTransformer.AffineNormalizerModelParameters<ImmutableArray<float>>);\r\n```\r\n\r\nCan we have another function which would accept name of column instead of index in `InputOutputColumnPair` array?\r\n\r\n```\r\n (normalizeTransform.GetNormalizerModelParameters(""BNorm"") as Microsoft.ML.Transforms.NormalizingTransformer.AffineNormalizerModelParameters<ImmutableArray<float>>);\r\n```'"
430591769,3236,b'DNN Featurizer sample bug.',b'DNN featurizer sample throws an exception because it cannot find the Resnet ONNX model.'
430583719,3235,b'Log Verbosity Handling in MLContext',"b""When subscribing to logs from MLContext, there may not be an easy / future-proof way to know the verbosity level of each returned log statement.\r\nAlso, when subscribing to logs, for one pipeline I ran, the logger returned a total of about 255 KB of text (lots of 'Trace'-level logs). Perhaps it could be convenient for a user, when subscribing to logs, to be able to specify a minimum log severity level if desired. (For instance, a user could subscribe to 'Warning'-level logs and above.)\r\nThanks for reading"""
430571441,3234,b'CreatePredictionEngine  overrides inputSchemaDefinition by calling into DataViewConstructionUtils.GetSchemaDefinition',"b'It seems `CreatePredictionEngine`  overrides `inputSchemaDefinition` by calling into `DataViewConstructionUtils.GetSchemaDefinition`. This is problematic if some of the features of input schema is determined at runtime, example, length of feature vector. \r\n\r\n```csharp\r\n            ITransformer trainedModel;\r\n            using (var stream = new FileStream(modelFileFullPath, FileMode.Open, FileAccess.Read, FileShare.Read))\r\n            {\r\n               var trainedModel = mlContext.Model.Load(stream, out var inputSchema);\r\n               var = mlContext.Model.CreatePredictionEngine<TInput, TOutput>(trainedModel, inputSchemaDefinition: inputSchema); \r\n\r\n//Throws an exception features<vector<single>> does not match features<vector<single, 432>> because CreatePredictionEngine returns transformer.CreatePredictionEngine<TSrc, TDst>(_env, false, DataViewConstructionUtils.GetSchemaDefinition<TSrc>(_env, inputSchema)); and `DataViewConstructionUtils.GetSchemaDefinition` overrides inputSchema.\r\n\r\n            }\r\n\r\n//Below workaround that overrides the override!\r\n\r\nusing (var stream = new FileStream(modelFileFullPath"", FileMode.Open, FileAccess.Read, FileShare.Read))\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 {\r\n\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 var trainedModel = mlContext.Model.Load(stream, out var inputSchema);\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 var outputSchemaDefinition = SchemaDefinition.Create(typeof(TInput));\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 outputSchemaDefinition[""Features""].ColumnType = new VectorDataViewType(NumberDataViewType.Single, Convert.ToInt32(432));\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 var p = mlContext.Model.CreatePredictionEngine<TInput, TOutput>(trainedModel, inputSchemaDefinition: outputSchemaDefinition);\r\n\xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 \xc2\xa0 }\r\n\r\n```\r\n\r\nCC: @TomFinley '"
430564280,3233,b'Clean up FCC Documentation',"b'The current documentation for the Feature Contribution Calculator is not showing up on the docs site, and needs minor changes.\r\n\r\nRelated to #1209 '"
430548234,3231,b'Fix bug in ONNX scorer sample',b'ONNX scorer transformer sample throws an exception today because it cannot find the model file. This PR fixes that.'
430161963,3229,b'Deep Learning with ML.NET',"b""I checked available documentation for ML.NET and didn't find any help regarding Deep Learning Framework. Is Deep Learning possible with ML.NET ? Like CAFFE deep learning framework ? I need Deep learning framework for Dot Net. Is it possible with ML.NET ?"""
430076989,3228,b'Overflow in MultiClassNaiveBayes',"b""We're storing the count of rows in an `int`. This causes an overflow for large datasets. In my case, Criteo 1TB w/ 4.4B rows. Recommend changing to a `long`.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d2bf3e72fa935b12644b0a695ad0d044a8077a83/src/Microsoft.ML.StandardTrainers/Standard/MulticlassClassification/MulticlassNaiveBayesTrainer.cs#L242\r\n\r\nError:\r\n```\r\nUnexpected exception: Arithmetic operation resulted in an overflow., 'System.OverflowException'\r\n   at System.Linq.Enumerable.Sum(IEnumerable`1 source)\r\n```"""
429958911,3226,b'NaiveBayes doesnt produce meaningful result on simple dataset',b'Use the same dataset as in  PR #3159 for NB but get garbage results no matter how good is separation among classes'
429944690,3224,b'Ensure we have the proper attribution for MurmurHash3 algorithm',b'We should ensure we have the correct attribution for\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.DataView/DataViewRowId.cs#L72-L76\r\n\r\nand\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Core/Utilities/Hashing.cs#L109-L115\r\n\r\nWe should ensure this is in our third-party notice and any other attributions that are necessary.\r\n\r\n@richlander @shauheen '
429873479,3219,b'Remove files with GPL v2 license from the repo',b'The following files with GPLv2 license need to be removed from the repo:\r\n\r\n- test/data/gplv2/infert.csv\r\n- test/data/gplv2/COPYING.txt\r\n- test/data/gplv2/airquality.csv\r\n\r\n'
429872637,3218,b'API reference - Finalize docs template for trainer API & estimators',"b'Currently API reference documentation for each trainer is split into two pages: 1) the creation method, and 2) the trainer estimator class. We also have a 3rd page for trainer options. In this issue, I want to reach a consensus about the content that goes in each page. The current proposal is as follows:\r\n\r\n# Page-1 - Creation extension methods\r\nThese methods act as the constructor for the trainer estimator class. There are two overloads per trainer and they\'re listed as extension methods in a MLContext trainer catalog. E.g. [BinaryClassificationCatalog.BinaryClassificationTrainers](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.binaryclassificationtrainers?view=ml-dotnet&branch=smoke-test-preview). \r\n\r\nBoth overloads also show up in the same page for the extension class; we call this page-1 (e.g. [LightGbm](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_LightGbmExtensions_LightGbm_Microsoft_ML_BinaryClassificationCatalog_BinaryClassificationTrainers_System_String_System_String_System_String_System_Nullable_System_Int32__System_Nullable_System_Int32__System_Nullable_System_Double__System_Int32_); please note that this page includes all LightGbm overloads including multiclass, ranking, etc and not just binary classification versions).\r\n\r\n### Summary\r\n1-liner summary of what the trainer does, then ""cref=the estimator class, i.e. page-2""\r\nTraining algorithm details are not here, and are included in page-2, so that other overloads of this  APIs share the same content.\r\n\r\n### Remarks\r\n[Gleb: add optional description for current overload]\r\n\r\n### Parameters\r\nParameters are defined\r\n\r\n### Example\r\nOne example is provided for this API (one per overload)\r\n\r\n# Page-2 - Trainer Estimator Class\r\nThis is the page for trainer estimator class. E.g. [LightGbmBinaryTrainer](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmbinarytrainer?view=ml-dotnet&branch=smoke-test-preview) \r\n\r\n### Summary\r\n1-liner summary of what the trainer does with ""cref=IEstimator(TTransformer)"". [Gleb: add info on when it is good to use it. - answer the WHY question.] [Gleb: Add link to options in summary]\r\nTraining algorithm details are not in the summary.\r\n\r\n### Remarks\r\nNote about creation: ""For creating this trainer please see ""cref to both overload methods from page-1""\r\n\r\nEasy properties:\r\n* Machine learning task: (redundant?)\r\n* Expected label type: bool, etc\r\n* Output columns: ""Score"", ""PredictedLabel"", etc with description of what each does\r\n* Is normalization required? Yes/No\r\n* Is caching required? Yes/No\r\n* Is convertible to Onnx format? Yes/No\r\n* Additional NuGet: ""Link to NuGet"" OR None of all that are included already in Microsoft.ML\r\n\r\nComplex properties:\r\n* Trainer Category (requires some taxonomy to be created)\r\n* When to use this trainer? [what goes here?]\r\n* Supported number of features?\r\n* Supported number of examples?\r\n\r\nTraining algorithm details with all the reference links.\r\n\r\n### Example\r\nRepeat example from overload-1 of page-1\r\nRepeat example from overload-2 of page-1\r\n\r\n### See also\r\n""cref to both overload methods from page-1""\r\n[Gleb: link to the catalog with those learners?]\r\n[Gleb: links to other similar learners?]\r\n[Gleb: links to options?]\r\n\r\n\r\n# Page-3 - Trainer Options Class\r\nThis is the page for trainer options class that\'s used in one of the overloads in page-1. E.g. [AveragedPerceptronTrainer.Options](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.averagedperceptrontrainer.options?view=ml-dotnet&branch=smoke-test-preview)\r\n\r\nPage-1 already links to this page from the type of the option parameter.\r\n\r\n### Summary\r\nOptions for ""cref=page-2"" as used in method ""cref=page-1/overload-with-option"".\r\n\r\n### Remarks\r\nNone\r\n\r\n### Example\r\nNone (page-1 already includes an example for using the options)\r\n\r\n### Parameters\r\nParameters are defined\r\n\r\n### See also\r\n[Gleb: the factory methods, the estimator]\r\n\r\n/cc @glebuk @sfilipi '"
429540526,3209,b'[1.0.0-preview] Bug? - Getting an exception while loading .ZIP model MultiClass-Classification trained with SdcaNonCalibrated',"b""I am trying to migrate IRIS Classification sample in the repo [here](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/MulticlassClassification_Iris) to **v1.0.0-preview**.\r\n\r\nWhile loading the model for prediction I am getting the below error at the statement \r\n\r\n                trainedModel = mlContext.Model.Load(stream, out var modelInputSchema);\r\n\r\n\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Error during class instantiation\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at MulticlassClassification_Iris.Program.TestSomePredictions(MLContext mlContext) in C:\\GitRepos\\machinelearning-samples-v1.0.0-Preview\\samples\\csharp\\getting-started\\MulticlassClassification_Iris\\IrisClassification\\IrisClassificationConsoleApp\\Program.cs:line 99\r\n   at MulticlassClassification_Iris.Program.Main(String[] args) in C:\\GitRepos\\machinelearning-samples-v1.0.0-Preview\\samples\\csharp\\getting-started\\MulticlassClassification_Iris\\IrisClassification\\IrisClassificationConsoleApp\\Program.cs:line 36\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 2:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 3:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 4:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 5:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 6:\r\nFormatException: Couldn't load model: 'TransformerChain\\Transform_002\\Transform_000\\Model'\r\n\r\n```\r\nthe dataset format is like this \r\n\r\n```\r\n#Label\tSepal length\tSepal width\tPetal length\tPetal width\r\n0\t5.4\t3.7\t1.5\t0.2\r\n0\t4.8\t3.4\t1.6\t0.2\r\n0\t4.8\t3.0\t1.4\t0.1\r\n0\t4.3\t3.0\t1.1\t0.1\r\n```\r\n\r\n\r\nI have pushed the code to the Github repo  here https://github.com/dotnet/machinelearning-samples/tree/migration/1.1.0-preview/samples/csharp/getting-started/MulticlassClassification_Iris\r\n\r\nI did not understand the reason for the error. Could anyone help"""
429452655,3207,b'Error for KeyType attribute without initializing the Count ',"b'The KeyType attribute has a public parameterless constructor, that initializes [the Count to int.maxInt ](https://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.Data/Data/SchemaDefinition.cs#L398).\r\n\r\nWhen we process the KeyTypes with  [KeyToMappingTransformer ](https://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L252) we [check that the Count of the KeyType is less than maxInt](https://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.Core/Data/ColumnTypeExtensions.cs#L37).  \r\n\r\nThe error message is that the \'counts exceeds int.MaxValue\', which for the case described (user annotating with the parameterless KeyType) leads to error. \r\n\r\nEither don\'t expose the parameterless KeyType constructor, or initialize to somethign else (MaxInt- 1?, is such a  large number even practical?) or accept MaxInt as a valid value. \r\n\r\n@TomFinley  @eerhardt @glebuk for suggestions. \r\n\r\nCode to repro\r\n```\r\n    class MapKeyToVector\r\n    {\r\n        /// This example demonstrates the use of the ValueMappingEstimator by mapping strings to other string values, or floats to strings. \r\n        /// This is useful to map types to a category. \r\n        public static void Example()\r\n        {\r\n            // Create a new ML context, for ML.NET operations. It can be used for exception tracking and logging, \r\n            // as well as the source of randomness.\r\n            var mlContext = new MLContext();\r\n\r\n            // Get a small dataset as an IEnumerable.\r\n            var rawData = new[] {\r\n                new DataPoint() { Timeframe = 45, Category = 5 },\r\n                new DataPoint() { Timeframe = 15, Category = 4 },\r\n                new DataPoint() { Timeframe = 65, Category = 4 },\r\n                new DataPoint() { Timeframe = 25, Category = 3 },\r\n                new DataPoint() { Timeframe = 45, Category = 3 },\r\n                new DataPoint() { Timeframe = 45, Category = 5 }\r\n            };\r\n\r\n            var data = mlContext.Data.LoadFromEnumerable(rawData);\r\n\r\n            // Constructs the ML.net pipeline\r\n            var pipeline = mlContext.Transforms.Conversion.MapKeyToVector(""TimeframeVector"", ""Timeframe"")\r\n                           .Append(mlContext.Transforms.Conversion.MapKeyToVector(""CategoryVector"", ""Category"", outputCountVector: true));\r\n\r\n            // Fits the pipeline to the data.\r\n            IDataView transformedData = pipeline.Fit(data).Transform(data);\r\n        }\r\n\r\n        private class DataPoint\r\n        {\r\n            [KeyType]\r\n            public uint Timeframe { get; set; }\r\n\r\n            [KeyType]\r\n            public uint Category { get; set; }\r\n\r\n        }\r\n}'"
429420795,3206,b'ONNX Exports are Lossy',"b'As shown in the [ONNX Functional Tests](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/ONNX.cs), export to ONNX models are lossy: They are not high-fidelity representations of the original ML.NET model and agree numerically to a relatively lower precision than expected.'"
429418962,3205,"b""API reference - Remove Microsoft.ML prefix from samples' namespace""",b'Currently the samples are written like this:\r\n\r\n```csharp\r\nnamespace **Microsoft.ML**.Samples.Dynamic.*\r\n{ \r\n}\r\n```\r\nThis is causing the samples to not require `using Microsoft.ML`. We want to drop the Microsoft.ML prefix from samples and write them like this:\r\n\r\n```csharp\r\nnamespace Samples.Dynamic.*\r\n{ \r\n}\r\n```\r\n'
429393248,3204,b'API reference - XML documentation template for transforms',"b'The XML documentation for the transforms should contain information about the schema: requirements about the type of the columns to work on, and information about the type of the columns produced. \r\n\r\n@shmoradims \r\n'"
429317754,3203,b'Extension methods from TimeSeriesStatic.cs (A Typo and A Missing Nuget for Static Time Series)',"b'### System information\r\n\r\n- Windows 10 Pro\r\n- .NET 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to use extension method `DetectSpikeBySsa` from class `SsaSpikeDetecotStaticExtensions` (there\'s a typo in the name btw). I\'m using static API and TimeSeries package.\r\n\r\n- **What happened?**\r\nThe extension method (and any other extension methods from that namespace) is not available to use on Scalar\\<float\\> type.\r\nI am using `SsaSpikeDetection()` test from `TimeSeriesStaticTests.cs` as a reference.\r\n\r\n- **What did you expect?**\r\nExpected usage (from the referenced test):\r\n```cs\r\nvar staticLearningPipeline = staticData.MakeNewEstimator()\r\n                .Append(r => r.Value.DetectSpikeBySsa(80, ChangeHistoryLength, TrainingWindowSize, SeasonalityWindowSize));\r\n```\r\nbut `DetectSpikeBySsa` is not available on my Scalar\\<float\\>.\r\n\r\n### Source code / logs\r\n\r\n```cs\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Transforms;\r\nusing Microsoft.ML.Transforms.TimeSeries;\r\nusing Microsoft.ML.StaticPipe;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace xxx.Modules.Data.ML.Dev\r\n{\r\n    public class DataLoader\r\n    {\r\n        private sealed class SpikePrediction\r\n        {\r\n            [VectorType(3)]\r\n            public double[] Data;\r\n        }\r\n\r\n        private class DataObject\r\n        {\r\n            public float Gain { get; set; }\r\n        }\r\n\r\n        public DataLoader()\r\n        {\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var loader = mlContext.Data.CreateTextLoader(ctx => (\r\n                    Id: ctx.LoadText(0),\r\n                    Begin: ctx.LoadText(1),\r\n                    End: ctx.LoadText(2),\r\n                    Gain: ctx.LoadFloat(3),\r\n                    Confidence: ctx.LoadFloat(4)\r\n                ), separator: \',\', hasHeader: true);\r\n\r\n            var data = loader.Load(""output_intervals.csv"");\r\n\r\n            var preview = data.AsDynamic.Preview();\r\n\r\n            var learningPipeline = loader.MakeNewEstimator()\r\n                .Append(r => (\r\n                    r.Gain.DetectSpikeBySsa(80, 800 / 4, 800 / 2, 800 / 8) // Cannot resolve symbol...\r\n                ));\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nIncluded packages:\r\n```\r\n<packages>\r\n  <package id=""Castle.Core"" version=""4.2.1"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.CpuMath"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.DataView"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.Experimental"" version=""0.12.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.FastTree"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.ImageAnalytics"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.Mkl.Redist"" version=""1.0.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.Recommender"" version=""0.12.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.StaticPipe"" version=""0.12.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Microsoft.ML.TimeSeries"" version=""0.12.0-preview"" targetFramework=""net461"" />\r\n  <package id=""Newtonsoft.Json"" version=""10.0.3"" targetFramework=""net461"" />\r\n  <package id=""NLog"" version=""4.6.1"" targetFramework=""net461"" />\r\n  <package id=""System.Buffers"" version=""4.4.0"" targetFramework=""net461"" />\r\n  <package id=""System.CodeDom"" version=""4.4.0"" targetFramework=""net461"" />\r\n  <package id=""System.Collections.Immutable"" version=""1.5.0"" targetFramework=""net461"" />\r\n  <package id=""System.Drawing.Common"" version=""4.5.0"" targetFramework=""net461"" />\r\n  <package id=""System.Memory"" version=""4.5.1"" targetFramework=""net461"" />\r\n  <package id=""System.Numerics.Vectors"" version=""4.4.0"" targetFramework=""net461"" />\r\n  <package id=""System.Reactive"" version=""4.0.0"" targetFramework=""net461"" />\r\n  <package id=""System.Reflection.Emit.Lightweight"" version=""4.3.0"" targetFramework=""net461"" />\r\n  <package id=""System.Runtime.CompilerServices.Unsafe"" version=""4.5.0"" targetFramework=""net461"" />\r\n  <package id=""System.Threading.Tasks.Dataflow"" version=""4.8.0"" targetFramework=""net461"" />\r\n  <package id=""System.ValueTuple"" version=""4.4.0"" targetFramework=""net461"" />\r\n  <package id=""WampSharp"" version=""19.3.1"" targetFramework=""net461"" />\r\n</packages>\r\n```\r\n'"
429316614,3202,b'LoadColumn Attribute Inconsistent Behavior for Vector Properties Between File and In-Memory Sources',"b'Given the following data model / schema where `Features` is a float vector:\r\n\r\n```csharp\r\npublic class IrisData\r\n{\r\n    [LoadColumn(0,2)]\r\n    public float Features { get; set; }\r\n    [LoadColumn(3)]\r\n    public float Label { get; set; }\r\n}\r\n```\r\n\r\nWhen loading data from a file and applying transformations, there are no errors and transforms work as expected. However, when trying to use the same data model / schema to create and score with in-memory data, there are errors as shown in the screenshot below:\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/55563915-caf2cf80-56c4-11e9-92e6-016c4932b9d7.png)\r\n\r\nWorkarounds both involve the use of the `VectorType` attribute on the property that loads columns together. Two suggestions are:\r\n\r\na) Add the `VectorType` attribute to the original model and change property type to `float[]`\r\n\r\n```csharp\r\npublic class IrisData\r\n{\r\n    [LoadColumn(0,2)]\r\n    [VectorType(3)]\r\n    public float[] Features { get; set; }\r\n    [LoadColumn(3)]\r\n    public float Label { get; set; }\r\n}\r\n```\r\n\r\na) In addition to the original input class `IrisData` that was used to load from a file and train the model, create a new input class (IrisDataFlotArrayValues) to define the data model / schema for in-memory data. This new class adds the `VectorType` attribute to the property that loads columns together and changes the property type from a `float` to `float[]`.\r\n\r\n```csharp\r\npublic class IrisDataFloatArrayFeatures{\r\n    [LoadColumn(0,2)]\r\n    [VectorType(3)]\r\n    public float[] Features { get; set; }\r\n    [LoadColumn(3)]\r\n    public float Label { get; set; }\r\n}\r\n```\r\n\r\nSince `LoadColumn` works for file data, it would be preferable to reuse the same data model / schema for in-memory data. Additionally, simply converting the property type to `float[]` without the `VectorType` attribute does not work when trying to apply transforms since the framework does not automatically pick up that the `float[]` property is a vector like it otherwise would with `LoadColumn` annotation leaving it to the user to manually convert the property to a vector.'"
429306551,3201,b'Normalize Transform on In-Memory Data Returns Zero',"b'Given the code below:\r\n\r\n```csharp\r\nstatic void RunNormalizeExample()\r\n{\r\n    MLContext mlContext = new MLContext();\r\n\r\n    SampleData[] inMemoryCollection = new SampleData[]\r\n    {\r\n        new SampleData {Features = new float[] {5.1f,3.5f,1.4f}}\r\n    };\r\n\r\n    IDataView data = mlContext.Data.LoadFromEnumerable<SampleData>(inMemoryCollection);\r\n\r\n    IEstimator<ITransformer> dataPrep = mlContext.Transforms.Normalize(""Features"");\r\n        \r\n    ITransformer dataPrepTransformer = dataPrep.Fit(data);\r\n\r\n    IDataView transformedDataView = dataPrepTransformer.Transform(data);\r\n\r\n    var transformedFeatures = transformedDataView.GetColumn<float[]>(mlContext, ""Features"").ToList();\r\n}\r\n```\r\n\r\nWhere the schema for `SampleData` is the following:\r\n\r\n```csharp\r\npublic class SampleData\r\n{\r\n    [VectorType(3)]\r\n    public float[] Features { get; set; }\r\n    public float Label { get; set; }\r\n}\r\n```\r\n\r\nThe values in `transformedFeatures` which are the normalized values using the default (MinMax) implementation of `Normalize` are all zero.\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/55562853-cf1ded80-56c2-11e9-8ee4-d178168d7876.png)\r\n'"
429301300,3200,b'Templates support for Visual Studio 2019',b'Add support for Visual Studio 2019 in templates\r\nhttps://marketplace.visualstudio.com/items?itemName=MLNET.07\r\n'
429027388,3198,b'OptmizationTolerance public trainer API options misspelling',"b'Should be ""Optim"" instead of ""Optm"". Misspelling occurs on the public API for some trainers, like\r\nhttps://github.com/dotnet/machinelearning/blob/b6c5b703de4bdc2e0212597075223f4710dc98da/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs#L54'"
429021548,3197,b'internal class GraphRunner needs to be exposed for NimbusML',b'Version 0.12.0-preview\r\ninternal sealed class GraphRunner  breaks NimbusML build as the class can not be found.\r\nNeed [BestFriend] attribute'
429020485,3196,b'Custom Exception exposes .Message',"b'Related to: VSO Task [799758](https://devdiv.visualstudio.com/DevDiv/_workitems/edit/799758)\r\n\r\nSecurity guidelines for release include the following for exposing sensitive data.\r\n\r\nApplications MUST NOT expose sensitive application data to end-users through error messages. This can be achieved by trapping all errors or exceptions within an application and exposing only a generic, innocuous message to the end-user. For example:\r\n\r\n- If a user attempts to login to a resource using a username/password combination, failures MUST NOT disclose whether it was the username or password that was incorrect. Instead, a more generic error message such as ""Invalid credentials, please try again."" should be displayed to the user.\r\n- For custom exception classes, display MUST NOT include direct output from .ToString(), .Message, or .StackTrace. On other platforms, similar guidance applies.\r\n- For web applications, a generic ""HTTP 500"" page SHOULD BE returned instead of a stack trace. This can be enabled within IIS through customer error pages (via CustomErrors).\r\n\r\n\r\nFound one instance of a custom exception class having .Message exposed. I don\'t think exposing a message related to premature convergence is in any way exposing sensitive information, but filing this issue for the sake of completeness. \r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.StandardTrainers/Standard/LogisticRegression/LbfgsPredictorBase.cs#L575-L581\r\n\r\ncc: @glebuk @TomFinley '"
429009394,3193,b'Exception Swallowing issues',"b'Related to: VSO Task [799764](https://devdiv.visualstudio.com/DevDiv/_workitems/edit/799764)\r\n\r\nSecurity guidelines for release include the following for exception handling.\r\n\r\nException Handlers\r\nAll new product code must be free of ""swallow everything"" exception handlers:\r\n\r\n- C code must not catch and dismiss all SEH exceptions or SEH exceptions that your application cannot responsibly handle.\r\n- In unmanaged C++ code, do not enable asynchronous exception handling [/EHa flag] in combination with catching and ""swallowing"" all exceptions.\r\n/Eha has the side-effect of swallowing all exceptions from hardware (ex. floating point exceptions, division by zero, and access violations) when catch(\xe2\x80\xa6) is used.\r\n- In managed code do not use HandleProcessCorruptedStateExceptionsAttribute in combination with catching and ""swallowing"" all exceptions.\r\n- Recover only on exceptions that your application can handle safely, and let all other exceptions pass through.\r\n\r\n\r\nReviewing the repo, I found the following cases that looked questionable to me in src folder (ignoring test folder).  Please see if any of these requires more adequate handling.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/CommandLine/CmdParser.cs#L1895-L1898\r\n\r\nShould we inform user what the exception is here and then return null?\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/ComponentModel/AssemblyLoadingUtils.cs#L213-L216\r\n\r\nShould we raise the actual error instead of just saying that Action xyz failed in IFileHandle?\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/Data/IFileHandle.cs#L110-L114\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/Data/IFileHandle.cs#L125-L129\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/Data/IFileHandle.cs#L142-L146\r\n\r\nA comment explaining that this should not throw.\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/Data/Repository.cs#L181-L183\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Core/Data/Repository.cs#L381-L383\r\n\r\nSee the review comment here.\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.Data/DataLoadSave/Binary/BinaryLoader.cs#L1384-L1393\r\n\r\nAn error message here?\r\nhttps://github.com/dotnet/machinelearning/blob/ac53748721939024d85e984c0b8911dbb1af3339/src/Microsoft.ML.TensorFlow/TensorFlow/TensorflowUtils.cs#L206-L207\r\n\r\ncc: @glebuk @TomFinley '"
428975243,3192,b'LDA always prints to console',b'Run LDA documentation sample:\r\n```\r\nusing 10 thread(s) to do train/test\r\nmem_block_size = 252\r\nalias_mem_block_size = 348\r\nstarted training with 10 threads\r\nIter: 0000      Thread = 0      Tokens: 29      Took: 0.0002612 sec     Throughput: 111026 token/(thread*sec)\r\nTotal likelihood: -210.838      ..........[Nomralized word ll: -323.375 Word  likelihood: 174.678       Doc   likelihood: -62.1403]\r\n```\r\nand so on without any option to turn it off.'
428898327,3190,b'API reference: Add a sanity test that ensures samples are runnable',"b""This is a simpler version of #2954.\r\n\r\nWe need to make sure all the samples are runnable. Basically we'd need to look inside Microsoft.ML.Samples with reflection and run all static methods called Example()."""
428744072,3188,"b""Evaluation ArgumentOutOfRangeException 'Score not found' and predicted val=0""","b'### System information\r\n\r\n- OS version/distro: Windows 10\r\n- .NET Version (eg., dotnet --info): Core 2.1 \r\n\r\n### Issue\r\n\r\n- What did you do?\r\nTrying to implement Movie recommendation example from: https://docs.microsoft.com/pl-pl/dotnet/machine-learning/tutorials/movie-recommmendation#other-recommendation-algorithms\r\n- What happened?\r\nReturned predicted values are 0. While model evaluation there is an error: ArgumentOutOfRangeException \'Score not found\'\r\n- What did you expect?\r\nReturns wellpredicted rating values. evaluation proccess ends successfully and returns R2 error.\r\n\r\n### Source code / logs\r\n\r\nModels:\r\n```C#\r\npublic class MovieRating\r\n{\r\n    [LoadColumn(0)]\r\n    public string userId;\r\n\r\n    [LoadColumn(1)]\r\n    public string movieId;\r\n\r\n    [LoadColumn(2)]\r\n    public float Label;\r\n}\r\n\r\npublic class MovieRatingPrediction\r\n{\r\n    [ColumnName(""Label"")]\r\n    public float Label;\r\n       \r\n    [ColumnName(""Score"")]\r\n    public float Score;\r\n}\r\n```\r\nTraining:\r\n```C#\r\nIEstimator<ITransformer> estimator = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""userIdEncoded"", inputColumnName: ""userId"")\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""movieIdEncoded"", inputColumnName: ""movieId""));\r\n\r\nvar options = new MatrixFactorizationTrainer.Options\r\n            {\r\n                MatrixColumnIndexColumnName = ""userIdEncoded"",\r\n                MatrixRowIndexColumnName = ""movieIdEncoded"",\r\n                LabelColumnName = ""Label"",\r\n                NumberOfIterations = 20,\r\n                ApproximationRank = 100\r\n            };\r\n\r\nvar trainerEstimator = estimator.Append(mlContext.Recommendation().Trainers.MatrixFactorization(options));\r\n\r\nvar trained_model = estimator.Fit(dataView);\r\n```\r\nSingle prediction:\r\n```C#\r\nvar predictionFunction = loadedModel.CreatePredictionEngine<MovieRating, MovieRatingPrediction>(mlContext);\r\n\r\nvar prediction = predictionFunction.Predict(new MovieRating { userId = ""1"", movieId = ""2"" });\r\n\r\nLog(""Predicted rating: "" + prediction.Score);\r\n```\r\nEvaluation:\r\n\r\n```C#\r\nvar predictions = model.Transform(dataView);\r\n\r\nvar metrics = mlContext.Regression.Evaluate(data: predictions, label: ""Label"", score: ""Score"");\r\n```\r\nEvaluation error\r\n```C#\r\nSystem.ArgumentOutOfRangeException: \xe2\x80\x9eScore column \'Score\' not found\xe2\x80\x9d\r\n```'"
428533121,3186,b'How to transform Date column into C# DateTime Column?',"b'I\'m working on a specific regression problem which provides Date of journey in string in dd/MM/yyyy format. How can I GetColumn as C# DateTime datatype column?\r\n\r\n```\r\npublic class IssueSample\r\n{\r\n        [LoadColumn(0)]\r\n        public string Col1;\r\n        [LoadColumn(1)]\r\n        public string DateOfJourneyStr;\r\n        \r\n        private const string DATETIME_FORMAT = ""dd/MM/yyyy"";\r\n        public DateTime? DateOfJourney\r\n            => ParseDateTime(DateOfJourneyStr);\r\n        public static DateTime? ParseDateTime(string dateOfJourneyStr)\r\n        {\r\n            if (DateTime.TryParseExact(dateOfJourneyStr, DATETIME_FORMAT, CultureInfo.InvariantCulture, DateTimeStyles.None, out var result))\r\n                return result;\r\n            return null;\r\n        }\r\n}\r\n```\r\n\r\nI\'m trying to get Min and Max DateOfJourney values as following:\r\n```\r\nprivate static void BuildTrainEvaluateAndSaveModel(MLContext mlContext)\r\n        {\r\n            // STEP 1: Common data loading configuration\r\n            IDataView baseTrainingDataView = mlContext.Data.LoadFromTextFile<IssueSample>(TrainDataPath, hasHeader: true, separatorChar: \',\');\r\n            IDataView testDataView = mlContext.Data.LoadFromTextFile<IssueSample>(TestDataPath, hasHeader: true, separatorChar: \',\');\r\n\r\n            var dateOfJourneyMin = baseTrainingDataView.GetColumn<DateTime?>(mlContext, nameof(IssueSample.DateOfJourney)).Min();\r\n            System.Console.WriteLine($""Min DateOfJourney = {dateOfJourneyMin}"");\r\n            var dateOfJourneyMax = baseTrainingDataView.GetColumn<DateTime?>(mlContext, nameof(IssueSample.DateOfJourney)).Max();\r\n            System.Console.WriteLine($""Max DateOfJourney = {dateOfJourneyMax}"");\r\n        }\r\n```\r\n\r\nBut I get an error as follows: \r\n\r\n> System.ArgumentOutOfRangeException: \'Could not find input column \'DateOfJourney\'\r\n> Parameter name: columnName\'\r\n\r\nCould somebody suggest how to achieve this in ML.NET?'"
428370621,3175,b'Auc is NaN when loading data from IEnumerable',"b'I am getting below error when I am evaluating the model.\r\n\r\nSystem.ArgumentOutOfRangeException: \'AUC is not definied when there is no negative class in the data\r\nParameter name: NegSample\'\r\n### Source code / logs\r\n\r\nThe values of  label column are **true**/**false**. I applied transformation on label using MapValuetoKey to convert true to 1 and false to 0. But I still get the error while evaluating.\r\n\r\nSee the below code.\r\n\r\n```csharp\r\nusing System;\r\nusing System.IO;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.Data.DataView;\r\nusing System.Collections.Generic;\r\n\r\nnamespace MLNETConsoleApp3\r\n{\r\n    class Program\r\n    {\r\n        static void Main()\r\n        {\r\n            // 1. Implement the pipeline for creating and training the model    \r\n            var mlContext = new MLContext();\r\n            var trainingData = GetTrainingData();\r\n            var TestData = GetTestData();\r\n\r\n            // 2. Specify how training data is going to be loaded into the DataView\r\n            IDataView trainingDataView = mlContext.Data.LoadFromEnumerable(trainingData);\r\n\r\n            // 2. Create a pipeline to prepare your data, pick your features and apply a machine learning algorithm.\r\n            // 2a. Featurize the text into a numeric vector that can be used by the machine learning algorithm.\r\n            var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: ""keyName"", inputColumnName: DefaultColumnNames.Label).\r\n                Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: DefaultColumnNames.Features, inputColumnName: nameof(SentimentData.Text)))\r\n                    .Append(mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent(labelColumnName: ""keyName"",\r\n                                                                                                   featureColumnName: DefaultColumnNames.Features))\r\n                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: DefaultColumnNames.Label, inputColumnName: ""keyName""));\r\n\r\n             var transformedData_default = pipeline.Fit(trainingDataView).Transform(trainingDataView);\r\n            var preViewTransformedData = transformedData_default.Preview(maxRows: 4);\r\n\r\n            foreach (var row in preViewTransformedData.RowView)\r\n            {\r\n                var ColumnCollection = row.Values;\r\n                string lineToPrint = ""Row--> "";\r\n                foreach (KeyValuePair<string, object> column in ColumnCollection)\r\n                {\r\n                    lineToPrint += $""| {column.Key}:{column.Value}"";\r\n                }\r\n                Console.WriteLine(lineToPrint + ""\\n"");\r\n            }\r\n\r\n            // 3. Get a model by training the pipeline that was built.\r\n            Console.WriteLine(""Creating and Training a model for Sentiment Analysis using ML.NET"");\r\n            ITransformer model = pipeline.Fit(trainingDataView);\r\n\r\n            // 4. Evaluate the model to see how well it performs on different dataset (test data).\r\n            Console.WriteLine(""Training of model is complete \\nEvaluating the model with test data"");\r\n\r\n            IDataView testDataView = mlContext.Data.LoadFromEnumerable(TestData);\r\n            var predictions = model.Transform(testDataView);\r\n            var results = mlContext.BinaryClassification.Evaluate(predictions);\r\n            Console.WriteLine($""Accuracy: {results.Accuracy:P2}"");\r\n\r\n            // 5. Use the model for making a single prediction.\r\n            var predictionEngine = model.CreatePredictionEngine<SentimentData, SentimentPrediction>(mlContext);\r\n            var testInput = new SentimentData { Text = ""ML.NET is fun, more samples at https://github.com/dotnet/machinelearning-samples"" };\r\n            SentimentPrediction resultprediction = predictionEngine.Predict(testInput);\r\n\r\n            /* This template uses a minimal dataset to build a sentiment analysis model which leads to relatively low accuracy. \r\n             * Building good Machine Learning models require large volumes of data. This template comes with a minimal dataset (Data/wikipedia-detox) for sentiment analysis. \r\n             * In order to build a sentiment analysis model with higher accuracy please follow the walkthrough at https://aka.ms/mlnetsentimentanalysis/. */\r\n            Console.WriteLine($""Predicted sentiment for \\""{testInput.Text}\\"" is: { (Convert.ToBoolean(resultprediction.Prediction) ? ""Positive"" : ""Negative"")}"");\r\n\r\n            // 6. Save the model to file so it can be used in another app.\r\n            Console.WriteLine(""Saving the model"");\r\n\r\n            using (var fs = new FileStream(""sentiment_model.zip"", FileMode.Create, FileAccess.Write, FileShare.Write))\r\n            {\r\n                model.SaveTo(mlContext, fs);\r\n                fs.Close();\r\n            }\r\n\r\n            Console.ReadLine();\r\n        }\r\n\r\n\r\n```\r\n'"
428339300,3171,b'Multi-column mapping API for normalizer estimators.',b'We need an API that lets the user normalize multiple columns at once for ease and more importantly performance benefits. '
428207932,3169,b'KeyType in example is invalid',"b""\r\n[Enter feedback here]\r\nIn 0.11 KeyType only takes 1 parameter -  'ulong count' \r\nclass MatrixElement\r\n       {\r\n           // Matrix column index starts from firstColumnIndex and is at most firstColumnIndex+n-1.\r\n           // Contieuous=true means that all values from firstColumnIndex to firstColumnIndex+n-1 are allowed keys.\r\n           // [KeyType(Contiguous = true, Count = n, Min = firstColumnIndex)]\r\n           // public uint MatrixColumnIndex;\r\n           // Matrix row index starts from firstRowIndex and is at most firstRowIndex+m-1.\r\n           // Contieuous=true means that all values from firstRowIndex to firstRowIndex+m-1 are allowed keys.\r\n           [KeyType(Contiguous = true, Count = m, Min = firstRowIndex)]\r\n           public uint MatrixRowIndex;\r\n           // The rating at the MatrixColumnIndex-th column and the MatrixRowIndex-th row.\r\n           public float Value;\r\n       }\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 335e2f1c-de96-9963-8edc-c45bc5d31105\r\n* Version Independent ID: 571d5df2-bce7-9fdf-c123-5c932d7935ce\r\n* Content: [MatrixFactorizationTrainer Class (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.matrixfactorizationtrainer?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/MatrixFactorizationTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/MatrixFactorizationTrainer.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**"""
428038943,3166,"b'The ValueMap Train method assumes that keys are on the first column, and values on the second, rather than storing the columns and using those'","b'If the [lookupMap IDataView  in the MapValue API](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L412) is constructed so that the first column contains the keys, and the second one contains the values, this API will work as expected; if the lookup idv is constructed in any other order, the API won\'t work, because the Train method of the transformer has hardcoded the index = 0 to be the keys of the idv, and index = 1 to be the values .\r\n\r\nThe [ValueMapping Train](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Transforms/ValueMapping.cs#L836)  should not assume that the first column is the keys, and the second is the values; it should instead save the columns passed to it [from the API](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L412) (and not just the column names, like it is doing now) and get the cursor based on the columns, rather than indices. \r\n\r\n\r\nEasy repro: : swap the order of the members in the LookupMap class below, and see how it fails. \r\n\r\n```csharp\r\n // Type for the IDataView that will be serving as the map\r\nprivate class LookupMap\r\n {\r\n     public float Value { get; set; }\r\n     public string Category { get; set; }\r\n }\r\n```\r\n\r\n```csharp\r\nusing System;\r\nusing System.Collections.Generic;\r\n\r\nnamespace Microsoft.ML.Samples.Dynamic\r\n{\r\n    public static class MapValueIdvLookup\r\n    {\r\n        /// This example demonstrates the use of MapValue by mapping floats to strings, looking up the mapping in an IDataView. \r\n        /// This is useful to map types to a grouping. \r\n        public static void Example()\r\n        {\r\n            // Create a new ML context, for ML.NET operations. It can be used for exception tracking and logging, \r\n            // as well as the source of randomness.\r\n            var mlContext = new MLContext();\r\n\r\n            // Get a small dataset as an IEnumerable.\r\n            var rawData = new[] {\r\n                new DataPoint() { Price = 3.14f },\r\n                new DataPoint() { Price = 2000f },\r\n                new DataPoint() { Price = 1.19f },\r\n                new DataPoint() { Price = 2.17f },\r\n                new DataPoint() { Price = 33.784f },\r\n\r\n            };\r\n\r\n            // Convert to IDataView\r\n            var data = mlContext.Data.LoadFromEnumerable(rawData);\r\n\r\n            // Create the lookup map data IEnumerable.   \r\n            var lookupData = new[] {\r\n                new LookupMap { Value = 3.14f, Category = ""Low"" },\r\n                new LookupMap { Value = 1.19f , Category = ""Low"" },\r\n                new LookupMap { Value = 2.17f , Category = ""Low"" },\r\n                new LookupMap { Value = 33.784f, Category = ""Medium"" },\r\n                new LookupMap { Value = 2000f, Category = ""High""}\r\n\r\n            };\r\n\r\n            // Convert to IDataView\r\n            var lookupIdvMap = mlContext.Data.LoadFromEnumerable(lookupData);\r\n\r\n            // Constructs the ValueMappingEstimator making the ML.NET pipeline\r\n            var pipeline = mlContext.Transforms.Conversion.MapValue(""PriceCategory"", lookupIdvMap, lookupIdvMap.Schema[""Value""], lookupIdvMap.Schema[""Category""], ""Price"");\r\n\r\n            // Fits the ValueMappingEstimator and transforms the data converting the Price to PriceCategory.\r\n            IDataView transformedData = pipeline.Fit(data).Transform(data);\r\n\r\n            // Getting the resulting data as an IEnumerable.\r\n            IEnumerable<TransformedData> features = mlContext.Data.CreateEnumerable<TransformedData>(transformedData, reuseRowObject: false);\r\n\r\n            Console.WriteLine($"" Price   PriceCategory"");\r\n            foreach (var featureRow in features)\r\n                Console.WriteLine($""{featureRow.Price}\\t\\t{featureRow.PriceCategory}"");\r\n\r\n            // TransformedData obtained post-transformation.\r\n            //\r\n            // Price        PriceCategory\r\n            // 3.14            Low\r\n            // 2000            High\r\n            // 1.19            Low\r\n            // 2.17            Low\r\n            // 33.784          Medium\r\n        }\r\n\r\n        // Type for the IDataView that will be serving as the map\r\n        private class LookupMap\r\n        {\r\n            public float Value { get; set; }\r\n            public string Category { get; set; }\r\n        }\r\n\r\n        private class DataPoint\r\n        {\r\n            public float Price { get; set; }\r\n        }\r\n\r\n        private class TransformedData : DataPoint\r\n        {\r\n            public string PriceCategory { get; set; }\r\n        }\r\n    }\r\n}\r\n```'"
427971389,3164,b'Use new Microsoft.DotNet.RemoteExecutor package',b'Dotnet team just added a new package in the arcade repo called Microsoft.DotNet.RemoteExecutor package. https://github.com/dotnet/arcade/pull/2176\r\n\r\nWe use a lot of code from this project to run our tests. This code was added in https://github.com/dotnet/machinelearning/pull/2200\r\n\r\nAlthough slight modifications were made to the code to handle Microsoft.ML based scenarios.\r\nBut i think we should be able to use this package to run other tests.\r\n\r\ncc @ViktorHofer '
427957016,3162,b'Schema comprehension fails for type System.Drawing.Bitmap',"b'Several of the image transforms in ML.NET produce intermediate columns of type System.Drawing.Bitmap\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e5cbca78683e3c1036966e07b7fd7d1b180c1562/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/ImageAnalytics/ConvertToGrayScale.cs#L39-L42\r\n\r\nIf we try to use  schema comprehension to  map some intermediate data (e.g. `transformedData`) to an IEnumerable,  we  hit an exception  when  dealing with  a column of type ` System.Drawing.Bitmap`\r\n\r\n**Error**: Unhandled Exception: System.ArgumentOutOfRangeException: Could not determine an IDataView type for member ImageObject\r\n\r\n@Ivanidzo4ka '"
427954237,3161,b'Remove generic normalizer estimator catalog methods.',b'We now have a method for each of the normalizer type so we should get rid of methods that accept enum for normalizer type.'
427931647,3160,b'API reference - Finalize the template for trainer samples',"b""Our current template for trainer API reference samples is as follows:\r\n\r\n1) Create in-memory random training data (as discussed in #2726 we're avoiding complex datasets and text-loader).\r\n2) Create a pipeline with just the trainer (i.e. focusing only on the API that this sample is about without getting into complex featurization pipeline).\r\n3) Fit the trainer.\r\n4) Generate 5 predictions and output results.\r\n5) Evaluate with in-memory test data and output metrics.\r\n\r\nBelow are some examples:\r\n* Binary classification: [FastTree](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/FastTree.cs), [FastTreeWithOptions](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/FastTreeWithOptions.cs)\r\n* Regression: [PoissonRegression](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/PoissonRegression.cs), [PoissonRegressionWithOptions](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/PoissonRegressionWithOptions.cs).\r\n\r\nOther samples will be added using this template. If you want to make any changes please mention them here so that we can finalize the sample.\r\n\r\n/cc @shauheen @glebuk\r\n"""
427863444,3155,"b""Beginner: 'Schema mismatch for label column '': expected R4, got Key<U4>' exception thrown.""","b'- **Windows 10**:\r\n\r\n\r\n\r\nTrying to create my first regression in ML.NET\r\nI get an exception thrown:\r\nSchema mismatch for label column \'\': expected R4, got Key<U4>\r\nI was expecting to get \r\n""Predicted 6 + 3 is: 9""\r\nprinted to the console.\r\n\r\nI wrote a python script to create training data with 3 columns :\r\nfirst, second, result.\r\nfirst and second are random values.\r\nresult is first+second.\r\n\r\nI expect the machine to get first and second and predict the result. \r\n\r\nnumbers.cvs:\r\n```\r\n35,74,109\r\n69,36,105\r\n75,3,78\r\n19,44,63\r\n65,93,158\r\n40,15,55\r\n2,67,69\r\n27,63,90 ... X1000 times\r\n```\r\nCode that matters:\r\n```\r\n\r\n    public class NumberData\r\n    {\r\n        [LoadColumn(0)]\r\n        public float first;\r\n        [LoadColumn(1)]\r\n        public float second;\r\n        [LoadColumn(2)]\r\n        public float result;\r\n    }\r\n    public class NumberPrediction\r\n    {\r\n        [ColumnName(""PredictedNumber"")]\r\n        public float PredictedNumber;\r\n    }\r\n.\r\n.\r\n.\r\nusing Microsoft.Data.DataView;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n.\r\n.\r\n.\r\nMLContext mlContext = new MLContext();          \r\nIDataView trainingDataView = \r\nmlContext.Data.LoadFromTextFile<NumberData>(\r\n""numbers.csv"",\',\',false);\r\nConsole.WriteLine(""Loaded Data"");\r\nvar trainingPipeline =\r\nmlContext.Transforms.Conversion.MapValueToKey(nameof(NumberData.result))\r\n.Append(mlContext.Transforms.Concatenate(\r\nDefaultColumnNames.Features,\r\nnameof(NumberData.first),\r\nnameof(NumberData.second)))\r\n.Append(mlContext.Regression.Trainers.StochasticDualCoordinateAscent(\r\nlabelColumnName: ""result"",\r\nfeatureColumnName: DefaultColumnNames.Features))\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedNumber""));\r\nConsole.WriteLine(""Created Trainer"");\r\nvar model = trainingPipeline.Fit(trainingDataView);//**RELEVANT** exception thrown here\r\nConsole.WriteLine(""Trained The Model"");\r\nvar prediction =\r\nmodel.CreatePredictionEngine<NumberData, NumberPrediction>(mlContext).Predict(\r\nnew NumberData()\r\n{\r\nfirst = 6f,\r\nsecond = 3f,\r\nresult = 0// To be predicted\r\n});\r\nConsole.WriteLine($""Predicted 6 + 3 is: {prediction.PredictedNumber}"");\r\n```\r\n'"
427810821,3154,b'ImageLoadingTransformer hides exceptions in Mapper.MakeGetter',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 1809\r\n- **.NET Version (eg., dotnet --info)**: 2.2.202\r\n\r\n### Issue\r\n\r\nI recently tried to use ML.NET in a Xamarin-based UWP app. I targeted the earliest version of UWP that support .NET Standard 2.0 and everything installed correctly. My intention was to make use a separately-trained TensorFlow model to predict some data from an image.\r\n\r\nWhile my code worked without issues in a .NET Core 2.2 console app, in the UWP it was failing. I was constantly getting an exception when attempting to load the target image - `Image [whatever] was not found.` No additional details, no inner exception.\r\n\r\nOnly after a fair amount of headscratching and trying various things I managed to find the culprit (which was obvious in hindsight): UWP does not support bitmaps. After I tried to replicate a little bit of the `ImageLoader` code, I got an unsupported platform exception.\r\n\r\nThis is all fair but then looking into the code some more, I found this:\r\nhttps://github.com/dotnet/machinelearning/blob/b5a8d9962a10bcf6b7885ba9a4efa56e2b65f3f4/src/Microsoft.ML.ImageAnalytics/ImageLoader.cs#L215\r\n\r\nThe code is catching all exceptions and throwing a custom exception in their place, *without* providing the base exception. I think this could be improved as part of making the API surface friendlier to use - spending an hour on this, I started to think I was doing something insanely wrong. The inner exception would have told me the root cause in 10 seconds flat.\r\n\r\nSo there are basically two issues:\r\n1. Hiding the base exceptions\r\n2. Image analytics won't work in UWP at all because of bitmaps\r\n\r\nI think a fix for 1. could be relatively simple. 2. will be much more difficult and might not be desirable but I wanted to throw it out there. Maybe using a platform-agnostic implementation of image handling could be useful.\r\n\r\nOpinions? Thoughts?\r\n\r\n\r\n"""
427564778,3153,b'AutoML feature request: Datetime column featurization',"b""Given a date time column, create features like 'day of the week', 'month of the year' etc."""
427545484,3152,b'AutoML feature request: Weight of evidence',b'Needed for automl feature engineering\r\nhttps://www.kaggle.com/pavansanagapati/weight-of-evidence-woe-information-value-iv'
427543868,3151,b'Time Series forecasting',"b""### System information\r\n\r\n- **OS version/distro Windows 10:\r\n- **.NET Version (eg., dotnet --info) Core 2.0 - 2.2: \r\n\r\n### Issue\r\n\r\nI am looking for time series prediction possibility, but can't find one example. There are a lot of posts about forecasting - all from 2018. So my question is: Is time series forecasting included into ml.net 0.11 or do you plan to add it in the future versions?\r\n"""
427543336,3150,b'AutoML feature request: Target encoding',"b'Needed for automl feature engineering\r\n(In TCL land, I imagine this is knows as Dracula??)'"
427542855,3149,b'AutoML feature request: Tree featurizer',b'Needed for \r\n- feature engineering\r\n- SMAC sweeper implementation '
427541127,3148,b'AutoML feature request:  Ensembling APIs',b'https://en.wikipedia.org/wiki/Ensemble_learning\r\nEnsembling of models produces better accuracy more often than not. \r\n'
427500760,3147,b'Linear Regression using ML.NET',"b""I am trying to do simple linear regression with ML.NET and am struggling to figure out how you would do this. Is it possible and if so what is your recommendation? It's not clear from the documentation if a simple linear regression is possible with ML.NET."""
427410278,3146,b'Error when using ConvertToOnnx',"b'When trying to use the `context.Model.ConvertToOnnx` method it shows an error saying `Reference to type \'ITransformer\' claims to be defined in \'Microsoft.ML.Core\', but it could not be found`.\r\n\r\nBelow is the code when trying to access it.\r\n\r\n```csharp\r\nvar context = new MLContext();\r\n\r\nvar textLoader = context.Data.CreateTextLoader(new[]\r\n{\r\n    new TextLoader.Column(""YearsExperience"", DataKind.Single, 0),\r\n    new TextLoader.Column(""Label"", DataKind.Single, 1),\r\n},\r\nhasHeader: true,\r\nseparatorChar: \',\');\r\n\r\nvar data = textLoader.Load(""./SalaryData.csv"");\r\n\r\nvar trainTestData = context.Regression.TrainTestSplit(data);\r\n\r\nvar pipeline = context.Transforms.Concatenate(""Features"", ""YearsExperience"")\r\n    .Append(context.Regression.Trainers.FastTree());\r\n\r\nITransformer model = pipeline.Fit(trainTestData.TrainSet);\r\n\r\ncontext.Model.ConvertToOnnx(model, data);\r\n```\r\n\r\nUsing version v.11. I have the `Microsoft.ML.Onnx` package installed, but I\'m not sure if it\'s needed.'"
427403727,3145,b'LinearSupportVectorMachines trained Model not working',"b""### System information\r\n\r\n- **OS windows 10**:\r\n- **.NET Version (Microsoft.NETCore.App 2.2.3)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\ntrained a model using LinearSupportVectorMachines\r\n- **What happened?**\r\nThe model was created then i load the model and tried to predict on the model but it shows exception\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Could not find input column 'IdPreservationColumn'\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.MakeColumn(DataViewSchema inputSchema, Int32 iinfo)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper..ctor(ColumnConcatenatingTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.MakeRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n```\r\n- **What did you expect?**\r\nI expected to predict based on loaded trained model\r\n### Source code / logs\r\n\r\nIdPreservationColumn i don't know what this is and i can't find any document about it\r\n"""
427399725,3144,b'K-means clustering getting centroid coordinates',"b'### System information\r\n\r\n- Windows 10\r\n- .NET 4.6.1, ML.NET .11\r\n\r\n### Issue\r\n\r\nI am using the KMeans clustering trainer but is there anyway to get the actual centroid locations as X,Y (trying to plot the results on a graph for visual representation).  I see the CentroidL2S private property on the KMeansParms class but those seem to be vector based.  Has anyone plotted the results of a cluster or have a good way to generate X,Y coords for plotting purposes?\r\n\r\nThanks\r\n'"
427175863,3143,b'Need Example for Onnx Export',"b'### System information\r\n\r\n- **OS version/distro**: All\r\n- **.NET Version (eg., dotnet --info)**: All\r\n\r\n### Issue\r\n\r\nThe tutorials page below contains invalid links for Onnx export functionality in ML.Net. Users need to have a working example. Please update the link with a working example of how to export to Onnx via ML.Net\r\n\r\nhttps://github.com/onnx/tutorials\r\n\r\n### Source code / logs\r\n\r\nN/A\r\n'"
427142386,3141,b'Problem with GloVe100D and GloVe200D files...',b'GloVe200D word embedding file contains 100D embedding vector and GloVe100D contains 200D embedding vector for each token. The file names look fine. It seems like contents of the file or filename got interchanged.\r\nhttps://github.com/dotnet/machinelearning/blob/e95f31d2417a58103f70fe06b212d31ac5963dff/src/Microsoft.ML.Transforms/Text/WordEmbeddingsExtractor.cs#L603\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e95f31d2417a58103f70fe06b212d31ac5963dff/src/Microsoft.ML.Transforms/Text/WordEmbeddingsExtractor.cs#L604\r\n\r\n\r\n\r\n'
427103253,3139,b'IPredictor inaccessible in 0.11',"b""### System information\r\n\r\n- Windows 10\r\n- .NET Core 2.2.104\r\n\r\n### Issue\r\n\r\n- Updated ML.Net 0.10 to 0.11 using NuGet\r\n- CS0122\t'IPredictor' is inaccessible due to its protection level\r\n- The rationale behind the change to be documented and new strategies to be highlighted.\r\n\r\n### Source code / logs\r\n\r\nPlease see https://stackoverflow.com/q/55344383/141172\r\n"""
427102104,3138,b'CreateEnumerable gone in 0.11',"b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 2.2.104\r\n\r\n### Issue\r\n\r\n- Updated ML.Net 0.10 to 0.11 using NuGet\r\n- MLContext.CreateEnumerable no longer available\r\n- Document the new way to create an `IEnumerable<T>` from an `IDataView`\r\n\r\n### Source code / logs\r\n\r\n`var nativePredictions = mlContext.CreateEnumerable<TP>(dataWithPredictions, false)`\r\n'"
427101121,3137,b'ColumnAttribute gone in 0.11',"b'### System information\r\n\r\n- Windows 10\r\n- .NET Core 2.2.104\r\n\r\n### Issue\r\n\r\n- Updated ML.Net 0.10 to 0.11 using NuGet\r\n- ColumnAttribute no longer defined\r\n- The change be documented in breaking change notes, specifically whether you now use the similar attribute from `System.ComponentModel.DataAnnotations.Schema` or if you defined a differently-named attribute.\r\n\r\n### Source code / logs\r\n\r\n        [Column(ordinal: ""0"", name: ""Label"")]\r\n        public float Sentiment;\r\n\r\n'"
426737482,3134,b'weighting parameter value lost for ProduceWordBag call',"b'When calling `ProduceWordBags` with `weighting` parameter specified it gets lost and the results always use `WeightingCriteria.Tf`.\r\n\r\nThe simplest repro-steps I have (based on `LdaTransform` sample):\r\n\r\n```csharp\r\n// Get a small dataset as an IEnumerable and then read it as a ML.NET data set.\r\nIEnumerable<SamplesUtils.DatasetUtils.SampleTopicsData> data = SamplesUtils.DatasetUtils.GetTopicsData();\r\nvar trainData = ml.Data.LoadFromEnumerable(data);\r\n\r\nstring review = nameof(SamplesUtils.DatasetUtils.SampleTopicsData.Review);\r\n\r\n// A pipeline for featurizing the ""Review"" column\r\nvar pipeline = ml.Transforms.Text.ProduceWordBags(""bags"", review, ngramLength: 1, weighting: Transforms.Text.NgramExtractingEstimator.WeightingCriteria.TfIdf);\r\n\r\n// The transformed data\r\nvar transformer = pipeline.Fit(trainData);\r\nvar transformed_data = transformer.Transform(trainData);\r\n\r\nvar preview = transformed_data.Preview();\r\n\r\nvar bagsColumn = transformed_data.GetColumn<VBuffer<float>>(""bags"");\r\nforeach (var featureRow in bagsColumn )\r\n{\r\n    foreach (var value in featureRow.GetValues())\r\n        Console.Write($""{value} "");\r\n    Console.WriteLine("""");\r\n}\r\n```\r\n\r\nExpected output:\r\n\r\n```\r\n1.386294 0.6931472 0.6931472 1.386294 0.6931472 0.2876821 0 0 0 0 0 0 0\r\n0 0.6931472 0.6931472 0 0.6931472 0.2876821 1.386294 1.386294 0 0 0 0 0\r\n0.6931472 0.6931472 0.6931472 0.6931472 0.6931472\r\n0 0 0 0 0 0.2876821 0 0 0.6931472 0.6931472 0.6931472 0.6931472 0.6931472\r\n```\r\n\r\nActual output:\r\n\r\n```\r\n1 1 1 1 1 1 0 0 0 0 0 0 0\r\n0 1 1 0 1 1 1 1 0 0 0 0 0\r\n1 1 1 1 1\r\n0 0 0 0 0 1 0 0 1 1 1 1 1\r\n```\r\n\r\nI\'ll send a PR with a fix shortly.'"
426718450,3132,"b'Version.txt in model .zip should use the FileVersion, not AssemblyVersion'","b'When you save a model, it generates a `Version.txt` file in the .zip, so we can tell which version of ML.NET was used to generate the model.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Core/Data/Repository.cs#L307-L310\r\n\r\nHowever, the issue is we are using the AssemblyVersion there, which isn\'t great information as all the models produced are showing:\r\n\r\n```\r\n1.0.0.0\r\n```\r\n\r\nWe should write the FileVersion or AssemblyInformationalVersion instead, which will give us the exact build and SHA:\r\n\r\n```\r\n[assembly: AssemblyFileVersion(""0.12.27526.3"")]\r\n[assembly: AssemblyInformationalVersion(""0.12.27526.3 @BuiltBy: dlab14-DDVSOWINAGE101 @Branch: master @SrcCode: https://github.com/dotnet/machinelearning/tree/9caafb04d2b4f298f2a9479a9550597afee32c94+9caafb04d2b4f298f2a9479a9550597afee32c94"")]\r\n````'"
426686238,3131,"b'ONNX Unit Tests should be using the dynamic API, not the static/PIGSTY API'","b'The ONNX Unit Test samples are currently using static/PIGSTY API. This is getting a lot harder for any user to see how to run ONNX models in ML.NET.\r\n\r\nIn any case Unit Tests should use the API that the users have to use which is the DYNAMIC API, so we test the same API, right?\r\n\r\nSee here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformerTest/OnnxTransformTests.cs#L180\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformerTest/DnnImageFeaturizerTest.cs#L92\r\n\r\nPlease, migrate these ONNX Unit Test samples to the dynamic API (the current standard in ML.NET).\r\n\r\n@jignparm \r\n@prathyusha12345 \r\n\r\n\r\n\r\n'"
426613687,3130,"b""CpuMath doesn't work as expected.""","b'### System information\r\n\r\n- **OS version/distro**: Linux, Windows, Mac. Basically [all debug builds](https://dev.azure.com/dnceng/public/_build/results?buildId=135940) in our CI.\r\n\r\n### Issue\r\n\r\n- **What did you do?** Call CpuMath to compute a matrix-vector product.\r\n- **What happened?** Memory not aligned.\r\n- **What did you expect?** All tests should just pass.\r\n\r\n### Source code / logs\r\n\r\nPlease take a look at [this PR](https://github.com/dotnet/machinelearning/pull/3124/files#diff-ce59b50bd87003b0ffb26912fc4a0e65).\r\n'"
426463414,3129,b'In CrossValidate use the same estimator in each fold?',"b'https://github.com/dotnet/machinelearning/blob/0b638bfa226320099a74b5eb7e8ea5316f1843a1/src/Microsoft.ML.Data/TrainCatalog.cs#L90\r\n\r\nThe correct approach should be to use different estimator for each round of fitting, and is a deep cloned version of the estimator  from the parameter.'"
426262875,3128,b'Creating a prediction engine from a model with a TextFeaturizer takes too long',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nLoad the model and call `CreatePredictionEngine` on a pipeline that was created like this:\r\n\r\n```C#\r\n            var ml = new MLContext(seed: 1);\r\n            var data = ml.Data.LoadFromTextFile<SentimentData>(GetDataPath(TestDatasets.Sentiment.trainFilename), hasHeader: true);\r\n\r\n            // Pipeline.\r\n            var pipeline = ml.Transforms.Text.FeaturizeText(""Features"", ""SentimentText"")\r\n                .AppendCacheCheckpoint(ml)\r\n                .Append(ml.BinaryClassification.Trainers.SdcaNonCalibrated(\r\n                    new SdcaNonCalibratedBinaryTrainer.Options { NumberOfThreads = 1 }));\r\n\r\n            // Train.\r\n            var model = pipeline.Fit(data);\r\n\r\n            var modelPath = GetOutputPath(""temp.zip"");\r\n            // Save model. \r\n            ml.Model.Save(model, data.Schema, modelPath);\r\n\r\n            // Load model.\r\n            var loadedModel = ml.Model.Load(modelPath, out var inputSchema);\r\n\r\n            // Create prediction engine and test predictions.\r\n            var engine = ml.Model.CreatePredictionEngine<SentimentData, SentimentPrediction>(loadedModel, inputSchema);\r\n```\r\n\r\n- **What happened?**\r\nIt takes an incredible amount of time to `CreatePredictionEngine`. Using the attached model.zip\r\n[SentimentModel.zip](https://github.com/dotnet/machinelearning/files/3015931/SentimentModel.zip) it takes roughly 1.5 seconds for `CreatePredictionEngine` on my machine in a benchmark:\r\n\r\n|                 Method |    Mean |    Error |   StdDev | Gen 0/1k Op | Gen 1/1k Op | Gen 2/1k Op | Allocated Memory/Op |\r\n|----------------------- |--------:|---------:|---------:|------------:|------------:|------------:|--------------------:|\r\n| CreatePredictionEngine | 1.516 s | 0.0302 s | 0.0461 s |  14000.0000 |   6000.0000 |           - |           146.35 MB |\r\n\r\n- **What did you expect?**\r\nI expected the model to load in a much shorter time with a lot less memory being allocated.\r\n\r\n### Source code / logs\r\n\r\nDoing a profile of the [Benchmark](https://github.com/glennc/Extensions.ML/blob/840211d64e1e165a124fd17020339479aac79231/benchmarks/micro/CreationBenchmarks.cs#L25-L29), I was able to get this flame graph:\r\n\r\n![image](https://user-images.githubusercontent.com/8291187/55124572-aa2ee680-50d4-11e9-8d5e-92fe5dc0846e.png)\r\n\r\nAs you can see, the two boxes show where we are writing a model and compressing it twice, just during the call to `CreatePredictionEngine`. This is because of the following code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/beb67a128544ee98b8c4309859f7e5a9f679ac4e/src/Microsoft.ML.Transforms/Text/TextFeaturizingEstimator.cs#L663-L679\r\n\r\nHere, `TextFeaturizingEstimator.Transformer` is doing things the ""old way"" using `ApplyTransformUtils.ApplyAllTransformsToData`, which operates on `IDataTransform`s. This eventually gets into:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/Utilities/ApplyTransformUtils.cs#L35-L52\r\n\r\nwhich is serializing and deserializing the transform, which is super expensive.\r\n\r\nThis happens twice because once inside `GetRowToRowMapper` and once inside `GetOutputSchema`.\r\n\r\nWe should optimize the text featurizing transform so creating a prediction engine isn\'t so slow.\r\n\r\n@TomFinley @glennc @CESARDELATORRE '"
426252611,3127,b'API Reference needs to include expected column types',"b""## Issue\r\nOur API documentation for trainers, evaluate and cross validate need to specify the expected column types. \r\n\r\nFor example:\r\n```\r\nParameters\r\nlabelColumn\r\nString\r\nThe name of the label column.\r\n\r\nmatrixColumnIndexColumnName\r\nString\r\nThe name of the column hosting the matrix's column IDs.\r\n\r\nmatrixRowIndexColumnName\r\nString\r\nThe name of the column hosting the matrix's row IDs.\r\n```\r\nTaken from here:\r\n[Matrix Factorization Help](url)\r\n[](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.recommendationcatalog.recommendationtrainers.matrixfactorization?view=ml-dotnet#Microsoft_ML_RecommendationCatalog_RecommendationTrainers_MatrixFactorization_System_String_System_String_System_String_System_Int32_System_Double_System_Int32_)\r\n\r\nNote that this takes:\r\n* Label Column (really name of the label column) and that the type is string\r\n* MatrixIndexColumnName -- also string\r\n* MatrixRowIndexColumnName - also string\r\n\r\nThe type string provides no information on the actual expected/supported column type. \r\n\r\n## Expected\r\nThere needs to be more documentation regarding the column types that trainers are expecting and if that trainer will add additional columns as a result of the transformation.\r\n\r\n## Suggestion\r\nThis can be added to the parameter description, for example:\r\n`The name of the label column. The label column must be one of the following ColumnType: DataKind.Int64, DataKind.Float,...</param>\r\n`\r\nAdditional content regarding if columns are added and what those columns are should be added in the Remarks section. Columns that are added should also include their ColumnType as well."""
426245097,3126,b'Catalog documentation is not in sync with the code',"b'## Issue\r\nOur documentation hierarchy is not  in sync with our code catalogs. For example, if you look at our Binary Classification Catalog:\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog?view=ml-dotnet\r\n\r\nIt contains a `Methods`  and `Properties` Links. If you drop down Properties, there is a `Trainers` but that page is fairly empty:\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.trainers?view=ml-dotnet\r\n\r\nIf you look in other catalogs, you will eventually find the Binary Classification Trainers -- for example, LightGBM is located under LightGBM Extensions:\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet\r\n\r\nHowever, this does not match what a user would see in code as you can type:\r\n`mlContext.BinaryClassification.Trainers.LightGBM`\r\n\r\nThe expectation is that a user should be able to navigate the API Catalog and view all of the functions under that catalog. \r\n\r\n## More info\r\nIt looks like the documentation tool is using the class name to determine the location of where the APIs are located:\r\nhttps://github.com/dotnet/machinelearning/blob/366332047340bdb12cf5fe2a11f9a6e257af9b84/src/Microsoft.ML.LightGbm/LightGbmCatalog.cs#L14\r\n\r\nMaybe there is a way we can override what the tool is using through an attribute? '"
426238569,3125,b'FastTree should only accept Boolean labels for binary classification ',b'In addition to #3119'
426190863,3121,b'DataKind U4 in error message with Matrix Factorization',"b'### System information\r\n\r\nWindows 10\r\nMicrosoft.ML.Recommenders 0.12.0-preview-27526-3\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan through the Movie Lens recommendation pipeline. \r\nDataset can be found from AzureML gallery:\r\nhttps://gallery.azure.ai/Experiment/Recommender-Movie-recommendation-3\r\n\r\n- **What happened?**\r\nThe UserId was set to Int32 - so when running the training, I get an error:\r\n\r\n> System.InvalidOperationException: \'Column \'UserId\' with role MatrixColumnIndex should be a known cardinality U4 key, but is instead \'Int32\'\'\r\n\r\n- **What did you expect?**\r\nNot to see U4 in the description as this tells me nothing. The error should say must be of KeyDataViewType. \r\n\r\n### Source code / logs\r\nHere is the sample code to reproduce:\r\n```\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers;\r\nusing System;\r\n\r\nnamespace ConsoleApp36\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Hello World!"");\r\n\r\n            var mlContext = new MLContext();\r\n            var loader = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = new TextLoader.Column[]\r\n                {\r\n                    new TextLoader.Column(""UserId"", DataKind.Int32, 0),\r\n                    new TextLoader.Column(""MovieId"", DataKind.Int32, 1),\r\n                    new TextLoader.Column(""Rating"", DataKind.Int32, 2),\r\n                    new TextLoader.Column(""Timestamp"", DataKind.Int64, 3)\r\n                },\r\n                HasHeader = true,\r\n                Separators = new char[] { \',\' }\r\n            });\r\n\r\n            var data = loader.Load(""{path to data}/Movie Ratings.csv"");\r\n            var pipeline = mlContext.Recommendation().Trainers.MatrixFactorization(new MatrixFactorizationTrainer.Options()\r\n            {\r\n                MatrixColumnIndexColumnName = ""UserId"",\r\n                MatrixRowIndexColumnName = ""MovieId"",\r\n                LabelColumnName = ""Rating""\r\n            });\r\n\r\n            var model = pipeline.Fit(data);\r\n            \r\n        }\r\n    }\r\n}\r\n```\r\n\r\nHere is the line of code where this is occurring:\r\nhttps://github.com/dotnet/machinelearning/blob/366332047340bdb12cf5fe2a11f9a6e257af9b84/src/Microsoft.ML.Recommender/RecommenderUtils.cs#L65\r\n'"
426168571,3119,"b'Prior binary trainer requires float label column, but all other binary trainers require bool'","b'Build a pipeline like:\r\n\r\n```C#\r\n            IEstimator<ITransformer> pipeline =\r\n                MLContext.Transforms.ReplaceMissingValues(""FixedAcidity"", replacementMode: MissingValueReplacingEstimator.ReplacementMode.Mean)\r\n                .Append(MLContext.FloatToBoolLabelNormalizer())\r\n                .Append(MLContext.Transforms.Concatenate(""Features"",\r\n                    new[]\r\n                    {\r\n                        ""FixedAcidity"",\r\n                        ""VolatileAcidity"",\r\n                        ""CitricAcid"",\r\n                        ""ResidualSugar"",\r\n                        ""Chlorides"",\r\n                        ""FreeSulfurDioxide"",\r\n                        ""TotalSulfurDioxide"",\r\n                        ""Density"",\r\n                        ""Ph"",\r\n                        ""Sulphates"",\r\n                        ""Alcohol""}))\r\n                .Append(MLContext.BinaryClassification.Trainers.Prior());\r\n```\r\n\r\nScenario taken from [XamlBrewer.Uwp.MachineLearningSample](https://github.com/XamlBrewer/UWP-MachineLearning-Sample/blob/b7337d6e49e2109d9f028c1942aa2b409d3bfb9c/XamlBrewer.Uwp.MachineLearningSample/Models/BinaryClassification/BinaryClassificationModel.cs#L18-L35) with the ""Random"" trainer changed to the ""Prior"" trainer.\r\n\r\nWhen you try to fit this pipeline, you get an exception:\r\n\r\n```\r\n{System.ArgumentOutOfRangeException: Invalid type for Label column\r\nParameter name: data\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Contracts.CheckParam(Microsoft.ML.Runtime.IExceptionContext ctx, bool f, string paramName, string msg) Line 542\tC#\r\n \tMicrosoft.ML.StandardTrainers.dll!Microsoft.ML.Trainers.PriorTrainer.Train(Microsoft.ML.TrainContext context) Line 235\tC#\r\n \tMicrosoft.ML.StandardTrainers.dll!Microsoft.ML.Trainers.PriorTrainer.Microsoft.ML.ITrainer<Microsoft.ML.Trainers.PriorModelParameters>.Train(Microsoft.ML.TrainContext context) Line 274\tC#\r\n \tMicrosoft.ML.StandardTrainers.dll!Microsoft.ML.Trainers.PriorTrainer.Fit(Microsoft.ML.IDataView input) Line 222\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Data.EstimatorChain<Microsoft.ML.ITransformer>.Fit(Microsoft.ML.IDataView input) Line 67\tC#\r\n>\tXamlBrewer.Uwp.MachineLearningSample.exe!XamlBrewer.Uwp.MachineLearningSample.Models.BinaryClassificationModel.BuildAndTrain(string trainingDataPath, Microsoft.ML.IEstimator<Microsoft.ML.ITransformer> algorithm) Line 46\tC#\r\n````\r\n\r\nIt appears the `Prior` binary trainer can only take `float` labels:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.StandardTrainers/Standard/Simple/SimpleTrainers.cs#L233\r\n\r\nHowever, all other binary trainers require the label column to be a `boolean`.\r\n\r\ncc @TomFinley '"
426160622,3117,b'Need a sample for saving and loading CustomMapping Transform',"b'We currently only have a simple sample to use the custom mapping transform, but saving and loading is a bit more involved and a sample about that would be very useful.\r\n\r\nHere is the current sample that we have:\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/CustomMappingSample.cs\r\n\r\nHere is a test that shows how to save and load the custom mapping transform:\r\nhttps://github.com/dotnet/machinelearning/blob/366332047340bdb12cf5fe2a11f9a6e257af9b84/test/Microsoft.ML.Tests/Transformers/CustomMappingTests.cs#L33-L85'"
426147593,3114,b'DropSlot transform is needed',"b'Consider this code snippet:\r\n```\r\nvar defaultPipeline = ml.Transforms.Text.FeaturizeText(""TextFeatures"", ""Text"")\r\n.Append(ml.Transforms.ProjectToPrincipalComponents(""PC"", ""TextFeatures"", null, 10))\r\n.Append(ml.Transforms.DropSlots(""ShortenedPC"", ""PC"", new int[] { 0, 1}))  // drop slots 0 & 1\r\n```\r\nCurrently its not possible bcs SlotDroppingTransform is not exposed. The workaround is to use CustomMapping which is bit cumbersome.\r\n```\r\n        public class InputRow\r\n        {\r\n            [VectorType(10)]\r\n            public float[] PC;\r\n        }\r\n        public class OutputRow\r\n        {\r\n            [VectorType(8)]\r\n            public float[] PCA = new float[8];\r\n        }\r\n...\r\nAction<InputRow, OutputRow> mapping =\r\n                (input, output) => Array.Copy(input.PC, 2, output.PCA, 0, 8);\r\n\r\nvar defaultPipeline = ml.Transforms.Text.FeaturizeText(""TextFeatures"", ""Text"")\r\n.Append(ml.Transforms.ProjectToPrincipalComponents(""PC"", ""TextFeatures"", null, 10))\r\n.Append(ml.Transforms.CustomMapping(mapping, null))\r\n            \r\n'"
426130356,3112,b'Baseline test for Multiclass Naive bayes',b'Add baseline test for multiclass naive bayes that will be used to detect any changes in numerical calculations caused by modifications in low level routines downstream or even in the algorithm itself.'
426129530,3111,b'Shall we add option to OneHotEncoding to treat each slot separately?',"b'So I\'m having file with 39 categorical features.\r\nI\'m too lazy to write text loader with 39 columns for them, so I just slap ` new TextLoader.Column(""CatFeatures"", DataKind.String, 190, 228),`\r\n\r\nNow during one hot encoding we will build one huge dictionary for all slots. And I would get huge indicator vector in the end.\r\nI\'m not sure is it actually bad, or not.\r\n\r\nBut if it\'s bad, I would prefer to have option in OneHotEncoding to treat each slot separately, since am too lazy to write `TextLoader.Column` definition 39 times. Or maybe we can have some kind of \r\n`TextLoader.Columns(""Prefix"", DataKind.String, 190,228)` object and it would automatically create me 39 columns of `Prefix01`, `Prefix02`, .., `Prefix39` with specified type.\r\n '"
426119725,3110,b'Absence of dataview joins',"b'In some cases data and labels present in two different files.\r\nRight now I have no way to load data in through one text loader, labels though another text loader and join them together.'"
426117711,3109,b'Microsoft.ML nuget package no longer has a way to specify number of bins for binning normalization',"b'In `v0.11.0`, it was possible to write code like the following:\r\n\r\n```C#\r\nvar normalizer = mLContext.Transforms.Normalize(\r\n    new NormalizingEstimator.BinningColumnOptions(outputColumnName: ""Label"", numBins: 2));\r\n```\r\n\r\nThis allowed you to create a `binning` normalizer with the number of bins set to `2`.\r\n\r\nHowever, this API is no longer public in `Microsoft.ML`. There is a public API where you can specify `mode: NormalizingEstimator.NormalizationMode.Binning`, but there is no way to set the number of bins. So when you use this mode, you always `MaximumBinCount` set to the default `1024`.'"
426115561,3108,b'`LossFunction` in regression metric is confusing',"b'The regression evaluator reports the following metrics: `MeanAbsoluteError`, `MeanSquaredError`, `RootMeanSquaredError`, `RSquared` and `LossFunction`.\r\n\r\n`LossFunction` reports a loss that can theoretically be specified by the user, but there is no public API that exposes this.\r\nI think we should either remove `LossFunction` from the `RegressionMetrics` class, or rename it to be its default value (`SquaredLoss`). Actually, it seems that `SquaredLoss` is identical to `MeanSquaredError`, so we should probably remove (or internalize) this field. '"
426107984,3107,b'Exceptions are not super helpful',"b'```\r\nvar loader = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                HasHeader = true,\r\n                Columns = new[] {\r\n                    new TextLoader.Column(""NumericFeatures"", DataKind.Single, 0, 189),\r\n                    new TextLoader.Column(""CatFeatures"", DataKind.String, 189, 229),\r\n                    new TextLoader.Column(""Label"", DataKind.Int32, 230)\r\n                }\r\n            });\r\n            var data = loader.Load(""train.tsv"");\r\n            var dic = new Dictionary<int, bool>();\r\n            dic.Add(1, true);\r\n            dic.Add(-1, false);\r\n            var pipeline = mlContext.Transforms.IndicateMissingValues(""NumericFeatures"").\r\n                Append(mlContext.Transforms.Categorical.OneHotEncoding(""CatFeatures"")).\r\n                Append(mlContext.Transforms.Concatenate(""Features"",""NumericFeatures"", ""CatFeatures"")).\r\n                Append(mlContext.Transforms.Conversion.MapValue(""Label"", dic));\r\n```\r\n```\r\nSystem.InvalidOperationException: \'Column \'CatFeatures\' has values of Singlewhich is not the same as earlier observed type of Boolean.\'\r\n```\r\nA) would be nice to have space between type and sentence.\r\nB) this exception happened in Concat transform and only indication of that is stack trace.\r\n'"
426095558,3106,"b""It's hard to create a TextLoader column of type key""","b'It seems that the only way to create a key column for `TextLoader` is using this constructor:\r\n\r\n```\r\npublic Column(string name, DataKind dataKind, TextLoader.Range[] source, KeyCount keyCount = null)\r\n```\r\n\r\nShould we consider adding an optional `KeyCount` argument to the other constructors?\r\n\r\n```\r\npublic Column(string name, DataKind dataKind, int index);\r\npublic Column(string name, DataKind dataKind, int minIndex, int maxIndex);\r\n```\r\n\r\n'"
426083811,3105,b'Not able to execute object detection sample',"b'\r\nAs part of creating ONNX Object detection sample to our MachineLearning Samples Repo, I am trying to execute  ONNX object detection sample by using the unit tests given [here](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fdotnet%2Fmachinelearning%2Fblob%2Fmaster%2Ftest%2FMicrosoft.ML.OnnxTransformerTest%2FOnnxTransformTests.cs&data=02%7C01%7Cv-prkor%40microsoft.com%7C9376cba2abc84a9ac5e208d6b22f6acf%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636892314038104547&sdata=jERmHMMiVkUKe%2B0pV3OKP7es4Mdkc6%2BuW4txhB2%2FHqc%3D&reserved=0) .Referring **OnnxStatic()** method in the link.\r\n \r\nWhen I am trying to execute the sample by pressing **F5** or **ctrl+F5**, I am getting the below exception.\r\n \r\n**System.TypeLoadException\r\n  HResult=0x80131522\r\n  Message=Method \'GetOutputSchema\' in type \'Microsoft.ML.Transforms.OnnxScoringEstimator\' from assembly \'Microsoft.ML.OnnxTransform, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\' does not have an implementation.\r\n  Source=<Cannot evaluate the exception source>\r\n  StackTrace:\r\n<Cannot evaluate the exception stack trace>**\r\n \r\nThe installed nuget packages are as below\r\n \r\n```\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n \r\n  <PropertyGroup>\r\n    <OutputType>Exe</OutputType>\r\n    <TargetFramework>netcoreapp2.2</TargetFramework>\r\n  </PropertyGroup>\r\n \r\n  <ItemGroup>\r\n    <PackageReference Include=""Microsoft.ML"" Version=""0.11.0"" />\r\n    <PackageReference Include=""Microsoft.ML.ImageAnalytics"" Version=""0.11.0"" />\r\n    <PackageReference Include=""Microsoft.ML.OnnxRuntime"" Version=""0.3.0"" />\r\n    <PackageReference Include=""Microsoft.ML.OnnxTransform"" Version=""0.10.0"" />\r\n  </ItemGroup>\r\n</Project>\r\n```\r\n \r\nI have pushed the sample in my repository [here](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fprathyusha12345%2Fmachinelearning-samples%2Ftree%2Fmaster%2Fsamples%2Fcsharp%2Fgetting-started%2FONNXModel_ObjectDetection%2FONNXModel_ObjectDetection&data=02%7C01%7Cv-prkor%40microsoft.com%7C9376cba2abc84a9ac5e208d6b22f6acf%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636892314038114541&sdata=7%2ByNauaS0cpkFReVM5GUcUOGMq4wOYhB27IItacoIYQ%3D&reserved=0)'"
425719040,3103,b'Add baseline-based tests for all componets of ML.NET',"b""### Issue\r\nCurrently there are many components in ML.NET that do not have any kind of baseline tests.  We run risk of regressions as we don't have tests for some components that can detect performance degradation.\r\n\r\n### Required work\r\nHere are the following identified baselines that are completely missing, yet exist in prior internal versions.  The task is to port them to ML.NET:\r\n\r\n- BaselineNormalize\r\n\r\n- Anomaly\r\n- Evaluators\r\n- FastTreeRanking\r\n- FastTreeRegression\r\n- FastTreeTweedieRegression\r\n- ImageTests\r\n- KM\r\n- LDSVM\r\n- LightGBMRank\r\n- ModelExport\r\n- MultiClassNaiveBayes\r\n- OGD\r\n- PoissonRegression\r\n- RegressionGamTrainer\r\n- ResultProcessor\r\n- SDCAMC\r\n- SDCAR\r\n\r\n"""
425654984,3100,b'F# API Documentation Examples',"b'While our machinelearning-samples repo has F# samples, the ML.Net API documentation examples do not contain F# examples.\r\n\r\nThis is a work item to add F# examples to demonstrate API usage and to mirror what we have in C#.\r\n\r\nThings that need to be understood:\r\n1) Does our current documentation pipeline support another language (we support python and C#, can we add F# examples and have it work or is there some additional work that  needs to be done? If so, lets create an issue -- following up with @JRAlexander and @natke)\r\n\r\n2) If it is supported, is there a specific directory structure or other restrictions that need to be followed?\r\n\r\nIf there are sub-issues that need to be created, please use this as the global issue for tracking.\r\n\r\ncc @shmoradims, @sfilipi, @zeahmed, @rogancarr \r\n\r\n'"
425637108,3098,b'Better documentation and discoverability around Append and Transfomer Scope',"b'As part of our public API, we support the ability to filter out parts of the estimator chain. The APIs that support this are not documented, nor do we provide any context in our Cookbooks. As we are doing an overall coverage of documentation/samples, I created this issue separately to ensure that it gets covered. Referencing from #3063, these are the two APIs that are used:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/db4ecc0135baffc8930201a85fb3e9a101cdfa46/src/Microsoft.ML.Data/DataLoadSave/EstimatorChain.cs#L87\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/db4ecc0135baffc8930201a85fb3e9a101cdfa46/src/Microsoft.ML.Data/DataLoadSave/TransformerChain.cs#L145\r\n\r\nIt would also be very useful to have more information about why you would want to filter as well as what scenarios we are trying to address.\r\n'"
425627055,3097,"b'Data kind R4, R8, etc. were removed, but errors still show up with those internal types'","b'Data Kind \'R4\', \'R8, \'etc. were removed in the new version. However trainer still validates against old type, which does not exist anymore ""externally"", for a user, so when getting errors it is very confusing.\r\n\r\nFor example:\r\n\r\n```\r\n   var trainData = mLContext.Data.LoadFromTextFile(path: trainDataPath,\r\n                     columns: new[]\r\n                     {\r\n                            new TextLoader.Column(nameof(InputData.PixelValues), DataKind.Double, 1, numSparseBits),\r\n                            new TextLoader.Column(""Number"", DataKind.Int16, 0)\r\n                     },\r\n                     hasHeader: false,\r\n                     separatorChar: \',\'\r\n                     );\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/54972539-4a2d2880-4f8c-11e9-8ba7-a9c73d328150.png)\r\n'"
425604072,3096,b'Code documentation: Improve IEstimator/ITransformer/IDataView XML and high level docs',"b'The central concept in the ML.NET API in the aftermath of #581 has become the `IEstimator`/`ITransformer`/`IDataView` triad, with the less essential but still important `IDataReader`/`IDataReaderEstimator`. That old issue, as you read it, defines a loose outline of what those now key interfaces should do, but in a somewhat vague and indefinite form, because it was not always obvious from the outset what would be correct or incorrect.\r\n\r\nYet, over the course of the last half-year or so as we pursued the practical work of making these structures and working with them, we\'ve refined what was once indefinite to more definite statements, about what makes a correct vs. incorrect, what invariants we assume they do and do not apply.\r\n\r\nThis documentation will take, as far as I can tell, two forms. One is refinements on the XML documentation of the appropriate types themselves, to clarify the ""pointwise"" accuracy of the individual components. The second is a more general document describing how all those components work together, to give a broader context not just of what they must do (which mostly belongs in the pointwise XML documentation), but also *why* things are the way they are.\r\n\r\nTo give a simple example of this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/366332047340bdb12cf5fe2a11f9a6e257af9b84/src/Microsoft.ML.Core/Data/IEstimator.cs#L268-L278\r\n\r\nWe have here arguably the two most important methods in `ITransformer`. Now these two descriptions are not *wrong*, but they are lacking a critical bit of information, specifically: given an `IDataView data`, we have come to rely on the fact that `GetOutputSchema(data.Schema)` will return the ""same"" schema (not in the reference sense) as `Transform(data).Schema` would. That should be described.\r\n\r\nSpeaking to the second point, we should explain *why* this must be so, that is the correctness of our composability, chaining, or ability to extract useful attribute information has come to rely upon that.\r\n\r\nI sort of view the second part as a companion to, or even a successor to, the existing [IDataView implementation](https://github.com/dotnet/machinelearning/blob/366332047340bdb12cf5fe2a11f9a6e257af9b84/docs/code/IDataViewImplementation.md) document, except one that also treats on `IEstimator` and `ITransformer`. That document, like this proposed document, encapsulated information that *existed* in the form of PR comments and other discussions, but concentrating that documentation ""in one place"" has proven an enormous time saver over the years to be able to point to that document to explain why things must be so, rather than isolated harder-to-find parts of conversations.\r\n\r\nWhile it may be of use to end users (certainly if I am a user of an API, knowing what I can expect out of the key interfaces for a library is of some worth), the primary goal of the documentation is to ensure that, going forward, people ""do the right thing"" and have the right set of expectations.'"
425603711,3095,b'Code documentation: Updating existing code documents',"b""Many of the [documents describing the code and the principles that make it work](https://github.com/dotnet/machinelearning/tree/366332047340bdb12cf5fe2a11f9a6e257af9b84/docs/code) need to be updated. Sometimes this updating will take the form of just updating the type names (e.g., what we used to call `ColumnType` is not `DataViewType`, `ICursor` interface has been subsumed by the `RowCursor` abstract class), and sometimes will take the form of changing the content rather entirely (e.g., we used to consider throwing in cursors bad practice, now we need to explain why we changed our mind, also, we've restricted key-types so that they are explicitly enumerations over sets rather than trying to do a bunch of additional things we never once found useful).\r\n\r\nNote that this is distinct from #2054, which is more about user-facing documentation and samples. This is more about the documentation of the principles upon which our code relies."""
425537505,3094,b' var idv = mlContext.Data.LoadFromEnumerable(data); is not working in v0.11',b'this statement is not working in v0.11. There is no LoadFromEnumerable() method available.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 476efb73-09c2-46dd-a567-91ad879bb3e7\n* Version Independent ID: 5dba3671-2591-409b-26b8-4abd8a5a3001\n* Content: [OnnxTransformer Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.onnxtransformer?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/OnnxTransformer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/OnnxTransformer.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
425366947,3093,b'out of memory exception',"b""I'm using fasttree to train my model but the program always crashes with the low on memory exception.\r\nI have an hp dl380 gen 8 with 64gig of ram and 2x 2620 xenon and windows server 2016.\r\nwhy the program crashes?\r\nshouldn't it handles low on memory?\r\nis there anything i can do so it limits memory usage?"""
425269564,3092,b'Lda bag of words export model',"b""I use LDA transformation from example\r\n\r\n```\r\nvar pipeline = \r\n  ml.Transforms.Text.ProduceWordBags(review).\r\n     Append(ml.Transforms.Text.LatentDirichletAllocation(review, ldaFeatures, numberOfTopics: 3));\r\n\r\nvar transformer = pipeline.Fit(trainData);\r\nvar transformed_data = transformer.Transform(trainData);\r\n\r\n```\r\n\r\nNow i try to visualize data with [pyLDAvis](https://github.com/bmabey/pyLDAvis) \r\n\r\nFor this task i need phi matrix, theta matrix, vocabulary, term_frequency.\r\n\r\nIt is possible to get theta matrix using documents transform, \r\nIt is possible to get phi matrix using, with SingleBox.GetModel internal method (using Reflection)\r\nIt din't managed to get the vocabulary.\r\n\r\nFor a moment it is to hard to export LDA related parameters from ml pipline.\r\n\r\nIf would be nice to be able to export complete set of related LDA parameters"""
425239903,3090,b'Exception when converting PredictedLabel from Key To Value',"b'When trying to convert the output PredictedLabel from key back to value, the exception\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Metadata KeyValues does not exist\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Contracts.Check(IExceptionContext ctx, Boolean f, String msg) in C:\\MLDotNet2\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 497\r\n```\r\nis thrown.\r\n\r\nCode to repro:\r\n```C#\r\nvar mlContext = new MLContext();\r\n\r\nvar textLoaderOptions = new TextLoader.Options()\r\n{\r\n\tColumns = new[]\r\n\t{\r\n\t\tnew TextLoader.Column(""Label"", DataKind.Single, 0),\r\n\t\tnew TextLoader.Column(""Row"", DataKind.Single, 1),\r\n\t\tnew TextLoader.Column(""Column"", DataKind.Single, 2),\r\n\t},\r\n\tHasHeader = true,\r\n\tSeparators = new[] { \'\\t\' }\r\n};\r\nvar textLoader = mlContext.Data.CreateTextLoader(textLoaderOptions);\r\nvar data = textLoader.Load(@""C:\\MLDotNet2\\test\\data\\trivial-train.tsv"");\r\n\r\nvar ap = mlContext.BinaryClassification.Trainers.AveragedPerceptron();\r\nvar ova = mlContext.MulticlassClassification.Trainers.OneVersusAll(ap);\r\n\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n\t.Append(mlContext.Transforms.Concatenate(""Features"", ""Row"", ""Column""))\r\n\t.Append(ova)\r\n\t.Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\nvar model = pipeline.Fit(data);\r\n```\r\n\r\nReplace `C:\\MLDotNet2\\` with path to ML.NET repo on your local machine'"
425166679,3089,b'Model.ConvertToOnnx() fails for Classification pipelines if non-default Features column name is used',"b'The following code fails to convert to ONNX model:\r\n```csharp\r\n            var mlContext = new MLContext();\r\n            var data = mlContext.Data.LoadFromEnumerable<Observation>(Data);\r\n            var chain = mlContext.Transforms.Concatenate(""FeatureVector"", ""Price"")\r\n                .Append(mlContext.BinaryClassification.Trainers.LogisticRegression(\r\n                    ""Label"", ""FeatureVector""));\r\n\r\n            var transformer = chain.Fit(data);\r\n            using (var stream = File.Create(""foo.onnx""))\r\n                mlContext.Model.ConvertToOnnx(transformer, data, stream);\r\n```\r\n\r\nOn the other hand, if you rename ""FeatureVector"" to ""Features"" it works. \r\nThis happens for various learners and both binary and multiclass. for both calibrated and non-calibrated. This does NOT happen on regression'"
425158582,3087,b'API to return ColumnPairs for a transformer.',b'We need an API to return ColumnPairs for transformers descending from OneToOneTransformerBase. Create such an API in the experimental nuget.'
425135348,3083,b'Cannot access leaf nodes of trained trees',"b'In this review https://github.com/dotnet/machinelearning/pull/2753, I notice the methods to traverse thru trained tree ensembles have been removed from the public API\r\n\r\n@wschin @TomFinley \r\n\r\nI understand the logic for removing.\r\n\r\nHowever, in our forked copy of SMAC, we require / have been using this functionality. Any advice on how to proceed?'"
425130591,3082,b'ApplyOnnxModel API parameters are in the wrong order',"b'The `ApplyOnnxModel` `Transformer` has a parameter order based on the `ONNX` model (see below) but as a `Transformer`, it should have parameters ordered to reflect the modification of the input `IDataView`.\r\n\r\nHere is the current API:\r\n```cs\r\npublic static OnnxScoringEstimator ApplyOnnxModel(this TransformsCatalog catalog,\r\n            string modelFile,\r\n            string outputColumnName,\r\n            string inputColumnName,\r\n            int? gpuDeviceId = null,\r\n            bool fallbackToCpu = false);\r\n```\r\n\r\nThis should be re-ordered to be:\r\n\r\n```cs\r\npublic static OnnxScoringEstimator ApplyOnnxModel(this TransformsCatalog catalog,\r\n            string outputColumnName,\r\n            string inputColumnName,\r\n            string modelFile,\r\n            int? gpuDeviceId = null,\r\n            bool fallbackToCpu = false);\r\n```\r\n\r\nRelated to #3079 '"
425125712,3081,b'Move transform catalog extensions into its own class in experimental nuget.',b'Move transform catalog extensions into its own class in experimental nuget.'
425086785,3079,"b""DnnFeaturizeImage sample doesn't match the signature in the current API""","b'The API for `LoadImage` is\r\n\r\n```\r\nLoadImages(string outputColumnName, string imageFolder, string inputColumnName = null)\r\n```\r\n\r\nbut in the sample it is used like this:\r\n\r\n```\r\nmlContext.Transforms.LoadImages(imagesFolder, ""ImageObject"", ""ImagePath"")\r\n```\r\n\r\nOne of them should be fixed, not sure which one? @TomFinley , @artidoro , @wschin \r\nI kind of like the second option (the folder first, output and input column names together).\r\n'"
425024171,3077,b'.NET Core OneHotEncoding Error',"b'### System information\r\n.Net Core 2.1\r\nMicrosoft.ML v0.11.0\r\n\r\n### Issue\r\n\r\nOneHotEncoding that works in the non core version was fine.  Now I get a type error.\r\nPreview of the data seems correct.\r\n\r\n### Source code / logs\r\nRelevant code snippets and error message.\r\n\r\nLoader\r\nnew TextLoader.Column(""RECORDTYPEID"",DataKind.String,3),\r\n\r\nPipeline\r\n.Append(mlContext.Transforms.Categorical.OneHotEncoding(""RECORDTYPEID""))\r\n\r\n.Append(mlContext.Transforms.Concatenate(""Features"",\r\n...\r\n""RECORDTYPEID"",\r\n\r\nError Message on this line of code,\r\nvar model = pipeline.Fit(trainingDataView);\r\n\r\nSystem.InvalidOperationException: \'Column \'RECORDTYPEID\' has values of R4which is not the same as earlier observed type of R8.\'\r\n'"
424809804,3076,b'Setting Epoch & Batch Size Hyper Parameters',"b""Hi,\r\n\r\nIs there a way to set Hyper Parameters such as EPOCH numbers and Batch Size for the LogisticRegression Trainer? What is the default if these aren't set?\r\n\r\nThanks!\r\n\r\n"""
424770910,3075,b'Schema comprehension in ML.NET needs more detailed document',"b""Areas that need to be covered in schema comprehension in ML.NET\r\n\r\n\r\n1. LoadFromEnumerable is not covered very well. for example how should huge amount of data be read from elasticsearh or sql ? \r\n\r\n- should that huge amount be converted to csv and then read it from csv using textloader?\r\n- should all of that data be presented in the memory? for example write a code like this:\r\n```\r\n  var dataAsList = GetAllDataFromSQLAndPutItIntoAList();\r\n\r\n  var trainingDataView= mlContext.Data.LoadFromEnumerable<dataType>(dataAsList);\r\n\r\n  trainingDataView = mlContext.Data.Cache(trainingDataView);\r\n\r\n  var pipeline = mlContext.Transforms.CreatePipeLine();\r\n\r\n  ITransformer model = pipeline.Fit(trainingDataView);\r\n```\r\n[Microsoft doc](GetChurnInfo) has an sql example. should all the data be loaded into a list at GetChurnInfo()?\r\n\r\n```\r\n// Create a new context for ML.NET operations. It can be used for exception tracking and logging,\r\n// as a catalog of available operations and as the source of randomness.\r\nvar mlContext = new MLContext();\r\n\r\n// Step one: read the data as an IDataView.\r\n// Let's assume that 'GetChurnData()' fetches and returns the training data from somewhere.\r\nIEnumerable<CustomerChurnInfo> churnData = GetChurnInfo();\r\n\r\n// Turn the data into the ML.NET data view.\r\n// We can use CreateDataView or CreateStreamingDataView, depending on whether 'churnData' is an IList,\r\n// or merely an IEnumerable.\r\nvar trainData = mlContext.Data.LoadFromEnumerable(churnData);\r\n```\r\n\r\n- is there any solution for large amounts of data that are not in text file format?\r\n\r\n2. streaming data. as \r\n\r\n> CreateStreamingDataView \r\n\r\nis out dated so it should be replaced with new detail [here](https://github.com/dotnet/machinelearning/blob/master/docs/code/SchemaComprehension.md)"""
424421592,3072,b'The hashed values stored in the annotations indices are skewed by -1',"b'Look at the [hash extension sample](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversion/Hash.cs#L58) and compare the hashed values with the values stored in the annotations of the ""CategoryHashed"" column. \r\n\r\nNotice how the indices in the annotations are skewed by -1 from the values in the dataview. \r\n\r\n// Category  CategoryHashed   Age     AgeHashed\r\n// MLB        36206            18      127\r\n// NFL        19015            14      62\r\n// NFL        **_19015_**            15      43\r\n// MLB        36206            18      127\r\n// MLS        **6013**             14      62\r\n\r\nversus [the annotations values:](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/Conversion/Hash.cs#L75)\r\n\r\n\r\n// Output Data\r\n// \r\n// The original value of the **6012** category is MLS\r\n// The original value of the **_19014_** category is NFL\r\n// The original value of the 36205 category is MLB\r\n\r\n\r\n'"
424402420,3070,b'Add Cancellation checkpoint in Normalizer transfomer',"b'This transform iterates over a dataset to calculate metrics such as mean, average, min, max etc. These values are used to normalize the values in a column. This is a trainable transform and it should have a checkpoint to see if the user has triggered cancellation.'"
424401373,3069,b'Add cancellation checkpoint in ValueToKeyMappingTransfomer',"b'This transform iterates over a dataset to construct key to value mapping. These mappings are used by other transformers like OneHotVectorizer, etc. This is a trainable transform and it should have a checkpoint to see if the user has triggered cancellation.'"
424395958,3068,b'Add multicolumn mapping for the estimators that need it the most',"b""This is not a Project 13 issue any longer, as it does not require any breaking API change.\r\n\r\nWe should enable multi-column mapping for all the estimators that support it. Since we don't have time to work on a general solution, we will go for option 1 presented in https://github.com/dotnet/machinelearning/issues/2884#issuecomment-475389060.\r\n\r\nThis will only be done for the estimators indicated in the list in the issue #2884. Going forward we should do it for all others.\r\n\r\n"""
424249440,3065,"b'Simple model error, conflicting annotations should cause an error or work'","b'### System information\r\n\r\n- **Windows 10 64 bit**:\r\n- **.NET 3.0. ML.Net 0.11**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nLoaded Textfile with label and array of float values\r\n\r\n```\r\nvar dataView = mlContext.Data.LoadFromTextFile<DataBase>(trainingFile.FullName, separatorChar: \'|\', hasHeader: false);\r\nvar dataset = mlContext.MulticlassClassification.TrainTestSplit(dataView, testFraction: 0.1);\r\n\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(nameof(DataBase.Label),sort:ValueToKeyMappingEstimator.SortOrder.Value)\r\n                    .Append(mlContext.Transforms.Normalize(new NormalizingEstimator.SupervisedBinningColumOptions(inputColumnName: nameof(DataBase.Features), outputColumnName: DefaultColumnNames.Features)))\r\n                    .Append(mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumnName: DefaultColumnNames.Label, featureColumnName: DefaultColumnNames.Features))\r\n                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\n\r\n\r\n//crashes here\r\nvar model = pipeline.Fit(dataset.TrainSet);\r\nvar predictions = model.Transform(dataset.TestSet);\r\nmetrics = mlContext.MulticlassClassification.Evaluate(predictions,DefaultColumnNames.Label,DefaultColumnNames.Score);\r\n[Sample.zip](https://github.com/dotnet/machinelearning/files/2997016/Sample.zip)\r\n\r\n```\r\n\r\n\r\n\r\n\r\n- **What happened?**\r\nGot error: Schema mismatch for feature column \'Features\': expected Vector<R4>, got R4\r\nParameter name: inputSchema\r\n- **What did you expect?**\r\nNo error as my class is a vector of float  \r\n\r\n### Source code / logs\r\n```\r\n    public class DataBase\r\n    {\r\n        [LoadColumn(0)]     \r\n        public string Label { get; set; }\r\n\r\n         //error in column definition\r\n        [LoadColumn(1),VectorType(220)]  \r\n        public float[] Features { get; set; }\r\n\r\n        public DataBase()\r\n        {\r\n            Features = new float[220];\r\n        }\r\n    }\r\n```\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
423996817,3063,b'Predict expects the Label as input',"b'## Issue\r\nWhen calling Predict, our Predict method will take in the same input as what is used for the training pipeline. This is a bit ""odd"" as we force the user to define a ""Label"" variable that does nothing nor is it needed for the output.\r\n\r\nUsing the example from #3037, we have something like this:\r\n```\r\n    let predictor = mlContext.Model.CreatePredictionEngine(transformer)\r\n    let prediction:Prediction = predictor.Predict({Area=0; Price = 209000})\r\n```\r\n\r\nWhere Area is our ""Label"", because this is required by the pipeline, we have to add this in as part of the input. \r\n\r\nCould our pipeline change to only consume the data that is needed to do the prediction? And ideally have something like this:\r\n```\r\nlet prediction:Prediction = predictor.Predict(209000)\r\n```\r\ncc @glebuk  for any additional comments.'"
423993829,3061,b'Null Reference Exception when Concatenating with a single value',"b'### Issue\r\nDiscovered from #3037, a user can call `Concatenate `and specify a single string. When this happens, a NullReference exception is thrown. Here is the code sample:\r\n```\r\n        EstimatorChain()\r\n            .Append(mlContext.Transforms.Conversion.ConvertType(""Features"", ""Price"", DataKind.Double))\r\n            .Append(mlContext.Transforms.Conversion.ConvertType(""Label"", ""Area"", DataKind.Double))\r\n            .Append(mlContext.Transforms.Concatenate(""Features""))  // This causes the error, should be (""Features"", ""Features"")\r\n            .AppendCacheCheckpoint(mlContext)\r\n            .Append(mlContext.Regression.Trainers.Sdca(""Label"", ""Features""))\r\n            , mlContext\r\n\r\n```\r\n\r\nHere is the callstack:\r\n\r\n```\r\n>\tMicrosoft.ML.Core.dll!Microsoft.ML.SchemaShape.Column.GetTypeString() Line 111\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Trainers.TrainerEstimatorBase<Microsoft.ML.Data.RegressionPredictionTransformer<Microsoft.ML.Trainers.LinearRegressionModelParameters>, Microsoft.ML.Trainers.LinearRegressionModelParameters>.CheckInputSchema(Microsoft.ML.SchemaShape inputSchema) Line 111\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Trainers.TrainerEstimatorBase<Microsoft.ML.Data.RegressionPredictionTransformer<Microsoft.ML.Trainers.LinearRegressionModelParameters>, Microsoft.ML.Trainers.LinearRegressionModelParameters>.GetOutputSchema(Microsoft.ML.SchemaShape inputSchema) Line 83\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Data.EstimatorChain<Microsoft.ML.Data.RegressionPredictionTransformer<Microsoft.ML.Trainers.LinearRegressionModelParameters>>.GetOutputSchema(Microsoft.ML.SchemaShape inputSchema) Line 83\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Data.EstimatorChain<Microsoft.ML.Data.RegressionPredictionTransformer<Microsoft.ML.Trainers.LinearRegressionModelParameters>>.Fit(Microsoft.ML.IDataView input) Line 60\tC#\r\n \tConsoleApp32.dll!Program.main(string[] argv) Line 33\tF#\r\n```\r\nThe problem is that a NullReference exception looks like a bug and its not obvious to the user on what is the cause of the problem.\r\n\r\n## Expected\r\nWe should instead notify the user that: \r\n1) A bad argument was passed in\r\n2) That its the Concatenate transform that has the bad argument\r\n\r\n### Solution A\r\nWe simply check the length of the name array that is passed to Concatenate and throw the correct exception.\r\n\r\n### Solution B\r\nAnother possible solution is to change the behavior so that when one column is specified for `Concatenate`, the name is treated as the source and destination -- so this:\r\n```\r\n            .Append(mlContext.Transforms.Concatenate(""Features""))\r\n```\r\nwould be the same as this:\r\n```\r\n            .Append(mlContext.Transforms.Concatenate(""Features"", ""Features""))\r\n```\r\n\r\ncc @glebuk for additional feedback'"
423990970,3060,b'Automatic conversion of data in the pipeline',"b'## Issue\r\nWhen providing data to a pipeline there is an expectation that we put on the user to know the data type the trainer is expecting. This is a painful experience for end-users as it requires them to not only know what data types they need to convert to, but also results in them having to add more steps to their pipeline to accommodate.\r\n\r\nThe example from #3037 demonstrates this issue as this pipeline is taking in integer values for the Label and Features and passing this into the SDCA trainer. Because the data is integer based, the pipeline uses `ConvertType ` to convert from int to float, followed by a `Concatenate` to generate a vector type (note this is in F# but still applies to C#)\r\n```\r\n        let mlContext = MLContext()\r\n        EstimatorChain()\r\n           .Append(mlContext.Transforms.Conversion.ConvertType(""Features"", ""Price"", DataKind.Single))\r\n           .Append(mlContext.Transforms.Conversion.ConvertType(""Label"", ""Area"", DataKind.Single))\r\n           .Append(mlContext.Transforms.Concatenate(""Features"", ""Features""))\r\n           .AppendCacheCheckpoint(mlContext)\r\n           .Append(mlContext.Regression.Trainers.StochasticDualCoordinateAscent(""Label"", ""Features""))\r\n           , mlContext\r\n```\r\nWithout conversions, the user will hit an exception saying that the expected type for a Label is of type float followed by the expected type for Features should be a vector of floats. \r\n\r\n## Suggestion\r\nWe should hide these details from the user as this would make the pipeline easier to load and simplify a user\'s pipeline. Taking the example above, if you were to remove the conversion steps, it would look something like this:\r\n```\r\n   let trainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(""Area"", ""Price"")\r\n```\r\n\r\ncc @glebuk for any additional input'"
423956830,3057,b'Add code analyzer support for IDataView Preview method',"b'We should write a code analyzer that checks to see if people are calling the `IDataView.Preview()` extension method, and if so it gives them an error/warning to not do that. It is only for debugging purposes.\r\n\r\n@TomFinley @shauheen '"
423949354,3054,b'Textloader behavior for non present columns',"b'```\r\nMLContext mlContext = new MLContext();\r\nmlContext.Log += MlContext_Log;\r\nvar loader = mlContext.Data.CreateTextLoader(new Data.TextLoader.Options()\r\n{\r\n    Columns = new[] { new Data.TextLoader.Column(""A"", Data.DataKind.Int32, 0),\r\n                      new Data.TextLoader.Column(""B"", Data.DataKind.Single, 1),\r\n                      new Data.TextLoader.Column(""C"", Data.DataKind.Single, 2),\r\n                      new Data.TextLoader.Column(""D"", Data.DataKind.Single, 3),\r\n                      new Data.TextLoader.Column(""E"", Data.DataKind.Single, 4),\r\n                      new Data.TextLoader.Column(""F"", Data.DataKind.Single, 5),\r\n                      new Data.TextLoader.Column(""G"", Data.DataKind.Single, 6),}\r\n                      });\r\nvar data =loader.Load(""sample.txt"");\r\nvar pr = data.Preview();\r\n}\r\n\r\nprivate static void MlContext_Log(object sender, LoggingEventArgs e)\r\n{\r\n    Console.WriteLine(e.Message);\r\n}\r\n```\r\n[sample.txt](https://github.com/dotnet/machinelearning/files/2994016/sample.txt)\r\n\r\nRight now if I inspect any column other than ""A"" I would see array of zeros.\r\nI see no messages in log regarding: column with index 1 not found.\r\nI\'m not sure why it\'s zeros and not NaN (so we can treat them as missing values).\r\nI don\'t know what behavior should TextLoader have, either fail or send warning messages, but I found it strange what we don\'t do anything right now.'"
423927392,3053,b'Defining a TextLoader with `hasHeader=true` and no data sample results in no slot names',"b'Related to issue #2663. We need to document the fact that if we create a `TextLoader` specifying `hasHeader=true` but without a data sample, then we are actually just letting the loader know that it needs to skip the first line when it eventually loads from a text file. The output schema of that `TextLoader` will not contain slot names, since the schema is created when the loader is created, and not when `Load` is called.'"
423917863,3051,b'LoadFromTextFile invalid model throw NullReferenceException',b'### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.2.104\r\n Commit:    73f036d4ac\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.104\\\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to load a model from [this Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction/kernels). My model definition skipped a column index.\r\n\r\n- **What happened?**\r\n\r\nNullReferenceException\r\n\r\n- **What did you expect?**\r\n\r\nA user-friendly error message. \r\n\r\n### Source code / logs\r\n\r\n```\r\npublic class KingCountyHouseData\r\n{\r\n        [LoadColumn(0)]\r\n        public string Id { get; set; }\r\n\r\n        [LoadColumn(1)]\r\n        public string SaleDate { get; set; }\r\n        public float Price { get; set; } // <== this was missed\r\n\r\n        [LoadColumn(2)]  // <=== this should be +1\r\n        public float Bedrooms { get; set; }\r\n\r\n        [LoadColumn(3)]  // <=== this should be +1\r\n        public float Bathrooms { get; set; }\r\n\r\n        [LoadColumn(4)]  // <=== this should be +1\r\n        public float LivingAreaSquareFoot { get; set; }\r\n\r\n        [LoadColumn(5)]  // <=== this should be +1\r\n        public float Floors { get; set; }\r\n\r\n        [LoadColumn(6)]  // <=== this should be +1\r\n        public bool Waterfront { get; set; }\r\n\r\n        //.... more fields below.\r\n}\r\n```'
423880131,3050,b'Rename ImageType to ImageDataViewType',"b'With #2297 we decided to suffix all the IDataView type classes with `DataViewType` instead of just `Type`. However, we missed `ImageType`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.ImageAnalytics/ImageType.cs#L12\r\n\r\nWe should rename this class as well to match the rest in the hierarchy. This will need to be done before v1.0 since it would be a breaking change to rename it later.'"
423870703,3049,b'Get cross val data splits',"b'Today, the very useful TrainTestSplit API hangs off MLContext. (This, of course, divides an input dataset into train and test portions.)\r\n\r\nIt would also be quite useful if you could expose a similar method -- CrossValSplit, which would split the data into cross val folds.\r\n\r\nUsing the same train/test splits across many training iterations would allow caching / re-use of various parts of the training pipeline across multiple iterations'"
423868546,3048,"b'MLContext class reference-doc should explain the seed parameter better and further introduction about the catalogs, etc.'","b'This is the reference doc for MLContext constructor:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.mlcontext.-ctor?view=ml-dotnet#Microsoft_ML_MLContext__ctor_System_Nullable_System_Int32__System_Int32_ \r\n\r\nCurrently, it just says the following about the \'seed\' parameter:\r\n\r\n_""Random seed. Set to null for a non-deterministic environment.""_\r\n\r\nThe info provided here is too simple. This should be the place to explain in further details what the MLContext class is for.\r\n\r\nEspecially, the `seed `parameter should be properly explained here. Why do we have such a parameter in the constructor and when to use it (deterministic results, etc.) with further explanations and example cases.\r\n\r\nAlso, explain if the `seed ` parameter is applicable or impacts only when using MLContext for training (creating a model) or if `seed `parameter matters or not if you are just loading a model from a .ZIP file and scoring with it etc.\r\n\r\nFinally, if it is recommended in most cases to have a seed, why don\'t we put any value as a by default value for the `seed ` parameter? For getting started users, the seed parameter feels really strange..\r\n\r\n\r\n'"
423857474,3047,b'Enable setting NormalizingEstimator options',"b'In PR #2959 we hid the NormalizingEstimator `ColumnOptions`. Currently users cannot set advanced parameters for the estimator.\r\n\r\nThe reason for not doing that was that `NormalizingEstimator` has 5 `ColumnOptions` classes and would have required at least that many overloads. So we opted for **waiting for the full `Options`** object to be made accessible and make sure that **no breaking API change** was going to be required. \r\n\r\nHowever, as per further discussion in #2884 and offline we decided that we would not make `Options` available before v1. We therefore need another solution.\r\n\r\nOne possible approach would be to add five new extensions to MLContext each presenting all the settings in one of the NormalizingEstiamtor `ColumnOptions`. The extensions could indicate in their name the type of normalization to perform.\r\n\r\nNote that this is not a breaking API change.'"
423844703,3045,b'DataViewType ToString should not use old DataKind names',"b'All the DataViewType ToString methods are returning DataKind names instead of ""normal .NET"" type names.\r\n\r\n```\r\nI4\r\nU8\r\nR4\r\netc.\r\n```\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5b22420d28c0cacc9b265d043555b6d11a017b91/src/Microsoft.ML.DataView/DataViewType.cs#L203-L222\r\n\r\nWe should change these to use typical .NET type names, like we have in the public API.\r\n\r\nNote: there are a bunch of tests that will need to be fixed with this since it baselines these names in baseline files.'"
423612907,3043,b'Add support for Isolation Forests',"b""Isolation forests appear to be one of the best options available for anomaly detection. I was disappointed to see that ML.NET doesn't support this algorithm.\r\n\r\nI don't have much experience in this field, but these people do and they seem to agree: http://www.eurecom.fr/en/publication/5334/download/data-publi-5334_2.pdf\r\n\r\nOne important aspect of isolation forests is that they allow for unsupervised online learning. There are endless applications for such an algorithm. I'm hoping to see this available in ML.NET in the future!"""
423534776,3040,b'Samples needed to show how to examine model weights',b'Currently it is very difficult to inspect model parameters.  It requires a lot of casting and non-trivial DOM navigation to get to actual weights of the model.\r\nIt would be good to have samples that inspect:\r\n1. Weights of a linear model\r\n2. Splits and nodes of a tree model\r\n\r\n'
423466041,3038,b'Getting exception when trying to evaulate in sample -PCA based Anomaly Detection',b'\r\n### Issue\r\n\r\nI am trying to create a new sample based on PCA based Anomaly Detection i.e CreditRisk Detection. i am using the **German Credit Risk** data as dataset from [here](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)). It contains label values as 1 and 2 with 1-positive and 2-negative.\r\n\r\nI am trying to train the model on train data by dropping label column as PCA based anomaly detection trains on unsupervised data. When I am trying to evaluate I am getting the **error** as below\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/54717972-addfcd80-4b16-11e9-8222-0efccdfe8252.png)\r\n\r\n\r\n### Source code / logs\r\n\r\nthe source code is available at the PR [https://github.com/dotnet/machinelearning-samples/pull/321](url)'
423432935,3037,b'Getting started with ML .NET with in-memory data is *painful*.',"b'Working with latest F#4.5 and net standard I\'m having huge problems trying to do even the most basic explorations with the latest ML .NET. Is there any example showing an absolutely basic example for an in-memory dataset using a simple ML algorithm?\r\n\r\nI\'m talking something as simple as an example from e.g. [scikit-learn](https://mcalglobal.com/2018/02/22/machine-learning-hello-world-using-python/) e.g. the following hello world is 7 lines of code, and if you leave at the data loading side of things and just focus on the ML side of things - which is exactly what I want to do - it\'s the following *three lines of code*.\r\n\r\n```\r\nmodel = linear_model.LinearRegression()\r\nmodel.fit(sqfeet, price)\r\nmodel.predict( pd.DataFrame([1750]))\r\n```\r\n\r\nLets try and port this into F#. Here\'s the source data as a simple F# list.\r\n\r\n```fsharp\r\ntype Observation = { Area:int; Price:int }\r\nlet data =\r\n    [ { Area = 1100; Price = 119000 }\r\n      { Area = 1200; Price = 126000 }\r\n      { Area = 1300; Price = 133000 }\r\n      { Area = 1400; Price = 150000 }\r\n      { Area = 1500; Price = 161000 }\r\n      { Area = 1600; Price = 163000 }\r\n      { Area = 1700; Price = 169000 }\r\n      { Area = 1800; Price = 182000 }\r\n      { Area = 1900; Price = 201000 }\r\n      { Area = 2000; Price = 209000 } ]\r\n```\r\n\r\nI\'ve spent a good few hours fighting with the API to try and get some - any - results. **I can\'t figure it out**.\r\n\r\nIssues I\'ve encountered:\r\n\r\n1. Discoverability. The API is pretty large and not (in my personal opinion) easy to navigate your way around. The namespaces need to be reworked so that the most obvious types are easy and obvious to get to.\r\n1. F# scripts are a pain because of the ""occasional"" reliance on native DLLs. However, you can work around this (or fall back to console applications if needed).\r\n1. Error messages are painful - `I4`, `R4` etc. etc. - most people will not know what these are.\r\n1. Vector types - it seems that in order to ""use"" data with a trainer you need to ""convert"" data from e.g. `float32` into a ""vector"" of `float32`. There\'s no explanation of what a ""vector"" in the context of ML .NET is, nor how to create one. Is it a .NET type? How do I create it? More than that, why as a developer should I have to care about it? I just want to give some of my data to the library as quickly and easily as possible.\r\n1. Why do I need to convert from ints or floats into float32s to do some machine learning? Again, this raises the barrier to entry. This is an internal implementation detail of ML .NET, it\'s nothing that should be forced on the developer.\r\n1. Why do I need the `MLContext`? What does it do? Does it store some ""hidden state""? What? Why?\r\n\r\nI managed to overcome some issues by randomly fumbling around with some existing samples until I got something that seemed to not error any more:\r\n\r\n```fsharp\r\nlet estimator, mlContext =\r\n    let mlContext = MLContext(Nullable 1)\r\n\r\n    let trainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(DefaultColumnNames.Label, ""Features"")\r\n\r\n    EstimatorChain()\r\n        .Append(mlContext.Transforms.Conversion.ConvertType(Transforms.TypeConvertingEstimator.ColumnOptions(""ConvertedArea"", DataKind.Single, ""Area"")))\r\n        .Append(mlContext.Transforms.CopyColumns(DefaultColumnNames.Label, ""ConvertedArea""))\r\n        .Append(mlContext.Transforms.Conversion.ConvertType(Transforms.TypeConvertingEstimator.ColumnOptions(""ConvertedPrice"", DataKind.Single, ""Price"")))\r\n        .Append(mlContext.Transforms.Concatenate(""Features"", ""ConvertedPrice""))\r\n        .AppendCacheCheckpoint(mlContext)\r\n        .Append(trainer), mlContext\r\n```\r\n\r\nNext. I try to fit my data to this model:\r\n\r\n```fsharp\r\nlet dv = mlContext.Data.LoadFromEnumerable(data)\r\nlet trained = estimator.Fit(dv)\r\n```\r\n\r\nThis returns, but then calls to `CreatePredictionEngine` fail with the error `System.ArgumentOutOfRangeException: Could not find input column \'Area\'`:\r\n\r\n```fsharp\r\ntype PredictionInput = { Price : int }\r\n[<CLIMutable>]\r\ntype PredictionOutput = { Area : int }\r\n\r\nlet z = trained.CreatePredictionEngine<PredictionInput, PredictionOutput>(mlContext)\r\n\r\nz.Predict { Price = 1000 }\r\n```\r\n\r\nTo get to this stage has taken 4-8 hours of effort (including spending 30-45 minutes with your team personally :-)). I don\'t consider myself a complete beginner when it comes to .NET / F# / machine learning - if it takes this long to get up and running, most people will simply not bother and go to scikit-learn, breeze or whatever else it out there.\r\n\r\nI would love to see a *simple* API that looked something like this:\r\n\r\n```fsharp\r\nlet model = Trainers.Regression.StochasticDualCoordinateAscend.fit(data, ""Area"", ""Price"")\r\nlet prediction = model.Predict(1234)\r\n```\r\n\r\nor\r\n\r\n```fsharp\r\nlet model = Trainers.Regression.StochasticDualCoordinateAscend.fit(data, fun d -> d.Area, fun d -> d.Price)\r\nlet prediction = model.Predict(1234)\r\n```\r\n\r\netc. etc.\r\n\r\nI get that there are more complicated scenarios - but I feel that this library should really be starting from the lowest common denominator and working from there. At the moment it seems to be the other way around.'"
423022552,3031,b'Cancellation checkpoints in LogisticRegression',b'**Goal:**\r\nImplement a way to a cancel Logistic Regression training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow is the performance graphs of Logistic Regression run from [this ](https://github.com/dotnet/machinelearning/blob/3af9a5d96ade88e888894af23baef8fe4598f826/docs/samples/Microsoft.ML.Samples/Dynamic/LogisticRegression.cs#L8) example. The graph will have a function selected and red stripes indicate the position in the graph it is called.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54652127-f0e86500-4a72-11e9-9fad-8fd034ee2a5f.png)\r\n\r\nThe checkpoint should be at `cursor.MoveNext()` in `TrainCore` method. As we can see in the graph this function is called periodically in the training process. Everything before this is CPU cycles consumed by the transforms and it is not related to Logistic Regression training cycles.'
423014771,3027,b'Cancellation checkpoints in FastTree',"b'**Goal:**\r\nImplement a way to a cancel FastTree training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow are the performance graphs of FastTree run from [this ](https://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/FastTree.cs#L12) example. The graph will have a function selected and red stripes indicate the position in the graph it is called.\r\n\r\nThe first checkpoint would be **`InitializeBins`** as evident from the below graph. We see before training there is the data prep step that is CPU intensive. In this step transpose of the dataset is created in-memory and binning of features is done. \r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650437-c646de00-4a6b-11e9-860e-c92b014b4105.png)\r\n\r\nThe second place would be somewhere in the Feature Flock creation. Here we think `CreateFlocksCore` would be ideal. Based on the below graph.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650452-db237180-4a6b-11e9-9aa1-9584d8732b3c.png)\r\n\r\n\r\nThe third place would be at `FeatureHistogram` ctr called by `CreateSufficientStats`. This function is called by constructor of `LeastSquaresRegressionTreeLearner` within a loop that creates `CreateSufficientStats`. We will just place a checkpoint in this loop.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650724-0c507180-4a6d-11e9-9ac2-7708ba680e6f.png)\r\n\r\nThe last place would be somewhere we do the splitting of the nodes and partitioning of the data to construct the tree. We see that **`FindBestThresholdForFlockThreadWorker()`** seems to be a good place to check for cancellation signal as it seems to consume bulk of CPU cycles as evident from the red stripes in the graph. We can also place the checkpoints into the functions that it calls such as `FindBestThresholdFromHistogram`, `Sumup`, `SubtractCore`, `FillSplitCandidates`, `FindBestSplitForFeature` but I think place checks in the inner function could degrade the performance. \r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54649487-a7464d00-4a67-11e9-9253-2a20b9ddb67e.png)\r\n\r\nCC: @TomFinley , @eerhardt , @shauheen , @glebuk \r\n'"
422997644,3025,"b'About models, ITransform, and IDataLoader, saving/loading'","b'So, I had a conversation with @eerhardt and @yaeldekel, about the nature of models, in particular relating to the saving and loading routines. This is very important for us to get right, since the artifacts of what we learn and how we transform data, and their persistability, is probably the most important thing we have to do correctly.\r\n\r\nWe take the view initially that the model is the `ITransformer` (note that a chain of `ITransformer`s is itself an `ITransformer`). But, by itself this is an insufficient description, was we saw in in #2663 and its subsequent ""child"" #2735, from the point of view of model being practically ""the stuff you need to keep,"" there\'s a lot more to a machine learning model than merely just the `ITransformer` chain -- you also need to preserve some notion of what the input is to that. So we added these things to take either a loader, or the input schema, to be saved as part of the model.\r\n\r\nYet, is the loader a model itself? Sometimes that\'s precisely what we call it:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L36\r\n\r\nAnd in the same file we call it something else:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L65\r\n\r\nIt is a model in one sense because it is yet another things that takes input data and produces output data -- the fact that `ITransformer` does it specifically over `IDataView` as input *specifically* does not give it some magical, special status to allow it to be called a model, to the exclusion of other candidates. If I take a loader, and append a transform to it, then the whole aggregate thing is *still* a loader. If it isn\'t a model, it only isn\'t one by the mere skin of its teeth. Hence the presence of the original thing, and why we have in the model operations catalog operations to save and load `IDataLoader` itself specifically.\r\n\r\nBut at the same time this duality of the term ""model"" is, as I understand @eerhardt, confusing. We have two things we\'re calling model. In an ideal world, I feel like if we *can* get away with just one story of what the model is, we should take it, and if there must be only one it must be `ITransformer`. We even have the situation where if you have `mlContext.Model.Save(`, the first thing that pops up is the `IDataLoader` thing, which is kind of strange.\r\n\r\nI am not quite sure what I think, since in this case I agree with whoever talks to me last with an even a vaguely convincing argument. But I think in this case I will see about getting rid of the `IDataLoader`-only APIs -- people can, if it is important, continue to save and load such things by using empty `ITransformer` chains (again, any chain of `ITransformer` is itself an `ITransformer`, including the empty chain).\r\n\r\nSince we are approaching v1, I view it as a bit more important to be conservative w.r.t. potentially confusing additions to the API, especially around something as central as the saving and loading of models. We might be able to add it back later if there\'s some really compelling scenario for them, that we somehow did not anticipate.\r\n\r\nWe will of course retain the saving and loading of transformers *with* loaders, since that is really important to be able to capture, but I think being consistent around the story that ""models are transformers"" as we are most places is kind of important.'"
422993685,3024,b'Cancellation checkpoint in StochasticDualCoordinateAscent ',"b'**Goal:**\r\nImplement a way to a cancel SDCA training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow is the performance graph of SDCA run from [this ](https://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/StochasticDualCoordinateAscent.cs#L9)example.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54647615-63037e80-4a60-11e9-9c91-a24c1cb5728f.png)\r\n\r\nWe see that **MoveNext() in TrainWithoutLock** seems to be a good place to check for cancellation signal as it seems to consume bulk of CPU cycles as evident from the red stripes in the graph.\r\n\r\nThe second checkout point would be **CheckConvergence** as evident from the below graph (look for red stripes):\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54647749-fdfc5880-4a60-11e9-8ec6-aec689a7abb1.png)\r\n\r\nCC: @TomFinley , @eerhardt , @shauheen , @glebuk \r\n'"
422933332,3016,"b'The ""Binary"" in ""LogisticRegressionBInaryTrainer"" Looks Redundant'","b'As title. Logistic regression is clearly a binary classifier, so we can consider dropping ""Binary"" among ""LogisticRegressionBinaryTrainer"". In addition, as L-BFGS is outperformed by SDCA and SymSGD, I feel we should not call this class `LogisticRegressionTrainer`. A suggested solution is to prepend `Lbfgs` to this class\' name.'"
422896100,3015,b'Missing libompd library for MklRedist nuget',"b'### Issue\r\nWith the latest changes to add openmp back with mkl, the libompd library for windows needs to be packaged as part of the MklRedist nuget package.\r\n'"
422888031,3014,"b""Can't find CollectionDataSource class ""","b""### System information\r\n\r\n- **OS Windows**\r\n- **.NET Version 4.7.2**: \r\n\r\n### Issue\r\n\r\nHi, I'm using ML.NET 0.11 in an ASP.Net MVC 5 Web App. the .Net version is 4.7.2 and I can use the CollectionDataSource to load data from list to the pipeline. How can I use it?\r\n\r\n\r\n"""
422877546,3013,b'All transforms extensions should be tested',"b'PR #2959 introduces new extensions and internalizes all the ones that rely on `ColumnOptions`.\r\nMost new extensions call the same constructor as the ones that were made internal. \r\n\r\nHowever, it would be best to make sure that all transforms extensions are being used in some tests.\r\n\r\n'"
422874003,3012,b'Need public constructor and settable properties on RegressionMetrics and their sibling classes ',"b""AutoML API returns Metric for each hypothesis it builds and runs.\r\nWhen data is small autoML API internally does cross validate (instead of train validate) and the metric it wants to return is the average of the metric from training each fold.\r\nCurrently it is not possible to build a new metric object and populate it with average values since the RegressionMetric and their siblings etc don't have public constructor.\r\n\r\nCan we please provide a public constructor to these Metric classes?\r\nIt will be great if we can accomadate for 0.12 release.\r\n\r\n@TomFinley @shauheen  \r\n"""
422733361,3009,"b""Can't find the constructor for MulticlassClassificationTrainers(ctx) (v0.10)""",b'Hello \r\n\r\nwhere is the constructor for a call like:\r\n\r\nvar sdcaContext = new MulticlassClassificationCatalog(ctx);\r\n\r\nbeen moved in 0.11? \r\n'
422493636,3007,b'Perf: Optimization for DoubleParser (VTune)',"b'Benchmarking using VTune has found several bottlenecks in parsing Doubles from string in text reader\r\nPerhaps we should consider optimizing this method:\r\nFor example, for training a FM it takes almost 37% of all clock cycles:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 27.390s\r\nCalculateGradientAndUpdateNative | factorizationmachinenative.dll | 22.609s\r\nHelperImpl::FetchNextField | Microsoft.ML.Data.dll | 13.826s\r\nCalculateIntermediateVariablesNative | factorizationmachinenative.dll | 12.201s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParse | Microsoft.ML.Core.dll | 9.666s\r\n\r\n'"
422490989,3005,b'Enum Name --- OneHotEncodingEstimator.OutputKind',"b'I personally prefer `OneHotEncodingEstimator.Representation` than `OneHotEncodingEstimator.OutputKind`. @sfilipi, @TomFinley, @rogancarr, any comment please?'"
422490241,3004,b'Perf: Optimization for GAMs (VTune)',"b'Benchmarking using VTune has found several bottlenecks in GAMS\r\n\r\n- Significant CPU cycles spent in Interlocked.CompareExchange. \r\n- Call-stack & source code of CenterGraph shows Interlocked.CompareExchange in the inner loop, contributing to the high CPU cycles in CompareExchange. Look at reducing the calls to this intrinsic.\r\n- Next step: Look at re-jiggering the code in CenterGraph to avoid the CompareExchange in the inner loop\r\n\r\nTop HotSpots:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nCOMInterlocked::CompareExchangeDouble | coreclr.dll | 55.754s\r\n<>c__DisplayClass46_0::<UpdateScoresForSet>b__0 | Microsoft.ML.FastTree.dll | 35.381s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 30.808s\r\n<>c__DisplayClass49_0::<CenterGraph>b__0 | Microsoft.ML.FastTree.dll | 26.872s\r\n\r\n\r\n\r\n'"
422477405,3003,b'MatrixFactorizationTrainer prints log statements to console even if Quiet = true',"b'Even when MatrixFactorizationTrainer option Quiet=true, the iterations print to console.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/481c37774afdbc6f8b1eab9c9f894c83f3ac984d/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs#L160\r\n\r\n![image](https://user-images.githubusercontent.com/10437687/54569846-8f07fc80-4999-11e9-8cec-b6808af726f8.png)'"
422475837,3002,b'Add check for collision of  `OutputTokensColumnName` with `OutputColumn` in `FeaturizeText`',b'Add check for collision of  `OutputTokensColumnName` with `OutputColumn` in `FeaturizeText`\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/2985#issuecomment-474100886\r\n\r\n\r\n'
422466180,3001,b'Perf: Optimization for MatrixFactorization',"b'Benchmarking using VTune has found several bottlenecks in Matrix Factorization training algorithm.\r\n-Experiment to find potential gain with AVX & SSE & Intrinsics  in matrixfactorizationnative.dll module\r\n-Based on result of above experiment, take a look at implementing this in the product [fat binary vs dynamic dispatch]\r\n\r\n'"
422465049,3000,b'Perf: Optimization for FactorizationMachine',b'Benchmarking using VTune has found several bottlenecks in Factrization Machine training algorithm.\r\n\r\n- Some phases training that are not parallelized. Consider adding parallel computation.\r\n- Evaluate using AVX/AVX2 (C++ or C# instrinsics) in factorizationmachinenative.dll which currently implements C++ SSE code\r\n- Consider optimizing the following hotspot\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 27.390s\r\nCalculateGradientAndUpdateNative | factorizationmachinenative.dll | 22.609s\r\nHelperImpl::FetchNextField | Microsoft.ML.Data.dll | 13.826s\r\nCalculateIntermediateVariablesNative | factorizationmachinenative.dll | 12.201s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParse | Microsoft.ML.Core.dll | 9.666s\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'
422428280,2998,b'The result of the weights calculation in the build definitions making use of Intrinsics are different from the other builds. ',"b'I am adding [a test](https://github.com/dotnet/machinelearning/pull/2048/files#r266634629) in [this PR](https://github.com/dotnet/machinelearning/pull/2048) and it is failing in the following definitions:\r\n\r\n* core30 Build_Debug_Intrinsics\r\n* core30 Build_Release_Intrinsics\r\n* CentOS Build_Debug_Intrinsics\r\n* Ubuntu Build_Release_Intrinsics\r\n\r\nThe weight calculation for MulticlassLR in those build definitions are different from the ones in the other definitions. \r\n\r\nweights in windows x64\r\n[0, 0.5247429, -2.43042159, -0.490746975],\r\n[0.210617781, 0, 0, -0.370147228],\r\n[1.62008985E-06, -0.002228372, 2.49340868, 1.77681744]\r\n\r\nweights in windows core30_debug_Intrinsics:\r\n[0, 0.621862, -2.38398933, -0.427630424],\r\n[0.108599916, 0, 0, -0.372884184],\r\n[-0.106881194, -0.0351369865, 2.42675567, 1.80688608]'"
422424814,2997,b'Add support for cancelling of training',"b'Once the cancellation mechanism is available, we need to enable cancellation of training for the following learners:\r\n- RegressionCatalog.Trainers.StochasticDualCoordinateAscent\r\n- RegressionCatalog.Trainers.FastTree\r\n- BinaryClassificationCatalog.Trainers.FastTree\r\n- BinaryClassificationCatalog.Trainers.LogisticRegression\r\n\r\nThis is continuation of #2795 \r\n\r\nAt the very least we should be able to check for cancellation at the beginning of training and at the beginning of each iteration.\r\n\r\n## Pri2: Also do this for:\r\n- Normalization\r\n- OneHotEncoding'"
422396695,2996,b'Cannot create TextLoader without loading assemblies into ComponentCatalog',"b'In the `TextLoader` constructor, it is allows to pass a null `Options`, or an `Options` object with a null `Columns` (see https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1095 and https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1111).\r\nWhen this is the case, the constructor goes to `TryParseSchema` which uses the `ComponentCatalog` to load the schema, so we get a null reference exception here: https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1293, if no assemblies are loaded.'"
422083705,2994,b'I want to convert a text classification sample from ML 0.4 to ML 0.11 and cannot find equivalent code for calling Transforms.Text.FeaturizeText',"b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI want to convert a text classification sample from ML 0.4 to ML 0.11\r\n- **What happened?**\r\nI cannot find equivalent parameters for TextFeaturizer, there are no CharFeatureExtractor and WordFeatureExtractor NgramExtractors in 0.11 Transforms.Text.FeaturizeText arguments\r\n\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\n**0.4 version**\r\n\r\n```\r\n                new TextFeaturizer(""Features"", ""TextColumn"")\r\n                {\r\n                    KeepDiacritics = false,\r\n                    KeepPunctuations = false,\r\n                    OutputTokens = true,\r\n                    Language = TextFeaturizingEstimatorLanguage.English,\r\n                    VectorNormalizer = TextFeaturizingEstimatorTextNormKind.L2,\r\n                    TextCase = TextNormalizingEstimatorCaseNormalizationMode.Lower,\r\n                    CharFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = false},\r\n                    WordFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = true}\r\n                }, \r\n\r\n```\r\n\r\n\r\n**0.11 version**\r\n\r\n```\r\nvar transform mlContext.Transforms.Text.FeaturizeText(outputColumnName: ""TextColumnFeaturized"",\r\n                        options: new TextFeaturizingEstimator.Options()\r\n                        {\r\n                            KeepDiacritics = false,\r\n                            KeepPunctuations = false,\r\n                            OutputTokens = true,\r\n                            TextLanguage = TextFeaturizingEstimator.Language.English,\r\n                            VectorNormalizer = TextFeaturizingEstimator.TextNormKind.L2,\r\n                            TextCase = TextNormalizingEstimator.CaseNormalizationMode.Lower,\r\n                            UseWordExtractor = true,\r\n                            UseCharExtractor = true\r\n                        }, inputColumnNames: new []{ ""TextColumn"" });\r\n```\r\n\r\nI see that CharFeatureExtractor and WordFeatureExtractor parameters are gone, and instead two we have boolean properties, UseWordExtractor and UseCharExtractor.\r\n\r\nThe models trained using the above code and the same train data perform differently, namly the 0.4 version has a better classsification performace.\r\n\r\nHow do I configure a pipeline to achieve the same results as in 0.4 version?\r\n\r\n\r\nThank you!\r\n\r\n'"
421788246,2989,b'DateTime  ERROR',"b'### System information\r\n\r\n- **OS version/distro**:  Windows 10 Home\r\n- **.NET Version (eg., dotnet --info)**:  .net core 2.2.0\r\n\r\n### Issue\r\nI updated Nuget package from ML 0.8 to 0.11. I have a truble. \r\nMy csv File contain:\r\n\r\nSECID,CurrentDate,OpenPrice,FareClosePrice\r\nLKOH,2019-01-01,4984.00,5007.00\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n  _textLoader = mlContext.Data.CreateTextLoader(\r\n                separatorChar: \',\',\r\n                hasHeader: true,\r\n                columns: new TextLoader.Column[]\r\n                {\r\n                    new TextLoader.Column(""SECID"", DataKind.String, 0),\r\n                    new TextLoader.Column(""CurrentDate"", DataKind.DateTime, 1),\r\n                    new TextLoader.Column(""OpenPrice"", DataKind.Double, 2),\r\n                    new TextLoader.Column(""FareClosePrice"", DataKind.Double, 3)\r\n                });\r\n\r\n           IDataView dataView = _textLoader.Load(dataPath);\r\n            var pipeline = mlContext.Transforms.CopyColumns(""Label"", ""FareClosePrice"")\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""SECID""))\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""SECID"", ""CurrentDate"", ""OpenPrice"", ""FareClosePrice""))\r\n            .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n// An error occurs here:  System.InvalidOperationException: ""Column \'CurrentDate\' has values of // DateTimewhich is not the same as earlier observed type of R4.""\r\n\r\n            var model = pipeline.Fit(dataView);\r\n\r\n'"
421740613,2986,b'Co-locate VBuffer and VectorType with IDataView',"b'Once we do #2974, to move `IDataView` into the `ML` namespace, we should move `VBuffer`, `VectorType` and `KeyType` into the same assembly/package as `IDataView`.\r\n\r\n`VBuffer` and `KeyType` were left in `Microsoft.ML` because they were too specific to machine learning usages to be in `Microsoft.Data`. If we are moving `IDataView` back into the `Microsoft.ML` namespace, then we should be able to locate these types in the same package.\r\n\r\ncc @TomFinley @shauheen @glebuk '"
421720910,2983,b'Add MLContext.Model.Load overload that takes a file path',"b""Today, the only way to load a model is by using a `Stream`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2464f606c69357898572aac8e4d8d3c1451c92f/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L36-L41\r\n\r\nWe should add an overload that takes a `string filePath` as a convenience API over top of this. That way all the callers don't need to open a `FileStream` and dispose of it, etc, just to load a model.\r\n\r\n@TomFinley @CESARDELATORRE @sfilipi @shauheen """
421720200,2982,b'ONNX Transform changes output types',"b'Serializing and deserializing a model to and from ONNX not only changes the names of the output (#2980) but also changes the types of the output. For example, a `Score` column produced by a model (`R4`/`float`) becomes a `Vec<R4, 1, 1>`.'"
421716798,2981,b'Cannot fit an Onnx Transform as part of a pipeline',"b'It is possible to fit an ONNX model by itself:\r\n\r\n```cs\r\nvar onnxEstimator = mlContext.Transforms.ApplyOnnxModel(modelPath)\r\nvar onnxModel = onnxEstimator.Fit(data);\r\n```\r\n\r\nBut it throws when it is part of a pipeline:\r\n```cs\r\nvar onnxEstimator = mlContext.Transforms.ApplyOnnxModel(modelPath)\r\n    // TODO #2980: ONNX outputs don\'t match the outputs of the model, so we must hand-correct this for now.\r\n    .Append(mlContext.Transforms.CopyColumns(""Score"", ""Score0""));\r\n    .Append(mlContext.Transforms.CopyColumns(""Label"", ""Fable""));\r\n    .Append(mlContext.Transforms.NormalizeLpNorm(""Features2"", ""Features"", LpNormNormalizingEstimatorBase.NormFunction.L2));\r\nvar onnxModel = onnxEstimator.Fit(data);\r\n```\r\nAny of these `Append` statements cause a throw. They do not affect the ONNX model at all, and use either the result of the calculation (`Score0`), rows unused by the model (`Label`) or rows also used by the transform (`Features`).\r\n\r\nIn this case, the error message is:\r\n`System.ArgumentOutOfRangeException : Schema mismatch for input column \'Label\': expected vector, got R4\r\nParameter name: inputSchema`'"
421712433,2980,"b""ONNX outputs don't match model outputs after serialization""","b""When I save a model to ONNX, load, and apply it with `ApplyOnnxModel`, it adds a zero as a suffix to all columns, including the expected output. This includes input columns, so the resulting `IDataView` now has double the columns, plus the output. To top it off, it's not clear how to find the output because it's been renamed.\r\n\r\nExample:\r\nML.NET model\r\n  Input:  `Features`\r\n  Output: `Score`\r\n  Resulting Schema: `Features`, `Score`\r\n\r\nAfter Onnx Serialization / Deserialization:\r\n  Input: `Features`\r\n  Output: `Features0`, `Score0`\r\n  Resulting Schema: `Features`, `Features0`, `Score0`\r\n\r\nI am not sure if this is by design, but it feels like a bug."""
421694588,2978,b'Public API for SchemaDefinition class',"b'There are no samples/tests in the code that make use of this class, even though it is part of the public API.\r\n'"
421683219,2977,b'Somehow discourage (or embrace!!) Preview Debugger Extensions from public usage',"b'We have these debugger extensions meant to make ""debugger level"" inspection of things like `IDataView` and `IDataLoader` and such like more convenient. How nice!\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/87ede9ef39c10b8511fc7f14f97d1250bbd2b951/src/Microsoft.ML.Data/DebuggerExtensions.cs#L15\r\n\r\nNow, this is fine, or would be, except that, wouldn\'t you know it, people are actually using it in their applications, as opposed to more scalable solutions like the as-enumerable helpers or even direct usage of `IDataView` directly. Which, of course, is bad. \xf0\x9f\x98\x84 So we should discourage its use as bad practice in the API.\r\n\r\nTwo ways that occur to me:\r\n\r\n1. `Obsolete` attribute on the class to ""hint"" at people that they shouldn\'t be doing it (hopefully it will not show up as obsolete in immediate window),\r\n\r\n2. Write something to the code analyzer forbidding its use in a project, while allowing it in the immediate window.\r\n\r\nMaybe there\'s some other way.'"
421633105,2975,b'FeatureColumn vs FeatureColumnName in Model Transformers.',"b""In the public API, we've been switching `FeatureColumn` to `FeatureColumnName`. However, trained models like `SDCA` have `FeatureColumnName` in the input, but produce a `Transformer` that has a `FeatureColumn` property. I think this is widespread."""
421499966,2974,b'Move IDataView into Microsoft.ML namespace',"b'We\'ve received feedback that having `IDataView` in the `Microsoft.Data` namespace (which was done in #2220) is confusing to users. Traditionally, the `System.Data` namespace has been populated with ""database"" specific technologies. `Microsoft.Data` isn\'t all that different from `System.Data`, and one could argue they are basically the ""same thing"", with the `System.Data` technologies being inside of the BCL and/or `netstandard` definition while `Microsoft.Data` being built outside of the BCL/`netstandard` definition. There are already ""database"" specific APIs in `Microsoft.Data`, for example https://docs.microsoft.com/en-us/dotnet/api/microsoft.data.sqlite.\r\n\r\n`System.Data` even already has a [`DataView` class](https://docs.microsoft.com/en-us/dotnet/api/system.data.dataview), and `IDataView` and `DataView` are drastically different.\r\n\r\nTo solve this confusion, we should rename the `Microsoft.Data.DataView` NuGet package to `Microsoft.ML.DataView` and move the `Microsoft.Data.DataView` namespace under `Microsoft.ML`. The NuGet package will still be separated from the algorithms and transforms in the larger `Microsoft.ML` NuGet package. So the value of #1860 can still be realized. The separate package will just be branded `ML` instead of `Data`.\r\n\r\n/cc @TomFinley @shauheen @markusweimer @glebuk '"
421308185,2972,b'TrainCatalog and RecommenderCatalog need cleaning',b'There are some methods in the catalogs that do not respect the naming conventions that we are enforcing in the trainers and the transforms. \r\n\r\nThe methods that should be fixed are the `Evaluate` and `CrossValidate` in particular.\r\n\r\nWe should rename the parameters accordingly.'
421286304,2967,b'More tests for TextFeaturizer.',"b'TextFeaturizer is a complex transform and it takes more options as input then any other component in ML.NET. Using those options, the TextFeaturizer build up the underlying components.\r\n\r\nAssuming that underlying component are well tested, there is a need to test the options for TextFeaturizer so that we are sure that underlying components are created as intended and results produced are as expected.'"
421285020,2965,b'Scrubbing of FeatureContributionCalculation and Explainability Catalog',b'Explainability catalog should be cleaned up. \r\n\r\nThe `MlContext.Model.Explainability` catalog was created with the idea that all the model explainability operations would live there.\r\n\r\nBut it only contains `FeatureContributionCalculation` because `PermutationFeatureImportance` lives in the training task specific catalog (i.e. `MlContext.BinaryClassification`...) because it is task specific. \r\n\r\n@rogancarr  and @TomFinley  agreed that it is not desirable to have a subcatalog with only one transform. And since `FeatureContributionCalculation` is an estimator/transformer it should probably live under:\r\n\r\n`MlContext.Transforms.FeatureContributionCalculation`'
421284887,2963,b'Create functional tests for all ONNX scenarios',"b'As laid out in #2498 , we need scenarios to cover the ONNX functionality we want fully supported in V1.\r\n\r\nScenarios:\r\n- I can take an existing ONNX model and get predictions from it (as both final output and as input to downstream pipelines)\r\n- P1: I can export ML.NET models to ONNX (limited to the existing internal functionality) (In Model Files section, but can be fleshed out a bit better with other ONNX tests)'"
421257608,2958,b'Duplicate param NormalizeFeatures for FieldAwareFactorizationMachineBinaryClassificationTrainer.Options ',"b'FieldAwareFactorizationMachineBinaryClassificationTrainer.Options (subclass of TrainerInputBaseWithWeight) has a parameter:\r\n[Argument(ArgumentType.AtMostOnce, HelpText = ""Whether to normalize the input vectors so that the concatenation of all fields\' feature vectors is unit-length"", ShortName = ""norm"", SortOrder = 6)]\r\npublic bool Normalize = true;\r\n\r\nHowever base class TrainerInputBaseWithWeight already has such parameter:\r\n[Argument(ArgumentType.AtMostOnce, HelpText = ""Normalize option for the feature column"", ShortName = ""norm"", SortOrder = 5, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly)]\r\n        internal NormalizeOption NormalizeFeatures = NormalizeOption.Auto;\r\n\r\nWe have duplicate parameter to indicate whether to normalizes features.\r\n\r\n\r\n'"
421179861,2957,b'FeaturizeText outputTokens uses a magical string to name a new column',"b""When using `OutputTokens=true`, `FeaturizeText` creates a new column called `${OutputColumnName}_TransformedText`. This isn't really well documented anywhere, and it's odd behavior. I suggest that we make the tokenized text column name explicit in the API.\r\n\r\nMy suggestion would be the following:\r\n- Change `OutputTokens = [bool]` to `OutputTokensColumn = [string]`, and a `string.NullOrWhitespace(OutputTokensColumn)` signifies that this column will not be created.\r\n\r\nWhat do you all think?"""
421170418,2955,b'Update tests for OVA',b'Fixes for OVA went in independently of updates to the tests. The tests need to be updated so that master builds.'
421135717,2954,b'The samples that are part of the Microsoft.ML.Samples project need to have a corresponding baseline test',"b'The samples currently have compile time checks, by being part of the solution, but not runtime validation. \r\nCreate a baseline test for each sample, to verify the output of their execution has not changed. \r\n'"
420790199,2952,b'Create the Binary Classification With Array float values',"b'### Binary classification\r\n\r\nI want create a Machine Learning, but I need use a vector (array) of floats values (through of a sensor). My question is this, each value must be a Column or I must create a single Column with all values separate with a the comma?\r\n\r\n\r\n'"
420710834,2946,b'It is awkward to turn off char-grams with FeaturizeText',"b'`FeaturizeText` was upgraded to allow specification of n-grams for words and characters. However, now it awkward to use `FeaturizeText` *without* specifying n-grams. It is now necessary to explicitly set `CharFeatureExtractor` as `null`.\r\n\r\nThis is how to compose a bag-of-words with the current API:\r\n```cs\r\nvar pipeline = mlContext.Transforms.Text.FeaturizeText(\r\n    ""Features"",\r\n    new TextFeaturizingEstimator.Options\r\n    {\r\n        KeepPunctuations = false,\r\n        OutputTokens = true,\r\n        CharFeatureExtractor = null,\r\n        WordFeatureExtractor = new WordBagEstimator.Options { NgramLength = 1},\r\n        VectorNormalizer = TextFeaturizingEstimator.NormFunction.None\r\n    },\r\n    ""SentimentText"");\r\n```\r\n\r\nI would expect to be able to do something like\r\n```cs\r\nCharFeatureExtractor = new WordBagEstimator.Options { NgramLength = 0},\r\n```\r\nBut this throws an error that `Skipgrams` is not less-than `NgramLength`, and `Skipgrams` must be positive.\r\n\r\nOverall, it is a bit awkward and not obvious that you have to manually null a option. Is this the API we want to ship in v1.0?'"
420685279,2945,b'Ignore a column on Training',"b'### System information\r\n\r\n- Win10\r\n- .net core 2.1\r\n\r\nCan I tell Training to Ignore Columns in Training Data\r\n\r\nI tried just leaving them out of Features but that does not appear to work. I thought by not including them in Features it would ignore, but prediction results are not good. If I totaly remove those fields from Data, then my predictions are really good.\r\n\r\nI would like to ignore IncidentReportedByID, IncidentReportedMethod and ID.\r\n```\r\npublic class MyData\r\n    {\r\n        [LoadColumn(0)]\r\n        public float State;\r\n\r\n        [LoadColumn(1)]\r\n        public float City;\r\n\r\n        [LoadColumn(2)]\r\n        public float IncidentType;\r\n\r\n        [LoadColumn(3)]\r\n        public float IncidentReportedByID;\r\n\r\n        [LoadColumn(4)]\r\n        public float IncidentReportedMethod;\r\n        \r\n        [LoadColumn(5)]\r\n        public float Label;\r\n    }\r\n```\r\n\r\nmy training looks like this\r\n```\r\nvar dataProcessPipeline = mlContext.Transforms.Concatenate(DefaultColumnNames.Features, nameof(MyData.State),                                                                                   nameof(MyData.City),\r\n                                                                                   nameof(MyData.IncidentType),                                                                                   \r\n                                                                       .AppendCacheCheckpoint(mlContext);\r\n           \r\n            var trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumnName: DefaultColumnNames.Label, featureColumnName: DefaultColumnNames.Features);\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n```'"
420642399,2943,b'Documentation: Create ML.NET Component Guide',"b'# ML.NET Guide section of the documentation missing key summary information\r\nSpecifically we need \r\n1. Summary of components that guide users to components needed\r\n2. Guide on how to make pipelines performant\r\n3. Which items are exportable to ONNX\r\n4. Which trainers need caching/normalization?\r\n5. Which trainers and transformers to try first?\r\n\r\nWe can start with existing structure and augment missing information or add additional pages\r\nIdeally, we can make a searchable list with checks where users can filter components by criteria.  For example, I want to get me a ""linear, regression"" or ""streaming, exportable to ONNX""\r\n## Trainers\r\n\r\n| Dimension |\r\n| ------- |\r\n| Trainer Name |\r\n| Short Description |\r\n| ML Tasks Supported with API doc links to each function | \r\n| Common useful applications  |\r\n| Category/Algorithm | \r\n| In which NuGet? | \r\n| Supports export to ONNX? |\r\n| Single or multi pass (need caching?) | \r\n| Require data to be normalized?  | \r\n| Calibration needed  | \r\n| Types of input supported?  (one or many columns? )| \r\n| Kind of output produced  | \r\n| Scalability in terms of features and examples  | \r\n\r\n## Transformers\r\nThis information can be either presented either as a list, or graphically or as table, or as searchable table or something like [this](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\r\n\r\n| Column |\r\n| ------- |\r\n| Transformer Name |\r\n| Short Description |\r\n| Common useful applications  |\r\n| Trainable or not? (estimator/transformer) - good to list both types and links to API | \r\n| In which NuGet? | \r\n| Supports export to ONNX? |\r\n| Category/Algorithm | \r\n| Single or multi pass (need caching?) | \r\n| Types of input supported?  (1-1, 1-many etc )| \r\n| Types of input supported  (only floats or other? one or many columns? )| \r\n| What is the output looks like )| \r\n| Scalability in terms of features and examples  | \r\n\r\n## Loaders\r\n\r\n| Column |\r\n| ------- |\r\n| Loader Name |\r\n| Short Description |\r\n| Data file type  | \r\n| Category/Algorithm | \r\n| Common useful applications  |\r\n| Scalability in terms of speed and column count | '"
420635274,2941,b'Unity 3d Compatiblity',b'### System information\r\nWindows Development Unity project\r\n4.x or standard 2.x\r\n\r\n### Issue\r\nCan you make a future release compatible with the latest version of Unity 3D.   Now that Unity 3d supports framework 4.x and .net standard 2.0 this would be a great platform to build the next generation of ml.net applications.\r\n\r\nhttps://unity3d.com/\r\n\r\nUnity projects now supports Nuget for package pull down:\r\n\r\nhttps://github.com/GlitchEnzo/NuGetForUnity\r\n\r\n\r\nThank you so much for taking the time to consider this new compatibility feature\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'
420571124,2940,b'need documentation: handling varvect',"b'### System information\r\n\r\n- windows 10, fast ring\r\n- .net 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\ni have a data input class:\r\n```cs\r\n        class NightLightDataRow\r\n        {\r\n            public bool IsActive { get; }\r\n            public byte[] Data { get; }\r\n\r\n            [Microsoft.ML.Data.VectorType(38)]\r\n            public float[] Data2 { get; }\r\n\r\n            public NightLightDataRow() {}\r\n\r\n            public NightLightDataRow(byte[] data, bool isActive)\r\n            {\r\n                Data = data;\r\n                Data2 = Data.Select(d => (float)d).Take(38).ToArray();\r\n                IsActive = isActive;\r\n            }\r\n        }\r\n```\r\n\r\nI train it using `mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent`.\r\n\r\nI got it somehow working using `Data2`, but my real data are `Data` and have 38..43 elements. If I try to train it on that directly, it throws with\r\n\r\n> System.ArgumentOutOfRangeException: \'Schema mismatch for feature column \'Data\': expected Vector<R4>, got VarVector<R4>\r\nParametername: inputSchema\'`\r\n\r\nthis is the pipeline:\r\n\r\n```cs\r\nvar trainingPipeLine = \r\n                mlContext.Transforms.Conversion.ConvertType(""Data"")\r\n                .AppendCacheCheckpoint(mlContext)\r\n                .Append(\r\n                mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent(\r\n                            labelColumnName: nameof(NightLightDataRow.IsActive)\r\n                            , featureColumnName: nameof(NightLightDataRow.Data)\r\n                            ));\r\n```\r\n\r\nI understand why it is throwing, but I have no idea how to fix it. What could I do and what would be the correct piece of documentation?\r\n\r\nAlso as a side question: how do I start my trainingPipeline with a CacheCheckpoint? (If i would want to do cache=>StochasticDualCoordinateAscent directly without any transforms)\r\n'"
420344420,2938,b'More trainer related naming alignment',"b'Take another pass over the trainers and the model parameter types, and align them, because now we have:\r\n\r\n`LogisticRegressionMulticlassClassificationTrainer` but `MulticlassLogisticRegressionModelParameters`. \r\n\r\nI think following the same principles on the ModelParams might make them more relatable; so change `MulticlassLogisticRegressionModelParameters` to `LogisticRegressionMulticlassModelParameters`\r\n'"
420247676,2934,b'Logs are inscrutable',"b'There is a `Log` on `MLContext` objects, but it is very hard to read. It would be nice to add a `Level` to the log and some better organization than brackets.\r\n\r\nFor example,  SDCA returns lines like:\r\n```cs\r\n""[Source=SdcaTrainerBase; Training, Kind = Info] Auto - tuning parameters: L2 = 0.001."",\r\n""[Source = SdcaTrainerBase; Training, Kind = Info] Auto - tuning parameters: L1Threshold(L1 / L2) = 0."",\r\n""[Source = SdcaTrainerBase; Training, Kind = Info] Using best model from iteration 7.""};\r\n```\r\nBut to find these, you have to search a huge stream of information.'"
420237013,2933,b'Knowing what to cast the model to is hard',"b'I have been writing a few tests about saving the model and reloading the models, and casting the model members to the right types, so I can get to something nested. \r\n\r\nExample  \r\n\r\n    `(IEstimator<ITransformer> pipe, IDataView dataView) = GetBinaryClassificationPipeline();\r\n\r\n     pipe = pipe.Append(ML.BinaryClassification.Trainers.LogisticRegression(\r\n     new LogisticRegression.Options\r\n     {\r\n         ShowTrainingStatistics = true,\r\n         ComputeStandardDeviation = new ComputeLRTrainingStdThroughMkl(),\r\n     }));\r\n\r\n     // SEE THE CASTS\r\n      var transformer = pipe.Fit(dataView) as TransformerChain<BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>>;\r\n\r\n      var linearModel = transformer.LastTransformer.Model.SubModel as LinearBinaryModelParameters;\r\n      var stats = linearModel.Statistics;\r\n\r\n     var modelPath = GetOutputPath(""temp.zip"");\r\n     // Save model. \r\n     using (var file = File.Create(modelPath))\r\n     transformer.SaveTo(ML, file);\r\n\r\n     // Load model.\r\n     TransformerChain<ITransformer> transformerChain;\r\n     using (var file = File.OpenRead(modelPath))\r\n     transformerChain = TransformerChain.LoadFrom(ML, file);\r\n\r\n     // SEE THE CASTS\r\n     var lastTransformer = transformerChain.LastTransformer as BinaryPredictionTransformer<IPredictorProducing<float>>;\r\n      var model = lastTransformer.Model as ParameterMixingCalibratedModelParameters<IPredictorWithFeatureWeights<float>, ICalibrator>;\r\n      linearModel = model.SubModel as LinearBinaryModelParameters;\r\n      var stats = linearModel.Statistics;\r\n`\r\n\r\nNotice the casts \r\nThe only way to get to the Statistics (or weights, bias etc) is by casting to the right type. \r\nIt takes living in the Visual Studio debugger to figure out the right types.. \r\n'"
420201052,2932,b'Create functional tests for all Debugging scenarios',"b'As laid out in #2498 , we need scenarios to cover the Debugging functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can see how my data was read in to verify that I specified the schema correctly\r\n- I can see the output at the end of my pipeline to see which columns are available (score, probability, predicted label)\r\n- I can look at intermediate steps of the pipeline to debug my model. \xc2\xa0 Example: > I were to have the text\xc2\xa0""Help I\'m a bug!""\xc2\xa0I should be able to see the steps where it is normalized to\xc2\xa0""help i\'m a bug""\xc2\xa0then tokenized into\xc2\xa0[""help"", ""i\'m"", ""a"", ""bug""]\xc2\xa0then mapped into term numbers\xc2\xa0[203, 25, 3, 511]\xc2\xa0then projected into the sparse float vector\xc2\xa0{3:1, 25:1, 203:1, 511:1}, etc. etc.\r\n- (P1) I can access the information needed for understanding the progress of my training (e.g. number of trees trained so far out of how many)\r\n\r\n'"
420128782,2928,b'Scrubbing normalization transforms',b'Sub task of #2827 \r\n`LpNormalize`\r\n`GlobalContrastNormalize`\r\n(since `LpNormColumnOptions` and `GcnColumnOptions` are nested classes we can just call them `ColumnOptions`)\r\n`Normalize `\r\nstuff like: `public TData Stddev`\r\nor  `public readonly ImmutableArray<NormalizingTransformer.ColumnOptions> Columns;`\r\nor `public readonly int NumBins;`\r\n'
420126813,2927,"b""FieldAwareFactorizationMachines trainer can't have any empty arguments list""","b'The `FieldAwareFactorizationMachines` trainer cannot be given an empty arguments list.\r\n\r\n```cs\r\nvar ffmTrainer = mlContext.BinaryClassification.Trainers.FieldAwareFactorizationMachine(\r\n    new FieldAwareFactorizationMachineBinaryClassificationTrainer.Options { });\r\n```\r\nor\r\n```cs\r\nvar ffmTrainer = mlContext.BinaryClassification.Trainers.FieldAwareFactorizationMachine(\r\n    new string[] {""Features""});\r\n```\r\nI suggest allowing an empty arguments list by default. cc @sfilipi '"
420121979,2926,b'More hiding of unnecessary public classes',"b""https://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Commands/EvaluateCommand.cs#L30\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L28\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/DataLoadSave/TrivialLoaderEstimator.cs#L10\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.StandardTrainers/Standard/MultiClass/OneVersusAllTrainer.cs#L244 Would ask @sfilipi  since she is mentioned she works on OVA output columns, maybe this enum would proof useful.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Transforms/SlotsDroppingTransformer.cs#L38 Would double check with @TomFinley  right now, all we have is public class, and everything inside it is hidden, so it's useless for user. We don't have `IEstimator` for it, so I'm not sure how valuable it's to have it. \r\n\r\n"""
419792652,2922,b'Logistic Regression: NumberOfIterations should be MaximumNumberOfIterations',"b'Similar to `SDCA` and `K-Means`, `Logistic Regression` has a `NumberOfIterations` option that stands for the maximum number of iterations.\r\n\r\nI propose changing it to `MaximumNumberOfIterations`.\r\n\r\n** I searched through all the learners, and this is the last learner that needs this change.'"
419766088,2920,b'OVA Multiclass Classification can be instantiated for variety of sub-trainer training tasks',"b'In writing a test for #2859, I have found that it is possible to create an `OVA` (aka ""One-Versus-All"") multiclass classification trainer learners other than a binary classifier as an input.\r\n\r\nOne of our V1 Goals is:\r\n- Metacomponents smartly restrict their use to compatible components.   Example: ""When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.""\r\n\r\nFor all types\r\n- **Anomaly Detection** throws on `Fit()` due to data mismatch. Suggests that this could work under ideal conditions.\r\n- **Binary classification** works, as expected.\r\n- **Clustering** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Multiclass classification** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Ranking** pipeline can be instantiated, but `Fit()` fails on ""mismatch for label column"".\r\n- **Regression** pipeline can be instantiated, but `Fit()` fails on ""mismatch for label column"".\r\n\r\n(Note that I didn\'t run a recommender check because this needs to be coded x64-only at this point.)\r\n\r\n**Updated**: With the recent change to one-label-type-per task, Ranking and Regression now fail on the `Fit()`. I\'ve updated the title to reflect that we can no longer train working models, but we can instantiate the pipeline.'"
419738674,2917,b'Unify way of setting random seed',"b""I can understand why we use nullable seed in one place and defaults in another, but why it's uint in one places and int in others is beyond my understanding.\r\n\r\n**UInt:**\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/Transforms/Hashing.cs#L1164\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L892\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L377\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/WrappedTextTransformers.cs#L184\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/OneHotHashEncoding.cs#L241\r\n\r\n**Int:**\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L135\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L293\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/RandomFourierFeaturizing.cs#L659\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.PCA/PCACatalog.cs#L31\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/MLContext.cs#L79\r\n"""
419668176,2912,b'Consider making DataView and IEstimator Preview methods return DataTable',"b'Visual Studio has the ability to visualize a data set if the object is a `System.Data.DataTable`.\r\n\r\nWe currently have some debugger extension methods:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/DebuggerExtensions.cs#L15-L62\r\n\r\nWe should consider making these return `DataTable`, so VS can visualize them. Or potentially we could add ancillary methods that return `DataTable`, and keep the current methods returning `DataDebuggerPreview`, if we think the current experience has value over the visualization in VS.'"
419655669,2910,b'Support encrypted models',"b'We want the ability to publish trained models that people can use to predict on their own devices, but not to reverse engineer the algorithms used to train them. That, in order to protect IP while allowing sensitive data to be predicted on customer machines.\r\nCan you support that?'"
419602870,2906,b'Create functional tests for all Training scenarios',"b'As laid out in #2498 , we need scenarios to cover the Training functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can provide multiple learners and easily compare evaluation metrics between them. \r\n- I can use an initial predictor to update/train the model for some trainers (e.g. linear learners like averaged perceptron). Specifically, start the weights for the model from the existing weights. \xc2\xa0\r\n- Metacomponents smartly restrict their use to compatible components. \xc2\xa0 Example: ""When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.""\r\n- I can use OVA and easily add any binary classifier to it\r\n\r\n'"
419009750,2897,b'Two Ways to Save a Model',"b'The current API has two ways to save a model:\r\n\r\n```cs\r\nmodel.SaveTo(MlContext, stream);\r\nmlContext.Model.Save(ITransformer, stream);\r\n```\r\n\r\nDo we just want one of these?\r\n\r\nMaybe related to #2735 '"
419007474,2896,b'Create functional tests for all Model Files scenarios',"b'As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nDefinitely need for V1\r\n- I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n- I can use a model file in a completely different process to make predictions \r\n- I can easily figure out which NuGets (and versions) I need to score an ML.NET model \r\n- I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nMay not need for now:\r\n- I can save a model to text \r\n- I can use newer versions of ML.NET with ML.NET model files of previous versions (for v1.x)\r\n- I can use model files interchangeably between compatible versions of ML.NET and NimbusML\r\n- I can move data between NimbusML and ML.NET (using IDV). Prepare with NimbusML and load with ML.NET'"
419005311,2895,"b'Discrepancy in NgramExtractorTrasform, NgramExtractingTransformer and NgramExtractingEstimator.'","b'If you search for `NgramExtract` in the solution, the following three main classes pop up.\r\n\r\n1. NgramExtractorTransform (in WordBagTransform.cs)\r\n2. NgramExtractingTransformer (in NgramTransform.cs)\r\n3. NgramExtractingEstimator (in NgramTrasnform.cs)\r\n\r\n`2` and `3` seem to be the actual classes where ngram extraction logic is written. However, `1` uses `2` and `3` with a pre-processing step where if input is text it is first converted to terms using ValueToKeyMappingTransformer.\r\n\r\nFirst, `NgramExtractorTransform` does not seem to be in correct file i.e filename and class name do not match.\r\nSecond, the `NgramExtractorTransform` is not doing ngram extraction instead composing two different estimators (NgramExtractingEstimator and ValueToKeyMappingEstimator).\r\n\r\nI think `NgramExtractorTransform` be renamed to `WordBagTransform` or something appropirate.\r\n\r\nCC: @Ivanidzo4ka, @TomFinley, @sfilipi, @rogancarr.'"
418522569,2884,b'Discussion: ColumnOptions actually a good name?',"b'In #2878, @eerhardt had a comment that we should consider, the gist of which was, since all of our `Options` classes have mutable properties, is it appropriate for `ColumnOptions` to be called this, since they are not and often cannot be mutable? We also have issue #2854 where @rogancarr thought he couldn\'t get normalization information out of the structure since it was named options, so this is not actually as academic an issue than I might have thought, say, a few days ago.\r\n\r\nThe approach taken in #2709 was that these structures created for configuration of the per-column options should be called options, and that it was (apparently) assumed to be irrelevant whether those items were mutable or not. Now, I\'m not saying we should revert that PR necessarily, but it is something to consider, since it seems to be confusing people.\r\n\r\nNow then, the structures themselves obviously must not be mutable, since they are often the same structures used in the associated estimators and transformers to project schema, e.g., here it is for the n-gram hashing estimator:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nHere it is in the transformer:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nSo, just something to think about, whether it was in fact a good idea for this thing to be called ""options"" really, in all the cases we named it options. Maybe we could have a refinement on the policy of naming this thing? Or maybe we decide to just live with it, because the confusion of calling all these things ""options"" vs. ""info"" vs. ""whatever"" is greater than this inconsistency in roles?\r\n\r\nI\'m fine with leaving it as is, but I do see some confusion so I think we should think about it, and at least formulate a psoition.\r\n\r\n/cc @eerhardt and @rogancarr and @sfilipi and @artidoro ...'"
418499835,2882,"b'Non-standard naming in L-BFGS Learners (LogisticRegression, PoissonRegression)'","b'In `LogisticRegression` and `PoissonRegression` (which use the same L-BFGS base), we have a parameter `IterationsToRemember` that refers to the number of gradients to accumulate in the history. While this terminology makes sense, it\'s not what we usually encounter in the field.\r\n\r\nIn the literature, we see this referred to as the ""history size"" (see e.g. [wikipedia](https://en.wikipedia.org/wiki/Limited-memory_BFGS)).\r\n\r\nIn the various toolkits that expose an L-BFGS solver, they use:\r\nScikit Learn: Doesn\'t expose it.\r\nSpark: [NumberOfCorrections](https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/mllib/optimization/LBFGS.html)\r\nTensorFlow: [num_correction_pairs](https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize)\r\nPyTorch: [history_size](https://pytorch.org/docs/stable/_modules/torch/optim/lbfgs.html)\r\n\r\nI would vote for `HistorySize`, with the docs explaining what it is.\r\n\r\nWhat do you all think? Any big feelings around this?'"
418487450,2881,b'Value-tuple stragglers in the public API',"b'There was a prior PR #2581 and issue #2501 related to value-tuples and why they should not be part of our public surface. I have noticed that there are some ""stragglers"" still remaining in the public API. So, the work is perhaps not yet complete.\r\n\r\nThe following list is I *believe* complete for `Core`/`Data`/`Transforms`/`FastTree`/`ImageAnalytics`/`KMeansClustering`/`LightGBM`/`PCA`/`Tensorflow`/`StandardLearners`/`Data.DataView` assemblies.\r\n\r\nThere are three distinct categories where this flaw has remained. (Though the last ""category"" other has only one item.)\r\n\r\n# Properties on transformers\r\n\r\nSome transformers are exposing information about themselves via this mechanism.\r\n\r\n* KeyToBinaryVectorMappingTransformer.Columns\r\n* MissingValueDroppingTransformer.Columns\r\n* MissingValueIndicatorTransformer.Columns\r\n* CustomStopWordsRemovingTransformer.Columns\r\n* TextNormalizingTransformer.Columns\r\n* TokenizingByCharactersTransformer.Columns\r\n* WordEmbeddingsExtractingTransformer.Columns\r\n* ImageGrayscalingTransformer.Columns\r\n* ImageLoadingTransformer.Columns\r\n* LatentDirichletAllocationTransformer.ItemScoresPerTopic and WordScoresPerTopic\r\n\r\n# MLContext estimator creation extension methods\r\n\r\nThere are some overloads of MLContext extension methods on various catalogs that are stil using it. I view this as a *lesser* sin since this is at least something that could conceivably be fixed using an overload if we decide it is necessary, but I\'d still prefer to be consistent.\r\n\r\n* ProduceHashedNgrams extension method\r\n* ProduceHashedWordBags extension method\r\n* ProduceNgrams extension method\r\n* ProduceWordBags extension method\r\n* RemoveDefaultStopWords extension method\r\n* TokenizeWords extension method\r\n\r\n# Others\r\n\r\nLastly, I see a Microsoft.ML.ColumnOptions global class with an implicit operator from value-tuples. This one is *probably* harmless, since that specific class is for representing a simple case.\r\n\r\n/cc @yaeldekel @Ivanidzo4ka '"
418432912,2879,b'Suggestion: Model Explainability Interpretability Visualization using Decision Tree Diagrams',"b'I previously logged an enhancement for #511 - ""Suggestion - Make Machine Learning Models explainable by design with ML.NET"". @rogancarr kindly broke down that request into separate new enhancements. \r\nhttps://github.com/dotnet/machinelearning/issues/511#issuecomment-448329385\r\n\r\nIn this enhancement, I am suggesting we add visualization of Machine Learning decisions using a Decision Tree within Visual Studio. Now that ML.NET supports Feature Importance (#599) this should be possible.\r\n\r\n**How it could be done.**\r\nI propose in the Visual Studio IDE Editor a new Model Visualization tab is added \r\n(Similar to the CPU Performance usage or a UML Class Diagram that shows how objects relate to each other)\r\n- The tab could show a graphical decision tree showing a path the algorithm took and why it did it\r\n- The decision tree could be derived from the feature importance metrics that are available within ML.NET\r\n- At each level of a tree, you could inspect the Data that contributed to it (an extension of IDataView?)\r\n\r\n **There have been similar issues logged, but my request is different from the following...**\r\n- Feature request: get reasons behind predictions made by Decision Trees #913\r\n- Is it possible to visualize a generated decision tree? #326\r\n- Pipeline visualization please #2478\r\n- Proof of concept for debugger visualization #847\r\n\r\n**Advanced Deep Learning Debugging / Explainability** \r\nAlso from the perspective of a Deep Learning model e.g. a TensorFlow or ONNX model, would it be possible to peek into the neural network nodes? (not only a high-level feature importance score but peek into what each node is doing e.g. you can view feature importance at each node level)\r\n\r\nIn the Visual Studio IDE we could have a Model with a tree of neurons (maybe thousands)... each neuron can be expanded and the evaluation of what each node is doing can be inspected.\r\n\r\nThis can open up the opportunity to allow developers to create custom graphing for visual feedback and monitor the progression of a decision in real-time.\r\n\r\nIt allows you to trace which neurons are fired in any given execution of the model and how a given set of data impacted the score and at what stage it changed.\r\n\r\nAn example problem scenario is AI Healthcare diagnosis... Why a prediction or diagnosis was made? to avoid over-diagnosis and unnecessary costs'"
418429070,2877,"b""FastForest catalog arguments haven't been scrubbed""","b'The FastForest `options` has been scrubbed, but the catalog arguments still have the old names. This is a reminder issue to go back and fix that at some point.'"
418035994,2873,b'exampleWeightColumnName v.s. weightColumnName',"b'In trainers like\r\n```csharp\r\n        internal RandomizedPcaTrainer(IHostEnvironment env,\r\n            string features,\r\n            string weights = null,\r\n            string featureColumnName,\r\n            string exampleWeightColumnName = null,\r\n            int rank = Options.Defaults.NumComponents,\r\n            int oversampling = Options.Defaults.OversamplingParameters,\r\n            bool center = Options.Defaults.IsCenteredZeroMean,\r\n            bool ensureZeroMean = Options.Defaults.EnsureZeroMean,\r\n            int? seed = null)\r\n```\r\nwe have `exampleWeightColumnName` but it seems `weightColumnName` is clear enough under this context. Can we switch to `weightColumnName`?'"
417998372,2871,b'NumberOfIterations vs. MaxIterations',"b'The recent naming changes to K-Means and SDCA (and perhaps others?) resulted in `MaxIterations` being renamed to `NumberOfIterations`. Since this parameter specifies the worst-case bound and not the actual number of iterations taken in most cases, I think we should keep it named `MaxIterations`. \r\n\r\nWhatever we call it, `NumberOfIterations` is not what this parameter specifies &mdash; this is a stopping criterion, not a guaranteed execution parameter.'"
417980422,2870,b'Update default n-gram length for Text Transform to match default text recipe',"b'@justinormont\xc2\xa0and the text team\xc2\xa0tuned default n-gram lengths for the default text recipe in the internal repo\r\n\r\nThese defaults are:\r\nWord -- bigrams (w/ unigrams)\r\nCharacter -- trigrams (w/o unigrams and bigrams)\r\n\r\nOne chart from his findings:\r\n![image](https://user-images.githubusercontent.com/4080826/51941076-8c8d1b80-23c8-11e9-89d5-e30b42db39d0.png)\r\n\r\nThe line w/ the light blue call-out represents current ML.NET defaults (Unigram + Trichar)\r\nThe line w/ the light green call-out is the requested change (Bigram + Trichar)\r\nThe line w/ the pink call-out shows the Trigram+Trichar is better in terms of accuracy, but with a time hit, and accuracy has a cross over at NumIterations > 8 for Averaged Perceptron learner.'"
417946257,2868,b'Further polishing of PFI statistics structures',"b'There are a couple problems with PFI public surface that should be resolved.\r\n\r\nThe statistics classes did not have their property names updated when the underlying metrics were themselves updated, for example, as seen here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/adb53c41fd8c612df30f8d0213b7f459ef113724/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs#L459-L463\r\n\r\nAlso, these statistics objects themselves exposed more of their infrastructure and workings than is necessary or helpful at this moment, for the purpose for which they are intended. (That is, exposing an abstract base class that is only necessary for internal usage, some protected members visible, being publicly instantiable, and all the usual problems.)'"
417582208,2866,b'Different behavior when calling Fit() on a transformer chain and on an IDataLoaderEstimator',"b'The following code runs without errors:\r\n\r\n```\r\n            var loader = ml.Data.CreateTextLoader<InputData>(hasHeader: true, dataSample: file);\r\n            var data = loader.Load(file);\r\n\r\n            // Pipeline.\r\n            var pipeline = ml.BinaryClassification.Trainers.GeneralizedAdditiveModels();\r\n\r\n            // Train.\r\n            var model = pipeline.Fit(data);\r\n```\r\nHowever, the following code fails with schema mismatch exception:\r\n```\r\n            var loader = ml.Data.CreateTextLoader<InputData>(hasHeader: true, dataSample: file);\r\n\r\n            // Define the same pipeline starting with the loader.\r\n            var pipeline = loader.Append(ml.BinaryClassification.Trainers.GeneralizedAdditiveModels());\r\n\r\n           // Train\r\n            var model = pipeline.Fit(file);\r\n```\r\n\r\nThis may also be related to issue #1969 .'"
417553476,2864,b'Different behavior for TokenizeChar and TokenizeWords',b'TokenizeChar produce vector of keys.\r\nTokenizeWords produce vector of strings.\r\nI have to add MapValueToKey to TokenizeWords in order to apply ProduceNgrams to it.\r\n'
417486587,2857,b'GAM parameter names are non-standard',"b'The trained `Generalized Additive Models` (aka `GAMs`) methods for obtaining trained model parameters have non-standard names and various inconsistencies.\r\n\r\nThese are the properties:\r\n```cs\r\nvar shapeFunctionsBins = gamModel.GetBinUpperBounds();\r\nvar shapeFunctionsValues = gamModel.GetBinEffects();\r\nvar numShapeFunctions = gamModel.NumShapeFunctions;\r\nvar intercept = gamModel.Intercept;\r\n```\r\n\r\nThere are a few issues here:\r\n1. Nonstandard names\r\nI propose `BinUpperBounds` and `BinEffects` be renamed `ShapeFunctionsBins` and `ShapeFunctionsBinValues`.\r\n2. Inconsistent names\r\nSometimes we say `ShapeFunctions`, sometimes we done. Same solution proposed as No. 1.\r\n3. Inconsistency in `Get` methods vs. properties\r\ne.g. `Intercept` vs. `GetBinUpperBounds`.\r\nI propose we move all the methods to be properties.\r\ne.g. `model.ShapeFunctionsBins`.\r\n4. Names leak implementation\r\n`BinUpperBounds` vs. `Bins`.\r\nQuestion: should we just say `Bins` rather than `BinUpperBounds` and say that they are the upper bounds for the bin in the documentation? `BinUpperBounds` is very verbose, and speaks to how we bin.'"
417475922,2854,b'Normalizer parameters require a manual cast',"b""A trained normalizer does not have public methods or properties that allows access to the normalization parameters. For example, a minmax normalizer doesn't have the min, max, or zero-level available.\r\n\r\nI would expect that the trained transformer would have a `.Model` property, similar to a trained learner.\r\n\r\nThis is required V1 Scenario (#2498):\r\n- I can inspect the normalization coefficients of a normalizer in my pipeline without much work. Easy to find via auto-complete.\r\n\r\n@shauheen @eerhardt @TomFinley I marked this as P13, but it could be a V1.1 as it does not change APIs, but needs new APIs. This is similar to LDA (#2197), and I think we have a more global problem where trained transforms don't expose a `.Model` property similar to our learners."""
417463711,2853,b'Estimators and their catalog extensions should have matching names',"b'In #2827, one of the items is to make sure the estimators and their catalog extensions have matching names. Like in trainers, we should keep the suffix estimator only in the estimator name, and remove it from the catalog extension, something like the following:\r\n\r\n`NameEstimator Name(...)`\r\n\r\n***The question now is: How do we reconcile the names and which convention should we follow?***\r\n\r\nMost estimator names follow the convention: `ActionPerformingEstimator`, while in the catalog usually we use the convetion: `PerformAction`.\r\n\r\nSome examples are:\r\n\r\nEstimator Name | Catalog Name\r\n------------ | -------------\r\n`KeyToBinaryVectorMappingEstimator` | `MapKeyToBinaryVector`\r\n`MutualInformationFeatureSelectingEstimator` | `SelectFeaturesBasedOnMutualInformation`\r\n`CountFeatureSelectingEstimator` | `SelectFeaturesBasedOnCount`\r\n... | ...\r\n\r\ncc/ @sfilipi @TomFinley @glebuk @eerhardt @rogancarr @ivanbasov'"
417413540,2848,b'Internalize random model parameters and trainer',"b""In #2846 it came out that we still somehow had the random predictor lying around -- I was unaware of this. This structure, being inherently stateful, will introduce subtle bugs and problems when used as part of a transformer. (E.g., what happens when you construct multiple prediction engines over the resulting transform.) These bugs are subtle, but still there and points to a deep problem with this structure. It claims to be a value mapper, so it is even claiming to be a function, which it definitely is not. Perhaps its presence was viewed as merely harmless which is why we did not remove it in prior years, but now that we're trying to finalize the API we must make a stronger case here.\r\n\r\nWe have in other places introduced other mechanisms to deal with inherently stateful predictors (e.g., what we had to do with time series). So, I think that in time we can address the need for this thing, *if there is a need*. (I have been unaware of any scenario where this thing is useful beyond a mere comparison point for evaluation, which can be done far better in a variety of ways.)\r\n\r\nThe work is fairly simple: internalize this architecturally troublesome trainer and model. (This is similar to how we are still keeping the generate number transform internal, though, that one has actual real application.) We can decide what to do with it later."""
417044942,2841,b'The curious case of TrainedWrapperEstimatorBase and friends',"b""So, while I was doing another round of internalization, one thing that I internalized was this. (Basically, something to handle the shimming from the now internal `IDataTransform` interface to the new `ITransformer` interface, during the regrettable situations -- thankfully few -- where such a thing is still necessary. So this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/63a7654edaddaf0eea6af98ea762b01594d083ee/src/Microsoft.ML.Data/DataLoadSave/TransformWrapper.cs#L20\r\n\r\nand this\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/63a7654edaddaf0eea6af98ea762b01594d083ee/src/Microsoft.ML.Data/DataLoadSave/TransformWrapper.cs#L151\r\n\r\nNow, that's all fine, but after doing the necessary work it seemed that I could delete the estimator wrapper entirely, but then I see this very intriguing note.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/63a7654edaddaf0eea6af98ea762b01594d083ee/src/Microsoft.ML.Data/DataView/RowToRowMapperTransform.cs#L50-L56\r\n\r\nI do not understand what is going on here. This is not essential -- everything here is internal -- but it seems at least odd. This seems to indicate that this method and the class I wanted to delete have something to do with each other, but as far as I can tell they have nothing to do with each other whatsoever. But then why the comment?\r\n\r\nAnyway, there's clearly something odd going on. This is absolutely not critical, but I wanted to register an issue about the oddness, since the code underlying it passes my understanding."""
417007709,2838,b'`UseStopRemover` parameter in TextFeaturizer does not make sense.',b'https://github.com/dotnet/machinelearning/blob/5746ec9eeb5aac9dcd3c4355ccce46d17ee46cdf/src/Microsoft.ML.Transforms/Text/TextFeaturizingEstimator.cs#L157\r\n\r\nI think it should be renamed to `UseStopWordRemover`? Xml comments need to be updated to too.'
416996331,2837,b'Remove public TrainformerChain SaveTo/LoadFrom APIs',"b'We currently have APIs on `MLContext.Model` to save and load model files.\r\n\r\nHowever, we have some hang-over APIs that were made before we had the `MLContext.Model` APIs:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b1801a8a6b6463ec5f6fb576ca279343e7cfaebb/src/Microsoft.ML.Data/DataLoadSave/TransformerChain.cs#L236-L300\r\n\r\nWe should remove these APIs from the public surface area. The only way to save/load models should be through `MLContext.Model`.\r\n\r\ncc @TomFinley '"
416987773,2836,b'Question : When 0.11 expected to be released',b'Question : When 0.11 expected to be released\r\n\r\nbest regards'
416980057,2835,b'Scrubbing rest of transformers',b'Sub task of #2827\r\n\r\nReplaceMissingValues\r\nIndicateMissingValues\r\nCustomMapping\r\n'
416979310,2834,b'Scrubbing time series related transformers',b'Sub task of #2827\r\nIidChangePointEstimator\r\nIidSpikeEstimator\r\nSsaChangePointEstimator\r\nSsaSpikeEstimator\r\n\r\n'
416979065,2833,b'Scrubbing Image related transformers',b'Sub task of #2827\r\nConvertToGrayScale\r\nResizeImage\r\nExtractPixel\r\nConvertImage\r\nLoadImage\r\n\r\n'
416960954,2832,b'Scrubbing Text related transformers',b'Sub task of #2827\r\n\r\n- [x] WordEmbedding #2891 \r\n- [x] FeaturizeText #2944 \r\n- [x] LDA #2890\r\n- [x] NormalizeText #2918\r\n- [x] ProduceHashedNGrams #2898\r\n- [x] ProduceHashedWordBag #2898\r\n- [x] ProduceNgrams #2898\r\n- [x] ProduceWordBag #2898\r\n- [x] RemoveStopWords #2916\r\n- [x] RemoveCustomStopWords #2916\r\n- [x] TokenizeChar #2916\r\n- [x] TokenizeWords #2916\r\n\r\n'
416960484,2831,b'Scrubbing `Projection` transformers',"b'Sub task of #2827\r\nRFF, LpNorm, GcNorm, PCA, Whiten, Normalize.\r\nProjection catalog is bad name, and we probably should toss around this transforms across other catalogs.'"
416959602,2830,b'Scrubbing feature selection transformers',b'Sub task of #2827 \r\n\r\nSelectFeaturesBasedOnCount\r\nSelectFeaturesBasedOnMutualInformation\r\n\r\n'
416959113,2829,b'Scrubbing key related transforms',b'Sub task of #2827\r\n\r\nMapKeyToBinaryVector\r\nMapKeyToBinaryVector\r\nMapKeyToVector\r\nMapKeyToValue\r\nMapValueToKey\r\nValueMap\r\nOneHotEncoding\r\nHash\r\nOneHotHash\r\n\r\n\r\n\r\n\r\n'
416958472,2828,b'Scrubbing schema related transformers',"b'Sub task of #2827\r\nCopy, SelectColumns, DropColumns, Concat\r\n\r\n\r\n'"
416955326,2827,b'Scrubbing transformers (Meta issue)',"b""We need to make sure our transforms are in good shape.\r\n\r\n1. No protected fields/members/method in public classes. Only private protected.\r\n\r\n2. Transformer class is sealed.\r\n\r\n3. Transformer/Estimator should and catalog method names should be sensible (#2853 fine if slightly different).\r\n\r\n4. Column options cleaning:\r\n- Option should have meaning and proper way it initialize it self. \r\n- No short names.\r\n5. `public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly(); ` \r\nI don't think that public thing make sense to me, I would prefer to get rid of it.\r\n\r\n6. No public value tuples (especially in catalog methods) (#2881)\r\n\r\nList still in progress."""
416585909,2826,b'Train binary classification with text label',"b'@justinormont points out (https://github.com/dotnet/machinelearning-automl/issues/255) :\r\n> `Key` type is needed for binary classification learners:\r\n> \r\n> * Dataset w/ text labels (as seen here)\r\n> * Datasets w/ missing labels -- `BL` no longer supports NA (changed in [dotnet/machinelearning#673](https://github.com/dotnet/machinelearning/issues/673))\r\n\r\nWhen the ""Label"" column is text, calling\r\n\r\n```C#\r\n\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"", ""Label"");\r\nvar trainer = mlContext.BinaryClassification.Trainers.LightGbm(labelColumnName: ""Label"", featureColumnName: ""Features"");\r\nvar trainingPipeline = pipeline.Append(trainer);\r\nvar crossValidationResults = mlContext.BinaryClassification.CrossValidateNonCalibrated(trainingDataView, trainingPipeline, numFolds: 5, labelColumn: ""Label"");\r\n```\r\nresults in the exception \r\n\r\n```\r\nSystem.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  Message=Schema mismatch for label column \'\': expected Bool, got Key<U4>\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckLabelCompatible(Column labelCol)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.TrainCatalogBase.<>c__DisplayClass7_0.<CrossValidateTrain>b__0(Int32 fold)\r\n   at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n   at Microsoft.ML.BinaryClassificationCatalog.CrossValidateNonCalibrated(IDataView data, IEstimator`1 estimator, Int32 numFolds, String labelColumn, String samplingKeyColumn, Nullable`1 seed)\r\n   at DogFruitNLP_14KB_735_rows_BinaryClassification.Program.BuildTrainEvaluateAndSaveModel(MLContext mlContext) in C:\\AutoMLDotNet\\bin\\AnyCPU.Debug\\mlnet\\netcoreapp2.1\\DogFruitNLP_14KB_735_rows_BinaryClassification\\Program.cs:line 74\r\n```\r\n\r\nWould you have any recommendation for handling these kinds of scenarios?'"
416548582,2824,"b'In v0.11 Transforms.Conversion.ConvertType() does not properly convert numeric values if they are ""in quotes"" '","b'Since v0.11, when a dataset file column\'s numeric value has quotes, ML.NET `mlContext.Transforms.Conversion.ConvertType()` cannot handle it properly. For instance, a column with the following values:\r\n\r\n- `""1""`\r\n- `""0""`\r\n\r\nML.NET `ConvertType()` in a pipeline was not able to convert those values to **Boolean** (it was transforming all values, either `""0""` and `""1""` to `0`) neither to **Float** (all values transformed to `NaN`)\xe2\x80\xa6\r\n\r\nThe following transformer puts a `0` to all values when converted to Boolean:\r\n`mlContext.Transforms.Conversion.ConvertType(outputColumnName: ""LabelBool"", inputColumnName: ""Label"", outputKind: DataKind.Boolean`\r\n\r\nThe following transformer puts a `NaN` to all values when converted to Float:\r\n`mlContext.Transforms.Conversion.ConvertType(outputColumnName: ""LabelFloat"", inputColumnName: ""Label"", outputKind: DataKind.Single`\r\n\r\nInterestingly, until ML.NET v0.10, ML.NET was able to directly load that properly into a Boolean type, properly.\r\n'"
416419753,2823,b'can not register',"b'@Emmagrabergs commented on [Sat Mar 02 2019](https://github.com/dotnet/core/issues/2361)\n\nProblem encountered on https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial/install\r\nOperating System: windows\r\n\r\nProvide details about the problem you are experiencing. Include your operating system version, exact error message, code sample, and anything else that is relevant..\n\n---\n\n@leecow commented on [Sat Mar 02 2019](https://github.com/dotnet/core/issues/2361#issuecomment-468941055)\n\nMoving to the ML repo. @Emmagrabergs - chances are they will need additional details on what you were doing and the errors you see. \n\n'"
416338475,2821,b'Exception in CreditCard Fraud Detection sample while migrating to v0.11',"b'### Issue\r\n\r\n- While migrating CreditCard Fraud Detection sample I am getting the below exception while trying to save train/test data\r\n\r\n\r\n\r\n```\r\n                //(trainData, testData) = classification.TrainTestSplit(data, testFraction: 0.2, stratificationColumn: ""Label"");\r\n                TrainTestData trainTestData = classification.TrainTestSplit(data, testFraction: 0.2);\r\n                trainData = trainTestData.TrainSet;\r\n                testData = trainTestData.TestSet;\r\n\r\n                // save test split\r\n                using (var fileStream = File.Create(Path.Combine(_outputPath, ""testData.csv"")))\r\n                {\r\n                    mlContext.Data.SaveAsText(testData, fileStream, separatorChar:\',\', headerRow:true, schema: true);\r\n                }\r\n```\r\n\r\n\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/53674701-96fb3900-3c44-11e9-9509-399e4ec226c9.png)\r\n\r\n\r\n\r\n\r\n'"
416311750,2820,b'Chains of Chains',"b'It is possible to nest `EstimatorChain`s inside one another, fit them, and use them to transform data. The result is an object that is a nested `TransformerChain`.\r\n\r\nQuestion: Is this intended behavior? Do we want to allow this sort of nesting in the V1 API?\r\n\r\nI think that the proper way to handle nesting is to **first flatten the structure before the fit and return a single `EstimatorChain`**. I believe that since there is no forking and joining, that nested and non-nested pipelines are identical, except for the returned object. Data transformed by these objects should be the same whether the pipeline is nested or not (and is in my limited testing).\r\n\r\nTake a look at the following example where we featurize the UCI Adult dataset.\r\n\r\n```cs\r\nvar mlContext = new MLContext(seed: 1, conc: 1);\r\n\r\n// Load the Adult (tiny) dataset\r\nvar data = mlContext.Data.LoadFromTextFile<Adult>(GetDataPath(TestDatasets.adult.trainFilename),\r\n    hasHeader: TestDatasets.adult.fileHasHeader,\r\n    separatorChar: TestDatasets.adult.fileSeparator);\r\n\r\n// Create the learning pipeline\r\nvar pipeline = mlContext.Transforms.Concatenate(""NumericalFeatures"", Adult.NumericalFeatures)\r\n    .Append(mlContext.Transforms.Concatenate(""CategoricalFeatures"", Adult.CategoricalFeatures))\r\n    .Append(mlContext.Transforms.Categorical.OneHotHashEncoding(""CategoricalFeatures"",\r\n        invertHash: 2, outputKind: OneHotEncodingTransformer.OutputKind.Bag))\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", ""NumericalFeatures"", ""CategoricalFeatures""))\r\n    .Append(mlContext.BinaryClassification.Trainers.LogisticRegression());\r\n\r\n// Train the model.\r\nvar model = pipeline.Fit(data);\r\n```\r\n\r\nHere, `pipeline` is an `EstimatorChain<BinaryPredictionTransformer<...>>` and `model` is a `TransformerChain<BinaryPredictionTransformer<...>>`.\r\n\r\nIt\'s also possible to nest the pipeline. Perhaps you accidentally put an errant `)` here and there, and then you have this:\r\n```cs\r\n// Create the learning pipeline\r\nvar pipeline = mlContext.Transforms.Concatenate(""NumericalFeatures"", Adult.NumericalFeatures)\r\n    .Append(mlContext.Transforms.Concatenate(""CategoricalFeatures"", Adult.CategoricalFeatures))\r\n    .Append(mlContext.Transforms.Categorical.OneHotHashEncoding(""CategoricalFeatures"",\r\n        invertHash: 2, outputKind: OneHotEncodingTransformer.OutputKind.Bag) // <-- missing a )\r\n    .Append(mlContext.Transforms.Concatenate(""Features"", ""NumericalFeatures"", ""CategoricalFeatures""))\r\n    .Append(mlContext.BinaryClassification.Trainers.LogisticRegression())); // <-- extra )\r\n```\r\n\r\nNow, `pipeline` is an `EstimatorChain<EstimatorChain<BinaryPredictionTransformer<...>>>` and `model` is a `TransformerChain<TransformerChain<BinaryPredictionTransformer<...>>>`.\r\n\r\nNow, if I compare the two (where `var predictor = model.LastTransformer` and `var nestedPredictor = nestedModel.LastTransformer.LastTransformer`), it\'s clear that the models and the transformed data are identical:\r\n```cs\r\n//True!\r\nAssert.Equal(predictor.Model.SubModel.Bias, nestedPredictor.Model.SubModel.Bias);\r\nint nFeatures = predictor.Model.SubModel.Weights.Count;\r\nfor (int i = 0; i < nFeatures; i++ )\r\n    //True!\r\n    Assert.Equal(predictor.Model.SubModel.Weights[i], nestedPredictor.Model.SubModel.Weights[i]); \r\n\r\nvar transformedRows = mlContext.Data.CreateEnumerable<BinaryPrediction>(transformedData, false).ToArray();\r\nvar nestedTransformedRows = mlContext.Data.CreateEnumerable<BinaryPrediction>(nestedTransformedData, false).ToArray();\r\nfor (int i = 0; i < transformedRows.Length; i++)\r\n    //True!\r\n    Assert.Equal(transformedRows[i].Score, nestedTransformedRows[i].Score); \r\n```'"
416308990,2818,b'Create samples for NaiveBayes trainer.',b'The samples are missing for NaiveBayes trainer.'
416247510,2817,b'Create functional tests for all V1 Introspective Training scenarios',"b'As laid out in #2498 , we need scenarios to cover the Introspective Training functionality we want fully supported in V1.\r\n\r\n* I can take an existing model file and inspect what transformers were included in the pipeline\t\xc2\xa0\t\xc2\xa0\t\r\n* I can inspect the coefficients (weights and bias) of a linear model without much work. Easy to find via auto-complete.\t\xc2\xa0\t\t\xc2\xa0\r\n* I can inspect the normalization coefficients of a normalizer in my pipeline without much work. Easy to find via auto-complete.\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0\r\n* I can inspect the trees of a boosted decision tree model without much work. Easy to find via auto-complete.\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0\r\n* I can inspect the topics after training an LDA transform. Easy to find via auto-complete.\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0\r\n* I can inspect a categorical transform and see which feature values map to which key values. Easy to find via auto-complete.\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0\r\n* P1: I can access the GAM feature histograms through APIs'"
416241807,2816,b'Follow up on removing the predicates from the IDataView methods signatures',"b'Following on [@Ivanidzo4ka comment](https://github.com/dotnet/machinelearning/pull/2796#discussion_r261487085) on PR #2796 we should not track column indices anymore through the codebase of the transforms, but the entire column for things like new columns, and active columns. \r\n\r\nTracking just indices is error prone. '"
416036873,2813,b'StochasticDualCoordinateAscent not work For Multi-class after migrate to 0.10.0 Gives different Evaluation result Compare to 0.6.0',"b'**### System information**\r\n* **OS version/distro**: W7\r\n* **.NET Version (eg., dotnet --info)**:  4.7.2\r\n\r\n### Issue\r\n* **What did you do?** Migrated my code from 0.6.0 to 0.10.0\r\n* **What happened?** StochasticDualCoordinateAscentClassifire Algorithm is giving different Evaluation result with same train and test data.\r\n\r\n* **What did you expect?**\r\n  it should work fine\r\n\r\n### Source code / logs\r\n**version 0.6.0 Code**\r\n            string trainingDataLocation = ""Data/VendortrainData.csv"";\r\n            string testDataLocation = ""Data/VendortestData.csv"";\r\n\r\nvar pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader(_trainingDataLocation).CreateFrom<VendorData>(useHeader: true, separator: \',\'));\r\n            pipeline.Add(new ColumnConcatenator(\r\n                            ""Features"",\r\n                            ""VendorID"",\r\n                            ""Item"",\r\n                            ""TooEarly"",\r\n                            ""OnTime"",\r\n                            ""TooLate"",\r\n                            ""TooLittle"",\r\n                            ""Right"",\r\n                            ""TooMuch""\r\n                          ));\r\n            pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n            var model= pipeline.Train<VendorData, VendorPrediction>();\r\n            var SDCAMetrics = modelEvaluator.EvaluateClass(perceptronSDCA, testDataLocation);\r\n           **RESULT**\r\n           **AccuracyMacro** : 1\r\n           **AccuracyMacro** : 1\r\n\r\n\r\n**version 0.10.0 Code**\r\n      var dataProcessPipeline = mlContext.Transforms.Concatenate(outputColumnName: DefaultColumnNames.Features, ""VendorID"",\r\n                            ""Item"",\r\n                            ""TooEarly"",\r\n                            ""OnTime"",\r\n                            ""TooLate"",\r\n                            ""TooLittle"",\r\n                            ""Right"",\r\n                            ""TooMuch"")\r\n                .Append(mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(DefaultColumnNames.Label, DefaultColumnNames.Features));\r\n\r\nITransformer trainedModel = dataProcessPipeline.Fit(trainingDataView);\r\n\r\n var predictions = trainedModel.Transform(testDataView);\r\n var metrics = mlContext.MulticlassClassification.Evaluate(data: predictions, label: DefaultColumnNames.Label, score: DefaultColumnNames.Score);\r\n\r\nConsoleHelper.PrintMultiClassClassificationMetrics(""StochasticDualCoordinateAscent"", metrics);\r\n **RESULT**\r\n           **AccuracyMacro** : 0.11\r\n           **AccuracyMacro** : 0.25\r\n\r\n\r\n\r\n'"
415911044,2810,b'IRISClassification sample -MultiLabel calssification : Getting exception while referring slotnames',"b""@Ivanidzo4ka \r\nI am trying to do multilabel classification on IRISClassification. I am referring to this link https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/Scenarios/Api/Estimators/PredictAndMetadata.cs#L41\r\n\r\nWhile I am running the code I am getting below exception 'Invalid call to 'GetGetter'' while accessing slotnames.\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/53612079-bbdca700-3b85-11e9-968a-e0fc5e4b19c7.png)\r\n\r\n\r\n\r\n"""
415885683,2806,"b""My data view has a label column named 'Score'""","b""My data view has a label column named 'Score'\r\n\r\nIs there any way to have trainers output scores to a column other than the default 'Score'?\r\n\r\nThis may also apply to 'PredictedLabel'. Not sure if there are others"""
415873095,2805,b'OneVersusAll calibrator for naturally calibrated models',"b'This question came up during a code review of some changes to the One Versus All (OVA) Trainer. The OVA Trainer takes in a calibrator. If one is not specified, the PlattCalibrator is then used. After looking at the code, it looks like the calibrator is attached to each model instance that the OVA Trainer evaluates. \r\n\r\nThe question is what happens when you are using a naturally calibrated mode like logistic regression? Can this produce unexpected results?'"
415855951,2802,b'TextFeaturizer cannot specify n-grams for words or characters',"b'One of the stated goals of the V1 API was:\r\n* I can modify settings in the `TextFeaturizer` to update the number of word-grams and char-grams used along with things like the normalization.\r\n\r\nIn the current API for `TextFeaturizer`, it is possible to create n-grams from words and/or characters (`UseCharExtrator`, `UseWordExtractor`) but it is not possible to specify what sorts of n-grams to make.\r\n\r\nRelated to #2711 '"
415850935,2801,b'TextFeaturizer API is non-standard',"b'When specifying the input columns, `TextFeaturizer` specifies an `IEnumerable<string>`. The standard in the API is to specify a `string[]`.\r\n\r\nThis API should be updated to be consistent with the others. If we prefer `IEnumerable`, then we should switch all the other APIs.\r\n'"
415760739,2798,b'Normalize double min and max value returns NaN',"b'### System information\r\n\r\n- **OS version/distro**: .Net 4.6.2, Win 10\r\n- **.NET Version (eg., dotnet --info)**: ML.Net nuget 0.10.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Input data has a double columns with (double.min, double.max, <100 random numbers from 0 to 10000>), I call \r\n```\r\n            var normalizeColumns = numericalFeatures.Select(\r\n                f => new NormalizingEstimator.MeanVarColumn(f.Name, fixZero: false, useCdf: false)).ToArray();\r\n            var normalizingEstimator = this.context.Transforms.Normalize(normalizeColumns);\r\n```\r\nI see a feature in transformedData.Preview, which is all NaN, for each row. I use SDCA trainer\r\n\r\n- **What happened?** \r\n\r\nThe `pipeline.Fit(transformedData)` fails and throw an exception say ""train with 0 instances""\r\n\r\n- **What did you expect?**\r\n\r\n1. ML.Net should handle double.min, double.max for NormalizingEstimator?\r\n2. ML.Net should throw a more meaningful exception - ""train with 0 instances"" for a feature with NaN is a bit misleading - I do have 100+ rows for this feature. \r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
415745269,2795,"b'Refactor cancellation mechanism and make it internal, accessible via experimental nuget.'","b""Some time ago I added `StopExecution` method and `IsCancelled` flag to IHost.\r\nhttps://github.com/dotnet/machinelearning/blob/fbf282d982223a51cf6e4a9ad9f3f036e0f150ca/src/Microsoft.ML.Core/Data/IHostEnvironment.cs#L98\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fbf282d982223a51cf6e4a9ad9f3f036e0f150ca/src/Microsoft.ML.Core/Data/IHostEnvironment.cs#L74\r\n\r\nIt was quick solution to make certain algorithms react to stop signal from user. I doubt in long run it's proper way to do it. And it probably required lengthy discussion how to expose stopping functionality (method, or `CancellationToken`, or something else).\r\n\r\nBut for now I think it's a good idea to remove method and flag from our public API. Especially considering what no code actually checking `IsCancelled` flag.\r\n\r\nEDIT: We decided to keep this functionality but make it internal and still be accessible via experimental nuget."""
415739041,2794,b'SamplesUtils is not searchable on doc site and makes ML.NET learning curve sharp',"b""We use `SamplesUtils` project in many examples. However, its functions and classes cannot be found in ML.NET's official doc site. This is not ideal because once a user has a question regarding `SamplesUtils` when learning our API examples, they will be blocked until they clones ML.NET or finds the right nuget package. This makes the learning curve of ML.NET very sharp. Also, please do not expect users have Visual Studio installed, so finding the right solution can be even more painful."""
415733785,2793,b'Training/testing models on dynamic types',"b""Using the latest stable 0.10.0 version\r\n\r\nMy training data is laid out in a CSV and is pulled from a SQL DB that transposes and aggregates rows into columns. \r\n\r\nSo at no point is there any guarantee that I know my exact schema of columns, making it impossible to create a C# class definition before running the program.\r\n\r\nHow can I pass in a dynamic type to create the IDataView for example? \r\n\r\n`IDataView trainingDataView = mlContext.Data.ReadFromTextFile<dynamic>(_trainDataPath, hasHeader: true, separatorChar: ',');`\r\n"""
415602006,2791,b'Error when using OnnxTransformer in two AppDomains',"b'### System information\r\n\r\n- **OS version/distro**: Version\tWindows 10.0.17763\r\n\r\n- **.NET Version (eg., dotnet --info)**:  .Net 4.6.2\r\n\r\n### Issue Error when using OnnxTransformer in two AppDomains\r\n\r\n- **What did you do?** \r\n\r\nI have a (production) application with two AppDomains. \r\nI\'m trying to run OnnxTransformer in my code within the AppDomain, and get an error when second AppDomain is invoked. \r\nThe error is easily reproduced in a Console App with two AppDomains (below). \r\n\r\n- **What happened?**\r\n\r\nError is thrown. \r\n\r\nMicrosoft.ML.OnnxRuntime.OnnxRuntimeException: \'[ErrorCode:RuntimeException] Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time\r\n\r\n### Source code / logs\r\n\r\nHere is simple code to reproduce the error:\r\n\r\nnamespace MlNetAppDomainErrorRepro\r\n{\r\n    using System;\r\n    using Microsoft.ML;\r\n    using Microsoft.ML.Transforms;\r\n\r\n    class Program\r\n    {\r\n        public static void CreateOnnxTransformer()\r\n        {\r\n            MLContext context = new MLContext();\r\n            OnnxTransformer t = new OnnxTransformer(context, @""PathToYourModel.onnx"");\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            CreateOnnxTransformer();\r\n\r\n            AppDomain secondAppDomain = AppDomain.CreateDomain(""SecondAppDomain""); \r\n\r\n            secondAppDomain.DoCallBack(CreateOnnxTransformer); // error here\r\n\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n}\r\n\r\n'"
415498520,2789,b'What is the relationship between this project and the Windows ML project?',b''
415460281,2788,"b'When running on WPF GUI thread, very unhelpful error Score column score not found, also found solution'","b""### System information\r\nWindows 10 .net 4.5.2\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nWriting code that is similar to the demand prediction regression example but inside a WPF gui app\r\n\r\n- **What happened?**\r\n\r\nRan into very non-descriptive and unhelpful error Score column score not found during a regression evaluation routine. Looked up information online and none of it was helpful. It looks like score column score not found essentially means undetermined exception. I think unknown exception would be more helpful just so I didn't spend so much time trying to figure out why I was missing a score column.\r\n\r\nWhen running regression evaluation from a button command on a WPF GUI, this error occurs for some reason. It can be solved simply by putting the regression evaluation routine in a Task like:\r\n\r\nTask.Run(() => {\r\nthis.mlContext.Regression.Evaluate().\r\n});\r\n\r\n- **What did you expect?**\r\n\r\nI expect it to not matter if I'm on an STA thread or not. I also expect a helpful error message like ml.net not supported on STA thread, or even just thread exception.\r\n\r\n\r\n"""
415433234,2787,b'FastForest - Add Probability for predictions',b'Add probability response for inference to the Fast Forest algorithm.'
415389466,2786,b'Rename Microsoft.ML.StandardLearners to Microsoft.ML.StandardTrainers.',"b'CC: @TomFinley , @eerhardt '"
415383318,2785,b'GetExecutingAssemblyLocation in the DNNImageFeaturizers composes the wrong path',"b'Create a console project, add the MIcrosoft.ML, the Microsoft.Ml.OnnxTransformer and one of the Microsoft.ML.DnnImageFeaturizer packages. \r\n\r\nTry running the following snippet:\r\n\r\n             // Downloading a few images, and an images.tsv file, which contains a list of the files from the dotnet/machinelearning/test/data/images/.\r\n            // If you inspect the fileSystem, after running this line, an ""images"" folder will be created, containing 4 images, and a .tsv file\r\n            // enumerating the images. \r\n            var imagesDataFile = Microsoft.ML.SamplesUtils.DatasetUtils.DownloadImages();\r\n\r\n            // Preview of the content of the images.tsv file\r\n            //\r\n            // imagePath    imageType\r\n            // tomato.bmp   tomato\r\n            // banana.jpg   banana\r\n            // hotdog.jpg   hotdog\r\n            // tomato.jpg   tomato\r\n\r\n            var data = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = new[]\r\n                {\r\n                        new TextLoader.Column(""ImagePath"", DataKind.String, 0),\r\n                        new TextLoader.Column(""Name"", DataKind.String, 1),\r\n                }\r\n            }).Load(imagesDataFile);\r\n\r\n            string codeBaseUri = typeof(Program).Assembly.CodeBase;\r\n            string path = new Uri(codeBaseUri).AbsolutePath;\r\n            var f =  Directory.GetParent(path).FullName;\r\n\r\n            var imagesFolder = Path.GetDirectoryName(imagesDataFile);\r\n            // Image loading pipeline. \r\n            var pipeline = mlContext.Transforms.LoadImages(imagesFolder, (""ImageObject"", ""ImagePath""))\r\n                          .Append(mlContext.Transforms.ResizeImages(""ImageObject"", imageWidth: 224, imageHeight: 224))\r\n                          .Append(mlContext.Transforms.ExtractPixels(""Pixels"", ""ImageObject""))\r\n                           //.Append(mlContext.Transforms.DnnFeaturizeImage(""FeaturizedImage"", m => m.ModelSelector.ResNet18(mlContext, m.OutputColumn, m.InputColumn, @""C:\\Code\\mlnet2\\machinelearning-1\\bin\\AnyCPU.Debug\\Microsoft.ML.Samples\\netcoreapp2.1\\DnnImageModels""), ""Pixels""));\r\n                           .Append(mlContext.Transforms.DnnFeaturizeImage(""FeaturizedImage"", m => m.ModelSelector.ResNet18(mlContext, m.OutputColumn, m.InputColumn), ""Pixels""));\r\n\r\n            var transformedData = pipeline.Fit(data).Transform(data);\r\n\r\n            var preview = transformedData.Preview();\r\n\r\nYou\'ll notice that the program will fail with message:\r\n\r\n`System.ArgumentOutOfRangeException: \'Specified argument was out of the range of valid values. Parameter name: ModelFile\'`\r\n\r\nThat is because the Resnet18 extension is looking for the model in the path created by [AssemblyPathHelper](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.DnnImageFeaturizer.AlexNet/AssemblyPathHelpers.cs)\r\n\r\nThe path created points to the  **lib\\netstandard2.0\\DnnImageModels\\**\r\nthe packages actually get downloaded in the  **\\tools\\DnnImageModels**  folder. \r\n\r\nFull path of the folders, inside the downloaded nuget packages. \r\n- constructed:  **microsoft.ml.dnnimagefeaturizer.resnet18\\<version>\\lib\\netstandard2.0\\DnnImageModels\\**\r\n- actual location of the DnnImageModels folder:  **microsoft.ml.dnnimagefeaturizer.resnet18\\<version>\\tools\\DnnImageModels**\r\n\r\nNeed to construct the correct path. '"
415381137,2784,b'Message related to missing models not sufficiently helpful in DNNImageFeaturizers packages',"b'Create a new console project, and try running the following sample:\r\n\r\n\r\n             // Downloading a few images, and an images.tsv file, which contains a list of the files from the dotnet/machinelearning/test/data/images/.\r\n            // If you inspect the fileSystem, after running this line, an ""images"" folder will be created, containing 4 images, and a .tsv file\r\n            // enumerating the images. \r\n            var imagesDataFile = Microsoft.ML.SamplesUtils.DatasetUtils.DownloadImages();\r\n            var data = mlContext.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = new[]\r\n                {\r\n                        new TextLoader.Column(""ImagePath"", DataKind.String, 0),\r\n                        new TextLoader.Column(""Name"", DataKind.String, 1),\r\n                }\r\n            }).Load(imagesDataFile);\r\n\r\n            string codeBaseUri = typeof(Program).Assembly.CodeBase;\r\n            string path = new Uri(codeBaseUri).AbsolutePath;\r\n            var f =  Directory.GetParent(path).FullName;\r\n\r\n            var imagesFolder = Path.GetDirectoryName(imagesDataFile);\r\n            // Image loading pipeline. \r\n            var pipeline = mlContext.Transforms.LoadImages(imagesFolder, (""ImageObject"", ""ImagePath""))\r\n                          .Append(mlContext.Transforms.ResizeImages(""ImageObject"", imageWidth: 224, imageHeight: 224))\r\n                          .Append(mlContext.Transforms.ExtractPixels(""Pixels"", ""ImageObject""))\r\n                           //.Append(mlContext.Transforms.DnnFeaturizeImage(""FeaturizedImage"", m => m.ModelSelector.ResNet18(mlContext, m.OutputColumn, m.InputColumn, @""C:\\Code\\mlnet2\\machinelearning-1\\bin\\AnyCPU.Debug\\Microsoft.ML.Samples\\netcoreapp2.1\\DnnImageModels""), ""Pixels""));\r\n                           .Append(mlContext.Transforms.DnnFeaturizeImage(""FeaturizedImage"", m => m.ModelSelector.ResNet18(mlContext, m.OutputColumn, m.InputColumn), ""Pixels""));\r\n\r\n            var transformedData = pipeline.Fit(data).Transform(data);\r\n\r\n            var preview = transformedData.Preview();\r\n\r\nYou\'ll notice that the program fails with the following exception:\r\n\r\n`System.ArgumentOutOfRangeException: \'Specified argument was out of the range of valid values.\r\nParameter name: ModelFile\'`\r\n\r\nThe message is not sufficiently helpful. '"
415367170,2778,"b'Possible Bug Tensorflow in v0.11 - Invalid argument: input must be 4-dimensional[224,224,3]'","b'Starting from [a working ML.NET sample](https://github.com/dotnet/machinelearning-samples/tree/migration/v.11/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow/ImageClassification) scoring the standard TensorFlow Inception v3 model (it was working on 0.9 and 0.10) after migrating to 0.11 (I just needed to fix a couple of breaking changes in the API) the model is now throwing the following exception: \r\n\r\nException from TensorFlow:\r\n\r\n```\r\n2019-02-27 14:56:18.800272: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:437 : Invalid argument: input must be 4-dimensional[224,224,3]\r\n\r\nEXCEPTION\r\n#########\r\ninput must be 4-dimensional[224,224,3]\r\n         [[{{node conv2d0_pre_relu/conv}} = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_input_0_0, conv2d0_w)]]\r\n```'"
415365770,2776,b'broken links in documentation search results',"b'Go to \r\nhttps://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml?view=ml-dotnet&branch=smoke-test-preview\r\nType IEstimator in the search box\r\nA few search results appear, first one being:\r\nMicrosoft.ML.Core.Data.IEstimator<TTransformer> Interface\r\nLinking to https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.core.data.iestimator-1?view=ml-dotnet\r\n\r\nThis link goes to 404\r\n'"
415360401,2774,b'OneHotEncoding with Outputkind.Bin spits out wrong dimension data arrays',"b'### System information\r\n\r\n- **OS version/distro**:  0.11.0-preview-27427-9 \r\n\r\n### Issue\r\nOneHotEncoding with Outputkind.Bin spits out data elements of 3-dimensional arrays, while 2 dimensional arrays expected. Outputkind.Ind and Outputkind.Bag are correctly spitting out 2 dimensional arrays. See repro source code below\r\n\r\n### Source code / logs\r\nusing System;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Transforms.Categorical;\r\n\r\nnamespace ConsoleApp1\r\n{\r\n    class TestData\r\n    {\r\n        public string data;\r\n    }\r\n\r\n\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var trainData = new[] { new TestData() { data = ""male"" }, new TestData() { data = ""female""} };\r\n            var testData = new[] { new TestData() { data = ""male"" }, new TestData() { data = ""female"" }, new TestData() { data = ""fem"" }, new TestData() { data = ""fem1"" } };\r\n\r\n            var mlContext = new MLContext();\r\n            var trainDataView = mlContext.Data.LoadFromEnumerable(trainData);\r\n            var testDataView = mlContext.Data.LoadFromEnumerable(testData);\r\n\r\n            var pipe = mlContext.Transforms.Categorical.OneHotEncoding(""Bag"", ""data"", OneHotEncodingTransformer.OutputKind.Bag)\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Key"", ""data"", OneHotEncodingTransformer.OutputKind.Key))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Ind"", ""data"", OneHotEncodingTransformer.OutputKind.Ind))\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Bin"", ""data"", OneHotEncodingTransformer.OutputKind.Bin));\r\n\r\n            var transformer = pipe.Fit(trainDataView);\r\n\r\n            var result = transformer.Transform(testDataView);\r\n\r\n            var bags = result.GetColumn<float[]>(mlContext, ""Bag"").ToArray();\r\n            var inds = result.GetColumn<float[]>(mlContext, ""Ind"").ToArray();\r\n            var bins = result.GetColumn<float[]>(mlContext, ""Bin"").ToArray();\r\n\r\n            Console.WriteLine(""Number of dimensions (should be 2) in each output kind: {0} {1} {2}"", bags[0].Length, inds[0].Length, bins[0].Length);\r\n            // Number of dimensions (should be 2) in each output kind: 2 2 3\r\n        }\r\n    }\r\n}'"
415354925,2772,b'KeyToVectorMappingEstimator catalog extension method summary is wrong',"b'This documentation appears to be incorrect.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a0edc5c5724ed2895fd0c2fa5c2525d03de13455/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L93-L97\r\n\r\nThis is for taking a key value (or key values) and mapping it into a floating point vector suitable for learning (variously, one-hot-encoding, or bag-of-words vector, depending on the type of input data and other applications). But to say it ""converts it back to its original vector"" is in no way accurate.\r\n\r\nPerhaps someone got a little excited copying and pasting from the `KeyToValue` methods above.'"
415339261,2769,b'BinaryClassificationMetrics is not sealed - but equivalent classes for regression and multiclass are',b'Inconsistency in API extensibility -- see title'
415336271,2768,b'One of the FeaturizeText extensions has the inputColumnNames as required',"b'The are two extensions for Featurize text. \r\n\r\n        public static TextFeaturizingEstimator FeaturizeText(this TransformsCatalog.TextTransforms catalog, string outputColumnName, string inputColumnName = null);\r\n\r\n        public static TextFeaturizingEstimator FeaturizeText(this TransformsCatalog.TextTransforms catalog, string outputColumnName, IEnumerable<string> inputColumnNames, TextFeaturizingEstimator.Options options);\r\n\r\nIMO,\r\n- On the first one, TextFeaturizingEstimator.Options options should exist as optional. \r\n- On the second one, TextFeaturizingEstimator.Options options should exist as optional. \r\n\r\nATM, if i want to use the TextFeaturizingEstimator.Options, i have to create an IEnumerable<string> for inputColumnNames and give it the output column name. \r\n\r\n    mlContext.Transforms.Text.FeaturizeText(""CarrierName"",\r\n        Enumerable.Repeat(""CarrierName"", 1),\r\n        new TextFeaturizingEstimator.Options\r\n        {\r\n                  KeepDiacritics = false,\r\n                  KeepPunctuations = false,\r\n                  TextCase =TextNormalizingEstimator.CaseNormalizationMode.Lower,\r\n                  OutputTokens = true,\r\n                  VectorNormalizer = TextFeaturizingEstimator.TextNormKind.L2\r\n         }))'"
415332979,2767,b'IndicateMissingValues documentation',"b'The documentation for \r\n```\r\npublic static MissingValueIndicatorEstimator IndicateMissingValues(this TransformsCatalog catalog,\r\n            string outputColumnName,\r\n            string inputColumnName = null)\r\n```\r\nsays:\r\nCreates a new output column, or replaces the source with a new column (depending on whether the `outputColumnName` is given a value, or left to null) \r\n\r\nit should be:\r\nCreates a new output column, or replaces the source with a new column (depending on whether the `inputColumnName` is given a value, or left to null) '"
415276845,2763,"b'LinearModelParameters have two ways to get Weights, should be one'","b""we have this:\r\nhttps://github.com/dotnet/machinelearning/blob/a0edc5c5724ed2895fd0c2fa5c2525d03de13455/src/Microsoft.ML.StandardLearners/Standard/LinearModelParameters.cs#L93\r\nand we have this:\r\nhttps://github.com/dotnet/machinelearning/blob/a0edc5c5724ed2895fd0c2fa5c2525d03de13455/src/Microsoft.ML.StandardLearners/Standard/LinearModelParameters.cs#L387\r\n\r\nI would prefer to hide second one (and `IHaveFeatureWeights` interface) but it's up to discussion\r\n"""
415270307,2762,b'TrainersName pattern (Discussion)',"b""https://github.com/dotnet/machinelearning/issues/2172 follow up on this one.\r\nSo right now we have mix of trainers names.\r\nI want to standardize them.\r\n\r\nWe have following zoo of naming patterns:\r\n`LogisticRegression`\r\n`SdcaMultiClassTrainer`\r\n`SgdNonCalibratedBinaryTrainer`\r\n`LinearSvmTrainer`\r\n`LightGbmMulticlassTrainer`\r\n`MulticlassLogisticRegression`\r\n\r\nMy proposal is following:\r\n\r\n`{AlgoName}(optional){Calibrated/NonCalibrated}{TypeOfTask}Trainer`\r\n\r\nWhere AlgoName is full name without abbreviations (SDCA->StochasticDualCoordinateAscent, Linearsvm ->LinearSupportVectorMachines) with exception of LightGBM.\r\n\r\nI would also prefer to explicitly specify TypeOfTask even if algorithm exist only for one type. (Which would create weird abominations like OneVersusAllMulticlassTrainer, but i'm fine with that)\r\n\r\nDoes that sound good for you?\r\n@sfilipi  @TomFinley  @eerhardt  @yaeldekel  \r\n"""
415249343,2760,b'Consistency in feature/label/weight/group names in LearnerInputBase classes',"b'We have this class which is base class for all(almost except KMeans) Trainers.Options\r\nhttps://github.com/dotnet/machinelearning/blob/d4f2dcfbc11d7081748408d20c35d3e2ff2aa143/src/Microsoft.ML.Data/EntryPoints/InputBase.cs#L42\r\n\r\nIn trainer catalog we use following names:\r\n```\r\n/// <param name=""labelColumnName"">The name of the label column.</param>\r\n/// <param name=""featureColumnName"">The name of the feature column.</param>\r\n/// <param name=""rowGroupColumnName"">The name of the group column.</param>\r\n/// <param name=""exampleWeightColumnName"">The name of the example weight column (optional).</param>\r\n```\r\nIt doesn\'t feel right to have this names in catalog and have other names in options class.\r\nSo we should make them consistent and update LearnerInputBase class to ones we use in catalog.\r\n'"
415171023,2756,b'Need to rename HalLearners assembly and nuget',"b'The name `HalLearners` isn\'t a great public name. We should come up with a better name.\r\n\r\nCurrent issues:\r\n\r\n1. What does `Hal` mean?\r\n2. We are using the term ""trainers"" instead of ""learners"" everywhere else.\r\n3. This assembly contains more than just learners/trainers. It also has vector whitening, which isn\'t a trainer.\r\n\r\nPossible suggestions to get the naming started:\r\n\r\n1. `Microsoft.ML.HardwareAccelerated`\r\n2. `Microsoft.ML.HardwareAccelerated.Components`\r\n3. `Microsoft.ML.Mkl`\r\n    - (we already have `Microsoft.ML.Mkl.Redist`. this would be an analog to `ML.TensorFlow` and `ML.TensorFlow.Redist`)\r\n4. `Microsoft.ML.Mkl.Components`\r\n\r\n@TomFinley @sfilipi @Ivanidzo4ka @shauheen @yaeldekel '"
414884463,2752,b'FastTree needs its own package',b'We decided move FastTree library into separate package.'
414872944,2751,b'Namespace reorg for the public surface ',"b'Related to #2326, and the feedback of the ML.Net public surface API recommended the following changes:\r\n \r\n1 - Microsoft.ML.Trainers.* everything should go to Microsoft.ML.Trainers, except FastTree. \r\n2- Microsoft.ML.Transforms.* should go to Microsoft.ML.Transforms with the exception of Text and Images\r\n\r\n\r\ncc @Ivanidzo4ka , @eerhardt @TomFinley \r\n\r\n'"
414869153,2750,b'R4 label works with some but not all binary classification trainers',"b'This code:\r\n\r\n```C#\r\nusing System;\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace Microsoft.ML.Samples\r\n{\r\n    internal static class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var context = new MLContext();\r\n            var options = new TextLoader.Options()\r\n            {\r\n                Columns = new TextLoader.Column[]\r\n                {\r\n                    new TextLoader.Column(""Label"", DataKind.Single, 0),\r\n                    new TextLoader.Column(""Sentiment"", DataKind.String, 1)\r\n                },\r\n                HasHeader = true\r\n            };\r\n            var loader = context.Data.CreateTextLoader(options);\r\n            var data = loader.Read(@""C:\\AutoMLDotNet\\src\\Samples\\Data\\wikipedia-detox-250-line-data.tsv"");\r\n            var estimator = context.Transforms.Text.FeaturizeText(""Features"", ""Sentiment"")\r\n                .Append(context.BinaryClassification.Trainers.AveragedPerceptron());\r\n            var transformer = estimator.Fit(data);\r\n            var scoredData = transformer.Transform(data);\r\n            var metrics = context.BinaryClassification.EvaluateNonCalibrated(scoredData);\r\n            Console.WriteLine(metrics.Accuracy);\r\n            Console.WriteLine(""Press any key..."");\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n}\r\n```\r\nworks great!\r\n\r\nIf you replace AveragedPerceptron with LogisticRegression, it throws the exception:\r\n```\r\n \'Schema mismatch for label column: expected Bool, got R4\'\r\n```\r\n\r\nThis may indicate a bug in label schema validation with some binary learners'"
414840331,2746,b'Should the Microsoft.ML.*.StaticPipe namespaces fold into the Microsoft.ML.StaticPipe?',"b'As we are aligning the namespaces of the trainers and transforms main package, `Microsoft.ML`; and moving them from subcategories to the main root, we should probably do the same for the StaticPipe assembly and namespaces. \r\n\r\nSo potentially move things like: \r\nMicrosoft.ML.StaticPipe.Runtime\r\nMicrosoft.ML.HalLearners.StaticPipe\r\nMicrosoft.ML.Transforms.StaticPipe\r\nMicrosoft.ML.LightGBM.StaticPipe\r\n\r\nto \r\nMicrosoft.ML.StaticPipe\r\n'"
414742119,2739,b'Rms is Too High',b'Hi \r\nI use the Taxi Fair Code Sample and i changed it to predict  the LAST Price of a Stock in Market \r\nnothing too big.....\r\nRms is on 40 and Predict is wrong\r\n\r\nMy question  is what can i do to reduce the Rms?\r\nand why Rms is too high?'
414729013,2737,b'Internalize Microsoft.ML.Internal.CpuMath.GeneralUtils',b'We have a single type exposed in `namespace Microsoft.ML.Internal.CpuMath`\r\n\r\n```C#\r\nnamespace Microsoft.ML.Internal.CpuMath {\r\n    public static class GeneralUtils {\r\n        public static int CbitLowZero(uint u);\r\n    }\r\n}\r\n```\r\n\r\nwe should make it internal.\r\n\r\nPart of #2326\r\n\r\n/cc @codemzs @sfilipi '
414713692,2736,b'Question in the Text Encoding when doing mlContext.Data.ReadFromTextFile',"b""General question, does ML.NET support code page other than utf-8?\r\nAre we able to set the file encoding to other than utf-8? Or that is totally not necessary.\r\n\r\nFor example, I'm going to analyze the sentiment project in French. And my training dataset is all in French. Will the training process run as expected? """
414701876,2735,b'Add API to save/load models with their input schema',"b'Reasons for this are listed in issue #2663.\r\n\r\nCurrently, ModelOperationsCatalog offers the following API:\r\n\r\n```\r\npublic void Save(ITransformer model, Stream stream) \r\npublic ITransformer Load(Stream stream)\r\n```\r\nSo when using a loaded model, users have to create the `IDataView` to be passed to the `ITransformer` themselves by creating a new `TextLoader`, (or another way?). \r\nI suggest adding these new APIs to ModelOperationsCatalog:\r\n\r\n```\r\npublic void Save<TSource>(IDataReader<TSource> model, Stream stream);\r\npublic void Save<TSource>(IDataReader<TSource> reader, ITransformer model, Stream stream);\r\npublic IDataReader<TSource> Load<TSource>(Stream stream);\r\n```\r\nThe last one would return a `CompositeDataReader` containing the loader and the `ITransformer` chain, so we could also add new APIs to `DataOperationsCatalog` to only load the reader:\r\n\r\n```\r\npublic TextLoader CreateTextLoader(Stream stream);\r\n```\r\n\r\nAnother option is to add an API that creates a `PredictionEngine` from a `Stream`, or an API that creates a `SchemaDefinition` from a `Stream` (that way users can use the existing API to create a `PredictionEngine`).\r\n\r\n@TomFinley, what do you think?\r\n'"
414594508,2734,"b""Catalog.NormalizeText doesn't offer a multi-column version""","b'API: Usually most catalog functions will have an overloaded method to supply multiple columns.\r\n\r\nE.g. `ctx.Transforms.Text.TokenizeWords()`. Though, `ctx.Transforms.Text.NormalizeText()` only offers single input column to single output column. Was this overlooked or by-design?'"
414434974,2732,b'Can speech recognition be done in ML.NET?',"b'### System information\r\n\r\n- **OS version/distro**:  Windows\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6\r\n\r\n### Issue\r\n\r\nI am new to Machine Learning. I came across ML.NET (Machine Learning framework by Microsoft). Can we use this framework for speech recognition? What all things you should know if you want to do a speech recognition in ML.NET?\r\n\r\n '"
414380107,2728,"b""Ranker Evaluate doesn't allow you specify metric parameters.""","b""https://github.com/dotnet/machinelearning/blob/3b9d407d9dc4f8c46fa85ab80575ef16d74df6df/src/Microsoft.ML.Data/TrainCatalog.cs#L626\r\nI can't specify how deep I want to calculate NDCG@i (i.e. i maximum), I can't specify custom gains."""
414369082,2726,b'Text loader v.s in-memory data structure in API reference samples',"b""We often starts our trainer examples with text loader but recently I feel loading text into `IDataView` is not directly related to the actual training procedure. If we use\r\n```csharp\r\n/// <summary>\r\n/// Example with one binary label and 10 feature values.\r\n/// </summary>\r\npublic class BinaryLabelFloatFeatureVectorSample\r\n{\r\n    public bool Label;\r\n\r\n    [VectorType(_simpleBinaryClassSampleFeatureLength)]\r\n    public float[] Features;\r\n}\r\n```\r\nas our in-memory example, we can create more [flexible examples](https://github.com/dotnet/machinelearning/blob/7cc208c36edec554b6353a3a268cfb5e49274d17/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/SDCASupportVectorMachine.cs#L12) like [scikit-learn ones (where data matrix is float matrix)](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) and make ML.NET's learning curve smoother (because users don't need to learn text loader, the loaded data, and trainer at the same time).\r\n\r\ncc @shmoradims, @rogancarr, @sfilipi, @shauheen \r\n\r\n#2780 shows a scikit-learn-style example for ML.NET. It is\r\n\r\n- Self-contained --- To understand it, user doesn't need to look another document or use Visual Studio to search for those used functions. Notice that we can't rely on Visual Studio because not everyone is using it (1st partry and 3rd party experiences should the same!).\r\n- End-to-end to C# developers --- because it trains a model over a C# List and get the prediction back as a C# List (The two ends are not IDataView so user doesn't need to learn IDataView to play with that API).\r\n- Independent to external packages --- We shouldn\xe2\x80\x99t expect a user who needs doc knows SamplesUtils.\r\n- Production-friendly --- Doing prediction with C# data structure is included. That's how a trained model will be used in production."""
414367658,2725,b'Are we happy with Anomaly Detection metrics?',"b'Right now it has two properties.\r\nAUC and DetectionRateAtKFalsePosititives.\r\nWe describe `DetectionRateAtKFalsePosititives`\r\nas:\r\n```\r\n /// This is computed as follows:\r\n        /// 1.Sort the test examples by the output of the anomaly detector in descending order of scores.\r\n        /// 2.Among the top K False Positives,  compute ratio :  (True Positive @ K)  / (Total anomalies in test data)\r\n        /// Example confusion matrix for anomaly detection:\r\n        ///                            Anomalies (in test data)  | Non-Anomalies (in test data)\r\n        ///  Predicted Anomalies     :         TP                |           FP\r\n        ///  Predicted Non-Anomalies :         FN                |           TN\r\n```\r\nand we expose nothing of that.\r\nNo True positive, no total anomalies, no K which user need to save somewhere else.\r\n\r\nShould we expand this metrics right now or wait till v1.0 release?\r\n'"
414359914,2723,b'CreateEnumerable with reused-object and CustomMapping returns identical rows',"b'When a pipeline with a `CustomMapping` is enumerated over with `CreateEnumerable(reuseRowObject: true)`, the row produced will be identical: The last row in the IDataView.\r\n\r\nThis is a reproducing example that can be run from the `Functional.Tests` project:\r\n```cs\r\nvar mlContext = new MLContext(seed: 1, conc: 1);\r\n\r\n// Load the Iris dataset\r\nvar data = mlContext.Data.ReadFromTextFile<Iris>(\r\n    GetDataPath(TestDatasets.iris.trainFilename),\r\n    hasHeader: TestDatasets.iris.fileHasHeader, \r\n    separatorChar: TestDatasets.iris.fileSeparator);\r\n\r\n// Subsample it down to the first 10 rows\r\nint numSamples = 10;\r\ndata = mlContext.Data.TakeRows(data, numSamples);\r\n\r\n// Create a function that generates a random number as a column.\r\n// Save this number for debugging.\r\nvar rng = new Random(1);\r\nvar randomNumbers = new List<int>(capacity: numSamples) { };\r\nAction<Iris, IrisWithGroup> generateGroupId = (input, output) =>\r\n{\r\n    var randomNumber = rng.Next(0, 30);\r\n    randomNumbers.Add(randomNumber);\r\n    Output.WriteLine($""{input.Label}\\t{input.PetalLength}\\t{randomNumbers.Count()}\\t{randomNumber}\\t{randomNumbers.Sum()}"");\r\n    output.Label = input.Label;\r\n    output.GroupId = randomNumber;\r\n    output.PetalLength = input.PetalLength;\r\n    output.PetalWidth = input.PetalWidth;\r\n    output.SepalLength = input.SepalLength;\r\n    output.SepalWidth = input.SepalWidth;\r\n};\r\n\r\n// Create a pipeline to execute the custom function.\r\nvar pipeline = mlContext.Transforms.CustomMapping(generateGroupId, null);\r\n\r\n// Transform the data\r\nvar transformedData = pipeline.Fit(data).Transform(data);\r\n\r\n// Verify that the column has the correct data.\r\n// Bug: Switch this to `reuseRowObject: false` for correct behavior\r\nvar transformedRows = mlContext.CreateEnumerable<IrisWithGroup>(transformedData, reuseRowObject: true).Take(numSamples).ToArray();\r\nAssert.Equal(randomNumbers.Count(), transformedRows.Length);\r\nfor (int i = 0; i < transformedRows.Length; i++)\r\n    Output.WriteLine($""{transformedRows[i].Label}\\t{transformedRows[i].PetalLength}\\t{transformedRows[i].GroupId}\\t{randomNumbers[i]}"");\r\n```\r\n\r\nNote that the iterator over the enumerable prints the last row over and over again.'"
414355960,2721,b'Remove and combine Microsoft.ML.UniversalModelFormat.Onnx with Microsoft.ML.Model.OnnxConverter',b'towards #2326\r\n'
414355875,2720,b'Remove and combine Microsoft.ML.UniversalModelFormat.Onnx with Microsoft.ML.Model.OnnxConverter',b'towards #2326\r\n'
414350523,2719,"b""Enumerable over IDataView cannot be Zip'ped""","b'When an enumerator over an `IDataView` is `zip`ped with Linq, the following error is thrown:\r\n\r\n""**System.InvalidOperationException**: Collection was modified; enumeration operation may not execute.""\r\n\r\nHere is an example:\r\n```cs\r\nvar myEnumerable = mlContext.CreateEnumerable<MyClass>(data, true);\r\nforeach (var rowAndNumber in myEnumerable.Zip(numbers, (row, number) => new { row, number }))\r\n{\r\n    Console.WriteLine($""{rowAndNumber.row.Column}\\t{rowAndNumber.number}"");\r\n}\r\n```\r\n\r\nI marked this as a bug, but is this expected behavior?'"
414344958,2717,"b""Ensemble project shouldn't be part of Microsoft.ML""","b""From public perspective it's just dll with 0 public classes and none of other projects in Microsoft.ML rely on it."""
414333531,2714,b'Microsoft.ML.Internal.Internallearn should be hidden/moved/renamed.',b'towards #2326'
414333079,2713,b'Drop Microsoft.ML.Training and replace it with Microsoft.ML.Trainers',b'towards #2326'
414309883,2711,b'Create functional tests for all V1 Data Transformation scenarios',"b'As laid out in #2498 , we need scenarios to cover the Data Transformation functionality we want fully supported in V1.\r\n\r\n- Extensible transformation: It should be possible to write simple row-mapping transforms.\r\nExamples: ""I can add custom steps to my pipeline such as creating a new column that is the addition of two other columns, or easily add cosine similarity, without having to create my own build of ML.NET.\r\n- I can modify settings in the TextFeaturizer to update the number of word-grams and char-grams used along with things like the normalization.\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0\r\n- I can apply normalization to the columns of my data'"
414216728,2708,b'Log loss metric can be Infinity or NaN',"b'For binary classification (and perhaps multiclass classification) the `log loss` can be infinite. The `log loss reduction` can also be negative infinity, as it is a shifting and rescaling of the `log loss`.\r\n\r\nSimilarly, the `log loss` can be a `NaN`. This is specifically guarded against in the code, but does seems like a bug too.\r\n\r\nThe culprit for both cases lies in the initial calculations in the `ProcessRow()` method of the `Aggregator` for the `BinaryClassifierEvaluator`.\r\n\r\n```cs\r\nDouble logloss;\r\nif (!Single.IsNaN(prob))\r\n{\r\n    if (_label > 0)\r\n    {\r\n        // REVIEW: Should we bring back the option to use ln instead of log2?\r\n        logloss = -Math.Log(prob, 2);\r\n    }\r\n    else\r\n        logloss = -Math.Log(1.0 - prob, 2);\r\n}\r\nelse\r\n    logloss = Double.NaN;\r\n```\r\n\r\nI propose that to guard against infinities we add an epsilon before taking the log.\r\n\r\nTo guard against `NaNs`, we will need to fix the probability calculations (e.g. in the calibrator(s)).'"
413578753,2699,"b""Support TensorFlow Saved Model's with legacy_init_op and main_op""","b'### System information\r\n\r\n- **OS version/distro**: All\r\n- **.NET Version (eg., dotnet --info)**: ML.net 0.11\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to load SavedModel.\r\n- **What happened?**\r\nReceived a table not initialized error.\r\n- **What did you expect?**\r\nTable initialization is specified in legacy_init_op. I expected the operation(s) in legacy_init_op to be executed after loading the model.\r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/saved_model/Builder#add_meta_graph for more information on legacy_init_op and main_op.'"
413504869,2696,b'Need to remove FastTree/Utils/MD5Hasher class',"b'Currently FastTree uses a 16byte MD5 hash to ensure uniqueness of content. \r\n\r\n### There are several issues with this:\r\n- The MD5 hash is a (weak) cryptographic hash, resulting in additional work for the release process with regards to export controls.\r\n- MD5 hash is quite slow and memory intensive\r\n\r\n### Suggested Fix:\r\n- Rename MD5Hash to ContentHash or similar. \r\n- Same goes to MD5Hasher\r\n- Update all Hash(,,,) methods to not use MD5CryptoServiceProvider but murmur hash or equivalent instead.\r\n- Ensure no reference to System.Security.Cryptography namespace exists in the codebase afterwards.\r\n- Alternatively, we can extend the murmurhash class to return \r\n'"
413221888,2694,b'ML.NET CLI using AutoML capabilities (Specs document for discussion)',"b'We\'re starting to work on a new ML.NET CLI (command-line tool) which aims to help developers to generate ""best models"" and their related C# ML.NET code (using .NET AutoML capabilities under the covers) so you don\'t need to be an expert in ML.NET algorithms and hyper-parameters in order to create a model and the C# code to train and score/run that model.\r\n\r\nI just created a PR with the initial specs we are thinking to target for the first preview versions, so anyone in the community can share their feedback and help us to improve the design of this CLI tool for ML.NET. \r\n\r\n[ML.NET CLI specs PR](https://github.com/dotnet/machinelearning/pull/2693)\r\n\r\nFeel free to share your feedback for the PR, we will really appreciate it.\r\n\r\n**High level plan:**\r\n\r\nThe initial design and development will be performed under a PRIVATE PREVIEW we\'ll make available for public enrollment in March 2019. \r\nIn the meantime, we\'d love to get your feedback about this mentioned ML.NET CLI specs doc.\r\n\r\nRelated issues:\r\nhttps://github.com/dotnet/machinelearning/issues/1203'"
413180339,2689,b'Metric Names: Relative Information Gain vs. LogLoss Reduction',"b""In our Binary Classification and Multiclass Classification metrics, we have a measure for Relative Information Gain called `LogLossReduction`. Relative information gain seems to be the more commonly used term &mdash; it's actually hard to find search results on log-loss reduction. I wanted to get a quick set of opinions on:\r\n1) Is this actually common nomenclature?\r\n2) If not, shall we rename this to be Relative Information Gain?"""
413131386,2686,b'CrossValidation and TrainTest for AnomalyDetection',"b""There are two extensions for training, `TrainTestSplit` and `CrossValidation`, that are not clearly suited for `AnomalyDetection` as written.\r\n\r\n`TrainTestSplit` is available in `AnomalyDetection` as it's in the `TrainerCatalogBase`, but anomaly detection scenarios often have structured data (e.g. time series) that we don't handle. Do we disable `TrainTestSplit` for `AnomalyDetection`? Do we add support for some sorts of structured data different than we have now? Do we assume that all structural problems can be solved with a `SamplingKeyColumn`?\r\n\r\n`CrossValidation` is not supported, but could be supported, should we solve the `TrainTestSplit` issue."""
413123714,2685,"b'CrossValidation not available for Ranking, TrainTest not suitable for Ranking'",b'`Ranking` does not support cross-validation. This task should support CV as well.\r\n\r\nEdited: See comment below.'
413091760,2683,b'ImagePixelExtractingEstimator do not applied scale and offset for image',"b'### System information\r\n\r\n- **Windows 10**:\r\n- **.NET Core 2.1 ML.NET v0.10.0**: \r\n\r\n### Issue\r\n\r\n- **Try to use ImagePixelExtractingEstimator with scale and offset**\r\n- **sclae and offset do not applied for pixels data**\r\n- **sclale and offset should successfully applied**\r\n\r\n### Source code / logs\r\nThis code below doesn\'t work correctly\r\n```\r\nvar pipeline = new ImageLoadingEstimator(_mlContext, string.Empty, (""ImageData"", ""ImagePath""))\r\n                    .Append(new ImageResizingEstimator(_mlContext, ""ImageResized"", ImageWidth, ImageHeight, ""ImageData""))\r\n                    .Append(new ImagePixelExtractingEstimator(_mlContext, ""input"", ""ImageResized"", colors: ImagePixelExtractorTransformer.ColorBits.Rgb, interleave:true, asFloat: true, offset: 128f, scale: 1/255f))\r\n```\r\n\r\nSample below works correctly, but here is shouldn\'t be difference, right?\r\n```\r\nvar pipeline = new ImageLoadingEstimator(_mlContext, string.Empty, (""ImageData"", ""ImagePath""))\r\n                    .Append(_mlContext.Transforms.Resize(""ImageResized"", imageWidth: ImageWidth, imageHeight: ImageHeight, inputColumnName: ""ImageData""))\r\n                    .Append(_mlContext.Transforms.ExtractPixels(new ColumnInfo(""input"", ""ImageResized"", colors: ColorBits.Rgb, interleave:true, asFloat: true, offset: 128f, scale: 1 /255f)))\r\n```\r\n[Commit with changes in sample app](https://github.com/knpoklonski/image-recognition-onnx-sample/commit/79930119725e6981cab3f948a8e442cac0f7e9b6)\r\n\r\n'"
413017314,2680,"b""Make trainer input arguments' names consistent""","b""Just by looking at [StandardLearnersCatalog.cs](https://github.com/dotnet/machinelearning/blob/1f90f50f813ecd152e46e92deb4a7827c7f24e31/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs) I found a lot of inconsistent naming for the binary classification trainer arguments. \r\n\r\nBelow are the many naming variations that need to be conflated (both in extension method signatures and the Options properties):\r\n* labelColumnName, labelColumn\r\n* featureColumnName, featureColumn\r\n* weightColumnName, weights\r\n* initLearningRate, learningRate\r\n* l2Weight, l2Const, l2RegularizerWeight\r\n* l1Threshold, l1Weight\r\n* numIterations, maxIterations\r\n* lossFunction, loss\r\n* numIterations, NumberOfIterations\r\n\r\nI haven't checked yet, but it's probably the case for other trainers. There's probably more of these inconsistencies."""
412994257,2679,"b'Using WordBagEstimator when building the pipeline result in a error ""System.IndexOutOfRangeException: Index was outside the bounds of the array""'","b'I want to customize the process of the TextFeaturizing. And I try to use the code in the ML.NET cookbook, but I run into an error when include \r\n`.Append(new WordBagEstimator(mlContext, ""BagOfWords"", ""NormalizedMessage""))` \r\n`Error message: System.IndexOutOfRangeException: Index was outside the bounds of the array`\r\n\r\nCode from cookBook,\r\n```\r\n    var pipeline =\r\n    // One-stop shop to run the full text featurization.\r\n    mlContext.Transforms.Text.FeaturizeText(""TextFeatures"", ""Message"")\r\n\r\n    // Normalize the message for later transforms\r\n    .Append(mlContext.Transforms.Text.NormalizeText(""NormalizedMessage"", ""Message""))\r\n\r\n    // NLP pipeline 1: bag of words.\r\n    .Append(new WordBagEstimator(mlContext, ""BagOfWords"", ""NormalizedMessage""))\r\n\r\n    // NLP pipeline 2: bag of bigrams, using hashes instead of dictionary indices.\r\n    .Append(new WordHashBagEstimator(mlContext, ""BagOfBigrams"",""NormalizedMessage"", \r\n                ngramLength: 2, allLengths: false))\r\n\r\n    // NLP pipeline 3: bag of tri-character sequences with TF-IDF weighting.\r\n    .Append(mlContext.Transforms.Text.TokenizeCharacters(""MessageChars"", ""Message""))\r\n    .Append(new NgramExtractingEstimator(mlContext, ""BagOfTrichar"", ""MessageChars"", \r\n                ngramLength: 3, weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf))\r\n\r\n    // NLP pipeline 4: word embeddings.\r\n    .Append(mlContext.Transforms.Text.TokenizeWords(""TokenizedMessage"", ""NormalizedMessage""))\r\n    .Append(mlContext.Transforms.Text.ExtractWordEmbeddings(""Embeddings"", ""TokenizedMessage"",\r\n                WordEmbeddingsExtractingEstimator.PretrainedModelKind.GloVeTwitter25D));\r\n\r\n// Let\'s train our pipeline, and then apply it to the same data.\r\n// Note that even on a small dataset of 70KB the pipeline above can take up to a minute to completely train.\r\nvar transformedData = pipeline.Fit(data).Transform(data);\r\n```\r\n\r\nMy goal is to build a multiClass Classification model to detect city, firstName and lastName, but my logisticRegression Model is not working pretty well, although all the result is slightly higher than 50%. \r\n```\r\nAccuracyMacro = 0.6804, a value between 0 and 1, the closer to 1, the better\r\nAccuracyMicro = 0.7098, a value between 0 and 1, the closer to 1, the better\r\nLogLoss = 0.7575, the closer to 0, the better\r\nLogLoss for class 1 = 0.9082, the closer to 0, the better\r\nLogLoss for class 2 = 0.8419, the closer to 0, the better\r\nLogLoss for class 3 = 0.7824, the closer to 0, the better\r\n```\r\nI try the others ML tasks, but still not that accuracy. \r\nI\'m just thinking what could be improved from here. \r\nMy training dataset is over 1m consisting of city, firstname and lastname. I think it should be sufficient. \r\nI\'m thinking maybe the problem happened durring the propressing of the data.\r\nAny helps will be really appreciated!!'"
412925728,2678,b'Unintuitive error when giving array to OneHotEncoder',"b'The following will throw a very ugly exception only when calling `Preview()` and not before:\r\n\r\n```csharp\r\n    public class MlDataEx\r\n    {\r\n      public string[] A { get; set; }\r\n      public MlDataEx(string a)\r\n      {\r\n        this.A = new[] { a };\r\n      }\r\n    }\r\n\r\n    public static void MlStuff()\r\n    {\r\n      var ctx = new MLContext();\r\n      var dv = ctx.Data.ReadFromEnumerable(new[] { new MlDataEx(""A"") });\r\n      var data = ctx.Transforms.Categorical.OneHotEncoding(""A"").Fit(dv).Transform(dv).Preview();\r\n    }\r\n```\r\n\r\n'"
412893065,2677,b'How to debug ML.NET internals.',"b""Hi,\r\n\r\nthis might be a more general question but I couldn't find anything in the developer-guide.\r\n\r\nIn the past months I've continously seen issues (or at least unintuitive exceptions thrown deep inside ML.NET) that I couldn't figure out.\r\n\r\nComing from a Java background we usually get the Java sources in our Jar and can just step into any code without any effort.\r\nThough, I'm having a really tough time to debug any errors.\r\n\r\n1. How can I step into the ML.NET code? I'm using the myget daily builds.\r\n\r\nCurrently I'm seeing an IndexOutOfRangeException somewhere deep inside the `KeyToVectorMappingTransformer`.\r\n\r\n2. Are there plans to offer a synchronous version of `Fit/Transform()` that avoids the whole threading problems?\r\n\r\nAny guidance on this would be greatly appreciated.\r\n"""
412640826,2671,b'TimeSeries should not be part of TransformsCatalog',b'Currently time series estimators are part of TransformsCatalog but instead they should be in catalog that contains trainers.'
412622853,2670,b'Add code analyzer support for CustomMapping',"b""See the conversation here:\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/2569#discussion_r257425601\r\n\r\nIt is very easy to incorrectly write a custom mapping transformer. We should consider adding a code analyzer that ensures users do it correctly.\r\n\r\nOn the same lines, since we explicitly don't check any of our `Microsoft.ML` assemblies for custom mapping transformers, we should write an internal code analyzer that ensures we don't try to do that in our product."""
412615656,2669,b'Clean up Conversions TryParse code.',"b""Following the feedback [here](https://github.com/dotnet/machinelearning/pull/2611#issuecomment-465228468) and [here](https://github.com/dotnet/machinelearning/pull/2611#discussion_r258144599), we should do the following for the Conversions code:\r\n\r\n* Make `Convert` and `TryParse` consistently named. Either `Convert` and `TryConvert`. Or `Parse` and `TryParse`.\r\n* Clean up the `TryParse` methods so they call `GetValueOrDefault` and don't do unnecessary writes.\r\n\r\n"""
412613469,2668,b'Enable TextFeaturization Test',"b'Test was skipped in v0.10 but does not work in v0.10. \r\n\r\nIt passes on v0.11 preview. \r\n\r\nTest should be enabled. If it runs longer than expected, consider reducing data/sample size but test should not be skipped.\r\n'"
412557173,2663,b'SlotNames for TextLoader are lost',"b'Before refactoring if we had header in file and we read it we filled slot names metadata with values in that header for columns.\r\nThis way we can have mapping between field ""A"" in csv file and slot number 5 in feature vector.\r\n\r\nThis functionality is lost right now.\r\nMostly because we split functionality of schema construction which done without file and reading data from file with already defined schema.\r\nIf I have this header:\r\n`Label A B C D E F G ....`\r\nand this source code:\r\n```\r\n            var reader = mlContext.Data.CreateTextLoader(new Microsoft.ML.Data.TextLoader.Column[] { new Microsoft.ML.Data.TextLoader.Column(""Label"", Microsoft.ML.Data.DataKind.R4, 0), new Microsoft.ML.Data.TextLoader.Column(""Features"", Microsoft.ML.Data.DataKind.R4, 1, 100) },\r\n                hasHeader: true, separatorChar: \' \');\r\n            var data = reader.Read(""data.txt"");\r\n```\r\nI expect Features column to have SlotNames metadata with values `A B C D E F G`, etc.\r\n'"
412551487,2662,"b'Consistent ordering of  (feature, label, groupid, weight) parameters in ML.NET trainer estimators'","b'The public API of ML.NET should have a defined ordering for  \r\n- feature column name\r\n- label column name\r\n- weight column name\r\n- group id column name\r\n\r\nCurrently the trainer estimators in ML.NET  do not have a defined ordering for the above  parameters. We should address this as we finalize the API for V1.0\r\n\r\nHere is a proposal for **consistent** ordering of these parameters for the trainer estimators:\r\n\r\n1. unsupervised trainer estimators (e.g. KMeansPlusPlusTrainer) \r\n   (feature , weight)\r\n\r\n2. supervised trainer estimators: (e.g. LightGbmBinaryTrainer)\r\n   (label,  feature, weight)\r\n\r\n3. ranking trainer estimators: (e.g. LightGbmRankingTrainer)\r\n   (label, feature, groupid, weight)\r\n\r\nRelated to #2177, #2257, #2660\r\n\r\n@Ivanidzo4ka @sfilipi @rogancarr @TomFinley @glebuk \r\n'"
412542449,2660,b'Rename GroupId column to RowGroup ',b'https://github.com/dotnet/machinelearning/blob/4a71e501f09846974e550f817f3f8f1243054c1b/src/Microsoft.ML.LightGBM/LightGbmCatalog.cs#L127\r\n\r\nConversation can be found here:\r\nhttps://github.com/dotnet/machinelearning/issues/2536'
412542306,2659,b'What to do with IFourierDistributionSampler and friends',"b'This interface is related to random Fourier features projection. We may want this functionality as part of our public surface, but the specific API right now is still very command-line and entry-points centric. This should change.\r\n\r\nSomewhat similar in spirit to the problem of loss functions as discussed in #1973, and has many of the same problems, and should probably have a similar resolution to whatever we choose to do with loss functions.'"
412533216,2658,b'Expose gain p-values in new RegressionTree interface',"b'For the new RegressionTree interface introduced with 0.11, can you also include gain p-values, gain, and ""previous leaf value""?'"
412532359,2657,b'Enhance CustomMapping documentation',"b""See discussion https://github.com/dotnet/machinelearning/pull/2569#discussion_r257425931\r\n\r\n> this is definitely something we'll want to document very carefully. It is a bit odd, this pattern of mutable input as a return value. (I of course know exactly why we do it, but a user will not.)\r\n\r\nWe should ensure we explain (in the cookbook, docs.microsoft.com, or otherwise) how this pattern works, and give the reasons why we do it like this.\r\n\r\n/cc @TomFinley """
412530060,2656,"b'Failed in using MultiClassClassification trainers other than StochasticDualCoordinateAscent with error ""System.ArgumentOutOfRangeException: \'Schema mismatch for label column \'\': expected Key<U4>, got R4"" '","b'### Issue\r\nI\'m trying to use other MulticlassClassification trainers but never succeed. The only one succeeded is StochasticDualCoordinateAscent. If i change to LogisticRegression or NaiveBayes, there will always be a error ""System.ArgumentOutOfRangeException: \'Schema mismatch for label column \'\': expected Key<U4>, got R4"". \r\n\r\n`MultiData.cs`\r\n```\r\npublic class MultiData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string DataValue { get; set; }\r\n        [LoadColumn(1)]\r\n        public float Label { get; set; }\r\n    }\r\n```\r\n\r\n`MultiDataPrediction.cs`\r\n```\r\npublic class MultiDataPrediction\r\n    {\r\n        public float[] Score { get; set; }\r\n    }\r\n```\r\n\r\n`BuildTrainEvaluateAndSaveModel() function`\r\n```\r\n            // STEP 1: Common data loading configuration\r\n            IDataView trainingDataView = mlContext.Data.ReadFromTextFile<MultiData>(TrainMultiDataPath1, hasHeader: false);\r\n            IDataView testDataView = mlContext.Data.ReadFromTextFile<MultiData>(TestMultiDataPath, hasHeader: false);\r\n\r\n            // STEP 2: Common data process configuration with pipeline data transformations          \r\n            var dataProcessPipeline = mlContext.Transforms.Text.FeaturizeText(outputColumnName: DefaultColumnNames.Features, inputColumnName: nameof(MultiData.DataValue))\r\n                .Append(mlContext.Transforms.Text.NormalizeText(""NormalizedData"", nameof(MultiData.DataValue)))\r\n                .Append(mlContext.Transforms.Text.TokenizeCharacters(""DataChars"", ""NormalizedData""))\r\n                .Append(new NgramExtractingEstimator(mlContext, ""BagOfTrichar"", ""DataChars"",\r\n                            ngramLength: 3, weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf));\r\n\r\n            // (OPTIONAL) Peek data (such as 2 records) in training DataView after applying the ProcessPipeline\'s transformations into ""Features"" \r\n            //ConsoleHelper.PeekDataViewInConsole<MultiData>(mlContext, trainingDataView, dataProcessPipeline, 2);\r\n            //ConsoleHelper.PeekVectorColumnDataInConsole(mlContext, DefaultColumnNames.Features, trainingDataView, dataProcessPipeline, 1);\r\n\r\n            // STEP 3: Set the training algorithm, then create and config the modelBuilder          \r\n            var trainer = mlContext.MulticlassClassification.Trainers.NaiveBayes(labelColumn: nameof(MultiData.Label), featureColumn: DefaultColumnNames.Features);\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            // STEP 4: Train the model fitting to the DataSet\r\n            Console.WriteLine(""=============== Training the model ==============="");\r\n            ITransformer trainedModel = trainingPipeline.Fit(trainingDataView);\r\n```\r\n\r\nRemark:\r\nEven I change the type of the MultiData.Label to UInt32 will not be working as well.\r\nWith Error, ""System.ArgumentOutOfRangeException: \'Schema mismatch for label column \'\': expected Key<U4>, got U4""\r\n'"
412525468,2655,b'Add AppendCacheCheckpoint large dataset usage warning to documentation',b'https://github.com/dotnet/machinelearning-samples/blob/bfcd66167bb4518afb538661a97ad98c27685349/samples/csharp/getting-started/MulticlassClassification_Iris/IrisClassification/IrisClassificationConsoleApp/Program.cs#L50 has a warning: \n// Use in-memory cache for small/medium datasets to lower training time. \n// Do NOT use it (remove .AppendCacheCheckpoint()) when handling very large datasets. \n\nThis should be added to the documentation. \n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 2a03f5f8-1ce2-ae98-0f03-3a0cdfd2a208\n* Version Independent ID: 58d012b4-4275-8c95-1634-08f7f66cbafb\n* Content: [EstimatorChain&lt;TLastTransformer&gt;.AppendCacheCheckpoint(IHostEnvironment) Method (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.estimatorchain-1.appendcachecheckpoint?view=ml-dotnet#Microsoft_ML_Data_EstimatorChain_1_AppendCacheCheckpoint_Microsoft_ML_IHostEnvironment_)\n* Content Source: [dotnet/xml/Microsoft.ML.Data/EstimatorChain`1.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/EstimatorChain`1.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
412415875,2654,b'Predicting an enum value is getting harder then expected',"b'### System information\r\n\r\n- **Windows 10 64 bit**:\r\n- **ml.net 0.10.0**: \r\n[Model.zip](https://github.com/dotnet/machinelearning/files/2884674/Model.zip)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrained a model from a text file that contains a integer for the values of an enum. The model contains a property named Label with a data type of uint \r\n\r\n- **What happened?**\r\nGot an error message generating prediction engine from model after it trained, the error:\r\nCould not apply a map over type \'U4\' to column \'Label\' since it has type \'Key<U4, 0-37>\'\r\n\r\n   at Microsoft.ML.Transforms.Conversions.ValueToKeyMappingTransformer.Bind(IHostEnvironment env, Schema schema, TermMap unbound, ColInfo[] infos, Boolean[] textMetadata, Int32 iinfo)\r\n   at Microsoft.ML.Transforms.Conversions.ValueToKeyMappingTransformer.Mapper..ctor(ValueToKeyMappingTransformer parent, Schema inputSchema)\r\n   at Microsoft.ML.Transforms.Conversions.ValueToKeyMappingTransformer.MakeRowMapper(Schema schema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.PredictionEngineExtensions.CreatePredictionEngine[TSrc,TDst](ITransformer transformer, IHostEnvironment env, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n- **What did you expect?**\r\nI would expect this to work. \r\n\r\n\r\n### Source code / logs\r\n```\r\nvar dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: DefaultColumnNames.Label, inputColumnName:nameof(MSBar2.Label))                                            \r\n                            .Append(mlContext.Transforms.Concatenate(DefaultColumnNames.Features, MSBar2.GetColumnNames(DataKind.R4)))\r\n                            ;\r\nvar trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(DefaultColumnNames.Label,DefaultColumnNames.Features);\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer)\r\n                                          .Append(mlContext.Transforms.Conversion.MapKeyToValue(DefaultColumnNames.PredictedLabel));\r\nvar model = trainingPipeline.Fit(trainingDataView);\r\nvar engine= model.CreatePredictionEngine<MSBar2, TrendPrediction>(mlContext);\r\n```\r\nThe class TrendPrediction looks like this:\r\n```\r\npublic class TrendPrediction\r\n{\r\n        /// <summary>\r\n        /// Initializes a new instance of the <see cref=""TrendPrediction""/> class.\r\n        /// </summary>\r\n        public TrendPrediction()\r\n        {\r\n        }\r\n\r\n        /// <summary>\r\n        /// The predicted labels\r\n        /// </summary>\r\n        [ColumnName(""PredictedLabel"")]\r\n        public uint PredictedLabels;\r\n\r\n        /// <summary>\r\n        /// The scores\r\n        /// </summary>\r\n        [ColumnName(""Score"")]\r\n        public float[] Scores;\r\n}\r\n```\r\nI have decorated my Label property like this:\r\n```\r\n[ColumnName(""Label""), LoadColumn(0) , Column(""0"", ""Label""),KeyType(Count =38)]\r\npublic uint Label;\r\n```\r\n\r\n[Model.zip](https://github.com/dotnet/machinelearning/files/2884678/Model.zip)\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
412316489,2653,b'samples look to be repetitive',"b'Hi,\n\nI think that a Copy & Past issue duplicated the samples\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: b7238dac-834a-09ec-15e2-aa35ced93ffd\n* Version Independent ID: f7a23c72-3335-a0dc-2858-dbb88defa132\n* Content: [ConversionsExtensionsCatalog.ValueMap Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.valuemap?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/ConversionsExtensionsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ConversionsExtensionsCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
412285718,2652,b'LightGbm ranking with Options does not set GroupId column even when specified in Options',"b'During the course of Fixing #2530 in PR #2650, I discovered that when creating a `LightGbmRankingTrainer` with `MLContext.Ranking.Trainers.LightGbm(Options options)`, the GroupId column is never set even though it is specified in the `Options`.\r\n\r\nDigging a bit deeper, I found that in [LightGbmTrainerBase.cs](https://github.com/dotnet/machinelearning/blob/4a71e501f09846974e550f817f3f8f1243054c1b/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs#L91-L92) we have\r\n```csharp\r\n        private protected LightGbmTrainerBase(IHostEnvironment env, string name, Options options, SchemaShape.Column label)\r\n           : base(Contracts.CheckRef(env, nameof(env)).Register(name), TrainerUtils.MakeR4VecFeature(options.FeatureColumn), label, TrainerUtils.MakeR4ScalarWeightColumn(options.WeightColumn))\r\n```\r\n\r\nThis does not use options.GroupIdColumn to create a `SchemaShape.Column` for GroupId to pass to the base constructor `TrainerEstimatorBaseWithGroupId`. Neither is there a method in `TrainerUtils` to create such a `SchemaShape.Column` object from options.GroupIdColumn for Key types such as GroupId.\r\n\r\nRepro:\r\nRun the sample in `Microsoft.ML.Samples.Dynamic.LightGbmRankingWithOptions.Example()`.\r\n\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Need a group column.\r\nParameter name: data\r\n   at Microsoft.ML.Contracts.CheckParam(IExceptionContext ctx, Boolean f, String paramName, String msg) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 543\r\n   at Microsoft.ML.LightGBM.LightGbmRankingTrainer.CheckDataValid(IChannel ch, RoleMappedData data) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.LightGBM\\LightGbmRankingTrainer.cs:line 127\r\n   at Microsoft.ML.LightGBM.LightGbmTrainerBase`3.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 313\r\n   at Microsoft.ML.LightGBM.LightGbmTrainerBase`3.TrainModelCore(TrainContext context) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 113\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 148\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2.Fit(IDataView input) in C:\\najeeb-kazmi\\machinelearning\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 75\r\n   at Microsoft.ML.Samples.Dynamic.LightGbmRankingWithOptions.Example() in C:\\najeeb-kazmi\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Dynamic\\Trainers\\Ranking\\LightGBMRankingWithOptions.cs:line 31\r\n   at Microsoft.ML.Samples.Program.Main(String[] args) in C:\\najeeb-kazmi\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Program.cs:line 9\r\n\r\ncc: @abgoswam @zeahmed @TomFinley @eerhardt '"
412193587,2645,b'Cannot produce a Precision-Recall Curve from our Binary Classification Evaluator',"b""In the Supported Scenarios for V1 (see #2498) we want to be able to easily plot a PR curve from output of the evaluator.\r\n\r\nThis is not currently possible in the current set of APIs*. As detailed in #2465, we cannot set a threshold on a binary classification prediction, so we cannot loop over the various thresholds. Furthermore, the Evaluator, while it has enough information to return lists of precisions and recalls at the various cutoffs, does not have an avenue to return this information.\r\n\r\n\r\n\\* Well, actually this is possible using custom mappers like so:\r\n1. Get a list of all unique probability scores\r\n  (e.g. by reading the IDataView as an enumerable and creating a dictionary of observed values)\r\n2. For each unique value of the probability:\r\n  a. Write a custom mapper to produce PredictedLabel at that probability threshold.\r\n  b. Calculate Precision and Recall with these labels.\r\n\r\nHowever, it doesn't seem like this workaround qualifies as satisfying the V1 Scenario &mdash; it's a more advanced use of the APIs, and it requires an individual to understand the ins-and-outs of calculating PR curves"""
412186672,2644,b'AnomalyDetection Evaluator returns NaNs',"b""The `Evaluator` for `AnomalyDetection` returns NaNs for all metrics under some conditions.\r\n\r\nThe individual metrics shouldn't be returned as a NaN. If something is wrong with the input data, the evaluator should throw an error instead.\r\n\r\nReproduction: Use the MNIST One Class dataset from `tests/data/`, train with default RandomizedPCA parameters, then evaluate the predictions on the training dataset. Observe that the metrics come back as NaN.\r\n```cs\r\nvar data = mlContext.Data.ReadFromTextFile<MnistOneClass>(GetDataPath(TestDatasets.mnistOneClass.trainFilename),\r\n    hasHeader: TestDatasets.mnistOneClass.fileHasHeader,\r\n    separatorChar: TestDatasets.mnistOneClass.fileSeparator);\r\n\r\n// Create a training pipeline.\r\nvar pipeline = mlContext.AnomalyDetection.Trainers.RandomizedPca();\r\n\r\n// Train the model.\r\nvar model = pipeline.Fit(data);\r\n\r\n// Evaulate the model.\r\nvar scoredData = model.Transform(data);\r\nvar preview = scoredData.Preview();\r\nvar metrics = mlContext.AnomalyDetection.Evaluate(scoredData);\r\n```"""
412171735,2642,b'ReadFromTextFile cannot load data as KeyType',"b""`CreateTextLoader` can read in data as KeyTypes, but `ReadFromTextFile` cannot.\r\n\r\n`CreateTextLoader` works like this:\r\n```cs\r\nnew TextLoader.Column(matrixColumnIndexColumnName, DataKind.U4, new [] { new TextLoader.Range(1) }, new KeyCount(20)),\r\n```\r\n\r\nNow, there is a `KeyType(Count = 20)` attributes that you can put on a class property, but this only seems to be used by scoring. I'd like to be able to use that, or something like that, to read in data directly as KeyType."""
412163473,2640,b'Microsoft.ML.Model cleanup and internalization',"b""Inside the core assembly is a namespace named `Microsoft.ML.Model`, dealing with the mechanisms by which we load and save models through ML.NET. This code is infrastructure, and while essential, needn't necessarily be exposed outside of ML.NET yet. This is well, because while we have no time to change it, there is some idiosyncratic behavior we may want to \r\n\r\nThe most difficult part of this will be `ICanSaveModel`. It *must* be public, pursuant to discussion in #2336, which means that the class `ModelSaveContext` must itself be public. But it needn't necessarily follow that the *members* of `ModelSaveContext` be public. (This is similar to how `IHostEnvironment` must be public, and so `ComponentCatalog` must be public too, but almost nothing about the class itself is exposed.) Much of the remaining types can merely be directly internalized, e.g., repositories, version info, etc.\r\n\r\nThis deals with API public surface area in a core assembly so much be completed prior to v1."""
412163022,2639,b'TrainerUtils.CreatePredicate fails on .NET 4.6.2 (.NET 0.10.0)',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\nTrainerUtils.CreatePredicate appears to use an extension method of IEnumerable that does not exist for .NET 4.6.2:\r\n\r\n  https://github.com/dotnet/machinelearning/blob/13b33392dd3fbffc0922b2af72c8236b74c95fc0/src/Microsoft.ML.Data/Training/TrainerUtils.cs#L235\r\n\r\nThis is probably the same issue that causes #2566.\r\n'"
412156877,2637,b'Add a note that NDCG returns values between 0 and 100',"b""NDCG, the normalized discounted cumulative gain metric that we often use in ranking, ranges in value between 0 and 100 in ML.NET. In the wide world, NDCG is often considered to be between 0 and 1 (e.g. see [Wikipedia](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG)). We should add a note to the ranking metrics object that the values range between 0 and 100 so that we don't confuse people who are new to the toolkit."""
412151937,2634,b'Ranking / Ranker API inconsistency',"b'In the API, we have references to ""Ranking"" and ""Ranker"". One (of many) examples is that `mlContext.Ranking.Evaluate` returns a `RankerMetrics` object. This leads to an inconsistency across the API surface. '"
412150643,2633,"b""Ranking evaluator doesn't have defaults for Label and GroupId""","b'The `Evaluate()` method for `Ranking` takes a `label` and `groupId` as input, but unlike other `Evaluators` and the ranking trainers, it does not have default values, so these must always be specified. This leads to an inconsistent feeling across the API surface.'"
412132752,2631,b'Internalization of OneToOne and ManyToOne Column classes',b'https://github.com/dotnet/machinelearning/blob/25404b83df1b6bf9f548ee59396a87e43f0f9058/src/Microsoft.ML.Data/Transforms/ColumnBindingsBase.cs#L17\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/25404b83df1b6bf9f548ee59396a87e43f0f9058/src/Microsoft.ML.Data/Transforms/ColumnBindingsBase.cs#L106\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/25404b83df1b6bf9f548ee59396a87e43f0f9058/src/Microsoft.ML.Data/Transforms/ColumnBindingsBase.cs#L112\r\n\r\nShould be hidden'
412131249,2629,b'ITrainerEstimator lack of documenation',"b""https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Training/ITrainerEstimator.cs\r\nWould be nice to have documentation for interface and it's property."""
412127282,2628,b'Mismatch in Label expectations for Multiclass Learners',"b'When training a multiclass classifier, the label must be converted to `KeyType`. Some learners, such as `SDCA`, do the conversion from `R4` automatically, while some, like `LogisticRegression` do not. This behavior   is confusing from an end-user perspective, as one cannot simply interchange learners without modifying the input pipeline.\r\n\r\nI suggest adding auto-label-conversion for all multiclass learners in ML.NET.'"
412126690,2627,b'QuantileRegression evaluator exposure',"b""We have following peace of code:\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Evaluators/QuantileRegressionEvaluator.cs\r\n\r\nIt looks like specific type of evaluation for regression task, but we don't expose it at all.\r\nShall we do it for v1.0?\r\n@TomFinley  @rogancarr \r\n"""
412124696,2626,b'Internalize Microsoft.ML.Data Evaluators folder',b'https://github.com/dotnet/machinelearning/blob/25404b83df1b6bf9f548ee59396a87e43f0f9058/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L1337\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/25404b83df1b6bf9f548ee59396a87e43f0f9058/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L1760\r\n\r\nLooks like good candidates for interanalization'
412122942,2624,b'Cleaning up metric classes',"b'We need to clean our metrics classes:\r\n\r\nAll classes are sealed.\r\nAll constructors are internal.\r\nEverything has proper documentation. Including class itself.\r\nNo short names (Dbi is awful name, DCG not great as well, L1, L2, Rms, etc)\r\n\r\nList of metrics:\r\n`AnomalyDetectionMetrics`\r\n`BinaryClassificationMetrics`\r\n`CalibratedBinaryClassificationMetrics`\r\n`ClusteringMetrics`\r\n`MultiClassClassifierMetrics`\r\n`RankerMetrics`\r\n`RegressionMetrics`\r\n\r\n\r\n'"
412122840,2623,b'Multiclass in API has many names',"b'When we refer to multiclass in the API, it has many names: `MulticlassClassification`, `MultiClassClassifierMetrics` are just two examples. For the V1 API, does it make sense to stick to one naming scheme?'"
412115527,2622,b'Metadata/annotations public surface of the API',"b'Metadata (FYI to be later named annotations per #2297) is an essential mechanism for attaching optional information about columns. This ranges from publicly facing stuff that user\'s should be aware of (slot names, which we use for feature names on feature columns, and key values), versus a bunch of stuff that is arguably useful for users but primarily for our internal infrastructure (e.g., whether something has already been normalized), versus stuff intended purely for our internal infrastructure.\r\n\r\nWe ought to decide what we really want to be part of our initial public surface (as small as possible but no smaller), and internalize the rest of it.\r\n\r\nSo, we will keep as is `Metadata` (to be `Annotations`):\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a56caeebaaa0076d6940bfdede90a4eb0a351a20/src/Microsoft.Data.DataView/DataViewSchema.cs#L172\r\n\r\nThis by itself is little more than an arbitrary string/object store, which is as intended. So that will not change. What will change however is the class we\'ve made to make access a little more structured.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a56caeebaaa0076d6940bfdede90a4eb0a351a20/src/Microsoft.ML.Core/Data/MetadataUtils.cs#L17\r\n\r\nThis has stuff that is ""good"" in that we want to keep it as part of the public surface, but also stuff that is internal and should not be part of the public surface.\r\n\r\n## The good\r\n\r\nA small amount of this stuff we probably want to keep.\r\n\r\nHowever we should probably move it somewhere else... perhaps, the static class `SchemaColumnAnnotationsExtensions` as a series of extension methods on top of `DataViewSchema.Column` to access the associated metadata.\r\n\r\nThis might include things like these methods.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a56caeebaaa0076d6940bfdede90a4eb0a351a20/src/Microsoft.ML.Core/Data/MetadataUtils.cs#L297\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a56caeebaaa0076d6940bfdede90a4eb0a351a20/src/Microsoft.ML.Core/Data/MetadataUtils.cs#L321\r\n\r\n## The bad\r\n\r\nMuch of this class though should be internal.\r\n\r\nSo for example, we have this static class of `Kinds` of metadata. Absolutely\r\nquite nice a thing to have for our own infrastructure for consistency, but this is not what we want to show users. Similar with this sort of labels for types of scorings, which is a scenario irrelevant to the ML.NET API as defined (since people evaluate scores by saying, ""here, evaluate these scores"" explicitly by calling some code). Also stuff on the ranges of categorical variables which, while essential, are mostly for the benefit of trainers downstream consuming data. (User\'s that want the raw categoricals can, by just programming, consume the source data themselves, since they control the pipeline.)\r\n\r\nThere\'s also a lot of stuff built around *implementing* metadata, which is of questionable worth at this time given the changes that have happened to schema in the past year, and which is of no use whatever.\r\n\r\n/cc @Ivanidzo4ka , @eerhardt , @rogancarr , @sfilipi '"
412105415,2621,b'Create functional tests for all V1 Evaluation scenarios',"b'As laid out in #2498 , we need scenarios to cover the Evaluation functionality we want fully supported in V1.\r\n\r\n* I can evaluate a model trained for any of my tasks on test data. The evaluation outputs metrics that are relevant to the task (e.g. AUC, accuracy, P/R, and F1 for binary classification)\r\n* I can get the data that will allow me to plot PR curves'"
412090646,2620,b'Scrubbing rest of learners',b'Sub task of #2613\r\n`FieldAwareFactorizationMachineTrainer`\r\n`MatrixFactorizationTrainer`\r\n`PriorTrainer`\r\n`RandomTrainer`\r\n`SymSgdClassificationTrainer`\r\n`KMeansPlusPlusTrainer`\r\n`MultiClassNaiveBayesTrainer`\r\n`OlsLinearRegressionTrainer`\r\nand their base classes'
412089481,2619,b'Scrubbing Meta learners',b'Sub task of #2613\r\n`Ova`\r\n`Pkpd`\r\nand their base classes'
412089060,2618,b'Scrubbing LightGBM learnears',b'Sub task of #2613\r\n`LightGbmBinaryTrainer`\r\n`LightGbmMulticlassTrainer`\r\n`LightGbmRankingTrainer`\r\n`LightGbmRegressorTrainer`\r\nand their base classes'
412088324,2617,b'Scrubbing FastTree learners',"b""Sub task of #2613\r\n`FastTreeBinaryClassificationTrainer`\r\n`FastTreeRankingTrainer`\r\n`FastTreeRegressionTrainer`\r\n`FastTreeTweedieTrainer`\r\n`BinaryClassificationGamTrainer`\r\n`RegressionGamTrainer`\r\n`FastForestClassification`\r\n`FastForestRegression`\r\n\r\nand their base classes.\r\nAlso note how everywhere in code we call AlgoTypeOfTask for our trainers and in GAM it's opposite.\r\n\r\n\r\nand their base classes"""
412086748,2616,b'Scrubbing SDCA learners',b'Sub task of #2613\r\n`SgdNonCalibratedBinaryTrainer`\r\n`SgdBinaryTrainer`\r\n`SdcaBinaryTrainer`\r\n`SdcaNonCalibratedBinaryTrainer`\r\n`SdcaRegressionTrainer`\r\n`SdcaMultiClassTrainer`\r\nand their base classes'
412085241,2615,b'Scrubbing LogisticRegression learners',b'Subtask for #2613 \r\n`LogisticRegression`\r\n`MulticlassLogisticRegression`\r\n`PoissonRegression`\r\nand their base classes'
412084113,2614,b'Scrubbing OnlineLinear learners.',b'Sub task of https://github.com/dotnet/machinelearning/issues/2613\r\n`AveragePerceptron`\r\n`LinearSVM`\r\n`OnlineGradientDescentTrainer`\r\nand their base classes'
412078855,2613,b'Scrubbing learners (Meta issue)',"b'We need to clean our API for learners.\r\nThis includes following things:\r\n\r\n1. No protected fields/members/method in public classes. Only private protected.\r\n\r\n2. Learner class is sealed.\r\n\r\n3. The trainer name types should follow the names used in the contexts (see https://github.com/dotnet/machinelearning/issues/2172)\r\n\r\n4. ModelPameters for this Learner is also clean. (sealed, public documentation, no public constructor)\r\n\r\n5. Options cleaning:\r\n- They should be named Options, and all their base classes (except `LearnerInputBase*`)\r\n- Option should have meaning and proper way it initialize it self. We shouldn\'t accept int if in reality we use enum (https://github.com/dotnet/machinelearning/issues/2521) or accept array of ints as a string separated by comma `public string CustomGains = ""0,3,7,15,31"";`\r\n- No short names.\r\n- Standard names like:\r\n`/// <param   name=""labelColumnName"">The name of the label   column.</param>`\r\n`/// <param   name=""featureColumnName"">The name of the feature   column.</param>`\r\n`NumberOfIterations`, `NumberOfThreads`, `LearningRate`,`L2Regularization`, `L1Regularization`\r\nno (`MaxIterations`,`NumIterations`, `NumThreads`, `L2Weight`, `L1Weight`)\r\n\r\n6. If we communicate with user (exceptions, channel messages), don\'t use DataKind values. No R4, U4, and so on, it should be float, uint, etc.\r\n\r\nignore for now:\r\n\r\n1. Everything public has proper documentation.\r\n\r\n7. We have samples of how use base call to trainer (no options) and call with options.\r\n\r\n8. We have baseline tests for learner.\r\n\r\n\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions#using-abbreviations-and-acronyms\r\n\r\n\r\n\r\n\r\n\r\n`'"
412047919,2612,b'Nullable .Value investigate and replace with .GetValueOrDefault()',"b""In #2579, it was revealed that full nullable values, *if you *know* that the nullable has a value at a certain point* that calling `GetValueOrDefault()` is faster than `.Value`, despite having equivalent code, since an unnecesssary check is avoided. While obvious in retrospect given the reasoning, that is not what most of our existing code is doing.\r\n\r\nGiven that insight, in principle we should not be using `.Value` in any case since if at a certain point we expect that a nullable value should not be null (because we checked, or because we require it to be non-null for some other reason), we would not consider the exception thorn by the .NET framework out of `.Value` to be sufficiently descriptive and helpful *anyway*. So the hardest part of this would actually be checking that everywhere we use `.Value` that we do have the appropriate checks in place, since otherwise it should be a relatively straightforward replacement.\r\n\r\nWhile I don't expect a measurable perf impact, since I don't think we use nullables in tight loops too often if anywhere, it certainly wouldn't hurt and would help to maintain best practices.\r\n\r\nNot critical work for v1, since it deals with internal code.\r\n\r\n/cc @stephentoub """
411752675,2610,b'Investigate lightweight blocking collection replacement',"b'We use threading in multiple places, and use `System.Collection.Concurrent` blocking collections, in particular queues, to have ""ordered"" work among gangs of worker threads. When debugging this specific .NET structure has a high cost, given our usage pattern. PR #2595 introduces a new mechanism to use in place of a blocking queue. This shows substantial speedups during debugging during our usage of it.\r\n\r\nThat\'s great for that PR, but that was focused on the text loader specifically, since that shows up in our initial examples. It may be that the debugging experience is problematic elsewhere in situations that are important but not written for our documentation writer. Perhaps we can apply the same innovation to other scenarios. (It may be as simple as a simple drop and replace, in which case 90% of the work would be writing appropriate benchmarks.)\r\n\r\nTargeted scenarios that may benefit include the splitter/consolidator logic for concurrent featurization pipelines, cache data view, and the binary loader, since their internal workflow follows this pattern of gangs of thread workers producing/consuming ordered batches of data.\r\n\r\nProbably something to think about post v1.'"
411723434,2609,b'Do something to ComponentCreation.ReadFromEnumerable',"b""There's this little ReadFromEnumerable method inside ComponentCreation that is the only remaining public method. While the method is useful, it doesn't really seem like it belongs there, but rather as perhaps either some method directly on the data catalog, or somewhere more appropriately named.\r\n\r\nOnce that is moved somewhere else the class itself can be made best-friend-internal, all methods inside made public.\r\n\r\nBased on a comment from @Ivanidzo4ka in #2605."""
411700547,2606,b'Internalization of Microsoft.ML.Data Dataview folder',"b""https://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/AppendRowsDataView.cs#L30\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/CompositeRowToRowMapper.cs#L14\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/DataViewConstructionUtils.cs#L727\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/DataViewConstructionUtils.cs#L755\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/EmptyDataView.cs#L15\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/OpaqueDataView.cs#L15\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/ZipDataView.cs#L17\r\n\r\nneed to be moved to somewhere else (We probably already have schema utils):\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/SimpleRow.cs#L73\r\n\r\nI don't see any usages, need to check is it still relevant:\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/LambdaFilter.cs#L19 \r\n\r\n\r\nnot sure about this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/ArrayDataViewBuilder.cs#L17\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/TypedCursor.cs#L35\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/DataView/TypedCursor.cs#L45\r\n"""
411697989,2604,b'Internalization of Microsoft.ML.Data Data folder.',b'https://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/Data/Combiner.cs#L13\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/Data/BufferBuilder.cs#L17\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/Data/DataViewUtils.cs#L19\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/Data/RowCursorUtils.cs#L16\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Data/Data/SchemaDefinition.cs#L102\r\n\r\nAll of them looks like great candidates for internalization.'
411692420,2603,b'Hide some parts of TrainerInfo',"b""There is this structure `TrainerInfo` which was previously used on `ITrainer`. It is returned however not only by this old (internal) interface, but also by the newer `ITrainerEstimator`. It is still useful in this capacity, but a few things on it should be hidden.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b881fdc2eab55e184eb0856d4c10c732a58e0887/src/Microsoft.ML.Core/Prediction/TrainerInfo.cs#L11\r\n\r\nThis is probably still a good idea to return from `ITrainerEstimator`, but in a restricted form. We'd internalize some of these things though, as they are either inapplicable for one reason or another: `NeedCalibration`, whether a trainer estimator returns a calibrated model or not is obvious from the return type and intellisense. The `Supports*` properties are intended per #509 to indicate which fields of `TrainContext` will be supported in a call to `Train`, which is totally irrelevant w.r.t. trainer estimators."""
411617454,2599,b'Lockdown TrainerEstimatorBase class',b'The below methods are protected but can be made private protected and hence we can reduce the public API surface area across the trainers.\r\n\r\n1. MakeTransformer\r\n2. CheckLabelCompatible\r\n3. GetOutputColumnsCore\r\n4. TrainTransformer'
411450029,2598,b'How to use the sample project \xe2\x80\x9cMicrosoft.ML.samples\xe2\x80\x9d code for predicting from sql server db as input?',b'I have tried to understand Microsoft.ML.samples code. \r\nSo how can I use this sample for predicting the output from giving input from one of my SQL server databases?\r\n\r\n### Ex: \r\n    var enumerableOfData = SamplesUtils.DatasetUtils.GetSampleTemperatureData(10);\r\n    var data = mlContext.Data.ReadFromEnumerable(enumerableOfData);\r\n\r\n- **we want to use MSSQL for getting record to fill \xe2\x80\x9cData\xe2\x80\x9d. So how can i use MSSQL?**\r\n- **which method or which assembly do I need to refer to fulfill my requirement?**\r\n'
411447090,2597,b'PermutationFeatureImportance on Categorical Features dataset ',"b'@caesar1995 @rogancarr @asthana86 \r\n\r\nI need an example how to use PermutationFeatureImportance on Categorical Feature dataset with MulticlassClassification.  I need to understand the output score of each categorical feature columns  to understand most important columns for a label column using PermutationFeatureImportance.  Can you please provide me one, i am struggling to make it work. '"
411423339,2596,b'Missing DLL tensorflow.dll when targeting .NET 472',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: .NET 472\r\n\r\n### Issue\r\n\r\n- **What did you do?** Added Microsoft.ML.TensorFlow nuget package to .NET 472 project\r\n- **What happened?** Nuget package was added but the tensorflow.dll was missing in the bin folder and tests would fail with the missing dll exception. Unit tests are passing when targeting .netcoreapp 2.0.\r\n- **What did you expect?** The tensorflow.dll to be found when targeting .net 472\r\n\r\n### Source code / logs\r\n\r\n`<Project Sdk=""Microsoft.NET.Sdk"">\r\n\r\n    <PropertyGroup>\r\n        <TargetFramework>net472</TargetFramework>\r\n    </PropertyGroup>\r\n\r\n    <ItemGroup>\r\n      <EmbeddedResource Include=""model\\saved_model.pb"">\r\n        <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\r\n      </EmbeddedResource>\r\n    </ItemGroup>\r\n\r\n    <ItemGroup>\r\n      <ProjectReference Include=""..\\Project.Core\\Project.Core.fsproj"" />\r\n    </ItemGroup>\r\n\r\n    <ItemGroup>\r\n      <PackageReference Include=""Microsoft.ML.TensorFlow"" Version=""0.10.0"" />\r\n    </ItemGroup>\r\n\r\n</Project>\r\n`\r\n\r\nComment: dll is still missing even when explicitly adding the nuget package Microsft.ML.TensorFlow.Redist.'"
411278686,2594,b'user defined loss function',b'How to declare/use user defined loss function in RegressionMetrics ? RegressionMetrics.LossFn is read only. \r\n\r\n---\r\n#### Document Details\r\n\r\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\r\n\r\n* ID: 8dd659ba-d3ca-b421-9b98-0ef4696eea68\r\n* Version Independent ID: 54bb95b7-ec27-4880-c464-7c1f5c292e7f\r\n* Content: [RegressionMetrics Class (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.regressionmetrics?view=ml-dotnet#applies-to)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/RegressionMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/RegressionMetrics.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**'
411230171,2593,"b'Docs: LoadColumn attribute mentions the column name, but no means to provide it'","b'The [LoadColumnAttribute](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.loadcolumnattribute?view=ml-dotnet) class description claims:\r\nhttps://github.com/dotnet/machinelearning/blob/cf7e3d992b4b770a7345174673107c47e8bf4d13/src/Microsoft.ML.Data/DataLoadSave/Text/LoadColumnAttribute.cs#L10-L15\r\n\r\nHowever, there are no means to provide the name of a column. Available three constructors only allow to specify the source indices.\r\n\r\nThat looks to be a copy-paste error from the [ColumnAttribute](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.columnattribute?view=ml-dotnet) documentation.\r\n\r\nAs I see from the usage of the `LoadColumn` attribute:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cf7e3d992b4b770a7345174673107c47e8bf4d13/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1336-L1345\r\n\r\nthe `LoadColumn` attribute is used to define only the source indices of a column, while the name is defined either by the `ColumnName` attribute or the property name.'"
411040624,2592,b'PredictionKind in TrainerEstimatorBase should be internalized',"b""I don't see any reason to expose it publicly especially since all our trainers coupled with specific catalog."""
411015117,2591,b'Documentation: ML.NET Algo Cheat Sheet/Bot',"b'### System information\r\n\r\nAll\r\n\r\n### Issue\r\n\r\nDocumentation Suggestion.\r\n\r\nCreate an algorithm cheat sheet along the lines of https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet for ML.NET. Add options each time an AI library is added/changes.\r\n\r\nA chart is nice/easy but a) too small for all the possibilities in all libraries?, b) hard to update.\r\n\r\nHow about an algo-picker bot? Some better/easier idea? I guess a chart with really really small writing might work for V1.0.\r\n\r\nThe point is: ""If you build it, they won\'t necessarily come - unless you make it stoopidly easy for them to get there"".\r\n\r\n### Source code / logs\r\n\r\nN/A\r\n'"
411013136,2590,b'Microsoft.ML.Internal.Internallearn namespace requires certain internalization',b'At least\r\n`public sealed class SlotDropper` should become internal.\r\n`public static class PredictionUtil` should become internal\r\n`public static class TypeUtils`\r\nalso all public delegates in this namespace can be made internal.'
411010883,2589,"b""Calibrators shouldn't have public constructors""",b'We closed our ModelParameters constructors. We should do same thing with calibrators.\r\nhttps://github.com/dotnet/machinelearning/blob/1f90f50f813ecd152e46e92deb4a7827c7f24e31/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1745'
410995976,2588,b'Some Roslyn analyzer tests have unexpected compilation errors',"b'In #2562, @sharwell updates the code analyzer tests to utilize some existing convenience classes. This is great, but it also reveals an issue with the existing tests that should be fixed.\r\n\r\nThe old mechanism that was based on the VS Roslyn templates was restrictive in the diagnostics it ""listened"" to and reported. But this went even so far as not even reporting actual compilation errors, and some of the test sources have compilation errors of one form or another (missing declarations mostly, it seems like, based on files from `src` that were included in compilation, seems to be a common theme).\r\n\r\nFor these, it was not intended that there be compilation errors in the code compiled for testing the Roslyn analyzers, so that should be addressed and fixed. (Possibly be inserting dummy declarations into the test input to get it to compile, or some other mechanism.)\r\n\r\nSee the above PR #2562, for those changes where actual compilation errors are now listed among ""expected"" errors. The goal of this issue would be to get it so that those new ""additions"" are no longer necessary.\r\n\r\nThis FYI is *not* API critical work for v1.'"
410994570,2587,b'IHost should become internal',b'towards #1602 '
410994297,2586,b'IProgressChannelProvider should become internal',b'towards #1602 '
410994166,2585,b'IChannelProvider should become internal',b'towards #1602'
410980618,2583,"b""DataKind shouldn't be present in our public API.""",b'We need to replace places like this \r\nhttps://github.com/dotnet/machinelearning/blob/13b33392dd3fbffc0922b2af72c8236b74c95fc0/src/Microsoft.ML.Data/Transforms/TypeConverting.cs#L542\r\nhttps://github.com/dotnet/machinelearning/blob/832ecad57808bbe79f36dc6886882781fb5bd399/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L45\r\nto proper .net type support.'
410977775,2582,b'Mark EntryPoints classes and APIs as internal',"b""We have a few classes in `Microsoft.ML.Core` that are public, but they shouldn't be.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/13b33392dd3fbffc0922b2af72c8236b74c95fc0/src/Microsoft.ML.Core/EntryPoints/TransformModel.cs#L14\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/13b33392dd3fbffc0922b2af72c8236b74c95fc0/src/Microsoft.ML.Core/EntryPoints/PredictorModel.cs#L14\r\n\r\nBasically, anything under the `Microsoft.ML.EntryPoints` namespace should be internal.\r\n\r\nThis is OK, because anything that uses EntryPoints already has `InternalsVisibleTo`.\r\n\r\n@TomFinley @glebuk @ganik @shauheen """
410976758,2581,b'Remove value tuples from TransformsCatalog methods',"b'Many of the methods in TransformsCatalog create estimators using a params array of (string outputColumnName, string inputColumnName). As mentioned in #2501, we should change all these to not use value tuples.\r\n'"
410957474,2576,"b'ReadFromTextLoader(..., supportsSparse, ...) defaults to true?'","b'ReadFromTextFile has a `supportsSparse = true` argument.  It seems like this should actually default to false?  Otherwise it tries to interpret all of the input as if it may contain sparse data and fails in the parsing on every line, unless there actually is sparse data.'"
410938671,2575,b'Add message in Visual Studio Template letting user know saving is complete.',"b'When running the ML.NET Console Application Visual Studio Template, the last message output to the console is ""Saving the model"". Although saving is done, the user may be confused and think that saving is still happening. Adding an extra console output message indicating saving is complete may help inform the user the model has been successfully saved and the application is done running.\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/52883521-427e9680-3139-11e9-9304-30fe8a961607.png)\r\n'"
410919698,2573,b'Create functional tests for all V1 Explainability scenarios',"b'As laid out in #2498 , we need scenarios to cover the TensorFlow functionality we want fully supported in V1.\r\n\r\n* I can get near-free (local) feature importance for scored examples (Feature Contributions)\r\n* I can view the overall importance of each feature (Permutation Feature Importance, GetFeatureWeights)\r\n* I can train interpretable models (linear model, GAM)\r\n* I can view how much each feature contributed to each prediction for trees and linear models (Feature Contributions)\t\xc2\xa0\t\xc2\xa0\t\xc2\xa0'"
410914923,2572,"b""TensorFlowUtils doesn't really fit with the 1.0 API""","b'One of the scenarios we want to support in ML.NET 1.0 is the ability to examine the schema of a TensorFlow model (see example below [1]). To do this, we currently use helper methods in the `TensorFlowUtils` class [2].\r\n\r\nRight now, this class and these methods are `public` and can be used as part of an ML.NET program, but that doesn\'t seem like the way we want to go in v1.0. What do you all think? Does it make sense to add these methods to mlContext and make them internal/BestFriend? If we add them to a catalog, where should they go?\r\n\r\n[1] Example of why you would want to examine the schema before loading. Here, we want to get the layer names and their sizes before specifying them as outputs in our `IDataView`:\r\n```cs\r\n// Get the output size of a layer\r\nvar schema = TensorFlowUtils.GetModelSchema(mlContext, model_location);\r\nvar outputColumn = schema.GetColumnOrNull(""Output"");\r\nif (outputColumn.HasValue)\r\n    outputLength = ((VectorType)outputColumn.Value.Type).Dimensions[0];\r\n```\r\n\r\n[2] Helper Methods\r\n```cs\r\npublic static Schema GetModelSchema(IHostEnvironment env, string modelPath);\r\npublic static IEnumerable<(string, string, ColumnType, string[])> GetModelNodes(IHostEnvironment env, string modelPath);\r\npublic static TensorFlowModelInfo LoadTensorFlowModel(IHostEnvironment env, string modelPath);\r\n```\r\nwhere `LoadTensorFlowModel` is already in the Transforms catalog.\r\n\r\nWould `GetModelSchema` and `GetModelNodes` go in the `DataOperations` catalog?\r\n\r\nAnd to pile on, `GetModelNodes` (which may not be necessary to expose) returns a list of returns, instead of an object, which we definitely can\'t have in V1.\r\n\r\nRelated to #2498'"
410892337,2571,b'Q: ML.NET within SQLCLR',"b'I would like to run/train a ML.NET model from with in SQL server as a SQLCLR; at present the ML.NET is failing with an obsquer error that looks to be related to security, is/will it be possible to run/train ML.NET models from inside SQL stored procedures close to the data source.'"
410885100,2570,b'MLContext.BinaryClassification.Trainers does not resolve to a documentation topic in the API Reference.',"b'MLContext.BinaryClassification.Trainers does not resolve to a documentation topic in the API Reference.  It should. \n\nGiven the following code: \n     Microsoft.ML.Trainers.SdcaBinaryTrainer train = mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: DefaultColumnNames.Label, featureColumn: DefaultColumnNames.Features);\n\nHow do we find and use the available set of Learners / Trainers via from the API Ref?       \n\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 8468bfed-64e4-c462-085d-19c1cce3b627\n* Version Independent ID: b4721a22-be85-9b1c-0914-fc591c3e9f28\n* Content: [MLContext.BinaryClassification Property (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.mlcontext.binaryclassification?view=ml-dotnet#Microsoft_ML_MLContext_BinaryClassification)\n* Content Source: [dotnet/xml/Microsoft.ML/MLContext.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/MLContext.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
410828380,2567,b'Bad exception experience loading a model',"b'See this PR review comment: https://github.com/dotnet/machinelearning/pull/1951/files#r244808064.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/13b33392dd3fbffc0922b2af72c8236b74c95fc0/src/Microsoft.ML.Data/DataLoadSave/TransformerChain.cs#L255-L263\r\n\r\nThis is causing a real problem with the Custom Mapping Transformer work that I\'m doing.\r\n\r\nWhen a user tries loading a model that contains a Custom Mapping Transformer, but we can\'t find that extension/contract we throw an exception during `ModelLoadContext.LoadModel` above saying `Can\'t find extension \'foo\'`.\r\n\r\nHowever, this code here eats that exception, tries doing something else and then throws a terrible exception `Repository doesn\'t contain entry DataLoaderModel\\Model.key`, which makes absolutely no sense to the user.\r\n\r\nWe should change this code such that the original exception is thrown if we can\'t load the `Pipeline`. Maybe we could start writing a flag into a ""pipeline"" model file to tell if it is supposed to be a Pipeline or not...? If we don\'t see that flag, then for sure the exception from `ModelLoadContext.LoadModel` above should be thrown.\r\n\r\n@TomFinley @Ivanidzo4ka - Thoughts?'"
410790856,2566,b'Exception on create predictor on release ',"b'### System information\r\n\r\n- **OS version/distro**: Virtual Machine W10\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** i call a method to generate a zip file model\r\n- **What happened?** through exception when deploy on the server but when i was on the debug mode it never crash\r\n- **What did you expect?**\r\nit should work.  is there is any missing dll \r\n\r\n\r\n### Source code / logs\r\n\r\n> Framework Version: v4.0.30319\r\nDescription: The process was terminated due to an unhandled exception.\r\nException Info: System.MissingMethodException\r\n   at Microsoft.ML.Training.TrainerUtils.CreatePredicate(Microsoft.ML.Data.RoleMappedData, Microsoft.ML.Training.CursOpt, System.Collections.Generic.IEnumerable`1<Int32>)\r\n   at Microsoft.ML.Trainers.FastTree.DataConverter+MemImpl.MakeBoundariesAndCheckLabels(Int64 ByRef, Int64 ByRef)\r\n   at Microsoft.ML.Trainers.FastTree.DataConverter+MemImpl..ctor(Microsoft.ML.Data.RoleMappedData, Microsoft.ML.IHost, Double[][], Single, Boolean, Boolean, Microsoft.ML.PredictionKind, Int32[], Boolean)\r\n   at Microsoft.ML.Trainers.FastTree.DataConverter.Create(Microsoft.ML.Data.RoleMappedData, Microsoft.ML.IHost, Int32, Single, Boolean, Boolean, Int32, Microsoft.ML.PredictionKind, Microsoft.ML.Trainers.FastTree.IParallelTraining, Int32[], Boolean)\r\n   at Microsoft.ML.Trainers.FastTree.ExamplesToFastTreeBins.FindBinsAndReturnDataset(Microsoft.ML.Data.RoleMappedData, Microsoft.ML.PredictionKind, Microsoft.ML.Trainers.FastTree.IParallelTraining, Int32[], Boolean)\r\n   at Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3[[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089],[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089],[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]].ConvertData(Microsoft.ML.Data.RoleMappedData)\r\n   at Microsoft.ML.Trainers.FastTree.FastTreeBinaryClassificationTrainer.TrainModelCore(Microsoft.ML.TrainContext)\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2[[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089],[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]].TrainTransformer(Microsoft.Data.DataView.IDataView, Microsoft.Data.DataView.IDataView, Microsoft.ML.IPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1[[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]].Fit(Microsoft.Data.DataView.IDataView)\r\n   at CommonLookPDFAutoTagger.ML.Train.MLModelGenerator.BuildArtifactTrainEvaluateAndSaveModel(CommonLook_PDF_AutoTagger.DataLayer.MLTrainersType, System.Collections.Generic.List`1<CommonLook_PDF_AutoTagger.DataLayer.LK_MLFeatures>)\r\n   at CLAIModelGenerator.MainViewModel.Generate()\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
410707837,2565,b'Example in README.md does not compile',"b'### System information\r\n\r\n- Windows 10.0.17134\r\n- 2.2.200-preview-009813\r\n\r\n### Issue\r\n\r\n- Copy-pasted code from readme.md to a new console project in Microsoft.ML.sln\r\n- Build failed with error CS0117: \'TextLoader.Arguments\' does not contain a definition for \'Column\', etc\r\n- Expected: The example code compiles successfully\r\n\r\n### Source code / logs\r\n\r\n```\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace ConsoleApp1 {\r\n    class Program {\r\n        static void Main( string[] args ) {\r\n            Console.WriteLine( ""Hello World!"" );\r\n\r\n            var mlContext = new MLContext();\r\n            var reader = mlContext.Data.CreateTextLoader( new TextLoader.Arguments {\r\n                Column = new[] {\r\n                    new TextLoader.Column(""SentimentText"", DataKind.Text, 1),\r\n                    new TextLoader.Column(""Label"", DataKind.Bool, 0),\r\n                },\r\n                HasHeader = true,\r\n                Separator = "",""\r\n            } );\r\n            var data = reader.Read( dataPath );\r\n            var learningPipeline = mlContext.Transforms.Text.FeaturizeText( ""Features"", ""SentimentText"" )\r\n                    .Append( mlContext.BinaryClassification.Trainers.FastTree() );\r\n            var model = learningPipeline.Fit( data );\r\n\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n}\r\n```\r\n'"
410542722,2559,b'Make `ISupportBoosterParameterFactory` internal in LightGBM project',"b'This interface was tried to be made internal in the following PR\r\nhttps://github.com/dotnet/machinelearning/pull/2476\r\n\r\nHowever, it seems like there is more work needed to make it internal. Thus, creating this issue to track the work.'"
410539667,2557,b'Renmants of Arguments keyword in public API',"b""There are some classes in our public API which still have word 'Arguments' in them \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/17c037f757113aba8acdc88abf2803b86fe95b93/src/Microsoft.ML.StandardLearners/Standard/Online/OnlineLinear.cs#L22\r\n\r\nWe should rename them to *Options instead. Related to #1798 #1758 \r\n"""
410490605,2555,b'All linear trainers should be typed',"b'There are still some binary classification trainers to (generalized) linear models. As done in  #2506, they all should be typed according to the types learned. They also should not do auto-calibration in API land.\r\n\r\nWe should also check if making other trainers typed is possible.\r\n\r\n- EnsembleTrainer\r\n- RegressionEnsembleTrainer\r\n- MulticlassDataPartitionEnsembleTrainer\r\n- MetaMulticlassTrainer\r\n- Ova related things\r\n- Stacking\r\n- TreeEnsembleFeaturizer'"
410484266,2554,b'ColumnInfo as an API parameter',"b""The use of `ColumnInfo` in the public API can be rather jarring. I'd like to clarify when we should use it in the catalog API, and if the parameter name could be made to be more consistent with the API, such as `ColumnOptions` or `Options`."""
410449581,2553,b'Cleaning of overload Fit functions',"b""- We shouldn't use `IPredictor` interface for `initialPredictor`, we should specify proper class type.\r\n- `initialPredictor` should be renamed to `modelParameters`\r\n"""
410447731,2552,b'Should TensorFlowModelInfo be public?',"b'Related to #2280.\r\nThe TensorFlowModelInfo class is still public, and so are two methods for creating a TensorFlowEstimator from a TensorFlowModelInfo. I was wondering whether we should have these, since the only way to get a TensorFlowModelInfo is by calling TensorFlowUtils.LoadTensorFlowModel(), and that uses a file name - and users that have a file name, can instantiate a TensorFlowEstimator from that directly. \r\nThere is one scenario that I can think of where a user would benefit from using this API: The TensorFlowModelInfo class has a method GetInputSchema(), that can be used to get the name of the input layer(s), and then the TensorFlowEstimator can be instantiated from the TensorFlowModelInfo instead of instantiating it from the file name and having to load it from disk again. Is this reason enough to keep these APIs?\r\nIf it is, then TensorFlowUtils.LoadTensorFlowModel should be moved to TensorFlowCatalog, and perhaps also the GetInputSchema() method of TensorFlowModelInfo.\r\n@TomFinley , @zeahmed , @abgoswam , @ganik  - thoughts?\r\n\r\nAnother unrelated issue: Microsoft.ML.TensorFlow has two AssemblyInfo.cs files, one in src\\Microsoft.ML.TensorFlow\\ and one in  src\\Microsoft.ML.TensorFlow\\Properties. These should be unified.\r\n'"
410423496,2551,b'Returns true for null array ',"b'Hi,\r\n\r\n`Microsoft.ML.Internal.Utilities.Utils` has a couple of array checks that return `true` when a `null` array is passed in. Is this the expected behavior?\r\n\r\nHere are the culprits:\r\n\r\n```cs\r\npublic static bool IsSorted(IList<float> values);\r\npublic static bool IsSorted(int[] values);\r\n```\r\n\r\n```cs\r\npublic static bool IsIncreasing(int min, ReadOnlySpan<int> values, int lim);\r\n```\r\n\r\nNote that `IsIncreasing` is typically used for checking `int[]` arrays because `ReadOnlySpan` performs an implicit cast and null arrays are set to a 0-length `ReadOnlySpan`.\r\n\r\nIn a similar vein, `IsSorted` uses a null-safe `Utils.Size()` to check the input length of the array.\r\n\r\nDoes this make sense that we say that `null` arrays are sorted, and that they are decreasing?'"
410407567,2550,b'Transforms.Resize has a vague name',"b""The `ImageResizingEstimator` is in the catalog as `Resize`. By it's name, it isn't clear that this is intended for images. It could easily refer to a transform that resizes vectors. I suggest naming it to something more specific, such as `ResizeImages` (e.g. parallel language to `LoadImages`)."""
410141329,2549,b'Example classes should be static',b'We have accumulated a bunch of examples while our coding guideline changes from time to time. We should as least make all example classes static to meet our latest decision.'
410093541,2545,b'Add support for string types in TensorFlowTransformer',"b'There are a couple of request to support string in TensorFlowTransformer. Strings are handled quite differently in TensorFlow. Strings are variable length data. To represent string as a tensor, TensorFlow requires tensor be represented in the following way c.f.\r\n https://github.com/tensorflow/tensorflow/blob/01cf864bb0d82370c259866c0735c0358e33377c/tensorflow/c/c_api.h#L206.\r\n\r\n``` c\r\n/ --------------------------------------------------------------------------\r\n// TF_Tensor holds a multi-dimensional array of elements of a single data type.\r\n// For all types other than TF_STRING, the data buffer stores elements\r\n// in row major order.  E.g. if data is treated as a vector of TF_DataType:\r\n//\r\n//   element 0:   index (0, ..., 0)\r\n//   element 1:   index (0, ..., 1)\r\n//   ...\r\n//\r\n// The format for TF_STRING tensors is:\r\n//   start_offset: array[uint64]\r\n//   data:         byte[...]\r\n//\r\n//   The string length (as a varint), followed by the contents of the string\r\n//   is encoded at data[start_offset[i]]]. TF_StringEncode and TF_StringDecode\r\n//   facilitate this encoding.\r\n```\r\n\r\n'"
410064346,2542,b'Multiclass classification Score vs Scores column',"b'This is silly, but probably worth small discussion.\r\nAll our Multiclass samples using following example:\r\nhttps://github.com/dotnet/machinelearning/blob/fd30559d9f8070d7cb71ba937897a63646d5b0bc/src/Microsoft.ML.SamplesUtils/SamplesDatasetUtils.cs#L500\r\nwhich has:\r\n```\r\n// The probabilities of being ""AA"", ""BB"", ""CC"", and ""DD"".\r\npublic float[] Scores;\r\n```\r\nThere is small problem with that. All our multiclass learners produce column `Score`, not `Scores`, so we just copy column from `Score` to `Scores`, or reassign them in pigsty.\r\nWhich doesn\'t look like good idea for me, more like workaround.\r\n\r\nQuestion is following: do we prefer to have consistency and call score column everywhere as `Score` column, or we want to be more user friendly and for multiclass use `Scores` (basically introduce (`DefaultColumnNames.MulticlassScore`)\r\n\r\nIn we want consistency we better rename `Scores` in `MulticlassClassificationExample` to `Score`. If we want be more user friendly, we need to go through lot of code, and replace for all multiclass cases `Score` to `Scores`.'"
410032214,2540,b'Explicit implementation for IsRowToRowMapper and GetRowToRowMapper',"b'The interface `ITransformer` defines two methods:\r\n\r\n```csharp\r\n/// <summary>\r\n/// Whether a call to <see cref=""GetRowToRowMapper(Schema)""/> should succeed, on an\r\n/// appropriate schema.\r\n/// </summary>\r\nbool IsRowToRowMapper { get; }\r\n\r\n/// <summary>\r\n/// Constructs a row-to-row mapper based on an input schema. If <see cref=""IsRowToRowMapper""/>\r\n/// is <c>false</c>, then an exception should be thrown. If the input schema is in any way\r\n/// unsuitable for constructing the mapper, an exception should likewise be thrown.\r\n/// </summary>\r\n/// <param name=""inputSchema"">The input schema for which we should get the mapper.</param>\r\n/// <returns>The row to row mapper.</returns>\r\nIRowToRowMapper GetRowToRowMapper(Schema inputSchema);\r\n```\r\n\r\nA transformer maps `IDataViews` to `IDataViews`, however this process can in some cases be optimized by mapping rows to rows with a `IRowToRowMapper`. Although for most scenarios a user should not be using them directly, they might be useful in custom extensions which we would like to enable in the future. This is why the above two methods are present in the interface of `ITransformer` and are necessary.  \r\n\r\nSince, however, these are not usually employed directly by users, we should implement them explicitly. \r\n\r\n/cc: @TomFinley \r\n'"
410026703,2538,b'Create functional tests for all V1 TensorFlow scenarios',"b'As laid out in #2498 , we need scenarios to cover the TensorFlow functionality we want fully supported in V1.\r\n\r\n- An existing TF model can be used to produce predictions\r\n- Any layer from a TF model can be used to produce predictions\r\n- Input and output nodes can be identified from an existing TF model\r\n- Train TF models with a defined TF model topology'"
410003743,2536,b'StratificationColumn in CrossValidation and TrainTestSplit',"b""`CrossValidation` and `TrainTestSplit` have a parameter called `StratificationColumn` that is used to preserve groupings of columns across splits (as discussed in #2487). This isn't actually stratification, so we should rename the column.\r\n\r\nThis is a forked sub-issue from #2487\r\n\r\nRelated to #1204"""
409989117,2535,b'Regression evaluate throws ArgumentOutOfRangeException with named parameters',"b'### System information\r\n\r\n- **OS version/distro**: win10\r\n- **.NET Version (eg., dotnet --info)**: 2.2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n[taxi fare prediction](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/taxi-fare) sample, Evaluate method:\r\n// this throws sys.argumentexception\r\nvar metrics = mlContext.Regression.Evaluate(dataView, label: ""Label"", score: ""Score"");\r\n// this works:\r\nvar metrics = mlContext.Regression.Evaluate(predictions, ""Label"", ""Score"");\r\n- **What happened?**\r\nSystem.ArgumentOutOfRangeException: \'Label column \'Label\' not found\r\nParameter name: schema\'\r\n\r\n### Source code / logs\r\n\r\n![image](https://user-images.githubusercontent.com/7790756/52741979-fc112680-2fd6-11e9-80a0-c4ba4466be10.png)\r\n'"
409987245,2534,"b""LightGbmMulti System.ArgumentOutOfRangeException: Schema mismatch for label column '': expected Bool, got Key<U4>""","b""running with 0.10 bits, started getting this error on certain datasets when benchmarking AutoML (not 100% positive but likely this started happening when we upgraded to 0.10):\r\n\r\nProcessing pipeline ColumnCopying{ col=Label:0} xf=ValueToKeyMapping{ col=Label:Label} tr=LightGbmMulti{}.\r\nLightGbmMulti{} Crashed System.ArgumentOutOfRangeException: Schema mismatch for label column '': expected Bool, got Key<U4>\r\nParameter name: labelCol\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2.CheckLabelCompatible(Column labelCol)\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Training.TrainerEstimatorBase`2.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Auto.SuggestedPipeline.Fit(IDataView trainData)\r\n   at Microsoft.ML.Auto.AutoFitter`1.ProcessPipeline(SuggestedPipeline pipeline)\r\n\r\nNote that we're adding ValueToKeyMapping to our pipelines to get around https://github.com/dotnet/machinelearning/issues/1969\r\n"""
409986610,2533,"b""lib_lightgbm.dll isn't published to Azure App Service""","b""Using `Microsoft.ML.LightGBM (0.9.0)` NuGet package to train locally. This succeeds.\r\nTrying to right click | Publish the solution directly from Visual Studio to Azure App Service succeeds. When trying to train a LightGBM model on the deployed Azure App Service, I get:\r\n```\r\nUnable to load DLL 'lib_lightgbm' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n```\r\n\r\nExamining the published files via Kudo (Azure Portal | My Service | Console | dir) shows that `lib_lightgbm.dll` isn't there.\r\n\r\nAny special steps I should take to publish this DLL and its dependencies to Azure?\r\n\r\nMaybe related to #1945 \r\ncc @eerhardt @sfilipi """
409941009,2530,b'Create Samples for LightGbm Ranker.',b'Need doc samples for lightgbm ranker. \r\nReference the samples in the xml docs for the two public lightgbm ranker methods.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f8e58dd4327f4c5013abbd7f691d835bdd377909/src/Microsoft.ML.LightGBM/LightGbmCatalog.cs#L104'
409582757,2527,b'Renaming .Train to .Fit in TrainerEstimators',"b""Some trainers allow training with an initial predictor, or with a validation data set. The initial predictor is used as a starting point for further training. However, the method that allows this is usually named:\r\n\r\n```csharp\r\nITransformer Train(IDataView trainData, IPredictor initialPredictor = null)\r\n```\r\nor \r\n```csharp\r\nITransformer Train(IDataView trainData, IDataView validationData = null, IPredictor initialPredictor = null)\r\n```\r\n\r\nThis could lead to quite a bit of confusion as the TrainerEstimators will have two methods for training -  `Fit()` and `.Train()` - that achieve pretty much the same result. In the above `initialPredictor` can be `null` so `.Fit(data)` does the same as `.Train(data)`.\r\n\r\nAs it was suggested in the issue #2502 in one of @TomFinley's comments https://github.com/dotnet/machinelearning/issues/2502#issuecomment-462493936, I think we should rename the `Train` method to `Fit`.\r\n\r\nThe result is that there will be a single method name `Fit` to train a model with an overload to perform training with an initial predictor. \r\n\r\n/cc: @TomFinley, @Ivanidzo4ka \r\n\r\n"""
409574317,2523,b'Registering subhosts when creating new catalog entries advances the pseudo random number generator',"b'For creating a new catalog entry in MLContext, the existing pattern is to register subhosts i.e. create a new Host out of the environment. This advances the pseudo random number generator. \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5c442a96edc3ac7a03bc10ef668310647f16db9a/src/Microsoft.ML.Data/TrainCatalog.cs#L195-L200\r\n\r\nThis means that if we add a new catalog entry in MLContext, the baseline tests would start failing.  (In fact this is the exact behaviour observed in PR #2390 when we try to add a AnomalyDetectionCatalog entry to MLContext)\r\n\r\nInstead of *forking* the environment we can just *store* the environment passed in.\r\n\r\n@TomFinley '"
409568014,2522,b'Docs and samples for the API reference site (P0 & P1 Trainers)',b'# List of trainers per catalog\r\n\r\n## BinaryClassification.Trainers\r\n\r\nBinaryClassification Trainers | Category | Priority | Docs (1st pass) | Docs (2nd pass) | Samples (1st   pass) | Samples (2nd   pass)\r\n-- | -- | -- | -- | -- | -- | --\r\nAveragedPerceptron | Linear | 0 | Shahab #2517 | Done Shahab #3310\xc2\xa0 | Shahab #2517 | \xc2\xa0Artidoro #3311 |\r\nLogisticRegression | Linear | 0 | Wei-Sheng #3385\xc2\xa0 | Done Wei-Sheng #3385 \xc2\xa0 | ZeeshanA #3099 | \xc2\xa0Artidoro #3311|\r\nStochastic GradientDescent | Linear | 0 | Shahab #2688 | \xc2\xa0@codemzs #3392 | Shahab #2688 | \xc2\xa0Artidoro #3311|\r\nStochasticDual CoordinateAscent | Linear | 0 | Shahab #2771 | \xc2\xa0@codemzs #3395  | Shahab #2771 | \xc2\xa0Artidoro #3311|\r\nSymbolicStochastic GradientDescent | Linear | 0 | Ivan\xc2\xa0 | @codemzs #3396 \xc2\xa0 | \xc2\xa0 | \xc2\xa0Artidoro #3311|\r\nLightGbm | Tree | 0 | Shahab #2886 | Done @codemzs\xc2\xa0#3397 | Shahab #2729 | \xc2\xa0Artidoro #3311|\r\nFastTree | Tree | 0 | Shahab #2970 | Done @codemzs #3398\xc2\xa0 | Shahab #3035 | \xc2\xa0Artidoro #3311|\r\nFastForest | Tree | 0 | Shahab #2970 | Done @codemzs #3399\xc2\xa0 | Shahab #3035 | \xc2\xa0Artidoro #3311|\r\nField Aware FactorizationMachine | FFM | 0 | Wei-Sheng #3374  | Done Wei-Sheng #3374\xc2\xa0 | #3312 Wei-Sheng\xc2\xa0 | Wei-Sheng #3374 \xc2\xa0|\r\nGeneralized AdditiveModels | GAM | 1 | Shahab #2970 | Done @codemzs #3425 | @codemzs \xc2\xa0 | \xc2\xa0Artidoro #3311|\r\nLinear Support VectorMachines | Linear | 2 | Yael\xc2\xa0| Done #3401 Yael\xc2\xa0 | \xc2\xa0 | \xc2\xa0Artidoro #3311|\r\nPrior | Baseline | 2 | Aridoro #2510 |  Done \xc2\xa0@codemzs #3426  | Artidoro #2510 | \xc2\xa0Artidoro #3311|\r\n\r\n\r\n## MulticlassClassification.Trainers\r\n\r\nMulticlassClassification   Trainers | Category | Priority | Docs (1st pass) | Docs (2nd pass) | Samples | Samples (2nd   pass)\r\n-- | -- | -- | -- | -- | -- | --\r\nLbfgs   MaximumEntropy | Linear | 0 | Wei-Sheng #3389 | Done Wei-Sheng #3389 | \xc2\xa0 | Artidoro#3322\r\nSdca   Max Ent | Linear | 0 | Shahab     #2771 | Done Wei-Sheng #3433\xc2\xa0 | #2771 | Artidoro\xc2\xa0#3322\r\nSdca   Non Calibrated | Linear | 0 | \xc2\xa0 | Done Wei-Sheng #3433\xc2\xa0 | \xc2\xa0 | Artidoro\xc2\xa0#3322\r\nLightGbm | Tree | 0 | Shahab     #2886 | Done @codemzs #3427\xc2\xa0 | #2729 | Artidoro\xc2\xa0#3322\r\nOneVersusAll | Meta | 0 | Gani     Done | Done Gani  #3387\xc2\xa0 | Done | Artidoro\xc2\xa0#3322\r\nPairwiseCoupling | Meta | 1 | Gani     Done | Done Gani\xc2\xa0#3387 | Done | Artidoro\xc2\xa0#3322\r\nNaiveBayes | Linear | 2 | Gani     Done | Done Gani\xc2\xa0#3387 | Done | Artidoro\xc2\xa0#3322\r\n\r\n\r\n## Regression.Trainers\r\n\r\nRegression.Trainers | Category | Priority | Docs (1st pass) | Docs (2nd pass) | Samples | Samples (2nd   pass)\r\n-- | -- | -- | -- | -- | -- | --\r\nStochasticDual   CoordinateAscent | Linear | 0 | Shahab     #2771 | @codemzs\xc2\xa0#3403 | #2771 | Wei-Sheng\xc2\xa0#3319\r\nPoissonRegression | Linear | 0 | Shahab     #3059 | Done @codemzs #3404 \xc2\xa0 | #3067 | Wei-Sheng\xc2\xa0#3319\r\nOrdinaryLeastSquares | Linear | 0 | Shahab     #3059 | \xc2\xa0Done @codemzs #3405 | Done | Wei-Sheng\xc2\xa0#3319\r\nOnlineGradientDescent | Linear | 1 | Shahab     #3059 | \xc2\xa0Done @codemzs #3422  | #3067(#2425 needs   to be fixed for the sample to be included | Wei-Sheng\xc2\xa0#3319\r\nLightGbm | Tree | 0 | Shahab     #2886 | \xc2\xa0Done @codemzs #3410 | #2729 | Wei-Sheng\xc2\xa0#3319\r\nFastForest | Tree | 0 | Shahab     #2970 | Done @codemzs #3411\xc2\xa0 | #2999 | Wei-Sheng\xc2\xa0#3319\r\nFastTree | Tree | 0 | Shahab     #2970 | Done @codemzs #3412\xc2\xa0 | #2999 | Wei-Sheng\xc2\xa0#3319\r\nFastTreeTweedie | Tree | 0 | Shahab     #2970 | Done @codemzs #3414\xc2\xa0 | #2999 | Wei-Sheng\xc2\xa0#3319\r\nGeneralized   AdditiveModels | GAM | 1 | Rogan | \xc2\xa0Done @codemzs #3421 | #2999 | Wei-Sheng\xc2\xa0#3319\r\n\r\n## Misc catalogs\r\n\r\n\r\nCatalog | Trainer | Priority | Docs | Docs (2nd pass) | Samples | Samples (2nd   pass)\r\n-- | -- | -- | -- | -- | -- | --\r\nClustering | KMeans | 0 | \xc2\xa0 | Done Gani #3387| \xc2\xa0 | Artidoro\xc2\xa0#3317\r\nAnomalyDetection | RandomizedPca | 1 | Yael\xc2\xa0 | @codemzs #3429\xc2\xa0 |  Done\xc2\xa0 | \xc2\xa0Done\r\nRanking | FastTree | 2 | Shahab     #2970 | Done @codemzs #3430\xc2\xa0 | \xc2\xa0 | Artidoro\xc2\xa0#3338\r\nRanking | LightGbm | 2 | Shahab     #2886 | Done @codemzs #3431\xc2\xa0 | #2729 | Artidoro\xc2\xa0#3338\r\nRecommendation | MatrixFactorization | 1 | Wei-Sheng #3409  | Done Wei-Sheng #3409 | \xc2\xa0 | Wei-Sheng #3362\r\n'
409564953,2521,b'FastTree EarlyStoppingMetric is an `int` but only accepts specific values',"b'In the current `Options` for `FastTree` (and `GAMs`), `EarlyStoppingMetric` is an `int`, but only specific values are accepted (e.g. 1 or 2 for regression, 1 or 3 for ranking).\r\n\r\nIt would be much cleaner if this was an enum.'"
409563915,2520,b'FastTree EarlyStoppingRule definition is inconsistent with API',"b'In `FastTree`, the `EarlyStoppingRule` is defined as\r\n```cs\r\n[Argument(ArgumentType.Multiple, HelpText = ""Early stopping rule. (Validation set (/valid) is required.)"", ShortName = ""esr"", NullName = ""<Disable>"")]\r\n[TGUI(Label = ""Early Stopping Rule"", Description = ""Early stopping rule. (Validation set (/valid) is required.)"")]\r\npublic IEarlyStoppingCriterionFactory EarlyStoppingRule;\r\n```\r\n\r\nThis can be specified like so:\r\n```cs\r\nvar fastTreeTrainer = mlContext.Regression.Trainers.FastTree(new \r\n    Trainers.FastTree.FastTreeRegressionTrainer.Options {\r\n        EarlyStoppingMetrics = 2,\r\n        EarlyStoppingRule = new GLEarlyStoppingCriterion.Arguments()\r\n    });\r\n```\r\n\r\nThis exposes the `IComponentFactory` way of doing things in the public API, which seems to be inconsistent with the public API. One suggestion is to use an `enum` over the existing options.\r\n\r\nThat said, this does support custom early stopping methods through implementing  `IEarlyStoppingCriterionFactory`.'"
409561261,2519,b'OnlineLinear trainer InitialWeights option is not user friendly',"b'```\r\n        [Argument(ArgumentType.AtMostOnce, HelpText = ""Initial Weights and bias, comma-separated"", ShortName = ""initweights"")]\r\n        [TGUI(NoSweep = true)]\r\n        public string InitialWeights;\r\n```\r\nIt need to be replaced with two fields Bias and Weights and they should be float and array of floats instead of just string'"
409468623,2515,b'Calibrator estimators as successor to ICalibratorTrainer',"b""One of the legacy interfaces we have is the calibrator trainer.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f269adcd30a33feeb969c17c2a9f9db235113cb1/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L95\r\n\r\nThis interface is unsuitable to being a public class as part of the `IEstimator`/`ITransformer` idioms, being more of implementation interface for the infrastructure of the calibrators. So we don't want that exposed, but we do nonetheless want the ability to given some data, produce a calibrator out of it.\r\n\r\nHappily we *almost* have it, in the form of the subclasses of the calibrator estimators.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f269adcd30a33feeb969c17c2a9f9db235113cb1/src/Microsoft.ML.Data/Prediction/CalibratorCatalog.cs#L52\r\n\r\nThe only real trouble is that this object assumes, at a fairly deep level, that internally there is an `IPredictor` in it, but as far as I know this is mostly due to some internal convenience code that I hope could be refactored to just take an `IDataView` directly.\r\n\r\nThis might be viewed as a sub-part of #1871.\r\n\r\n/ccing @sfilipi for visibility."""
409416767,2514,b'General Questions/observations',"b'All, I\'ve cross posted [this](https://github.com/dotnet/docs/issues/10150) from dotnet/docs. Any insight or feedback you could give would be appreciated!  CC: @AlexSapple, @kkho (orginal posters)\r\n-----\r\nHi,\r\n\r\nI\'ve started playing with ML.net and made a slightly modified version of [the taxi fare tutorial](https://docs.microsoft.com/en-gb/dotnet/machine-learning/tutorials/taxi-fare) to suit data I had. exercise has given me a few questions (please bear in mind I am completely new to this type of thing).\r\n\r\n1. My dataset was from elastic search documents - I found that I could use CreateStreamingDataView() to work with this. All the examples seem to use text file datasets. are text file datasets more common? (I come from a database world).\r\n2. working with int\'s caused errors when training a model. I was getting the following error: ""One or more errors occurred. (Column \'AdultCount\' has values of I4which is not the same as earlier observed type of R4"".\r\n\r\nI think ""l4which"" was intended to be ""l4 which"" but in any case without any other changes, if i changed data type to be float, no such error. I\'m not sure what R4 and L4 refer to but something to do with datatypes?\r\n\r\nwhen I got my modified example working - evaluating test data gave a metric of: RSquared = -0.12 and a RMS of 92.02. Clearly these values are outside the parameters that they should be - but I don\'t know how to troubleshoot such things - are there any tutorials on identifying why a model is messed up?\r\n\r\n1. I had a datetime field in my data. It may be a relevant field for making predictions (in my case I was looking at predicting a result count for a search with a 3rd party, based on existing logged search data). I am curious about fields like dates and how they might play a role - but not sure how they might be encoded into the pipeline. I thought that a date may be a lot more use if it was transformed into a day of year (or similar) to capture a pattern of seasonality rather than the pure date.\r\n2. my predictions were absolutely miles out (but that was expected after looking at the score of the model). I was in some cases predicting result counts of negative numbers.\r\n\r\noverall, I\'m really excited by having the framework available to dev with - but really need more learning resources!\r\n'"
409214400,2513,"b""Load tensorflow model created by python error while 'Visual Studio Tools for AI' well""","b'### System information\r\n\r\n- **OS version/distro**: \r\n    windows 10\r\n    ml.net v0.10.0\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n  dotcore v2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nI have a tensorflow model, when I use Visual Studio Tools for AI, it auto generator code like this\r\n\r\n` \r\n    \r\n    private static List<long> serving_defaultFeaturesShapeForSingleInput = new List<long> { 1, 6, 8 };\r\n    private static List<string> serving_defaultInputNames = new List<string> { ""features"" };\r\n    private static List<string> serving_defaultOutputNames = new List<string> { ""predictions"" };\r\n    etc...\r\n    /// <summary>\r\n    /// Runs inference on abc model for a single input data.\r\n    /// </summary>\r\n    /// <param name=""features"">From signature: input 1 with tensor name features; Shape of the input: { 1, 6, 8 }</param>\r\n    public IEnumerable<float> Serving_default(IEnumerable<float> features)\r\n    {\r\n        List<Tensor> result = manager.RunModel(\r\n            modelName,\r\n            int.MaxValue,\r\n            serving_defaultInputNames,\r\n            new List<Tensor> { new Tensor(features.ToList(), serving_defaultFeaturesShapeForSingleInput) },\r\n            serving_defaultOutputNames\r\n        );\r\n        List<float> r0 = new List<float>();\r\n        result[0].CopyTo(r0);\r\n        return r0;\r\n    }     \r\n  `\r\nand everything goes well, I run this instance and got a return. \r\n\r\nwhen I use the ML.Net v0.10.0 try a test the same tensorflow model :\r\n\r\n`\r\n     \r\npublic class TensorData\r\n    {\r\n        [VectorType(1, 4, 6)]\r\n        [ColumnName(""lstm_1_input"")]\r\n        public float[] input { get; set; }\r\n    }\r\n\r\n    etc.....\r\n\r\n    var pipeline = mlContext.Transforms.ScoreTensorFlowModel(\r\n       tensorModel, new[] { ""lstm_1_input"" }, new[] { ""lstm_1_input"" });\r\n    var data = GetTensorData();\r\n    var idv = mlContext.Data.ReadFromEnumerable(data);\r\n    var trainedModel = pipeline.Fit(idv);\r\n    var predicted = trainedModel.Transform(idv);\r\n\r\n`\r\n\r\nit throw a exception: \r\n>System.InvalidOperationException:\xe2\x80\x9cInput shape mismatch: Input \'lstm_1_input\' has shape [1, 4, 6], but input data is Vec<R4, 1, 4, 6>.\xe2\x80\x9d\r\n\r\n1\xe3\x80\x81 how to caputure the inputColumnNames/outputColumnNames from a exists model ,  when Visual Studio Tools for AI use different input/output names ?\r\n2\xe3\x80\x81how to construct a shape [1, 4, 6], when I change input  type as float[,,] ,> it throw a\r\n >System.InvalidOperationException:\xe2\x80\x9cVariable length input columns not supported\xe2\x80\x9d.\r\n\r\nso how I can correctly use the tensorflow model ? please give a example, thanks much.\r\n\r\n\r\n'"
409126387,2512,"b""SaveAsText documentation doesn't address scope of separator argument""","b'`SaveAsText` in the `Data` catalog has a `separator` parameter, which is specified as a `char`. However, this throws an `ArgumentOutOfRangeException` if the `separator` is not a ""space, tab, comma, semicolon, or bar"".\r\n\r\nCurrently, the only way to discover this delimiter limitation is to try and fail.\r\n\r\nWe have a few options. We could allow any character to be used as a delimiter, we could add documentation to the parameter that says it must be one of these characters, or, if we really do want to scope to a limited set of characters, then we could add a compile-time check by changing this to an `enum`.'"
409018745,2508,b'Create functional tests for all V1 Data I/O scenarios',"b'As laid out in #2498 , we need scenarios to cover the Data Sources functionality we want fully supported in V1.\r\n\r\nWe need to be able to read and write from\r\n- IEnumerable\r\n- Delimited files\r\n- Binary (.idv) files'"
408971935,2502,"b""Validation training isn't supported by the new API""","b'I cannot find a way to train with a validation set in the new API, and I think there is some confusion as to how this would work, were it possible.\r\n\r\nTake this example:\r\n\r\n```cs\r\n// Create a pipeline to train on the sentiment data\r\nvar trainData = readTrainData();\r\nvar validData = readValidData();\r\n\r\nvar pipeline = mlContext.Transforms.SomTransform.()\r\n    .AppendCacheCheckpoint(mlContext) as IEstimator<ITransformer>;\r\nvar preprocessor = pipeline.Fit(trainData);\r\nvar preprocessedValidData = preprocessor.Transform(validData);\r\n\r\n// Train model with validation set.\r\n// There is no way below to specify a validation set for the learner\r\npipeline = pipeline.Append(mlContext.Regression.Trainers.FastTree(numTrees: 2));\r\n// Nor is there a way to specify a validation set in the Fit\r\nvar model = pipeline.Fit(trainData);\r\n```\r\n\r\nThis example uses `FastTree`, but the same problem exists for `GAM` and `FFM`, our other validation-set trainers: There is nowhere to specify a validation set.\r\n\r\nA second problem exists, namely: If we were to specify a validaiton set, would we specify the raw, unprocessed validation set (here `validData`) or would we specify the pre-transformed validation set (here, `preprocessedValidData`).'"
408949370,2501,b'Remove value-tuples from the public surface of the API',"b""The public surface of the API contains value-tuples, which present a few problems:\r\n- We can't change the data we return in future releases (e.g. add functionality)\r\n- They don't play well with F#\r\n- Support in VS isn't great\r\n\r\nThese occur are in at least\r\n- `CrossValidation` (e.g. for each task)\r\n- `TrainTestSplit`: (e.g. for each task)\r\n\r\nWe should make sure that no value-tuples are returned and that they are not in the parameters of any public API.\r\n\r\nRelated to: #2487 """
408947750,2500,b'OnnxTransform - Ubuntu-only unit tests and friendly error message on incompatible Linux distributions',"b'### System information\r\n\r\n- **OS version/distro**: Ubuntu 16.04\r\n- **.NET Version (eg., dotnet --info)**: 2.1\r\n\r\n### Issue\r\n\r\nOnnxTransform tests need to be activated on  new Ubuntu leg (when ready)\r\n\r\nOnnxTransform tests need to be deactivated on  CentOS leg (glibc version is not compatible).\r\n\r\nUpdate OnnxTransform to throw friendly error  message when running on incompatible Linux distro.\r\n\r\n'"
408946115,2499,b'Create functional tests for all V1 validation scenarios',"b'As laid out in #2498 , we need scenarios to cover the Validation functionality we want fully supported in V1.\r\n\r\n- Cross-validation (already covered)\r\n- Validation'"
408941928,2498,b'V1 Scenarios need to be covered by tests',"b'In issue #584, we laid out a set of scenarios that we\'d like to cover for V1.0 of ML.NET. We need high-level functional tests to make sure that these work well in the 1.0 library.\r\n\r\nHere is a list of tests that cover the scenarios. Let\'s use this issue as a top-level issue to track coverage of the APIs.\r\n\r\nCategory | Scenarios | Link to Test | Completed PR | Blocked by Issue\r\n-- | -- | -- | -- | --\r\nData I/O| I can   use objects already in memory (as IEnumerable) as input to my ML   pipeline/experiment | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0\r\nData I/O | I can   use locally stored delimited files (.csv, .tsv, etc.) as input to my ML   pipeline/experiment | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0 \xc2\xa0\r\nData I/O | I can   use locally stored binary files (.idv) as input to my ML   pipeline/experiment | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0\r\nData I/O | I can   go through any arbitrary data transformation / model training and save the   output to disk as a delimited file (.csv, .tsv, etc.). | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0\r\nData I/O | I can   go through any arbitrary data transformation / model training and save the   output to disk as a binary file (.idv). | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0\r\nData I/O | I can   go through any arbitrary data transformation / model training and convert the   output to an IEnumerable. | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/DataIO.cs)\xc2\xa0 | #2518\xc2\xa0 | \xc2\xa0\r\nData I/O | I can   use data from a SQL database by reading it into memory or to disk using an   existing SQL reader and then use that as input to my ML pipeline/experiment | (May be a sample)\xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nData   Transformation, Feature Engineering | I can   take an existing ONNX model and get predictions from it (as both final output   and as input to downstream pipelines) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nData   Transformation, Feature Engineering | Extensible   transformation: It should be possible to write simple row-mapping transforms.   \xc2\xa0   Examples:   ""I can add custom steps to my pipeline such as creating a new column   that is the addition of two other columns, or easily add cosine similarity,   without having to create my own build of ML.NET."" | \xc2\xa0 | \xc2\xa0#2803 | \xc2\xa0\r\nData   Transformation, Feature Engineering | I can   modify settings in the TextFeaturizer to update the number of word-grams and   char-grams used along with things like the normalization. | \xc2\xa0 | \xc2\xa0#2803 | \xc2\xa0#2802 \r\nData   Transformation, Feature Engineering | I can   apply normalization to the columns of my data | \xc2\xa0 | #2803\xc2\xa0 | \xc2\xa0\r\nData   Transformation, Feature Engineering | I can   take an existing TF model and get predictions from it or any layer in the   model | \xc2\xa0 | WIP Rogan\xc2\xa0 | \xc2\xa0\r\nData   Transformation and Feature Engineering | P1: I   can take an existing TF model and use ML.NET APIs to identify the input and   output nodes | \xc2\xa0 | WIP Rogan\xc2\xa0 | \xc2\xa0\r\nDebugging | I can   see how my data was read in to verify that I specified the schema correctly | \xc2\xa0 | #2937\xc2\xa0 | \xc2\xa0\r\nDebugging | I can   see the output at the end of my pipeline to see which columns are available   (score, probability, predicted label) | \xc2\xa0 | #2937\xc2\xa0 | \xc2\xa0\r\nDebugging | I can   look at intermediate steps of the pipeline to debug my model.   \xc2\xa0   Example:   > I   were to have the text `""Help I\'m a bug!""` I should be able to see   the steps where it is normalized to `""help i\'m a bug""` then   tokenized into `[""help"", ""i\'m"", ""a"",   ""bug""]` then mapped into term numbers `[203, 25, 3, 511]` then   projected into the sparse float vector `{3:1, 25:1, 203:1, 511:1}`, etc. etc. | \xc2\xa0 | #2937\xc2\xa0 | \xc2\xa0\r\nDebugging | P1: I   can access the information needed for understanding the progress of my   training (e.g. number of trees trained so far out of how many) | \xc2\xa0 | \xc2\xa0#2937 | \xc2\xa0\r\nEvaluation | I can   evaluate a model trained for any of my tasks on test data. The evaluation   outputs metrics that are relevant to the task (e.g. AUC, accuracy, P/R, and   F1 for binary classification) | \xc2\xa0 | #2646  | \xc2\xa0\r\nEvaluation | P1: I   can get the data that will allow me to plot PR curves | \xc2\xa0 | #2646  | \xc2\xa0#2645\r\nExplainability   & Interpretability | I can   get near-free (local) feature importance for scored examples (Feature   Contributions) | \xc2\xa0 | \xc2\xa0#2584  | \xc2\xa0\r\nExplainability   & Interpretability | I can   view how much each feature contributed to each prediction for trees and   linear models (Feature Contributions) | \xc2\xa0 | \xc2\xa0#2584  | \xc2\xa0\r\nExplainability   & Interpretability | I can   view the overall importance of each feature (Permutation Feature Importance,   GetFeatureWeights) | \xc2\xa0 | #2584 \xc2\xa0 | \xc2\xa0\r\nExplainability   & Interpretability | I can   train interpretable models (linear model, GAM) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nIntrospective   training | I can   take an existing model file and inspect what transformers were included in   the pipeline | \xc2\xa0 | #2859\xc2\xa0 | \xc2\xa0\r\nIntrospective   training | I can   inspect the coefficients (weights and bias) of a linear model without much   work. Easy to find via auto-complete. | \xc2\xa0 | #2859| \xc2\xa0\r\nIntrospective   training | I can   inspect the normalization coefficients of a normalizer in my pipeline without   much work. Easy to find via auto-complete. | \xc2\xa0 | \xc2\xa0#2859 | \xc2\xa0\r\nIntrospective   training | I can   inspect the trees of a boosted decision tree model without much work. Easy to   find via auto-complete. | \xc2\xa0 | \xc2\xa0#2859 | \xc2\xa0\r\nIntrospective   training | I can   inspect the topics after training an LDA transform. Easy to find via   auto-complete. | \xc2\xa0 | \xc2\xa0#2859 | \xc2\xa0\r\nIntrospective   training | I can   inspect a categorical transform and see which feature values map to which key   values. Easy to find via auto-complete. | \xc2\xa0 | \xc2\xa0#2859 | \xc2\xa0\r\nIntrospective   training | I   can access the GAM feature histograms through APIs | \xc2\xa0 | #2859\xc2\xa0 | \xc2\xa0\r\nModel   files | I can   train a model and save it as a file. This model includes the learner as well   as the transforms   (e.g.   Decomposability) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nModel   files | I can   use a model file in a completely different process to make predictions.    (e.g.   Decomposability) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nModel   files | I can   use newer versions of ML.NET with ML.NET model files of previous versions   (for v1.x) | \xc2\xa0 | \xc2\xa0*test in V1.1* | \xc2\xa0\r\nModel   files | I can   easily figure out which NuGets (and versions) I need to score an ML.NET model | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nModel   files | P2: I   can move data between NimbusML and ML.NET (using IDV). Prepare with NimbusML   and load with ML.NET | \xc2\xa0 | \xc2\xa0*V1.1* | \xc2\xa0\r\nModel   files | P2: I   can use model files interchangeably between compatible versions of ML.NET and   NimbusML. | \xc2\xa0 | \xc2\xa0*V1.1* | \xc2\xa0\r\nModel files | P1: I   can export ML.NET models to ONNX (limited to the existing internal   functionality) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nModel files | I can   save a model to text | \xc2\xa0 | \xc2\xa0*V1.1* | \xc2\xa0\r\nPrediction | I can   get predictions (scores, probabilities, predicted labels) for every row in a   test dataset | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nPrediction | I can   reconfigure the threshold of my binary classification model based on analysis   of the PR curves or other metrics scores. | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/Prediction.cs) | \xc2\xa0 | \xc2\xa0#2465\r\nPrediction | (Might   not work?)   I can   map the score/probability for each class to the original class labels I   provided in the pipeline (multiclass, binary classification). | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nTasks | I can   train a model to do classification (binary and multiclass) | \xc2\xa0 | #2646 | \xc2\xa0\r\nTasks | I can   train a model to do regression | \xc2\xa0 | #2646 | \xc2\xa0\r\nTasks | I can   train a model to do anomaly detection | \xc2\xa0 | #2646  | \xc2\xa0\r\nTasks | I can   train a model to do recommendations | \xc2\xa0 | #2646  | \xc2\xa0\r\nTasks | I can   train a model to do ranking | \xc2\xa0 | #2646  | \xc2\xa0\r\nTasks | I can   train a model to do clustering | \xc2\xa0 | #2646  | \xc2\xa0\r\nTraining | I can   provide multiple learners and easily compare evaluation metrics between them. | \xc2\xa0 | #2921\xc2\xa0 | \xc2\xa0\r\nTraining | I can   use an initial predictor to update/train the model for some trainers (e.g.   linear learners like averaged perceptron). Specifically, start the weights   for the model from the existing weights. | \xc2\xa0 | \xc2\xa0#2921 | \xc2\xa0\r\nTraining | Metacomponents   smartly restrict their use to compatible components.   \xc2\xa0   Example:   ""When specifying what trainer OVA should use, a user will be able to   specify any binary classifier. If they specify a regression or multi-class   classifier ideally that should be a compile error."" | \xc2\xa0 | \xc2\xa0#2921 | \xc2\xa0\r\nTraining | I can   train TF models when I bring a TF model topology | \xc2\xa0 |  WIP Rogan\xc2\xa0 | \xc2\xa0\r\nTraining | I can   use OVA and easily add any binary classifier to it | \xc2\xa0 | \xc2\xa0#2921 | \xc2\xa0\r\nUse in   web environments | I can   use ML.NET models to make predictions in multi-threaded environments like   ASP.NET. (This doesn\'t have to be inherent in the prediction engine but   should be easy to do.) | \xc2\xa0 | \xc2\xa0 | \xc2\xa0\r\nValidation | Cross-validation:   I can take a pipeline and easily do cross validation on it without having to   know how CV works. | [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/Validation.cs)\xc2\xa0 | \xc2\xa0#2470 | \xc2\xa0\r\nValidation | I can   use a validation set in a pipeline for learners that support them (e.g.   FastTree, GAM) | \xc2\xa0 [Link](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Functional.Tests/Validation.cs) |\xc2\xa0#2503 | \xc2\xa0\r\n\r\n'"
408921384,2496,"b'""UnbalancedSets"" not available on FastTree in v0.10'",b'Somehow the ability to set UnbalancedSets flag on FastTree (at least) is gone from v 0.10 API.\r\n\r\nIt was available (via a delegate) in v0.90.'
408905116,2495,b'Create sample/test on ImageLoadingEstimator for TensorFlow scoring for loading an in-memory image stream (instead of files from the drive)',"b""Related to [this issue](https://github.com/dotnet/machinelearning/issues/2121), we need a clear/simple sample code/test for ImageLoadingEstimator for TensorFlow scoring so it loads an in-memory image stream as input (instead image files from a drive).\r\n\r\nI couldn't see a clear way to do it here (Mentioned by Gleb): https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/ImagesTests.cs\r\n"""
408581650,2492,b'Is custom preprocessing available?',"b""Hi,\r\n\r\nI am working on productivization of Keras's VGG16 model in C#. The VGG16's weights are adapted from Caffe and demands turning image into BGR and substracting mean of channels over dataset from the channels of pixel. If my explaination is not understandable, you can see the code [here](https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py) in the first else branch of _preprocess_numpy_input. \r\n\r\nIs there an option to do such thing in ML.NET? If not, is there an option to skip the graph definition of preprocessing steps and defining own preprocessing? If not, are there any plans for such feature?\r\n\r\nThanks"""
408550929,2490,b'How to use Options.TreeBooster.Arguments',"b'I currently have an ML.Net project based on version 0.10.0. As a starter into ML.Net  I\'am trying to remake one of my python ML projects into ML.Net.\r\n\r\nI\'am running on Windows 10 with .NET Core 3.0.100-preview-010184.\r\n\r\nI have a pipeline setup (and working) in the following way:\r\n\r\n`var pipeline = mlContext.Transforms.Concatenate(""Features"", ""Feat1"", ""Feat2"", ""Feat3"")\r\n                                                .Append(mlContext.BinaryClassification.Trainers.LightGbm(numLeaves: 200,\r\n                                                                                                        numBoostRound: 1000,\r\n                                                                                                        minDataPerLeaf: 200,\r\n                                                                                                        learningRate: 0.05,\r\n                                                                                                        labelColumn: ""Label""));`\r\n\r\nI would like to further specify the LightGBM parameters as are available in Options.TreeBooster.Arguments (specifically FeatureFraction and MaxDepth) but I can\'t figure out how it should be added or appended to the pipeline. Also I have not been able to find any samples or documentation.\r\n\r\nIs it possible to give me some information or clarification about this?'"
408527140,2489,b'Exception on ReadFromEnumerable with NULL values data',"b'### System information\r\n\r\n- **OS version/distro**:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.0.100-preview-009812\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoaded the [wine data](https://www.kaggle.com/rajyellow46/wine-quality) into a database and read data to use in `ReadFromEnumerable`\r\n\r\n- **What happened?**\r\nGot the below exception when loading the data into `ReadFromEnumerable`. I believe this is because there are null values within the data.\r\n\t```\r\n\tSystem.ArgumentOutOfRangeException: \'Could not determine an IDataView type for member \r\n\tParameter name: rawType\'\r\n\t```\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\nHave this ML.NET code:\r\n```\r\nvar dbData = ReadFromDatabase();\r\n\r\nvar context = new MLContext();\r\n\r\nvar mlData = context.Data.ReadFromEnumerable(dbData);\r\n```\r\n\r\nAnd a preview of `dbData` where I think it\'s failing at:\r\n```\r\n[\r\n  {\r\n    ""Type"": ""white"",\r\n    ""FixedAcidity"": null,\r\n    ""VolatileAcidity"": 1.0,\r\n    ""CitricAcid"": 0.0,\r\n    ""ResidualSugar"": 1.0,\r\n    ""Chlorides"": 0.0,\r\n    ""FreeSulfurDioxide"": 29.0,\r\n    ""TotalSulfureDioxide"": 75.0,\r\n    ""Density"": 1.0,\r\n    ""Ph"": 3.0,\r\n    ""Sulphates"": 0.0,\r\n    ""Alcohol"": 13.0,\r\n    ""Quality"": 8.0\r\n  }\r\n]\r\n```\r\n\r\nAlso, is this the correct way to handle missing data when reading from a database instead of from a CSV file? Or should I be handling it another way?'"
408519971,2488,b'ProductRecommander sample - System.AccessViolationException',"b""### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried the sample Product recommander with my own sample of product IDs. I first try it with the provided data (Amazon0302) and it works fine. Then I try a different file (which is attached).\r\n- **What happened?** An exception is throw at ITransformer model = est.Fit(traindata); System.AccessViolationException: 'Attempted to read or write protected memory. This is often an indication that other memory is corrupt.'\r\n- **What did you expect?** To not have this kind of exception at least (this is scary) and to be able to use a different sample than the one provided.\r\nI have the same error if, for example, I truncate the file Amazon0302 to only keep the first 10 lines.\r\n\r\n\r\n### Source code / logs\r\n[test_sample.txt](https://github.com/dotnet/machinelearning/files/2848725/test_sample.txt)\r\nI just downloaded the ProductRecommander sample and replace the variable TrainingDataLocation with my own file. I reproduced the problem on two machines (one with Win10, another one with Windows Server 2016, both with .net core 2.1)\r\n"""
408485549,2487,b'Cross-Validation API for v1.0',"b""Hi All,\r\n\r\nAs we approach v1.0, I thought it might be nice to look at the API for cross-validation. Currently, our cross-validation API takes the inputs:\r\n\r\n```cs\r\nIDataView data; // training data\r\nIEstimator<ITransformer> estimator; // Model to fit\r\nint numFolds; //Number of folds to make\r\nstring labelColumn; // The label\r\nstring stratificationColumn; // The column to stratify on\r\nseed; // The seed\r\n```\r\n\r\nand returns an array of\r\n```cs\r\nRegressionMetrics metrics;\r\nITransformer model;\r\nIDataView scoredTestData;\r\n```\r\nwith one entry for each fold.\r\n\r\nI have a few questions:\r\n\r\n1) Are we happy with the outputs?\r\nI'm not overly concerned with these, but it will be hard to make this list smaller as we go.\r\n2) Do we need to specify `labelColumn`?\r\nIsn't there a way to get the label from the model? Making this explicit means that we are allowing the learner and the CV metrics to utilize different labels.\r\n3) Are we using the right terminology for `stratification`?\r\nStratification usually means that ratios of classes are maintained across splits (see [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling) on wikipedia). Here, `stratification` means that items with the same value are clumped into the same split. The former makes sense if you want to maintain class ratios, especially with highly imbalanced classes, while the latter is useful for things like ranking (e.g. `groupIds`) or where leakage due to something like ordering may be a concern.\r\n\r\n"""
408418151,2486,b'StochasticDualCoordinateAscent not work For Multiclass after migrate to 0.10.0',"b'### System information\r\n\r\n- **OS version/distro**: W10\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Migrated my code from 0.9.0 to 0.10.0\r\n- **What happened?** StochasticDualCoordinateAscent Algorithm was working fine  for multi class and binary trainer  before move to 0.10 after updating its working only for binary and freeze on \r\ntrainingPipeline.Fit(trainingDataView); for Multiclass take a while \r\n- **What did you expect?**\r\nit should work fine \r\n### Source code / logs\r\n`var mlContext = new MLContext(seed: 1);\r\n\r\n#region ""STEP 1: Common data loading configuration""\r\n\r\n    IDataView trainingDataView = GetNormalDataSet(mlContext, allFeatures, mLFeatures);\r\n\r\n    if (trainingDataView.GetRowCount() == 0)\r\n    {\r\n\r\n        return;\r\n    }\r\n\r\n    textFeatures = GetTextFeatures(normalFeatures);\r\n\r\n    numericFeatures = GetNumericFeatures(normalFeatures).ToArray();\r\n\r\n#endregion\r\n\r\n#region ""STEP 2: Common data process configuration with pipeline data transformations""\r\n\r\n// STEP 2: Common data process configuration with pipeline data transformations\r\n\r\nvar textFeaturesProcessPipeline = mlContext.Transforms.Text.FeaturizeText(DefaultColumnNames.Features, textFeatures);\r\n\r\nvar numericFeaturesProcessPipeline = mlContext.Transforms.Concatenate(DefaultColumnNames.Features, numericFeatures);\r\n\r\nvar dataProcessPipeline = numericFeaturesProcessPipeline.Append(textFeaturesProcessPipeline).AppendCacheCheckpoint(mlContext);\r\n\r\n#endregion\r\n\r\n#region  ""STEP 3: Set the training algorithm, then create and configure the modelBuilder""  \r\n\r\nITransformer trainedModel = null;\r\n\r\n//""StochasticDualCoordinateAscent""\r\n\r\nvar trainingPipeline = mlContext.Transforms.Conversion.MapValueToKey(DefaultColumnNames.Label)\r\n   .Append(dataProcessPipeline)\r\n   .Append(mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: DefaultColumnNames.Label, featureColumn: DefaultColumnNames.Features))\r\n   .Append(mlContext.Transforms.Conversion.MapKeyToValue(DefaultColumnNames.PredictedLabel));\r\n\r\n#region STEP 4: Train the model fitting to the DataSet\r\n\r\n    //Take a while and no responce when call fit method\r\n\r\n    trainedModel = trainingPipeline.Fit(trainingDataView);\r\n\r\n#endregion`\r\n\r\n you can see some screen for values and when change from \r\n""StochasticDualCoordinateAscent"" to ""Naive Bayes"" Working fine\r\n\r\nwhat wrong on my code \r\n![image](https://user-images.githubusercontent.com/5037612/52519439-04c6cd00-2c64-11e9-9e11-64808c1d22cd.png)\r\n![image](https://user-images.githubusercontent.com/5037612/52519443-0b554480-2c64-11e9-9116-8d17f4ff02e1.png)\r\n![image](https://user-images.githubusercontent.com/5037612/52519455-2e7ff400-2c64-11e9-8e8c-bd0684ad988f.png)\r\n\r\nalso those my Data Structure Classes \r\n`[Serializable]\r\n    public class NormalTagsModelFeatures\r\n    {\r\n        //[Column(ordinal: ""0"", name: ""Label"")] public string Label;\r\n        [LoadColumn(0)]\r\n        public string Label;\r\n        [LoadColumn(1)]\r\n        public float fontSize;\r\n        [LoadColumn(2)]\r\n        public float isBold;\r\n        [LoadColumn(3)]\r\n        public float isItalic;\r\n        [LoadColumn(4)]\r\n        public float isUnderLine;\r\n        [LoadColumn(5)]\r\n        public float containsDot;\r\n        [LoadColumn(6)]\r\n        public float containsQuestionMark;\r\n        [LoadColumn(7)]\r\n        public string fontColor;\r\n        [LoadColumn(8)]\r\n        public float isAllCaps;\r\n        [LoadColumn(9)]\r\n        public string tagText;\r\n        [LoadColumn(10)]\r\n        public string firstWord;\r\n        [LoadColumn(11)]\r\n        public string FontName;\r\n        [LoadColumn(12)]\r\n        public float verticalText;\r\n        [LoadColumn(13)]\r\n        public float trdLeft;\r\n        [LoadColumn(14)]\r\n        public float trdRight;\r\n        [LoadColumn(15)]\r\n        public float trdTop;\r\n        [LoadColumn(16)]\r\n        public float trdBottom;\r\n        [LoadColumn(17)]\r\n        public float pageNo;\r\n\r\n    }\r\n\r\n    public class NormalTagsPrediction\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public string PredictedLabel;\r\n\r\n        [ColumnName(""Score"")]\r\n        public float[] Score { get; set; }\r\n\r\n    }`\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
408414358,2485,"b""CookBook sample - Could not find input column 'CategoricalOneHot'""","b'### System information\r\n\r\n- **OS version/distro**:Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  4.6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to follow the sample code from the GitHub article\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-do-i-train-my-model-on-categorical-data\r\nand get an understanding of how to get one-hot encoding to work\r\n- **What happened?**\r\nRun time error message - Could not find input column \'CategoricalOneHot\'\r\nParameter name: inputSchema\'\r\n\r\n- **What did you expect?**\r\nI expected the code to run without errors and then I should be able to examine how the data has been transformed\r\n\r\n### Source code / logs\r\n            // Build several alternative featurization pipelines.\r\n            var pipeline =\r\n                // Convert each categorical feature into one-hot encoding independently.\r\n                mlContext.Transforms.Categorical.OneHotEncoding(""CategoricalFeatures"", ""CategoricalOneHot"")\r\n                // Convert all categorical features into indices, and build a \'word bag\' of these.\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""CategoricalFeatures"", ""CategoricalBag"", Microsoft.ML.Transforms.Categorical.OneHotEncodingTransformer.OutputKind.Bag))\r\n                // One-hot encode the workclass column, then drop all the categories that have fewer than 10 instances in the train set.\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(""Workclass"", ""WorkclassOneHot""))\r\n                .Append(mlContext.Transforms.FeatureSelection.SelectFeaturesBasedOnCount(""WorkclassOneHot"", ""WorkclassOneHotTrimmed"", count: 10));\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n![image](https://user-images.githubusercontent.com/20245330/52518944-8c541200-2c4b-11e9-8b9c-0f0f12fb3b20.png)\r\n'"
408363212,2484,b'How about a Preview for Metadata?',"b'something like this?\r\n`DataDebuggerPreview Preview(this Metadata metadata, int maxRows = 100)`'"
408272304,2482,b'TreeEnsembleFeaturizer is not a Transformer yet',"b'[TreeEnsembleFeaturizer](\r\nhttps://github.com/dotnet/machinelearning/blob/6b1a0d337f74274509cfd439974dca2305a6bfbb/src/Microsoft.ML.FastTree/TreeEnsembleFeaturizer.cs#L44) is a very useful tool in many applications. Do we have a plan to make it publicly available?\r\n\r\ncc @shauheen, @Ivanidzo4ka, @TomFinley, @yaeldekel.\r\n'"
408165013,2480,b'Microsoft.ML.InternalCodeAnalyzer should use Microsoft.CodeAnalysis.Testing for harness setup',"b'As discussed in [in this PR](https://github.com/dotnet/machinelearning/pull/2434#discussion_r254508809), the tests for the internal code analyzer should make use of the facilities provided in `Microsoft.CodeAnalysis.Testing`.\r\n\r\nThat would make the test project more best-practice compliant and easier to maintain.'"
408161063,2479,b'How to normalize 2 columns simultaneously?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET 4.6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have loaded sample data from a text file and I am trying to normalize and print the normalized data\r\n- **What happened?**\r\nThe max normalized value was 1.0 which is expected. The min normalized value should have been 0 or -1 but it was another positive number < 1 and > 0\r\n- **What did you expect?**\r\n\r\n- The minimum of the normalized values should be between 0 and 1, or -1 and +1.  **Solved using fixZero=false**\r\n- I am confused whether I have taken the right programmatic approach\r\n\r\n### Source code / logs\r\n        [TestMethod]\r\n        public void Normalize_MultipleColumn()\r\n        {\r\n            string pathFull = System.IO.Path.Combine(Util.GetProjectDir2(), _datafile);\r\n            var mlContext = new Microsoft.ML.MLContext();\r\n            Microsoft.Data.DataView.IDataView dataView = LoadDummy2(mlContext, pathFull);\r\n            Trace.WriteLine(""Before normalization"");\r\n            EnumerOverData(mlContext, dataView);\r\n            var schema = dataView.Schema;\r\n\r\n            var pipeline_Ht_And_Wt = mlContext.Transforms.Normalize(\r\n                new Microsoft.ML.Transforms.Normalizers.NormalizingEstimator.MinMaxColumn(""Height""),\r\n                new Microsoft.ML.Transforms.Normalizers.NormalizingEstimator.MinMaxColumn(""Weight"")\r\n                );\r\n\r\n            var normalizedData = pipeline_Ht_And_Wt.Fit(dataView).Transform(dataView);\r\n            Trace.WriteLine(""After normalization"");\r\n            EnumerOverData(mlContext, normalizedData);\r\n        }\r\n        private IDataView LoadDummy2(MLContext mlContext, string pathFull)\r\n        {\r\n            var argsLoader = new Microsoft.ML.Data.TextLoader.Arguments();\r\n            argsLoader.HasHeader = true;\r\n            argsLoader.Separators = new char[] { \'|\' };\r\n            argsLoader.Column = new Microsoft.ML.Data.TextLoader.Column[]\r\n            {\r\n                new Microsoft.ML.Data.TextLoader.Column(""Id"", Microsoft.ML.Data.DataKind.I4,0),\r\n                new Microsoft.ML.Data.TextLoader.Column(""Height"", Microsoft.ML.Data.DataKind.R8,1),\r\n                new Microsoft.ML.Data.TextLoader.Column(""Weight"", Microsoft.ML.Data.DataKind.R8,2),\r\n                new Microsoft.ML.Data.TextLoader.Column(""IsOverWeight"", Microsoft.ML.Data.DataKind.Bool,3)\r\n            };\r\n\r\n            var loader = mlContext.Data.CreateTextLoader(argsLoader);\r\n            Microsoft.Data.DataView.IDataView dataView = loader.Read(pathFull);\r\n            return dataView;\r\n        }\r\n        private void EnumerOverData(MLContext mlContext, IDataView dataView)\r\n        {\r\n            var someRows = mlContext.CreateEnumerable<entity.Dummy2>(dataView, false);\r\n            foreach (var oRow in someRows)\r\n            {\r\n                System.Diagnostics.Trace.WriteLine($""id={oRow.Id}    wt={oRow.Weight}   ht={oRow.Height}  isOverWt={oRow.IsOverWeight}"");\r\n            }\r\n        }\r\n      \r\n### Before normalization\r\n    id|wt|ht|overwt\r\n    01|30.0|4.0|False\r\n    02|35.0|4.5|False\r\n    03|40.0|5.0|False\r\n    10|33.0|4.0|True\r\n    11|38.0|4.5|True\r\n    12|43.0|5.0|True\r\n\r\n### After normalization (fixZero=true)\r\n    id=1    wt=0.8   ht=0.697674418604651  \r\n    id=2    wt=0.9   ht=0.813953488372093  \r\n    id=3    wt=1   ht=0.930232558139535  \r\n    id=10    wt=0.8   ht=0.767441860465116  \r\n    id=11    wt=0.9   ht=0.883720930232558  \r\n    id=12    wt=1   ht=1  \r\n\r\n### After normalization (fixZero=false)\r\n    id=1    wt=0   ht=0  \r\n    id=2    wt=0.5   ht=0.384615384615385  \r\n    id=3    wt=1   ht=0.769230769230769  \r\n    id=10    wt=0   ht=0.230769230769231 \r\n    id=11    wt=0.5   ht=0.615384615384615  \r\n    id=12    wt=1   ht=1 \r\n\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
408095652,2478,b'Pipeline visualization please',"b""Can you add a way to generate a DOT graph of a pipeline, like [https://docs.microsoft.com/en-us/NimbusML/tutorials/c_a-visualize-a-pipeline](NimbusML) ?\r\n\r\nI tried to build it myself, but all the transformer's properties are being internalized.\r\nThanks\r\n"""
407987467,2477,b'Sample Breaks When Change Learner from FastTree to AveragedPerceptron',"b""@srsaggam and I were looking at the sentiment analysis sample:\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/blob/a79ced6c6bb788c2189d81e5993863e15cf8be0c/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis/SentimentAnalysis/SentimentAnalysisConsoleApp/Program.cs#L59\r\n\r\nWhen you change the learner from 'FastTree' to 'AveragedPerceptron', the sample throws the exception:\r\n```\r\nSystem.ArgumentOutOfRangeException: 'Probability column 'Probability' not found'\r\n```\r\nThis is probably because AveragedPerceptron is not calibrated, but FastTree is. Any thoughts on how to handle this scenario? We've successfully made use of PlattCalibratorEstimator, but I don't think this is supported b/c (1) it's not exposed / hanging off of MLContext, and (2) it takes an IPredictor"""
407967700,2474,b'Get tests passing on Mono and add Mono to CI',"b'@Anipik and others have been scouting Mono. \r\n\r\nAs soon as our tests pass on Mono, we should add it to CI to protect it.\r\n\r\nNote - the Mono build will need (at least) the fix for https://github.com/mono/mono/issues/12690\r\n'"
407967569,2473,b'GetColumn method is extension for IDataView but not mlContext.',"b'https://github.com/dotnet/machinelearning/issues/1708 moved CreateEnumerable from extension on top of DataView to become extension on mlContext object.\r\n\r\nWe still have GetColumn extension https://github.com/dotnet/machinelearning/blob/7fc7e50ce6f8fed24fc0b9528839a0ac8d0ed320/src/Microsoft.ML.Data/Utilities/ColumnCursor.cs#L25\r\nwhich works on top of DataView. Shall we move it to mlContext?\r\n\r\n`var enumerable = mlContext.CreateEnumerable<SamplesUtils.DatasetUtils.SampleTemperatureData>(filteredData, reuseRowObject: true);`\r\n`var originalColumnBack = transformedData_default.GetColumn<VBuffer<ReadOnlyMemory<char>>>(mlContext, defaultColumnName);`\r\n\r\nThey look silly together.\r\n'"
407950240,2472,b'Any reason for inconsistency in params for TextLoader?',"b""1) This Method :\r\nhttps://github.com/dotnet/machinelearning/blob/834e4715afa070f5e5c3628693682943b3f0bd6d/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L55\r\n\r\n2) and this one : \r\nhttps://github.com/dotnet/machinelearning/blob/834e4715afa070f5e5c3628693682943b3f0bd6d/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L22\r\n\r\nLooks like the first one has params like : \r\n```\r\nchar separatorChar = '\\t', bool allowQuotedStrings = true, bool supportSparse = true, bool trimWhitespace = false\r\n```\r\n\r\nWhere as the second one doesn't have those. In order to use those params there is another method overload : \r\n```\r\nCreateTextLoader(this DataOperationsCatalog catalog, TextLoader.Arguments args, IMultiStreamSource dataSample = null);\r\n```\r\n\r\nThis takes Arguments class and particularly one param is interesting in this Arguments:\r\n```\r\nchar [] Separators\r\n```\r\n Any reason this is char[] and not char like in other overloads? and why inconsistency in params for the methods 1) and 2).\r\n"""
407947315,2471,b'Missing support for Anomaly Detection metrics.',"b'ML.NET supports several evaluation metrics but is missing support for Anomaly Detection metrics.\r\n\r\nExample of supported metrics:\r\n- [BinaryClassificationMetrics](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Evaluators/Metrics/BinaryClassificationMetrics.cs)\r\n- [RegressionMetrics](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Evaluators/Metrics/RegressionMetrics.cs)\r\n\r\nIs anomaly detection a scenario we want to support for V 1.0 ?  If yes, we should probably add support for anomaly detection metrics\r\n\r\n@Ivanidzo4ka @sfilipi @shauheen @glebuk @artidoro \r\n\r\n'"
407935001,2469,b'Model produced by SdcaBinaryTrainer is not and can not be strongly-typed',"b'The [`CreatePredictor`](https://github.com/dotnet/machinelearning/blob/6ec3280fe62b34ab07e183cd5d9e5d2767dd0dcc/src/Microsoft.ML.StandardLearners/Standard/SdcaBinary.cs#L1550) function,\r\n```csharp\r\n        using TScalarPredictor = IPredictorWithFeatureWeights<float>;\r\n        ...\r\n        protected override TScalarPredictor CreatePredictor(VBuffer<float>[] weights, float[] bias)\r\n        {\r\n            ...\r\n            var predictor = new LinearBinaryModelParameters(Host, in maybeSparseWeights, bias[0]);\r\n            if (Info.NeedCalibration)\r\n                return predictor;\r\n            return new ParameterMixingCalibratedPredictor(Host, predictor, new PlattCalibrator(Host, -1, 0));\r\n        }\r\n```\r\n in `SdcaBinaryTrainer` can produce two different types depending on the specified loss function. To generate model in a type-safe manner, we need two trainers for the two possible model types. cc @TomFinley for visibility.'"
407929070,2468,b'Remove the dead code inside the FastTree assembly',b'The code inside src/Microsoft.ML.FastTree/Application is not in use. \r\n\r\nDelete the Folder. '
407926515,2467,b'OvaModelParameters is not strongly-typed',"b"" In the constructor of 'OvaModelParameters`,\r\n```csharp\r\n        using TScalarPredictor = IPredictorProducing<float>;\r\n        ...\r\n        internal static OvaModelParameters Create(IHost host,  OutputFormula outputFormula, TScalarPredictor[] predictors)\r\n        {\r\n        ...\r\n        }\r\n```\r\nwe remove the type information of predictors by forcing them to be `IPredictorProducing<float>`. To make all multi-class classifiers' outputting strongly-typed models. We need to make `OvaModelParameters` strongly-typed."""
407909145,2466,b'Displaying the records that have been loaded using TextLoader',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET 4.5\r\n\r\n### Issue\r\nI was trying to get a better understanding of loading records from a flat file. All I wanted to do was to access the records that have been loaded sequentially and display  them.\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\nThe code in the **while block** below is my attempt. **This worked well**. However, I am wondering if this is the right way to iterate over a cursor?  Is there anything simpler to get the individual column values? Feels a bit onerous.\r\n\r\n### Source code / logs\r\n        [TestMethod]\r\n        public void TestMethod1()\r\n        {\r\n            string datafile = @""Data\\Dummy2.csv"";\r\n            string pathFull = System.IO.Path.Combine(Util.GetProjectDir2(), datafile);\r\n            var argsLoader = new Microsoft.ML.Data.TextLoader.Arguments();\r\n            try\r\n            {\r\n                argsLoader.HasHeader = true;\r\n                argsLoader.Separators = new char[] { \'|\' };\r\n                argsLoader.Column = new Microsoft.ML.Data.TextLoader.Column[]\r\n                {\r\n                    new Microsoft.ML.Data.TextLoader.Column(""id"", Microsoft.ML.Data.DataKind.I4,0),\r\n                new Microsoft.ML.Data.TextLoader.Column(""ht"", Microsoft.ML.Data.DataKind.R4,1),\r\n                new Microsoft.ML.Data.TextLoader.Column(""wt"", Microsoft.ML.Data.DataKind.R4,2),\r\n                new Microsoft.ML.Data.TextLoader.Column(""overwt"", Microsoft.ML.Data.DataKind.Bool,3)\r\n                };\r\n                var mlContext = new Microsoft.ML.MLContext();\r\n                var loader = mlContext.Data.CreateTextLoader(argsLoader);\r\n                Microsoft.Data.DataView.IDataView dataView = loader.Read(pathFull);\r\n                var schema = dataView.Schema;\r\n                Microsoft.Data.DataView.RowCursor cur = dataView.GetRowCursor(schema);\r\n                while (cur.MoveNext())\r\n                {\r\n                    System.Diagnostics.Trace.WriteLine($""got a row, position={cur.Position}"");\r\n                    ///\r\n                    /// Column 0\r\n                    ///\r\n                    Microsoft.Data.DataView.ValueGetter<int> getter = cur.GetGetter<int>(0);\r\n                    int id = 0;\r\n                    getter.Invoke(ref id);\r\n                    ///\r\n                    /// Column 1\r\n                    ///\r\n                    Microsoft.Data.DataView.ValueGetter<float> getterWt = cur.GetGetter<float>(1);\r\n                    float wt = 0;\r\n                    getterWt.Invoke(ref wt);\r\n                    ///\r\n                    /// Column 3\r\n                    ///\r\n                    Microsoft.Data.DataView.ValueGetter<bool> getterIsOverWt = cur.GetGetter<bool>(3);\r\n                    bool isOverWt = false;\r\n                    getterIsOverWt.Invoke(ref isOverWt);\r\n\r\n                    System.Diagnostics.Trace.WriteLine($""id={id}    wt={wt}    isOverWt={isOverWt}"");\r\n                }\r\n\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                System.Diagnostics.Trace.WriteLine(ex.ToString());\r\n            }\r\n        }\r\n/*\r\nid|wt|ht|overwt\r\n01|30.0|4.0|False\r\n02|35.0|4.5|False\r\n03|40.0|5.0|False\r\n10|33.0|4.0|True\r\n11|38.0|4.5|True\r\n12|43.0|5.0|True\r\n\r\n*/\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
407873363,2465,b'Cannot set the threshold on a binary predictor',"b'It is no longer possible to set a custom `Threshold` and `ThresholdColumn` on a binary classifier.\r\n\r\nPreviously, we had been using `BinaryPredictionTransformer`. Recently, `BinaryPredictionTransformer` was marked as `internal` and is no longer available for usage outside of the library.\r\n\r\nRelated to question #403'"
407856732,2464,b'BinaryPredictionTransformer has a public constructor',"b'`BinaryPredictionTransformer` has a `public` constructor of the form:\r\n```cs\r\nBinaryPredictionTransformer(IHostEnvironment env, ModelLoadContext ctx)\r\n```\r\n\r\nSince the usable constructor\r\n```cs\r\nBinaryPredictionTransformer(IHostEnvironment env, TModel model, Schema inputSchema, string featureColumn, float threshold = 0f, string thresholdColumn = DefaultColumnNames.Score)\r\n```\r\nis marked `internal`, it seems like the one taking a `ModelLoadContext` should be too.'"
407855783,2463,b'ConvertToOnnx throws Protobuf exception',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro 1809 17763.253\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.0 and 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Added ML.NET.Onnx NuGet package to any official sample, and a call to ConvertToOnnx.\r\n- **What happened?** Exception: Sequence contained null element / Parameter: values / Google.Protobuf\r\n\r\n- **What did you expect?** A successful conversion in at least one of the samples\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nExample from the Clustering_CustomerSegmentation sample (inserted after step 6):\r\nvar onnx = mlContext.Model.ConvertToOnnx(trainedModel, pivotDataView);\r\n\r\nSame behavior is experienced in all the samples that I opened (and downgraded to v0.9).\r\n\r\n![onnxexception](https://user-images.githubusercontent.com/9828352/52436561-e69e8700-2b14-11e9-8851-324dfc95dbef.png)\r\n'"
407813277,2462,b'ScoreTensorFlowModel does not produce the expected results',"b'### System information\r\n\r\n- **OS version/distro**: Win10-x64 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: dotnet SDK 2.1.402\r\n\r\nvisual Studio 15.8.4\r\n\r\n### Issue\r\n`ScoreTensorFlowModel` does not produce the expected results from a pre-trained network\r\n- **What did you do?**\r\nI trained a [regression model](https://colab.research.google.com/drive/1kuR3ugh-EOXcNXz_Qglt06MQQQkA2Mmp) and saved the full model as an h5 file. Then i load the file and convert it to a pb file. Then the pb file was fed to an ML.NET project.\r\n\r\n- **What happened?**\r\nThe predicted results from ML.NET project are not the same with the predicted results in TensorFlow notebook.\r\n- **What did you expect?**\r\nto get the same results.\r\n### Source code / logs\r\nthe C# code was:\r\n\r\n```csharp    \r\n    class Program\r\n    {\r\n        static string dataset = Path.Combine(Directory.GetCurrentDirectory(), ""mpg.txt"");\r\n        static string pbModel = Path.Combine(Directory.GetCurrentDirectory(), ""fromh5.pb"");\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext(); \r\n\r\n            string dataFile = File.ReadAllText(dataset);\r\n            // Creating a data reader, based on the format of the data\r\n            var reader = TextLoaderStatic.CreateReader(mlContext, c => (\r\n                        index: c.LoadFloat(0),  //it is irrelevant with inputs or output\r\n                        dense_input_1: c.LoadFloat(1, 9)),\r\n                        separator: \'\\t\', hasHeader: true);\r\n\r\n            // Read the data\r\n            var data = reader.Read(new MultiFileSource(dataset));\r\n\r\n            var estimator = mlContext.Transforms.ScoreTensorFlowModel(\r\n                                    pbModel,\r\n                                    new string[] { ""dense_2_1/BiasAdd"" },\r\n                                    new string[] { ""dense_input_1"" });\r\n\r\n            var model = estimator.Fit(data.AsDynamic);\r\n            var predictionMachine = model.CreatePredictionEngine<InputData, OutputData>(mlContext);\r\n            var inputs = mlContext.CreateEnumerable<InputData>(data.AsDynamic, reuseRowObject: false).ToArray();\r\n            for (int i = 0; i < inputs.Length; i++)\r\n            {\r\n                var predictedLabel = predictionMachine.Predict(inputs[i]);\r\n                for (int j = 0; j < inputs[i].Features.Length; j++)\r\n                {\r\n                    Console.Write(inputs[i].Features[j]);\r\n                    Console.Write("" "");\r\n                }\r\n                Console.WriteLine(predictedLabel.Output[0]);\r\n            }\r\n\r\n        }\r\n    }\r\n\r\n    class InputData\r\n    {\r\n        [ColumnName(""dense_input_1""), VectorType(9)]\r\n        public float[] Features { get; set; }\r\n    }\r\n\r\n    class OutputData\r\n    {\r\n        [ColumnName(""dense_2_1/BiasAdd""), VectorType(1)]\r\n        public float[] Output { get; set; }\r\n    }\r\n```\r\n\r\nThe inputs which were used for prediction were read from `mpg.txt` file with contents:\r\n\r\n```\t\r\n         Cylinders \tDisplacement \tHorsepower \tWeight \tAcceleration \tModel Year \tUSA \tEurope \tJapan\r\n9 \t1.483887\t 1.865988 \t2.234620\t1.018782\t-2.530891 \t-1.604642 \t0.774676 \t-0.465148 \t-0.495225\r\n25 \t1.483887 \t1.578444 \t2.890853 \t1.925289 \t-0.559020 \t-1.604642 \t0.774676 \t-0.465148 \t-0.495225\r\n28 \t1.483887 \t1.041693 \t2.313368 \t2.063931 \t1.054328 \t-1.604642 \t0.774676 \t-0.465148 \t-0.495225\r\n31 \t-0.869348 \t-0.789008 \t-0.259066 \t-0.903250 \t-0.559020 \t-1.332580 \t-1.286751 \t-0.465148 \t2.012852\r\n33 \t0.307270 \t0.351586 \t-0.127819 \t-0.422150 \t-0.917542 \t-1.332580 \t0.774676 \t-0.465148 \t-0.495225\r\n39 \t1.483887 \t1.961837 \t1.840880 \t1.746357 \t-1.455325 \t-1.332580 \t0.774676 \t-0.465148 \t-0.495225\r\n40 \t1.483887 \t1.492180 \t1.263395 \t1.379015 \t-0.738281 \t-1.332580 \t0.774676 \t-0.465148 \t-0.495225\r\n43 \t1.483887 \t1.961837 \t1.709634 \t2.080521 \t-1.276064 \t-1.332580 \t0.774676 \t-0.465148 \t-0.495225\r\n48 \t0.307270 \t0.524113 \t-0.442811 \t0.176263 \t-0.379759 \t-1.332580 \t0.774676 \t-0.465148 \t-0.495225\r\n54 \t-0.869348 \t-1.181986 \t-0.941548 \t-1.632011 \t0.875068 \t-1.332580 \t-1.286751 \t-0.465148 \t2.012852\r\n```\r\n\r\nThe pb file is:\r\n[pbfile](https://user-images.githubusercontent.com/31559543/52429060-05e4e680-2b0c-11e9-8a15-59e04c24ffc8.jpg)\r\n\r\nPredicted results :\r\n```15.770189 ,  8.624239 ,  7.2484765, 24.726585 , 21.833643 , 12.528247 , 13.377004 , 12.101825 , 20.065805 , 32.288208```\r\n\r\nPredicted results from ML.NET:\r\n```-0.5800864, -0.775505, -0.7530465, -0.1452617, -0.2986267, -0.6405546, -0.4707591, -0.6763195, -0.1432758, -0.2586956```'"
407810071,2461,b'The method Read of TextLoader does not check for the presence of the file.',"b'### System information\r\n\r\n- **OS version/distro**:Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET 4.6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\nThe method Read of the class TextLoader does not validate the presence of the input file. I understand that there is an element of lazy loading here. But, it would help to get feedback earlier in the form of System.IO.FileNotFoundException\r\n\r\n'"
407801948,2460,b'Modify API for FeaturizeText ?',"b'In the MLContext for the text featurizer, the input column names are taken as a IEnumerable<string>\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/834e4715afa070f5e5c3628693682943b3f0bd6d/src/Microsoft.ML.Transforms/Text/TextCatalog.cs#L43-L46\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/2394#discussion_r254357200   recommends making them params instead.   \r\n\r\nShould we modify this API ?\r\n\r\n@sfilipi '"
407733950,2459,b'Is there any end to end C# sample code using LightGBM  ?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  4.6\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
407727494,2458,b'TensorFlowTransformer is not properly matching the input dimensions',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10/Pro\r\n- **.NET Version (eg., dotnet --info)**: .NET Version 2.1.202\r\n- ML.TensorFlow Version 0.10\r\n\r\n### Issue\r\n\r\n- **What did you do?**: Executed a TensorFlow model using TensorFlowEstimator\r\n- **What happened?**: Mapper does not properly match the input dimensions to the TensorFlow model dimensions\r\n- **What did you expect?**: Properly matched dimensions\r\n\r\n### Source code / logs\r\n\r\nTensorFlowTransform.cs, Lines 810 - 875\r\n\r\nLine 853:\r\n\r\nvar d = originalShape.NumDimensions > 2 ? Math.Pow(typeValueCount / valCount, 1.0 / (originalShape.NumDimensions - 2)) : 1;\r\n\r\nThe case with 2 dimensions, where the originalShape is [1, ?] is not matched properly.'"
407707792,2457,b'No sample code! ',"b'There used to be a MSDN , a long time ago. There used to code snippets which made learning so easy. I understand you have GitHub. But, you could provide links to make the user journey more comfortable.\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 022855f3-11d3-616c-f742-51e109c739d3\n* Version Independent ID: fc02b6bb-c669-5081-f891-71d8e911834b\n* Content: [TextLoader.Read Method (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.textloader.read?view=ml-dotnet#Microsoft_ML_Data_TextLoader_Read_System_String_)\n* Content Source: [dotnet/xml/Microsoft.ML.Data/TextLoader.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/TextLoader.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
407680241,2456,"b'support for ""autoconstructive evolution"" & Genetic Programming (GP)'","b'what about support for these?:\r\n\r\nhttps://en.wikipedia.org/wiki/Autoconstructive_evolution\r\n\r\nIn the ""autoconstructive evolution"" approach to meta-genetic programming, the methods for the production and variation of offspring are encoded within the evolving programs themselves, and programs are executed to produce new programs to be added to the population.[45][46]\r\nhttps://en.wikipedia.org/wiki/Genetic_programming#Meta-genetic_programming\r\n\r\nthanks'"
407562064,2455,b'FastForest learning rate not settable thru options object',b'Learning rate for FastForest is not settable thru options object\r\n\r\nThis issue also appears as one of the later comments in this issue: https://github.com/dotnet/machinelearning/issues/1983'
407553549,2454,b'OneHotEncodingTransformer inputs?',"b""The OneHotEncodingTransformer object does not provide properties to get the constructor's parameters back (e.g. input column)"""
407524418,2452,b'DataOperationsCatalog SaveAsText extension method is evil',"b'I was attempting to migrate some of our tests, when I discovered we have a few problems in our new API on text saving. I know @artidoro had some thoughts on text saving/loading so mentioning him. Also I know @sfilipi and @rogancarr are handling many issues w.r.t. API completeness and consistency as they work on samples and docs, so maybe they have some thoughts on this. (Of course everyone is free to chime in.)\r\n\r\nFrom what I can see, whoever authored this method confused the defaults with the text *loader* and the text *saver*. (Note how the defaults used in the text saving utility method are coming from `TextLoader`, which is incorrect.) It might seem intuitive if you don\'t think about it too hard that text saving and loading should have the same defaults, but practically it becomes clear they should not. The situations where one is ""loading"" into ML.NET and ""saving"" out of ML.NET are in fact very different situations. When someone is using a text loader ***with non-default settings*** they\'re usually asking us to ingest *their* format (so we chose the most helpful defaults for that more common scenario), whereas our text saver makes some attempt at schema. (Note also that under default settings, the text loader loads our own format without trouble, since it detects that a schema and settings is embedded in the file itself.)\r\n\r\nThis is the offending method:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e192a18d553a71ded3728495e9aaf4349169290d/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderSaverCatalog.cs#L147-L153\r\n\r\nAs point of reference, this is that constant:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e192a18d553a71ded3728495e9aaf4349169290d/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L401\r\n\r\nNow, compare this with the *actual* defaults on our text saver:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e192a18d553a71ded3728495e9aaf4349169290d/src/Microsoft.ML.Data/DataLoadSave/Text/TextSaver.cs#L28-L43\r\n\r\n* The default for whether header row is saved has gone from `true` to `false`. The primary practical effect of this is, we\'re now dropping feature names (or more precisely, slot names) by default. This seems silly. Feature names are *important*. I think we ought to keep them by default.\r\n\r\n* We\'ve lost the ability to force saving as dense format *at all* through this new API. This is often important for comprehensibility.\r\n\r\nI ran into it while I was trying to clean up some of our tests to use more of the actual public surface. Consider this test.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e192a18d553a71ded3728495e9aaf4349169290d/test/Microsoft.ML.Tests/Transformers/ConcatTests.cs#L133-L138\r\n\r\nThat\'s kind of obnoxious, and not using our public API. I\'d love to migrate it over to something like this:\r\n\r\n```csharp\r\nusing (var fs = File.Create(outputPath)) \r\n    ML.Data.SaveAsText(data, fs, keepHidden: false, forceDense: true);\r\n```\r\n\r\nBut I can\'t specify equivalent settings because there\'s no way to force dense.\r\n\r\n***So I suggest this:*** we change the defaults of this text *saving* utility function to use the text *saver* defaults, instead of the text loader defaults, and also restore the ability to force a dense format.\r\n\r\n## Why forcing dense is kind of useful sometimes...\r\n\r\nIt may not be obvious why forcing to dense is kind of useful. So imagine this input file `foo.txt`.\r\n\r\n```\r\n1,2,3,4,5,6\r\n0,0,1,0,0,0\r\n```\r\n\r\nThen imagine I have this MML command line:\r\n\r\n    dotnet MML.dll savedata loader=text{sep=comma} data=foo.txt dout=foo1.txt\r\n\r\nThe resulting `foo1.txt` file is this:\r\n\r\n```\r\n#@ TextLoader{\r\n#@   header+\r\n#@   sep=tab\r\n#@   col=Label:R4:0\r\n#@   col=Features:R4:1-5\r\n#@ }\r\nLabel   5       0:""""\r\n1       2       3       4       5       6\r\n6       2:1\r\n```\r\n\r\nWhat is that `6 2:1` line? It is encoding the information that this line has 6 fields, and the field at index 2 is the only one with a non-default value. That is, it has detected, ""hey, this can be sparsely encoded,"" and it has done so. Similarly with this seemingly crazy `Label   5       0:""""` line. But sometimes we find that confusing!! I\'ve spent over the years probably, cumulatively, *days* trying to explain the ins and outs of the mixed sparse/dense format. So we have this setting to say, ""you know what, I don\'t care about efficient, give me a dense format.""\r\n\r\n    dotnet MML.dll savedata loader=text{sep=comma} data=foo.txt dout=foo2.txt saver=text{dense+}\r\n\r\nThe result is this:\r\n\r\n```\r\n#@ TextLoader{\r\n#@   header+\r\n#@   sep=tab\r\n#@   col=Label:R4:0\r\n#@   col=Features:R4:1-5\r\n#@ }\r\nLabel   """"      """"      """"      """"      """"\r\n1       2       3       4       5       6\r\n0       0       1       0       0       0\r\n```\r\n\r\nLess efficient? Sure. Eaier to understand? I\'d say so. And lots of our tests use it, since our tests are usually writing small amounts of data and we found comprehensibility of test files to be valuable.'"
407472887,2447,b'ValueMapping Documentation missing bullets in the remarks section',"b'The remarks section for ValueMappingTransform contains a list that does not render to the HTML. This is due to a missing type on the this list element:\r\nCurrently its this:\r\n``\r\nExamples for using a ValueMappingEstimator are:\r\n<list>\r\n...\r\n</list>\r\n``\r\n\r\nExpected is this:\r\n``\r\nExamples for using a ValueMappingEstimator are:\r\n<list type=""bullet"">\r\n...\r\n</list>\r\n``\r\n'"
407469954,2446,b'Updating LightGBM to version 2.2.3',"b'LightGBM has been updated to version 2.2.3, ml.net references 2.2.1.1. \r\n\r\nCreating this issue to update ml.net to the latest version of LightGBM.'"
407466897,2445,"b'Inventory of the Microsoft.ML public types: what to rename, move, hide there. '","b""This is the list of the types in the Microsoft.ML namespace, as seen from the docs site.  Taking a first pass at what doesn't need to be there, what needs to be hidden, and what needs to be moved to a different namespace. \r\n\r\nMicrosoft.ML namespace type | Rename/Move/Hide |\r\n--------------------------- | --------- |\r\nBinaryClassificationCatalog |    | \r\nBinaryClassificationCatalog.BinaryClassificationTrainers|    | \r\nBinaryClassificationMetricsStatistics|    | \r\nBinaryLoaderSaverCatalog|    | \r\nCategoricalCatalog|    | \r\nChannelMessage |   move to Microsoft.ML.Data | \r\nChannelMessageKind|  move to Microsoft.ML.Data | \r\nClusteringCatalog|    | \r\nClusteringCatalog.ClusteringTrainers|    | \r\nComponentCatalog|  move to Microsoft.ML.Core | \r\nConversionsCatalog|    | \r\nConversionsExtensionsCatalog|    | \r\nCustomMappingCatalog|    | \r\nDataOperationsCatalog|    | \r\nDataReaderExtensions|    | \r\nDebuggerExtensions|    | \r\nExplainabilityCatalog |    | \r\nExpLoss | move  to Microsoft.ML.Trainers.Loss | \r\nExpLoss.Arguments |  move  to Microsoft.ML.Trainers.Loss | \r\nExtensionsCatalog |    | \r\nFactorizationMachineExtensions |    | \r\nFeatureSelectionCatalog |    | \r\nHalLearnersCatalog |    | \r\nHingeLoss |  move to Microsoft.ML.Trainers.Loss | \r\nHingeLoss.Arguments |  move to Microsoft.ML.Trainers.Loss | \r\nIChannel |  move to Microsoft.ML.Data | \r\nIChannelProvider |  move to Microsoft.ML.Data | \r\nIClassificationLoss |  move to Microsoft.ML.Trainers.Loss | \r\nIComponentFactory | move to Microsoft.ML.Data | \r\nIComponentFactory<TComponent> | move to Microsoft.ML.Data | \r\nIComponentFactory<TArg1,TComponent> |  move to Microsoft.ML.Data | \r\nIComponentFactory<TArg1,TArg2,TComponent> |  move to Microsoft.ML.Data | \r\nIComponentFactory<TArg1,TArg2,TArg3,TComponent> |  move to Microsoft.ML.Data | \r\nIExceptionContext |  move to Microsoft.ML.Core | \r\nIFileHandle | move to Microsoft.ML.Data | \r\nIHost |  move to Microsoft.ML.Data  | \r\nIHostEnvironment |  move to Microsoft.ML.Data  | \r\nILossFunction<TOutput,TLabel> | move  to Microsoft.ML.Trainers.Loss | \r\nImageEstimatorsCatalog |    | \r\nIParameterValue |  move  to Microsoft.ML.Sweeper| \r\nIParameterValue<TValue> |   move  to Microsoft.ML.Sweeper| \r\nIPipe<TMessage> |  move  to Microsoft.ML.Data | \r\nIPredictionTransformer<TModel> |    | \r\nIPredictor |    | \r\nIPredictorProducing<TResult> |    | \r\nIProgressChannel | move  to Microsoft.ML.Data   | \r\nIProgressChannelProvider |  move  to Microsoft.ML.Data  | \r\nIProgressEntry | move  to Microsoft.ML.Data   | \r\nIRegressionLoss |  move  to Microsoft.ML.Trainers.Loss  | \r\nIRunResult |   move  to Microsoft.ML.Sweeper | \r\nIRunResult<T> |   move  to Microsoft.ML.Sweeper | \r\nIScalarOutputLoss |  move to Microsoft.ML.Trainers.Loss | \r\nISingleFeaturePredictionTransformer<TModel> |    | \r\nISupportClassificationLossFactory |   move to Microsoft.ML.Trainers.Loss| \r\nISupportRegressionLossFactory |   move to Microsoft.ML.Trainers.Loss| \r\nISupportSdcaClassificationLoss |  move to Microsoft.ML.Trainers.Loss| \r\nISupportSdcaClassificationLossFactory |   move to Microsoft.ML.Trainers.Loss| \r\nISupportSdcaRegressionLossFactory |    move to Microsoft.ML.Trainers.Loss| \r\nISweeper |  move  to Microsoft.ML.Sweeper| \r\nISweepResultEvaluator<TResults> |  move  to Microsoft.ML.Sweeper| \r\nIValueGenerator |  move  to Microsoft.ML.Sweeper| \r\nKMeansClusteringExtensions |    | \r\nLearningPipelineExtensions |    | \r\nLightGbmExtensions |    | \r\nLoggingEventArgs |    | \r\nLogLoss |   move to Microsoft.ML.Trainers.Loss | \r\nLogLossFactory |  move to Microsoft.ML.Trainers.Loss | \r\nMessageSensitivity |  move to Microsoft.ML.Data | \r\nMetricsStatisticsBase<T> |  move to Microsoft.ML.Data | \r\nMetricStatistics |  move to Microsoft.ML.Data  | \r\nMLContext |    | \r\nModelOperationsCatalog |    | \r\nModelOperationsCatalog.ExplainabilityTransforms |    | \r\nModelOperationsCatalog.SubCatalogBase |    | \r\nMulticlassClassificationCatalog |    | \r\nMulticlassClassificationCatalog.MulticlassClassificationTrainers |    | \r\nMultiClassClassifierMetricsStatistics |  move to Microsoft.ML.Data  | \r\nNormalizerCatalog |    | \r\nOnnxCatalog |    | \r\nOnnxExportExtensions |    | \r\nParameterSet |   move to Microsoft.ML.Sweeper  | \r\nPcaCatalog |    | \r\nPermutationFeatureImportanceExtensions |  move to Microsoft.ML.Data  | \r\nPoissonLoss |  move to Microsoft.ML.Trainers.Loss  | \r\nPoissonLossFactory |   move to Microsoft.ML.Trainers.Loss | \r\nPredictionEngine<TSrc,TDst> |    | \r\nPredictionEngineBase<TSrc,TDst> |    | \r\nPredictionEngineExtensions |    | \r\nPredictionKind |    | \r\nProgressHeader |  move  to Microsoft.ML.Data | \r\nProjectionCatalog |    | \r\nQuantileStatistics |  move to Microsoft.ML.Data   | \r\nRankerMetricsStatistics |  move to Microsoft.ML.Data  | \r\nRankingCatalog |    | \r\nRankingCatalog.RankingTrainers |    | \r\nRecommendationCatalog |    | \r\nRecommendationCatalog.RecommendationTrainers |    | \r\nRecommenderCatalog |    | \r\nRegressionCatalog |    | \r\nRegressionCatalog.RegressionTrainers |    | \r\nRegressionMetricsStatistics | move to Microsoft.ML.Data   | \r\nRunMetric |   move  to Microsoft.ML.Sweeper | \r\nRunResult |  move  to Microsoft.ML.Sweeper | \r\nSignatureClassificationLoss |  move to Microsoft.ML.Trainers.Loss | \r\nSignatureRegressionLoss |  move to Microsoft.ML.Trainers.Loss | \r\nSignatureSuggestedSweepsParser |  move  to Microsoft.ML.Sweeper | \r\nSignatureSweeper |  move  to Microsoft.ML.Sweeper | \r\nSignatureSweepResultEvaluator |  move  to Microsoft.ML.Sweeper  | \r\nSimpleFileHandle |  move to Microsoft.ML.Data | \r\nSmoothedHingeLoss |   move to Microsoft.ML.Trainers.Loss | \r\nSmoothedHingeLoss.Arguments |  move to Microsoft.ML.Trainers.Loss | \r\nSquaredLoss | move to Microsoft.ML.Trainers.Loss | \r\nSquaredLossFactory |  move to Microsoft.ML.Trainers.Loss | \r\nStandardLearnersCatalog |    | \r\nTensorflowCatalog |    | \r\nTextCatalog |    | \r\nTextLoaderSaverCatalog |    | \r\nTrainCatalogBase |    | \r\nTrainCatalogBase.CatalogInstantiatorBase |  hide  | \r\nTrainerInfo |    | \r\nTransformExtensionsCatalog |    | \r\nTransformsCatalog |    | \r\nTransformsCatalog.CategoricalTransforms |    | \r\nTransformsCatalog.ConversionTransforms |    | \r\nTransformsCatalog.FeatureSelectionTransforms |    | \r\nTransformsCatalog.ProjectionTransforms |    | \r\nTransformsCatalog.SubCatalogBase |    | \r\nTransformsCatalog.TextTransforms |    | \r\nTreeExtensions |    | \r\nTweedieLoss |  move to Microsoft.ML.Trainers.Loss | \r\nTweedieLoss.Arguments |   move to Microsoft.ML.Trainers.Loss | \r\n\r\ncc @yaeldekel @TomFinley @glebuk  see if any of my suggestions need to change. \r\nFor the cases marked with `move`, where should they live?"""
407452712,2444,b'FastTree does not work in UWP',"b""### System information\r\n\r\n- **OS version/distro**: Windows UWP app\r\n- **.NET Version (eg., dotnet --info)**:  UWP\r\n\r\n### Issue\r\n\r\nFastTree is currently always attempting to `PrintMemoryStats` during training. This is an issue on some platforms (specifically UWP) because these APIs throw exceptions.\r\n\r\nWe should at least have a way to disable these stats when on platforms that don't support it.\r\n\r\n- **What did you do?**\r\n\r\nTry to train a FastTree model in a UWP app.\r\n\r\n- **What happened?**\r\n\r\nA `PlatformNotSupportedException` was thrown from the following method:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/6b1a0d337f74274509cfd439974dca2305a6bfbb/src/Microsoft.ML.FastTree/FastTree.cs#L458-L483\r\n\r\n- **What did you expect?**\r\n\r\nI expected FastTree to work inside a UWP app.\r\n\r\n### Source code / logs\r\n\r\nOn UWP apps, you can't get certain information about local processes - it throws an exception:\r\n\r\n```\r\nSystem.PlatformNotSupportedException: Retrieving information about local processes is not supported on this platform.\r\n   at System.Diagnostics.NtProcessInfoHelper.GetProcessInfos(Predicate`1 processIdFilter)\r\n   at System.Diagnostics.ProcessManager.GetProcessInfo(Int32 processId, String machineName)\r\n   at System.Diagnostics.Process.EnsureState(State state)\r\n   at System.Diagnostics.Process.get_WorkingSet64()\r\n```\r\n"""
407446429,2443,b'Very scanty documentation - ',b'No sample code. What value is this page providing?\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 2c4f07b9-e625-aa2e-940a-69bedbe67a3b\n* Version Independent ID: 1f4fe341-3c68-bc18-06d2-480c6283a609\n* Content: [LightGbm Class (Microsoft.ML.LightGBM)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbm.lightgbm?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.LightGBM/LightGbm.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.LightGBM/LightGbm.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
407433163,2440,"b'Add ""Row"" to the title of ambiguous DataOperations catalog members'","b'Certain operations in the `DataOperations` catalog are as to whether they operate on rows, columns, or slots. I suggest renaming the `FilterBy...`s and `Shuffle` to have `Rows` after the verb (e.g. `FilterRowsBy...`), similar to how we named `SkipRows` and `TakeRows`.'"
407421102,2438,b'We need documentation describing how to use the explainability features in ML.NET',"b'We have some great explainability features in ML.NET, but they are hidden here and there. It would be great to have an explainability doc, similar to the [ML.NET Cookbook](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md), that showed how to use these features and what they do.'"
407383688,2437,b'VariableVectorType attribute',"b""`VectorType(0)` is currently used to designate a variable in a type as variable length vector e.g.\r\n\r\n``` csharp\r\npublic class IMDBSentiment\r\n{\r\n    public string Sentiment_Text { get; set; }\r\n\r\n    /// <summary>\r\n    /// This is a variable length vector designated by VectorType(0) attribute.\r\n    /// Variable length vectors are produced by applying operations such as 'TokenizeWords' on strings\r\n    /// resulting in vectors of tokens of variable lengths.\r\n    /// </summary>\r\n    [VectorType(0)]\r\n    public int[] VariableLenghtFeatures { get; set; }\r\n}\r\n```\r\n\r\nThis seems not very intuitive. Can we have attribute type that can be specifically used to designed variable length vectors? such as `VariableVectorType`"""
407175873,2433,"b""NimbusML's dot_export_pipeline for c#""","b'How can I access the list of estimators inside a pipeline?\r\nI can see it as _estimators in the ""Non-Public"" area of the Locals window when I debug.\r\nI\'m trying to display the pipeline graphically (from c#) similar to the way NimbusML does\r\n\r\nfrom nimbusml.utils.exports import dot_export_pipeline\r\ndot_vis = dot_export_pipeline(pipeline, stream)\r\nprint(dot_vis)\r\n\r\nI\'m stuck at how to navigate the pipeline.'"
407057097,2430,b'BoostrapSample not in Data catalog',b'mlcontext.Data.BoostrapSample does not exists (from your samples)'
407003246,2425,b'We have zero tests for OnlineGradientDescent',"b'While looking into https://github.com/dotnet/machinelearning/issues/2407 I found we have only one test which indirectly touches OGD, `TestPfiRegressionOnDenseFeatures` we have zero tests with baselines (well we have them, but they marked as skipped)'"
406982910,2423,b'Unable to find TensorFlow dll',"b""### System information\r\n\r\n- **OS version/distro**: Win7-x64\r\n- **.NET Version (eg., dotnet --info)**: NET.Core SDK 2.1.502 and project target NET.Core 2.1\r\nVisual Studio version 15.9.4\r\n\r\n### **Unable to find TensorFlow DLL**\r\n\r\n- **What did you do?**\r\nI tried to run the example [TensorFlowTransform](https://github.com/dotnet/machinelearning/blob/e3830910531f00013c27391914233a085a1394a4/docs/samples/Microsoft.ML.Samples/Dynamic/TensorFlowTransform.cs)\r\n\r\n- **What happened?**\r\n\r\nWhen the method `ScoreTensorFlowModel` is invoked, I receive the following runtime exception:\r\n\r\n`Unable to load DLL 'tensorflow' or one of its dependencies: Exception from HRESULT: 0xC000001D`\r\n\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nI used version `0.11.0-preview-27405-2`. I also tried to set build target to x64 but didn't work.\r\nI also notice that the static extension method `ApplyTensorFlowGraph` is not available in nuget package."""
406949376,2422,b'Stop using MEF as part of the public API',"b'We have received feedback that we should limit our usage of MEF as part of the public API, according to feedback by .NET team. We currently for the sake of writing ""custom"" transformers have the user interact with it. This can be seen here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2d351eb73855cdc30e9c978c00820470cb38cf39/test/Microsoft.ML.Tests/Scenarios/Api/CookbookSamples/CookbookSamplesDynamicApi.cs#L535\r\n\r\nAs we see, we are hsing on `MLContext` MEF containers and catalogs, using types exposing MEF `Import` and `Export` attributes, etc. etc. The feedback from .NET team is, stop, do something else, because MEF is apparently not ""clean"" enough.\r\n\r\n(What is to be done instead? Possibly registering some ""named"" delegate to produce these things, or other. But anyway, we should not use MEF directly. Maybe not use attributes at all, and just require explicit registration somehow. I\'m not sure.)\r\n\r\n@eerhardt and others may have more specific recommendations or context on why we should not use MEF in this way.'"
406926510,2420,b'SampleDatasetUtils is in disarray',"b'There is a project called `SamplesUtils` sitting *inside* the core ML.NET codebase. I believe this was created before the `[BestFriend]` concept came around. \r\n\r\nThis project contains one `namespace`, `SampleDatasetUtils` that has one `static` `class`, `DatasetUtils`. Here are the following issues:\r\n1. Everything is public and nothing is sealed.\r\n2. This was built for Samples, but now Tests have taken a dependence on a couple of methods.\r\n3. The file itself has no organization, everything is everywhere.'"
406650529,2418,b'ImagePixelExtractingEstimator should not require the ImageResizingEstimator in the pipeline',"b'Currently in ML.Net, to be able to use an ImagePixelExtractingTransformer/ImagePixelExtractingEstimator, you need to have an ImageResizingEstimator  in the pipeline before the ImagePixelExtracting, otherwise the pipeline [fails at run-time ](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImagePixelExtractorTransform.cs#L447)with a schema mismatch error. \r\n\r\n`""\'Schema mismatch for input column \'ImageObject\': expected known-size image, got unknown-size image\'"". `\r\n\r\nThis happen because the ImagePixelExtracting operating on [ImageTypes ](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageType.cs)needs the Width and the Height properties, to extract the pixels. \r\n\r\nThe Estimator that creates the [ImageType ](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageType.cs)object, is the ImageLoadingEstimator, but the Width and Height properties of the estimator don\'t get filled until they get passed to ImageResizing. \r\n\r\nProposed fix: \r\n- The ImageLoadingEstimator should allow the user to specify the height and width of the images, if the user has images of fixed with and height, rather than fail at ""ExtractPixels"" if resize is not present. \r\n- if we make a bool about `imagesHaveSameDimentions`, and that is set to `yes`, the ImageLoadingTransformer could memorize the width and height of the first image, and check every subsequent image, drop all the samples that don\'t have the right dimensions, and warn about the records dropped. \r\n\r\ncc @yaeldekel @Ivanidzo4ka @TomFinley '"
406610414,2415,b'BestFriend on public members ought to complain',"b""We have the best friend attribute introduced in #1520, which is great, but sometimes I or someone makes a mistake and puts it on a public class. This is harmless, has no visible effects, but is just a bit odd and definitely not intended usage.\r\n\r\nAt least for me, the procedure is this: I make something `public` become `[BestFriend] internal`, but then I realize something is a bit more complicated than I thought, and I decide to delay that *specific* internalization work until some other conditions are met. (E.g., in #2404, I internalized `IPredictorProducing`, but then realized that the problems with calibrators represented a hard barrier, so I wrote #2378 to capture those difficulties, and changed it back to public, until that is resolved.) The trouble is sometimes I leave the `[BestFriend]` behind. This has happened multiple times.\r\n\r\nIt might be nice, though hardly essential, to have `[BestFriend]` itself be analyzed to see that any usage of it is not applied to any publicly accessible thing. This is not actually essential per se, it's just a code cleanliness type of thing.\r\n\r\nThis hypothetical work would go in `Microsoft.ML.InternalCodeAnalyzer`."""
406608701,2413,b'TensorFlowTransformer: Passing constant value to the model',"b'There should be a way to pass constant values to the TensorFlow model because there are cases when model requires an input which is constant regardless of the input feature vector.\r\n\r\nFor example, the [Batch Normalization](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) in TensorFlow requires a paramter called `training` which is set to `True` during training and `False` during inference. This variable is often set through as a `Placeholder` variable which is taken as input at runtime. \r\n\r\nWhen using such a model for inference in `TensorFlowTransformer`, we need to always pass `False` for this variable or always set it to `True` when training.'"
406590476,2412,b'ValueMapper: Output Schema is not vector when Value type is vector.',"b'This is the bug similar to #2385. \r\n\r\nWhen value type of the dictionary/map is a vector the output is vector. However, the ValueMappingEstimator GetOutputSchema fails at the following line\r\nhttps://github.com/dotnet/machinelearning/blob/1706b3cfbf838ddd9c5e5a8eba80c4f1d2fd1aec/src/Microsoft.ML.Core/Data/IEstimator.cs#L67\r\n\r\nCC: @singlis '"
406566572,2410,b'ValueMapping: Write test for schema propagation for all types of inputs.',"b'There is a ValueMapping test that test for the schema propagation for `ValueMapperEstimator` and `ValueMapperTransformer`\r\nhttps://github.com/dotnet/machinelearning/blob/2dfc51aa7172199c1b2145e48ecb9eb855bb87f1/test/Microsoft.ML.Tests/Transformers/ValueMappingTests.cs#L506\r\n\r\nThis test is not complete in a sense that it does not test all the possible inputs that can be provided to `ValueMapperEstimator`. It should test the ValueMapperEstimator on all possible data type the estimator can take as input and on all possible maps types.  \r\n\r\nCC: @artidoro, @singlis '"
406514472,2407,b'OnlineGradientDescent throws exception',"b'### System information\r\n- Microsoft Windows Pro version 10.0.17763, 64GB RAM, I7-7700K 4 physical cores 4.2 GHz, 2x 250 GB M2 Drives, AMD FirePro W5100 with 4096 MB/930 MHz\r\n- .Net Version 4.72, Microsoft.ML 0.9.0 Wednesday, January 9, 2019 (1/9/2019) \r\n- Dataset 3,378,393 rows\r\n\r\n### Issue\r\nWhat did I do\r\n- Comparing the prediction accuracy using\r\n1. same data source \r\n2. same normalisation \r\n3. with different trainers\r\n\r\nI configured the estimator chain like so:\r\n```\r\nvar dataProcessPipeline = mlContext.Transforms.CopyColumns(""predictField"", ""Label"")\r\n.Append(mlContext.Transforms.Normalize(inputName: ""SH1"", mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n.Append(mlContext.Transforms.Normalize(inputName: ""SL1"", mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n\xe2\x80\xa6 665 more\r\n.Append(mlContext.Transforms.Normalize(inputName: ""SH9"", mode: NormalizingEstimator.NormalizerMode.MeanVariance))\r\n.Append(mlContext.Transforms.Concatenate(""Features"",""SH1"",...""SH9""));\r\ndataProcessPipeline.AppendCacheCheckpoint(mlContext);\r\n```\r\nPreviously I had 119 data points in the model and had no error.\r\n\r\nI test the models based on the parameter telling it what network to learn, the item causing the error is this\r\n\r\n```\r\nelse if (Definition.MachineLearningMethod == AI.ML.Factory.MachineLearningMethods.OnlineGradientDescent)\r\n                    {\r\n                        var trainer = mlContext.Regression.Trainers.OnlineGradientDescent(labelColumn: ""Label""\r\n                                                                                        , featureColumn: ""Features""\r\n                                                                                        , advancedSettings: a =>\r\n                                                                                        {                                                                                            \r\n                                                                                            a.DecreaseLearningRate = true;\r\n                                                                                            a.DoLazyUpdates = true;\r\n                                                                                            a.NormalizeFeatures = NormalizeOption.Yes;                                                                                           \r\n                                                                                            a.DecreaseLearningRate = true;\r\n                                                                                            a.Caching = Microsoft.ML.EntryPoints.CachingOptions.Memory;                                                                                            \r\n                                                                                        }\r\n                                                                                        );\r\n                       var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n                       return trainingPipeline.Fit(trainingDataView);\r\n```\r\n\r\n\r\n\r\n\r\n- **What happened?**\r\nAfter I call Fit on my Training Data view I see following errors\r\nException thrown: \'System.InvalidOperationException\' in Microsoft.ML.StandardLearners.dll\r\nthen\r\nException OnlineGradientDescent:The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc\r\n\r\nafter, I think, the .net framework throws an error in my running  test (no debugger attached)\r\n> Managed Debugging Assistant \'ContextSwitchDeadlock\' \r\n> The CLR has been unable to transition from COM context 0x248b5058 to COM context 0x248b5180 for 60 seconds. The thread that owns the destination context/apartment is most likely either doing a non pumping wait or processing a very long running operation without pumping Windows messages. This situation generally has a negative performance impact and may even lead to the application becoming non responsive or memory usage accumulating continually over time. To avoid this problem, all single threaded apartment (STA) threads should use pumping wait primitives (such as CoWaitForMultipleHandles) and routinely pump messages during long running operations.\r\n\r\n\r\n\r\n\r\n\r\n- **What did you expect?**\r\nHaving been able to run the network without any of the advanced using a smaller dataset and receiving the error I added the Advanced settings hoping to be able to solve the issue. this however is not the case. \r\n\r\n### Source code / logs\r\n:\r\n\r\n_[Source=NormalizingEstimator; RowToRowMapperTransform; Cursor, Kind=Trace] Channel finished. Elapsed 00:04:53.5139276.\r\n[Source=NormalizingEstimator; RowToRowMapperTransform; Cursor, Kind=Trace] Channel disposed\r\n[Source=ColumnConcatenatingEstimator ; RowToRowMapperTransform; Cursor, Kind=Trace] Channel finished. Elapsed 00:04:53.4765765.\r\n[Source=ColumnConcatenatingEstimator ; RowToRowMapperTransform; Cursor, Kind=Trace] Channel disposed\r\n[Source=ColumnConcatenatingEstimator ; RowToRowMapperTransform; Cursor, Kind=Trace] Channel finished. Elapsed 00:04:53.4197884.\r\n[Source=ColumnConcatenatingEstimator ; RowToRowMapperTransform; Cursor, Kind=Trace] Channel disposed\r\n[Source=Stochastic Gradient Descent (Regression); Training, Kind=Trace] 2/4/2019 2:59:47 PM Finished training iteration 1; iterated over 3412517 examples.\r\n[Source=Stochastic Gradient Descent (Regression); Training, Kind=Trace] Channel finished. Elapsed 00:04:56.6368673.\r\n[Source=Stochastic Gradient Descent (Regression); Training, Kind=Trace] Channel disposed\r\n\r\nException OnlineGradientDescent:The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.\r\nException:The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.\r\ntesthost.exe Error: 0 : The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc._\r\n\r\n\r\nfull log is attached\r\n[Learning exception.zip](https://github.com/dotnet/machinelearning/files/2829739/Learning.exception.zip)\r\n'"
406468153,2403,"b'Segregate ""scoring"" ML.NET components/NuGet packages so the scoring components evolve autonomously from the rest of ML.NET'","b'Segregate ""scoring"" ML.NET components/NuGet packages so the scoring components evolve autonomously from the rest of ML.NET.\r\n\r\nThis will be a breaking change, although easy to fix in the apps when having the breaking changes.\r\n\r\nIf we segregate the scoring area of ML,NET, that would help when providing support to:\r\n- UWP\r\n- Unity\r\n- ARM\r\n\r\nSo initially, only the ""scoring"" area of ML.NET could be supported in those environments. It would be less expensive than providing support to UWP, Unity and ARM to the whole ML.NET.\r\nAnd in most scenarios, for those environments, the customer just want to score a model, not to train a model in an UWP app, Unity app or ARM app (Xamarin mobile app or IoT).\r\n\r\nRelated issues:\r\nhttps://github.com/dotnet/machinelearning/issues/1886\r\nhttps://github.com/dotnet/machinelearning/issues/1736\r\nhttps://github.com/dotnet/machinelearning/issues/22\r\nhttps://github.com/dotnet/machinelearning/issues/2252\r\nhttps://xamlbrewer.wordpress.com/2019/01/25/machine-learning-with-ml-net-in-uwp-clustering/\r\n\r\n'"
406437068,2401,"b""Take / Skip / TakeAndSkip Filters don't have catalog entries""","b'The `Take`, `Skip`, and `TakeAndSkip` commands are not in the the catalog. For 1.0, we need to have them in the catalog, with samples linked from the catalog xml docs. We can add these just like the `BootstrapSample` and `RangeFilter`.'"
406436370,2400,"b""NA Filter doesn't have a sample""","b""The `NAFilter` command doesn't have a sample and isn't in the catalog. For 1.0, we need to have it in the catalog, with a sample linked from the catalog xml docs."""
406435554,2399,"b""Cache command doesn't have a sample""","b""The `Cache` command doesn't have a sample. For 1.0, we need to have a sample, with links from the catalog xml docs."""
406433722,2398,b'RangeFilter has no samples',b'The RangeFilter has no sample to show how to use it. I would like to see a sample and links to the sample from the catalog entries.'
406265489,2397,b'Prediction function always returns the same value for regression models.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 64-bit\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI created a program that is meant to predict the likelihood of a device being on at a given time.\r\n- **What happened?**\r\nThe prediction function always returns the same value e.g. 0 or 1.\r\nIf the regression trainer is changed, the value that is returned by the prediction function changes to a different value. The value is always the same for each different trainer (e.g. Regression.Trainers.FastTree may always return 0 and another trainer will always return 1).\r\n- **What did you expect?**\r\nI expected the prediction function for to return different values representing the probability of the device being on.'"
406162918,2396,b'ReadFromEnumerable and CreateEnumerable not working',"b""### System information\r\n\r\n- **Windows 10**:\r\n- **.NET Core 2.2 and ML.NET v0.9.0**: \r\n\r\n### Issue\r\n\r\n- I tried to recreate the spike detector sample, but encountered issues for the 2 methods.\r\n- `DataOperations does not contain a definition for ReadFromEnumerable` and `MLContext does not contain a definition for CreateEnumerable` were the errors I got.\r\n- I didn't expect any errors to pop up. I did a copy and paste of the namespaces and code, in case I missed something.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/SsaSpikeDetectorTransform.cs\r\n"""
406109060,2391,b'Incorrect naming of Options argument in TensorFlowTransform public api',"b""In PR : #2312  we modified the public surface of the TensorFlowTransform  as per issue #1798 #2280 \r\n\r\nThere is a bug - we did not rename the 'args' parameter. It should be 'options'  (else it breaks consistency with rest of public surface)\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5b98e0cd4cdd150029fddf3c33c6c6bd71abb119/src/Microsoft.ML.TensorFlow/TensorflowCatalog.cs#L53-L54\r\n\r\n@ganik \r\n\r\n"""
405993615,2389,b'Incorrect throwing during data loading',"b""### System information\r\n\r\n- Win10\r\n- .NET Core 2.1/3.0 Preview 2\r\n\r\n### Issue\r\n\r\nLet's say we do loading of data from CSV file using simple POCO class and forget to add `LoadColumn` attribute on the properties. Then call to `CreateTextLoader<T>/CreateTextReader<T>` fails with NullReferenceException\r\n\r\n```\r\nUnhandled Exception: System.NullReferenceException: Object reference not set to an instance of an object.\r\n   at Microsoft.ML.Data.TextLoader.CreateTextReader[TInput](IHostEnvironment host, Boolean hasHeader, Char separator, Boolean allowQuotedStrings, Boolean supportSparse, Boolean trimWhitespace)\r\n   at MLConsoleApp1.Program.Main(String[] args) in MLConsoleApp1\\Program.cs:line 54\r\n```\r\n\r\nwhich definitely not user friendly. I track down that to line https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1344\r\n\r\nwhere you delegate assertion to IHostEnvironment since I running LocalEnvironment, I believe that by default when running in Local environment proper default behavior would be just throw. Right now I could not even imaging that such big usability mistake was made by MS, so I have to manually clone project and compile it locally to track down this error. \r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\npublic class SentimentRow\r\n{\r\n    public bool Sentiment { get; set; }\r\n\r\n    public string SentimentText { get; set; }\r\n}\r\n...\r\nvar mlContext = new MLContext();\r\nvar reader = mlContext.Data.CreateTextLoader<SentimentRow>(hasHeader: true);\r\n```\r\n"""
405940234,2385,b'Fix output schema produced by ValueMappingEstimator ',"b'There is a bug in `ValueMappingEstimator` output schema. \r\nhttps://github.com/dotnet/machinelearning/blob/0e80d6c07580cea5ce072fd7cba02d7171dc61f4/src/Microsoft.ML.Data/Transforms/ValueMapping.cs#L61\r\n\r\nWhen input is a vector the output produced is a vector. However, the schema produced by the `ValueMappingEstimator` shows that the output is scalar. This throws an exception when `ValueMappingEstimator` is followed by another estimator which checks for schema.\r\n\r\nThis regression was caused by #2162 '"
405930430,2384,b'Add BootstrapSamplingTransform to DataOperationsCatalog',"b""As noted in #933, the `BootstrapSamplingTransform` isn't something that we want recorded in pipelines (e.g. having it executed on a test set). However, it is super useful to have in our library, so it would be nice to have a way to use it in user-facing code."""
405918700,2381,b'Add Ubuntu CI leg',"b'Right now we build and test for Linux on only one distro -- Centos 7 (a container hosted on Ubuntu 1804). We use .NET Core 2.1.\r\n\r\nWe maybe should add a leg to test on a Debian/Ubuntu family distro (Centos is in the RedHat family). That should be able to use all the same binaries. If we did that it would probably be good to use .NET Core 3.0 instead of 2.1 to get Linux coverage with that.\r\n\r\n.NET Core also supports Alpine, which some people use to minimise the size and security surface of their containers. It would be more ""interesting"" (takes= more work to support) because as well as having few default packages it is musl not glibc based so it needs a special build. We probably have to defer support for Alpine.\r\n\r\n@eerhardt thoughts?'"
405915069,2379,b'Image Classification Benchmark',"b'@Anipik: We could make a good benchmark for the image processing pipeline. \r\nI\'d recommend using the Dog Breeds vs. Fruits dataset which we used in [NimbusML for its image examples](https://docs.microsoft.com/en-us/nimbusml/tutorials/b_f-image-processing-clustering). We currently host this dataset in our CDN for NimbusML.\r\n\r\nIn Python, the dataset / image loader looks like:\r\n```Python\r\n# Load image summary data from github\r\nurl = ""https://express-tlcresources.azureedge.net/datasets/DogBreedsVsFruits/DogFruitWiki.SHUF.117KB.735-rows.tsv""\r\ndf_train = pd.read_csv(url, sep = ""\\t"", nrows = 100)\r\ndf_train[\'ImagePath_full\'] = ""https://express-tlcresources.azureedge.net/datasets/DogBreedsVsFruits/"" + \\\r\n                         df_train[\'ImagePath\']\r\n... load images\r\n```\r\n\r\nPurpose of the dataset is for example code & includes ~775 images of dogs & fruit:\r\n![image](https://user-images.githubusercontent.com/4080826/52151638-ab89e880-2628-11e9-9df5-2b060875e56e.png)\r\n![image](https://user-images.githubusercontent.com/4080826/52151656-b5abe700-2628-11e9-8f5a-483b3ddf20e5.png)\r\n\r\n(copied from PR -- https://github.com/dotnet/machinelearning/pull/2372#pullrequestreview-199284335)'"
405894257,2378,b'State of CalibratorPredictorBase v1',"b'There have been some issues concerning calibrator estimators (#1871 and #1622) but not calibrators themselves.\r\n\r\nSo, calibrated models are basically wrappers for model that have.\r\n\r\nThey are ultimately something akin to `CalibratedPredictorBase`. The trouble with `CalibratedPredictorBase` is this property:\r\n\r\nSo, consider this code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/docs/samples/Microsoft.ML.Samples/Dynamic/PermutationFeatureImportance/PFIRegressionExample.cs#L21-L29\r\n\r\nFocus on the last part, where we\'re able to get the feature weights.\r\n\r\nWhat is this `SubPredictor`? It is this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L130\r\n\r\nGreat news: it has a definite type! Bad news: that is just a marker interface. As a mechanism for the API, it is as useless as if it were just, say, of type `object` (which, incidentally, I will have to do anyway as part of #2251). For that reason, we see lots of code that looks like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/test/Microsoft.ML.Tests/TrainerEstimators/LbfgsTests.cs#L66\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/test/Microsoft.ML.Predictor.Tests/TestIniModels.cs#L584\r\n\r\nThis reason is, that object by itself is not useful: to get the actual model parameters, you have to do a ""magical cast"" to somehow get it into the right format. This sort of worked in command-line land or entry-point land, since everything was more or less dynamically typed anyway.\r\n\r\nIt might be desirable that, when training a logistic regression binary classification model, I should be able to, in a type safe fashion, be able to inspect the model weights without having to perform any ""magical casts.""\r\n\r\nThe most obvious solution to me is the following: calibrators becomes some sort of class which involves generics on both the ""subpredictor"" model parameters, as well as the calibrator. Then things like logistic regression would return instances of that generic class, or else some class derived from that generic class if we decide that must be an abstract class for some reason.7\r\n\r\nThe alternative is: we accept that ""magical casts"" are desirable, which I would not like since it is a little silly since I view the above ""desirable"" state is perfectly reasonable. But some people really hate generics.\r\n\r\nI believe @yaeldekel had some thoughts on this, perhaps others do as well.'"
405876197,2377,b'MissingValueHandlingTransformer -- do you ever plan to make it an estimator?',b'I see MissingValueIndicatorEstimator and MissingValueReplacingEstimator have been created. Do you currently plan to make an estimator for MissingValueHandlingTransformer?'
405867914,2376,b'KeyToValueMapping API is inconsistent with rest',"b'Pursuant to #2064 and the work done in #2239, column mapping transforms are to have an output and input column. However, I notice something like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L72-L73\r\n\r\nThis has just one column specified, that is, there is no convenient way to map an input to an output column and have the mapping have a distinct names, without working through the `params` overload which is a bit less convenient. This is inconsistent with the direction summarized by @sfilipi in #2064 as well as some of our other APIs. For example, in this same file:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L30-L31\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/578c188876cd7f158aca214d2e729500183b588c/src/Microsoft.ML.Data/Transforms/ConversionsExtensionsCatalog.cs#L49-L50\r\n\r\nThis method should be similar to the others in terms of the `string outputColumnName, string inputColumnName = null` signature. Note that this mistake extends down into the associated estimator and transformer constructors as well, so it will have to be fixed there as well.\r\n\r\n/cc @sfilipi '"
405850866,2375,b'Parameter name Consistency in FastTree',b'https://github.com/dotnet/machinelearning/blob/4bb3e0006c656387ec96dc7e5878e204e1710f50/src/Microsoft.ML.FastTree/FastTreeArguments.cs#L528\r\n\r\nShould this be LearningRate? The Options have it named wrongly.\r\n\r\nThe named parameter for the FastTree is named correctly as learningRate.\r\nhttps://github.com/dotnet/machinelearning/blob/4bb3e0006c656387ec96dc7e5878e204e1710f50/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L34\r\n\r\n\r\nIt would be great if you can check the same with all the trainers and transforms. i.e the named parameters(in the method) resemble the Actual Property name(in the options). In my opinion these all should be consistent. In case of named params (camel case) and for actual Property (of course is pascal case)'
405845505,2373,b'DnnImageFeaturizingTests failing for netfx',"b'These tests were not being tested due to the bug in conditionalFact attribute.\r\nHowever when I tried to run these tests on my local machine they are failing.\r\n\r\nThe call stack is this\r\n```C#\r\nSystem.ArgumentOutOfRangeException : Specified argument was out of the range of valid values.\r\nParameter name: ModelFile\r\nStack Trace:\r\n  C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs(155,0): at Microsoft.ML.Transforms.OnnxTransformer..ctor(IHostEnvironment env, Arguments args, Byte[] modelBytes)\r\n  C:\\git\\machinelearning\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet18\\ResNet18Extension.cs(43,0): at Microsoft.ML.Transforms.ResNet18Extension.ResNet18(DnnImageModelSelector dnnModelContext, IHostEnvironment env, String outputColumnName, String inputColumnName, String modelDir)\r\n  C:\\git\\machinelearning\\src\\Microsoft.ML.DnnImageFeaturizer.ResNet18\\ResNet18Extension.cs(25,0): at Microsoft.ML.Transforms.ResNet18Extension.ResNet18(DnnImageModelSelector dnnModelContext, IHostEnvironment env, String outputColumnName, String inputColumnName)\r\n  C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\DnnImageFeaturizerTransform.cs(66,0): at Microsoft.ML.Transforms.DnnImageFeaturizerEstimator..ctor(IHostEnvironment env, String outputColumnName, Func`2 modelFactory, String inputColumnName)\r\n  C:\\git\\machinelearning\\test\\Microsoft.ML.OnnxTransformTest\\DnnImageFeaturizerTest.cs(161,0): at Microsoft.ML.Tests.DnnImageFeaturizerTests.TestOldSavingAndLoading()\r\n```\r\n\r\n\r\nThe tests failing due to this are \r\nTestOldSavingAndLoading\r\nOnnxStatic\r\nTestDnnImageFeaturizer\r\n\r\ncc @jignparm @yaeldekel @danmosemsft @eerhardt '"
405817670,2371,b'SelectColumns handles input string arrays differently than other schema transformations',"b'`SelectColumns` has a different input contract than related schema manipulation transforms. Look at the difference:\r\n\r\n```cs\r\nmlContext.Transforms.DropColumns(""Column1"", ""Column2"");\r\nmlContext.Transforms.SelectColumns(new string[] { ""Column1"", ""Column2"" })\r\n```\r\n'"
405804094,2370,b'Add an example for the SelectColumns transform',"b""The SelectColumns schema transformer doesn't have an example, and it's summary is a bit incorrect."""
405571223,2361,b'MLContext.Transform should be further organized',"b'It seems that `MLContext.Transforms` can be further organized.\r\nIn `MLContext.Transforms` it is possible to access many transforms directly:\r\n- IndicateMissingValues\r\n- ReplaceMissingValues\r\n- ApplyOnnxModel\r\n- Concatenate\r\n- LoadImage\r\n- Normalize\r\n- Resize\r\n- ScoreTensorFlowModel\r\n- SelectColumns\r\n- TemsorFlow\r\n\r\nThere are also subgroups:\r\n- Transforms.Text\r\n- Transforms.Projection\r\n- Transforms.Categorical\r\n- Transforms.Conversion\r\n- Transforms.FeatureSelection\r\n\r\n\r\n\r\n**Suggestions:**\r\n1. It seems that more groupings can be made:\r\n      - Transforms.Image\r\n      - Transforms.MissingValues\r\n     - Transforms.TensorFlow\r\n2. And maybe Normalize can be moved to the `Transforms.Projections`.\r\n\r\n\r\n**Question:**\r\nDoes it even make sense to have some transforms in a subgroup, while others directly accessible?\r\n\r\n/cc: @rogancarr, @sfilipi, @TomFinley '"
405513844,2358,b'ValueToKeyEstimator constructors should be cleaned and documented better',"b'There 3 problems in the constructors/catalog of the ValueToKey estimator:\r\n1. The `ColumnInfo` object has two fields: `Terms`  and `Term`,  that are meant to serve the same function. \r\n2. Futhermore, it would probably make more sense to break the constructor in two. Providing `KeyData` should be in alternative to a list of terms. Right now it can be quite confusing to be able to set all of them together.\r\n3. Lastly, what happens when we specify several columns in `ColumnInfo[]` and also `KeyData` does `keyData` apply to all the columns?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e3830910531f00013c27391914233a085a1394a4/src/Microsoft.ML.Data/Transforms/ValueToKeyMappingEstimator.cs#L34-L39'"
405499523,2356,b'Curate resource links for API reference',"b""There are many topics that repeat throughout the API reference. For each topic, we want to have a separate link that contains more details, instead of duplicating content, or worse, stating the obvious like the following:\r\n* Bias: The predictor's bias term.\r\n* L2Weight: L2 regularization weight for trainer\r\n\r\nTable below captures all the topics that we want to cover. These are the topics that apply to many APIs. For example, we have 4 or 5 cross validation extension methods, one per ML task. We can have one page explaining CV, instead of duplicating content. \r\n\r\nSome topics already exist in [glossary](https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/glossary). We need to have a discussion about our linking strategy later. For now let's keep the list here. I suggest using the LinkPlaceholder string (tmpurl_*) in the XMLs, so that we can easily find-replace with the final link.\r\n\r\n| Topic | Description | In Glossary? | Link Placeholder | Link |\r\n| ------------- |-------------| -----| -----| -----|\r\n| Regularization | L1, L2, and other topics related to regularization | no | tmpurl_regularization | https://en.wikipedia.org/wiki/Regularization_(mathematics) |\r\n| Loss  | Loss functions  | no  | tmpurl_loss  | https://en.wikipedia.org/wiki/Loss_function |\r\n| Calibration / calibrators  | calibrators used for producing probabilities  | no  | tmpurl_calib  | https://en.wikipedia.org/wiki/Calibration_(statistics)  |\r\n| Learning rate  | what is learning rate in training  | no | tmpurl_lr  | There's no wikipage talking about learning rate. It's always mixed with SGD or the training algorithm using it. Deleting this since it's not an independent concept. |"""
405493886,2354,b'Trivial estimators should also be ITransformer',"b'We are making constructors of transformers internal as part of issue #1798. This makes the creation of non trainable transformers somewhat clumsy. This problem is already reported in the following issue #2165 by an external user.\r\n Here is an example:\r\n\r\n```csharp\r\nIDataView data = ...\r\nvar estimator = mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"");\r\nvar transformer = estimator.Fit(ANY DATA);\r\nvar transformedData = transformer.Transform(data);\r\n```\r\nThe problem here is the step where the call to `Fit()` is completely useless and feels silly. However, we need estimators for non trainable transformers to use them in estimator pipelines, and the estimator interface cannot change.\r\n\r\nOne possible approach that we came up with @glebuk and @TomFinley is to make the \'trivial\' estimators (estimators for non trainable transformers) `ITransformers` themselves. This is how the API would look like if we make this change, you can see that it is still possible to make the trivial estimators part of a pipeline:\r\n```csharp\r\nIDataView data = ...\r\nvar estimatorTransformer = mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel"");\r\nvar transformedData = estimatorTransformer.Transform(data);\r\n\r\nvar pipeline = estimatorTransformer.Append(ml.Regression.Learners.FastTree(options);\r\nvar trainedPipeline = pipeline.Fit(data);\r\nvar transformedData2 = trainedPipeline.Transform(data);\r\n```\r\n\r\n\r\nThe conversion would be very simple. The estimator will have a field `ITransformer Transformer` which is instantiated in the constructor using the arguments passed to the constructor of the estimator (this is already done in cases where the estimator derive from `TrivialEstimator` which should be the case for non trainable estimators). The methods of the interface `ITransformer` will be implemented by calling the respective methods of `Transformer`. A sample conversion should look like the following:\r\n\r\n```csharp\r\npublic sealed class KeyToValueMappingEstimator : TrivialEstimator<KeyToValueMappingTransformer>, ITransformer\r\n    {\r\n        public KeyToValueMappingEstimator(IHostEnvironment env, string columnName)\r\n            : base(Contracts.CheckRef(env, nameof(env)).Register(nameof(KeyToValueMappingEstimator)), new KeyToValueMappingTransformer(env, columnName))\r\n        {        }\r\n\r\n        public KeyToValueMappingEstimator(IHostEnvironment env, params (string outputColumnName, string inputColumnName)[] columns)\r\n            : base(Contracts.CheckRef(env, nameof(env)).Register(nameof(KeyToValueMappingEstimator)), new KeyToValueMappingTransformer(env, columns))\r\n        {        }\r\n\r\n        public override SchemaShape GetOutputSchema(SchemaShape inputSchema)\r\n        {            ...        }\r\n\r\n        public bool IsRowToRowMapper => Transformer.IsRowToRowMapper;\r\n        public Schema GetOutputSchema(Schema inputSchema) => Transformer.GetOutputSchema(inputSchema);\r\n        public IRowToRowMapper GetRowToRowMapper(Schema inputSchema) => Transformer.GetRowToRowMapper(inputSchema);\r\n        public IDataView Transform(IDataView input) => Transformer.Transform(input);\r\n    }\r\n}\r\n```\r\n\r\n/cc @Ivanidzo4ka \r\n'"
405485707,2353,b'Add a sample for DropColumns',"b""The `DropColumns` transform doesn't have a sample."""
405483783,2352,b'VBuffer in samples code.',"b'In our samples we have code which looks like this `transformedData_default.GetColumn<VBuffer<float>>(ml, defaultColumnName);`\r\nWhich introduce users into wonderful world of VBuffers. \r\nConsidering how [confusing sometimes VBuffers can be](https://github.com/dotnet/machinelearning/issues/2341) ? Shall we replace all `GetColumn` calls from `VBuffer<T>` to `t[]` ?'"
405482516,2350,b'Add a sample for CopyColumns',b'`CopyColumns` does not have a sample for its documentation.'
405462831,2348,b'Limited functionality for fine-tuning TF models using the TensorFlowTransform',"b""The TensorFlowTransform in ML.NET  provides some basic capabilities for re-training pre-trained TF models.  \r\n\r\nThe table below lists down the capabilities currently supported for fine-tuning TF models. It also lists  functionality that's currently not supported.\r\n\r\n | Fine-Tuning abilities | Supported by ML.NET TensorFlowTransform | \r\n | ---------- | -------- | \r\n | Continue retraining on TF SavedModel,  given dataset  with same shape as  original model | Yes | \r\n | Continue retraining on TF SavedModel,  given dataset  with _different_ shape as  original model | No | \r\n | Freeze weights of all layers, except the last layer. Replace last layer of TF SavedModel  with new layer  based on categories of new dataset. Re-train the weights for last layer only.  | No |\r\n | Freeze weights upto any  arbitrary Nth layer  (given layer name). Replace final layer of TF SavedModel  with new layer  based on categories of new dataset.  Re-train the weights from (N+1) th layer to the last layer.  | No | \r\n\r\n@zeahmed  @JRAlexander """
405389708,2346,b'ValueMappingEstimator in the Conversions catalog is missing the treatAsKeys parameter',"b'When adding samples, I noticed that the treatValuesAsKeys parameter is not available as part of the Conversions catalog. Therefore I am not able to do this:\r\n```\r\n         var pipeline = ml.Transforms.Conversions.ValueMap(educationKeys, educationValues, true, (""EducationKeyType"", ""Education""));\r\n```\r\n\r\nAnd instead have to do this:\r\n```\r\n            var pipeline = new ValueMappingEstimator<string, string>(ml, educationKeys, educationValues, true, (""EducationKeyType"", ""Education""));\r\n```\r\n\r\nTherefore we should add another function to the Conversions Catalog to handle this.'"
405222280,2342,b'Tests in CpuMathUtilsUnitTests are culture sensitive',"b'Hello all. While working on #2325 I noticed that tests in class `CpuMathUtilsUnitTests` seem to be locale-sensitive. My computer uses Slovak locale, which uses comma (`,`) as a decimal separator. Simply running these tests leads to failures with exception message `Input string was not in a correct format.` This is coming from `float.Parse` calls.\r\n\r\nSetting `CultureInfo.CurrentCulture = CultureInfo.InvariantCulture;` in the class constructor resolves the failures.\r\n\r\nThis should probably be resolved to lower friction for non-English contributors.'"
405100194,2341,b'DataView.GetColumn<T> returns incorrect data for vector columns',"b'Ran the C# code:\r\n```C#\r\nvar values = data.GetColumn<VBuffer<float>>(new MLContext(), ""col"");\r\n```\r\nAll the returned values were identical, and equal to the last value in the column.\r\nI think the bug is that this code\r\nhttps://github.com/dotnet/machinelearning/blob/7fc7e50ce6f8fed24fc0b9528839a0ac8d0ed320/src/Microsoft.ML.Data/Utilities/ColumnCursor.cs#L90-L95\r\nshould be\r\n```C#\r\nwhile (cursor.MoveNext())\r\n{\r\n   T curValue = default;\r\n   getter(ref curValue);\r\n   yield return curValue;\r\n}\r\n```\r\n\r\nAlso, it would be really helpful if you could override the Equals & GetHashCode methods on VBuffer, for use cases like values.Distinct().Count(), etc. Thanks!\r\n'"
405025450,2338,b'Make SweepableParamAttribute and related classes public',"b'If SweepableParamAttribute and related classes were public, AutoML could leverage them :). As AutoML iterates to recommend improvements in sweep ranges, the main repo could benefit'"
404999364,2337,b'TrainTestSplit should be inside MLContext.Data ',"b'Currently `TrainTestSplit` can be found in the various training tasks in `MLContext`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/533171a430063c5db234aff20e6d39e6673d3c4d/test/Microsoft.ML.Tests/Scenarios/Api/CookbookSamples/CookbookSamples.cs#L604-L605 \r\n\r\nSince that is a data operation that only involves splitting data and since it is independent on the training task, it would make more sense to have it in `mlContext.Data`. The previous line would look like:\r\n\r\n```csharp\r\nvar (trainData, testData) = mlContext.Data.TrainTestSplit(data, testFraction: 0.1);\r\n```'"
404991481,2336,b'ITransformer should derive from ICanSaveModel and we should explicitly implement ICanSaveModel',"b""In our code base we make the implicit assumption that all classes implementing `ITransformer` also implement `ICanSaveModel`. `ITransformer` is the abstraction that transforms the data and both single and chained components in a pipeline are made into an `ITransformer` once they are trained. Since this is the abstraction that contains trained models and data transformations, it should also be savable to a file. The standard scenario is that after training, one saves trained models, or `ITransformer`, for later use for scoring/transforming new data.\r\n\r\nThe above highlights that this is an important assumption and that we should capture it in code by making `ITransformer` derive from `ICanSaveModel`. Especially going forward as we think about allowing custom components, we should make it explicit that new transformers also implement `ICanSaveModel`.\r\n\r\nFurthermore, we should explicitly implement in the transformers the `Save` method of the `ICanSaveModel` interface. This would make it less visible to the users. The reasons for doing so are twofold:\r\n1.  `ModelSaveContext` only has internal constructors, so a user cannot instantiate it. \r\n2. We only use the `Save` method internally, and we don't want the user to call it directly.\r\n\r\n/cc @TomFinley @sfilipi """
404989082,2335,"b""MultiClassClassifier.Evaluate calculates the confusion matrix, but doesn't make it accessible to the user""","b'The [Evaluate](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Evaluators/MultiClassClassifierEvaluator.cs#L519) method in the MultiClassClassifierEvaluator, calculates the overall metrics, and the confusionTable, but makes no use of the confusion table. \r\n\r\nThe confusion table should be part of the MultiClassClassifierMetrics. \r\n'"
404954952,2333,b'KeyType missing documentation for a few methods/parameters',b'The following properties of KeyType are missing documentation\r\n- Contiguous\r\n- Equals(ColumnType)\r\n- Equals(Object)\r\n- GetHashCode()\r\n- ToString()'
404948023,2332,b'Finalize documentation for ValueToKeyMapping (aka TermTransform)',"b'The documentation and samples for the `ValueToKeyMapping` is almost in place, but the documentation could use more remarks, like answering the ""what is this / why would you use this?"" questions, and links to the samples.'"
404908830,2328,b'Make MutualInformationFeatureSelection scores available',"b'Some scenarios, such as detecting label leakage and sorting features by their relationship with the label, are no longer possible now that the `MutualInformationFeatureSelectionUtils` class is `internal`. One solution would be to add an option to `MutualInformationFeatureSelection` return scores for each column. This could return a similar output to `FeatureContributionCalculator`.\r\n\r\nFrom #2196'"
404889241,2326,"b'What namespaces to keep, what to drop, and what to hide'","b""In the table below there are all the namespaces that are in ML.Net. \r\nThey also all display in the docs site. Some of them, like Microsoft.ML.Ensemble needs to continue to exist in the code, but it is not ready to be exposed to the users, and can be hidden in the docs site. \r\n\r\nSome others, like Microsoft.ML.Internal.Internallearn can potentially be merged into other namespaces. \r\nLet's annotate in the list below the namespaces that need to be hidden in the docs site, and the ones that need to be gone altogether:\r\n\r\n\r\nNamespace| Drop it from code | Hide it from docs | Ships In Nuget | \r\n-------- | ----------------- | ----------------- | ----------- |\r\nMicrosoft.ML |    |   | Microsoft.ML |\r\nMicrosoft.ML.Calibrator |    |   | Microsoft.ML  |\r\nMicrosoft.ML.Core.Data | drop   |   | \t  |\r\nMicrosoft.ML.Data |    |   | Microsoft.ML |\t\r\nMicrosoft.ML.Data.IO | drop?   |   |\t  |\r\nMicrosoft.ML.Data.IO.Zlib |  drop  |   |\t  |\r\nMicrosoft.ML.Ensemble | Microsoft.ML.Trainers.Ensemble   |  hide |\tNone  |\r\nMicrosoft.ML.Ensemble.EntryPoints |    |   |Microsoft.ML  |\t\r\nMicrosoft.ML.Ensemble.OutputCombiners |  Microsoft.ML.Trainers.Ensemble  | hide  |\t None |\r\nMicrosoft.ML.Ensemble.Selector | Microsoft.ML.Trainers.Ensemble   | hide  |\t None |\r\nMicrosoft.ML.Ensemble.Selector.DiversityMeasure | Microsoft.ML.Trainers.Ensemble   | hide  |\tNone  |\r\nMicrosoft.ML.EntryPoints |    |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.EntryPoints.JsonUtils |  drop?  |   |  |\t\r\nMicrosoft.ML.FactorizationMachine | Microsoft.ML.Trainers.FactorizationMachine   |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.ImageAnalytics |    |   | Microsoft.ML.ImageAnalytics\t  |\r\nMicrosoft.ML.ImageAnalytics.EntryPoints |   Microsoft.ML.ImageAnalytics |   |\t  |\r\nMicrosoft.ML.Internal.Calibration | Microsoft.Ml.Calibrator   | hide  |\tMicrosoft.ML   |\r\nMicrosoft.ML.Internal.CpuMath |    |  hide |\tMicrosoft.ML   |\r\nMicrosoft.ML.Internal.Internallearn | drop?   |   |\t  |\r\nMicrosoft.ML.Internal.Internallearn.ResultProcessor |   drop? |   | None\t  |\r\nMicrosoft.ML.Learners |  Microsoft.ML.Trainers  |   | Microsoft.ML \t  |\r\nMicrosoft.ML.LightGBM | Microsoft.ML.Trainers.LightGBM   |   | Microsoft.ML.LightGBM\t  |\r\nMicrosoft.ML.Model |    |   |\tMicrosoft.ML.Onnx ,  Microsoft.ML |\r\nMicrosoft.ML.Model.Onnx |    |   |\tMicrosoft.ML.Onnx  |\r\nMicrosoft.ML.Numeric |  drop?  |   |  |\t\r\nMicrosoft.ML.SamplesUtils |    |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.StaticPipe |    |   | Microsoft.ML.StaticPipe\t  |\r\nMicrosoft.ML.StaticPipe.Runtime | drop?   |   |  |\t\r\nMicrosoft.ML.Sweeper |    |  hide |\tMicrosoft.ML  |\r\nMicrosoft.ML.Sweeper.Algorithms |    |  hide | Microsoft.ML\t  |\r\nMicrosoft.ML.TimeSeries |    |   |Microsoft.ML.TimeSeries\t  |\r\nMicrosoft.ML.TimeSeriesProcessing |  drop?  |   |  |\t\r\nMicrosoft.ML.Tools |    |   hide? |\t  |\r\nMicrosoft.ML.Trainers |    |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.Trainers.FastTree |    |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.Trainers.FastTree.Internal |  Microsoft.ML.Trainers.FastTree|   |\t  |\r\nMicrosoft.ML.Trainers.HalLearners |    |   Microsoft.ML.Trainers.HalLearners |\t  |\r\nMicrosoft.ML.Trainers.KMeans |    |   |  Microsoft.ML |\t\r\nMicrosoft.ML.Trainers.Online |    |   | Microsoft.ML  |\t\r\nMicrosoft.ML.Trainers.PCA |    |   |\tMicrosoft.ML  |\r\nMicrosoft.ML.Trainers.Recommender |    |   |\t  |\r\nMicrosoft.ML.Trainers.SymSgd |  Microsoft.ML.Trainers.HalLearners |   |  |\t\r\nMicrosoft.ML.Training |  drop  |   |\t  |\r\nMicrosoft.ML.Transforms |    |   |\t  |\r\nMicrosoft.ML.Transforms.Categorical |    |   |\t  |\r\nMicrosoft.ML.Transforms.Conversions |    |   |\t  |\r\nMicrosoft.ML.Transforms.FeatureSelection |    |   |\t  |\r\nMicrosoft.ML.Transforms.Normalizers |    |   |\t  |\r\nMicrosoft.ML.Transforms.Projections |    |   |\t  |\r\nMicrosoft.ML.Transforms.TensorFlow |    |   |\t  |\r\nMicrosoft.ML.Transforms.Text |    |   |  |\r\nMicrosoft.ML.UniversalModelFormat.Onnx |  Microsoft.ML.Model.Onnx  |   |"""
404885636,2325,b'Clean up the XmlInclude EntryPoint attribute annotations',"b'The `XmlInclude` EntryPoint annotation attribute was created when we needed to simultaneously document the so called runtime classes, and the autogenerated CSharpApi.cs classes. \r\n\r\nNow that the auto-generated C#api is gone, there is no need to have the `XmlInclude` EntryPoint annotation attribute.\r\n\r\nSo searching for `XmlInclude ` and deleting it everywhere would consider this work item complete.  '"
404736011,2322,b'Error in code FakeSchemaFactory.Create(...) throws Exception: Index was outside the bounds of the array.',"b'Exception: Index was outside the bounds of the array. In FakeSchemaFactory.Create(...) \r\n\r\nThere is mistake in code :\r\n`   for (int j = 0; j < partialMetadata.Count; ++j)\r\n                {\r\nvar metaColumnType = MakeColumnType(partialMetadata[i]);`\r\n\r\nThere should be ""j"" instead of ""i"" variable.\r\n'"
404589225,2319,b'Accessibility Problem of FastTree through Dynamic APIs',"b'The following examples shows a way to retrieved the underlying model learned by a trainer, but I failed compiling it. For [static APIs](https://github.com/dotnet/machinelearning/blob/e3830910531f00013c27391914233a085a1394a4/test/Microsoft.ML.StaticPipelineTesting/Training.cs#L434), we are able to assign `FastTreeRegressionModelParameters` to `pred` but in the corresponding dynamic API, the type of `p` becomes \r\n```csharp\r\nMicrosoft.ML.Data.BinaryPredictionTransformer<Microsoft.ML.Internal.Internallearn.IPredictorWithFeatureWeights<float>>\r\n```\r\n, which doesn\'t publicly expose `FastTreeRegressionModelParameters as one of its field.\r\n```csharp\r\n            var data = new TextLoader(Env,\r\n                    new TextLoader.Arguments()\r\n                    {\r\n                        Separator = "";"",\r\n                        HasHeader = true,\r\n                        Column = new[]\r\n                        {\r\n                            new TextLoader.Column(""Features"", DataKind.R4, 0, 10),\r\n                            new TextLoader.Column(""Label"", DataKind.R4, 11)\r\n                        }\r\n                    }).Read(GetDataPath(TestDatasets.generatedRegressionDataset.trainFilename));\r\n\r\n\r\n            var trainer = ML.BinaryClassification.Trainers.FastTree(\r\n                new FastTreeBinaryClassificationTrainer.Options\r\n                {\r\n                    NumThreads = 1,\r\n                    NumTrees = 10,\r\n                    NumLeaves = 5,\r\n                });\r\n\r\n            FastTreeRegressionModelParameters pred = null;\r\n            trainer.WithOnFitDelegate((p) => { pred = p; });\r\n```\r\nAny tricks I can use to make this code example compiled without using internal classes? Or we need to modify our dynamic APIs?\r\n\r\ncc @TomFinley, @Ivanidzo4ka, @sfilipi, @zeahmed.\r\n\r\nWe also should add an example using public interfaces introduced in #2243 after fixing this issue.'"
404576675,2318,b'Add support for custom missing value in ValueMappingTransformer.',"b'The `ValueMappingTransformer` currently handles missing values. It does so by using the default value for the value type.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b4c10662706589426a0a870304e3088dec8077ac/src/Microsoft.ML.Data/Transforms/ValueMapping.cs#L807\r\n\r\nIn some cases, it is desirable to map the value that is missing in the dictionary with the user specified value. For example, when using the following text classification model from TensorFlow\r\nhttps://github.com/tensorflow/models/tree/master/research/sentiment_analysis\r\n\r\n, an `out-of-vocabulary` word (missing value) is mapped to integer `3`. This cannot be done currently using `ValueMappingTransformer`  in ML.NET.\r\n'"
404554268,2316,b'Concat transform is missing a link to its sample',b'The concat transform is missing a link to the sample.\r\n\r\n#1209 '
404543801,2315,b'Add sample link to mutual information feature selection docs',"b""The mutual information feature selection docs don't contain links to the samples for it.\r\n\r\nRelated to #1209 """
404529487,2313,b'MulticlassClassification.Trainers.StochasticDualCoordinateAscent',"b'### System information\r\n\r\n- **Windows 7 Enterprise**:\r\n- **.NET Framework 4.6.1**: \r\n\r\n### Issue\r\n\r\n- **What did you do? I\'m trying to predict an error classification based on error message. I have three classifications. Dismiss, Immediate and Observe. Trained, evaluated, saved and now consuming the model file. I\'m using the MulticlassClassification.Trainers.StochasticDualCoordinateAscent trainer.**\r\n- **What happened? It works fine for errors that exist in the training data. Predicting very well. However, for new error that comes in, it appears to be grabbing the classification with largest population. In my case, it\'s the Dismiss.**\r\n- **What did you expect? I really wanted to classify the new error to flag as Immediate as at this time it is unknown and needs to be investigated. Perhaps I am using the wrong trainer and instead of StochasticDualCoordinateAscent, I should be using another trainer?**\r\n\r\n### Source code / logs\r\n\r\nmlContext = new MLContext(seed: 0);\r\ntrainErrorsEnumerable = TrainErrors(trainingViewVersion);\r\ntrainErrorsDataView = mlContext.CreateStreamingDataView(trainErrorsEnumerable);\r\ntestErrorsEnumerable = TestErrors();\r\ntestErrorsDataView = mlContext.CreateStreamingDataView(testErrorsEnumerable);\r\n\r\ndataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Message"", ""MessageEncoded""))\r\n\r\nmodelBuilder = new Common.ModelBuilder<Error, Models.ErrorPrediction>(mlContext, dataProcessPipeline);\r\ntrainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: ""Label"",featureColumn: ""Features"");\r\nmodelBuilder.AddTrainer(trainer);\r\nmodelBuilder.Train(trainErrorsDataView);\r\nvar metrics = modelBuilder.EvaluateMultiClassClassificationModel(testErrorsDataView, ""Label"");\r\nmodelBuilder.SaveModelAsFile(modelFilePath);\r\nvar modelScorer = new Common.ModelScorer<Error, Models.ErrorPrediction>(mlContext);\r\nmodelScorer.LoadModelFromZipFile(modelFilePath);\r\nvar predictionScores = modelScorer.PredictSingle(error);\r\n'"
404496742,2311,b'Consider changing Pretrained Dnn Image packages to not be built every day/release',"b""The Pretrained Dnn Image packages:\r\n\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet18/\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet50/\r\n- Microsoft.ML.DnnImageFeaturizer.AlexNet/\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet101/\r\n\r\nContain rather large files. The AlexNet package alone is 200MB.\r\n\r\nHowever, we rebuild and republish these same large files every day in our official build:\r\n\r\nhttps://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML.DnnImageFeaturizer.AlexNet\r\n\r\nAnd we publish new versions of them every release:\r\n\r\nhttps://www.nuget.org/packages/Microsoft.ML.DnnImageFeaturizer.AlexNet/\r\n\r\nHowever, the large files in these packages haven't changed 1 time since we've enabled this feature.\r\n\r\nWe should consider splitting these packages up, or some other way of not having to republish the same large files over and over.\r\n\r\n/cc @vaeksare @shauheen @glebuk """
404492614,2310,b'All namespaces should have a top-level description',"b'Currently none of our namespaces has a top-level description, causing the description column to be completely empty at [the docs site](https://docs.microsoft.com/en-us/dotnet/api/index?view=ml-dotnet)\r\n\r\n\r\n'"
404451038,2306,"b""Add a Functional.Tests project that doesn't have InternalsVisibleTo""","b""Today, our ML.NET project has `InternalsVisibleTo` all of our tests projects. This is not ideal because we can't ensure that our public API meets scenarios that our customers can actually use. We could easily internalize something that is necessary to a scenario, but we wouldn't catch it by our tests because our tests all have internal-access.\r\n\r\nWe should add a new test project - or set of test projects - that do not have `InternalsVisibleTo` access. We can put all our public API tests in this project, and we can ensure that customers can use the same code to meet those scenarios. At first we should have at least one test in the project(s), and we can migrate and add new tests over time.\r\n\r\n/cc @TomFinley @shauheen @glebuk """
404447239,2305,b'Change default # of iterations in Averaged Perceptron to 10',"b'@justinormont figured out that setting default # of iterations to 10 in the Averaged Perceptron learner would lead to better results\r\n\r\nFrom: Justin Ormont\r\nSent: Monday, April 3, 2017 2:52:13 PM\r\nSubject: Re: Move AveragedPerceptron defaults to iter=10 \r\n \r\nGreetings folks,\r\n \r\nI had a chance to run larger datasets, and I think my conclusion holds. \r\n \r\nI did a sweep of the 15GB dataset, and the 2.7TB dataset. \r\n \r\nSweep: 1 to 20 iterations; while it\'s still running; it\'s finished most of the experiments and the pattern is pretty clear.\r\n \r\n**15GB text** (note x-axis is number of iterations, not time; y-axis AUC)\r\n![image](https://user-images.githubusercontent.com/43974253/51938308-9cedc800-23c1-11e9-855d-2c08c35de2ad.png)\r\nAlso run (not shown) was **FastTreeBinary**, its AUC is below this graph at 89.1%, and much, much slower.\r\n \r\n**2.7TB numeric** (note x-axis is number iterations, not time; y-axis AUC)\r\n![image](https://user-images.githubusercontent.com/43974253/51938318-a24b1280-23c1-11e9-872e-62a9dedec045.png)\r\n \r\nIt doesn\'t appear that I\'ve hit overfitting thus far in either dataset. AUC continues to increase from a low at iter=1 (far left), to a high on the right (iter=15)\r\n \r\n## How does AP iterations affect time?\r\n \r\nTime was a bit odd (not a smooth graph) but generally increasing as the number of iterations increases.\r\n \r\n**15GB text** (note x-axis is iteration count, y-axis is time)\r\n\r\n \r\n![image](https://user-images.githubusercontent.com/43974253/51938564-40d77380-23c2-11e9-90d1-0a1027d5a68f.png)\r\n\r\n\r\nTime was almost constant with added iterations (noise is due zooming). There\'s ~5% runtime difference between fastest and slowest on this graph, with 15 iterations being fastest (likely noise).\r\n\r\nFor 1 iterations: 14,478 (4.0 hours)\r\nFor 10 iterations: 14,623 sec (4.1 hours)\r\nThat\'s a very sub-linear 1.01x growth from 1 to 10 iterations\r\n \r\n \r\n**2.7TB numeric**  (note x-axis is iteration count, y-axis is time)\r\n \r\n![image](https://user-images.githubusercontent.com/43974253/51938570-47fe8180-23c2-11e9-8973-3e966a417040.png)\r\n\r\n\r\nSorry, the GUI cuts off the time labels on the left. Time given on next line.\r\nFor 1 iteration: 111,367 sec (1.3 days); \r\nFor 10 iterations: 317,203 sec (3.7 days). \r\nThat\'s a sub-linear 2.8x growth from 1 to 10 iterations.\r\n \r\n \r\nI think the 15GB text dataset fitting fully in memory causes it to have a near constant runtime vs iterations and it\'s dominated by another factor, like Text featurization[wild guess].\r\nThe dataset being 2.7TB had to have caching turned off, and each iteration had to fetch the data from CT01; data fetch time may have dominated[wild guess].\r\n \r\nPresented is AUC as the datasets are binary. Accuracy graphs look similar though more noisy indicating perhaps we could look at how we\'re setting the binary threshold.\r\n \r\n**Memory usage**\r\nIn both datasets, memory usage appears flat (plus noise) as iteration count increases.\r\n \r\n \r\n**Methodology**\r\nBoth datasets are binary classification of larger size than previous experiments w/ AveragedPerceptron\'s iteration count. All experiments were run on HPC with each experiment taking a full node until finished. Data was stored on CT01.\r\n \r\nFor the 2.7 TB numeric dataset, caching, normalization and shuffling were turned off. Caching was disabled due to size (2.7TB)\r\n \r\n\r\n**Conclusion**\r\nFor AveragedPerceptron, iterations=10 seems to be an OK default for these two larger datasets; it appears the ""best"" (in terms of AUC/Acc) hasn\'t been hit and is above 15 for these. \r\n \r\nFor 10 iterations, the added duration in the 15GB dataset was negligible and the added runtime for the 2.7TB was an additional 1.8x. \r\n \r\nThe 2.7TB dataset gains ~0.2% AUC w/ 10 iterations (~7% decrease in relative AUC-loss [aka, 1-AUC]). The 15G dataset gains ~0.4% AUC w/ 10 iterations (~4% decease in relative AUC-loss).\r\n'"
404124516,2301,b'Create a test for text classification in TensorFlow.',b'Create an example test which takes textual features as input and output the probability of being in each class.'
404071500,2299,b'FastRank MSM sparse test baselines are suspicious ',"b""We shouldn't have this \r\nhttps://github.com/dotnet/machinelearning/blob/master/test/BaselineOutput/Common/FastRank/FastRank-TrainTest-MSM-sparse-sample-out.txt\r\n`Could not find file '%Data%`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/BaselineOutput/Common/FastRank/FastRank-TrainTest-MSM-sparse-sample-test-out.txt\r\n`Unexpected exception: Could not find file '%Output% 'System.IO.FileNotFoundException'`\r\n\r\nWe shouldn't have such baselines.\r\n"""
404069870,2298,b'AvxIntrinsics.DotSU is Slower than the native version ',b'We can verify this by running the benchmark https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Text/MultiClassClassification.cs#L62\r\n\r\n``` ini\r\n\r\n\r\n```\r\n|      Method |     (netcoreapp2.1)Mean |    Error |   StdDev |        netcoreapp3.0 |\r\n|------------ |--------------:|---------:|---------:|--------------------:|\r\n| CV_Multiclass_WikiDetox_WordEmbeddings_OVAAveragedPerceptron| 148.84s | 28.107 s | 1.5 s | 158.3s |\r\n\r\nI verified using the perfview that the cause of regression is DotSU. The exclusive time fot DotSU on netcoreapp3.0  is 70s and on native version of cpumath is 47 s\r\n\r\nThis failure is not due to small array size. The size of the arrays involved is in thousands\r\n\r\ncc @danmosemsft @adamsitnik @tannergooding @eerhardt \r\n'
404069855,2297,b'Naming overhaul for IDataView subsystem',"b'We should make sure the type names in the IDataView subsystem are the names we want to use forever.\r\n\r\nSee \r\n\r\n1. https://github.com/dotnet/machinelearning/pull/2220#discussion_r251141578\r\n\r\n> If all of these types are column types, should they include column in the name? e.g. TextColumnType?\r\n\r\n2. https://github.com/dotnet/machinelearning/pull/2254#discussion_r251259500\r\n\r\n> The idea was broached I know, but resolution never reached: should we rename? Or else perhaps make Schema a nested class of something appropriate, so as to give it definition?\r\n\r\n> We could rename the class to DataViewSchema, or ViewSchema.\r\nWe\xe2\x80\x99d probably want to rename everything then. Row is a pretty generic name. So is ColumnType.\r\n\r\n\r\n________\r\n\r\n# Proposal\r\n\r\n1. We will ensure the class names in the `Microsoft.Data.DataView` package are unique by adding a prefix to any name deemed too general.\r\n    - Currently we have 2 options for the prefix:\r\n        - `DataView`, ex. `DataViewSchema`, `DataViewRow`, `DataViewType`.\r\n        -  `DV`, ex. `DVSchema`, `DVRow`, `DVType`. \r\n            - Note: this is following the `Db` prefix pattern in `System.Data`: `DbDataReader`, `DbConnection`, `DbColumn`, etc.\r\n            - It could be argued to lower-case the `v`: `DvSchema` to follow the same pattern above.\r\n2. Add the base type suffix to all types that derive from the current `ColumnType` class, using whatever name we decide for the base `ColumnType` class. For example, assuming we rename `ColumnType` => `DataViewType`, we would have:\r\n    - `NumberDataViewType`\r\n    - `TextDataViewType`\r\n    - `BooleanDataViewType`\r\n    - etc\r\n3. Rename the properties on [`NumberType`](https://github.com/dotnet/machinelearning/blob/17b07d8ec34a843410b125cecd4205428d1b9c69/src/Microsoft.Data.DataView/ColumnType.cs#L103) to match the type name in `System.` namespace.\r\n    - ex. use `Int16` instead of `I2`. use `Single` instead of `R4`.\r\n    - For the `UG` property and corresponding `struct RowId`, use whatever we rename the `Row` type, followed by `Id`. Example, `DataViewRowId`.\r\n4. Rename the `Schema.Metadata` class to `Schema.Annotations`, and rename the property on `Schema.Column` from `Metadata` to `Annotations`.\r\n5. Move the `Builder` classes to be nested under the types they build, following the same pattern as [`System.Collections.Immutable`](https://docs.microsoft.com/en-us/dotnet/api/system.collections.immutable.immutablearray-1.builder).'"
404065679,2294,b'TextLoader backcompat version number is wrong ',b'The version number for backwards compatibility comparison in TextLoader is wrong. It should be updated to the correct version number 0x0001000C.\r\n\r\nWe should also add a test for backwards compatibility.\r\n\r\nThis is related to the change #2146.'
404058095,2293,b'SequencePool.GetCore slower on netcoreapp3.0',"b'https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Text/MultiClassClassification.cs#L122 \r\n\r\nBenchmark is slower on netcoreapp3.0. On investigation, I find out the major culprit for the regression is the function below\r\n\r\n\r\n```C#\r\n// Returns the ID of the requested sequence, or -1 if it is not found.\r\nprivate int GetCore(uint[] sequence, int min, int lim, out uint hash)\r\n{\r\n    AssertValid();\r\n    Contracts.Assert(0 <= min && min <= lim && lim <= Utils.Size(sequence));\r\n\r\n    hash = Hashing.HashSequence(sequence, min, lim);\r\n\r\n    for (int idCur = GetFirstIdInBucket(hash); idCur >= 0; idCur = _next[idCur])\r\n    {\r\n        Contracts.Assert(0 <= idCur && idCur < _idLim);\r\n        if (_hash[idCur] != hash)\r\n            continue;\r\n\r\n        var ibCur = _start[idCur];\r\n        var ibLim = _start[idCur + 1];\r\n        for (int i = min; ; i++)\r\n        {\r\n            Contracts.Assert(ibCur <= ibLim);\r\n            if (i >= lim)\r\n            {\r\n                // Need to make sure that we have reached the end of the sequence in the pool at the\r\n                // same time that we reached the end of sequence.\r\n                if (ibCur == ibLim)\r\n                    return idCur;\r\n                break;\r\n            }\r\n            if (ibCur >= ibLim)\r\n                break;\r\n            uint decoded;\r\n            var success = TryDecodeOne(_bytes, ref ibCur, _start[idCur + 1], out decoded);\r\n            Contracts.Assert(success);\r\n            if (sequence[i] != decoded)\r\n                break;\r\n        }\r\n    }\r\n    return -1;\r\n}\r\n```\r\n\r\nThe exclusive time for this function on netcore2.1 is areound 689ms where as on netcoreapp3.0 it takes around 824ms\r\n\r\nThe function is defined here https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Utils/SequencePool.cs#L151\r\n\r\nI was not able to find any reason behind this regression. cc @eerhardt @danmosemsft @jkotas \r\n'"
404050430,2292,b'Tensorflow sharp files need to come from a nuget ',"b'The files under Microsoft.ML.Tensorflow/Tensorflow should come from a nuget since ML.NET team does not maintain these files. These files are also included in code coverage when they should not be, PR #2290 removes them.'"
404043553,2291,b'ONNXML.cs needs to be generated at BUILD',"b'Currently ONNXML.cs is generated manually using protobuf definition. It is also included as part of code coverage which should not happen and PR #2290 will remove it. We need to make it such that it is clear that file is not authored by ML.NET team and is coming from an external source. \r\n\r\nCC: @wschin , @shauheen , @TomFinley '"
404033442,2289,b'Update NuGet Metdata for Microsoft.Data.DataView',"b'With the introduction of the new NuGet we need to update some of the metadata to better signify the position of DataView.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/pkg/Directory.Build.props#L26\r\n\r\nshould be overridden to show the following info for this specific package only:\r\n\r\n```\r\n    <projectUrl>https://dot.net/</projectUrl>\r\n    <iconUrl>http://go.microsoft.com/fwlink/?LinkID=288859</iconUrl>\r\n```\r\n \r\n@eerhardt , @danmosemsft \r\n'"
404015455,2288,b'Make entrypoints inside Microsoft.ML.Transforms project internal',"b""We have 20+ entrypoints classes inside Microsoft.ML.Transforms like [this](https://github.com/dotnet/machinelearning/blob/a570da14a41f2870eb8f61d84496a58422398253/src/Microsoft.ML.Transforms/NAHandling.cs#L14) one. I think they should be made internal because the end-user would use the MLContext extensions instead, not these entrypoints. Also, the entrypoints documentation doesn't get rendered properly because the TlcModule.EntryPoint annotation is not understood by docs.microsoft.com (example: #1725)\r\n\r\nThoughts?\r\n\r\n/cc @TomFinley @sfilipi @eerhardt """
404003450,2286,b'TensorFlow redist nuget package wants license url',b'Run:\r\nbuild -BuildPackages locally.\r\n```\r\nerror : Enabling license acceptance requires a license url. [d:\\src\\fork-machinelearning\\pkg\\Microsoft.ML.TensorFlow.Redist\\Microsoft.ML.TensorFlow.Redist.nupkgproj]\r\n```'
403989510,2283,b'Error load Model (Generated from 64 bit ) From 32 bit ',"b'### System information\r\n\r\n- **OS version/distro**: W10\r\n- **.NET Version (eg., dotnet --4.6.1)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\ni generated a model From 64 bit application and saved the .zip file \r\nthen try load this Model from 32 bit application\r\n- **What happened?**\r\nit throw an exception while loading the model\r\n""\'Could not load type \'Microsoft.ML.Transforms.Categorical.CategoricalTransform\' from assembly \'Microsoft.ML.Transforms, Version=1.0.0.0, Culture=neutral""\r\n- **What did you expect?**\r\nmy believe is there is a different in transform information between 32 , 64 \r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nGenerating model from 64 bit process \r\n\r\n` public void BuildNormalTrainEvaluateAndSaveModel()\r\n        {\r\n            //Set a random seed for repeatable/deterministic results across multiple trainings.\r\n            var mlContext = new MLContext(seed: 1);\r\n\r\n            #region ""STEP 1: Common data loading configuration""\r\n            IDataView trainingDataView = GetNormalDataSet(mlContext);\r\n            #endregion\r\n            #region ""STEP 2: Common data process configuration with pipeline data transformations""\r\n            var dataProcessPipeline1 = mlContext.Transforms.Text.FeaturizeText(new List<string> { ""tagText"", ""firstWord"", ""fontColor"" }, ""Features"");\r\n\r\n            var dataProcessPipeline = mlContext.Transforms.Concatenate(""Features"", ""fontSize"",\r\n                                                                                       ""isBold"",\r\n                                                                                       ""isItalic"",\r\n                                                                                       ""isUnderLine"",\r\n                                                                                       ""containsDot"",\r\n                                                                                       ""containsQuestionMark"",\r\n                                                                                       ""isAllCaps""\r\n                                                                                        );\r\n            //var dataProcessPipeline2 = mlContext.Transforms.Text.FeaturizeText(new List<string> { ""Label"" }, ""Features"");\r\n            dataProcessPipeline.Append(dataProcessPipeline1);\r\n            //mlContext.Transforms.CustomMapping()\r\n            #endregion\r\n            #region  ""STEP 3: Set the training algorithm, then create and config the modelBuilder""                            \r\n            var modelBuilder = new ModelBuilder<NormalTagsModelFeatures, NormalTagsPrediction>(mlContext, dataProcessPipeline);\r\n            // We apply our selected Trainer \r\n            //modelBuilder.AddEstimator(dataProcessPipeline1);\r\n            //modelBuilder.AddEstimator(new Dictionarizer(""Label""));\r\n            //modelBuilder.AddEstimator(dataProcessPipeline2);\r\n\r\n            var pipeline = mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                .Append(dataProcessPipeline1)\r\n                .Append(mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: ""Label"", featureColumn: ""Features""))\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\n            //var trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: ""Label"", featureColumn: ""Features"");\r\n            //modelBuilder.AddTrainer(trainer);\r\n            modelBuilder.AddTrainer(pipeline);\r\n            #endregion\r\n            #region ""STEP 4: Train the model fitting to the DataSet""\r\n            //The pipeline is trained on the dataset that has been loaded and transformed.\r\n            //Console.WriteLine(""=============== Training the model ==============="");\r\n\r\n            modelBuilder.Train(trainingDataView);\r\n            #endregion\r\n            #region ""STEP 5: Evaluate the model and show accuracy stats""\r\n            //Console.WriteLine(""===== Evaluating Model\'s accuracy with Test data ====="");\r\n            //var metrics = modelBuilder.EvaluateMultiClassClassificationModel(trainingDataView, ""Label"");\r\n            //Common.ConsoleHelper.PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);\r\n            #endregion\r\n            #region ""STEP 6: Save/persist the trained model to a .ZIP file\r\n            //Console.WriteLine(""=============== Saving the model to a file ==============="");\r\n            string fullFilePath = GetModelPath(""Norm"");\r\n[Norm_131931638095612677_544677f3-3124-4979-aae8-0a6142ab4c67.Zip](https://github.com/dotnet/machinelearning/files/2804785/Norm_131931638095612677_544677f3-3124-4979-aae8-0a6142ab4c67.Zip)\r\n\r\n            modelBuilder.SaveModelAsFile(fullFilePath);\r\n            #endregion\r\n        }\r\n`\r\n\r\nLoad Model From 32 bit proccess\r\n\r\n```\r\npublic void LoadNormalTagsModel(string modelPath)\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n            ITransformer trainedModel;\r\n//Here is the Exception line\r\n            using (var stream = new FileStream(modelPath, FileMode.Open, FileAccess.Read, FileShare.Read))\r\n            {\r\n                trainedModel = mlContext.Model.Load(stream);\r\n            }\r\n            var predEngine = trainedModel.CreatePredictionEngine<NormalTagsModelFeatures, NormalTagsPrediction>(mlContext);\r\n            \r\n        }\r\n```\r\n\r\ni attached the generated model , \r\n\r\nhow can i overcome this scenario please advice\r\n\r\nHistory \xf0\x9f\x91\x8d https://github.com/dotnet/machinelearning-samples/issues/216'"
403960852,2282,b'Lockdown Microsoft.ML.Transforms public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.'"
403960616,2281,b'Lockdown Microsoft.ML.TimeSeries public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.'"
403960467,2280,b'Lockdown Microsoft.ML.TensorFlow public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.'"
403960221,2279,"b'Separate Nuget versioning for ""final"" and ""experimental"" nugets'","b'Right now all our nugets have one global version. Once we ship V1, however, there will be some assemblies and nugets that are ""final,"" in that their API surface is locked and going forward we do not make breaking changes, and other assemblies doing more experimental work where we\'re not quite so sure what the final surface will look like.\r\n\r\nAn example of this is `Microsoft.ML.StaticPipe` and friends. The statically typed pipelines work is interesting and we want to continue working on it post v1. Similarly, `Microsoft.ML.Ensemble` seems like something we don\'t have time to get the API ""right"" for yet. (Though we might solve that specific one in a different way by just hiding it altogether for now.)\r\n\r\nA different example of this would be things like `Microsoft.ML.EntryPoints`, which we have to make public for ""reasons,"" but cannot reasonably be said to have a public API.\r\n\r\nAnother example would be some sort of ""smuggler\'s cove"" assembly/nuget (which does not yet exist) that exposes some infrastructure that some important scenario or other needs access to, but we are not comfortable making as part of our public API. (E.g., some conduit to ""get at"" the internal methods of the `ComponentCatalog`.)\r\n\r\n @eerhardt opined that if we do that, then of course there should be a separate versioning scheme for those. This would include changes to the package build infrastructure to accomodate this ""two tier"" structure we do not have yet.'"
403958011,2278,"b""Simplify post-prediction schema info to make user-friendly prediction's info such as list of ranked predicted labels/categories""","b'**CONTEXT:** \r\n\r\nIn this PR (and probably, available in 0.10), we\'re allowing the user to get some schema info after predicting:\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/2250 \r\n\r\nThat way a user can get, for example, get the list of the predicted labels in a multi-class classification and related that to the list/array of scores. \r\n\r\nThat\'s very useful for business cases where you want to automatically predict/assign a product to multiple categories, for example, instead of predicting a single category/label.\r\n\r\nHowever, the current user\'s code needs to be like the following, using not user-friendly types such as VBuffer, etc.:\r\n\r\n```\r\n            // Slot names on top of Score column represent original labels for i-th value in Score array.\r\n            VBuffer<ReadOnlyMemory<char>> slotNames = default;\r\n            engine.OutputSchema[nameof(IrisPrediction.Score)].GetSlotNames(ref slotNames);\r\n            // Key names represent original values for PredictedLabel column.\r\n            VBuffer<ReadOnlyMemory<char>> keys = default;\r\n            engine.OutputSchema[nameof(IrisPrediction.PredictedLabel)].GetKeyValues(ref keys);\r\n\r\n            Assert.True(slotNames.GetItemOrDefault(0).ToString() == ""Iris-setosa"");\r\n            Assert.True(slotNames.GetItemOrDefault(1).ToString() == ""Iris-versicolor"");\r\n            Assert.True(slotNames.GetItemOrDefault(2).ToString() == ""Iris-virginica"");\r\n```\r\n\r\n**REQUEST:**\r\n\r\nThe ask is to simplify it and provide types and simpler API with user-friendly data-types that are familiar for regular .NET developers. \r\n\r\nAlso, a more straightforward way to relate the list of labels with their related scores. Maybe returning a single array/list with both concepts coming along (labels-scores) instead of separated arrays/lists?\r\n\r\n\r\n-------------\r\nRelated info\r\n-------------\r\n\r\nThis topic is related with this original issue, too:\r\nMulti-class classification returning ranked list of possible labels): https://github.com/dotnet/machinelearning/issues/2233\r\n'"
403957934,2277,b'Lockdown Microsoft.ML.SamplesUtils public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.\r\n\r\nThis is an odd one. In spirit it seems similar to [similar utilites from sklearn](https://scikit-learn.org/stable/datasets/index.html), which are valuable. But, should it be part of the main nuget? Is this public API surface what we really want? It seems like maybe making it an extension on top of `DataOperationsCatalog` or somesuch might be a better choice. And should it be in a separate Nuget since its functionality is just to make some samples be self contained? (Certainly our samples could reference another nuget, since this one is so odd.)\r\n\r\nThese existential questions may be best answered by @sfilipi .'"
403956157,2276,b'Lockdown Microsoft.ML.Recommender public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.\r\n\r\nThis particular assembly and its nuget might be one we mark as having an experimental API via its nuget. It seems valuable, but I\'m not sure how confident we are that we got the shape of the API ""right."" @wschin may know best on this front.'"
403955447,2275,b'Lockdown Microsoft.ML.PCA public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API.'"
403955169,2274,b'Lockdown Microsoft.ML.Parquet public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API. In particular, making it resemble the other methods for creation of data views out of files (similar to text loading and binary file loading) would probably be the focus. Having it be what we call an `IDataReader` instead of the old legacy `IDataLoader` would be necessary.\r\n\r\nIf we do not have time for that, then perhaps making everything in this internal or else making the `Microsoft.ML.Parquet` nuget an experimental version is an answer.'"
403953134,2273,b'Lockdown Microsoft.ML.Onnx public surface',"b'We ought to internalize as much of that assembly to those things we want to be public, and finalize its public API. This may be completed already; the public surface area I hope should just be the extension methods to export.'"
403952471,2272,"b'Lockdown Microsoft.ML.OnnxTransform public surface, possibly rename'","b'We ought to internalize as much of that assembly to those things we want to be public.\r\n\r\nAlso, I wonder if the assembly and associated nuget (both `Microsoft.ML.OnnxTransform`) is misnamed. We do not have ""transforms,"" we have ""transformers.""'"
403951851,2271,b'Lockdown Microsoft.ML.LightGBM public surface',b'We ought to internalize as much of that assembly to those things we want to be public.'
403951691,2270,b'Lockdown Microsoft.ML.KMeansClustering public surface',b'We ought to internalize as much of that assembly to those things we want to be public.'
403951449,2269,b'Lockdown Microsoft.ML.ImageAnalytics public surface',b'We ought to internalize as much of that assembly to those things we want to be public.'
403951121,2268,"b'Lockdown Microsoft.ML.Ensemble public surface, or isolate it'","b""We ought to internalize as much of that assembly to those things we want to be public. The trouble with this one is that the API for ensembling, it is unclear what a good public version would look like and we don't have time to develop it. So it may be that at least for now internalizing the *whole thing* is the answer.\r\n\r\nComplicating matters, FastTree depends on this assembly; it may do so for good or bad reasons, I am not sure. That should be investigated. If it is not doing so for important reasons, we could break that dependency in some fashion, and then put Ensemble in a separate Nuget that we will keep in a sub-v1 version even as much of the API becomes v1."""
403947411,2267,b'Lockdown Microsoft.ML.HalLearners public surface',b'We ought to internalize as much of that assembly to those things we want to be public.'
403947143,2266,b'Lockdown Microsoft.ML.FastTree public surface',b'We ought to internalize as much of that assembly to those things we want to be public. Right now this assembly has a tremendously needlessly large public surface area.'
403946809,2265,b'Lockdown Microsoft.ML.EntryPoints public surface',b'We ought to internalize as much of the Lockdown Microsoft.ML.EntryPoints assembly to those things we want to be public.\r\n\r\nThis may be considered less urgent if we take the decision that the associated EntryPoints nuget is to be marked as experimental for v1.'
403946061,2264,b'Lockdown Microsoft.ML.StandardLearners public surface',b'We ought to internalize as much of the Lockdown Microsoft.ML.StandardLearners assembly to those things we want to be simplified.'
403942080,2263,b'LightGbmMulticlassTrainer does not train correctly',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10 64bit\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n4.7.2 .Net Framework\r\nML.Net v0.9\r\nCompiling with x64 and Release/Debug (does not matter)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI tried to get a simple LightGbmMulticlassTrainer working. I had have a look at several tutorials as I am quite new to this library but not to Machine Learning in general. \r\n\r\n- **What happened?**\r\nWhen I train the dataset with LightGbmMulticlassTrainer, it will always return an accuracy of 33,3%, because it always predicts ""Setosa"". However what is strange is, that in general my approach works. When I use \r\n\r\nmlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent()\r\n\r\ninstead of my LightGBM trainer it gives me accuracy of 100% (which is not too suprising as my testset and trainingset is the same).\r\n\r\n\r\n### Source code / logs\r\n\r\n            TextLoader textLoader = mlContext.Data.CreateTextReader(new TextLoader.Arguments()\r\n            {\r\n                Separator = "","",\r\n                HasHeader = false,\r\n                Column = new[]\r\n                {\r\n                    new TextLoader.Column(""SepalLength"", DataKind.R4, 0),\r\n                    new TextLoader.Column(""SepalWidth"", DataKind.R4, 1),\r\n                    new TextLoader.Column(""PetalLength"", DataKind.R4, 2),\r\n                    new TextLoader.Column(""PetalWidth"", DataKind.R4, 3),\r\n                    new TextLoader.Column(""Label"", DataKind.Text, 4)\r\n                }\r\n            });\r\n\r\n            IDataView dataView = textLoader.Read(_dataPath);\r\n\r\n            string featuresColumnName = ""Features"";\r\n            var pipeline =  mlContext.Transforms.Conversion.MapValueToKey(""Label"")\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth""))\r\n                .Append(new LightGbmMulticlassTrainer(mlContext, ""Label"",""Features""))\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(""PredictedLabel""));\r\n\r\n            // Train the model.\r\n            var model = pipeline.Fit(dataView);\r\n\r\n            // Compute quality metrics\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(model.Transform(dataView));\r\n            Console.WriteLine(metrics.AccuracyMacro);\r\n\r\n\r\n'"
403639245,2260,b'Hyperparameter optimization framework and sample',b'Framework and sample to perform hyperparameter optimization with IAsyncSweeper wrapped KdoSweeper.\r\n\r\nhttps://github.com/fwaris/HpOpt/tree/master/HpOptModelRunner\r\n\r\nAllows for parallel evaluation of models via multiple client processes and named pipes communication.\r\n\r\nHowever I could not use the NelderMeadSweeper as it runs into some issue with not having enough results returned (I think).\r\n\r\nIn general we need better documentation of the Microsoft.ML.Sweeper namespace.\r\n\r\n\r\n\r\n\r\n'
403618022,2258,b'Code coverage has been disabled for src directory',"b'Pull request #2200 (unintentionally) caused the complete omission of code coverage information from the **src** directory.\r\n\r\nThe following line causes a problem in **Directory.Build.props**:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2f0c4755888e6a6a7f2f1206516479a8120a089b/test/Directory.Build.props#L9-L10\r\n\r\nBy placing this definition early in the build, the following does not take effect:\r\n\r\nhttps://github.com/Microsoft/msbuild/blob/3a844ce00a873d8ca6ba0a8abc0c6b64f772d937/src/Tasks/Microsoft.Common.CurrentVersion.targets#L584-L594\r\n\r\nCurrently the test projects fail to copy assemblies and symbol files to the output directories, which completely breaks code coverage instrumentation for referenced projects. The property needs to be moved to **Directory.Build.targets** so it comes after the common definition.'"
403597488,2257,b'Rename `weights` parameter in ML.NET Public API',b'Couple of conventions to follow for `weights` parameter in ML.NET Public API\r\n\r\n- Name of the `weight` argument in trainer API should be consistent with the other column names i.e it should end on *Column.\r\n- Proposal to disambiguate this by calling it exampleWeightColumn.\r\n\r\n@glebuk '
403452422,2255,b'linqpad fails to load ml.net because of wrong package definition',"b'### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Version (latest**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nLoad nuget in LinqPad 5\r\n\r\n- **What happened?**\r\nError reading a falsely formatted  attribute in [nontent.types].xml\r\n<Override PartName=""//LICENSE"" ContentType=""application/octet"" />\r\nThe two slaches //LICENSE prevent loading\r\n\r\n- **What did you expect?**\r\nThat it loads without hassle!\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
403384908,2253,b'AvxIntrinsics.DotU is Slower than the native version',"b'We can verify this by running the benchmark https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/StochasticDualCoordinateAscentClassifierBench.cs#L157\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.11.3, OS=Windows 10.0.17763.253 (1809/October2018Update/Redstone5)\r\nIntel Xeon CPU E5-1650 v4 3.60GHz, 1 CPU, 12 logical and 6 physical cores\r\n.NET Core SDK=3.0.100-preview-009812\r\n  [Host]     : .NET Core 2.1.6 (CoreCLR 4.6.27019.06, CoreFX 4.6.27019.05), 64bit RyuJIT\r\n  Job-RQXZIO : .NET Core 2.1.6 (CoreCLR 4.6.27019.06, CoreFX 4.6.27019.05), 64bit RyuJIT\r\n\r\nArguments=/p:Configuration=Release  Toolchain=netcoreapp2.1  MaxIterationCount=20  \r\nWarmupCount=1  \r\n\r\n```\r\n|      Method |     (netcoreapp2.1)Mean |    Error |   StdDev |        netcoreapp3.0 |\r\n|------------ |--------------:|---------:|---------:|--------------------:|\r\n| PredictIris | 515.6 ns | 3.097 ns | 2.745 ns | 620.3ns |\r\n\r\nif we use ```UseIntrinsics=false``` Then we get the same performance for netcoreapp3.0\r\n\r\nI verified using the perfview that the cause of regression is DotU. The Inclusive time fot DotU on netcoreapp3.0  is 95ns and on native version of cpumath is 11 ns\r\n\r\n\r\ncc @danmosemsft @adamsitnik @tannergooding @eerhardt '"
403379725,2252,b'Lack of support for UWP apps in ML.NET',"b'Current version (0.9 and 0.10) don\'t support UWP apps properly.\r\n\r\nSee additional details in this Blog Post:\r\nhttps://xamlbrewer.wordpress.com/2019/01/25/machine-learning-with-ml-net-in-uwp-clustering/ \r\n\r\nRelated issues:\r\nhttps://github.com/dotnet/machinelearning/issues/1736\r\nhttps://github.com/dotnet/machinelearning/issues/1595\r\n\r\nSUGGESTED APPROACH:\r\n\r\nUsually, the common scenario for UWP apps (visual desktop applications) is just about scoring a model.\r\nThe same common scenario for ARM based platforms like Xamarin on iOS and Android.\r\n(ARM has nothing to do with this #2252 issue, it just happens that we still don\'t support ARM, neither)\r\n\r\nThe suggested approach would be to split ML.NET components/NuGet packages so the scoring components are segregated from the rest of ML.NET. \r\n\r\nAchieving support in UWP and ARM just for the ""scoring part"" of ML.NET might be easier and require less cost/work in testing and development than achieving support for the whole ML.NET (training/test model area).\r\n\r\n\r\n\r\n'"
403374666,2251,b'IPredictor and related parts hiding',"b""We have a few types inside `IPredictor.cs` that are perhaps useful for internal infrastructure, but are not directly useful from the point of view of the `IEstimator`/`ITransformer`/`MLContext` public API.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3e03fcef46e0bdd6961e0cccb7cc490ab535fbaf/src/Microsoft.ML.Core/Prediction/IPredictor.cs#L10\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3e03fcef46e0bdd6961e0cccb7cc490ab535fbaf/src/Microsoft.ML.Core/Prediction/IPredictor.cs#L31\r\n\r\nThe thing that makes me the most nervous are things like `IPredictorProducing` and `IDistPredictorProducing`, which are definitely marker interfaaces that we don't want, but I would argue we don't really want any of this to be public.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3e03fcef46e0bdd6961e0cccb7cc490ab535fbaf/src/Microsoft.ML.Core/Prediction/IPredictor.cs#L43\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3e03fcef46e0bdd6961e0cccb7cc490ab535fbaf/src/Microsoft.ML.Core/Prediction/IPredictor.cs#L67\r\n\r\nThere are a significant number of side effects from this, including the hiding of many other APIs that we want hidden anyway, since anything that is part of the `IEstimator`/`ITransformer`/`IDataView`/`MLConext` idiom does not take an `IPredictor` (it *produces* things that implement that interface, but generally we do not use that interface). So this will be a driver for hiding many other things."""
403357373,2249,b'Internalize or remove Zlib implementation',"b'We have public Zlib types. We should at least make them internal, and remove them if possible.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/0c62e30b4d9eabb60322b2a3e75bc90e20007889/src/Microsoft.ML.Data/DataLoadSave/Binary/Zlib/ZDeflateStream.cs#L10'"
403291754,2247,b'Adding ModelParameters concept in the ML.NET documentation',b'We should probably consider adding ModelParameters concept in the ML.NET documentation  \r\n(albeit one of the low-priority concepts)\r\n\r\nRelated to #1866 \r\n\r\n@eerhardt  @TomFinley  @sfilipi '
403253739,2244,b'Official builds are broken because myget is full',"b'We are not getting official builds because the step that publishes the NuGet package to myget is failing because our feed is full. See https://github.com/dotnet/core-eng/issues/5070.\r\n\r\nWe should disable this step, for now, until the underlying myget feed is fixed.\r\n\r\n/cc @shauheen @safern @Ivanidzo4ka '"
403153995,2242,b'FastTreeBinaryClassificiationTrainer class declaration is incorrect',"b'Using ML.Net 0.9 an error is given when attempting the following - \r\n`var pipeline = mlContext.Transforms.Concatenate(""Features"", featureNames)\r\n        .Append(mlContext.Transforms.Normalize(""Features""))\r\n        .Append(mlContext.BinaryClassification.Trainers.FastTree(numLeaves: 50, numTrees: 50, minDatapointsInLeaves: 20));\r\n\r\n      var model = pipeline.Fit(dataView);\r\n            \r\n      var m = model.LastTransformer.Model;\r\n`\r\n\r\nwhere the error given is - `\'TNewTrans\' does not contain a definition for \'Model\' and no accessible extension method \'Model\' accepting a first argument of type \'TNewTrans\' could be found (are you missing a using directive or an assembly reference?)`\r\n\r\nAdvise given on gitter is that this is due to the class declaration for FastTreeBinaryClassification (FastTreeClassification.cs : line 106) being incorrect and that in that declaration BinaryPredictionTransformer<IPredictorWithFeatureWeights<float>> should be changed to RegressionPredictionTransformer<FastTreeBinaryModelParameters>'"
402963317,2240,b'Help utilizing multi-column vectors',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  2.1.5\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nIn my migration to v0.8, I\'m moving away from the legacy API and have data that consists of over 400 columns. Previously, by manually mapping each column, I achieved results from evaluation:\r\n```\r\nRMS = 1.02567798627118\r\nRSquared = 0.993830469856289\r\n```\r\n\r\nNow, I\'m reading in the columns as multi-column vectors (note: column names have been obfuscated here):\r\n```csharp\r\nTextLoader textLoader = mlContext.Data.TextReader(new TextLoader.Arguments()\r\n            {\r\n                Column = new TextLoader.Column[] {\r\n                    new TextLoader.Column(""NumericRelatedData"", DataKind.R4, 0, 359),\r\n                    new TextLoader.Column(""CategoricalRelatedData"", DataKind.Text, 360, 407),\r\n                    new TextLoader.Column(""SpecificData1"", DataKind.Text, 408),\r\n                    new TextLoader.Column(""SpecificData2"", DataKind.Text, 409),\r\n                    new TextLoader.Column(""SpecificData3"", DataKind.R4, 410),\r\n                    new TextLoader.Column(""Label"", DataKind.R4, 411)\r\n                },\r\n                HasHeader = true,\r\n                Separator = "",""\r\n            });\r\n```\r\n\r\n- **What happened?**\r\nI got vastly different results from my model evaluation:\r\n```\r\n*       L1 Loss:        1.543\r\n*       L2 Loss:        182.015\r\n*       RMS:            13.491\r\n*       Loss Function:  182.015\r\n*       R-squared:      -0.067\r\n```\r\n\r\nAdditionally, the model is not explorable, because the class I have to represent a single prediction has each column mapped to a different field, but those fields cannot be identified in the model.\r\n\r\n- **What did you expect?**\r\nI expected identical metrics, since I\'m using the same trainer (`FastTree`)\r\n\r\nIt\'s obvious that I\'m not understanding how the multi-column vectors are supposed to work.\r\n\r\n**My question is primarily: Do I have to continue to map each column in the TextLoader (and thus all subsequent uses of it in transformers) to get the results I\'d like?**\r\n\r\n### Source code / logs\r\n\r\nI\'m asking a very similar question in the [documentation repo](https://github.com/dotnet/docs/issues/9962)\r\n'"
402948523,2238,b'Code Snippet Language Options Visible for Languages Not Yet Available',"b'On the top toolbar there is a dropdown to select the language to display the code snippet in with options for F# and VB. However, when either F# or VB are selected, the code in the code snipped remains the default C# implementation. \n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 209d151a-38b8-5ef8-57b9-bbdb0fcdef55\n* Version Independent ID: 0dbd3424-7e4e-8189-5f6b-f46767cc7554\n* Content: [OnnxTransform Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.onnxtransform?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/OnnxTransform.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/OnnxTransform.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'"
402947185,2237,b'Remove learningRate argument from FastForest constructor',"b'Started from issue #1983 where there is a comment about learningRate is accessible from the FastForest constructor but not accessible from the FastForest Arguments (now Options) class. After investigating, learningRate is not an argument for FastForest and that it was added to the constructor by mistake. \r\n\r\nFor this issue, the fix is to remove learningRate from the constructor for FastForest and update the code/tests as needed:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/1baaec31e0477cb17032b8a9a8a8488acb3606af/src/Microsoft.ML.FastTree/RandomForestClassification.cs#L155\r\n\r\n\r\n'"
402915267,2233,b'Enable to get ranked-list of predicted labels when performing a multi-class classification prediction',"b""This is a needed scenario that can be pretty common from a business needs perspective.\r\n\r\nWhen using ML.NET code implementing multi-class classification, we\xe2\x80\x99re returning/predicting a single label\xe2\x80\xa6 \r\n\r\n**Multi-class Classification**\r\n- Label: Original Label of the example.\r\n- Score: Its an array whose length is equal to number of classes and contains probability for each class.\r\n**- PredictedLabel: Predicted class.** _<-- (*) There's a single PredictedLabel_\r\n\r\nBut in many business scenarios, a list of possible labels where something can be classified is also very useful.\r\n\r\n\xe2\x80\xa2\tFor instance, a real product might be related to multiple product-categories in an eCommerce, not just one category.\r\n\xe2\x80\xa2\tAnother example where this scenario is possible (and we actually have it working), is image classification in TensorFlow, you can get a list of the best labels with a score per each, from the TF model.\r\n\r\nIn fact, the class used to get a prediction is like:\r\n\r\n   ```\r\n public class MyPrediction\r\n    {\r\n        public float[] Score;\r\n\r\n        public string PredictedLabelValue;\r\n    }\r\n```\r\n\r\nSo, we actually get an array of Scores, like here:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/51705169-bc56b080-1fcf-11e9-8bd2-1ba930359a4a.png)\r\n\r\n**We need a way to map the array of float confidence/score levels back to each original class/label names, in addition to the \xe2\x80\x9csingle best\xe2\x80\x9d PredictedLabelValue.**\r\n\r\nAdditional info provided by **Ivan Matantsev**: \r\n\r\n_Technically it should be accessible via metadata in Schema, but I don\xe2\x80\x99t see any way to access it in transformer.\r\nTheoretically if you load model from file, you can call GetOutputSchema, but if you just do prediction, you don\xe2\x80\x99t have dataview to get Schema you just have example/prediction classes.\r\nSo we either need a way to Expose output Schema in prediction function or to have Transformer which would spit out specific metadata for certain columns._\r\n\r\n\r\n\r\n"""
402859597,2231,b'Remove IDataLoader from public API surfaces for specifying data',"b'So in ""command line"" world, we have things that look like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/eed91b988fe6850d13255d599c9191c9a9b80aa0/src/Microsoft.ML.Data/Transforms/ValueToKeyMappingTransformer.cs#L116-L123\r\n\r\nThis makes sense, considering that when invoking a command line, you are not working in the context of an existing process but starting a new one, so the most plausible source for data is some file, which we have to specify how to load and so on and so on.\r\n\r\nHowever, then we enter API land, and (understandably, to be clear) people just decided to do a direct translation, as we see below:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/eed91b988fe6850d13255d599c9191c9a9b80aa0/src/Microsoft.ML.Data/Transforms/ValueToKeyMappingEstimator.cs#L41-L42\r\n\r\nThat the API might resemble command line as a first preference is understandable, but in this specific context of an API, a variance from this trend would make sense. We\'ve invented what amounts to an entirely new API to load data from a source, when we already have mechanisms to do this.\r\n\r\nIf we wanted this to work over input `IDataView`s, which seems to be what the authors are really getting at, then it should just do so directly. This has a few advantages:\r\n\r\n1. No new way of loading files distinct from existing API for that same task,\r\n2. Simpler method signatures,\r\n3. Hides `IDataLoader` transform, which is something relating to #1995 we need to do anyway. (This in particular is why we might consider this to have some greater urgency.)\r\n\r\n/cc @Ivanidzo4ka @sfilipi '"
402511845,2223,b'Array checks in Utils return true for null arrays',"b'`Microsoft.ML.Internal.Utilities.Utils` has a couple of array checks that return `true` when a `null` array is passed in. Is this the expected behavior?\r\n\r\nHere are the culprits:\r\n\r\n```cs\r\npublic static bool IsSorted(IList<float> values);\r\npublic static bool IsSorted(int[] values);\r\n```\r\n\r\n```cs\r\npublic static bool IsIncreasing(int min, ReadOnlySpan<int> values, int lim);\r\n```\r\n\r\nNote that `IsIncreasing` is typically used for checking `int[]` arrays because `ReadOnlySpan` performs an implicit cast and null arrays are set to a 0-length `ReadOnlySpan`.\r\n\r\nIn a similar vein, `IsSorted` uses a null-safe `Utils.Size()` to check the input length of the array.\r\n\r\nDoes this make sense that we say that `null` arrays are sorted, and that they are decreasing?'"
402446945,2213,b'Array Checks in Microsoft.ML.Internal.Utilities.Utils are not tested',"b'The array tests used as sanity checks are not tested, even though they have very particular expectations on behavior (different from their names imply, sometimes). We should add tests to cover them.'"
402337721,2211,b'Re-build the MKL binaries together with OpenMP and update SymSGD to make use of parallelism',"b'The current binaries for MlNetMKLDeps are build with sequential threading, and SymSgd has parallelism turned off. \r\n\r\nNow that the legal issues around packaging and re-distributing Open MP are clarified, re-build the ML bits with threading=parallel and update SymSGD. '"
402335901,2210,b'Update the cookbook to contain just the dynamic examples',b'A few people have commented that having both the dynamic API and the static API examples in the cookbook is confusing for new users. \r\n\r\nSeparate them into two documents. '
402025304,2207,b'ColumnBindingBase still contains legacy ISchema functions',b'As title. We should try cleaning `ColumnBindingBase` again.'
401620306,2201,b'Build.sh fails due to clang does not exist',"b'### System information\r\n\r\n- OS Distro: ubuntu 18.04\r\n- dotnet version: Version  : 2.0.9  Build    : 1632fa1589b0eee3277a8841ce1770e554ece037\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI tried to build ML.net on my machine. had to run build.sh\r\n- **What happened?**\r\nbuild.sh failed because clang compiler does not exist. see attached exact error\r\n\r\nWhen I tried to install clang I had lot\'s of unmet dependencies which I could not resolve (I really do now know what was the problem here, I followed the dependencies everywhere for a couple of days but no luck)\r\n- **What did you expect?**\r\nI expected that the script uses gcc or g++ to build which comes packaged with Ubuntu.\r\n\r\n### Source code / logs\r\n\r\n Unable to find Clang Compiler\r\n  Install clang-3.5 or clang3.6 or clang3.9\r\n/home/usr/machinelearning/src/Native/build.proj(47,5): error MSB3073: The command /home/usr/machinelearning/src/Native/build.sh"" --configuration Debug --arch x64  --mkllibpath /home/usr/machinelearning/packages/mlnetmkldeps/0.0.0.6/runtimes/linux-x64/native exited with code 1.\r\nBuild FAILED.\r\n/home/usr/machinelearning/src/Native/build.proj(47,5): error MSB3073: The command /home/usr/machinelearning/src/Native/build.sh"" --configuration Debug --arch x64  --mkllibpath /home/usr/machinelearning/packages/mlnetmkldeps/0.0.0.6/runtimes/linux-x64/native exited with code 1.\r\n\r\n### Did you manage to solve this issue? How?\r\nI just replaced clang with gcc and the solution was built successfully which made me think about opening this issue to ask if submitting a PR here makes sense. \r\n'"
401451431,2198,b'NEAT and HYPERNEAT algorithm support.',"b""\r\n### Feature Request\r\n\r\nNEAT is an unsupervised learning method that evolves neural networks as it learns.  Is this something that is on the roadmap for features to implement?  I saw that ANN is on the roadmap, however I wasn't sure if that includes methods like NEAT.\r\n\r\n"""
401343223,2197,b'Latent Dirichlet Allocation (LDA) - how to get a list of topics?',"b""### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10 Home\r\n- **.NET Version (eg., dotnet --info)**: \r\n2.1.6\r\n\r\n### Question\r\nHello\r\n\r\nI have the latest ML.NET version 0.9.0 and I'm trying to use LDA - Latent Dirichlet Allocation but can't figure out how to get a list of topics generated by LDA, can you please suggest how to do it?\r\n\r\nThanks!"""
401214520,2196,b'Mutual information feature selection scores',"b'@rogancarr @asthana86 From 0.7 the MutualInformationFeatureSelectionUtils.Train is removed, i was using to understand the score for the columns in the Mutual feature selection. \r\n\r\nCan you please include the same in upcoming releases i need to understand the scores for the columns in the Mutual feature selection. Something similar to what i see in Azure ML below.\r\n\r\n![image](https://user-images.githubusercontent.com/8811335/51457187-6cc97800-1d76-11e9-8b6e-301693062d19.png)\r\n'"
401050786,2193,b'Code Coverage',b'Integrate coverlet to get coverage files and upload them to codecov.io. Enable code coverage for Windows x64 Debug and later enable for all debug legs when covertlet releases a more performant version. Display code coverage report for every commit in every PR.'
400892129,2191,b'SaveAsText should accept a string path',"b'The MLContext extension `MLContext.Data.SaveAsText` currently has the following signature:\r\n\r\n```csharp\r\n        public static void SaveAsText(this DataOperations catalog,\r\n            IDataView data,\r\n            Stream stream,\r\n            char separatorChar = TextLoader.DefaultArguments.Separator,\r\n            bool headerRow = TextLoader.DefaultArguments.HasHeader,\r\n            bool schema = true,\r\n            bool keepHidden = false)\r\n```\r\n\r\nWe should change the parameter `Stream stream` to `string path`. '"
400790865,2187,b'GAMs only allow getting one feature at a time',"b'As pointed out by @artidoro  on #2142, it is not possible to get the entire set of shape functions and bins in one go. Rather, we have ` GetFeatureWeights(int featureIndex)`. We need a `GetFeatureWeights()` that fetches the entire array.'"
400789828,2186,b'GAMs are missing tests on some methods',"b'GAMs have end-to-end tests, but certain public APIs are not tested:\r\n- Creating a model from new parameters\r\n- GetFeatureWeights()\r\n- GetBinUpperBounds()'"
400584033,2185,b'Conditions in KeyToVectorMappingEstimator.GetOutputSchema seem wrong',"b'While reviewing #2176, I incidentally read what I take to be some bugs in this method, the schema shape propagation for key values:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L762\r\n\r\nAs the name suggests, this ""key to vector"" transformer this produces a vector valued column out of a key-valued column. That key-valued column can be either a scalar, vector, or unknown size vector. Much of the logic in this method did not seem to conform to my understanding of what the transformer is doing (and, in one case, *should* be doing but isn\'t). It may be that we need some more test coverage for this, in addition to fixing the bugs, if I am right about any of these.\r\n\r\n## Bug 1: The Type Test\r\n\r\nLet\'s review the type test:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L770\r\n\r\nI see some problems here:\r\n\r\n* This is the ""key to vector"" transform, yet, there is no test to see if it is a key?\r\n\r\n* Instead first we see that it fails if it\'s of an unknown `DataKind` (which seems totally besides the point).\r\n\r\n* We also see that we have this totally unnecessary `ItemType.GetItemType()`, which considering the description is not necessary.\r\n\r\n* Related: later on we see `col.ItemType is VectorType`, which according to the documentation here could never be the case anyway:\r\n\r\n \r\n https://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Core/Data/IEstimator.cs#L46-L49\r\n\r\n* `col.ItemType is PrimitiveType` is totally redundant given that we already had the much stronger test that it was one of the ""known"" datakinds. (Which, again, is still completely wrong.)\r\n\r\nSo, I think practically, we might have a much stronger test if we dropped practically all this matter and just tested `col.IsKey`. *Maybe* also verify that the raw type is not `ulong` or something. But, the rest of this doesn\'t make a lot of sense to me.\r\n\r\n## Bug 2: Error message\r\n\r\nNow what does that test lead to... it leads to this exception being thrown:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L771\r\n\r\nIf you trace through to what becomes the exception message, it becomes this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Core/Utilities/Contracts.cs#L463\r\n\r\nWhich is of course not right. ""Luckily,"" the test above was so screwed up that the only conceivable way a user could run into it is if they fed in an image type, if I interpret it correctly.\r\n\r\n## Bug 3: The metadata tests.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L774-L780\r\n\r\nThe first batch of metadata should verify that the type is of `col.Kind == SchemaShape.Column.VectorKind.Vector`. Instead, it only verifies it\'s not a *variable* vector. but apparently scalar values are just fine. :)\r\n\r\nFor the second metadata, this is sort of a bug more on the transformer itself than the estimator: given that the behavior of bagging is only relevant on *vectors* of keys, `CategoricalSlotRanges` should be added as metadata on a scalar source column only (or, I guess, ideally on a vector of length 1); if it\'s not a scalar (or vector of length 1), then it could not be a one-hot vector anyway, and so could not be encoding a categorical value. Might be more a @codemzs problem.\r\n\r\nThe third metadata looks actually reasonable, at least at first glance.\r\n\r\n## Bug 4: The column type.\r\n\r\nIf bagging is off, *and* the input is a variable sized vector, then the output will be a variable sized vector as well. Yet we see the result is unconditionally a `.Vector`, which does not cover that case:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb92c06f7207546377f63d969ffe063780ee4922/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L782\r\n\r\n/cc @Ivanidzo4ka '"
400549736,2184,b'failed when adding ML.NET package',"b'### System information\r\nD:\\Works\\Codes\\CSharpPrjs\\dotNetPrjs\\myApp>dotnet --info\r\n.NET Core SDK\xef\xbc\x88\xe5\x8f\x8d\xe6\x98\xa0\xe4\xbb\xbb\xe4\xbd\x95 global.json\xef\xbc\x89:\r\n Version:   2.2.103\r\n Commit:    8edbc2570a\r\n\r\n\xe8\xbf\x90\xe8\xa1\x8c\xe6\x97\xb6\xe7\x8e\xaf\xe5\xa2\x83:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.103\\\r\n\r\nHost (useful for support):\r\n  Version: 2.2.1\r\n  Commit:  878dd11e62\r\n\r\n.NET Core SDKs installed:\r\n  2.2.103 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.2.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\n\r\nI just followed [ML.NET Tutorial](https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial) but failed when adding ML.NET package.\r\n\r\n### Source code / logs\r\n\r\nD:\\Works\\Codes\\CSharpPrjs\\dotNetPrjs\\myApp>dotnet add package Microsoft.ML --version 0.9.0\r\n  Writing C:\\Users\\34460\\AppData\\Local\\Temp\\tmp40CD.tmp\r\ninfo : \xe6\xad\xa3\xe5\x9c\xa8\xe5\xb0\x86\xe5\x8c\x85\xe2\x80\x9cMicrosoft.ML\xe2\x80\x9d\xe7\x9a\x84 PackageReference \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe9\xa1\xb9\xe7\x9b\xae\xe2\x80\x9cD:\\Works\\Codes\\CSharpPrjs\\dotNetPrjs\\myApp\\myApp.csproj\xe2\x80\x9d\xe3\x80\x82\r\nlog  : \xe6\xad\xa3\xe5\x9c\xa8\xe8\xbf\x98\xe5\x8e\x9f D:\\Works\\Codes\\CSharpPrjs\\dotNetPrjs\\myApp\\myApp.csproj \xe7\x9a\x84\xe5\x8c\x85...\r\nerror: \xe6\x97\xa0\xe6\xb3\x95\xe8\xa7\xa3\xe6\x9e\x90 .NETCoreApp,Version=v2.2 \xe7\x9a\x84\xe2\x80\x9cMicrosoft.ML (>= 0.9.0)\xe2\x80\x9d\xe3\x80\x82\r\nerror: \xe5\x8c\x85\xe2\x80\x9cMicrosoft.ML\xe2\x80\x9d\xe4\xb8\x8e\xe9\xa1\xb9\xe7\x9b\xae\xe2\x80\x9cD:\\Works\\Codes\\CSharpPrjs\\dotNetPrjs\\myApp\\myApp.csproj\xe2\x80\x9d\xe4\xb8\xad\xe7\x9a\x84\xe2\x80\x9call\xe2\x80\x9d\xe6\xa1\x86\xe6\x9e\xb6\xe4\xb8\x8d\xe5\x85\xbc\xe5\xae\xb9\xe3\x80\x82\r\n'"
400518940,2183,b'Support in TextReader/TextLoader.Read() for loading dataset files through HTTP (such as from Azure Blobs) in addition to files on the local drive ',"b'This can be a very common scenario if the data is not available locally.\r\n\r\nWe could ready it from Azure Storage Blobs by allowing the TextReader/TextLoader.Read() method to load files through HTTP (such as from Azure Blobs) in addition to files on the local drive that it does today.\r\n\r\nWith an overriden .Read() method providing additional parameters like:\r\n\r\nurl:""http://any-azure-blob-url/sales.csv""\r\nsecretKey:""AgJQV/hHBVymD735hFOzveX4qz54YrO6q8WsM6nyb345l67 \r\n\r\nAnd any other Azure credentials needed.\r\n\r\n\r\n\r\n\r\n'"
400516192,2181,b'Load Http',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
400509207,2179,b'Number of feature columns',"b'It has been a while that ML.NET assumes only one feature column can exist in a training pipeline. Recently, we have added field-aware factorization machine so that argument becomes not 100% correct. We will only have only two public APIs per trainer (please see #2047 as an example). To make our public APIs consistent, we need to determine if feature column name should be an array or a scalar. Or we can introduce another API which accepts multiple feature (even label) columns. @TomFinley, @eerhardt, any comments please?'"
400482464,2177,b'The parameter descriptions should distinguish between columns and column names. ',"b'As @wschin pointed out here: https://github.com/dotnet/machinelearning/pull/2170#issuecomment-455346083 the parmaters, and in general our XML documentation should distinguish between columns and column names. \r\n\r\nThis issue will be considered closed when all the params of this language:\r\n\r\n```\r\n/// <param name=""labelColumn"">The label column.</param>\r\n/// <param name=""featureColumn"">The featureColumn column.</param>\r\n/// <param name=""weights"">The optional weights column.</param>\r\n```\r\nGet changed to: \r\n```\r\n/// <param name=""labelColumnName"">The name of the label column.</param>\r\n/// <param name=""featureColumnName"">The name of the feature column.</param>\r\n/// <param name=""weightsColumnName"">The name of the optional weights column.</param>\r\n```'"
400473294,2175,b'ML.NET public API  exposes parameter `weights` which is not used.',"b""For some of the learners e.g. SdcaRegression  ML.NET public API  exposes parameter `weights`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cabf55b543129e8962ba716e8e22c72ac08773e3/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs#L65-L70\r\n\r\nHowever, the advanced `Options` for  `SdcaRegressionTrainer` do not have a field for 'WeightColumn'.  Also, I believe  the algo itself does not use  weights  (need to verify)\r\n\r\nWe need to scrub our public API  for such spurious uses of  `weights` parameter.\r\n\r\nEDIT :  \r\n- Based on investigations (see below), we see that the `SdcaRegressionTrainer`  does use the weights column.  So the proper fix would be to ensure that the weight column passed in the constructor gets used by the trainer. \r\n- For the example above, we need to add `WeightColumn` in the advanced `Options` for  `SdcaRegressionTrainer`  and verify it gets used by the SDCA trainer.\r\n\r\n@sfilipi @glebuk @TomFinley """
400456878,2174,b'Inconsistency in usage of LossFunction for AveragedPerceptron and OnlineGradientDescent  ',"b""The `Options`  class for AveragedPerceptron  and  OnlineGradientDescent  have a field  `LossFunction`  which is used as a factory \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cabf55b543129e8962ba716e8e22c72ac08773e3/src/Microsoft.ML.StandardLearners/Standard/Online/AveragedPerceptron.cs#L42-L46\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cabf55b543129e8962ba716e8e22c72ac08773e3/src/Microsoft.ML.StandardLearners/Standard/Online/OnlineGradientDescent.cs#L38-L43\r\n \r\nInstead of using the factory pattern, they should be  defined  as `IClassificationLoss` and `IRegressionLoss` respectively.  \r\n\r\nThat's  what the public API also uses:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cabf55b543129e8962ba716e8e22c72ac08773e3/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs#L167-L172\r\n\r\n\r\nRefer to test case `OnlineLinearWorkout`\r\n\r\n@sfilipi \r\n"""
400399978,2172,b'The trainer name types should follow the names used in the contexts',"b'Now that, as part of #1798 the Options of the trainers are part of the API signature, and the name of the trainer type displays as part of it. \r\n\r\nThe API looks like this:\r\n\r\n```\r\n// Pipeline.\r\nvar pipeline = ml.Transforms.Text.FeaturizeText(""SentimentText"", ""Features"")\r\n      .AppendCacheCheckpoint(ml)\r\n      .Append(ml.BinaryClassification.Trainers.SymbolicStochasticGradientDescent(\r\n     new SymSgdClassificationTrainer.Options\r\n     {\r\n         NumberOfThreads = 1\r\n     }));\r\n```\r\n\r\nnotice the discrepancy between the extension name, and the trainer type. \r\nAlign naming where possible. Don\'t abbreviate the names, at least. \r\n\r\n.Append(ml.BinaryClassification.Trainers.**SymbolicStochasticGradientDescent**(\r\n     new **SymSgdClassificationTrainer**.Options'"
400397241,2171,b'Baseline Tests are based on SubComponents',"b'Baseline tests are based on `SubComponents`. Are `SubComponents` going away? Either way, it might be better to have baseline tests using the public API.'"
400033016,2167,b'Models produced by the GAM Trainer depend on feature flocks',"b'In `FastTree`, `Feature Flocks` are simply helpful tools in the calculation and do not impact the final model. When `GAMs` are trained however, the final model is dependent on the `Feature Flocks`. That is, if there are 6 features, and two are flocked, then the resulting model will have 5 shape functions and one of the input features will be ignored. \r\n\r\nAs per `FastTree`, the output of `GAM` training should not depend on whether feature flocks were used in the calculation.'"
399991608,2165,b'Using ScoreTensorFlow model is a bit confusing',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: 0.8.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nSee code below. I\'m loading a pre-trained TensorFlow model and I was working from the existing examples.\r\n- **What happened?**\r\nI didn\'t understand why the example was passing training/test data to get the prediction function (see code and comment below).\r\n\r\n- **What did you expect?**\r\nIt seems like I should just be able create a pipeline with pre-processing steps and ScoreTensorFlowModel and then just get the predict function. To test this theory I tried making MulitFileSource(null) and everything works fine. If it\'s not needed ... Can you recommend different code? If it is needed ... it seems kind of odd.\r\n\r\n### Source code / logs\r\n\r\n```\r\n            var loader = new TextLoader(mlContext,\r\n                new TextLoader.Arguments\r\n                {\r\n                    Column = new[] {\r\n                        new TextLoader.Column(""ImagePath"", DataKind.Text, 0),\r\n                    }\r\n                });\r\n\r\n            // Why is this needed? It works fine with the MultiFileSource being null. There shouldn\'t need to be training data when loading a pre-trained model.\r\n            var data = loader.Read(new MultiFileSource(null));\r\n\r\n            var pipeline = mlContext.Transforms.LoadImages(imageFolder: imageFolderPath, columns: (""ImagePath"", ""ImageReal""))\r\n                            .Append(mlContext.Transforms.Resize(""ImageReal"", ""ImageReal"", ImagePreprocessSettings.imageHeight, ImagePreprocessSettings.imageWidth))\r\n                            .Append(mlContext.Transforms.ExtractPixels(new[] { new ImagePixelExtractorTransform.ColumnInfo(""ImageReal"", TensorFlowModelSettings.InputTensorName, interleave: ImagePreprocessSettings.channelsLast, offset: ImagePreprocessSettings.mean) }))\r\n                            .Append(mlContext.Transforms.ScoreTensorFlowModel(modelFilePath, new[] { TensorFlowModelSettings.InputTensorName }, new[] { TensorFlowModelSettings.OuputTensorName }));\r\n            \r\n            // What am I ""fitting"" and why am I passing ""data""?\r\n            var modeld = pipeline.Fit(data);\r\n\r\n            var predictionFunction = modeld.MakePredictionFunction<TrainTestData, PredictionProbability>(mlContext);\r\n\r\n            return predictionFunction;\r\n```\r\n'"
399983766,2164,b'Loading TensorFlow Models with unsupported Node types throws confusing Exception',"b""### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: ML.Net 0.8.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to load a TensorFlow model with an input of type String.\r\n- **What happened?**\r\nException thrown saying that the node with the given input name didn't exist.\r\n- **What did you expect?**\r\nI would expect this to work but if it's unsupported ... I would expect an Exception thrown saying that the node is an unsupported type instead of saying it doesn't exist.\r\n\r\n### Source code / logs\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.TensorFlow/TensorFlow/TensorflowUtils.cs#L43\r\n\r\nThis should throw an exception or log something to inform developers that there is an unsupported  node.\r\n\r\n"""
399958081,2162,b'Add support for vector as input/output in ValueMappingTransformer',"b""Currently, ValueMappingTransformer https://github.com/dotnet/machinelearning/blob/ef638f480a2be117b181ea52a1786e391244e5d2/src/Microsoft.ML.Data/Transforms/ValueMappingTransformer.cs#L256 does not take vector as input. It works on only on scalar input.\r\n\r\nTo enable Text/NLP scenario (#747) in TensorFlowTransform where model's expected input is vector of integers (indexes into dictionary), following needs to be done. Note that this is only needed if model accepts vector of integers as input.\r\n\r\n1. Tokenize the string into words.\r\n2. Map the words to indexes into the dictionary provided with the TF model.\r\n3. If the model is Seq2Seq model, take the output from the model which is again vector of integers and convert it back to vector of text.\r\n\r\nNo. 1 can be done using ML.Net's WordTokenizer.\r\nNo. 2 and 3 can be done using ML.Net's ValueMappingTransformer. However, it does not currently supports vector as input/output. Furthermore, the Estimator https://github.com/dotnet/machinelearning/blob/ef638f480a2be117b181ea52a1786e391244e5d2/src/Microsoft.ML.Data/Transforms/ValueMappingTransformer.cs#L42 of ValueMappingTransformer also does not expose interface to load dictionary from file."""
399638165,2159,b'AggregateException/InvalidOperationException when training from IEnumerable backed by EF Core Context',"b'### System information\r\n- .Net Core 2.2, EF Core 2.2.1, ML.NET 0.9\r\n\r\n### Issue\r\n\r\n- Read data from SQL DB via EF Core as IEnumerable, pass to pipeline via streaming IDataView\r\n- Get InvalidOperationException from Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.LoopProducerWorker()\r\n- It worked fine in ML.NET 0.8. I can work-around by forcing the trainer to be single-threaded but this makes training in 0.9 much slower than in 0.8 (on my machine).\r\n\r\nThe EF Core problem could be addressed by allowing multiple dbcontexts to be provided but this is likely to be an issue with any non thread-safe IDataView source...  \r\n\r\n### Source code / logs\r\n\r\nSource at: https://github.com/endintiers/Unearth.Demo.ML.FromDB shows this working in 0.8, failing in 0.9 and a work-around for 0.9 (single-threading the training).\r\n'"
399586255,2156,b'Loading of same model for tensorflow throw exception',"b'just run in two different threads:\r\n`var loadModelSchema = TensorFlowUtils.GetModelSchema(mlContext, modelLocation);`\r\nit will throw exception.'"
399572511,2155,b'C# samples should probably use C# and not Python naming conventions',"b'I was reading a PR when suddenly I saw something a bit odd.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/6b9f5893ea6830481a8779f81f2b723e9b5cd6cd/docs/samples/Microsoft.ML.Samples/Dynamic/KeyToValue_Term.cs#L42-L47\r\n\r\nNote the underscores in the middle of a variable name. While in private we might elect to bend the rules a little bit, in our public API and also probably our samples, we probably ought to write them with [consideration of standard practices](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/capitalization-conventions). This does not seem to be a justifiable or explainable diversion from the recommended practice, and I\'m guessing it was added by mistake.\r\n\r\nEach individual renaming is probably not huge, but might span several files, since the example listed above is just one of many examples I see in our samples project. So not a ""hard"" change, except possibly in scale?'"
399558585,2154,b'Add XML summary comments to fields in Options class',"b'We need to add XML summary comments to fields in `Options` class.\r\n\r\nLearners where its missing:\r\n\r\n- SdcaBinaryTrainer\r\n- SdcaMultiClassTrainer\r\n- SdcaRegressionTrainer\r\n- StochasticGradientDescentClassificationTrainer\r\n- MulticlassLogisticRegression  + related LR learners\r\n- Online learners\r\n\r\nAlso, in XML help for `options` we should say something consistent (right now there is inconsistency in  the help text for `options`) \r\ne.g.  \r\n\r\n`/// <param name=""options"">Advanced **options** to the algorithm.</param>`'"
399423437,2151,b'TreeEnsembleFeaturizerTransform has no Transformer derivative',"b'As title. Please see [TreeEnsembleFeaturizerTransform](https://github.com/dotnet/machinelearning/blob/2e5612c029583185c10044fb1b665c5d308676d7/src/Microsoft.ML.FastTree/TreeEnsembleFeaturizer.cs#L540). As most transforms have become transformers, maybe this one should do as well.'"
399311728,2150,b'FeatureContributionCalculator property is frequently misspelled',"b""FeatureContributionCalculator is misspelled as FeatureContributionClaculator (note the switched 'a' and 'l' in 'Calculator' => 'Claculator').\r\n\r\nThe mistake seems to have been copy-pasted around a bit: https://github.com/dotnet/machinelearning/search?q=FeatureContributionClaculator"""
399229993,2149,b'OnnxTransfrom - onnxruntime.dll - ReleaseOrtAllocatorInfo- System.EntryPointNotFoundException:',"b""### System information\r\n\r\n- **OS version/distro**: Win 10, 64-bit, 10.0.17763\r\n- **.NET Version (eg., dotnet --info)**:  4.6.2\r\n\r\n### Issue\r\n\r\nAdded OnnxTransformSample.cs + nugets to a console app, trying to run the example.\r\n\r\n1. Exception onnxruntime.dll is not found, probably similar to this https://github.com/dotnet/machinelearning/issues/2106\r\n\r\n2. Copied onnxruntime.dll from ..\\packages\\Microsoft.ML.OnnxRuntime.Gpu.0.1.5\\runtimes\\win10-x64\\native to my app directory. The example works find, but when I close the console app, there is an exception \r\n\r\nSystem.EntryPointNotFoundException: 'Unable to find an entry point named 'ReleaseOrtAllocatorInfo' in DLL 'onnxruntime.dll'.'\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
399211321,2148,b'TextLoader.ColInfo will be a redundant data structure',"b'As mentioned in #2140, TextLoader.ColInfo can potentially be removed because its function overlaps with that of the output schema of TextLoader. We should remove TextLoader.ColInfo for cleaning.'"
399173592,2147,b'Check range of ScalePosWeight in LightGBM',"b'Our recommendation seems to be (0,Inf) for `ScalePosWeight`, but we then restrict it to (0,1].\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a570da14a41f2870eb8f61d84496a58422398253/src/Microsoft.ML.LightGBM/LightGbmArguments.cs#L155-L158\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a570da14a41f2870eb8f61d84496a58422398253/src/Microsoft.ML.LightGBM/LightGbmArguments.cs#L170\r\n\r\nThis likely should be:\r\n```C#\r\nContracts.CheckUserArg(Args.ScalePosWeight > 0, nameof(Args.ScalePosWeight), ""must be > 0."");\r\n```'"
399162632,2145,b'Relocate Microsoft.ML.TensorFlow.TestModels nuget or grant access to dotnet-core feed.',"b""Currently, Microsoft.ML.TensorFlow.TestModels nuget is created from https://github.com/dotnet/machinelearning-testdata and push to dotnet-core feed. \r\n\r\nML.Net people don't have push access to dotnet-core feed. Whenever there is a change in the repo and nuget needs to be regenerated, we need to ask the relevant people (who have access) to do this. The solution is either create a new feed where ML.Net people have access to or grant push access on dotnet-core to ML.Net people (whichever is convenient).\r\n\r\nCc: @yaeldekel, @ericstj, @eerhardt."""
399147635,2144,b'Decide a good name for TextLoader',"b'In #1690 we renamed `MLContext.Data.CreateTextReader` to `MLContext.Data.CreateTextLoader` to have the method match the return type `TextLoader`.\r\n\r\nIn #581 and subsequent work, we are replacing `IDataLoader` with `IDataReader`, and so renaming the `TextLoader` to `TextReader` would make sense. However, doing so would lead to disambiguation issues between `Microsoft.ML.Data.TextReader` and `System.IO.TextReader`, which we should avoid as per .NET guidelines. So, we must come up with a new name for `TextLoader` that is descriptive but is different from `TextReader`.\r\n\r\nSome suggestions:\r\n- `DelimitedTextReader`\r\n- `DelimTextReader`\r\n- `TextDataReader`\r\n\r\ncc: @glebuk @eerhardt @TomFinley '"
399112226,2141,"b""Why can't SlotDroppingTransformer be applied to integer columns?""","b'This is the comment on the IsValidColumnType method of the transformer:\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Transforms/DropSlotsTransform.cs#L474\r\n\r\nBoth scalars and vectors are acceptable types, but the item type must have a default value which means it must be a string, a key, a float or a double.\r\n\r\nI think integers fit this description as well.'"
399055967,2137,b'Change TextLoader synchronization to not use exceptions',"b'The `TextLoader` code in its current form uses multithreading in its parsing. While reading the raw data from the file is in a single thread, the work of interpreting that data, putting it into buffers, etc. etc., is done in separate threads as that was the bottleneck in parsing. It uses blocking collections to synchronize this work, as we do in many other places. So far, so good.\r\n\r\nNow, unfortunately, unlike our other usages of blocking collections, this implementation uses exception catching simply as a matter of course, to detect and react to empty buffers, etc. While this always seemed to me to have at least a bad code smell, apparently it is detrimental from a perf perspective as well, being needlessly slow compared to the other exception free mechanisms of using blocking collections, according to @stephentoub, whose diagnosis I quote directly below:\r\n\r\n> I believe the problem is that the demo is throwing ~110,000 exceptions (which are caught internally).  Adding the AppendCacheCheckpoint drops that to 50.  Exception throwing/catching is expensive, and there\xe2\x80\x99s a noticeable difference in throughput even without the debugger attached, but exceptions are even more expensive when a debugger is attached, hence F5 being super slow.\r\n> \r\n> Almost all of the exceptions are InvalidOperationExceptions stemming from invalid use of a BlockingCollection:\r\n> System.InvalidOperationException: The collection argument is empty and has been marked as complete with regards to additions.\r\n> \r\n> Coming from:\r\n> \r\n> ```\r\n> System.Collections.Concurrent.dll!System.Collections.Concurrent.BlockingCollection<Microsoft.ML.Data.TextLoader.Cursor.LineBatch>.Take() Line 545     C#\r\n> Microsoft.ML.Data.dll!Microsoft.ML.Data.TextLoader.Cursor.LineReader.GetBatch() Line 451     C#\r\n> Microsoft.ML.Data.dll!Microsoft.ML.Data.TextLoader.Cursor.GetSomeLines(Microsoft.ML.Data.IMultiStreamSource source, int count, ref System.Collections.Generic.List<System.ReadOnlyMemory<char>> lines = null) Line 221    C#\r\n> Microsoft.ML.Data.dll!Microsoft.ML.Data.TextLoader.Bindings.Bindings(Microsoft.ML.Data.TextLoader parent = {Microsoft.ML.Data.TextLoader}, Microsoft.ML.Data.TextLoader.Column[] cols = {Microsoft.ML.Data.TextLoader.Column[5]}, Microsoft.ML.Data.IMultiStreamSource headerFile = null, Microsoft.ML.Data.IMultiStreamSource dataSample) Line 570      C#\r\n> Microsoft.ML.Data.dll!Microsoft.ML.Data.TextLoader.TextLoader(Microsoft.ML.IHostEnvironment env, Microsoft.ML.Data.TextLoader.Arguments args, Microsoft.ML.Data.IMultiStreamSource dataSample) Line 1135     C#\r\n> Microsoft.ML.Data.dll!Microsoft.ML.TextLoaderSaverCatalog.CreateTextReader(Microsoft.ML.DataOperations catalog, Microsoft.ML.Data.TextLoader.Arguments args, Microsoft.ML.Data.IMultiStreamSource dataSample) Line 37 C#\r\n> MulticlassClassification_Iris.dll!MulticlassClassification_Iris.Program.BuildTrainEvaluateAndSaveModel(Microsoft.ML.MLContext mlContext = {Microsoft.ML.MLContext}) Line 51 C#\r\n> MulticlassClassification_Iris.dll!MulticlassClassification_Iris.Program.Main(string[] args = {string[0]}) Line 38      C#\r\n> ```\r\n> \r\n> Whether or not that\xe2\x80\x99s the only issue, I don\xe2\x80\x99t know, but my guess is if you fix that issue, the perf will get a lot better.\r\n\r\nTangentially related to #2099, insofar as it sprang from the same discussion.'"
398491210,2134,"b'Support for ""Multi target regression models"" (MTR)'","b'This feature request started from a particular customer feedback (see feedback at the end of the comment).\r\n\r\nContext/explanation:\r\n\r\nMost Machine Learning models targeting a regression problem usually support a single target variable to predict, which for the case of a regression is a numeric value.\r\n\r\nHowever, other machine learning frameworks also provide ""Multi target regression models"" (MTR) like explained in the post link below:\r\n\r\nhttps://towardsdatascience.com/regression-models-with-multiple-target-variables-8baa75aacd \r\n\r\nHowever, ML.NET currently doesn\'t have a built-in multi-output regression learner/trainer.\r\n\r\nCurrently, by just using ML.NET, you need to use a different trained model per each target variable/prediction. If you want to predict 5 different target or dependent variables , you\'d need to create 5 different models for that, instead of a single model predicting 5 target variables. \r\n\r\nFEATURE:\r\n\r\nThe implementation of this feature would allow ML.NET to support ""Multi target regression models"" (MTR), built-in in ML.NET without needing external frameworks like TensorFlow.\r\n\r\n--------------------------------------------------------------------------------------------------------\r\nCUSTOMER FEEDBACK:\r\n--------------------------------------------------------------------------------------------------------\r\nta.speot.is\r\nHi, thanks for improving ML.NET. I\xe2\x80\x99ve spent a little bit of time with it and it\xe2\x80\x99s nice to have a first-class .NET API for Machine Learning.\r\n\r\nRight now I\xe2\x80\x99m using ML.NET very much like described in \xe2\x80\x9cTutorial: Predict New York taxi fares using a regression learner with ML.NET\xe2\x80\x9d but I\xe2\x80\x99m wondering how to build on it. Presently I\xe2\x80\x99m predicting one attribute (in the tutorial\xe2\x80\x99s case: the taxi fare) but I have more complicated scenarios I want to predict that involve multiple attributes (using the tutorial\xe2\x80\x99s domain it would be predicting, say, taxi fare AND a surge charging multiple e.g. 1.0x, 1.5x).\r\n\r\nTrying to make \xe2\x80\x9cScore\xe2\x80\x9d an array of floats didn\xe2\x80\x99t work (the glossary on MSDN says regression is \xe2\x80\x9cthe output is a real value, for example, double\xe2\x80\x9d i.e. one value so that it didn\xe2\x80\x99t work was to be expected).\r\n\r\n**Obviously I could train 10 models for the 10 attributes I want to predict but I feel like there\xe2\x80\x99s a better way.** \r\n\r\nIf anybody has any thoughts I\xe2\x80\x99d appreciate any suggestions!\r\n\r\n--------------------------------------------------------------------------------------------------------\r\n'"
398485238,2133,"b'Command-line oriented arguments, that have more suitable alternatives for the API should be made internal'","b'In the arguments classes there are several arguments that get translated to the same parameter for the estimators/transforms. \r\n\r\nOne of the variant is  a convenience for the command line version of ML.Net. \r\n\r\nI think those can be made internal, and kept away from the user for v1. \r\n\r\nExample:\r\n\r\n[ValueToKeyMappingTransformer.ArgumentsBase](https://github.com/dotnet/machinelearning/blob/312f9e4c71953bee701ea2a63be3cb4d2d276d20/src/Microsoft.ML.Data/Transforms/ValueToKeyMappingTransformer.cs#L53)\r\n\r\n```csharp\r\npublic abstract class ArgumentsBase : TransformInputBase\r\n{\r\n     [Argument(ArgumentType.AtMostOnce, HelpText = ""Maximum number of terms to keep per column when auto-training"", ShortName = ""max"", SortOrder = 5)]\r\n      public int MaxNumTerms = ValueToKeyMappingEstimator.Defaults.MaxNumTerms;\r\n\r\n      [Argument(ArgumentType.AtMostOnce, HelpText = ""Comma separated list of terms"", SortOrder = 105, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly)]\r\n      public string Terms;\r\n\r\n      [Argument(ArgumentType.AtMostOnce, HelpText = ""List of terms"", SortOrder = 106, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly)]\r\n      public string[] Term;\r\n```\r\n\r\nI don\'t think our API users should see the first \r\n\r\n`public string Terms`'"
398476524,2129,b'ImagePixelExtractor bug when interleave=true',"b'The outer for loop is over x and the inner loop is over y, causing the results to be inconsistent with the interleave=false case, which loops over y first and x second.'"
398434532,2127,"b'Allow multiple numeric data types in pipeline and estimators, plus allow different datatypes in the Concat estimator'","b""Related to this issue at the ML.NET Samples repo with feedback from a customer: https://github.com/dotnet/machinelearning-samples/issues/198\r\n\r\nMost of our algorithms expect floating point values as input. You need to either read your input as floats (DataKind.R4 or DataKind.R8) or convert ints to floats later in the pipeline.\r\n\r\nThis is a typical problem that customers might have when starting with new datasets where data could initially be Integer, etc. and since DataKind enum has more than just float and double it can be misleading and create trouble when getting started.\r\n\r\nIt's definitely unclear to beginners why integer only wouldn't work, etc. \r\n\r\nPROPOSALS:\r\n\r\n- 1. Expand API so it'd accept additional numeric data types like Integer. Do conversions/cast internally?\r\n\r\n- 2. Expand Concat estimator API to accept multiple/different numeric column types for the multiple columns being being concatenated. So I could concatenate an integer column with a double column and so forth. Again, it might need conversions, but it probably could be done internally?\r\n\r\n\r\n\r\n\r\n"""
398417494,2126,b'Please add vector distance transform',"b""### Issue\r\n- **What did you do?**\r\nWhen I used SSWE WordEmbedding, I'd like to have VectorDistanceTranform to compute similarity score between two sentiment vectors. In my use case,  I don't need to maintain two sentiment vectors beyond the similarity score.\r\n\r\n- **What did you expect?**\r\nI would like to have VectorDistanceTransform to compute similarity score.\r\n"""
398225244,2122,b'New StaticPipe nuget should be mentioned in release notes',b'Title says it all. I just spend way too much time on this issue.'
398118616,2121,b'ImageLoadingEstimator for TensorFlow scoring should allow in-memory image streams as input in addition to images from files on drive ',"b'Right now the only way for ML.NET to load images is via ImageLoadingEstimator, which can load them *only* from disk files (as confirmed by @yaeldekel and Pete a few weeks ago).\r\n\r\nHowever, it is a very common scenario in applications, such as a web app, where users submit images through Http, then the DataView/pipeline would load in-memory image streams (either BitMap, byte[], Image) instead of loading images from files in a folder on a disk/drive. \r\n\r\nThat\'s the right way to do it for many scenarios in web apps and services (Web APIs).\r\nAnd for instance, you can do that when using TensorFlowSharp in C#. But we cannot in ML.NET, as of today.\r\n\r\nWhen implementing this feature improvement in ML.NET, there could be the following two approaches:\r\n\r\n- Modify schema comprehension to be able to map Bitmap fields/properties to Image columns of a data view.\r\n\r\n- Add another version of ImageLoading transformer that loads/decodes the image from a byte vector, rather than from a disk file identified by path.\r\n\r\nIn any case, this is an important scenario to implement because not being able to load images from in-memory streams and only from files can be a big handicap in performance for on-line scenarios like the ones mentioned.\r\n\r\nWith the current implementation in ML.NET, the only workaround is to save the upcoming image from http and in-memory into a temporary file on the disk and load it from there. But that is a very ""coarse/poor"" workaround, not performant at all for a real application in production. \r\n\r\nThe following is a sample app I created for this online scenario where the user uploads an image from the browser into a service (Web API) and ultimately you get it as an in-memory image stream.\r\n\r\nSEE CODE HERE:\r\n\r\nhttps://github.com/CESARDELATORRE/TensorFlowImageClassificationWebAPI\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/51009187-00dc4980-1504-11e9-866d-2c69bbd0db74.png)\r\n\r\n- That web form uploads the image through Http into a service (Web API) in the server-side. At that point, the image is an in-memory image stream.\r\n\r\n- In this implementation the sample app works because I implemented a workaround so the submitted image is temporarily stored as a file, then loaded from the file into the DataView through the pipeline...)\r\n\r\nBasically, when the C# method in the Web API gets the image as an in-memory stream it should be able to load it directly in the DataView. The following code is an example:\r\n\r\n```cs\r\n        // Controller\'s method from Web API \r\n        [HttpPost]\r\n        [ProducesResponseType(200)]\r\n        [ProducesResponseType(400)]\r\n        [Route(""classifyimage"")]\r\n        public async Task<IActionResult> ClassifyImage(IFormFile imageFile)\r\n        {\r\n                if (imageFile.Length == 0)\r\n                    return BadRequest();\r\n\r\n                // WORKAROUND: Save image into a temporal file\r\n                //Save the temp image image into the temp-folder \r\n                string fileName = await _imageWriter.UploadImageAsync(imageFile, _imagesTmpFolder);\r\n                string imageFilePath = Path.Combine(_imagesTmpFolder, fileName);\r\n\r\n                // Use image filename as the workaround...\r\n                // Rest of the implementation with ML.NET API for scoring TensorFlow model...\r\n                // ...\r\n           \r\n        }\r\n```\r\n\r\nTo sum up:\r\n\r\nI believe it is ""a must"" for ML.NET to be able to load in-memory image streams into the DataView to use those images when scoring TensorFlow models (in addition ""from files"") because of the mentioned on-line and in-memory scenarios that are pretty common.\r\n\r\n'"
398096620,2120,b'Several functions in FCC scorer not used/tested',"b'As title. The functions below have zero reference counts.\r\n```csharp\r\n        private static IDataScorerTransform Create(IHostEnvironment env, Arguments args, IDataView data, ISchemaBoundMapper mapper, RoleMappedSchema trainSchema)\r\n        {\r\n            Contracts.CheckValue(env, nameof(env));\r\n            env.CheckValue(data, nameof(data));\r\n            env.CheckValue(mapper, nameof(mapper));\r\n            if (args.Top< 0)\r\n                throw env.Except($""Number of top contribution must be non negative"");\r\n            if (args.Bottom < 0)\r\n                throw env.Except($""Number of bottom contribution must be non negative"");\r\n\r\n            var contributionMapper = mapper as RowMapper;\r\n            env.CheckParam(mapper != null, nameof(mapper), ""Unexpected mapper"");\r\n\r\n            var scorer = ScoreUtils.GetScorerComponent(env, contributionMapper);\r\n            var scoredPipe = scorer.CreateComponent(env, data, contributionMapper, trainSchema);\r\n            return scoredPipe;\r\n        }\r\n\r\n        // Factory method for SignatureBindableMapper.\r\n        private static ISchemaBindableMapper Create(IHostEnvironment env, Arguments args, IPredictor predictor)\r\n        {\r\n            Contracts.CheckValue(env, nameof(env));\r\n            env.CheckValue(predictor, nameof(predictor));\r\n            var pred = predictor as IFeatureContributionMapper;\r\n            env.CheckParam(pred != null, nameof(predictor), ""Predictor doesn\'t support getting feature contributions"");\r\n            return new BindableMapper(env, pred, args.Top, args.Bottom, args.Normalize, args.Stringify);\r\n        }\r\n\r\n        // Factory method for SignatureLoadModel.\r\n        private static ISchemaBindableMapper Create(IHostEnvironment env, ModelLoadContext ctx)\r\n            => new BindableMapper(env, ctx);\r\n```\r\nI further commented out the whole `FeatureContributionCalculation.cs`, rebuilt my solution, and ran all tests starting with `FeatureCont`. Surprisingly, all tests passed.'"
398041725,2114,b'ValueMappingTransform does not handle type string for keys and values',"b'ValueMappingTransform does handle ReadOnlyMemory<char> for values and keys, it does not handle strings. \r\n\r\nThis should be updated as users will naturally want to use strings for the data type. With this support, the following should work:\r\n```\r\n            var educationKeys = new List<string>()\r\n            {\r\n                ""0-5yrs"",\r\n                ""6-11yrs"",\r\n                ""12+yrs""\r\n            };\r\n\r\n            var educationValues = new List<string>()\r\n            {\r\n                ""Cat1"",\r\n                ""Cat2"", \r\n                ""Cat3""\r\n            };\r\n\r\n            var pipeline = new ValueMappingEstimator<string, string>(ml, educationKeys, educationValues, (""Education"", ""EducationCategory""));\r\n```'"
397636627,2106,b'Onnxruntime not working properly for netfx',"b""I am trying to run the test SimpleEndToEndOnnxConversionTest on netfx\r\n\r\nI get this is as an error\r\n```C#\r\n[xUnit.net 00:00:08.31]     Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest [FAIL]\r\nFailed   Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest\r\nError Message:\r\n System.DllNotFoundException : Unable to load DLL 'onnxruntime.dll': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\nStack Trace:\r\n   at Microsoft.ML.OnnxRuntime.NativeMethods.OrtCreateSessionOptions()\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions..ctor()\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions.MakeSessionOptionWithMklDnnProvider()\r\n   at System.Lazy`1.CreateValue()\r\n   at System.Lazy`1.LazyInitValue()\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession..ctor(String modelPath)\r\n   at Microsoft.ML.Transforms.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxUtils.cs:line 101\r\n   at Microsoft.ML.Transforms.OnnxTransform..ctor(IHostEnvironment env, Arguments args, Byte[] modelBytes) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 190\r\n   at Microsoft.ML.Transforms.OnnxTransform..ctor(IHostEnvironment env, String modelFile, String[] inputColumns, String[] outputColumns, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 273\r\n   at Microsoft.ML.Transforms.OnnxScoringEstimator..ctor(IHostEnvironment env, String modelFile, String[] inputColumns, String[] outputColumns, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 560\r\n   at Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest() in C:\\git\\machinelearning\\test\\Microsoft.ML.Tests\\OnnxConversionTest.cs:line 74\r\n```\r\n\r\nAlthough I looked at the output folder, I saw there was a dll named as Microsost.ML.OnnxRuntime.dll(not sure if it is similar to onnxruntime.dll)\r\nI renamed it to onnxruntime.dll, and then I was getting\r\n\r\n```C#\r\n[xUnit.net 00:00:07.41]     Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest [FAIL]\r\nFailed   Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest\r\nError Message:\r\n System.EntryPointNotFoundException : Unable to find an entry point named 'OrtCreateSessionOptions' in DLL 'onnxruntime.dll'.\r\nStack Trace:\r\n   at Microsoft.ML.OnnxRuntime.NativeMethods.OrtCreateSessionOptions()\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions..ctor()\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions.MakeSessionOptionWithMklDnnProvider()\r\n   at System.Lazy`1.CreateValue()\r\n   at System.Lazy`1.LazyInitValue()\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession..ctor(String modelPath)\r\n   at Microsoft.ML.Transforms.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxUtils.cs:line 101\r\n   at Microsoft.ML.Transforms.OnnxTransform..ctor(IHostEnvironment env, Arguments args, Byte[] modelBytes) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 190\r\n   at Microsoft.ML.Transforms.OnnxTransform..ctor(IHostEnvironment env, String modelFile, String[] inputColumns, String[] outputColumns, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 273\r\n   at Microsoft.ML.Transforms.OnnxScoringEstimator..ctor(IHostEnvironment env, String modelFile, String[] inputColumns, String[] outputColumns, Nullable`1 gpuDeviceId, Boolean fallbackToCpu) in C:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform\\OnnxTransform.cs:line 560\r\n   at Microsoft.ML.Tests.OnnxConversionTest.SimpleEndToEndOnnxConversionTest() in C:\\git\\machinelearning\\test\\Microsoft.ML.Tests\\OnnxConversionTest.cs:line 74\r\n```\r\n\r\n@eerhardt @danmosemsft @shauheen @TomFinley @jignparm """
397632760,2104,b'Not able to load Whitening Module in Maml on full framework',"b'```\r\n[xUnit.net 00:00:03.65]     Microsoft.ML.Tests.Transformers.NormalizerTests.TestWhiteningCommandLine [FAIL]\r\nFailed   Microsoft.ML.Tests.Transformers.NormalizerTests.TestWhiteningCommandLine\r\nError Message:\r\n System.InvalidOperationException : Unknown loadable class: whitening\r\nStack Trace:\r\n   at Microsoft.ML.Tools.Maml.MainCore(IHostEnvironment env, String args, Boolean alwaysPrintStacktrace) in C:\\git\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 210\r\n   at Microsoft.ML.Tools.Maml.MainWithProgress(String args) in C:\\git\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 68\r\n   at Microsoft.ML.Tools.Maml.MainAll(String args) in C:\\git\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 45\r\n   at Microsoft.ML.Tools.Maml.Main(String[] args) in C:\\git\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 34\r\n   at Microsoft.ML.Tests.Transformers.NormalizerTests.TestWhiteningCommandLine() in C:\\git\\machinelearning\\test\\Microsoft.ML.Tests\\Transformers\\NormalizerTests.cs:line 332\r\n```\r\n\r\nI am trying to run TestWhiteningCommandLine test on netfx. The test using Maml.Main and it is not able to load the whitening module.\r\n\r\nAdding ``` Type t = typeof(VectorWhiteningTransformer);``` helps solve the issue but I think we may require more permanent solution\r\n\r\ncc @danmosemsft @eerhardt @TomFinley '"
397631592,2103,b'Build system for Mac machines is broken on homebrew installation',"b""```019-01-10T00:14:33.9225520Z Updating Homebrew...```\r\n```019-01-10T00:15:19.2254360Z /usr/local/Homebrew/Library/Homebrew/config.rb:39:in 'initialize': no implicit conversion of nil into String (TypeError)\r\n2019-01-10T00:15:19.2255080Z \tfrom /usr/local/Homebrew/Library/Homebrew/config.rb:39:in 'new'\r\n2019-01-10T00:15:19.2255680Z \tfrom /usr/local/Homebrew/Library/Homebrew/config.rb:39:in '<top (required)>'\r\n2019-01-10T00:15:19.2256260Z \tfrom /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:55:in 'require'\r\n2019-01-10T00:15:19.2256920Z \tfrom /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:55:in 'require'\r\n2019-01-10T00:15:19.2257470Z \tfrom /usr/local/Homebrew/Library/Homebrew/global.rb:25:in '<top (required)>'\r\n2019-01-10T00:15:19.2258050Z \tfrom /usr/local/Homebrew/Library/Homebrew/brew.rb:13:in 'require_relative'\r\n2019-01-10T00:15:19.2258570Z \tfrom /usr/local/Homebrew/Library/Homebrew/brew.rb:13:in '<main>'```"""
397624333,2102,b'GetModelNodes not compatible with multi-file saved models',"b""### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: ML.Net 0.8.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to call GetModelNodes on a Tensor Flow model that was successfully able to be loaded using ScoreTensorFlowModel. \r\n- **What happened?**\r\nReceived Exception:  Access Denied Error\r\n- **What did you expect?**\r\nSuccessfully load model and enumerate model nodes.\r\n### Source code / logs\r\n\r\nI believe it's because it's trying to load my folder path as a file:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bdc9a9e1348abfdd2287d43e2633089e9eba36c7/src/Microsoft.ML.TensorFlow/TensorFlow/TensorflowUtils.cs#L83\r\n"""
397620380,2100,b'Refactoring of Constructors',"b'Currently in our codebase, we have two `constructors`  that are used for initialization of the underlying object.\r\n\r\n**Example:**\r\n\r\nA. \r\nhttps://github.com/dotnet/machinelearning/blob/bdc9a9e1348abfdd2287d43e2633089e9eba36c7/src/Microsoft.ML.FastTree/FastTreeRanking.cs#L75-L84\r\n\r\nB.\r\nhttps://github.com/dotnet/machinelearning/blob/bdc9a9e1348abfdd2287d43e2633089e9eba36c7/src/Microsoft.ML.FastTree/FastTreeRanking.cs#L93-L95\r\n\r\n\r\nWe need to bringing the public API surface to the desired shape.  As such, we are making both constructors `internal`, and fixing other issues with the public API as outlined in #1798. \r\n\r\n\r\nAdditionally, constructor (B)  has all the details  for constructing the underlying object. As such, we can delete constructor (A)  altogether.\r\n\r\n\r\nNOTE:  We will do this issue only after finishing  the work to bring public API to the desired shape .\r\n\r\nConstructors that need closer look towards unification:\r\n\r\nSdcaBinaryTrainer\r\nSdcaMultiClassTrainer\r\nSdcaRegressionTrainer\r\nStochasticGradientDescentClassificationTrainer\r\nFastTreeRankingTrainer\r\nFastTreeRegressionTrainer\r\nFastTreeBinaryClassificationTrainer\r\nFastForestClassification\r\nFastForestRegression\r\nPoissonRegression\r\nLogisticRegression\r\nBinaryClassificationGamTrainer\r\nLightGbmBinaryTrainer\r\nLightGbmMulticlassTrainer\r\nLightGbmRankingTrainer\r\nLightGbmRegressorTrainer\r\n\r\n\r\n@TomFinley @glebuk @shauheen @sfilipi @artidoro @rogancarr '"
397597796,2099,"b'[BUG] Possible Bug when training causes a ""never-ending-training"" when VS-F5 Debugging/attached but works OK without debugger attached'","b'This was working properly in ML.NET v0.8, so looks like a bug appearing in v0.9?\r\n\r\n**CONTEXT:**\r\nI just migrated the **Iris-MultiClassClassification** sample to ML.NET **v0.9**.\r\n\r\nCode is here, ONLY in **branch 09migration**:\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/tree/09migration/samples/csharp/getting-started/MulticlassClassification_Iris \r\n\r\n**PROBLEM:**\r\nIf I run it without attaching to debugger such as with Ctrl+F5, it works/trains properly:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/50934719-60f8c000-141e-11e9-83ca-02928601d8b8.png)\r\n\r\nHowever, if I run the console app with F5 (Debugging with VS attached to the process), then the app is ""training"" the model ""forever"", meaining that instead of 20 seconds I\'ve been waiting for more than 30 minutes and it ""never ends""..\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/50934520-b7193380-141d-11e9-9cfb-7066652189c3.png)\r\n\r\nI talked to @danmosemsft and we think it can be related to any issue with too many threads being created?\r\n\r\nIn the debug window we see a bunch of threads being created, not sure if that\'s the cause? Too many threads being created and that\'s causing the issue to Visual Studio?\r\n\r\nThe thread 0x3ab4 has exited with code 0 (0x0).\r\nThe thread 0x5038 has exited with code 0 (0x0).\r\nThe thread 0x2994 has exited with code 0 (0x0).\r\nThe thread 0x4b18 has exited with code 0 (0x0).\r\nThe thread 0xf3c has exited with code 0 (0x0).\r\nThe thread 0x4e8 has exited with code 0 (0x0).\r\nThe thread 0x3cd0 has exited with code 0 (0x0).\r\nThe thread 0x28d4 has exited with code 0 (0x0).\r\nThe thread 0x56cc has exited with code 0 (0x0).\r\nThe thread 0x38d0 has exited with code 0 (0x0).\r\nThe thread 0x658 has exited with code 0 (0x0).\r\nThe thread 0x17d4 has exited with code 0 (0x0).\r\nThe thread 0x3ef0 has exited with code 0 (0x0).\r\nThe thread 0x6284 has exited with code 0 (0x0).\r\nThe thread 0x1664 has exited with code 0 (0x0).\r\nThe thread 0x2c5c has exited with code 0 (0x0).\r\nThe thread 0x536c has exited with code 0 (0x0).\r\nThe thread 0x1e04 has exited with code 0 (0x0).\r\nThe thread 0x5014 has exited with code 0 (0x0).\r\nThe thread 0x4f4c has exited with code 0 (0x0).\r\nThe thread 0x3444 has exited with code 0 (0x0).\r\nThe thread 0x670 has exited with code 0 (0x0).\r\nThe thread 0x42f0 has exited with code 0 (0x0).\r\nThe thread 0x2750 has exited with code 0 (0x0).\r\nThe thread 0x55e8 has exited with code 0 (0x0).\r\nThe thread 0x30a0 has exited with code 0 (0x0).\r\nThe thread 0x4810 has exited with code 0 (0x0).\r\nThe thread 0x4e7c has exited with code 0 (0x0).\r\nThe thread 0x6450 has exited with code 0 (0x0).\r\nThe thread 0x2a0 has exited with code 0 (0x0).\r\nThe thread 0x38d8 has exited with code 0 (0x0).\r\nThe thread 0x4708 has exited with code 0 (0x0).\r\nThe thread 0x6dc has exited with code 0 (0x0).\r\nThe thread 0x1880 has exited with code 0 (0x0).\r\nThe thread 0x4ffc has exited with code 0 (0x0).\r\nThe thread 0xd04 has exited with code 0 (0x0).\r\nThe thread 0x3ff8 has exited with code 0 (0x0).\r\nThe thread 0x6328 has exited with code 0 (0x0).\r\nThe thread 0x5030 has exited with code 0 (0x0).\r\nThe thread 0x6438 has exited with code 0 (0x0).\r\nThe thread 0x44a8 has exited with code 0 (0x0).\r\nThe thread 0x1eb8 has exited with code 0 (0x0).\r\nThe thread 0x6034 has exited with code 0 (0x0).\r\nThe thread 0x3f64 has exited with code 0 (0x0).\r\nThe thread 0x5788 has exited with code 0 (0x0).\r\nThe thread 0x1420 has exited with code 0 (0x0).\r\nThe thread 0x3ed4 has exited with code 0 (0x0).\r\nThe thread 0x66e4 has exited with code 0 (0x0).\r\nThe thread 0x30b4 has exited with code 0 (0x0).\r\nThe thread 0x2794 has exited with code 0 (0x0).\r\nThe thread 0x42d0 has exited with code 0 (0x0).\r\nThe thread 0x6504 has exited with code 0 (0x0).\r\nThe thread 0x2a90 has exited with code 0 (0x0).\r\nThe thread 0x4bfc has exited with code 0 (0x0).\r\nThe thread 0x1470 has exited with code 0 (0x0).\r\nThe thread 0x5e2c has exited with code 0 (0x0).\r\nThe thread 0x6580 has exited with code 0 (0x0).\r\nThe thread 0x6200 has exited with code 0 (0x0).\r\nThe thread 0x42d4 has exited with code 0 (0x0).\r\nThe thread 0x211c has exited with code 0 (0x0).\r\nThe thread 0x2724 has exited with code 0 (0x0).\r\nThe thread 0x20 has exited with code 0 (0x0).\r\nThe thread 0x30c has exited with code 0 (0x0).\r\nThe thread 0x28a8 has exited with code 0 (0x0).\r\nThe thread 0xba8 has exited with code 0 (0x0).\r\nThe thread 0x2810 has exited with code 0 (0x0).\r\nThe thread 0x64f0 has exited with code 0 (0x0).\r\nThe thread 0x5dd0 has exited with code 0 (0x0).\r\nThe thread 0x2fa8 has exited with code 0 (0x0).\r\nThe thread 0x57c8 has exited with code 0 (0x0).\r\nThe thread 0x72c has exited with code 0 (0x0).\r\nThe thread 0x5124 has exited with code 0 (0x0).\r\nThe thread 0x6310 has exited with code 0 (0x0).\r\nThe thread 0x3344 has exited with code 0 (0x0).\r\nThe thread 0x5fd4 has exited with code 0 (0x0).\r\nThe thread 0x35c has exited with code 0 (0x0).\r\nThe thread 0x435c has exited with code 0 (0x0).\r\nThe thread 0x6318 has exited with code 0 (0x0).\r\nThe thread 0x2838 has exited with code 0 (0x0).\r\nThe thread 0x2124 has exited with code 0 (0x0).\r\nThe thread 0x4a8 has exited with code 0 (0x0).\r\nThe thread 0x48a0 has exited with code 0 (0x0).\r\nThe thread 0x1f24 has exited with code 0 (0x0).\r\nThe thread 0x2334 has exited with code 0 (0x0).\r\nThe thread 0x4dd8 has exited with code 0 (0x0).\r\nThe thread 0x6330 has exited with code 0 (0x0).\r\nThe thread 0x49d8 has exited with code 0 (0x0).\r\nThe thread 0x4e10 has exited with code 0 (0x0).\r\nThe thread 0x22a8 has exited with code 0 (0x0).\r\nThe thread 0x673c has exited with code 0 (0x0).\r\nThe thread 0x3498 has exited with code 0 (0x0).\r\nThe thread 0x4fac has exited with code 0 (0x0).\r\nThe thread 0x5594 has exited with code 0 (0x0).\r\nThe thread 0x63a0 has exited with code 0 (0x0).\r\nThe thread 0x4584 has exited with code 0 (0x0).\r\nThe thread 0x2480 has exited with code 0 (0x0).\r\nThe thread 0x4afc has exited with code 0 (0x0).\r\nThe thread 0x5fe8 has exited with code 0 (0x0).\r\nThe thread 0x1908 has exited with code 0 (0x0).\r\nThe thread 0x70c has exited with code 0 (0x0).\r\nThe thread 0x46e0 has exited with code 0 (0x0).\r\nThe thread 0x33bc has exited with code 0 (0x0).\r\nThe thread 0x1d2c has exited with code 0 (0x0).\r\nThe thread 0x1ea8 has exited with code 0 (0x0).\r\nThe thread 0x1d84 has exited with code 0 (0x0).\r\nThe thread 0x4540 has exited with code 0 (0x0).\r\nThe thread 0x6634 has exited with code 0 (0x0).\r\nThe thread 0x4b24 has exited with code 0 (0x0).\r\nThe thread 0x315c has exited with code 0 (0x0).\r\nThe thread 0x2844 has exited with code 0 (0x0).\r\nThe thread 0x4c20 has exited with code 0 (0x0).\r\nThe thread 0x65f4 has exited with code 0 (0x0).\r\nThe thread 0x252c has exited with code 0 (0x0).\r\nThe thread 0x6484 has exited with code 0 (0x0).\r\nThe thread 0x4da8 has exited with code 0 (0x0).\r\nThe thread 0x4f9c has exited with code 0 (0x0).\r\nThe thread 0x56a0 has exited with code 0 (0x0).\r\nThe thread 0x5d3c has exited with code 0 (0x0).\r\nThe thread 0x519c has exited with code 0 (0x0).\r\nThe thread 0x1ae8 has exited with code 0 (0x0).\r\nThe thread 0x6234 has exited with code 0 (0x0).\r\nThe thread 0x90c has exited with code 0 (0x0).\r\nThe thread 0x4428 has exited with code 0 (0x0).\r\nThe thread 0x4310 has exited with code 0 (0x0).\r\nThe thread 0x3230 has exited with code 0 (0x0).\r\nThe thread 0x60d8 has exited with code 0 (0x0).\r\nThe thread 0x3288 has exited with code 0 (0x0).\r\nThe thread 0x1d28 has exited with code 0 (0x0).\r\nThe thread 0x5f80 has exited with code 0 (0x0).\r\nThe thread 0x216c has exited with code 0 (0x0).\r\nThe thread 0x3774 has exited with code 0 (0x0).\r\nThe thread 0x5b94 has exited with code 0 (0x0).\r\nThe thread 0x4c04 has exited with code 0 (0x0).\r\nThe thread 0x2c80 has exited with code 0 (0x0).\r\nThe thread 0x38c4 has exited with code 0 (0x0).\r\nThe thread 0x13dc has exited with code 0 (0x0).\r\nThe thread 0x6100 has exited with code 0 (0x0).\r\nThe thread 0xc60 has exited with code 0 (0x0).\r\nThe thread 0x5d40 has exited with code 0 (0x0).\r\nThe thread 0x5448 has exited with code 0 (0x0).\r\nThe thread 0x50bc has exited with code 0 (0x0).\r\nThe thread 0x16f8 has exited with code 0 (0x0).\r\nThe thread 0x381c has exited with code 0 (0x0).\r\nThe thread 0x2c84 has exited with code 0 (0x0).\r\nThe thread 0x5068 has exited with code 0 (0x0).\r\nThe thread 0x33f8 has exited with code 0 (0x0).\r\nThe thread 0xc98 has exited with code 0 (0x0).\r\nThe thread 0x598 has exited with code 0 (0x0).\r\nThe thread 0x5ee4 has exited with code 0 (0x0).\r\nThe thread 0x2438 has exited with code 0 (0x0).\r\nThe thread 0x4e30 has exited with code 0 (0x0).\r\nThe thread 0x1d24 has exited with code 0 (0x0).\r\nThe thread 0x443c has exited with code 0 (0x0).\r\nThe thread 0x3e98 has exited with code 0 (0x0).\r\nThe thread 0x5c60 has exited with code 0 (0x0).\r\nThe thread 0x23f0 has exited with code 0 (0x0).\r\nThe thread 0x2eec has exited with code 0 (0x0).\r\nThe thread 0x3a74 has exited with code 0 (0x0).\r\nThe thread 0x560 has exited with code 0 (0x0).\r\nThe thread 0x2088 has exited with code 0 (0x0).\r\nThe thread 0x2b04 has exited with code 0 (0x0).\r\nThe thread 0x129c has exited with code 0 (0x0).\r\nThe thread 0x3f18 has exited with code 0 (0x0).\r\nThe thread 0x627c has exited with code 0 (0x0).\r\nThe thread 0x33e0 has exited with code 0 (0x0).\r\nThe thread 0x4010 has exited with code 0 (0x0).\r\nThe thread 0x1f48 has exited with code 0 (0x0).\r\nThe thread 0x2374 has exited with code 0 (0x0).\r\nThe thread 0x4598 has exited with code 0 (0x0).\r\nThe thread 0x5c64 has exited with code 0 (0x0).\r\nThe thread 0x4a40 has exited with code 0 (0x0).\r\nThe thread 0x8d4 has exited with code 0 (0x0).\r\nThe thread 0x3ee8 has exited with code 0 (0x0).\r\nThe thread 0x161c has exited with code 0 (0x0).\r\nThe thread 0x1818 has exited with code 0 (0x0).\r\nThe thread 0x2b9c has exited with code 0 (0x0).\r\nThe thread 0x376c has exited with code 0 (0x0).\r\nThe thread 0x4ee8 has exited with code 0 (0x0).\r\nThe thread 0x1894 has exited with code 0 (0x0).\r\nThe thread 0x5e80 has exited with code 0 (0x0).\r\nThe thread 0x6420 has exited with code 0 (0x0).\r\nThe thread 0x55d8 has exited with code 0 (0x0).\r\nThe thread 0x47f0 has exited with code 0 (0x0).\r\nThe thread 0x1e8c has exited with code 0 (0x0).\r\nThe thread 0x5c28 has exited with code 0 (0x0).\r\nThe thread 0x212c has exited with code 0 (0x0).\r\nThe thread 0x3998 has exited with code 0 (0x0).\r\nThe thread 0x4914 has exited with code 0 (0x0).\r\nThe thread 0x2ce0 has exited with code 0 (0x0).\r\nThe thread 0x2544 has exited with code 0 (0x0).\r\nThe thread 0x4570 has exited with code 0 (0x0).\r\nThe thread 0x6040 has exited with code 0 (0x0).\r\nThe thread 0x8a8 has exited with code 0 (0x0).\r\nThe thread 0x2a7c has exited with code 0 (0x0).\r\nThe thread 0x54a8 has exited with code 0 (0x0).\r\nThe thread 0x2e3c has exited with code 0 (0x0).\r\nThe thread 0x38d4 has exited with code 0 (0x0).\r\nThe thread 0x6538 has exited with code 0 (0x0).\r\nThe thread 0x65b8 has exited with code 0 (0x0).\r\nThe thread 0x2b88 has exited with code 0 (0x0).\r\nThe thread 0x21b0 has exited with code 0 (0x0).\r\nThe thread 0x5bf4 has exited with code 0 (0x0).\r\nThe thread 0x5d2c has exited with code 0 (0x0).\r\nThe thread 0x5650 has exited with code 0 (0x0).\r\nThe thread 0x4398 has exited with code 0 (0x0).\r\nThe thread 0x243c has exited with code 0 (0x0).\r\nThe thread 0x4f60 has exited with code 0 (0x0).\r\nThe thread 0x1874 has exited with code 0 (0x0).\r\nThe thread 0x26d0 has exited with code 0 (0x0).\r\nThe thread 0x1a34 has exited with code 0 (0x0).\r\nThe thread 0x3d84 has exited with code 0 (0x0).\r\nThe thread 0x5140 has exited with code 0 (0x0).\r\nThe thread 0x3170 has exited with code 0 (0x0).\r\nThe thread 0x4608 has exited with code 0 (0x0).\r\nThe thread 0x356c has exited with code 0 (0x0).\r\nThe thread 0x2758 has exited with code 0 (0x0).\r\nThe thread 0x4c4 has exited with code 0 (0x0).\r\nThe thread 0x5a04 has exited with code 0 (0x0).\r\nThe thread 0xe6c has exited with code 0 (0x0).\r\nThe thread 0x4348 has exited with code 0 (0x0).\r\n\r\nThis issue or possible bug needs to be researched as soon as possible, please. \xf0\x9f\x91\x8d  \r\n'"
397590165,2097,b'Add Non-negative support for Averaged Perceptron',"b'This is a request to add non-negative weight support to AveragedPerceptron, similar to Logistic Regression through the EnforceNonNegativity (""nn=+"") argument. \r\n\r\nThe reason of asking for this is because Averaged Perceptron can at times perform better in terms of timing and accuracy -- therefore it would useful to have parity with this feature. \r\n\r\n@justinormont '"
397560479,2096,b'Normalization considerations',b'One could consider explaining that output columns may need to be mapped or normalised and how\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 12000716-85e6-bd1c-ec99-ff19f740a577\n* Version Independent ID: a73fcfff-3fb7-1041-0826-678538a2ec66\n* Content: [TransformExtensionsCatalog.CopyColumns Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transformextensionscatalog.copycolumns?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/TransformExtensionsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TransformExtensionsCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**'
397554718,2095,b'nuget metadata needs to be updated',"b'`<licenseUrl>` element will be deprecated, please consider switching to specifying the license in the package. [Learn more](https://aka.ms/deprecateLicenseUrl).'"
397533719,2094,b'The projects containing the static extensions are generally not part of any NuGet. ',"b'I believe the projects with the name pattern Microsoft.ML.*.StaticPipe were created setting apart the static extensions so they can be on a separate nuget package. \r\n\r\nMost of them are currently part of no package. There exists a main package for the main project containing the static pipe: Microsoft.ML.StaticPipe. \r\n\r\n@TomFinley, @glebuk @shauheen Should those projects be part of that package, or separate package?\r\n\r\ncc @abgoswam, @eerhardt \r\n\r\nNote: this issue can be closed when all the projects containing static extensions are part of NuGet packages, depending on the resolution of the question above. '"
397481842,2092,b'GroupTransform and UngroupTransform are not transformers',"b""I don't see any `GroupTransform` and `UngroupTransform` implemented as `Transformer`. I am not sure if they have any intension to join `Transformer` family.\r\n\r\nNote that we have `GroupTransform`/`UngroupTransform` --> `TransformBase` --> `IDataTransform`."""
397473330,2090,b'Microsoft.ML.Transforms.csproj should not have a dependency on mkl',b'Apparently [Microsoft.Ml.Transforms](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/Microsoft.ML.Transforms.csproj#L51) contains a dependency in the mlnetmkldeps package. \r\n\r\nNo project that gets packaged under the main Microsoft.ML NuGet should depend on MKL. Components that need MKL should get moved to the HalLearners project. '
397276144,2089,b'How can I use the topic mode trained by LightLDA to infer a new doc?',"b'Hi,\r\nas far as I see there is currently no implementation for inferencing new/unseen documents. Is that correct? Do you have any pointers on how to accomplish that and contribute?\r\n\r\n'"
397207791,2087,b'KmeansOnnxConversionTest failing on NetCoreApp3.0',"b'KmeansOnnxConversionTest is failing on NetCoreApp3.0\r\nThis happened after we changed the version of netcoreapp sdk to 3.0 preview1\r\nAssociated PR https://github.com/dotnet/machinelearning/pull/2082\r\n\r\nThis is not caused due to any change in cpumath library as it is even reproducable by using the software implementation of the functions.\r\n\r\n```\r\n2019-01-09T01:44:33.0500908Z [xUnit.net 00:01:21.86]     Microsoft.ML.Tests.OnnxConversionTest.KmeansOnnxConversionTest [FAIL]\r\n2019-01-09T01:44:33.3587704Z Failed   Microsoft.ML.Tests.OnnxConversionTest.KmeansOnnxConversionTest\r\n2019-01-09T01:44:33.3591191Z Error Message:\r\n2019-01-09T01:44:33.3644424Z  Assert.Equal() Failure\r\n2019-01-09T01:44:33.3644561Z Expected: 0 (rounded from 0)\r\n2019-01-09T01:44:33.3648151Z Actual:   NaN (rounded from NaN)\r\n2019-01-09T01:44:33.3648305Z Stack Trace:\r\n2019-01-09T01:44:33.3648786Z    at Microsoft.ML.Tests.OnnxConversionTest.CompareSelectedR4VectorColumns(String leftColumnName, String rightColumnName, IDataView left, IDataView right, Int32 precision) in D:\\a\\1\\s\\test\\Microsoft.ML.Tests\\OnnxConversionTest.cs:line 500\r\n2019-01-09T01:44:33.3648953Z    at Microsoft.ML.Tests.OnnxConversionTest.KmeansOnnxConversionTest() in D:\\a\\1\\s\\test\\Microsoft.ML.Tests\\OnnxConversionTest.cs:line 159\r\n2019-01-09T01:44:33.3649371Z Standard Output Messages:\r\n2019-01-09T01:44:33.3649668Z  Test KmeansOnnxConversionTest: aborted: passed\r\n```\r\n\r\ncc @eerhardt @danmosemsft @tannergooding '"
397178799,2086,b'ValueMappingEstimator KeyType metadata maps to Key data and not to the Value data',"b'### Issue\r\nDiscovered while fixing #2083.\r\n\r\nWhen creating a ValueMappingEstimator with KeyTypes as the values, the generated KeyType does not covert back to the original value. This is demonstrated when appending a KeyToValueTransform to retrieve the original values using the following code:\r\n\r\n```\r\n            // Creating a list of keys that are based on the Education values\r\n            // These lists are created by hand for the demonstration, but the ValueMappingEstimator can take in any IEnumerables.\r\n            var educationKeys = new List<string>()\r\n            {\r\n                ""0-5yrs"",\r\n                ""6-11yrs"",\r\n                ""12+yrs""\r\n            };\r\n\r\n            var educationValues = new List<string>()\r\n            {\r\n                ""Cat1"",\r\n                ""Cat2"", \r\n                ""Cat3""\r\n            };\r\n\r\n            // Generate the estimator with the key type set as true. Even though are values are strings, this will\r\n            // create a key for each value. For this example, a KeyToValue Estimator is added to the ValueMapping Estimator to demonstrate the\r\n            // reverse lookup of the KeyType\r\n            var pipeline = new ValueMappingEstimator<string, string>(ml, educationKeys, educationValues, true, (""Education"", ""EducationKeyType""))\r\n                              .Append(new KeyToValueMappingEstimator(ml, (""EducationKeyType"", ""EducationCategory"")));\r\n```\r\n\r\nThe expected results should be:\r\n```\r\nAge   Education   EducationCategory\r\n26      0-5yrs          Cat1\r\n42      0-5yrs          Cat1\r\n39      12+yrs          Cat3\r\n34      0-5yrs          Cat1\r\n35      6-11yrs         Cat2\r\n```\r\nThe actual results are:\r\n```\r\nAge     Education    EducationCategory\r\n26      0-5yrs          0-5yrs\r\n42      0-5yrs          0-5yrs\r\n39      12+yrs          12+yrs\r\n34      0-5yrs          0-5yrs\r\n35      6-11yrs         6-11yrs\r\n```\r\n\r\n'"
397178583,2084,b'Cannot access leaf nodes of trained trees',"b""### Issue\r\n\r\n- **What did you do?**\r\nIn FastTreeTrainerBase, I see that 'TrainedEnsemble' is not a public attribute.\r\n\r\n- **What did you expect?**\r\nIt would be awesome and useful for us if we could access the trained trees here. Thanks!"""
397159261,2083,b'ValueMappingEstimator does not produce the correct output schema with metadata',"b'The ValueMappingEstimator when calling GetOutputSchema and setting the treatAsKeyTypes to true does not return an output schema that contains metadata. This is can be reproduced by creating a ValueMappingEstimator and appending with a KeyToValueMappingEstimator to do a reverse lookup of the KeyType to the original value. \r\n\r\nHere is the code snippet that reproduces the error:\r\n```\r\n            var pipeline = new ValueMappingEstimator<string, string>(ml, educationKeys, educationValues, true, (""Education"", ""EducationKeyType""))\r\n                              .Append(new KeyToValueMappingEstimator(ml, (""EducationKeyType"", ""EducationCategory"")));\r\n```\r\n'"
397133345,2079,b'Making IDataView TrainingData inside LearnerInputBase internal.',"b'One of the fields in the  `Arguments`  class  for `FastTree`  is `public IDataView TrainingData`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8cf259639cc3f77feec5d87db1a4e4429b5c9936/src/Microsoft.ML.Data/EntryPoints/InputBase.cs#L35-L40\r\n\r\nThis is currently being used by the Entrypoint infrastructure. We should consider making this field `internal`\r\n\r\nHowever, this needs to be done with caution. \r\n\r\nHere is explanation by @TomFinley : \r\n\r\n"" Anything relating to entry-points specifically should be internal, but we must do so carefully, since currently entry-points and command line processing relies on processing of fields which is currently done on public fields only, whereas it should be over public or internal fields. Once that is done, any fields that are relevant to entry-points only should be internal.\r\n\r\n(This is a problem for all the settings objects, that they are exposing things that should not be in the public API in some cases. (Indeed entry-points will need a lot of work to make them work for estimators and transformers. Estimator graphs are sort of a ""lightweight"" estimator chain as they stand right now that performs absolutely no validation. But for now, anything relating to entry-points should just be hidden.)\r\n\r\n@TomFinley @artidoro \r\n\r\n\r\n\r\n\r\n'"
397126785,2078,b'API to identify colinearity (high-correlation between attributes/features/input-variables)',"b'Related to model explainability features and feature or input variable selection in general, if would be good to have any API to identify colinearity (high correlation between attributes/features/input-variables).\r\n\r\nColinearity in the input variables can make choosing the correct attributes/input-variables to use more difficult, especially in linear models.\r\n\r\nThis issue is also related to the more general issue: https://github.com/dotnet/machinelearning/issues/749\r\nBut this issue focuses on a particular feature which is ""colinearity detection"".\r\n\r\nIn short, collinearity:\r\n\r\n- Can make choosing the correct predictors to include more difficult.\r\n- Interferes in determining the precise effect of each predictor, but...\r\n- BUT, it doesn\xe2\x80\x99t affect the overall fit of the model or produce bad predictions.\r\n\r\nDepending on your goals, multicollinearity isn\xe2\x80\x99t always a problem. However, because of the difficulty in choosing the correct model when severe multicollinearity is present, it\xe2\x80\x99s always worth exploring.\r\n\r\nThis feature is not critical for our current major release (v1.0) that we are currently stabilizing, but should be taken into account for future releases.'"
397089290,2077,b'MatrixFactorization nuget package should have a dependency on Microsoft.ML',"b'Since the `Microsoft.ML.Recommender.dll` library references types from the core NuGet package (`Microsoft.ML`), the `Microsoft.ML.MatrixFactorization` needs to have a dependency on `Microsoft.ML`.\r\n\r\nTo fix this, add a ProjectReference in \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/pkg/Microsoft.ML.MatrixFactorization/Microsoft.ML.MatrixFactorization.nupkgproj\r\n\r\nSee this for an example:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8cf259639cc3f77feec5d87db1a4e4429b5c9936/pkg/Microsoft.ML.Parquet/Microsoft.ML.Parquet.nupkgproj#L9\r\n\r\nAlso, while we are in here - we should synchronize the names between the NuGet package and the assembly. It is super confusing that the assembly is named `Microsoft.ML.Recommender` and the package is named `Microsoft.ML.MatrixFactorization`.\r\n\r\n/cc @wschin '"
397046119,2075,b'Move public facing classes used in Samples into appropriate namespaces.',"b""As part of the grand rename of namespaces, let's finalize the set of namespaces of public-facing components.\r\n\r\n| Class/Interface/Enum/Delegate                           | Current Namespace      | New Namespace                                                 | Current Path                                                              |\r\n|---------------------------------------------------------|------------------------|---------------------------------------------------------------|---------------------------------------------------------------------------|\r\n| TransformerScope                                        | Microsoft.ML.Data      | Microsoft.ML                                                  | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs |\r\n| ITransformerChainAccessor                               | Microsoft.ML.Data      | Microsoft.ML                                                  | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs |\r\n| TransformerChain                                        | Microsoft.ML.Data      | Microsoft.ML                                                  | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs |\r\n| IDataView                                               | Microsoft.ML.Data      | Microsoft.ML                                                  | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| ISchema                                                 | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| delegate void ValueGetter<TValue>(ref TValue value);    | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| abstract class Row                                      | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| CursorState                                             | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| abstract class RowCursor                                | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IDataView.cs                |\r\n| interface IRowReadableAs<TRow>                          | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataView\\TypedCursor.cs          |\r\n| class RowCursor<TRow>                                   | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataView\\TypedCursor.cs          |\r\n| interface ICursorable<TRow>                             | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataView\\TypedCursor.cs          |\r\n| class TypedCursorable<TRow>                             | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataView\\TypedCursor.cs          |\r\n| static class CursoringUtils                             | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataView\\TypedCursor.cs          |\r\n| MultiFileSource                                         | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\MultiFileSource.cs  |\r\n| VBuffer<T>                                              | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\VBuffer.cs                  |\r\n| BinaryPredictionTransformer<TModel>                     | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| PredictionTransformerBase<TModel, TScorer>              | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| SingleFeaturePredictionTransformerBase<TModel, TScorer> | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| AnomalyPredictionTransformer<TModel>                    | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| MulticlassPredictionTransformer<TModel>                 | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| RegressionPredictionTransformer<TModel>                 | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| RankingPredictionTransformer<TModel>                    | Microsoft.ML.Data      | Make a catalog entry in ML namespace? Or move to ML namespace | E:\\machinelearning\\src\\Microsoft.ML.Data\\Scorers\\PredictionTransformer.cs |\r\n| interface Itransformer                                  | Microsoft.ML.Core.Data | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IEstimator.cs               |\r\n| interface IEstimator<out TTransformer>                  | Microsoft.ML.Core.Data | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IEstimator.cs               |\r\n| interface IDataReaderEstimator<in TSource, out TReader> | Microsoft.ML.Core.Data | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IEstimator.cs               |\r\n| interface IDataReader<in TSource>                       | Microsoft.ML.Core.Data | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IEstimator.cs               |\r\n| class SchemaShape                                       | Microsoft.ML.Core.Data | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IEstimator.cs               |\r\n| RoleMappedData                                          | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\RoleMappedSchema.cs         |\r\n| RoleMappedSchema                                        | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Core\\Data\\RoleMappedSchema.cs         |\r\n| ColumnCursorExtensions                                  | Microsoft.ML.Data      | ?                                                             | E:\\machinelearning\\src\\Microsoft.ML.Data\\Utilities\\ColumnCursor.cs        |\r\n\r\nCC: @TomFinley """
397042782,2074,b'Roadmap needs updating',"b""Our [READMAP.md](https://github.com/dotnet/machinelearning/blob/master/ROADMAP.md) has gotten rather out-of-date. \r\n\r\nThe current roadmap should reflect the progress we made.\r\n\r\nIt may also be helpful to have a CHANGELOG.md at the root folder which links to each of the detailed [release notes](https://github.com/dotnet/machinelearning/tree/master/docs/release-notes), and provides a few-line summary in a unified location. Currently it would be difficult to scroll though the releases for the last few months (which is overly optimistic for how often I update packages). There is a [releases tab](https://github.com/dotnet/machinelearning/releases) for GitHub, which is very similar, though I'm uncertain if this content is under version control which would cause it (possibly) not follow forks."""
397028918,2072,b'Add static APIs to a new nuget package',"b""In #1930 we introduced new static assemblies. Yeah! But then we forgot to add the new assemblies to any nuget package. Whoops. Which means they're effectively unshipped.\r\n\r\nThe ultimate solution should be that there are separate nugets for the static API. However, until that happens and we decide what shape those nugets would take, for the sake of the v0.9 we should maintain the status quo, which was that the new projects introduced in #1930 are shipped with their old assemblies.\r\n\r\n/cc @eerhardt @shauheen """
397020025,2070,b'Binary ensemble score and prediction column relationship',"b""So let's say I'm using WeightedAverage ensemble of two binary classification learners.\r\nEach learner will produce Score and Probability column.\r\n\r\nSince it's a weightedAvaerage we will learn weights for each learner let's say A and B. \r\nResulted Score value would be (A*ScoreA + B*ScoreB)/2.\r\nFor probability column we just take median so Resulted probability  = (ProbA+ProbB)/2.\r\nI'm not quite sure why we decide to calculate probability this way for all binary Ensembles (no matter is it average, min, max).\r\n\r\nIn all other binary learners Probability and score is related to each other via calibrator. So there is a function of score which produce probability, in case of ensemble it's not and I find it bit confusing."""
396998931,2069,b'Some functions are not used in HeaderSchema.cs',"b'As title. In class\r\n```\r\n    [BestFriend]\r\n    internal abstract class FeatureNameCollection : IEnumerable<string>\r\n```\r\nthose functions\r\n```       \r\n        private FeatureNameCollection()\r\n        {\r\n        }\r\n\r\n        public static FeatureNameCollection Create(string[] names)\r\n        {\r\n            return Create(Utils.Size(names), names);\r\n        }\r\n\r\n        public static FeatureNameCollection Create(RoleMappedSchema schema)\r\n        {\r\n            \xe2\x80\xa6\r\n        }\r\n\r\n        public static void Save(ModelSaveContext ctx, in VBuffer<ReadOnlyMemory<char>> names)\r\n        {\r\n            \xe2\x80\xa6\r\n        }\r\n\r\n        public bool TryLookup(string name, out int index)\r\n        {\r\n            \xe2\x80\xa6\r\n        }     \r\n```\r\nare not used.'"
396782168,2068,b'Word embedding output dimensions',"b'### System information\r\n\r\n- **OS version/distro**: windows 64bit 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: 2.1.502\r\n\r\n### Issue\r\nI am having trouble understanding the output of the WordEmbeddings function. Using a model with 50 dimensionality output, I would expect the embedding dimensions to match that output in some way. It only just multiplies the expected output dimension by 3.\r\n\r\nI have checked the model files, and they have the correct output for each word for each model.\r\n\r\n- **What did you do?** \r\nCreated wordEmbedding using several different preprocessed models. Both default and downloaded elsewhere\r\n- **What happened?**\r\nFor GloVe50D the output dimensions were 150.\r\nFor FastTextWikipedia300D the output was 900\r\n- **What did you expect?**\r\nI expected the output to match the embedding size in the models.\r\nFor GloVe50D to output dimensions 50 * input size, or [inputsize][50].\r\nFor FastTextWikipedia300D to output dimensions 300 * input size, or [inputsize][300].\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nThis code illustrates my issue. I would assume the output to be of variable size, but all outputs have dimensionality of 150, which I have trouble grasping. I have tried forcing the output to a variable vector output but it changes nothing.\r\n\r\nWhat worries me most, is what happens, when the input is a single word sentence, as I can not fathom or figure out what the extra 100 values are.\r\n\r\n```\r\n\r\nusing System;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.StaticPipe;\r\nusing Microsoft.ML.Transforms.Text;\r\n\r\nnamespace ConsoleApp1\r\n{\r\n    class DataEntry\r\n    {\r\n        public DataEntry(string message, int label)\r\n        {\r\n            Message = message;\r\n            Label = label;\r\n        }\r\n        public string Message { get; set; }\r\n        public int Label { get; set; }\r\n    }\r\n\r\n    class ModelOutput\r\n    {\r\n        public int Label;\r\n        public float[] Embedding;\r\n    }\r\n\r\n    class Program\r\n    {\r\n        private static MLContext mLContext = new MLContext();\r\n        private static PredictionFunction<DataEntry, ModelOutput> wordEmbedder;\r\n\r\n        static void Main()\r\n        {\r\n            var dataEntries = new[]\r\n            {\r\n                ""I am a horse"",\r\n                ""cow"",\r\n                ""The cat is norse"",\r\n                ""Don\'t ask me how"",\r\n                ""This is a sentence that is very long, and should have a different dimension than the other ones?""\r\n            };\r\n            var labels = dataEntries.Select((_, i) => i).ToArray();\r\n\r\n            TokenizeData(dataEntries, labels, out  var data);\r\n            \r\n            Console.WriteLine($""{data.Length} {data[0].Length}"");\r\n            foreach (var d in data)\r\n            {\r\n                Console.WriteLine($""{d.Length}"");\r\n            }\r\n\r\n            Console.Read();\r\n        }\r\n        \r\n\r\n        private static void TokenizeData(string[] dataEntries, int[] labels, out double[][] dataVectors)\r\n        {\r\n            var dataEnum = dataEntries.Select((s, i) => new DataEntry(s, labels[i])).ToArray();\r\n            var reader = mLContext.CreateDataView(dataEnum).AssertStatic(\r\n                mLContext, c =>\r\n                (\r\n                    Message: c.Text.Scalar,\r\n                    Label: c.I4.Scalar));\r\n\r\n            // Inspect the message texts that are read from the file.\r\n            var pipeline = reader.MakeNewEstimator()\r\n                    .Append(r => (\r\n                        LabelMid: r.Label,\r\n                        Embedding: r.Message\r\n                            .NormalizeText()\r\n                            .TokenizeText()\r\n                            .RemoveStopwords()\r\n                            .WordEmbeddings(\r\n                                WordEmbeddingsExtractingTransformer\r\n                                    .PretrainedModelKind\r\n                                    .GloVe50D)\r\n                    ))\r\n                ;\r\n\r\n            var modelFit = pipeline.Fit(reader);\r\n\r\n            wordEmbedder = modelFit.AsDynamic.MakePredictionFunction<DataEntry, ModelOutput>(mLContext);\r\n\r\n            dataVectors = dataEntries.Select((s, i) => NameToTfVector(s, labels[i])).ToArray();\r\n        }\r\n        \r\n        private static double[] SentenceFromWordEmbedding(ModelOutput embedding)\r\n        {\r\n            return embedding.Embedding.Select(f => (double) f).ToArray();\r\n        }\r\n\r\n        private static double[] NameToTfVector(string inputText, int label)\r\n        {\r\n            return SentenceFromWordEmbedding(wordEmbedder.Predict(new DataEntry(inputText, label)));\r\n        }\r\n    }\r\n}\r\n```\r\nOutput:\r\n`5 150\r\n150\r\n150\r\n150\r\n150\r\n150`'"
396691593,2064,"b'Estimator arguments should take output column name as first parameter, any inputs as subsequent parameters'","b'So, a somewhat embarrassing blunder to report... not quite sure how to say this.\r\n\r\nThroughout our codebase, for years we\'ve ***always*** specified the name of the output column of a transform first, *then* the source(s).\r\n\r\nThat\'s good. But when estimators were introduced, somehow, nearly all of them were introduced in the reverse order: nearly all of them specify the inputs, *then* the outputs. This was probably an unconscious mistake, but it\'s one with fairly wide consequences, since that mistaken pattern was copied again and again as people did the estimator conversion work, to the point where most (not all!) estimators are now inconsistent with the whole rest of the codebase!\r\n\r\nThis should be corrected: it is at least inconsistent, and even if not inconsistent actually rather obnoxious practically because specifying the name of the output first has practical benefits, and makes a lot more sense, since if you\'re specifying a transformation the *most* important information someone will want to know is what you\'re calling your output!\r\n\r\n# The Story Until a Few Months Ago\r\n\r\nSo, throughout our codebase, for years, it has been our practice that when specifying a transform, you specify the name of the output, *then* you specify the name of the input(s) (if any). The reason for this is practical: the outputs are usually the result of a well defined single calculation (the application of the transform), whereas what is taken as an ""input"" to a transform can have various meanings since it is sometimes a multivariate function in its *inputs* more often than in its *outputs*. (E.g., concatenate can have multiple inputs, text can have multiple inputs, MI feature selection takes multiple heterogeneous inputs, but all produce single output columns.)\r\n\r\nThis was our practice certainly when this code was a tool, as we see in the command line help string, specifying name *then* source.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bb46fdf405828134de9feebce74f21b4aacb15ed/src/Microsoft.ML.Data/Transforms/ColumnCopying.cs#L109-L110\r\n\r\nThis trend continued during our initial attempts at an API, as seen in this [early discussion in PR 405](https://github.com/dotnet/machinelearning/pull/405#discussion_r197980521), and as seen here:\r\n\r\nhttps://github.com/zeahmed/machinelearning/blob/16f7883933b56f8fd86077bf0fd262b24374e9d0/src/Microsoft.ML.Data/Transforms/ConvertTransform.cs#L116\r\n\r\nand here\r\n\r\nhttps://github.com/zeahmed/machinelearning/blob/16f7883933b56f8fd86077bf0fd262b24374e9d0/src/Microsoft.ML.Data/Transforms/DropSlotsTransform.cs#L226\r\n\r\nand numerous other places.\r\n\r\nThis is done for the practical reason that, when a transform produces an\r\noutput, what outputs it has are usually finite and well defined, whereas it can take multiple examles. The most conspicuous and widely used example of this is\r\nthe concatenation transform. Also included are things like the text featurizing transform, and other such things.\r\n\r\nSo far so good...\r\n\r\n# But Then...\r\n\r\nNow, somehow, through some mechanism that wasn\'t quite clear to me, as `IEstimator` implementations are being created, someone commits a fateful mistake of *reversing* inputs and outputs. Suddenly instead of being typically parameterized as `name` and a sometimes optional `source`, we instead have the required `input` and a sometimes optional `output`. What a disaster! And, I did not catch it in review. An early example:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c8de311476eb04dd4c8be1ad5b898487d66c9ef5/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L278-L279\r\n\r\nThen, as people use this as a template for their own estimator conversion work, nearly *all* estimators copied this mistake, until practically all estimators had this problem. This includes much of the extensions.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d9270c9c42da70817e8a71e39a069d2339f6972d/src/Microsoft.ML.Data/Transforms/ExtensionsCatalog.cs#L30-L31\r\n\r\nNow then, the reason why I know any of this is that @stephentoub wrote and says, ""hey, how come you have your column concatenation operation specify output *then* inputs? That\'s different from everywhere else! I know it\'s less convenient, but it\'s better to be consistent.""\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d9270c9c42da70817e8a71e39a069d2339f6972d/src/Microsoft.ML.Data/Transforms/ExtensionsCatalog.cs#L39\r\n\r\nAnd, after thinking that he must be very confused, since again, the pattern of name *then* source being very, very well defined throughout the codebase, I look and find **he is absolutely correct**, and a thoroughly massive blunder had somehow made it throughout the entire codebase under our very noses, including it must be said mine. :) :)\r\n\r\nSo, this is bad, but happily this was caught before v1. But, needless to say this must be fixed immediately.'"
396685323,2063,b'How should EntryPoint consumers register ML.NET assemblies?',"b'@eerhardt,  when we made HostEnvironmentBase and ComponentCatalog internal you mentioned that EntryPoint consumers like NimbusML or the GUI should be responsible for registering their ML.NET assemblies:\r\n\r\n>[2. ...\r\n>3. Other subsystems (like the GUI, command-line, Entry Points, and model loading) will be responsible for registering the components they require in the manner they require.\r\n>4. ...](https://github.com/dotnet/machinelearning/issues/208#issuecomment-422136134)\r\n\r\nCould you give me some pointers on how to best go about that?  Currently NimbusML registers assemblies using the ComponentCatalog from when it was public and we need to update this to ML.NET 0.9:  https://github.com/Microsoft/NimbusML/blob/e1004720ec0c252ba87f02c190c33739d9c00f20/src/DotNetBridge/Bridge.cs#L314\r\n\r\ncc: @TomFinley @yaeldekel @shmoradims \r\n\r\n'"
396684412,2062,b'Fixing NimbusML GraphRunner',"b'ML.NET changes below are causing NimbusML GraphRunner to break. @TomFinley, @yaeldekel  could you please advise how to best fix these?\r\n\r\n1. [GraphRunner.GetPortDataKind](https://github.com/dotnet/machinelearning/blob/0c62e30b4d9eabb60322b2a3e75bc90e20007889/src/Microsoft.ML.EntryPoints/JsonUtils/GraphRunner.cs#L142) is made internal and inaccessible. [Nimbus usage](https://github.com/Microsoft/NimbusML/blob/80ce48f0505eba1564dafd2dfd249905ee7b6143/src/DotNetBridge/RunGraph.cs#L134). Also TlcModule.DataKind is made internal and inaccessible. \r\n\r\n2. Cannot load PredictorModel from file using constructor, because the class has become abstract. [Nimbus usage](https://github.com/Microsoft/NimbusML/blob/80ce48f0505eba1564dafd2dfd249905ee7b6143/src/DotNetBridge/RunGraph.cs#L170).\r\n\r\n3. PredictorModel.Save is made internal and inaccessible.  [Nimbus usage](https://github.com/Microsoft/NimbusML/blob/80ce48f0505eba1564dafd2dfd249905ee7b6143/src/DotNetBridge/RunGraph.cs#L85).\r\n\r\n4. Both 2 & 3 also apply to 2 TransformModel.\r\n\r\n5. #1958 (being discussed separately in that issue)'"
396587971,2056,b'Add Linux support for OnnxRuntime and OnnxTransform',b'Require scoring support for Onnx models on Linux'
396574013,2055,"b'Run code in documentation regularly, to prevent breaks'","b'We need to figure out a way to run the code in the documentation, perhaps using a unit test.\r\nRelated to #2039 .\r\n@justinormont , in the issue above it is mentioned that you had already suggested some sort of solution to this, please feel free to reference the issue discussing this, or close this issue if it is a duplicate.\r\n'"
396569525,2054,b'Update broken documentation code',b'For example: https://github.com/dotnet/machinelearning/blob/80f5720438d544b1c9cf019a889479d8e67d5837/docs/code/SchemaComprehension.md.\r\n\r\nRelated to #2039 .'
396566993,2053,b'Metrics results ToString overload?',"b'Consider this class, a result from a non-calibrated evaluation of binary classification.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2f7075782764c9dab8f0a04013aaf8b9921d984/src/Microsoft.ML.Data/Evaluators/Metrics/BinaryClassificationMetrics.cs#L10\r\n\r\nIt might be nice if `ToString` was enabled on it, would it not? Maybe something that looks like a JSON serialized object (perhaps even exploiting the presence of Newtonsoft, since we must rely on it elsewhere?) would be appropriate? Who knows.\r\n\r\nNeedless to say, if we do it for one we should probably do it for all.'"
396564514,2052,b'BinaryLoader created from IMultiStreamSource not Stream',"b'Whenever a binary loader is created, it can be crated from either a path or a stream. It is inappropriate for the public API to intimate that it is possible for the binary loader to be creatable from a stream. Even though it can be, this is a historical accident as the format (and its reader) predates `IMultiStreamSource`. Rather it, like all readers of this shape, should take `IMultiStreamSource`. That *internally* it operates over a single stream is an implementation detail that should not be visible externally.'"
396548632,2051,b'Removal of IHostEnvironment.ConcurrencyFactor and replace with ... ?',"b""Consider this property\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2f7075782764c9dab8f0a04013aaf8b9921d984/src/Microsoft.ML.Core/Data/IHostEnvironment.cs#L43\r\n\r\nset for example via this `conc` parameter here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2f7075782764c9dab8f0a04013aaf8b9921d984/src/Microsoft.ML.Data/MLContext.cs#L76\r\n\r\nThat we should have some sort of indication hinting of degree of desired parallelism might have seemed useful at one point, but the practical reality has more closely resembled this: components where parallelism matters for performance or results invariably wind up having their own independent settings *anyway*, to such a degree even that the `IHostEnvironment.ConcurrencyFactory` property is for the most part totally ignored -- e.g., people set `conc = 1` thinking this will give them deterministic results, but of course things like SDCA and LR have separate multithreading behavior, which under default settings will not give deterministic results unless it is set.\r\n\r\nAs an integer property, and as originally intended, this property is, i'd claim, a failure, since everywhere it *could* matter we wind up inevitably ignoring and overriding its behavior anyway, and where we don't it's only because that is a situation where such control doesn't really matter.\r\n\r\nWe ought at least to remove this, I think. This must be done prior to v1.\r\n\r\nWhether post v1 we want to replace it with *anything* is another matter. Clearly at least for *test* purposes we want to have something to ensure consistent deterministic results, but is this really a user concern? (Definitely in other ML frameworks it is not a guarantee at all, so the idea of providing it and making it some sort of global configuration option seems questionable.)\r\n\r\n/cc @stephentoub """
396536833,2050,b'Gentle suggestion for missing columns?',"b'Often times, we have a method that takes some input with a default column names as inputs... e.g., `Label` and `Features` for trainers, `Label` and `Score` for evaluators, and so on, and so on. Indeed this was the subject of a discussion in issue #1524.\r\n\r\nIn these situations, it might be helpful if the error message, in addition to saying, ""we could not find column `Foo`"" might provide a gentle parenthetical suggestion along the lines of ""(Did you remember to actually produce that column, or did you perhaps name it something else?)"" might help get people thinking in the ""right"" direction.\r\n\r\nLess sure about this one.\r\n\r\n/cc @stephentoub '"
396311883,2046,b'TextLoader Arguments/ArgumentsCore classes',"b'Consider this class, the settings object for `TextLoader`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L382\r\n\r\nThis descends from this class.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L337\r\n\r\nWhy establish this class relationship? Well, because we want to distinguish between arguments that are ""core"" vs. not, and so that should be retained when we save the ""header"" of the text file, vs. those that might vary from iteration to iteration.\r\n\r\nThis class is used in two places for this purpose, in two places exactly.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1193-L1195\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1230-L1236\r\n\r\nBack when these classes were written and meant to support a command line and GUI tool only, it was acceptable to use class relationships for this purpsoe -- we did not expose this class to the users via an API. Now that we do expose it through an API, this little ""trick"" is no longer acceptable and causes confusion. There are only three ""special"" non-core arguments to account for, surely we can handle their presence through some mechanism other than this odd pollution of our type hierarchy (which is visible to users necessarily), and instead just handle it in the code for the saving/loading of the header itself. (That is, the load/save code could just account for the three arguments directly, instead of working in this strange way through the command line processor.)\r\n\r\nThe end result of this should be there should be only one class, `Arguments`, containing everything that is now in these two classes. It is also essential that the arguments presently occurring *only* in the `Arguments` class at present be excluded from the header and header parsing code.\r\n\r\nThere are several ways we could imagine doing this.\r\n\r\n1. The most obvious is to just special case this code in the `TextLoader` code itself.\r\n\r\n2. Another possibility is we add another attribute to the command line processing code itself, to capture those arguments that are meant to capture purely runtime and not behavioral considerations. Indeed, this happens in other contexts: those components that benefit from GPU acceleration might, naturally, have the GPU device ID as a configuration parameter, but if we were to ask this component to describe its configuration, behaviorally we might want it to *exclude* that configuration, since that is not portable from one computer or platform to another. (Which is the purpose of the current arrangement.) Rather than special casing this, as suggested above, we could have another (internal!!) attribute to flag such arguments as these.\r\n\r\nI give two options because O am not too particular as to how. I might favor 1 until we gain more experience in scenario 2 so as to justify a more general solution. Though, perhaps we have already reached that point, since I know scenario 2 that I have described has already come up, though in situations less central and important than the text loader.\r\n\r\n/cc @stephentoub '"
396290933,2044,b'Improve TrainerEstimatorBase exception messages for types',"b'Consider this error message:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs#L98-L99\r\n\r\nThis is quite a charming message. Most of the time (not always, perhaps) a trainer expects a known size vector of float. What if the user feeds in something else? They get this, and are told that it is ""not compatible."" It is absolutely true. That\'s not compatible. They try something else, if it doesn\'t happen to be exactly right, they get the same error message. Not compatible. So, while absolutely true, it sort of reminds me of this game:\r\n\r\n![Calvin and Hobbes ""Nope guess again""](https://i.pinimg.com/736x/c0/f3/32/c0f33288f377a621cca764d375b09092.jpg)\r\n\r\nThis error message is in the `TrainerEstimatorBase`. Which is to say, nearly all trainers (except specialized trainers) will check the features column through this, which means that a user\'s likelihood of seeing this message is fairly high.\r\n\r\nConsider the following far more helpful example. Note that we even have a convenience function for standard reporting and formatting of this type mismatch error, since it is so common!\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/Evaluators/MultiClassClassifierEvaluator.cs#L82-L83\r\n\r\nOf course, it may be that there are plenty of places that we are not being less descriptive with types than we should be, but since trainers (and especially the base class!) will be used by nearly everyone, we might identify this as deserving special prioritization.\r\n\r\nWe should probably change `TrainerEstimatorBase` so that it or its subclasses use these more descriptive helpers, throughout the type checks. Ideally we\'d also scour the codebase for typical checks of this form to make sure they are likewise descriptive.\r\n\r\nThat is at least what we should do, but, in a *super* ideal world, we might be able to go one step further and even provide advice on *what* should be done to get it into the required form (that is, be not just descriptive, but prescriptive, to borrow a phrase from @stephentoub), but how to do that is unclear to me. (The best thing I can think of is, we, by which I mean a data scientist, probably ought to write a web article on typical strategies for featurization, and why it\'s important to give it some thought, but that\'s certainly not something you want to put in an exception message. Though it might be a nice thing to *link* from the exception, if possible.)\r\n\r\n/cc @stephentoub '"
396233233,2042,b'MLContext.Log to become event?',"b'Consider this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/faffd179c961f120ec4e6babb06bbfb2cca6a6ea/src/Microsoft.ML.Data/MLContext.cs#L64\r\n\r\nIf that were instead an event, we would gain some benefits, specifically, some measure of protection again line X registering some logging, then line X+N in some way registering more logging that in some way undoes the original logging. (It is linguistically simpler to perform this ""wrong"" action in C#, so some guard against it may certainly be worthwhile.)\r\n\r\n/cc @stephentoub '"
396229213,2041,b'TextLoader Separator/SeparatorChars',"b'Consider these two settings:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/496e185fdaf8969ffd856c65c42dd259368a242d/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L356-L360\r\n\r\nThey both exist for the same purpose but serve very different endpoints. One exists for the benefit of the command line, one for the benefit of the API. The API one (currently named `SeparatorChars`) should instead become `Separators` (plural pursuant to #2040). The other, currently named `Separator`, can remain named that, but should be invisible to API users since it exists purely for the benefit of the command line users. So, it should become `internal`.\r\n\r\n/cc @stephentoub '"
396227082,2040,b'Pluralize names of settings/arguments field values to plural when array',"b'Consider this content of concatentating transformer\'s `Argument`\'s class:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/496e185fdaf8969ffd856c65c42dd259368a242d/src/Microsoft.ML.Data/Transforms/ColumnConcatenatingTransformer.cs#L116-L117\r\n\r\nOr this similar entry:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/496e185fdaf8969ffd856c65c42dd259368a242d/src/Microsoft.ML.Data/Transforms/ColumnConcatenatingTransformer.cs#L122-L123\r\n\r\nYou will notice something curious. This is an array of `Column[]`, yet is named `Column`, not `Columns`. The reason for this is somewhat odd: this settings object *originally* arose out of the need to provide a command line settable object back when this code was supporting a tool (and not an API!). And, the presence of an array indicate that this setting can be set multiple times... so one could say, for instance, `column=Foo column=Bar column=Biz`, and so wind up with this field populated with 3 items. In this setting the name ""column"" is the most natural name.\r\n\r\nNow we are trying to ship an API. What we did for the convenience of the command line now causes confusion for an API user, because they see an array (which can clearly handle multiple items), yet it has a singular name!\r\n\r\nFortunately, we can have our cake and eat it too: the `ArgumentAttribute` has something called `Name`, to allow the field name to be distinguished from the command line name. So, this:\r\n\r\n```csharp\r\n[Argument(ArgumentType.Multiple | ArgumentType.Required,\r\n    HelpText = ""New column definition(s) (optional form: name:srcs)"",\r\n    ShortName = ""col"", SortOrder = 1)]\r\npublic Column[] Column;\r\n```\r\n\r\ncould become this:\r\n\r\n```csharp\r\n[Argument(ArgumentType.Multiple | ArgumentType.Required,\r\n    HelpText = ""New column definition(s) (optional form: name:srcs)"",\r\n    Name = ""Column"", ShortName = ""col"", SortOrder = 1)]\r\npublic Column[] Columns;\r\n```\r\n\r\nand remain equivalent from the command line perspective, while not being confusing from the API perspective.\r\n\r\nAs a general rule any field with an `ArgumentAttribute` attribute on it that is also an array, we have often not made plural, for the aforementioned reasons. If it is singular:\r\n\r\n1. Make the field name itself plural and\r\n\r\n2. Retain the old singular command line as this `Name` parameter, so as to retain the benefit of why we named it this way in the first place.\r\n\r\nHowever, please, not thoughtlessly! Think about whether that change makes sense *in context*.\r\n\r\n/cc @stephentoub '"
396224973,2039,b'Code in Documentation Not Working',b'### Issue\r\n\r\n- **What did you do?**\r\nNavigated to https://github.com/dotnet/machinelearning/blob/80f5720438d544b1c9cf019a889479d8e67d5837/docs/code/SchemaComprehension.md\r\n\r\nNoticed that the code uses Microsoft.ML.Data.TlcEnvironment that no longer exists\r\n\r\n@justinormont had a great suggestion -- perhaps wrap each documentation code sample in a unit test to prevent breakage?'
396144986,2038,"b""ReplaceMissingValues' input argument type""","b'Most transforms use string as column names but in the function below, users need to create `ColumnInfo` first.\r\n```\r\n        public static MissingValueReplacingEstimator ReplaceMissingValues(this TransformsCatalog catalog, params MissingValueReplacingTransformer.ColumnInfo[] columns)\r\n```\r\nIs it appropriate to use\r\n```\r\n        public static MissingValueReplacingEstimator ReplaceMissingValues(this TransformsCatalog catalog, string[] inputs, string[] outputs)\r\n```\r\nor\r\n```\r\n        public static MissingValueReplacingEstimator ReplaceMissingValues(this TransformsCatalog catalog, params (string, string) inputOutputColumnPairs)\r\n```\r\n?'"
396125056,2037,b'Need better exception for TextLoader when column attribute is not present',"b'In PR #2033 we converted all uses of the legacy TextLoader to the new TextLoader.\r\n\r\nIt emerged that when reading from a file providing the schema, if there is no column attribute, then there are two different exceptions thrown depending on whether it is a debug or release build.\r\n\r\nWe need a single exception for both debug and release, and we need the name to be more informative. We also need a single message for both exceptions.\r\n\r\nThis is the test that exerts these exceptions: ThrowsExceptionWithPropertyName in TextLoaderTests.cs'"
396122184,2035,b'APIs that were made internal need to be exposed for use in an internal repo',b'We need to add the InternalsVisibleTo attribute to a few of the ML.NET projects so that components in the internal repo can use their internal APIs.'
396118100,2034,"b'When in debug loading ML model fails with ""Unknown file type""'","b'When in debug, I get an exception, ""Unknown file type"", when I try to load an already trained ML model. The weird thing is that this only happens in debug. Any idea as to why this is failing? Thanks'"
396082082,2028,b'Internalization of CacheDataView and IRowSeekable',"b'One thing we may want to consider is that, while having caching is nice and necessary, and we should expose some ability to *perform* caching if we want (as we do with the, exposing `AppendCacheCheckpoint`, as seen here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5c00980abeae594161d0b9ee748d7d0b959962b5/src/Microsoft.ML.Data/DataLoadSave/EstimatorChain.cs#L99\r\n\r\nThis itself *uses* `CacheDataView`, but does not expose it. I am somewhat uncomfortable exposing the cache data view as part of our public API in a way that makes it a first class citizen of the API, at least, in v1.0 of the API. Its particular interface is a bit odd (possibly for good reasons, but odd nonetheless), and most of the reasons for its oddness have to do with how components might want to behave ""specially"" with it, and component authoring scenarios are not a target for v1.0. So hiding it, and `IRowSeekable` (which is a useful but, again, somewhat odd interface), might be good.'"
396068456,2026,"b""TextFeaturizingEstimator shouldn't use Argument class as main way of setting itself.""",b'https://github.com/dotnet/machinelearning/blob/5c00980abeae594161d0b9ee748d7d0b959962b5/src/Microsoft.ML.Transforms/Text/TextFeaturizingEstimator.cs#L141\r\n\r\nCurrently if I want to play with Word extractor and Char extractor I need to do that via \r\nhttps://github.com/dotnet/machinelearning/blob/5c00980abeae594161d0b9ee748d7d0b959962b5/src/Microsoft.ML.Transforms/Text/TextFeaturizingEstimator.cs#L497\r\n\r\nwhich stops me from hiding IDataTransform interface.\r\nWe should have proper way to set it up via Setting object.\r\n\r\nRelated to https://github.com/dotnet/machinelearning/issues/1995'
396049815,2025,b'Add a method in DataOperationsCatalog that creates an IDataView from an IEnumerable<T>',"b'Currently we have an extension method CreateStreamingDataView in ComponentCreation that operates over IHostEnvironment. We should add an extension over DataOperations instead, and consider making the current one internal.\r\nRelated to #1993 .'"
395956164,2022,b'Convolutional net gives different results under ML.NET and Keras/TensorFlow',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 1809\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.2.100\r\n Commit:    b9f2fa0ca8\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.100\\\r\n\r\nHost (useful for support):\r\n  Version: 2.2.0\r\n  Commit:  1249f08fed\r\n\r\n.NET Core SDKs installed:\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.500 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.502 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.100 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\nI\'m facing an issue while trying to score my Keras-trained, TensorFlow-backed model using ML.NET 0.8.\r\n\r\n#### The ML task\r\nThis is a rather small convolutional neural net that inputs an image and attempts to identify two areas of interest in the image. We are attempting to read some data off a hardware device.\r\n\r\n#### The model\r\n\r\nWe have a trained Keras model (.5h) and we converted it into a frozen TensorFlow model (.pb). The net contains 4 convolutional layers, 1 dense layer (the output), and uses ReLU activations. The output of the model is an array of 8 numbers: [X1_1, Y1_1, X2_1, Y2_1, X2_1, Y2_1, X2_2, Y2_2]. These are the top-left and bottom-right corners of the two areas of interest.\r\n\r\nNetron diagram:\r\n\r\n![current_model_best](https://user-images.githubusercontent.com/7479226/50692919-bfe0c280-1035-11e9-8e21-d32da1006a4a.png)\r\n\r\nThis model works very well for our use case when we execute it using Keras.\r\n\r\n#### the ML.NET scoring setup\r\n\r\nSince our main application is written in C#, I tried to use ML.NET to access the predictions from C# code. The pipeline is setup like this:\r\n\r\n\r\n``` csharp\r\nvar pipeline =\r\n    new ImageLoadingEstimator(env, imagePath, (nameof(AreaInput.Path), ""ImageData""))\r\n    .Append(new ImageResizingEstimator(env, ""ImageData"", ""ImageResized"", Areas.ImageWidth,\r\n        Areas.ImageHeight))\r\n    .Append(new ImagePixelExtractingEstimator(env,\r\n        new ImagePixelExtractorTransform.ColumnInfo(\r\n            ""ImageResized"", Areas.InputLayerName,\r\n            ImagePixelExtractorTransform.ColorBits.Rgb, interleave: true,\r\n            scale: 1 / 255f)))\r\n    .Append(new TensorFlowEstimator(env, modelPath, new[] {Areas.InputLayerName},\r\n        new[] {Areas.OutputLayerName}));\r\n```\r\n\r\nOn the surface, we do the same thing as with Keras:\r\n1. Load an image from the file system\r\n2. Resize the image to 400x400 (the model\'s expected input size)\r\n3. Convert the image to a vector (dimmensions of (batch_size, 400, 400, 3) - we are using RGB mode)\r\n4. Feed this vector into the TF model\r\n\r\nThen we make a predictor function from this pipeline and use that to score examples.\r\n\r\n#### The issue\r\n\r\nThere are actually two issues with this. One is a problem with interoperability - the `ImageResizingEstimator` is doing something very different than Keras\' `load_img`:\r\n\r\n* `load_img(x, target_size=(400,400), color_mode=""rgb"")` loads the image in RGB and resizes it to 400x400. The image ends up ""squeezed"" into a square\r\n* `ImageResizingEstimator to 400x400` either pads or crops the source image to be 400x400. The result of this operation is therefore very different.\r\n* Resizing the source images to 400x400 BEFORE feeding them into the ImageResizingEstimator actually leads to an `ArgumentException` - the resulting bitmap is invalid when it gets to the `ImagePixelExtractingEstimator` stage.\r\n\r\nThis is mainly an issue with documentation, I guess - it would be very helpful to declare this behavior explicitly, especially for interoperability scenarios such as this. At any rate, while realizing this, we went and resized our training images to 401x401 (to bypass the third bullet point issue) and retrained the model. \r\n\r\nOur theory was that will both allow the resizer to do its job without exception and will avoid the difference in behavior of the resize behavior - since resizing from 401x401 to 400x400 does not change the bitmap too much. So the expectation was that feeding the same 401x401 image to Keras and ML.NET should produce the same predictions.\r\n\r\nThis did not happen. The ML.NET code seems to be working and produces predictions, however these predictions are way off of the Keras results (the Keras/TF results are actually correct which we proved by drawing the resulting coordinates on the images).\r\n\r\nSo the problem here is: is our TF setup wrong? Or is this some underlying difference in behavior which we can\'t see? I\'m attaching a repro code as well. The ML.NET part is a .NET Core 2.2 project. To run the Keras part, you\'ll need the whole Keras stack installed (Keras + Tensorflow). The models and some sample images are included as well.\r\n\r\nSample output demonstrating the issue:\r\n\r\nML.NET predictions for three images:\r\n78,151,124,196,157,152,208,195\r\n83,160,131,208,167,162,220,207\r\n82,161,136,212,174,163,229,211\r\n\r\nKeras output for the same three images:\r\n[96, 182, 166, 247, 218, 179, 291, 247]\r\n[97, 186, 169, 253, 222, 182, 297, 252]\r\n[99, 252, 172, 314, 225, 249, 294, 311]\r\n\r\nSome additional details:\r\nWe tested this both against TensorFlow and Tensorflow-GPU, the issue persists. Therefore it\'s not a problem of running on GPU vs CPU. One possible explanation would be that I simply froze the TF graph wrong by specifying an incorrect final node, but I\'m pretty sure TensorBoard is telling me that `final_layer/BiasAdd` is my final node:\r\n![image](https://user-images.githubusercontent.com/7479226/50694338-e86abb80-1039-11e9-98b4-59688a076450.png)\r\n\r\nAny help with tracing this down would be greatly appreciated - operationalizing a TF model directly from C# is an awesome capability to have.\r\n\r\n#### Source\r\n[MLNetConvNetRepro.zip](https://github.com/dotnet/machinelearning/files/2727391/MLNetConvNetRepro.zip)\r\n'"
395808852,2019,b'FastTree learning rate in advanced settings does not override the default value ',"b'These lines in the BoostingFastTreeTrainerBase ctor reset it to the value specified directly (or the default value):\r\n\r\n            if (Args.LearningRates != learningRate)\r\n            {\r\n                using (var ch = Host.Start($""Setting learning rate to: {learningRate} as supplied in the direct arguments.""))\r\n                    Args.LearningRates = learningRate;\r\n            }\r\n\r\n(Reported in #1983 .)\r\n'"
395770903,2016,b'Feature Contribution Calculation Top/Bottom arguments are confusing',"b""### Issue\r\nThe current API for Feature Contribution are confusing.  They have the following parameters:\r\n` FeatureContributionCalculation(... int top = 10, int bottom = 10..);`\r\nthose arg names are confusing.  From naming it is unclear if bottom means max negative or min abs() contribution.  \r\nLet's rename them params to `topPositive and topNegative`\r\n\r\n"""
395757961,2014,b'Recommendation as a method on MLContext object',"b'\r\nRegression, BinaryClassification and MulticlassClassifcation context appear as properties on MLContext object while Recommendation context appear as method. Also tooltip is showing incorrect help.\r\n\r\n![image](https://user-images.githubusercontent.com/38438266/50666493-d15c9880-0f69-11e9-8c58-fcc593e477ec.png)\r\n'"
395737137,2010,b'LinearModelStatistics API usage cleanup',"b'There are several issues with the usage of the [LinearModelStatistics ](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs). \r\nSome of them are captured on the discussion of PR #1979. \r\n\r\nAnother issue with this class as is, is its two constructors. \r\n[One of them](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L95) initializes just the trainingExampleCount, deviance, nullDeviance. \r\n[The other one](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L107) adds to it the bias and weights, so parameter specific stats can be calculated. \r\n\r\nThe uncertain existance of the weights, bias makes all the methods of this class do work on the first batch of stats (trainingExampleCount, deviance, nullDeviance) than check for the existence of the weights and bias std, and  exit if this is missing, or continue to work.  See lines [199](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L199), [222](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L222), [238](https://github.com/dotnet/machinelearning/blob/25f3287036fd5956d3726a9dc7c510883eb608d4/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L238); almost every method has its half-way out. \r\n\r\nThe implementation should clearly be broken down, potentially hierarchically, all methods should be instance methods and whatever field/property they need from the ModelParams class that hosts them, should be passed down to the constructor. \r\n'"
395725626,2009,b'Bring back support for `ConfusionMatrix`  in the new API',"b'While updating tests from the old AP to the new API, we found that  the new API does not support  `ConfusionMatrix`  in the evaluation output.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/21d64aa5781750bfaddad262100c54989e8901f8/src/Microsoft.ML.Data/Evaluators/MultiClassClassifierEvaluator.cs#L506-L520\r\n\r\nIn the Legacy API,  there was support for  `ConfusionMatrix`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/21d64aa5781750bfaddad262100c54989e8901f8/src/Microsoft.ML.Data/Evaluators/MultiClassClassifierEvaluator.cs#L1031-L1049\r\n\r\nWe should add back the  checks for `ConfusionMatrix`  in the following tests : \r\n- TrainAndPredictIrisModelTest\r\n- TrainAndPredictIrisModelWithStringLabelTest\r\n\r\n@codemzs  @Ivanidzo4ka '"
395642518,2006,b'DataKind Enum is not well documented',"b'This issue was initially logged in the dotnet/docs repo [9278](https://github.com/dotnet/docs/issues/9278) and [9184](https://github.com/dotnet/docs/issues/9184). \r\n\r\n@TomFinley, @CESARDELATORRE, @eerhardt Is the DataKind Enum something that will remain user facing, or will it get behind the .net types?\r\n\r\nShould we document the DataKind or cleanup our error messages, and usage to not contain references to the DataKind anymore like #1943 suggest?\r\n\r\ncc @mairaw @JRAlexander \r\n\r\n'"
395450969,2003,b'StaticPipe.Runtime namespace',"b'As part of #1697 , we have removed ""Runtime"" from namespaces\r\n\r\nDo we also get rid of the  `Microsoft.ML.StaticPipe.Runtime` namespace,  and perhaps  consolidate the code related to the Static API inside  the `Microsoft.ML.StaticPipe`  namespace  instead ?\r\n'"
395416094,2002,b'Running a Dry Run for the benchmarks',b'Currently we are not running benchmarks on our CI. So they keep on breaking when we change the behavior. I propose running a dry job for all the benchmarks i.e. running the benchmarks for atleast one iteration.\r\neg.\r\nKmeans was broken and fixed by https://github.com/dotnet/machinelearning/pull/1883/files\r\nSimilarly before that stoachastic Gradient benchmarks were broken\r\n\r\ncc @danmosemsft @eerhardt @adamsitnik '
395404836,1999,"b""Unhandled Exception: System.DllNotFoundException: Unable to load DLL 'CpuMathNative' ""","b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.2.101\r\n Commit:    236713b0b7\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.2.101\\\r\n\r\nHost (useful for support):\r\n  Version: 2.2.0\r\n  Commit:  1249f08fed\r\n\r\n.NET Core SDKs installed:\r\n  2.2.101 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.2.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\n\r\n- **What did you do?** Followed tutorial: https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial\r\n\r\n- **What happened?** Unhandled Exception: System.DllNotFoundException: Unable to load DLL 'CpuMathNative' or one of its dependencies: The specified module could not be found.\r\n(Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Runtime.Learners.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Runtime.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at myApp.Program.Main(String[] args) in C:\\Users\\jakeradzikowski\\dev\\iris\\Program.cs:line 69\r\n- **What did you expect?** Iris example to work.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
395384176,1997,"b'Need to support Poisson, Gamma, and Tweedie regressions from LightGbm'","b'As mentioned in #1424, for LightGbm regression, ML.NET interface only exposes L2-loss function to users.'"
395351773,1996,b'StopwordsRemovingEstimator direct instantiation tests/samples?',"b""We have #1646 introduced the estimator for stopwords removal, and the estimator, as `StopwordsRemovingEstimator` and transform. Howeve,r we did not directly test it, though it is being tested through the text transform. We should probably have direct tests for it, as well as an extension emthod for the text transformation catalog through `MLContext`.\r\n\r\nThis also makes me wonder if we've added other text featurizing things. That should be checked as well."""
395320291,1995,b'Internalize concepts of IDataTransform/Loader/TransformTemplate.',"b'Before we had the `IEstimator`/`ITransformer`/`IDataView` triad (see #581), we combined all three concepts inside `IDataTransform`. The initialization, the data, *and* the data model were all conflated. This was the source for years of constant confusion internally. We of course had to abandon the idea when we were trying to make an API. Here\'s the interface, for reference:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2e67134b45c9253797d0fa137054ec8da1d7ad9c/src/Microsoft.ML.Data/Data/IDataLoader.cs#L90\r\n\r\nSimilarly, before we had `IDataReaderEstimator`/`IDataReader`/`IDataView` triad, we combined all three concepts inside `IDataLoader`.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2e67134b45c9253797d0fa137054ec8da1d7ad9c/src/Microsoft.ML.Data/Data/IDataLoader.cs#L53\r\n\r\nWe also have the old concept of `ITransformTemplate`, which the `ITransformer` interface has likewise obviated.\r\n\r\nWe\'ve introduced the new concepts over the course of the last half year or so, which is great, yet the artifacts of the old world remain. The interfaces should be made internal so people don\'t stumble into using them. Further, the objects used through `ITransform` and `IDataView` should (even when still backed by an `IDataTransform` object!) be hidden so it is not obvious these concepts are being conflated internally, even if ""under the hood"" there is just a small shim to present what is (internally) an `IDataTransform` as publicly an `ITransformer`/`IDataView`. (Always with the aim, of course, of having the architecture reflect the shape it presents as its public surface, but what we can refactor over some time we can at least hide now.)'"
395118902,1993,b'CreateStreamingDataView does not exist in MLContext',"b'### System information\r\n\r\n- **All**:\r\n- **All**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** Tried to access CreateStreamingDataView method\r\n- **What happened?** It does not exits in MLContext, has it moved or should i be using something else?\r\n- **What did you expect?** i expected to be able to load data using CreateStreamingDataView\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
395107830,1992,b'LightGBM Random Forest',"b""LightGBM added [random forest support](https://github.com/Microsoft/LightGBM/pull/678) in July 2017. ML.NET should expose this functionality. \r\n\r\nThis is exposed as another booster type. Currently we support { Tree Booster, Dropout Tree Booster, and Gradient-based One-Size Sampling } ([src](https://github.com/dotnet/machinelearning/blob/c5a18ef512ecf880eeba41483e4e300c9e0cf8e7/src/Microsoft.ML.LightGbm/LightGbmArguments.cs#L201-L352)) boosters of LightGBM.\r\n\r\nFor our defaults for the new booster type we could copy the test:\r\nhttps://github.com/Microsoft/LightGBM/blob/fb28070e1daa500b087d3102145ae48988030195/tests/python_package_test/test_engine.py#L53-L62\r\n\r\nI don't see that LightGBM provides a default for these parameters. So we need to provide reasonable defaults for the user; without ff/bagfrac set to <1.0, LightGBM throws an error. I think `ff=0.5` & `bagfrac=0.5` may be a bit low; perhaps 0.7? As always benchmarks on representative datasets speak louder than I.\r\n\r\nThis adds to our existing FastTree Random Forest implementation, and is another implementation that could be use for #1729. """
395075069,1991,b'Why do I need to add a property to my class to get Score?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 2.2.0\r\n\r\n### Issue\r\n\r\nIn the [GitHubLabeler sample application](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) the input data is defined like this:\r\n\r\n    internal class GitHubIssue\r\n    {\r\n        public string ID;\r\n        public string Area; // This is an issue label, for example ""area-System.Threading""\r\n        public string Title;\r\n        public string Description;\r\n    }\r\n\r\nAnd the class to get the prediction is defined like this:\r\n\r\n    internal class GitHubIssuePrediction\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public string Area;\r\n    }\r\n\r\nI think it makes sense that you need to define the prediction class yourself since I guess it could contain any kinds of properties and types.\r\n\r\nIf you have the model loaded and a model prediction function created it\xe2\x80\x99s easy to get a prediction:\r\n\r\n    GitHubIssue singleIssue = new GitHubIssue() { ID = ""Any-ID"", Title = ""Entity Framework crashes"", Description = ""When connecting to the database, EF is crashing"" };\r\n\r\n    //Predict label for single hard-coded issue\r\n    //Score\r\n    var prediction = _predFunction.Predict(singleIssue);\r\n\r\nSo far everything makes sense. But if you want to get scores of the prediction you need to change the prediction class to:\r\n\r\n    internal class GitHubIssuePrediction\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public string Area;\r\n\r\n        [ColumnName(""Score"")]\r\n        public float[] Score { get; set; }\r\n    }\r\n\r\nPersonally, I find this to be very unintuitive. Can\xe2\x80\x99t `PredictionFunction.Predict` instead return an object like this instead? \r\n\r\n    public sealed class PredictionResult<TDst>\r\n        where TDst : class, new()\r\n    {\r\n        public float[] Score { get; set; }\r\n\r\n        public TDst Prediction { get; set; }\r\n    }\r\n\r\nWhere `TDst` would be `GitHubIssuePrediction` in this specific case. Or maybe something more fancy like this:\r\n\r\n    public sealed class PredictionResult<TDst>\r\n        where TDst : class, new()\r\n        {\r\n            public float PredictionScore { get; set; }\r\n\r\n            public TDst Prediction { get; set; }\r\n\r\n            public float[] ScoresForAllCategories { get; set; }\r\n        }\r\n\r\nAs mentioned in #1881, it would be very useful to map a score to a specific category too.'"
395060167,1990,b'Vector of length 0 as missing value for vector type columns is problematic',"b'ValueMappingTransformer returns a vector of length 0 when the value it is trying to map is not in the dictionary. When data that has a missing value like this is saved as text data, then TextLoader is not able to reload this data. For example: if the mapping is\r\n""a"" -> 0,1\r\n""b"" -> 1,0\r\n""c"" -> 1,1\r\n\r\nand we apply the ValueMappingTransformer to the following data:\r\n\r\na b\r\nb c\r\nd a\r\n\r\nthe result should be:\r\n\r\na b 0 1 1 0\r\nb c 1 0 1 1\r\nd a <missing vector of length 2> 0 1\r\n\r\nbut the actual result is\r\na b 0 1 1 0\r\nb c 1 0 1 1\r\nd a 0 1\r\n\r\nwhich causes TextLoader to load the data as\r\n\r\na b 0 1 1 0\r\nb c 1 0 1 1\r\nd a 0 1 0 0\r\n\r\n'"
394779080,1987,b'Model Contain Text and numeric features 0.8 issue',"b'### System information\r\n\r\n- **OS version/distro**:W10\r\n- **.NET Version (eg., dotnet --info)**: 4.61\r\n\r\n### Issue\r\n\r\n- **What did you do?**i read training data from database then convert to to IDataView i try to learn the Model \r\nMy Model Object Contain numeric value + Text values \r\n\r\ni used 0.8 version\r\n- **What happened?** throw exception \'Column \'tagText\' has values of Textwhich is not the same as earlier observed type of R4.\'\r\n- **What did you expect?** should be worked as schema read correctly [observed type of R4. i don\'t know when this value read from]\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n`public class NormalTagsModelFeatures\r\n    {\r\n        [Column(ordinal: ""0"", name: ""Label"")] public string Label;\r\n\r\n        [Column(""1"")] public float fontSize;\r\n        [Column(""2"")] public float isBold;\r\n        [Column(""3"")] public float isItalic;\r\n        [Column(""4"")] public float isUnderLine;\r\n        [Column(""5"")] public float containsDot;\r\n        [Column(""6"")] public float containsQuestionMark;\r\n        [Column(""7"")] public string fontColor;\r\n        [Column(""8"")] public float isAllCaps;\r\n        [Column(""9"")] public string tagText;\r\n        [Column(""10"")] public string firstWord;\r\n\r\n    }`\r\n\r\n`    public class NormalTagsPrediction\r\n    {\r\n        [Column(ordinal: ""0"", name: ""PredictedLabel"")]\r\n        // public string Class;\r\n        public string Label;\r\n        public float[] Score { get; set; }\r\n    }`\r\n\r\n`public  void BuildNormalTrainEvaluateAndSaveModel()\r\n        {\r\n            //Set a random seed for repeatable/deterministic results across multiple trainings.\r\n            var mlContext = new MLContext(seed: 1);\r\n\r\n            #region ""STEP 1: Common data loading configuration""\r\n            IDataView trainingDataView = GetNormalDataSet(mlContext);\r\n            \r\n            //var env = mlContext.Data.GetEnvironment();\r\n            //IDataView trainingDataView  =mlContext.Data.ReadFromBinary(stream);\r\n            #endregion\r\n            #region ""STEP 2: Common data process configuration with pipeline data transformations""\r\n         \r\n            var dataProcessPipeline = mlContext.Transforms.Concatenate(""Features"", ""fontSize"",\r\n                                                                                       ""isBold"",\r\n                                                                                       ""isItalic"",\r\n                                                                                       ""isUnderLine"",\r\n                                                                                       ""containsDot"",\r\n                                                                                       ""containsQuestionMark"",\r\n                                                                                       ""isAllCaps"",\r\n                                                                                        //""pageNo"",\r\n                                                                                        //""tagHeight"",\r\n                                                                                        //""tagWidth"",\r\n                                                                                        //""NumericFeatures""\r\n                                                                                        //""fontColor"",\r\n                                                                                        ""tagText"",\r\n                                                                                        ""firstWord"");\r\n            var dataProcessPipeline1 = mlContext.Transforms.Text.FeaturizeText(new List<string> { ""tagText"", ""firstWord"" }, ""Features"");\r\n            \r\n\r\n            //mlContext.Transforms.CustomMapping()\r\n            #endregion\r\n            #region  ""STEP 3: Set the training algorithm, then create and config the modelBuilder""                            \r\n            var modelBuilder = new ModelBuilder<NormalTagsModelFeatures, NormalTagsPrediction>(mlContext, dataProcessPipeline);\r\n            // We apply our selected Trainer \r\n            \r\n            var trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: ""Label"", featureColumn: ""Features"");\r\n            \r\n            modelBuilder.AddTrainer(trainer);\r\n            #endregion\r\n            #region ""STEP 4: Train the model fitting to the DataSet""\r\n            //The pipeline is trained on the dataset that has been loaded and transformed.\r\n            //Console.WriteLine(""=============== Training the model ==============="");\r\n           \r\n            modelBuilder.Train(trainingDataView);\r\n            #endregion\r\n            #region ""STEP 5: Evaluate the model and show accuracy stats""\r\n            //Console.WriteLine(""===== Evaluating Model\'s accuracy with Test data ====="");\r\n            var metrics = modelBuilder.EvaluateMultiClassClassificationModel(trainingDataView, ""Label"");\r\n            Common.ConsoleHelper.PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);\r\n            #endregion\r\n            #region ""STEP 6: Save/persist the trained model to a .ZIP file\r\n            //Console.WriteLine(""=============== Saving the model to a file ==============="");\r\n            string fullFilePath = GetModelPath(""Norm"");\r\n            UpdateNormalModelPath(fullFilePath);\r\n            modelBuilder.SaveModelAsFile(fullFilePath);\r\n            #endregion\r\n        }`\r\n\r\n![image](https://user-images.githubusercontent.com/5037612/50536401-b4d0f280-0b5c-11e9-856b-3b0cafd1a9be.png)\r\n\r\n![image](https://user-images.githubusercontent.com/5037612/50536406-c3b7a500-0b5c-11e9-8c79-2902bed261a5.png)\r\n'"
394774516,1986,b'Convert CollectionDataSource  to IDataView 0.8 ',"b'### System information\r\n\r\n- **OS version/distro**: W10\r\n- **.NET Version (eg., dotnet --info)**: 4\r\n\r\n### Issue\r\n\r\n- **What did you do?** try reading training data from Microsoft SQL \r\n- **What happened?** no way to convert CollectionDataSource to IDataView\r\n- **What did you expect?** i expected a way to enable me to read data from Sql Server not only Txt or CSV FIle\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
394745106,1985,b'SymbolicStochasticGradientDescent always prints to console',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan this code:\r\n```\r\nconst string trainDataPath = @""C:\\data\\sample_train2.csv"";\r\nconst string validationDataPath = @""C:\\data\\sample_valid2.csv"";\r\nconst string testDataPath = @""C:\\data\\sample_test2.csv"";\r\n\r\nvar mlContext = new MLContext();\r\n\r\n// auto-infer text loader args\r\nvar textLoaderArgs = RecipeInference.MyAutoMlInferTextLoaderArguments(mlContext, trainDataPath, ""Label"");\r\n\r\n// load data\r\nvar textLoader = new TextLoader(mlContext,\r\n\tnew TextLoader.Arguments()\r\n\t{\r\n\t\tSeparator = "","",\r\n\t\tHasHeader = true,\r\n\t\tColumn = new[]\r\n\t\t{\r\n\t\t\tnew TextLoader.Column(""Age"", DataKind.R4, 0),\r\n\t\t\tnew TextLoader.Column(""Workclass"", DataKind.TX, 1),\r\n\t\t\tnew TextLoader.Column(""Fnlwgt"", DataKind.R4, 2),\r\n\t\t\tnew TextLoader.Column(""Education"", DataKind.TX, 3),\r\n\t\t\tnew TextLoader.Column(""EducationNum"", DataKind.R4, 4),\r\n\t\t\tnew TextLoader.Column(""MaritalStatus"", DataKind.TX, 5),\r\n\t\t\tnew TextLoader.Column(""Occupation"", DataKind.TX, 6),\r\n\t\t\tnew TextLoader.Column(""Relationship"", DataKind.TX, 7),\r\n\t\t\tnew TextLoader.Column(""Race"", DataKind.TX, 8),\r\n\t\t\tnew TextLoader.Column(""Sex"", DataKind.TX, 9),\r\n\t\t\tnew TextLoader.Column(""CapitalGain"", DataKind.R4, 10),\r\n\t\t\tnew TextLoader.Column(""CapitalLoss"", DataKind.R4, 11),\r\n\t\t\tnew TextLoader.Column(""HoursPerWeek"", DataKind.R4, 12),\r\n\t\t\tnew TextLoader.Column(""NativeCountry"", DataKind.TX, 13),\r\n\t\t\tnew TextLoader.Column(""Label"", DataKind.Bool, 14),\r\n\t\t}\r\n\t});\r\n\r\nvar trainData = textLoader.Read(trainDataPath);\r\nvar validationData = textLoader.Read(validationDataPath);\r\nvar testData = textLoader.Read(testDataPath);\r\n\r\n// preprocess\r\nvar preprocessorEstimator = mlContext.Transforms.Categorical.OneHotEncoding(""Workclass"", ""Workclass"")\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Education"", ""Education""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""MaritalStatus"", ""MaritalStatus""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Occupation"", ""Occupation""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Relationship"", ""Relationship""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Race"", ""Race""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Sex"", ""Sex""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""NativeCountry"", ""NativeCountry""))\r\n\t.Append(mlContext.Transforms.Concatenate(DefaultColumnNames.Features,\r\n\t\t""Age"", ""Workclass"", ""Fnlwgt"", ""Education"", ""EducationNum"", ""MaritalStatus"", ""Occupation"", ""Relationship"",\r\n\t\t""Race"", ""Sex"", ""CapitalGain"", ""CapitalLoss"", ""HoursPerWeek"", ""NativeCountry""));\r\n\r\n// train model\r\nvar trainer = mlContext.BinaryClassification.Trainers.SymbolicStochasticGradientDescent();\r\nvar estimatorChain = preprocessorEstimator.Append(trainer);\r\nvar model = estimatorChain.Fit(trainData);\r\n```\r\n\r\n- **What happened?**\r\n```\r\nInitial learning rate is tuned to 10.000000\r\n```\r\nwas printed to the console. Looks like SymSGD learner w/ no initialization params always prints this line?\r\n\r\n- **What did you expect?**\r\nNothing to be printed to the console'"
394743280,1984,b'LinearSupportVectorMachines trainer not working',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n**Setup code**\r\n```\r\nconst string trainDataPath = @""C:\\data\\sample_train2.csv"";\r\nconst string validationDataPath = @""C:\\data\\sample_valid2.csv"";\r\nconst string testDataPath = @""C:\\data\\sample_test2.csv"";\r\n\r\nvar mlContext = new MLContext();\r\n\r\n// auto-infer text loader args\r\nvar textLoaderArgs = RecipeInference.MyAutoMlInferTextLoaderArguments(mlContext, trainDataPath, ""Label"");\r\n\r\n// load data\r\nvar textLoader = new TextLoader(mlContext,\r\n\tnew TextLoader.Arguments()\r\n\t{\r\n\t\tSeparator = "","",\r\n\t\tHasHeader = true,\r\n\t\tColumn = new[]\r\n\t\t{\r\n\t\t\tnew TextLoader.Column(""Age"", DataKind.R4, 0),\r\n\t\t\tnew TextLoader.Column(""Workclass"", DataKind.TX, 1),\r\n\t\t\tnew TextLoader.Column(""Fnlwgt"", DataKind.R4, 2),\r\n\t\t\tnew TextLoader.Column(""Education"", DataKind.TX, 3),\r\n\t\t\tnew TextLoader.Column(""EducationNum"", DataKind.R4, 4),\r\n\t\t\tnew TextLoader.Column(""MaritalStatus"", DataKind.TX, 5),\r\n\t\t\tnew TextLoader.Column(""Occupation"", DataKind.TX, 6),\r\n\t\t\tnew TextLoader.Column(""Relationship"", DataKind.TX, 7),\r\n\t\t\tnew TextLoader.Column(""Race"", DataKind.TX, 8),\r\n\t\t\tnew TextLoader.Column(""Sex"", DataKind.TX, 9),\r\n\t\t\tnew TextLoader.Column(""CapitalGain"", DataKind.R4, 10),\r\n\t\t\tnew TextLoader.Column(""CapitalLoss"", DataKind.R4, 11),\r\n\t\t\tnew TextLoader.Column(""HoursPerWeek"", DataKind.R4, 12),\r\n\t\t\tnew TextLoader.Column(""NativeCountry"", DataKind.TX, 13),\r\n\t\t\tnew TextLoader.Column(""Label"", DataKind.Bool, 14),\r\n\t\t}\r\n\t});\r\n\r\nvar trainData = textLoader.Read(trainDataPath);\r\nvar validationData = textLoader.Read(validationDataPath);\r\nvar testData = textLoader.Read(testDataPath);\r\n\r\n// preprocess\r\nvar preprocessorEstimator = mlContext.Transforms.Categorical.OneHotEncoding(""Workclass"", ""Workclass"")\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Education"", ""Education""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""MaritalStatus"", ""MaritalStatus""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Occupation"", ""Occupation""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Relationship"", ""Relationship""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Race"", ""Race""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""Sex"", ""Sex""))\r\n\t.Append(mlContext.Transforms.Categorical.OneHotEncoding(""NativeCountry"", ""NativeCountry""))\r\n\t.Append(mlContext.Transforms.Concatenate(DefaultColumnNames.Features,\r\n\t\t""Age"", ""Workclass"", ""Fnlwgt"", ""Education"", ""EducationNum"", ""MaritalStatus"", ""Occupation"", ""Relationship"",\r\n\t\t""Race"", ""Sex"", ""CapitalGain"", ""CapitalLoss"", ""HoursPerWeek"", ""NativeCountry""));\r\n```\r\n\r\n**Code that worked**\r\n```\r\n// train model\r\nvar trainer = mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent();\r\nvar estimatorChain = preprocessorEstimator.Append(trainer);\r\nvar model = estimatorChain.Fit(trainData);\r\n```\r\n\r\n**Code that didn\'t work**\r\n```\r\n// train model\r\nvar trainer = mlContext.BinaryClassification.Trainers.LinearSupportVectorMachines();\r\nvar estimatorChain = preprocessorEstimator.Append(trainer);\r\nvar model = estimatorChain.Fit(trainData);\r\n```\r\n\r\n**Exception**\r\nSystem.InvalidOperationException: \'Weight column \'Weight\' is not found\''"
394742731,1983,b'FastTree LearningRate not settable thru arguments object',"b'### Issue\r\n\r\n- **What did you do?**\r\n```\r\n            Action<FastTreeBinaryClassificationTrainer.Arguments> argsFunc = (args) =>\r\n            {\r\n                args.LearningRates = 0.1;\r\n            };\r\n            var trainer = mlContext.BinaryClassification.Trainers.FastTree(advancedSettings: argsFunc);\r\n```\r\n- **What happened?**\r\ntrainer.Args.LearningRate = the default learning rate of 0.2\r\n\r\n- **What did you expect?**\r\ntrainer.Args.LearningRate = 0.1\r\n\r\nI think this happens because \r\n```\r\nif (Args.LearningRates != learningRate)\r\n            {\r\n                using (var ch = Host.Start($""Setting learning rate to: {learningRate} as supplied in the direct arguments.""))\r\n                    Args.LearningRates = learningRate;\r\n            }\r\n```\r\nin BoostingFastTree.cs'"
394733229,1982,b'NGramHashingTransformer cannot read old models',"b'The serialization version was recently incremented, but we should be able to load old models using SignatureLoadDataTransform.'"
394675873,1981,"b'Is ""mlContext.Transforms.Conversion.MapKeyToValue"" call supported in 0.8 version?'","b'Hello,\r\n\r\nI have installed the 0.8 version, and can see that mlContext.Transforms.Conversion.MapKeyToValue() gives me compiler error. What would be the alternative call?\r\n\r\nThank you.\r\n\r\n'"
394645400,1980,b'Missing Values (from a CSV file) and how TextLoader processes them',"b'### System information\r\n- **OS version/distro**:\r\nWindows 10 Home\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Core 2.1.5\r\nML.NET 0.8\r\n\r\n### Issue\r\nWhen I read the Titanic data set from Kaggle and TextLoader reads missing numeric values as ZEROES. \r\n\r\n- **What did you do?**\r\nI removed a data from AGE column and I tried to use context.Transforms.IndicateMissingValues and/or context.Transforms.ReplaceMissingValues in order to process the missing values but got no luck as TextLoader processes empty/missing values as ZEROES so there are no NaN values in the Data View processed by IndicateMissingValues/ReplaceMissingValues \r\n\r\n- **What happened?**\r\nData sample:\r\n\r\nPassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\r\n1,0,3,""Braund, Mr. Owen Harris"",male,,1,0,A/5 21171,7.25,,S\r\nTake a look - there is no age (it goes after ""male"") but TextLoader reads the data like that passenger\'s age == 0\r\n\r\n- **What did you expect?**\r\nI expected to see something like NaN or similar value in the data when there is an empty space in the file in the cell/position related to the related portion of the data\r\n\r\n### Source code / logs\r\nHere is how I create the TextLoader, BTW when I use AllowQuoting = false it can\'t read names even if I use Separator = "","" - it uses "" "" (the very first space in the name) as a separator\r\n            return context.Data.TextReader(new TextLoader.Arguments()\r\n            {\r\n                HasHeader = true, Separator = "","", TrimWhitespace = true, AllowSparse = false, AllowQuoting = true, \r\n                Column = [...columns array...]\r\n            });\r\nI\'d prefer to have some kind of one more settings for the TextLoader - something like NanIfEmpty (?) true/false\r\n\r\nThank you!\r\n'"
394552966,1978,b'KeyToValueMappingTransformer need to expose the key-value map',b'The key-value map is useful to some scenarios: like in multi-class it is needed to interpreting the scores for each label. '
394549347,1977,b'GetCoefficientStatistics in Microsoft.ML.Learners.LinearModelStatistics  needs to be public',"b""[GetCoefficientStatistics](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/ModelStatistics.cs#L327) in Microsoft.ML.Learners.LinearModelStatistics  needs to be publicly accessible. \r\n\r\nThe statistics calculated provide no value, if they can't be accessed. """
394518639,1976,b'EvaluatorBase and IEvaluator internalization',"b'We should consider internalizing `IEvaluator` and all implementations of it. The reason we might be able to do so is that while the code to do evaluation must exist somewhere, we are currently exposing the way we compute metrics via `MLContext`, as we see here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.Data/TrainContext.cs#L232\r\n\r\nSo it is not clear to me that `IEvaluator` needs to be part of our public API.\r\n\r\nIf this for some reason proves impractical for reasons I do not appreciate yet, we must then refactor the evaluators so that they are engineered so that they expose fewer of their guts for everyone to see. For example:\r\n\r\n`public sealed class AnomalyDetectionEvaluator : EvaluatorBase<AnomalyDetectionEvaluator.Aggregator>`\r\n\r\nThat we might have an `IEvaluator` and a convenience class is fine, but the generic parameter describes something that the user should not need to know about, e.g., how it collates and computes the metrics.'"
394509272,1974,b'Internalize signature delegates in Core and Data assemblies',"b'We have these ""signature"" delegates throughout the codebase, used for purposes of entry-points and other dependency injection style things.\r\n\r\nMany are public, as we see here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.Data/Dirty/ILoss.cs#L49\r\n\r\nYet there is no need for them to be public, and many of these have already been ""internalized,"" e.g.:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L20\r\n\r\nWe should complete this work, since we do not want these as part of the public surface of the API.'"
394505225,1973,b'TlcModule.ComponentKind and the curse of the empty interfaces',"b'Consider this attribute class:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.Core/EntryPoints/ModuleArgs.cs#L82\r\n\r\nIt *looks* harmless enough, but kind of isn\'t. It exists, as far as I can tell, to give some sort of ""name"" to various types of entry-point nodes. These mostly serve to decorate specific `IComponentFactory` subinterfaces. However, because we need to attach this attribute to a definite type, we have the following implication: that we\'ve littered our codebase with a bunch of interfaces as subinterfaces of `IComponentFactory`, and these exist only so we can attach attributes to them. To take just one example:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.Data/Utils/LossFunctions.cs#L84-L87\r\n\r\nThat\'s fairly obnoxious. From an API user\'s perspective, this represents a completely pointless complication -- all an API user really wants to do is be able to set a loss function. But because we have this other ""entry point"" thing we also have to work through this generic way to create subcomponents (this `IComponentFactory` thing, which is subideal but possibly OK), but then because we also wanted to attach an attribute to this ""type"" of set of component factories which we did through attributes on the type, which required creating this empty interface that otherwise has no reason to exist -- etc., etc. Anyway, we see that things have piled up.\r\n\r\nWhat I might like instead is the following:\r\n\r\n1. In all cases, never exposing the empty `IComponentFactory` derived empty interfaces that exist just for the sake of this attribute never be publicly accessible.\r\n\r\n2. Ideally have some alternative for entry-points that does not intersect with the public surface of the API in such a visible way. I am having difficulty with suggesting a specific course here, since I am having difficulty finding anyone that knows why this attribute was introduced in the first place, or how it is used in entry-points. (Though, it seems *to* be used.)\r\n\r\n3. Where possibly and reasonable, replace the public surface of the API of `IComponentFactory<Foo>` with ` Foo` directly. As seen above for the case of loss functions, there is no reason not to do this. Indeed, in some places we have done this, which is good:\r\n\r\n   https://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.StaticPipe/SdcaStaticExtensions.cs#L170\r\n\r\n   Yet there are too many places in the code where we have not, e.g., here:\r\n   https://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs#L42\r\n   or here:\r\n \r\n \r\n https://github.com/dotnet/machinelearning/blob/7e21afa4612ddca53bbf9d67b84df2b58d4636c2/src/Microsoft.ML.StandardLearners/Standard/SdcaBinary.cs#L1600\r\n\r\n   The reasons for this are somewhat historical, in that we had the attitude for a while that the statically typed API would be the public face, but if the dynamic API is to be the public face then it should be a little less terrible than it is now.'"
394242765,1970,b'wikipedia-detox-250-line-data.tsv: Unclosed quoted field on line 83.',b'https://github.com/dotnet/machinelearning/blob/master/test/data/wikipedia-detox-250-line-data.tsv\r\n\r\nWe can make this file beautiful and searchable if this error is corrected: Unclosed quoted field on line 83.\r\npls fixit'
394237956,1969,b'MetaMulticlassTrainer throws an exception when used in an estimator chain',"b'### Issue\r\n\r\nSetup code:\r\n```\r\n            // load data from disk\r\n            var textLoader = new TextLoader(mlContext, new TextLoader.Arguments()\r\n                {\r\n                    Separator = "","",\r\n                    HasHeader = true,\r\n                    Column = new[]\r\n                        {\r\n                            new TextLoader.Column(""Label"", DataKind.R4, 0),\r\n                            new TextLoader.Column(""Features"", DataKind.R4, 1, 784),\r\n                        }\r\n                });\r\n```\r\n\r\nCode that succeeds:\r\n```\r\n            var apTrainer = mlContext.BinaryClassification.Trainers.AveragedPerceptron();\r\n            var trainer = mlContext.MulticlassClassification.Trainers.OneVersusAll(apTrainer);\r\n            var model1 = trainer.Fit(testData);\r\n```\r\n\r\nCode for a dummy estimator chain that fails:\r\n```\r\n            IEstimator<ITransformer> pipeline = new EstimatorChain<ITransformer>();\r\n            pipeline = pipeline.Append(trainer);\r\n            var model2 = pipeline.Fit(trainData);\r\n```\r\n\r\nThis fails b/c of \r\n```\r\nLabelColumn = new SchemaShape.Column(labelColumn, SchemaShape.Column.VectorKind.Scalar, NumberType.U4, true);\r\n```\r\nin the MetaMulticlassTrainer class, which expects label column to be U4, not R4.\r\n\r\nIf I try to fix by changing the data type of Label column to U4, the code that used to succeed fails with the exception:\r\n```\r\nSystem.ArgumentOutOfRangeException: \'Training label column \'Label\' type is not valid for multi-class: U4. Type must be R4 or R8.\'\r\n```\r\nin TrainerUtils.CheckMultiClassLabel'"
394201957,1968,"b""Could not find input column 'MovieID'""","b'### System information\r\n\r\n- **OS version/distro**: Mac\r\n- **.NET Version (eg., dotnet --info)**: 2.2.100, ML 0.8.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI modified the official e2e MovieRecommender model training program to build a genres-based recommender.\r\n- **What happened?**\r\nIn step 7 Try/test a single prediction by predicting a single movie rating for a specific user, it throw an `ArgumentOutOfRangeException:  Could not find input column \'MovieId\'`\r\n\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nCodes:\r\n```\r\n//STEP 2: Create a reader by defining the schema for reading the gallery recommendation datasets\r\nvar reader = ctx.Data.TextReader(new TextLoader.Arguments\r\n{\r\n    // Separator = ""comma"",\r\n    // HasHeader = true,\r\n    Column = new[]\r\n    {\r\n        new TextLoader.Column(""UserId"", DataKind.Text, 0),\r\n        new TextLoader.Column(""MovieID"", DataKind.Text, 1),\r\n        new TextLoader.Column(""Title"", DataKind.Text, 2),\r\n        new TextLoader.Column(""Genres"", DataKind.Text, 3),\r\n        new TextLoader.Column(""Rating"", DataKind.Bool, 4)\r\n    }\r\n});\r\n\r\n......\r\n\r\n//STEP 4: Transform your data by encoding the two features userId and movieId. \r\n//        These encoded features will be provided as input to FieldAwareFactorizationMachine learner\r\nvar pipeline = ctx.Transforms.Categorical.OneHotEncoding(""UserId"", ""UserIdEncoded"")\r\n    .Append(ctx.Transforms.Categorical.OneHotEncoding(""MovieID"", ""MovieIDEncoded"")\r\n        .Append(ctx.Transforms.Text.TokenizeWords(""Genres"", ""GenresTokens"", new[] {\'|\'})\r\n            .Append(ctx.Transforms.Text.ExtractWordEmbeddings(""GenresTokens"", ""GenresEmbeddings"",\r\n                    WordEmbeddingsExtractingTransformer.PretrainedModelKind.GloVeTwitter25D)\r\n                .Append(ctx.Transforms.Concatenate(""Features"", ""UserIdEncoded"", ""MovieIDEncoded"",\r\n                    ""GenresEmbeddings""))\r\n                .Append(ctx.BinaryClassification.Trainers.FieldAwareFactorizationMachine(\r\n                    labelColumn: ""Rating"",\r\n                    featureColumns: new[]\r\n                    {\r\n                        ""Features""\r\n                    })\r\n                ))));\r\n\r\n......\r\n\r\n//STEP 7:  Try/test a single prediction by predicting a single movie rating for a specific user\r\nvar predictionengine = model.MakePredictionFunction<TrainingData, RatingPrediction>(ctx); // line 76\r\nvar movieratingprediction = predictionengine.Predict(\r\n    new TrainingData\r\n    {\r\n        //Example rating prediction for userId = 6, movieId = 10 (GoldenEye)\r\n        UserId = ""6"",\r\n        MovieId = ""17""\r\n    }\r\n);\r\n\r\n......\r\npublic class TrainingData\r\n{\r\n    public string UserId;\r\n\r\n    public string MovieId;\r\n\r\n    public string Title;\r\n\r\n    public string Genres;\r\n\r\n    public float Rating;\r\n\r\n    public string Timestamp;\r\n}\r\n```\r\n\r\nLogs:\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Could not find input column \'MovieId\'\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Runtime.Data.OneToOneTransformerBase.CheckInput(ISchema inputSchema, Int32 col, Int32& srcCol)\r\n   at Microsoft.ML.Runtime.Data.OneToOneTransformerBase.OneToOneMapperBase..ctor(IHost host, OneToOneTransformerBase parent, Schema inputSchema)\r\n   at Microsoft.ML.Transforms.Text.WordTokenizingTransformer.Mapper..ctor(WordTokenizingTransformer parent, Schema inputSchema)\r\n   at Microsoft.ML.Transforms.Text.WordTokenizingTransformer.MakeRowMapper(Schema schema)\r\n   at Microsoft.ML.Runtime.Data.RowToRowTransformerBase.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.GetRowToRowMapper(Schema inputSchema)\r\n   at Microsoft.ML.Runtime.Api.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.CreatePredictionEngine[TSrc,TDst](IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Data.PredictionFunction`2..ctor(IHostEnvironment env, ITransformer transformer)\r\n   at Microsoft.ML.Runtime.Data.PredictionFunctionExtensions.MakePredictionFunction[TSrc,TDst](ITransformer transformer, IHostEnvironment env)\r\n   at model.Program.Main(String[] args) in Program.cs:line 76\r\n```\r\n\r\nI\'ve set breakpoint on OneToOneTransformerBase line 77\r\nhttps://github.com/dotnet/machinelearning/blob/51ea627fbc618120c7d63ab984b1b13c6d80b4a0/src/Microsoft.ML.Data/Transforms/OneToOneTransformerBase.cs#L77\r\n\r\nand I got this\r\n![](https://i.imgur.com/BED6j2R.jpg)\r\n\r\nI also tried to change the order of the transforms in pipeline, for e.g. `TokenizeWords(""Genres"", balabala)` - `ExtractWordEmbeddings(""GenresTokens"", balabala)` - `OneHotEncoding(""UserId"", balabala)` - `OneHotEncoding(""MovieID"", balabala)`, it still raises the ArgumentOutOfRangeException but shows different message (in this order the message is ` Could not find input column \'Genres\'`).'"
393929556,1967,b'ML.net build failing with Visual Studio 2019  Version 16.0',"b'I just rebooted my machine. So while setting up the visual studio, I installed the latest Visual Studio 2019.\r\nThe visual studio version for this 16.0\r\n\r\nSo when I try to build the repo, I get an error as \r\n``` Error: Visual Studio 2015 or 2017 required.```\r\n\r\nMy guess is that the problem is here \r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Native/build.cmd#L48\r\n\r\nThis check fails as the value of the version is 16.0\r\n\r\nI changed this line to \r\n```if %VisualStudioVersion% geq 15.0 (```\r\n\r\nand the build works fine then.\r\n\r\nis this an appropriate fix and anything else also needs to be done here ?\r\n\r\ncc @danmosemsft @safern @eerhardt @TomFinley '"
393798905,1965,b'Remove Runtime in namespace from docs folder',b'Followup from #1697 for the documents specifically.'
393795576,1964,b'Remove `runtime` namespace from example code',"b'In #1956, we removed `runtime` from the namespaces. \r\n\r\nNow we have to update the example code.\r\n\r\nFor example, we moved:\r\n* `Microsoft.ML.Runtime.Data` to `Microsoft.ML.Data`\r\n* `Microsoft.ML.Runtime.TimeSeriesProcessing` to `using Microsoft.ML.TimeSeriesProcessing`\r\n* `Microsoft.ML.Runtime.Learners` to `Microsoft.ML.Learners`\r\n\r\ncc: @JRAlexander, @codemzs '"
393792668,1962,b'Remove unused namespaces in source files.',b''
393791680,1961,b'Sort namespaces in source files as per Microsoft .NET convention',b'Parent issue #1697 \r\n\r\nStyleCop rules:\r\n**SA1210:** Using directives must be ordered alphabetically by namespace.\r\n**SA1208:** System using directives must be placed before other using directives.\r\n'
393761428,1960,b'Make FastTree/LightGBM learned model suitable for public consumption',"b""Related to #1901. Regarding FastTree/LightGBM we may want to refine the public prediction/learned model surface a bit more.\r\n\r\nThe structures exposed here, including [`TreeEnsemble`](https://github.com/dotnet/machinelearning/blob/00577c06ff99ad07006ca8c58cf974943cb1971f/src/Microsoft.ML.FastTree/TreeEnsemble/TreeEnsemble.cs#L21) but especially [`RegressionTree`](https://github.com/dotnet/machinelearning/blob/00577c06ff99ad07006ca8c58cf974943cb1971f/src/Microsoft.ML.FastTree/TreeEnsemble/RegressionTree.cs#L22), are dual use structures in the sense that they are used for both training and prediction. This means it is irretreivably mutable (as it must be during training) even during prediction. It is polymorphic in its structure, in the sense that various structures are active and populated during training than are used during prediction -- worse, in some cases the *same* structures are used, but have distinct meanings. (E.g., the feature indices during training are distinct from those used during prediction, since if FastTree determines it can only use a subset of features, it will during training not even consider the unusable features to exist, until it is done with training and maps the structure back to the original feature space so it is usable by ML.NET.) There are other serious but (in context) comparatively minor notes, like not being either sealed or abstract, disobeying more .NET naming and implementation guidelines than I care to enumerate, etc.\r\n\r\nYet, we cannot avoid exposing *some* structure, since of course people want to inspect the trees they have learnt. And, we use this structure to represent the trained ensembles of both the FastTree and LightGBM learner, and, if we ever clean up our XGBoost wrapper so it can be open sourced (or, perhaps even, someone implements a fresh wrapper for us), maybe it will wind up using exactly that same structure. This will also serve them better since this class's structure is, for the same reasons enumerated above, incomprehensible, since about half the members on it are things people shouldn't use. (Since they are used as explained above exclusively during training.)\r\n\r\nWhat should be done instead is the following: during training there is an internal class, in fact, probably more or less the same class that exists now, with a separate *immutable* class that is exposed as the model during training, created out of instances of this class. This also implies a separate training/prediction structure of what is currently called `TreeEnsemble`, and of course the quantile trees will have to be fashioned in some way. Much of the code supporting prediction and the standard ML.NET interfaces would move into *that* set of immutable classes."""
393694338,1959,b' internal static partial class Utils is not accessible anymore from NimbusML',b'This is a breaking changes in ML.NET 0.8 or later for NimbusML\r\nPls advise\r\n\r\n'
393693702,1958,b'ArgumentAttribute is inaccessible due to its protection level from NimbusML',b'ML.Runtime.CommandLine.ArgumentAttribute is inaccessible anymore from NimbusML. \r\nPlease advise how to proceed\r\n\r\nthx'
393693371,1957,b'Contracts is internal and inaccessible from NimbusML',b'NimbusML has DotNetBridge that uses Microsoft.ML.Runtime.Contracts(..) throughout its code base. Now its not possible due to Contracts being internal. \r\nPlease advise how to proceed.'
393625373,1954,b'TextFeaturizingEstimator does not have a setting to modify ngram length',b'### Issue\r\n\r\nTextFeaturizingEstimator does not seem to have a public setting to modify the desired ngram length for extracted words / characters?\r\n\r\nSuch a setting would be really useful'
393594805,1952,b'Update/Add Documentation for Ml.Net Dependencies ',"b'Trying to use existing samples on my Mac failed because I wasn\'t aware there were pre-reqs for the samples. (Most tutorials actually say ""Prereq: None"")\r\n\r\n\r\n### System information\r\n\r\n- **OS version/distro**: Mac\r\n- **.NET Version (eg., dotnet --info)**:  Ml.Net 0.8.0\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.2.101\r\n Commit:    236713b0b7\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.14\r\n OS Platform: Darwin\r\n RID:         osx.10.14-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/2.2.101/\r\n\r\nHost (useful for support):\r\n  Version: 2.2.0\r\n  Commit:  1249f08fed\r\n\r\n.NET Core SDKs installed:\r\n  2.2.101 [/usr/local/share/dotnet/sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.2.0 [/usr/local/share/dotnet/shared/Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.2.0 [/usr/local/share/dotnet/shared/Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.2.0 [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nTried to use the example: https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow on a Mac\r\n\r\n- **What happened?** \r\nImage /Users/jakeradzikowski/dev/experiment/mlNet/GitHubExample/ImageClassification/assets/inputs/images/broccoli.jpg was not found.\r\n\r\n- **What did you expect?**\r\nThe above path does exist ... So I expected the image to be found and loaded. Does mlContext.Transforms.LoadImages work on a MacOS?\r\n\r\n### Source code / logs\r\n\r\nSee the example referenced above.'"
393277936,1950,b'LightGBM extensions are not tested',"b""Three functions listed below are not tested (VS doesn't find any references):\r\n```csharp\r\n        public static LightGbmRankingTrainer LightGbm(this RankingContext.RankingTrainers ctx,\r\n            string labelColumn = DefaultColumnNames.Label,\r\n            string featureColumn = DefaultColumnNames.Features,\r\n            string groupIdColumn = DefaultColumnNames.GroupId,\r\n            string weights = null,\r\n            int? numLeaves = null,\r\n            int? minDataPerLeaf = null,\r\n            double? learningRate = null,\r\n            int numBoostRound = LightGbmArguments.Defaults.NumBoostRound,\r\n            Action<LightGbmArguments> advancedSettings = null)\r\n```\r\n```csharp\r\n        public static LightGbmBinaryTrainer LightGbm(this BinaryClassificationContext.BinaryClassificationTrainers ctx,\r\n            string labelColumn = DefaultColumnNames.Label,\r\n            string featureColumn = DefaultColumnNames.Features,\r\n            string weights = null,\r\n            int? numLeaves = null,\r\n            int? minDataPerLeaf = null,\r\n            double? learningRate = null,\r\n            int numBoostRound = LightGbmArguments.Defaults.NumBoostRound,\r\n            Action<LightGbmArguments> advancedSettings = null\r\n```\r\n```csharp\r\n        public static LightGbmRegressorTrainer LightGbm(this RegressionContext.RegressionTrainers ctx,\r\n            string labelColumn = DefaultColumnNames.Label,\r\n            string featureColumn = DefaultColumnNames.Features,\r\n            string weights = null,\r\n            int? numLeaves = null,\r\n            int? minDataPerLeaf = null,\r\n            double? learningRate = null,\r\n            int numBoostRound = LightGbmArguments.Defaults.NumBoostRound,\r\n            Action<LightGbmArguments> advancedSettings = null\r\n```"""
393254461,1949,b'How to get ComponentCatalog from MLContext?',"b'For NimbusML we have a ""ManifestGenerator"" that creates the EntryPoint manifest.json from a given set of ML.NET assemblies.  Currently we implement this the same way it is implemented in [TestEntryPoints.cs](https://github.com/dotnet/machinelearning/blob/337cc551f1a4fb45b5efc9797803c06bd451ee29/test/Microsoft.ML.Core.Tests/UnitTests/TestEntryPoints.cs#L349), but ConsoleEnvironment has been made internal, and ML.Context doesn\'t have a ComponentCatalog.  What are ways I could get access to a ComponentCatalog and use JsonManifestUtils to build a new manifest.json?\r\n\r\n@Ivanidzo4ka @yaeldekel @ganik '"
393253748,1948,b'Public constructors for GamModelParameters',"b'Part of #1698 \r\n\r\nRight now, in `BinaryClassificationGamModelParameters` and `RegressionGamModelParameters` we have constructors that look like the following;\r\n\r\n```csharp\r\ninternal BinaryClassificationGamModelParameters(IHostEnvironment env, int inputLength, Dataset trainset,\r\n            double meanEffect, double[][] binEffects, int[] featureMap)\r\n            : base(env, LoaderSignature, inputLength, trainset, meanEffect, binEffects, featureMap) { }\r\n```\r\n\r\nWe want to make public constructors for all `ModelParameters` (previously `predictors`). However, for GAMs, this requires the user to pass in a training set, which is a `Dataset` object in `Microsoft.ML.FastTree.Internal`. This is not something we should expect the end user of the API to be aware of, so the constructor was not made public. Currently, `Dataset` is needed in `GamModelParametersBase` to map features to flocks and get bin upper bounds. We should rewrite GAMs so that this information is passed on from the Trainer rather than be computed when constructing the `GamModelParameters`.'"
393249901,1947,b'Need Example of Generating DataView and Feeding It to Static Pipeline',"b'All of example (static) pipelines start with a text file, which is not very true when deploying models to apps. We need to create examples using in-memory C# data structures.\r\n'"
393209435,1945,b'lib_lightgbm.dll is not getting loaded while running benchmarks on .NetFramework',"b""when we try to run this https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Numeric/Ranking.cs#L50\r\nand \r\nhttps://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Text/MultiClassClassification.cs#L47\r\n\r\non .netFramework, the benchmark is not able to load the lib_lightgbm.dll\r\n```\r\nUnexpected exception: Unable to load DLL 'lib_lightgbm': The specified module could not be found. (Exception from HRESULT: 0x8007007E), 'System.DllNotFoundException'\r\n```\r\n\r\nThe benchmarks run properly on .NetCore\r\n\r\n\r\ncc @danmosemsft @eerhardt @adamsitnik """
393177430,1943,"b'Should the error messages use the standart .net types, rather than the internal types?'","b'Most of our error messages related to type mismatch/schema mismatch use the internal R4, U4 types. \r\n\r\nShould those get scrubbed and substituted with the .net types before 1.0, to make them more user friendly?\r\n'"
393175239,1942,b'Reconcile the check for Probability in the BinaryClassifierEvaluator with the logic in the calibrators',"b'Fitting an IDataView that contains a score column(produced by a binary classifier scorer), currently will append a column with the name probability to the IDataView . \r\n\r\nIf one column with the name ""Probability"" exists, another one will be added. (Maybe if the user wants to try out different calibrators?). The calibrators don\'t complain about its existence. \r\n\r\nCurrently the [BinaryClassifierEvaluator](https://github.com/dotnet/machinelearning/blob/3188f1a3a176fe80902491b08024b10dd6cc2a25/src/Microsoft.ML.Data/Evaluators/BinaryClassifierEvaluator.cs#L145) checks that there are no more than one probability columns. \r\n\r\nReconcile the behavior/expectations, or is this ok, and we can leave the user cleanup if more than one Probability columns. \r\n\r\ncc @yaeldekel @TomFinley '"
392882569,1939,"b'CategoricalHashTransform breaks on OutputKind ""Key""'","b'Found in ML.NET 0.7, ML.NET 0.8\r\nThis breaks NimbusML\r\n\r\nRepro:\r\n* Copy graph and data into C;/Test\r\n* Run:\r\n            var args = new ExecuteGraphCommand.Arguments() { GraphPath = ""C:/test/graph.json"" };\r\n            var cmd = new ExecuteGraphCommand(Env, args);\r\n            cmd.Run();\r\nWill get you exception:\r\n\r\nSystem.ArgumentNullException : Value cannot be null.\r\n       Parameter name: estimator\r\n       Stack Trace:\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(581,0): at Microsoft.ML.Runtime.Contracts.CheckValue[T](T val, String paramName)\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorExtensions.cs(54,0): at Microsoft.ML.LearningPipelineExtensions.Append[TTrans](IEstimator`1 start, IEstimator`1 estimator, TransformerScope scope)\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Transforms\\OneHotHashEncoding.cs(183,0): at Microsoft.ML.Transforms.Categorical.OneHotHashEncoding..ctor(HashingEstimator hash, IEstimator`1 keyToVector, IDataView input)\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Transforms\\OneHotHashEncoding.cs(319,0): at Microsoft.ML.Transforms.Categorical.OneHotHashEncodingEstimator.Fit(IDataView input)\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Transforms\\OneHotHashEncoding.cs(176,0): at Microsoft.ML.Transforms.Categorical.OneHotHashEncoding.Create(IHostEnvironment env, Arguments args, IDataView input)\r\nC:\\sources\\machinelearning\\src\\Microsoft.ML.Transforms\\OneHotEncoding.cs(311,0): at Microsoft.ML.Transforms.Categorical.Categorical.CatTransformHash(IHostEnvironment env, Arguments input)\r\n\r\nThe problem is with:\r\n\r\ninternal OneHotHashEncoding(HashingEstimator hash, IEstimator<ITransformer> keyToVector, IDataView input)\r\n        {\r\n            var chain = hash.Append(keyToVector);\r\n            _transformer = chain.Fit(input);\r\n        }\r\n\r\nThe keyToVector is null in case OutputKind is Key.\r\n\r\n\r\n\r\n[dbg.zip](https://github.com/dotnet/machinelearning/files/2697399/dbg.zip)\r\n'"
392859677,1935,b'The demo code in ML.NET cookbook is incorrectly in the latest version v0.8.',"b""### System information\r\n\r\n- **WIN 10**:\r\n- **.NET Core V2.2**: \r\n\r\n### Issue\r\n\r\n- The demo code in ML.NET cookbook is incorrectly  in the latest version v0.8.\r\n\r\n### Source code / logs\r\n```\r\n// Create the reader: define the data columns and where to find them in the text file.\r\nvar reader = mlContext.Data.CreateTextReader(ctx => (\r\n        // A boolean column depicting the 'target label'.\r\n        IsOver50K: ctx.LoadBool(0),\r\n        // Three text columns.\r\n        Workclass: ctx.LoadText(1),\r\n        Education: ctx.LoadText(2),\r\n        MaritalStatus: ctx.LoadText(3)),\r\n    hasHeader: true);\r\n```\r\nThe `mlContext.Data.CreateTextReader` method is no longer exists in the latest version. \r\n"""
392839215,1933,b'Enable running tests against .NET Framework',"b""Right now the tests are only built and run against `netcoreapp2.1`. We want to be able to run our unit tests on .NET Framework as well, as we will support that when we release 1.0\r\n\r\n1. The build part is because of [here](https://github.com/dotnet/machinelearning/blob/master/test/Directory.Build.props#L5-L8). The tests either need to be built against `netstandard2.0` or multitargeted. Building against `netstandard2.0` (modifying the line above) fails because the tests depend on the package `xunit.runner.visualstudio 2.4.0` which it happens does not have support for `netstandard2.0`. So probably this line needs to be changed to something like `<DefaultTestTargetFramework>net461,netstandard2.0</DefaultTestTargetFramework>` (comma separated) so that it produces assets for both. Not sure which version of .NET Framework to use here. Whichever it is, the developer will need reference assemblies installed so perhaps we can pick whatever the default is for those.\r\n\r\n2. The running part I did not investigate. Maybe the above is sufficient and it's just another flag to pass to run against .NET Framework."""
392806397,1931,b'Some projects limited to .NET Core unnecessarily?',"b""As far as I know, all our projects should declare `<TargetFramework>netstandard2.0</TargetFramework>` unless they are \r\n1. exe's - these have to pick a runtime, probably `<TargetFramework>netcoreapp2.1</TargetFramework>`\r\n2. use 3.0-only features, these have `<TargetFramework>netcoreapp3.0</TargetFramework>`\r\n\r\nAre the following projects using code that will not run on .NET Framework? If not, they should target `<TargetFramework>netstandard2.0</TargetFramework>`. \r\n\r\n```xml\r\n\r\nc:\\git\\machinelearning\\src\\Microsoft.ML.HalLearners.StaticPipe\\Microsoft.ML.HalLearners.StaticPipe.csproj:\r\n    2  \r\n    3    <PropertyGroup>\r\n    4:     <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    5    </PropertyGroup>\r\n    6  \r\n\r\nc:\\git\\machinelearning\\src\\Microsoft.ML.LightGBM.StaticPipe\\Microsoft.ML.LightGBM.StaticPipe.csproj:\r\n    2  \r\n    3    <PropertyGroup>\r\n    4:     <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    5    </PropertyGroup>\r\n    6  \r\n\r\nc:\\git\\machinelearning\\src\\Microsoft.ML.OnnxTransform.StaticPipe\\Microsoft.ML.OnnxTransform.StaticPipe.csproj:\r\n    2  \r\n    3    <PropertyGroup>\r\n    4:     <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    5    </PropertyGroup>\r\n    6  \r\n\r\nc:\\git\\machinelearning\\src\\Microsoft.ML.StaticPipe\\Microsoft.ML.StaticPipe.csproj:\r\n    2  \r\n    3    <PropertyGroup>\r\n    4:     <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    5    </PropertyGroup>\r\n    6  \r\n\r\nc:\\git\\machinelearning\\src\\Microsoft.ML.TensorFlow.StaticPipe\\Microsoft.ML.TensorFlow.StaticPipe.csproj:\r\n    2  \r\n    3    <PropertyGroup>\r\n    4:     <TargetFramework>netcoreapp2.1</TargetFramework>\r\n    5    </PropertyGroup>\r\n    6  \r\n```"""
392735405,1927,"b'The BinaryLoader cursor doesn\'t always set its state to ""Done"" when it\'s done'","b'If instead of the usual while loop:\r\n\r\nwhile (cursor.MoveNext())\r\n{\r\n// do stuff\r\n}\r\n\r\nwe have this loop:\r\n\r\nwhile (cursor.State != CursorState.Done)\r\n{\r\n// do stuff\r\ncursor.MoveNext();\r\n}\r\n\r\nwe get an exception. This happens in the PerGroupTransformBase class, that uses an auxiliary cursor that moves ahead to check where the current group ends.\r\n'"
392669835,1925,b'Spurious Failures on TestPfiClusteringOnDenseFeatures test',"b""TestPfiClusteringOnDenseFeatures has, I believe introduced a week ago in PR #1832, has been responsible for some seemingly spurious test failures that are blocking builds. See, e.g., this build here from @Zruty0 for his PR #1920 , where PFI (which is totally unrelated to @Zruty0 's change) is blocking checking it in.\r\n\r\nMy best guess as to why this is happening is that for this clustering test the number of threads was not set to 1. (That obviously will cause issues, but whether it's the only issue is more than I know right now.) Sometimes you can *kinda* get away with that (e.g., sometimes results from logistic regression can resemble each other in different configuration settings since it is solving a convex problem), but this is not true of clustering. For that reason, the test `TestPfiClusteringOnDenseFeatures` has been responsible for multiple spurious test failures since its introduction last week.\r\n\r\nWe will have a PR to set the threads to 1, at least as a first try to get the situation somewhat under control. Note that this will  not be necessary in FastTree since it is engineered in such a way that it gets the same result no matter how many or few threads are used.\r\n\r\n/cc @rogancarr @shmoradims @artidoro """
392462853,1923,b'ColumnInfo associated with RoleMappedSchema should be replaced with Schema.Column',"b'We have a fun class called `RoleMappedSchema`. It operates over a class called `ColumnInfo` that looks like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/98163f9c481ceda7887c9ba6abdf74608aa4a3b9/src/Microsoft.ML.Core/Data/RoleMappedSchema.cs#L18-L22\r\n\r\nThis structure is quite useful -- oftentimes we want to have names and types and indices of columns, all bundled together. We used this hundreds of places. In fact it was so useful we decided to build something `Schema.Column` that looked a little something like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/98163f9c481ceda7887c9ba6abdf74608aa4a3b9/src/Microsoft.ML.Core/Data/Schema.cs#L86-L106\r\n\r\nClearly this new more fundamental structure and the older legacy structure have some things in common. In fact, the newer structure is what we are going with for our public API, so we should probably remove that older legacy structure.\r\n\r\nWe will shift usage of `ColumnInfo` to use `Schema.Column` instead (nullables where appropriate, where things can be null), and then remove `ColumnInfo`.'"
392421899,1921,b'Plans for EDA/Data Viz?',b'Python ML/plotting libraries provide great ways to support Exploratory Data Analysis (EDA) with some awesome charting capabilities - any plans in this area for ML.NET?'
392387962,1919,"b""We don't have backward compatibility with old models if they include normalize transform""","b""Try load old model with normalize transform. You get exception what it can't be loaded.\r\nWe broke this functionality during conversion to IEstimator."""
392349570,1916,b'Add support for signing models',"b'When a model is passed to a third party, it would be nice to have a guarantee for where the model originated, and that its parameters have not been modified. I propose adding a method for signing a model in such a way that the original developer can be identified an the contents can be shown to be unchanged.\r\n\r\nRelated to #511 '"
392348895,1915,b'Support adding metadata to models',"b'When a model is passed to a third party, information about the model, like the evaluation metrics, must be passed separately. It would be nice to have a supported way to encode metadata into models such that they can be visualized in an IDE and programatically extracted.\r\n\r\nRelated to #511 \r\nRelated to #1908 \r\nRelated to #1912 '"
392345332,1913,b'Add tooling to measure bias metrics over datasets',"b""Bias and fairness in predictions are big concerns with deploying ML models, and bias can work its way into ML models through the datasets they are trained on**. It would be helpful for modelers to have tools to assist in calculating standard metrics for bias over training data.\r\n\r\n** Bias in the training data doesn't always translate evenly to the bias and fairness of the model's predictions, so we need separate evaluation metrics of bias and fairness for the model predictions (captured in #1911).\r\n\r\nRelated to #511 \r\nRelated to #1911 \r\nRelated to #1912 """
392337848,1912,b'Add metadata of bias and fairness metrics to models',"b'Currently, we can use ML.NET to evaluate the performance of a model. However, when the model is passed to a third party, any metrics must be passed separately.\r\n\r\nIf you consider the bias and fairness metrics** to be properties of the model, then it makes sense to include them in the model. I expect this to be helpful in deployment, productionization, debugging, etc. Plus it would be nice to have properties of the model visible in an IDE and accessible programatically.\r\n\r\nRelated to #511\r\nRelated to #1911 \r\nRelated to #1908\r\n\r\n** e.g. over a dataset representative of the expected distribution of data to be seen by the model'"
392337059,1911,b'Add an evaluator for Bias and Fairness metrics',"b'We currently have model evaluators that produce metrics on the predicted label. For practical use of machine learning, it is necessary to have a sense for any biases the model may propagate and any fairness issues the mode has. In this way, it would be great to have a standard evaluators for bias and fairness metrics.\r\n\r\nRelated to #511 '"
392335902,1909,b'IStopWordsRemoverFactory returns null',"b'The implementations of CreateComponent() of the stop words removers return the IDataTransform as an IStopWordsRemoverTransform, which is null since the IDataTransform is actually a RowToRowMapperTransform.'"
392326537,1908,b'Add metadata of evaluation metrics to models',"b'Currently, we can use ML.NET to evaluate the performance of a model. However, when the model is passed to a third party, the evaluation metrics must be passed separately.\r\n\r\nIf you consider the evaluation metrics** to be properties of the model, then it makes sense to include them in the model. I expect this to be helpful in deployment, productionization, debugging, etc. Plus it would be nice to have properties of the model visible in an IDE and accessible programatically. \r\n\r\nRelated to #511 \r\n\r\n** e.g. over a dataset representative of the expected distribution of data to be seen by the model'"
392325428,1907,b'One-time prediction without PredictionFunction',"b""This question has been asked a number of times now (recently in https://stackoverflow.com/questions/53837654/ml-net-makepredictionfunction-dynamic-type )\r\n\r\nEssentially, the users will sometimes need to perform the prediction without the ability to use schema comprehension to define the input/output classes. \r\n\r\nIn the API we have `IRowToRowMapper` that is performing the work under the hood: it takes a `Row` as an input, and outputs a `Row` with predictions. However, we don't have a good 'easy' way to 'make a `Row`'. Maybe we should have something public and similar to `SimpleRow` for this purpose?\r\n\r\ncc @TomFinley @yaeldekel """
392298832,1906,b'Include confidence intervals for non-probabilistic scores',"b""For probabilistic classifiers, we get a sense for the confidence of a model's output from the probability. For other types of scorers (e.g. regression), we just get a raw score out. Oftentimes, consumers of ML models want to know how confident a model is in its prediction. Thus, it would be nice to output confidence intervals for predictions.\r\n\r\nThere are methods to generate confidence intervals for ML models, but those usually require a lot of hand tuning and a background in statistics. It would be nice to automate such techniques so that anybody could use them.\r\n\r\nRelated to #511 \r\n"""
392274894,1904,b'LDA transform ignores per-column arguments',b'The constructor that instantiates the transform from the Arguments object ignores the arguments defined per column and just uses the global values defined in the args.'
392245697,1903,b'Need a sample for multiclass classification in docs',"b""In the ML.NET docs, we have a [collection of samples](https://github.com/dotnet/machinelearning/tree/master/docs/samples/Microsoft.ML.Samples) but there are no samples for Multiclass classification. There has already been an issue (#459) where someone wanted to use a multiclass classifier to get the predictions across the top-K classes, but wasn't able to understand the APIs as is. It would be super helpful to have a simple sample for multiclass classification that prints out the results for a few examples and then discusses the overall evaluation metrics."""
391946894,1899,b'Improve discoverability of components not in the main nuget',"b""ML.NET is split into multiple nugets, mostly motivated by the dependency structure of the components: Things that have native code are not in the main nuget, neither are things that pull in other OSS packages such as LightGBM or TensorFlow.\r\n\r\nThe benefit of this approach is that it allows apps to depend on the smallest possible and most portable subset of ML.NET with ease.\r\n\r\nThe major downside is that components in this other nugets aren't easily discovered, as they will only show up on `MLContext` after they have been installed. And there is no way to discover that they could be installed from e.g. IntelliSense.\r\n\r\nLet's use this issue to discuss ideas and strategies to improve this situation."""
391930971,1895,b'MurmurHash code slower on Netcoreapp3.0',"b'MurmurHash function is slower on netcoreapp3.0 as compared netstandard. This is most probably due to codegen.\r\nThe numbers are\r\nsdk = 3.0.100-preview-009841\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.11.3, OS=Windows 10.0.17134.471 (1803/April2018Update/Redstone4)\r\nIntel Xeon CPU E5-1650 v4 3.60GHz, 1 CPU, 12 logical and 6 physical cores\r\n.NET Core SDK=3.0.100-alpha1-009630\r\n  [Host]     : .NET Core 3.0.0-preview1-26928-03 (CoreCLR 4.6.26927.03, CoreFX 4.6.26927.03), 64bit RyuJIT\r\n  Job-GLYGMU : .NET Core 3.0.0-preview1-26928-03 (CoreCLR 4.6.26927.03, CoreFX 4.6.26927.03), 64bit RyuJIT\r\n\r\nBuildConfiguration=Release-Intrinsics  Toolchain=netcoreapp3.0  MaxIterationCount=20  \r\nWarmupCount=1  \r\n\r\n```\r\n|              Method |     Mean |    Error |   StdDev | Extra Metric |\r\n|-------------------- |---------:|---------:|---------:|-------------:|\r\n| MurmurHashBenchmark | 231.0 ns | 4.122 ns | 3.654 ns |            - |\r\n\r\n\r\n\r\n``` ini\r\n sdk version 2.1.401\r\n\r\n```\r\n|              Method |     Mean |     Error |    StdDev | Extra Metric |\r\n|-------------------- |---------:|----------:|----------:|-------------:|\r\n| MurmurHashBenchmark | 197.8 ns | 0.9518 ns | 0.8438 ns |            - |\r\n\r\n\r\nthe associated code is \r\n```C#\r\nchar[] input2;\r\nuint arg;\r\n\r\n[GlobalSetup(Target = nameof(MurmurHashBenchmark))]\r\npublic void setup2()\r\n{\r\n    int min = 0;\r\n    int max = 100;\r\n    Random randNum = new Random();\r\n    arg = (uint)randNum.Next(min, max);\r\n\r\n    input2 = new char[max];\r\n\r\n    for (int i = 0; i < input2.Length; i++)\r\n    {\r\n        input2[i] = (char)randNum.Next(min, 128);\r\n    }\r\n\r\n}\r\n\r\n[Benchmark]\r\npublic void MurmurHashBenchmark()\r\n{\r\n    ReadOnlySpan<char> _t = input2.AsSpan();\r\n    MurmurHash(arg, _t);\r\n}\r\n\r\npublic void MurmurHash(uint hash, ReadOnlySpan<char> span)\r\n{\r\n    ulong cur = 0;\r\n    int bits = 0;\r\n    for (int ich = 0; ich < span.Length; ich++)\r\n    {\r\n        uint ch = span[ich];\r\n        cur |= ch << bits;\r\n        bits += 8;\r\n\r\n        if (bits >= 32)\r\n        {\r\n            hash = MurmurRound(hash, (uint)cur);\r\n            cur = cur >> 32;\r\n            bits -= 32;\r\n        }\r\n    }\r\n}\r\n\r\npublic static uint MurmurRound(uint hash, uint chunk)\r\n{\r\n    chunk *= 0xCC9E2D51;\r\n    chunk = Rotate(chunk, 15);\r\n    chunk *= 0x1B873593;\r\n\r\n    hash ^= chunk;\r\n    hash = Rotate(hash, 13);\r\n    hash *= 5;\r\n    hash += 0xE6546B64;\r\n\r\n    return hash;\r\n}\r\n\r\nprivate static uint Rotate(uint x, int r)\r\n{\r\n    return (x << r) | (x >> (32 - r));\r\n}\r\n\r\n```\r\n@danmosemsft do I need to shorten the code more in order to open the codegen issue in coreclr ?\r\n\r\ncc @danmosemsft @tannergooding @eerhardt '"
391890300,1891,b'Hash join fails with bad image exception.',"b'Add this test:\r\n```\r\n        [Fact]\r\n        public void EntryPointHashJoinCountTable()\r\n        {\r\n            TestEntryPointPipelineRoutine(GetDataPath(""breast-cancer.txt""), ""col=Text:TX:1-9 col=Label:0"",\r\n                new[]\r\n                {\r\n                    ""Transforms.HashConverter"",\r\n                },\r\n                new[]\r\n                {\r\n                    @""\'Column\': [\r\n                      {\r\n                        \'Name\': \'Temp\',\r\n                        \'Src\': \'Text\',\r\n                        \'CustomSlotMap\': \'0,1;2,3,4,5\'\r\n                      }\r\n                      ]"",\r\n                });\r\n        }\r\n```\r\nyou get following exception.\r\n```\r\nMessage: System.InvalidOperationException : Splitter/consolidator worker encountered exception while consuming source data---- \r\nSystem.BadImageFormatException : An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)\r\n```'"
391804837,1890,b'ONNX Exporter Needs Examples',"b""As title. We currently don't have a user-facing example."""
391422629,1886,b'ML.NET and Unity',"b'### System information\r\n\r\n- **win 10**:\r\n- **.NET Version (  .NET Global Assembly Cache Utility. Version 4.0.30319.0)**: \r\n\r\n### Issue\r\nUnity editor reports two errors:\r\n1.Assembly \'Library/ScriptAssemblies/Assembly-CSharp.dll\' will not be loaded due to errors:\r\nReference has errors \'MLAICore\'.\r\n2.Assembly \'Assets/Plugins/MLAICore.dll\' will not be loaded due to errors:\r\nUnable to resolve reference \'Microsoft.ML.Data\'. Is the assembly missing or incompatible with the current platform?\r\n\r\n- **What did you do?**\r\nI have made an API that loads model.zip file and predicts a nr given some input values(It is almost exactly as your taxi fare example). Through commenting out lines and rebuilding my api I deduced that  if I put this code: MLContext ml = new MLContext(seed: 0); into any of my api methods I get this error when importing the api into unity.\r\n- **What happened?**\r\n It all works great but when I import this api into Unity, the unity editor returns an error.\r\n- **What did you expect?**\r\nSince unity has now support for .net 2.0 apis and frameworks 4+ I was hoping ML.Net would work in that environment. Any sugestions would be most welcom.\r\n[sampleUnityProject.zip](https://github.com/dotnet/machinelearning/files/2683139/sampleUnityProject.zip)\r\n[exampleDotnetApiProject.zip](https://github.com/dotnet/machinelearning/files/2683142/exampleDotnetApiProject.zip)\r\n[https://stackoverflow.com/questions/53781312/ml-net-in-unity/53781387#comment94434358_53781312](url)\r\n\r\n\r\n### Source code / logs\r\n`using System;\r\nusing Microsoft.ML;\r\nnamespace MLAICore\r\n{\r\n    public class Class1\r\n    {\r\n        public static string SayHello()\r\n        {\r\n            MLContext ml = new MLContext(seed: 0);//if I comment out this line code compiles in unity\r\n            return ""hello from core ML"";                    //and i get this response, if I live it as is =>err\r\n        }\r\n    }\r\n}`\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
391215774,1882,b'Regression due to removal of autoCache',b'The Auto-cache was removed in https://github.com/dotnet/machinelearning/commit/435a63b9db7464ec0400eb4be8ecc362f0d33dcc\r\n\r\nI added new benchmark https://github.com/dotnet/machinelearning/pull/1855\r\nBefore the change the time taken by this benchmark was 2.8sec (after converting to api version and making label as key instead of R4)\r\n\r\nAfter the removal of the cache The time went upto 10s. But after the adding the cache check point me and @wschin was able to reduce it to 3.8s which is still regressed from 2.8s.\r\n\r\n'
391186727,1881,b'Multi classification - Probability',"b'Hello,\r\nI have an application that use using ml.net multiclassification trainer to predict a category. However, it seems as though we remove the TryGetScoreLabelNames() method from the library. Basically, the application would like to output as well how confident (in percentage) is the predicted label. How can I achieve that in ML.NET 0.8?'"
391124866,1880,b'GPU-powered KNN',"b""I'm aware that there is an issue already #1712, I'm just looking for guidance. I've migrated the dlib based face recognition to a c# project using DlibDotNet project. The final missing piece is a fast way of processing 1000s of candidates for a closest match.\r\n\r\nCan anyone point me in the right direction?"""
390904625,1874,b'Our binary learners estimators work only on top of boolean label',b'https://github.com/dotnet/machinelearning/blob/dfe9f3ad36cf382516276ad902a5f89a5f21c7e7/test/Microsoft.ML.Benchmarks/KMeansAndLogisticRegressionBench.cs\r\nFail currently because R4 is not supported.'
390543168,1871,b'Follow up on Calibrator estimators',"b'There are a few follow ups to the work to create calibrator estimators:\r\n\r\n1- The public classes in Microsoft.ML.Core/Prediction/Calibrator.cs need to have descriptive XML documentation. \r\n2- The Calibrators need to be added as property to the BinaryClassificationContext\r\n3- Some of the Calibrators have a public constructor, that allows initializing the parameters. Does  it make sense to expose and  wire those parameters to the CalibratorEstimators, and set them from there? \r\nSo they will all look like [FixedPalttCalibratorEstimator](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Prediction/CalibratorCatalog.cs#L319)\r\n\r\ncc @Zruty0 '"
390038519,1867,b'Remove IRowCursorConsolidator',"b""Consider this method:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/9067a1be58434999e37db7504d6b4e06eca8bbf4/src/Microsoft.ML.Core/Data/IDataView.cs#L114-L115\r\n\r\nThis returns an instance of the mysterious `IRowCursorConsolidator` interface. Why an interface? In retrospect I'm not quite sure.\r\n\r\nHaving an interface allows for different implementations, but we've never actually really exploited that capability. Nor, even if we were of such a mind to do so, would it be clear how we could. What would they even do differently? The semantics around `Batch` and whatnot are sufficiently clear and simple as to make only one implementation obvious, and even if we did have different implementations since the resulting cursors result most often from transformers (that is, components downstream from the set creation), they couldn't really do anything radically different anyway, since to do anything implementation specific on any cursor would be to break the composability at the core of what makes `IDataView` work at all.\r\n\r\nSo: get rid of this interface, and replace all usage of it with a simple utility method *somewhere* that can be called to do the reconciliation. It needn't even be a public utility method, but there may be reasons to do so."""
390016903,1866,b'Public Constructors for ModelParameters',"b'During the course of fixing #1698 and deriving work items (e.g. #1699, #1701, #1702), we created public constructors for the various `ModelParameter` objects (formerly `Predictor` objects).\r\n\r\n@sfilipi raised the question whether these should be public or be made internal as the only thing that can create `ModelParameters` (`Predictors`) is training a model. What use case are we supporting with this? When might a user want to create say a `LinearRegressionModelParameters` object with bias and weights instead of training a linear regression model?'"
389936673,1860,b'Extract IDataView into its own assembly and NuGet package',"b'IDataView is a very flexible, efficient way of describing tabular data (columns and rows) in a read-only manner.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewDesignPrinciples.md\r\n\r\nAt its heart are 2 key concepts:\r\n- Schema (describing the columns)\r\n- Cursoring (how to read the rows of data)\r\n\r\nIt has other capabilities that I won\xe2\x80\x99t enumerate here, the above link describes them in more detail.\r\n\r\nIDataView is very useful as an abstraction for tabular data that will allow users to pass data between two independent libraries.\r\n\r\nFor example, ML.NET is able to both consume and produce IDataView instances. Say there was a .NET library for Apache Arrow. If the Arrow .NET data type implements IDataView, the Apache Arrow data can be passed directly into ML.NET without having to copy it into a format that ML.NET consumes.\r\n\r\nAnother example is: say we had a visualization/graphing/plotting library in .NET that could consume data using IDataView. Then we could take data that was produced by ML.NET, or Apache Arrow, and feed it directly into the graphing library. There would be no need to copy, or change the shape of the data at all. And there is no need for this graphing library to know anything about ML.NET or Apache Arrow.\r\n\r\nIn my mind, we can use IDataView in a similar manner to what [OData](https://www.odata.org/) was promised to be: An exchange format which allows producers and consumers of data to communicate in a standardized way. (Although, OData has more capabilities such as filtering, sorting, updating data, etc which I am not proposing we add to IDataView. I was just using it as an analogy.)\r\n\r\n/cc @TomFinley @Zruty0 @markusweimer @danmosemsft @stephentoub '"
389546906,1857,b'Schema Equtable',"b'Sometime, we have code like\r\n```csharp\r\n            public Cursor(IChannelProvider provider, RowToRowScorerBase parent, RowCursor input, bool[] active, Func<int, bool> predicateMapper)\r\n                : base(provider, input)\r\n            {\r\n                Ch.AssertValue(parent);\r\n                Ch.AssertValue(active);\r\n                Ch.AssertValue(predicateMapper);\r\n\r\n                _bindings = parent.GetBindings();\r\n                Schema = parent.OutputSchema;\r\n                Ch.Assert(active.Length == _bindings.ColumnCount);\r\n                _active = active;\r\n\r\n                _output = _bindings.RowMapper.GetRow(input, predicateMapper);\r\n                try\r\n                {\r\n                    Ch.Assert(_output.Schema == _bindings.RowMapper.OutputSchema);\r\n                    _getters = parent.GetGetters(_output, iinfo => active[_bindings.MapIinfoToCol(iinfo)]);\r\n                }\r\n                catch (Exception)\r\n                {\r\n                    _output.Dispose();\r\n                    throw;\r\n                }\r\n            }\r\n```\r\nwhere the equivalence between two `Schema` objects is enforced by using things like\r\n```\r\n_output.Schema == _bindings.RowMapper.OutputSchema\r\n```\r\n. This implies that we need to implement proper comparison function for `Schema`.\r\n'"
389517133,1854,b'ColumnAttribute and TextLoader.Column and TextLoader.Arguments has header property',"b'From @PeterPann23:\r\n\r\n""To me, this seems to all address the same problem on several different steps of designing the data, perhaps make ordinal an integer and not a string and define the data kind all on-top of the class and have the text loader override it when needed if needed. Most likely one would create a model class as in MVC that consumes a given ""view"" on the world. Perhaps my MVC experience has made me bias but this in my opinion overly complicated as is.""\r\n\r\nFixes https://github.com/dotnet/docs/issues/9470\r\n\r\nOpened an issue for this  as it\'s product feedback, and not a docs issue. '"
388843490,1853,b'Add components to EntryPoint catalog that are missing.',"b'There are several new components in ML.NET that were not added to the EntryPoint catalog:\r\n\r\n- MatrixFactorizationTrainer\r\n- PermutationFeatureImportance\r\n- GeneralizedAdditiveModels\r\n- SsaSpikeDetector\r\n- SsaChangePointDetector\r\n- IidSpikeDetector\r\n- IidChangePointDetector\r\n\r\n\r\nTo add these to the EntryPoint catalog, simply:\r\n\r\n1. Add the `SignatureEntryPointModule` signature to the `LoadableClass` assembly attribute.\r\n2. Create a public static method, that: \r\n    1. Takes as input, among others, an object representing the arguments of the component you want to expose. \r\n    2. Initializes and run the components, returning one of the nested classes of `Microsoft.ML.Runtime.EntryPoints.CommonOutputs`\r\n    3. Is annotated with the `TlcModule.EntryPoint` attribute'"
388832123,1852,b'No way to set the log verbosity in the MLContext',b'There is currently ways to set a Logging verbosity in the MLContex. \r\nThe users need to be able to tweak logging verbosity. \r\n'
388820432,1851,"b""Native assemblies from NuGet aren't copied correctly for packages.config""","b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: .NET Framework 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate an ""old style"" .csproj using packages.config and added Microsoft.ML nuget package and built.\r\n\r\nWhen creating the project, if you uncheck the ""Create directory for solution"" checkbox, then the .sln and .csproj are in the same folder. When you restore NuGet packages, the nuget files get put in a `packages` folder in the same folder as the .csproj.\r\n\r\n- **What happened?**\r\nThe native assemblies (CpuMathNative, FastTreeNative, LdaNative, etc) were all copied into subdirectories of my output path instead of directly in my output path.\r\n\r\nFrom looking at a binlog of the build, it appears that the `AssignTargetPath` is getting confused at our `Content` items since they appear to be part of the project (since they are under the same folder as the .csproj).\r\n\r\n- **What did you expect?**\r\nThe native assemblies should be copied directly to the output folder.\r\n\r\n### Note\r\n\r\nTo fix this, we should put the `<Link>` metadata on our content items:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/14c7a472579afa3ce98bad2e3495e4c0524471b9/pkg/common/CommonPackage.props#L10-L20\r\n\r\nSee\r\n* https://github.com/dotnet/roslyn/issues/15137#issuecomment-260470890\r\n* https://github.com/Microsoft/onnxruntime/pull/127#discussion_r239845745\r\n\r\nFor other places that had this same bug.\r\n'"
388786512,1850,b'OLS FeatureWeights are not the model weights',"b'For the `LinearPredictor`, the `GetFeatureWeights` returns the model weights, as expected:\r\n\r\n```\r\npublic virtual void GetFeatureWeights(ref VBuffer<Float> weights)\r\n{\r\n    Weight.CopyTo(ref weights);\r\n}\r\n```\r\n\r\nThe `OlsLinearRegressionPredictor` has the same method, but it does not return the model weights. It returns the [`-log(p-value)` for each feature](https://github.com/dotnet/machinelearning/blob/14c7a472579afa3ce98bad2e3495e4c0524471b9/src/Microsoft.ML.HalLearners/OlsLinearRegression.cs#L782). This is weird because it overrides the `LinearRegressionPredictor`\'s GetFeatureWeights method but returns a different kind of value, essentially the magnitudes of the p-values.\r\n\r\nNow, this goes back to the meaning of `feature weight`. Many predictors that are not linear models implement `GetFeatureWeight`, and it looks like it\'s a measure of importance. What\'s the right thing here? Do we want to return a measure of relative importance or do we want to return the model weights?\r\n\r\nCurrently, I find this API to be super confusing because there is no docstring to explain what you are getting back, and I would expect the ""Feature Weights"" of a linear model to the model weight parameters.\r\n\r\nAlso, this is a nit, but if we really want to return the magnitude of the p-values, doesn\'t `-log10(p-value)` make more sense? The base e log puts these onto a weird scale.'"
388365719,1843,b'Schema.Metadata needs a better name',"b'""Metadata"" is perhaps not the best name for what we currently call metadata.\r\n\r\nFirst, what is it: what we call Metadata is meant to suggest not just any metadata, but that data that we consider auxiliary, or at *most* ancillary. (So for example, slot names are in metadata, because not everything will have names for each slot. But sometimes they will, and we need a place to keep that.)\r\n\r\nThe trouble with the name ""metadata"" is that it means literally everything but the data. But this is inaccurate: there are lots of things that are data about the data (e.g., the types, the vector sizes, the names of columns) that we definitely do not want to keep in the metadata structure (since they\'re absolutely required information), but that is ""metadata"" in the strict linguistic sense of the word.\r\n\r\nThe only name suggested as an alternative that I am aware of is ""annotations."" I am fine with the name annotations. Perhaps we could come up with a better name. I\'ll leave this open for a bit, and unless people object we can rename metadata annotations.'"
388364996,1841,b'DNNImageModels are downloaded on all machines during official builds',"b'The models only need to be downloaded on one machine during official builds, not all of them.\r\n'"
388362048,1840,b'Add confidence intervals to permutation feature importance',"b'`Permutation Feature Importance` (aka `PFI`) computes the importance of a feature to a model by permuting values for that feature, scoring it with the model, and comparing the new evaluation metrics to the original evaluation metrics. For speed, `PFI` uses only one permutation, and this leads to a bit of randomness in the predicted importances. For example, based on the random seed features can change orderings of importance and permutations can even end up showing to improve the model performance. These issues can be fixed by allowing the calculation of confidence intervals around the feature importance values.'"
388338539,1839,b'FastTree cannot solve a simple toy problem when using feature arrays',"b'I\'m having a hard time understanding the API for doing basic machine learning. In our application, our feature vectors come in as basic arrays of floating point values. I create a simple toy problem to try to understand how the API works (using the samples as a guide) which uses the `FastTree` binary classifier. The training data is just 2 vectors <0, 0>:0, <1, 1>:1, which should be easily be able to fit a model to. However, when I run the evaluation I get 50% accuracy. Here is my sample code:\r\n\r\n```\r\n class Program\r\n    {\r\n        public class FeatureData\r\n        {\r\n            [ColumnName(""Label"")]\r\n            public bool Label { get; set; }\r\n\r\n            [ColumnName(""Features"")]\r\n            public float[] Features { get; set; }\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n\r\n            var featuresTrainingData = new List<FeatureData>()\r\n            {\r\n                new FeatureData() { Features = new float[]{0.0f, 0.0f}, Label = false},\r\n                new FeatureData() { Features = new float[]{1.0f, 1.0f}, Label = true}\r\n            };\r\n\r\n            var schemaDef = SchemaDefinition.Create(typeof(FeatureData));\r\n            schemaDef[""Features""].ColumnType = new VectorType(NumberType.R4, 2);\r\n\r\n            var dataView = mlContext.CreateDataView(featuresTrainingData, schemaDef);\r\n\r\n            //Train the model\r\n            var pipeline = mlContext.BinaryClassification.Trainers.FastTree(featureColumn:""Features"", labelColumn:""Label"");\r\n            var model = pipeline.Fit(dataView);\r\n\r\n            //Evaluate\r\n            var predictions = model.Transform(dataView);\r\n            var metrics = mlContext.BinaryClassification.Evaluate(predictions, ""Label"");\r\n\r\n            Console.WriteLine();\r\n            Console.WriteLine(""Model quality metrics evaluation"");\r\n            Console.WriteLine(""--------------------------------"");\r\n            Console.WriteLine($""Accuracy: {metrics.Accuracy:P2}"");\r\n            Console.WriteLine($""Auc: {metrics.Auc:P2}"");\r\n            Console.WriteLine($""F1Score: {metrics.F1Score:P2}"");\r\n            Console.WriteLine(""=============== End of model evaluation ==============="");\r\n\r\n        }\r\n    }\r\n```\r\n\r\nWhat am I doing wrong here?\r\n\r\nThank you!'"
388020090,1834,"b'OnnxTransform -- upgrade to support Linux, Mac and CUDA GPU'",b'Add support for Linux X64\r\nAdd support for Mac X64\r\nAdd support for CUDA GPU for Windows and Linux (no Mac yet)'
387971885,1831,b' Deprecate documentation topics migrated to docs.microsoft.com',b'The ML.NET Cookbook and ML.NET High-Level Concepts documents have been migrated to docs.microsoft.com as agreed upon. The current documents need to be updated to point to the migrated ones.\r\n'
387560427,1827,b'The trainer API for MLContext is inconsistent for learner in external nugets',"b'APIs are discoverable via the MLContext. There are some learners that are declared on the MLContext where other learners define an MLContext extension in cases where the learner is in a separate nuget package. \r\n\r\nThis results inconsistent API calls when accessing APIs, for example BinaryClassification vs Recommendation():\r\n```\r\nvar foo_bar = mlContext.BinaryClassification.Trainers;\r\nvar foo_moo_bar = mlContext.Recommendation().Trainers;\r\n```\r\n\r\nThe API discover ability should be consistent and work across nuget pakages.\r\nOriginal issue: #1806 \r\n\r\nThis issue may be the solution #1319 as it creates extensions for the trainers. '"
387557320,1826,b'MatrixFactorization construction parameters are not consistent with other learners',"b'The ordering of parameters for the Matrix Factorization constructor is inconsistent with other trainers, specifically the Label column should be first before the matrixColumnIndex and matrixRowIndex as the matrixColumnIndex and matrixRowIndex are the feature columns:\r\n\r\n```csharp\r\n        /// <summary>\r\n        /// Initializing a new instance of <see cref=""MatrixFactorizationTrainer""/>.\r\n        /// </summary>\r\n        /// <param name=""env"">The private instance of <see cref=""IHostEnvironment""/>.</param>\r\n        /// <param name=""matrixColumnIndexColumnName"">The name of the column hosting the matrix\'s column IDs.</param>\r\n        /// <param name=""matrixRowIndexColumnName"">The name of the column hosting the matrix\'s row IDs.</param>\r\n        /// <param name=""labelColumn"">The name of the label column.</param>\r\n        /// <param name=""advancedSettings"">A delegate to apply all the advanced arguments to the algorithm.</param>\r\n        public MatrixFactorizationTrainer(IHostEnvironment env,\r\n            string matrixColumnIndexColumnName,\r\n            string matrixRowIndexColumnName,\r\n            string labelColumn = DefaultColumnNames.Label,\r\n            Action<Arguments> advancedSettings = null)\r\n            : base(env, LoadNameValue)\r\n```\r\n\r\nWhere other trainers have the label column argument followed by feature column:\r\n```csharp\r\n public static SdcaBinaryTrainer StochasticDualCoordinateAscent(\r\n                this BinaryClassificationContext.BinaryClassificationTrainers ctx,\r\n                string labelColumn = DefaultColumnNames.Label,\r\n                string featureColumn = DefaultColumnNames.Features,\r\n                string weights = null,\r\n...)\r\n```'"
387550458,1825,b'RffWorkout test is not stable and randomy fails during the build.',b'As title. I failed multiple times for some unknown reasons. It needs to be improved for a more smooth merging process.'
387547559,1824,b'Make Row Disposable',"b'We have previously used what was `IRow`, and now `Row`, for two purposes:\r\n\r\n1. It was a ""restricted"" row cursor that allowed inspection but not movement. Nearly all of our transforms perform their data transformations through this mechanism, which is fine.\r\n\r\n2. It was a convenient way to store what amounted to a property bag that had the benefit of using the `IDataView` type system and familiar APIs.\r\n\r\nThe trouble was, that for scenario 2 it would have been incredibly awkward to have `IRow` be disposable. But for scenario 1 we absolutely required it. So we did awkward things like this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/521acad830408b43175821575f5f774629aeafe7/src/Microsoft.ML.Core/Data/ISchemaBindableMapper.cs#L116\r\n\r\n""Here\'s a `Row`, and by the way, when you\'re done, if this thing is non-null, you should treat it as disposable."" Kind of silly. But this was able to be done, because these `Row` objects were ""driving"" `RowCursor` implementations, and those were disposable, so we were able to hide this complexity from people. But, since `Row` must be a public type in our API (just as `RowCursor` must be), we must change it.\r\n\r\nWe have now actually resolved scenario 2 by inventing a new type of container, called `Metadata`, that operates *kind of* like a `Row`, but isn\'t quite one. And this leaves us free now, I think, to make `Row` disposable.\r\n\r\n* Anything that is still a `Row` that should become a `Metadata` should start being a `Metadata`. (This includes anything that currently yields `Row`s that are understood by convention to be immovable and where all columns are active... that is, simple property bags.)\r\n\r\n* Much of the disposer logic currently on `RowCursor` can be moved to `Row`.\r\n\r\n* Implement [dispose pattern](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern) on `Row`.\r\n\r\nThis issue is an explication of a minor subpoint of #1532 .'"
387533990,1823,b'Cannot use ML.NET in a Windows nano container',"b""### System information\r\n\r\nBase image: microsoft/dotnet:2.1-aspnetcore-runtime-nanoserver-1803\r\n\r\nMicrosoft Windows [Version 10.0.17134.345]\r\n(c) 2018 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\app>dotnet --info\r\n\r\nHost (useful for support):\r\n  Version: 2.1.5\r\n  Commit:  290303f510\r\n\r\n.NET Core SDKs installed:\r\n  No SDKs were found.\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n### Issue\r\nRepro: Install the Visual Studio Service Fabric Mesh tools from https://blogs.msdn.microsoft.com/azureservicefabric/2018/12/04/service-fabric-mesh-preview-refresh-release/ then follow the tutorial at https://docs.microsoft.com/en-us/azure/service-fabric-mesh/service-fabric-mesh-tutorial-create-dotnetcore and install the ML.NET package to try training an ML model.\r\n\r\nWhen the web project starts, a System.InvalidOperationException is thrown.\r\nInner Exception\r\nDllNotFoundException: Unable to load DLL 'CpuMathNative' or one of its dependencies: The specified module could not be found.\r\n"""
387452308,1820,b'ImagePixelExtractorTransform only supports images with pixel format Format32bppArgb',b'We also need support for Format24bppRgb.\r\n'
387354345,1819,"b'CreatePredictionEngine<TSrc, TDst> is internal now. What is replacement?'","b""The CreatePredictionEngine method is internal now. What is replacement for trainedModel (ITransfomer) and scheme (SchemaDefinition)? MakePredictionFunction can't use SchemaDefinition and makes exception for me.\r\n\r\n"""
387293032,1818,"b'Can I use TimeSeries prediction with Vec<R4, N> input data?'","b'Is it possible in the future?\r\nNow it makes an exception ""The feature column has  type \'Vec<R4, 3>\', but must be a float.""'"
387011404,1809,b'MissingValueDroppingTransformer has a bug',"b""When it is getting the getter of the source column, it tries to use 'iinfo' instead of '_srcCols[iinfo]'."""
386999804,1807,b'Incorrect link in PFI sample',b'The correct link in here:\r\nhttps://github.com/dotnet/machinelearning/blob/be115f416a77f88f56f6d3abe0931ca1f74ef40b/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs#L43\r\n\r\nis:\r\n\r\n~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/PermutationFeatureImportance.cs'
386637374,1806,b'Usage of Matrix Factorization Trainer for Recommendation ',"b'When using Matrix Factorization Trainer:\r\n\r\n ```csharp\r\nvar trainer = mlcontext.Recommendation().Trainers.MatrixFactorization\r\n                                                     (""userIdEncoded"", ""movieIdEncoded"", ""rating""));\r\n```\r\nWhen using other trainers:\r\n\r\n ```csharp\r\nvar trainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent\r\n                                                       (label: ""Label"", features: ""Features"");\r\n``` \r\n\r\nIs the difference in usage prop vs. method by design? Also there is a difference in the order of parameters being passed. First parameter is Label vs. Features being used. \r\n'"
386489059,1803,b'Bug in ApplyInto() method',"b'When the result of applying the function is dense, indices might be null, but this is not checked.'"
386487666,1802,b'SSE bug when scaling a vector by a negative number',"b'When the number of elements is not divisible by 4, the sign of the result sometimes wrong.\r\nHere is an explanation from @eerhardt .\r\n\r\nWe are \xe2\x80\x9cdouble computing\xe2\x80\x9d at the end of the vector when there are remaining elements (1, 2, or 3 hanging elements). We then mask out the \xe2\x80\x9cdouble computed\xe2\x80\x9d elements in temp (which should have all 0s for the \xe2\x80\x98double computed\xe2\x80\x99 elements).\r\n\r\nHowever, when doing `temp = _mm_mul_ps(temp, x1);`, since \xe2\x80\x98x1\xe2\x80\x99 is negative, multiplying the 0s in temp against a negative number is turning them into -0 (negative zero).\r\n\r\nWe then `_mm_or_ps(temp, result);` which then switches the sign of the \xe2\x80\x98double computed\xe2\x80\x99 elements \xe2\x80\x93 which is incorrect.\r\n\r\nSo that\xe2\x80\x99s why some of the elements are getting the wrong sign. Because we are OR\xe2\x80\x99ing them with negative zero, which changes the sign.\r\n\r\n'"
386443439,1800,b'Simpler Scenario Focused (getting started API) for ML.NET',"b'ML.NET is a machine learning framework focused on bringing .NET developers to the world of machine learning. Given the complexity of machine learning there are a number of concepts for developers to get familiar with before becoming successful right from the get-go.  \r\n\r\nIs there a way to provide a more templated/recipe-driven scenario focused set of API which represent common machine learning task for developers like Recommendation, Sentiment Analysis, Forecasting, Image Classification etc. This can help them get started quickly and progressively graduate to machine learning using the Dynamic API guarenting both short-term and long term success with ML. \r\n\r\ne.g. (Recommendation: Just a quick ugly mockup)\r\n\r\nCurrently for the recommendation scenario for Matrix Factorization the input feature are limited to UserId, OrderId, Rating or for co-purchase scenarios limited to UserId, OrderId. Given the nature of these features the transforms (categorical) and trainers (Matrix Factorization/One Class Matrix Factorization) are somewhat pre-known. \r\n\r\nIs it potentially possible to simplify the API to as follows:\r\n\r\n            //STEP 1: Create MLContext to be shared across the model creation workflow objects \r\n            var mlcontext = new MLContext();\r\n\r\n            //STEP 2: Create a reader by defining the schema for reading the movie recommendation datasets\r\n            var reader = mlcontext.Data.TextReader(new TextLoader.Arguments()\r\n            {\r\n                Separator = ""tab"",\r\n                HasHeader = true,\r\n                Column = new[]\r\n                {\r\n                    new TextLoader.Column(""userId"", DataKind.Text, 0),\r\n                    new TextLoader.Column(""movieId"", DataKind.Text, 1),\r\n                    new TextLoader.Column(""Rating"", DataKind.R4, 2)\r\n                }\r\n            });\r\n\r\n            //STEP 3: Read in training data \r\n            var trainingDataView = reader.Read(new MultiFileSource(TrainingDataLocation));\r\n\r\n            //STEP 4: Create default Recommendtion model \r\n            var model = mlcontext.CreateRecommendationModel(trainingDataView);\r\n\r\n            //STEP 5: Read in test data \r\n            var testDataView = reader.Read(new MultiFileSource(TestDataLocation));\r\n\r\n            //STEP 6: Use Recommendation model to evaluate performance of test data \r\n            var prediction = model.Transform(testDataView);\r\n            var metrics = model.Evaluate(prediction, label: ""Label"", score: ""Score"");\r\n\r\nThis for getting started purposes avoids .NET developers to necessarily dive into understanding the concept of estimators, transforms, choice of learners etc. \r\n\r\n  var pipeline = mlcontext.Transforms.Categorical.MapValueToKey(""userId"", ""userIdEncoded"")\r\n                                    .Append(mlcontext.Transforms.Categorical.MapValueToKey(""movieId"", ""movieIdEncoded"")\r\n                                    .Append(new MatrixFactorizationTrainer(mlcontext, ""Label"", ""userIdEncoded"", ""movieIdEncoded"")));\r\n\r\nOther ML Frameworks focused on developers and AutoML approaches out there provide a simpler set of APIs targeting developers already. Is there something we can learn on that front given ML.NET already has some AutoML smarts based upon the static rule based engine. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
386441449,1799,b'Logging and Tracing in ML.NET',b'In EntityFramework there exists a context log property which allows for logging SQL generated by dbcontext.\r\n\r\nFor MLContext is there a similar log property which allows for logging some of the diags currently printed to Console when using various transforms or learners? Additionally is there a way to control log location and verbosity? \r\n\r\n**_E.g.: When using Matrix Factorization:_** \r\nSample: https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/MatrixFactorization_MovieRecommendation/MovieRecommendation/Program.cs\r\n\r\n=============== Training the model ===============\r\niter   tr_rmse          obj\r\n   0    0.0002   4.8456e+02\r\n   1    0.0002   7.8940e+02\r\n   2    0.0002   1.1160e+03\r\n   3    0.0002   1.2787e+03\r\n   4    0.0002   1.6045e+03\r\n   5    0.0002   2.0909e+03\r\n   6    0.0002   2.5788e+03\r\n   7    0.0002   2.9040e+03\r\n   8    0.0002   3.2300e+03\r\n   9    0.0002   3.2758e+03\r\n  10    0.0001   2.8742e+03\r\n  11    0.0001   2.5185e+03\r\n  12    0.0000   2.0396e+03\r\n  13    0.0000   1.9213e+03\r\n  14    0.0000   1.6839e+03\r\n  15    0.0000   1.3291e+03\r\n  16    0.0000   1.2107e+03\r\n  17    0.0000   9.7367e+02\r\n  18    0.0000   9.7325e+02\r\n  19    0.0000   9.7242e+02\r\nreal tr_rmse = 0.0000\r\n\r\nEF provides the following to users:\r\n\r\n**Output directly to console:**\r\nusing (var context = new YourDbContext()) \r\n{ \r\n    context.Database.Log = Console.Write; \r\n     // rest of you code goes here... \r\n}\r\n\r\n**_Log output to the trace window_**\r\nusing (var context = new YourDbContext()) \r\n{ \r\n    context.Database.Log = message => Trace.Write(message);\r\n    // rest of you code goes here\r\n}\r\n\r\n**_Already have a logging framework in place_**\r\nusing Common.Logging;\r\n\r\npublic class SomeClass\r\n{\r\n    private static readonly ILog log = LogManager.GetCurrentClassLogger();\r\n\r\n    public void SomeMethod()\r\n    {\r\n        context.Database.Log = message => log.Debug(message);\r\n    }\r\n}\r\n\r\nThanks. \r\n\r\n'
386392122,1798,b'Creation of components through MLContext: advanced options and other feedback',"b'In our estimators and other similar components often have advanced settings, because, sometimes people have unusual circumstances. At the same time, there is a 95% or 99% scenario for ""simple"" usage that most people will be happy with. For this reason we have often made a distinction between common and advanced settings, as we see here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb37c7e7f1e1b29b5608a2755db793c5435d10b1/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L29-L38\r\n\r\nThere are some possible things that excited feedback:\r\n\r\n1. Echoing feedback seen in #1690, these things where we\'re making something should have the prefix `Create`, even in situations where this a catalog where we are *always* creating. Note: `Create` preferred to `Make`.\r\n\r\n2. The worth of ASP.NET style configuration was questioned (seen above as `Action<FastTreeRegressionTrainer.Arguments> advancedSettings`), e.g., there may not be much purpose in having a delegate. The older style where it just takes the `Arguments` *period* was preferred.\r\n\r\n3. Having this `Arguments` object as a nested class the component being created was viewed as positive, but this would be more idiomatically called `Options` -- `Arguments` was a holdover name from when these were exclusively for command line arguments, but for the API this is not a great name. So while keeping the general structure of how they are placed currently, they should probably be renamed to `Options`.\r\n\r\n4. It is good to have the convenience for the simple arguments, however, if we have both simple and advanced settings, we should not mix them but have instead two distinct constructors/extension methods. (E.g., in the above, we would have two methods, one that took the advanced options.) To do otherwise is to invite confusion about which ""wins"" if we have the setting set in both.\r\n\r\n    * Note that phase setting ""set in both,"" which suggests that these settings object should retain the ""simpler"" settings in them. This reinforces feedback elsewhere as seen [here](https://github.com/dotnet/machinelearning/pull/1352#discussion_r228319239).\r\n\r\n5. If the simple arguments are totally sufficient, then there is no need to expose this `Arguments` class in hte public API. (For practical reasons relating to command line and entry-point usage, we still need to always have these `Arguments` objects, but if they serve no purpose for the API the class can simply be made internal.)\r\n\r\n/cc @KrzysztofCwalina, @terrajobst , on whose feedback this list is primarily based, and who can correct me and provide clarification in case I misspoke.'"
386380493,1797,"b'Remove TextLoader.Read(string), promote IDataReader<MSS> extension'","b""Pursuant to #1090 and #1041 there was agreement that we should be able to just pass a *string* into a data reader that reads from streams, rather than have to muck about with the creation of this `IMultiStreamSource` object.\r\n\r\nAs it happens, this one request was done in two separate ways:\r\n\r\n1. #1252 where this instance method on `TextLoader` was created:\r\n  \r\n https://github.com/dotnet/machinelearning/blob/cb37c7e7f1e1b29b5608a2755db793c5435d10b1/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1340\r\n\r\n2. #1281 where an extension method on top of `IDataReader<IMultiStreamSource>` was introduced.\r\n\r\nClearly we don't need both, and the second being more flexible and more broadly applicable was the one that should be checked in, so let us remove the class specific method introduced in #1252. The extension method should however be moved to a namespace where it is more likely to be picked up (probably `Microsoft.ML`) since right now it's a bit buried and generally people would never see this extension method."""
386378043,1796,b'Rename types inside MLContext as Catalogs',"b'We had an idea in #949 to have ""context"" objects that enabled the easy and convenient creation of training algorithms. We eventually came to like this idea so much that it expanded considerably, until we came to think it actually a good idea that *most* components (whether trainers or not) could work through this object, to the point where eventually in in #1098, there was a ""master"" context, of which the formerly independent contexts became properties of that master context.\r\n\r\nThe newer things that were added were then called ""catalogs,"" for example:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb37c7e7f1e1b29b5608a2755db793c5435d10b1/src/Microsoft.ML.Data/MLContext.cs#L47\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb37c7e7f1e1b29b5608a2755db793c5435d10b1/src/Microsoft.ML.Data/MLContext.cs#L52\r\n\r\nHowever the old objects retained the type names they had back when they were independent.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb37c7e7f1e1b29b5608a2755db793c5435d10b1/src/Microsoft.ML.Data/MLContext.cs#L25\r\n\r\nWe ought to probably standardize the name of these things as being ""catalogs."" E.g., things in here with the type name suffix `Context` should change that to `Catalog`, things that are catalogs but aren\'t named that yet (`DataOperations`) should be standardized as well.'"
386358567,1795,b'Evaluator of one-class matrix factorizaition is missing',"b'One class matrix factorization is solved as a regression problem but common metrics in practices are top-k accuracy, nDCG, etc.\r\n'"
386356570,1794,b'Time series improvements',"b""Mainly for @codemzs, I wanted to ask what additional work is needed for time series.  Here are few things I noticed:\r\n\r\n1. Add support for doubles in SSA and IID estimators. Currently we check to verify floats, for all other types we throw an exception.\r\n2. Create class with named properties for output metrics of Martingale, P-Value, Alert, and Score.  Currently we output a column of vector type that contains these four values. Alternate approach would be to have four output columns.\r\n3. Move everything under namespace `Microsoft.ML.Runtime.TimeSeriesProcessing` into `Microsoft.ML.TimeSeries`.  Is there a reason why we need both namespaces?\r\n4. Add missing unit tests.  We are missing IID and SSA spike detection, and we don't have code coverage over types such double, int, etc.\r\n5. Improve naming for estimator arguments.  Currently we have `Source` for our input column and `Name` for our output column.  It would make more sense to be `Source` and `Dest` or `InputColumn` and `OutputColumn`.\r\n6. Format the samples for the docs site.  For each transformer we have the option of using the transformer on a batch of data or creating a prediction engine - which should we be displaying as the sample on the docs site? Both on separate pages?"""
386324624,1791,b'Feature Contribution Calculation should become Transformer',"b'We should make the `FeatureContributionCalculationTransform` a transfomrer, and add a related estimator that produces it so that it can become part of a pipeline. Below I show how it could look like with the new API:\r\n\r\n```csharp\r\n// Define a pipeline for feature extraction with a trainer at the end\r\nvar pipeline_1 = mlContext.BinaryClassification.Trainers.trainerEstimator(arguments);\r\n// Train model and cast it to IPredictor\r\nvar predictor = pipeline.Fit(data).Model;\r\n```\r\nTwo ways of applying FeatureContributionCalculation:\r\n```csharp\r\n// 1 First Way: Define another pipeline with FeatureContributionCalculation and possibly more \r\n// estimators appended to it\r\nvar pipeline_2 = mlContext.Model.Explainability.FeatureContributionCalculatingEstimator(arguments, predictor);\r\nvar outputData = pipeline_2.Fit(data).Transform(data);\r\n``` \r\n\r\n```csharp\r\n// 2 Second Way: Use the transformer directly, as it is not a trainable transformer\r\nvar transformer = new FeatureContributionCalculatingTransformer(mlContext, arguments, predictor);\r\nvar outputData = transformer.Transform(data);\r\n```\r\n\r\nIn either cases the output data will contain a `score` column along with a `FeatureContribution` column.\r\n\r\ncc: @rogancarr, @TomFinley, @Zruty0, @Ivanidzo4ka '"
386318747,1790,b'Support scoring on ARM',b'This issue is a concrete work item from question #1662.\r\n\r\nMotivation:\r\nWe need ARM for scoring models on IoT devices and for mobile devices running Xamarin apps on iOS or Android. All those workloads are important for .NET.'
386312702,1789,b'Provide sample and documentation for PredictionFunction object-pooling for ASP.NET applications',"b'This is the concrete work item from discussions in #1718.\r\n\r\nMotivation:\r\nMajority of .NET Core apps use ASP.NET Core. In order to get the best developer experience we should provide a sample that implements object pooling approach for PredictionFucntion (which is not trivial) and also document it in docs.microsoft.com.\r\n\r\nBased on feedback from users, we might add this functionality to ML.NET. \r\n'"
386276592,1787,b'Delete the Legacy API',"b'Before shipping v1.0, we need to delete all the APIs that are marked ""legacy"" and ""obsolete"". Specifically, after this work is completed https://github.com/dotnet/machinelearning/tree/master/src/Microsoft.ML.Legacy should be completely removed, and any assets in it that need to remain should be migrated elsewhere. For example #1565 is for migrating the entry-points that we still need.'"
385940933,1783,b'Change the <a> tags to <image> tags',"b'In the RankerMetrics the `<a>`  tags for images will need to get converted to `<image>` tags, so the images display. \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Evaluators/Metrics/RankerMetrics.cs#L23'"
385900239,1781,b'FastTree uses lots of memory with dropout on',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan FastTreeRegressor with DropoutRate > 0.\r\n\r\n- **What happened?**\r\nConsumed around 15 GB of memory. Memory usage increased linearly with # of trees\r\n\r\nRunning FastTreeRegressor with DropoutRate > 0 leads to much higher memory consumption than when DropoutRate = 0. It used approx 14 GB more for 200 trees, and ran into an out of memory exception for 500 trees. Perhaps there is a leak? (Turning on DropoutRate seemed to consistently cause memory footprint to rise significantly.)'"
385558004,1778,b'Consider adding convenience functions to load / save models from / to files',"b'In order to load a model from disk, one currently has to do something like this:\r\n\r\n```cs\r\nITransformer trainedModel;\r\nusing (var stream = new FileStream(ModelPath, FileMode.Open, FileAccess.Read, FileShare.Read))\r\n{\r\n  trainedModel = mlContext.Model.Load(stream);\r\n}\r\n```\r\n\r\n(Code taken from our sample [here](https://github.com/dotnet/machinelearning-samples/blob/ff0ae26e3bd2366c1fe55e8e8fbee17b4596cc61/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis/SentimentAnalysis/SentimentAnalysisConsoleApp/Program.cs#L101)\r\n\r\nWe should consider adding convenience methods for this common case to allow for code like this:\r\n\r\n```cs\r\nITransformer trainedModel = mlContext.Model.LoadFromFile(ModelPath);\r\n```\r\n\r\nSimilarly, we could consider adding a convenience method to save to a file to allow for code like this:\r\n\r\n```cs\r\nmlContext.Model.SaveToFile(trainedModel, ModelPath);\r\n```\r\n\r\nOf course, we might also want the `*Async` variants thereof.'"
385532361,1776,b'Extra Spaces in Baseline file for Netcoreapp3.0',"b'TestName EntryPointPipelineEnsembleGetSummary\r\n\r\nThe original baseline file contains ```""Features.bare_nuclei\\t%Number%  \\t%Number% \\t%Number%  \\t%Number% ***""```\r\nfile - machinelearning\\\\test\\\\BaselineOutput\\\\Common\\\\EntryPoints\\\\ensemble-summary.txt""\r\n\r\nbaseline - ""Features.bare_nuclei\\t%Number%   \\t%Number% \\t%Number%  \\t%Number% ***""\r\noutput -   ""Features.bare_nuclei\\t%Number%  \\t%Number% \\t%Number%  \\t%Number% ***""\r\n\r\ncc @eerhardt @danmosemsft @shauheen '"
385529295,1774,b'Regression in Rff Code due to OVA + AveragedPerceptron',b'I ran a benchmark provided to me By @justinormont  that uses Rff Transformer.\r\nI ran it too on  master as well as on https://github.com/dotnet/machinelearning/commit/7d9660a3e3881e444f7a4212b175856aaa9bdbe0\r\nand https://github.com/dotnet/machinelearning/commit/8b19930c3413b578b1b9603633f0e9ec30cd8acd\r\n\r\nThe time taken by the benchmark for both of the last two commit was around 850 ms for both netstandard as well as netcoreapp 3.0 implementation where as it was around 1.3 sec for the master branch.\r\n\r\nI am working on adding the benchmark into the repo.\r\nThe rsp being used here is \r\n![image](https://user-images.githubusercontent.com/10516582/49246698-651ad200-f3ca-11e8-8f1e-4d4275a1aa98.png)\r\n\r\n\r\n\r\ncc @adamsitnik @eerhardt @danmosemsft @shauheen \r\n'
385528888,1773,b'Official build can fail due to copying of the same redist assets',"b'Currently, all of the files under Redist are assumed to be RID specific, and get built/executed by every leg of the official build script. This is not the case for the DNNImageFeaturizer models, which means the same models get copied over from each RID leg (MacOS, Linux, etc) into the same destination container. This can cause issues if this happens at the exact same time.'"
385523553,1772,b'GenericSpanSortHelper should have an overload that takes an IComparer',"b'This would enable sorting using a custom comparer, instead of the default CompareTo() method.'"
385521137,1771,"b'PFI should work for multi class classification, clustering and recommendation'","b'PFI currently only works for binary classification and regression. It should be extended to multi class classification, clustering and recommendation to provide explainability functionalities in other experiment categories.\r\n\r\nThe PFI approach works for all the above training scenarios, and it is natural for users that use the tool for binary classification/regression to also want to use it for other scenarios.\r\n\r\ncc: @rogancarr '"
385520391,1770,b'MatrixFactorization cannot be found in the MLContext catalog',b'`MatrixFactorization` cannot be found in the MLContext catalog. MLContext.Recommendation is currently empty. \r\n\r\nThis is with the 0.8.0-preview-27128-6 Microsoft.ML and Microsoft.ML.MatrixFactorization NuGets.'
385520367,1769,b'Need example for one-class matrix factorization',"b'Currently we only have [one test](https://github.com/dotnet/machinelearning/blob/533e18647a77c31f8149ccf2618ccb2e354f8e62/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs#L376) as our example. We should add one into our sample project. Also, in that actual example, we need to tell user to install MatrixFactorization nuget. The ultimate scope of the new example is to cover everything user needs to do to run one-class matrix factorization.\r\n\r\nAlso, because of some settings in our test framework, our tests are not examples which can be run by copy-and-paste.'"
385517917,1768,b'Need XML doc string for each public field',"b""At ML.NET doc site, there are a lot of fields with empty description, for example, see [this](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.matrixfactorizationtrainer.arguments?view=ml-dotnet). To make users' life easier, it'd be better to fill them with meaningful information."""
385516350,1767,b'Need sample/code snippet for how to read and write from IDV files ',"b'#1678 added the ability to save and load as binary (IDV) files. It would be useful to have a code snippet/sample to show how this can be done, with some remarks on why this is useful that show up in the docs website.'"
385510457,1766,b'Need PFI sample for binary classification',"b""This [PFI sample](https://github.com/dotnet/machinelearning/blob/3d33e20f33da70cdd3da2ad9e0b2b03df929bef4/docs/samples/Microsoft.ML.Samples/Dynamic/PermutationFeatureImportance.cs) has great detail, but it focuses on regression. Using PFI with binary classification requires a slightly different approach and it isn't immediately obvious how to do it. An additional sample explaining how to use PFI for binary classification would be quite helpful"""
385510433,1765,b'Feature Contribution Calculator Documentation is Vague',"b'The [documentation](https://github.com/dotnet/machinelearning/blob/533e18647a77c31f8149ccf2618ccb2e354f8e62/src/Microsoft.ML.Data/Scorers/FeatureContributionCalculationTransform.cs#L29) for the Feature Contribution Calculation Transform is rather vague. It should be updated to talk about the feature, why it is useful, and point to the corresponding example.'"
385508416,1764,b'PFI BinaryClassification XML Documentation is Outdated',"b""The [sample documentation](https://github.com/dotnet/machinelearning/blob/533e18647a77c31f8149ccf2618ccb2e354f8e62/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs#L86) for Binary Classification PFI is still the old text, while [regression documentation](https://github.com/dotnet/machinelearning/blob/533e18647a77c31f8149ccf2618ccb2e354f8e62/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs#L14) is the new text. Let's update the binary classification documentation so that it's on par with the regression documentation."""
385497612,1763,b'Add a Filter for text-based columns',"b'Afaik, the new filter APIs can target just numeric-based columns, but not text-based columns.\r\nAs of v0.8 we have: \r\n1) \r\n```\r\n//FilterByColumn()\r\n\r\nIDataView trainingDataView = mlContext.Data.FilterByColumn(baseTrainingDataView, ""FareAmount"", lowerBound: 1, upperBound: 150);\r\n```\r\n\r\nThis is a very convenient filter, but for NUMERIC values. I\xe2\x80\x99m currently using this for the sample code-snippet\r\n\r\n2)\r\n`FilterByKeyColumnFraction()`\r\nGood for hashed values.\r\n\r\nBut if we want to filter by text-based columns, let\'s say I want to remove the rows where a text based column has no value (this might be doable when transforming to numeric values, then missing value is NaN and it will get filtered, but you need an additional not straightforward step) or to **remove specific rows when categorical values are equal to ""some text""**, I think we cannot do that, yet.\r\n\r\n'"
385494229,1761,b'Name of MakePredictionFunction is confusing (to me).',"b'I was following the start example in the Readme, and when I came to the line with MakePredictionFunction, I got a bit confused and had to go over it a few times before I could continue:\r\n\r\n> Now from the model we can make inferences (predictions):\r\n> \r\n> ```C#\r\n> var predictionFunc = model.MakePredictionFunction<SentimentData, SentimentPrediction>(mlContext);\r\n> var prediction = predictionFunc.Predict(new SentimentData\r\n> {\r\n>     SentimentText = ""Today is a great day!""\r\n> });\r\n> Console.WriteLine(""prediction: "" + prediction.Prediction);\r\n> ```\r\n\r\nI expected the return value of `MakePredictionFunction()` to a function-type thing, but instead it was an object.  This was hard for me not because of pedantic correctness, but rather from a usability standpoint as a beginner trying to keep my concepts straight (estimators, transformers, models, etc.) this took me a step back and I had to go over the section several times to make sure I hadn\'t missed something.\r\n\r\nIs there a better name that would be less confusing?\r\n- `MakePredictionObject()`\r\n- `MakePredictionEngine()`\r\n- `MakePredictor()`\r\n- ?\r\n\r\n'"
385454643,1760,"b'The ColumnInfo structure should live in the estimators, rather than transformers'","b'For OneHotEncoding estimator/transformer, ColumnInfo lives in the estimator. \r\nFor most other pairs, ColumnInfo lives in the transformer. \r\n\r\nStandardize their location. \r\n\r\nI think they should live in the estimator, since they are mostly used on Estimator definition. \r\n\r\n'"
385448660,1758,b'Arguments class should be made internal when possible',"b'For transformers like `SlotsDroppingTransformer`, and most other OneToOneTransformers, we implement a ColumnInfo object that allows to set all the transformation specific parameters. We should therefore make the Arguments class internal, as it is only used for the command line.'"
385420907,1756,"b'Bug in ""ApplyAt"" method in VBufferUtils'","b""In the sparse case, it should create the VBufferEditor with keepOldOnResize set to true, so that we don't lose the existing values and indices."""
385418956,1755,b'IColumn and related code removal',"b'Years ago I wrote this code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Data/IColumn.cs\r\n\r\nThat was fine, but many of the conveniences that this offered were not heavily used throughout the codebase, and the few places where it was convenient have been supplanted, I think, by the new `Schema.Column`, `Schema.Metadata`, and `MetadataBuilder` idioms.\r\n\r\nThis is work done as a prelude to #1532, since that change would heavily affect this code here, and this code serves a limited purpose, we may as well remove it.\r\n\r\n'"
385417936,1754,b'MLContext extension naming mismatch with dynamic API',"b""Extensions to MLContext don't consistently match either the static API names, or the dynamic API names for estimators. This leads users that directly instantiate the dynamic API to find different names for the same estimators than when finding them through MLContext. \r\n\r\nSince the estimators obtained through MLContext use the dynamic API, I would suggest that their names match the dynamic API names. """
385408689,1753,b'Coefficients for Dynamic API',"b'Using version 0.70 and we are trying to figure out if we are able to view the coefficients of our trained model like is shown in the example with the static API in the cookbook. However, we are using the dynamic API... is there a way to accomplish this? \r\n\r\nAlternatively is there a way to define a static pipeline without a TextReader? All of our data is pulled from a DB \xe2\x80\xa6 so we are utilizing CreateStreamingDataView.\r\n\r\nThanks!\r\n\r\n\r\n\r\n\r\n'"
385389414,1752,b'Changing trainer makes application exit with STATUS_STACK_OVERFLOW ',"b'### System information\r\n\r\n- Windows 10\r\n-  Microsoft.ML 0.7.0\r\n - Dotnet.Core 2.1.403 \r\n\r\n### Issue\r\n\r\nI have created a .NET Core application that is using a lot of code of the GitHubLabeler sample. To be specific this file:\r\n\r\nhttps://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler/GitHubLabeler/GitHubLabelerConsoleApp/Program.cs\r\n\r\nOne major change I have done is to create a text file in memory with training data instead of reading from a file, otherwise it\xe2\x80\x99s very similar. If I create my trainer with this code the application runs fine in all situations:\r\n\r\n    var averagedPerceptronBinaryTrainer = mlContext.BinaryClassification.Trainers.AveragedPerceptron(DefaultColumnNames.Label,\r\n        DefaultColumnNames.Features,\r\n        numIterations: 10);\r\n\r\n    IEstimator<ITransformer> trainer = new Ova(mlContext, averagedPerceptronBinaryTrainer);\r\n\r\nBut if I use this code instead:\r\n\r\n    IEstimator<ITransformer> trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(DefaultColumnNames.Label,\r\n        DefaultColumnNames.Features);\r\n\r\n\r\nMy application exists with error code -1073741571, which I guess means STATUS_STACK_OVERFLOW (0xc00000fd). But it only does this when I run the application as a webjob in Azure, I can\xe2\x80\x99t replicate the problem locally (yet).\r\n\r\nIf I reduce the number of training data, it also works fine (I\xe2\x80\x99m changing the number of items from 10 000 to 1 000).\r\n\r\nMy guess it that the StochasticDualCoordinateAscent trainer makes evil things on the stack :-) Or could it be something else?\r\n'"
385267112,1751,b'Spittler/consolidator worker exception while consuming data w/ 0.8.0-preview-27128-5',"b'### Issue\r\n\r\n- **What did you do?**\r\nUpgraded from 0.7 to 0.8-preview.\r\n\r\n- **What happened?**\r\nI got an exception during `estimator.fit()`. Though it also appears doing a `encodedTrainingData.AsDynamic.Preview` where my ""encoder"" only does encoding (no ML model learnt).\r\n\r\nI\'m not sure how to further debug this. I probably won\'t have time for a minimal repro example.\r\n\r\n### Source code / logs\r\nException:\r\n\r\n**IndexOutOfRangeException: Index was outside the bounds of the array.**\r\n\r\n```\r\n                public void SetAll(OutPipe[] pipes)\r\n                {\r\n                    if (_ex != null)\r\n                        throw Contracts.Except(_ex, ""Splitter/consolidator worker encountered exception while consuming source data"");\r\n                    Contracts.Assert(Utils.Size(pipes) == _batchColumns.Length);\r\n[...]\r\n```\r\n\r\nException trace:\r\n```\r\n   at System.ThrowHelper.ThrowIndexOutOfRangeException() in E:\\A\\_work\\65\\s\\corefx\\src\\System.Memory\\src\\System\\ThrowHelper.cs:line 43\r\n   at Microsoft.ML.Transforms.Conversions.KeyToVectorMappingTransformer.Mapper.<>c__DisplayClass11_0.<MakeGetterOne>b__0(VBuffer`1& dst) in E:\\A\\_work\\423\\s\\src\\Microsoft.ML.Data\\Transforms\\KeyToVector.cs:line 483\r\n   at Microsoft.ML.Runtime.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst) in E:\\A\\_work\\423\\s\\src\\Microsoft.ML.Data\\Transforms\\ColumnConcatenatingTransformer.cs:line 690\r\n   at Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill() in E:\\A\\_work\\423\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 730\r\n   at Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.Consolidator.<>c__DisplayClass4_1.<ConsolidateCore>b__2() in E:\\A\\_work\\423\\s\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 417\r\n```\r\n\r\nTrace:\r\n```\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.Batch.SetAll(Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.OutPipe[] pipes) Line 839\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() Line 1114\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Data.RootCursorBase.MoveNext() Line 70\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Transforms.Normalizers.NormalizingTransformer.Train(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.Data.IDataView data, Microsoft.ML.Transforms.Normalizers.NormalizingEstimator.ColumnBase[] columns) Line 375\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.EstimatorChain<Microsoft.ML.Core.Data.ITransformer>.Fit(Microsoft.ML.Runtime.Data.IDataView input) Line 68\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.EstimatorChain<Microsoft.ML.Core.Data.ITransformer>.Fit(Microsoft.ML.Runtime.Data.IDataView input) Line 68\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.StaticPipe.Estimator<(Microsoft.ML.StaticPipe.Vector<float>, Microsoft.ML.StaticPipe.Key<uint, string>), (Microsoft.ML.StaticPipe.Scalar<string>, Microsoft.ML.StaticPipe.Scalar<string>, Microsoft.ML.StaticPipe.Vector<float>), Microsoft.ML.Core.Data.ITransformer>.Fit(Microsoft.ML.StaticPipe.DataView<(Microsoft.ML.StaticPipe.Vector<float>, Microsoft.ML.StaticPipe.Key<uint, string>)> view) Line 35\tC#\r\n[...]\r\n```\r\n'"
385040896,1746,b'WordTokenizeingTransformer need example of how to use it.',"b""I am looking for examples for using `WordTokenizingTransformer`. The only resources I found is [its test](https://github.com/dotnet/machinelearning/blob/18d7ea306c480013f54674d92431386abccce64f/test/Microsoft.ML.Tests/Transformers/WordTokenizeTests.cs#L67), but after reading that, I still don't know how to print out its output using `Console.WriteLine`. As a C# library, we need more end-to-end examples which **feed C#** data structures and get the produced results **as native C#** objects."""
385003505,1743,b'DnnImageFeaturizer copies models on incremental builds',b''
384966647,1741,b'Build break caused by DnnImageFeaturizer PR (#1447)',b''
384923074,1738,b'GenerateCodeCommand generates scoring code that uses old APIs',b'The command should be updated to use the new API.'
384846639,1737,b'F# api issues',"b'Hi, wanted to point out the generic problems of ""new"" api from fsharp perspective.\r\nFirst of all, what is really missing is the Pipeline itself, instead we see is context, set of objects and extensions.\r\n\r\nExpected to see:\r\n```\r\ndata\r\n|> Clean Cleaners.RemoveRow\r\n|> Normalize Normalizers.Median\r\n|> Split Splitters.Random\r\n|> Train Learners.BoostedDecisionTree\r\n|> CrossValidate\r\n|> Evaluate\r\n```\r\n\r\nSecondly, as most of logic is implemented as extension methods on interfaces, in fsharp we need to to unsafe double cast sometimes:\r\n```\r\nlet dynamicPipeline =\r\n        mlContext.Transforms.Categorical.OneHotEncoding(""CategoricalFeatures"", ""CategoricalOneHot"")\r\n        :> IEstimator<CategoricalTransform>\r\n        :?> IEstimator<ITransformer>\r\n```\r\n\r\n'"
384698416,1736,b'Use of Reflection.Emit in ML.NET',"b""Can ML.NET be used on platforms that don't support Reflection.Emit, such as Windows UWP or Xamarin iOS?\r\n\r\nI'm helping a customer get ML.NET running on UWP, but seeing there are code paths that might end up using Reflection.Emit worry me that I'm just wasting time."""
384638106,1734,b'Add Permutation Feature Importance for Binary Classification Tasks',b'The `PermutationFeatureImportance` currently only supports Regression. We also need to add support for Binary Classification.'
384615623,1732,b'Add detailed XML Docs for Permutation Feature Importance',"b'The XML Docs for `Permutation Feature Importance`, aka `PFI`, can be extended a bit to discuss the technique and the derivation.'"
384607502,1730,b'Add detailed XMLDocs for Generalized Additive Models',b'The XML docs for Generalized Additive Models are not very detailed and sometimes incorrect (e.g. in the tree trainer catalog). I would like to see detailed descriptions in the XML docs that link to samples.'
384574100,1729,b'Add Random Forest support',"b'To ease the transition from Azure ML Studio to ML.NET, please add an equivalent of https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/multiclass-decision-forest to ML.NET'"
384548223,1726,"b'EntryPointSDCARegression test fails intermittenly in Mac Debug with: longIdx=449, invariants.Length=449 '","b'Related to #1471\r\n\r\nFailure is in [SdcaBinary.cs](https://github.com/dotnet/machinelearning/blob/284e02cadf5342aa0c36f31d62fc6fa15bc06885/src/Microsoft.ML.StandardLearners/Standard/SdcaBinary.cs#L541)\r\n\r\n Contracts.Assert(0 <= longIdx & longIdx < invariants.Length, $""longIdx={longIdx}, invariants.Length={invariants.Length}"");\r\n\r\nTest Microsoft.ML.Runtime.RunTests.TestEntryPoints.EntryPointSDCARegression\r\nfails intermittnely in the Mac builds, with failure message:\r\n\r\nAssert failed: longIdx=449, invariants.Length=449\r\nExpected: True\r\nActual: False\r\n\r\nStack trace: \r\n\r\n   at Microsoft.ML.Runtime.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in /Users/vsts/agent/2.142.1/work/1/s/test/Microsoft.ML.TestFramework/GlobalBase.cs:line 70\r\n   at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 754\r\n   at Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 767\r\n   at Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 825\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.StandardLearners/Standard/SdcaBinary.cs:line 541\r\n   at Microsoft.ML.Runtime.Learners.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.StandardLearners/Standard/StochasticTrainerBase.cs:line 42\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer<TModel>.Train(TrainContext context) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 94\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 161\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor, RoleMappedData testData) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 278\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 247\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.Data/EntryPoints/InputBase.cs:line 190\r\n   at Microsoft.ML.Trainers.Sdca.TrainRegression(IHostEnvironment env, Arguments input) in /Users/vsts/agent/2.142.1/work/1/s/src/Microsoft.ML.StandardLearners/Standard/SdcaRegression.cs:line 189'"
384543195,1725,b'Docs rendered incorrectly',"b""These pages don't have correct docs rendered:\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.selectfeatures.countselect?view=ml-dotnet\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.selectfeatures.mutualinformationselect?view=ml-dotnet\r\n\r\nIt's rendering like this:\r\n![image](https://user-images.githubusercontent.com/15950225/49046677-c3a53d80-f189-11e8-8218-d42580a46da7.png)\r\n\r\n"""
384531809,1723,b'Create a sample for Permutation Feature Importance',"b""We recently added 'PermutationFeatureImportance` for `Regression`. It would be great to have a sample on how to use it."""
384450093,1721,b'StochasticDualCoordinateAscentClassifier issue when x86 (32 bits)',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n4.6.1\r\n### Issue\r\n\r\n- **What did you do?**\r\ntry to use StochasticDualCoordinateAscentClassifier as classifier on My ML application\r\n- **What happened?**\r\ni ran it through 86x and through the following exception\r\n\r\n> Managed Debugging Assistant \'PInvokeStackImbalance\' \r\n  Message=Managed Debugging Assistant \'PInvokeStackImbalance\' : \'A call to PInvoke function \'Microsoft.ML.CpuMath!Microsoft.ML.Runtime.Internal.CpuMath.Thunk::SumSqU\' has unbalanced the stack. This is likely because the managed PInvoke signature does not match the unmanaged target signature. Check that the calling convention and parameters of the PInvoke signature match the target unmanaged signature.\'\r\n\r\n\r\n- **What did you expect?**\r\nit should work normally in 86x as it work fine with 64 and this exception occur only with 86x and i need to run it with 86 \r\n\r\n### Source code / logs\r\n```pipeline.Add(CollectionDataSource.Create(noramalTagsTrainingData));\r\npipeline.Add(new Dictionarizer(""Label""));\r\n// Transform any text feature to numeric values\r\npipeline.Add(new CategoricalOneHotVectorizer(\r\n""fontColor"",\r\n""tagText"",\r\n""firstWord""\r\n));\r\npipeline.Add(new ColumnConcatenator(\r\n""Features"",\r\n""fontSize"",\r\n""isBold"",\r\n""isItalic"",\r\n""isUnderLine"",\r\n""containsDot"",\r\n""containsQuestionMark"",\r\n""isAllCaps"",\r\n""tagText"",\r\n""firstWord""\r\n));\r\npipeline.Add(new StochasticDualCoordinateAscentClassifier\r\n            {\r\n                MaxIterations = 100,\r\n                NumThreads = 7,\r\n                LossFunction = new SmoothedHingeLossSDCAClassificationLossFunction()\r\n            });\r\npipeline.Add(new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = ""PredictedLabel"" });\r\n\r\n // The pipeline is trained on the dataset that has been loaded and transformed.\r\nvar model = pipeline.Train<NormalTagsModelFeatures, NormalTagsPrediction>();\r\n```\r\n\r\nit through the exception at last line within only 86x\r\n\r\nany help please\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
384446595,1720,b'Remove the dependency on Math.Net numeric',"b'For the training statistics of Logistic regression, and specifically the (STD calculation)https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/LogisticRegression.cs#L440] we have two implementations: one in the Hal Learners project, that gets packaged in the HalLearners nuget, and the other on the StandardLearners project, that gets packaged in the main Microsoft.ML package. \r\n\r\nRemove the implementation in the StandartLearners package, we will go ahead with just the MKL implementation offer. '"
384150863,1718,b'Need PredictionFunction to provide object-pooling or to be thread-safe',"b'This issue is suggesting an enhancement since the current approaches/workarounds have both drawbacks, meaning we\'re not getting the scalability and performace as good as it could be in multithreaded scenarios like ASP.NET Core web apps or Web API services.\r\n\r\n**Context:**\r\nIn multiple scenarios, but especially in ASP.NET Core web apps, the **model-object (ITransformer)** and the **prediction function (PredictionFunction) object** should be re-used because they are ""expensive"" objects when initializing and will impact when having many concurrent users. \r\n\r\nIn the case of the model-object (ITransformer), it is a thread-safe object, so the model-object loaded from the .ZIP file can be registered as singleton. That way it\'ll be re-used by any thread or Http request in the ASP.NET Core app. See this code as an example: https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/Regression-SalesForecast/src/eShopDashboard/Startup.cs#L53\r\n\r\n**Main issue with the Prediction Function:**\r\nThe Prediction function is also ""expensive"" as it takes significant milliseconds when creating the prediction-function object from the model-object with the `model.MakePredictionFunction()` method. \r\nIdeally, because it is ""expensive"", it should be re-used across executions in the same app. But since it is not thread-safe, the current options in an ASP.NET Core web app are the following:\r\n\r\n**- OPTION 1:** Register the PredictionFunction object as **Scoped** (`AddScoped()`) for its DI/IoC object lifetime, as in this code:\r\nhttps://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/Regression-SalesForecast/src/eShopDashboard/Startup.cs#L61\r\n\r\nBut, the problem with this approach is that in many of the cases you don\'t get much benefit unless within the same Http request you make multiple calls to the .Predict() method. The point is that since the Scope lifetime is only re-used within a single Http request, for most of the Http requests it\'ll need to call the model.MakePredictionFunction() method.\r\n\r\nThe only way to share an object across Http requests in .NET Core DI/IoC is with singleton, but that requires the object to be thread-safe.\r\n\r\nThe possible service/object lifetimes in .NET Core IoC/DI are:\r\n- Singleton (shared across all threads)\r\n- Transient (per object call/new)\r\n- Scoped (Per Http request of object scope)\r\n\r\nSee the available object lifetimes here:\r\nhttps://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.1#service-lifetimes\r\nhttps://blogs.msdn.microsoft.com/cesardelatorre/2017/01/26/comparing-asp-net-core-ioc-service-life-times-and-autofac-ioc-instance-scopes/ (Autofac does support Thread Scope, though..)\r\n\r\n**- OPTION 2:** Register the PredictionFunction object as **Singleton** (`AddSingleton()`) for its DI/IoC object lifetime, as in this code (Commented line):\r\nhttps://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/Regression-SalesForecast/src/eShopDashboard/Startup.cs#L60\r\n\r\n**Benefits:** If you register the prediction-function object as Singleton for its ASP.NET Core DI/IoC object lifetime, since it is Singleton, any new Http request (except the first Http request since the app started) will just use the prediction function by calling the `Predict()` method. Therefore the performance of a single Http request would be significantly better. \r\n\r\n**Problem:** However, the issue with this approach is that since the prediction function is not thread-safe, you need to use mechanisms like a critical section to lock the prediction function object to be used by a single thread when executing the `Predict()` method, like in this code (Commented line):\r\nhttps://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/Regression-SalesForecast/src/eShopDashboard/Controllers/CountrySalesForecastController.cs#L57 \r\n\r\nThe issue with this approach is that since you are limiting the use of ""Predict()"" to a single thread, that will be a bottleneck when scaling. In the cases when you could have many concurrent Http requests and many of them trying to run the Predict() method, the scalability won\'t be as good as it could be because we\'re limiting that code execution to a single thread able to run the Predict() method. \r\n\r\nBasically, with this approach you might significantly limiting the scalability of the app (in regards the model execution/scoring) across threads when having many Http requests.\r\n\r\n**Workarounds:** Currently, use any of the two mentioned methods, being aware of the handicaps from each:\r\n- PredictionFunction as Scoped object\r\n- Predictionfunction as Singleton but using critical section when running ""Predict()""\r\n\r\n**Long term solutions:**\r\nI see two possible solutions:\r\n\r\n1. Create an object pooling of ""prediction function objects"". That way, most Http requests won\'t need to call the ""expensive"" `.CreatePredictionFunction()` method while it would be scalable since many threads could be using the multiple objects available in the object pooling.\r\n\r\n2. Make the prediction Function thread-safe. If the prediction-function was thread-safe while scalable enough, it could be simply registered as Singleton in the DI/IoC system in ASP.NET Core without needing to use a critical section or comparable approaches.\r\n\r\nIs there any other possible approach available?\r\n\r\nOnce these scenarios are further discussed in this thread or in our API reviews, I\'ll document the current possible approaches when consuming/running an ML.NET morel in an ASP.NET Core web app or Web API service.\r\n\r\nRelated issues:\r\nhttps://github.com/dotnet/machinelearning/issues/421 '"
383669020,1715,b'Microsoft.ML.Samples does not have a TensorFlowTransform example',b'Creating an issue to make the following updates to the TF Transform:\r\n\r\n- add mlcontext extension\r\n- add example to Microsoft.ML.Samples'
383529757,1713,b'How to use Feature selection ',"b'I want to use FeatureSelectorByMutualInformation feature selection, can you please provide me a sample code snippet how to use it with a dataset,  i could not able find in the samples provided. '"
383391405,1712,b'Does ML.Net support KNN?',b'https://github.com/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping\r\n\r\nI suggest adding the algorithm of this article to the function of time series.'
383333802,1711,b'Adding a new ci leg for netcoreapp 3.0',"b'Lately some of our commits are breaking stuff for our netcoreapp3.0\r\nwith the new ci leg up, we wont have to test the changes locally for netcoreapp3.0\r\n'"
383299766,1708,b'Add MLContext.Data extensions for schema comprehension',"b""- Move `AsEnumerable<T>` to `Microsoft.ML` (move AsEnumerable into an isolated file and make it an extension to MLContext). #2182.\r\n- Move `AsCursorable<T>` to `Microsoft.ML.Data`: I'm not sure if it's ever useful, so let's at least get it out of people's faces. Maybe `internal-best-friend` it. Working item: #2182\r\n- Add `MLContext.Data.ReadFromCollection<T>` (And make `env.CreateDataView` and `env.CreateStreamingDataView` internal. Their uses should be replaced with the new ReadFromCollection<T>.). The new signature of `ReadFromCollections<T>` should look like\r\n```csharp\r\npublic static IDataView ReadFromTextFile<TInput>(this DataOperations catalog, IEnumerable<TInput> collection)\r\n```\r\n- Add `MLContext.Model.MakePredictionFunction` as an alternative to `model.MakePredictionFunction`. Maybe still turn it into `Create`? @TomFinley ? [Update]: it has been done in `ModelOperationsCatelog.cs`\r\n"""
383297403,1707,b'Merge API assembly into Data',"b""Go over `Microsoft.ML.Api` in the following fashion:\r\n\r\n- For all code that is currently used by our code or tests, move it to `Microsoft.ML.Data`.\r\n  - This, I assume, will include all schema propagation, `PredictionEngine` (but not Batch), and `CustomMappingEstimator` and probably the `StatefulFilter` for the time series.\r\n- For all code that is needed by TLC, move back to TLC.\r\n  - I'm not aware of any such code at the moment.\r\n- For code that is not used by either, remove.\r\n\r\nAfter this, remove `Microsoft.ML.Api`\r\n"""
383296195,1706,b'Final interface of SchemaShape',"b'1. Move to `Microsoft.ML.Data`\r\n2. `internal-best-friend` all methods that are not accessing columns.\r\n3. Make `SchemaShape` be a `IReadOnlyList<SchemaShape.Column>`\r\n4. Add an accessor by name, and `GetColumnOrNull`, like `Schema` has.\r\n5. Make `SchemaShape.Column` a `struct`.\r\n6. Remove `SchemaException`.'"
383293825,1705,b'Make members of leaf assemblies internal',"b""Similar to #1602, let's make as many members of these assemblies internal as possible.\r\n\r\nThis applies to all assemblies other than `Core`, `Data` and `Transforms`."""
383293627,1704,b'Make members of Data and Transforms assemblies internal',"b""Similar to #1602, let's make as many members of these assemblies internal as possible"""
383293224,1703,b'Final public API for remaining learners',"b""Part of #1698 \r\n\r\nLet's make good public classes for trained artifacts of:\r\n- `FFM`\r\n- `Naive Bayes`\r\n- `PCAAnomaly`\r\n- `MF`\r\n- Any other trainers not covered in sub-issues of #1698 \r\n\r\n- Move to an appropriate namespace inside `Microsoft.ML`\r\n- Reduce the public surface\r\n- Add public constructor\r\n- Add a sample"""
383292843,1702,b'Final public API for linear learners',"b""Part of #1698 \r\n\r\nLet's make `LinearModelParameters` a good public class for Linear models' trained artifacts.\r\nThis applies to all linear models (SDCA, LR, SymSgd, OLS etc.)\r\n\r\n- Move to `Microsoft.ML.StandardLearners` or an appropriate namespace\r\n- Reduce the public surface\r\n- Add public constructor\r\n- Add a sample"""
383292425,1701,b'Final public API for Tree predictors',"b""Part of #1698 \r\n\r\nLet's make `TreeEnsembleModelParameters` a good public class for our tree learners' trained artifacts.\r\nThis applies to all descendants of `FastTreePredictionWrapper`.\r\n\r\n- Move to `Microsoft.ML.FastTree` or an appropriate namespace\r\n- Reduce the public surface\r\n- Add public constructor\r\n- Add a sample"""
383291823,1699,b'Final public API for KMeans predictor',"b""Part of #1698 \r\n\r\nLet's make `KMeansModelParameters` a good public class for KMeans trained artifacts.\r\n\r\n- Move to `Microsoft.ML.KMeansClustering` or an appropriate namespace\r\n- Reduce the public surface\r\n- Add public constructor\r\n- Add a sample"""
383291130,1698,b'Final public API for predictor classes',"b'1. All predictor classes should be named `SoAndSoModelParameters` (like `KMeansModelParameters`, `LinearBinaryModelParameters` etc. \r\n\r\n2. Strive to remove unnecessary interfaces from the public API: thinks like `IPredictor`, `IPredictorProducing<float>` etc. should not be public. \r\n\r\n3. Review the public surface of `ModelParameters` to enable ONLY parameter introspection. For example:\r\n  - `KMeans` should only expose centroid coordinates.\r\n  - `Linear` should only expose weights/biases.\r\n\r\n4. If possible, try to add public constructors. For example:\r\n  - Make it possible to create `KMeansModelParameters` from centroid coordinates\r\n  - Make it possible to create `LinearBinaryModelParameters` from weights and biases\r\n'"
383289386,1697,"b'Remove ""Runtime"" from all namespace reference, sort namespaces as per .net convention and enforce the same.'","b'Remove ""Runtime"" from all namespace reference, sort namespaces as per .net convention listed below and enforce the same.\r\n\r\n**SA1210:** Using directives must be ordered alphabetically by namespace.\r\n**SA1208:** System using directives must be placed before other using directives.\r\n'"
383288462,1696,b'(Azure Stream Analytics) Multivariate support for time series anomaly detection',"b""### System information\r\n\r\n- **OS version/distro**:  All\r\n- **.NET Version (eg., dotnet --info)**: All\r\n\r\n### Issue\r\n- **What did you do?** Azure Stream Analytics is currently running a private preview of built-in Anomaly Detection ML models. \r\n\r\n- **What happened?** In our discussions with several customers in private preview, lack of support for multi-variate A/D is coming up as a blocker to have them fully operationalize their hot path pipelines with this core feature. The list of customers include: \r\n1) Azure IoT Central (IoT SaaS solution) which uses Stream Analytics under the covers and are expected to grow to supporting '000s of IoT deployment by mid 2019. They require support for upto 4 variables.\r\n2) Stanley Black and Decker\r\n3) ATOS - European SI's IoT practice that works with many customers to build end to end IoT solutions. \r\n\r\n- **What did you expect?** N/A\r\n\r\n### Source code / logs N/A\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
383247595,1695,b'Separate assembly for statically typed API extensions',"b'There should be a greater separation between the statically typed API and the dynamic API, so that users are more aware of which one they are using. Ideally the statically typed extensions should live in a separate assembly, but they should at least be in a separate namespace.\r\n\r\nCurrently some extensions for the statically typed API are not under the StaticPipe namespace. From preliminary search the following estimators seem to have extensions that are not under Microsoft.ML.StaticPipe:\r\nhttps://github.com/dotnet/machinelearning/blob/dd46276cc257e20fe09239aeedb2f25c4bded6dd/src/Microsoft.ML.Transforms/MissingValueIndicatorTransformer.cs\r\nhttps://github.com/dotnet/machinelearning/blob/dd46276cc257e20fe09239aeedb2f25c4bded6dd/src/Microsoft.ML.Data/Transforms/KeyToValue.cs\r\nhttps://github.com/dotnet/machinelearning/blob/dd46276cc257e20fe09239aeedb2f25c4bded6dd/src/Microsoft.ML.Transforms/KeyToVectorMapping.cs\r\nhttps://github.com/dotnet/machinelearning/blob/e74bc65524430a1e0ed06912bdb5c6c21ef8d158/src/Microsoft.ML.Transforms/Text/TextFeaturizingEstimator.cs\r\nhttps://github.com/dotnet/machinelearning/blob/dd46276cc257e20fe09239aeedb2f25c4bded6dd/src/Microsoft.ML.Transforms/MissingValueReplacing.cs\r\nhttps://github.com/dotnet/machinelearning/blob/dd46276cc257e20fe09239aeedb2f25c4bded6dd/src/Microsoft.ML.Data/Transforms/KeyToVector.cs'"
382919304,1693,"b'QUESTION: The ""pipeline"" is immutable; sometimes a chain of Estimators, sometimes a single Estimator. Easy to understand?'","b'This is just an observation of a possible risk. I\'m not saying that my hypothetical proposal below is better, since it is probably less flexible. I just would like to get feedback from the community about our current approach to double-check we\'re on the right path.\r\n\r\nThe fact that a ""pipeline"" sometimes is a ""chain of estimators"", but sometimes ""it can be"" a single estimator could be confusing for developers. For instance:\r\n\r\nIn this case ""dataProcessPipeline"" is a single Estimator of type `TextFeaturizingEstimator`:\r\n\r\n`var dataProcessPipeline = mlContext.Transforms.Categorical.MapValueToKey(""Area"", ""Label"")\r\n;`\r\n\r\nIn this other case below, ""dataProcessPipeline"" is a chain of estimators of type `EstimatorChain<TTrans>`, as soon as you call the first `Append()`:\r\n\r\n```\r\nvar dataProcessPipeline = mlContext.Transforms.Categorical.MapValueToKey(""Area"", ""Label"")\r\n                .Append(mlContext.Transforms.Text.FeaturizeText(""Title"", ""TitleFeaturized""))\r\n                .Append(mlContext.Transforms.Text.FeaturizeText(""Description"", ""DescriptionFeaturized""))\r\n                .Append(mlContext.Transforms.Concatenate(""Features"", ""TitleFeaturized"", ""DescriptionFeaturized""));\r\n```\r\n\r\nAlso, the fact that an EstimatorChain pipeline is created from its first element might also be confusing?\r\n\r\nSimplifying and in comparison, when you create a List or collection in C# you first create the List (the box) then add things/elements  into it. You usually don\'t create a collection of items from the first item but you create the ""box"" first, then add items. But that is for mutable collections. Not the same! :)\r\n\r\nIn the case of our current EstimatorChain it is using a more advanced pattern based on fluent API and immutable objects. Since each estimator and estimator-chain is immutable, when you append another estimator in reality you are creating a new estimator-chain and returning that new pipeline (estimator-chain).\r\n\r\n**QUESTION: Is this pattern clear or confusing for you?**\r\n\r\nA different approach based on a typical **mutable** collection could be something like the following (This is NOT how ML.NET currently works and might require different types):\r\n\r\n```\r\n//DataView with dataset\r\nIDataView trainingDataView = textLoader.Read(TrainDataPath);\r\n\t\t\r\n// Create an ""empty"" EstimatorChain, the ""box"", which would be mutable, as it\'ll be growing with items:\r\nvar dataProcessPipeline = MLContext.CreateEstimatorChain();\r\n\r\n// Add Estimators to the same chain/pipeline\r\ndataProcessPipeline.Append(mlContext.Transforms.CopyColumns(""FareAmount"", ""Label"");\r\ndataProcessPipeline.Append(mlContext.Transforms.Categorical.OneHotEncoding(""VendorId"", ""VendorIdEncoded""));\r\ndataProcessPipeline.Append(mlContext.Transforms.Normalize(inputName: ""TripTime"", mode: NormalizerMode.MeanVariance));\r\ndataProcessPipeline.Append(mlContext.Transforms.Concatenate(""Features"", ""VendorIdEncoded"", ""TripTime""));\r\n\r\n//... Peek data into the DataView, etc. if you want\r\n\r\n//Optional - Clone the pipeline with data transformations in case you want to reuse the dataProcessPipeline for parallel executions of additional trainers\r\nvar trainingPipeline = dataProcessPipeline.Clone();\r\n\r\n//Add trainer to the training pipeline\r\nvar sdcaTrainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(label: ""Label"", features: ""Features"");\r\ntrainingPipeline.Append(sdcaTrainer);\r\n\r\n//Train the model fitting to the dataSet\r\nvar trainedModel = trainingPipeline.Fit(trainingDataView);\r\n```\r\nIn this last code, when you execute dataProcessPipeline.Append(estimator) it is really appending an estimator into that current pipeline. \r\n\r\nIn comparison and shown below, with our current API, when adding a trainer, you have to ""catch"" the returned pipeline, as the estimator/trainer was added only to the returned new pipeline, not to the pipeline owning the method Append() you run.\r\n\r\n```\r\n//Add trainer to the training pipeline\r\nvar sdcaTrainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(label: ""Label"", features: ""Features"");\r\nvar trainingPipeline = dataProcessPipeline.Append(sdcaTrainer);\r\n\r\n//Train the model fitting to the dataSet\r\nvar trainedModel = trainingPipeline.Fit(trainingDataView);\r\n```\r\nThat\'s also why you don\'t need to clone the pipeline if you want to ""fork"" it, since every time you call Append() you are creating a new pipeline, so you could ""fork"" whenever you call .Append().\r\n\r\nAs summary, in our current API, .Append() is not appending anything into the current pipeline, but creating and returning a new pipeline (EstimatorChain) with that new estimator appended.\r\n\r\nOur current approach is probably more flexible based on immutable EstimatorChains but I\'d like to double check if our current approach is clear for anyone learning the API.\r\n\r\n What are your thoughts about it?\r\nCan you provide your feedback? \xf0\x9f\x91\x8d \r\nThanks, \r\n \r\n\r\n'"
382906847,1690,b'Rename mlContext.Data.TextReader() to mlContext.Data.CreateTextLoader()',"b'Since the object being created is a ""TextLoader"", I\'d recommend the method\'s name to say so, instead of ""TextReader"" which looks like a different type. \r\n\r\nI mean code like the following feels confusing:\r\n\r\n```\r\n            TextLoader textLoader = mlContext.Data.TextReader(new TextLoader.Arguments()\r\n                                                    {\r\n                                                        Separator = ""tab"",\r\n                                                        HasHeader = true,\r\n                                                        Column = new[]\r\n                                                                    {\r\n                                                                    new TextLoader.Column(""Label"", DataKind.Bool, 0),\r\n                                                                    new TextLoader.Column(""Text"", DataKind.Text, 1)\r\n                                                                    }\r\n                                                    });\r\n```\r\n\r\nIn addition to that, methods should have a verb as part of the name, so if what it is doing is to create a TextReader, let\'s say so, as:\r\n\r\nmlContext.Data.CreateTextLoader()\r\n\r\nWe\'re not being consistent now when having some methods with a verb but other methods just a noun:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/48811328-18f0d300-ece2-11e8-8d31-2e2fad81ab60.png)\r\n\r\nIt is also against C# conventions (and most languages). A method\'s name should have a verb describing the action being performed by that method:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/names-of-type-members#names-of-methods'"
382904365,1689,"b'Include the ""save file"" action (.ZIP file) as part of model.SaveFile()'","b'Currently, whenever we are saving a .ZIP model file, you always need to handle the code for the File stream class.\r\n\r\nI think that is repetitive code that could be included in the API.\r\nInstead of:\r\n\r\n```\r\nusing (var fs = new FileStream(ModelPath, FileMode.Create, FileAccess.Write, FileShare.Write))\r\n                mlContext.Model.Save(trainedModel, fs);\r\n```\r\n\r\nWe could have an overridden method so I could simply do the following:\r\n\r\n`mlContext.Model.Save(trainedModel, modelPath);`\r\n\r\nOr even the following, if those methods were part of the model class itself instead of a utility class in the MLContext:\r\n\r\n`model.Save(modelPath);`\r\n\r\nCurrently, this kind of line using the file stream class is something you need to repeat over and over in every/most training app (even when the constructor can be simplified):\r\n\r\n`using (var fs = new FileStream(ModelPath, FileMode.Create, FileAccess.Write, FileShare.Write))`\r\n\r\nHandling a FileStream object might should not be mandatory for the user **but optional**:\r\n\r\nOf course, I would also maintain the current methods because in some cases you might want to just provide an existing stream object, but as opt-in.\r\n'"
382878508,1688,b'CpuMath has a bad project reference to ML.Core',"b'See https://github.com/dotnet/machinelearning/pull/1659#discussion_r235195505\r\n\r\nWe recently made CpuMath depend on ML.Core, but this is broken.\r\n\r\nThe `Microsoft.ML` nuget package depends on the `Microsoft.ML.CpuMath` NuGet package.  So having the CpuMath.dll depend on `Microsoft.ML.Core` is backwards.\r\n\r\nSee https://github.com/dotnet/machinelearning/pull/542 for the reasoning why this was done that way.'"
382790848,1685,b'MapValueToKey and MapKeyToValue in different catalogs',"b'The `MapValueToKey` transform is currently in the `Categorical` transforms catalog, whereas the `MapKeyToValue` transform is in the `Conversion` transforms catalog. \r\n\r\nWould it be more helpful to have both of these in the same catalog, as the latter transform is often needed to reverse the former? Otherwise a user might not realize that a transform exists to convert back from key to value when they look in the original catalog they used.'"
382786531,1684,b'Obsolete the Legacy API',"b'As long planned, we want to obsolete the Legacy API in the 0.8 release.\r\nNamely: \r\n- Mark everything in `Legacy` assembly to be `[Obsolete]`.\r\n- For all our tests that trigger the obsolete warning, suppress the warning.\r\n- For all our code that triggers the obsolete warning, either fix to not rely on `Legacy`, or make obsolete, or remove.'"
382454170,1679,b'Cannot access GAM model parameters from a trained model',"b'When we train a GAM model, we want to inspect the features, just as we do a linear model. Currently, the only way we can do this is through the `SaveSummary()` command, where we pass in a `StringBuilder` object.\r\n\r\nI propose adding public methods to the GAM objects to fetch back the `intercept` (bias / baseline prediction), `feature-indices`, and `feature-index-weights`. This would allow for inspection of the model parameters within the .NET runtime.\r\n'"
382432417,1675,b'What the Feature Scorer for FastTree Ranking',"b'Potential bug from a customer: `What-The-Feature scorer` is not computing feature contributions for `FastTree Ranking`.\r\n\r\nNeeds to first be reproduced with a sample dataset in ML.NET, then can be triaged as a bug or non-issue.\r\n\r\nReference Issue for WTF: #1644 '"
382400022,1673,b'How to use LinearSvm?',"b""Sorry if this is not the place for questions.\r\n\r\nCurrently I'm using FastTree for binary classification, but I would like to give SVM a try and compare metrics.\r\n\r\nAll the docs mention LinearSvm, but I can't find code example anywhere.\r\n\r\n`mlContext.BinaryClassification.Trainers` does not have public SVM trainers. There is `LinearSvm` class and `LinearSvm.TrainLinearSvm` static method, but they seem to be intended for different things.\r\n\r\nWhat am I missing? \r\n\r\n**Version: 0.7**"""
382392863,1672,b'Low discrepancy random ',"b'Low discrepancy random sweeper (LDRand) should be moved to the external repo. \r\n\r\nLDRand was held back in the internal repo due to a dependence on the MKL library. This issue has been resolved, and I think we are now able to move this code.'"
382315922,1669,b'Float v.s float',"b""In ML.NET codebase, one can see two different names for 32-bit float type. Recent PR uses `float` while [old places](https://github.com/dotnet/machinelearning/blob/e0906608ca0d37ad0c10ba647e83b45990afde43/src/Microsoft.ML.Sweeper/ISweeper.cs#L5) have `Float`. It'd be nice to have only one of the two styles."""
382070777,1668,b'14 TB of Hundreds of Thousands of Input Files For Training?',"b'I am sorry if this was answered, but the closest I could find is this:\r\nhttps://github.com/dotnet/machinelearning/issues/192\r\n\r\nWhich looks to have an answer of specifying all the related files.\r\n`var data = reader.Read(exampleFile1, exampleFile2);`\r\n\r\nThe other tutorials on Microsoft all used a single file.\r\n\r\nI am looking at something to examine about 14 Terabytes worth of data within hundreds of thousands of files across multiple hard drives.  Because of the size there would not really be any way to store that in memory either.  \r\n\r\nCould I use ML.NET for this problem?\r\n'"
382070208,1667,b'Crash in OnlineGradientDescentRegressor',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan AutoML\r\n- **What happened?**\r\nException below\r\n\r\n### Source code / logs\r\n\r\nException:\r\n```\r\nTrainers.OnlineGradientDescentRegressor{LearningRate:1, DecreaseLearningRate:True, L2RegularizerWeight:0.3115694, NumIterations:7, InitWtsDiameter:0.537725, Shuffle:True} Crashed System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.InvalidOperationException: The weights/bias contain invalid values (NaN or Infinite). Potential causes: high learning rates, no normalization, high initial weights, etc.\r\n   at Microsoft.ML.Runtime.Contracts.Check(IExceptionContext ctx, Boolean f, String msg) in C:\\MLDotNet\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 501\r\n   at Microsoft.ML.Trainers.Online.OnlineLinearTrainer`2.TrainModelCore(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.StandardLearners\\Standard\\Online\\OnlineLinear.cs:line 275\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 93\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 159\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor, RoleMappedData testData) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 276\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 245\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 189\r\n   at Microsoft.ML.Trainers.Online.OnlineGradientDescentTrainer.TrainRegression(IHostEnvironment env, Arguments input) in C:\\MLDotNet\\src\\Microsoft.ML.StandardLearners\\Standard\\Online\\OnlineGradientDescent.cs:line 178\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run() in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 826\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 1022\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros() in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\GraphRunner.cs:line 67\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll() in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\GraphRunner.cs:line 55\r\n   at Microsoft.ML.Runtime.Experiment.Run() in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\Experiment\\Experiment.cs:line 130\r\n   at Microsoft.ML.Runtime.PipelineInference.PipelinePattern.RunTrainTestExperiment(IDataView trainData, IDataView testData, SupportedMetric metric, TrainerKinds trainerKind, Double& testMetricValue, Double& trainMetricValue) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\PipelinePattern.cs:line 212\r\n   at Microsoft.ML.Runtime.PipelineInference.AutoInference.AutoMlMlState.ProcessPipeline(SweeperProbabilityUtils utils, Stopwatch stopwatch, PipelinePattern candidate, Int32 numOfTrainingRows) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoInference.cs:line 251\r\n   at Microsoft.ML.Runtime.PipelineInference.AutoInference.AutoMlMlState.MainLearningLoop(Int32 batchSize, Int32 numOfTrainingRows) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoInference.cs:line 224\r\n```'"
382069907,1666,b'Exception in AutoML Hyperparam Sweeper',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Source code / logs\r\n```\r\nSystem.InvalidOperationException: Value not in correct range\r\n   at Microsoft.ML.Runtime.Contracts.Check(Boolean f, String msg) in C:\\MLDotNet\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 496\r\n   at Microsoft.ML.Runtime.Sweeper.FloatValueGenerator.NormalizeValue(IParameterValue value) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Parameters.cs:line 442\r\n   at Microsoft.ML.Runtime.Sweeper.Algorithms.SweeperProbabilityUtils.ParameterSetAsFloatArray(IHost host, IValueGenerator[] sweepParams, ParameterSet ps, Boolean expandCategoricals) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Algorithms\\SweeperProbabilityUtils.cs:line 207\r\n   at Microsoft.ML.Runtime.Sweeper.Algorithms.KdoSweeper.SampleChild(ParameterSet parent, Double fitness, Int32 n, IRunResult[] previousRuns, Double rMean, Double rVar, Boolean isMetricMaximizing) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Algorithms\\KdoSweeper.cs:line 206\r\n   at Microsoft.ML.Runtime.Sweeper.Algorithms.KdoSweeper.GenerateChildConfigurations(IRunResult[] history, Int32[] parentIndicies, Double[] weights, IRunResult[] previousRuns, Double rMean, Double rVar) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Algorithms\\KdoSweeper.cs:line 187\r\n   at Microsoft.ML.Runtime.Sweeper.Algorithms.KdoSweeper.GenerateCandidateConfigurations(Int32 numOfCandidates, IRunResult[] previousRuns) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Algorithms\\KdoSweeper.cs:line 176\r\n   at Microsoft.ML.Runtime.Sweeper.Algorithms.KdoSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns) in C:\\MLDotNet\\src\\Microsoft.ML.Sweeper\\Algorithms\\KdoSweeper.cs:line 153\r\n   at Microsoft.ML.Runtime.PipelineInference.PipelineOptimizerBase.SampleHyperparameters(SuggestedLearner learner, ISweeper sweeper, Boolean isMaximizingMetric, PipelinePattern[] history) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\Interfaces\\IPipelineOptimizer.cs:line 143\r\n   at Microsoft.ML.Runtime.PipelineInference.RocketEngine.SampleHyperparameters(SuggestedLearner learner, PipelinePattern[] history) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoMlEngines\\RocketEngine.cs:line 128\r\n   at Microsoft.ML.Runtime.PipelineInference.RocketEngine.NextCandidates(PipelinePattern[] history, Int32 numCandidates, Boolean defaultHyperParams, Boolean uniformRandomTransforms) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoMlEngines\\RocketEngine.cs:line 309\r\n   at Microsoft.ML.Runtime.PipelineInference.RocketEngine.GetNextCandidates(IEnumerable`1 history, Int32 numCandidates, RoleMappedData dataRoles) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoMlEngines\\RocketEngine.cs:line 266\r\n   at Microsoft.ML.Runtime.PipelineInference.AutoInference.AutoMlMlState.MainLearningLoop(Int32 batchSize, Int32 numOfTrainingRows) in C:\\MLDotNet\\src\\Microsoft.ML.PipelineInference\\AutoInference.cs:line 213\r\n```'"
382069406,1665,"b'AutoML seeks to minimize RSquared, instead of maximize it'","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\nAutoML seeks to minimize RSquared, instead of maximize it --\r\nhttps://github.com/dotnet/machinelearning/blob/e0906608ca0d37ad0c10ba647e83b45990afde43/src/Microsoft.ML.PipelineInference/PipelineSweeperSupportedMetrics.cs#L84'"
381854072,1662,b'Will there be ML.NET support for ARM applications?',b'Build 0.7 introduced support for x86 applications.\r\nWill ARM support also be included? \r\nExamples of usages are Always Connected Windows 10/Linux laptops running ARM processors\r\n\r\n.NET Core supports ARM so the route to enable it should be possible'
381815949,1660,b'ReadOnlyMemory<char> codec fails if we write and then read empty vector',"b'How to reproduce:\r\nGo to WordBagWorkout test and set WordHashBagEstimator to have invertHash to be -1\r\n`Append(new WordHashBagEstimator(Env, ""text"", ""bag_of_wordshash"", invertHash:-1));`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bc6d7f463258eb4fc9af5ce55b9b426b626312fe/src/Microsoft.ML.Data/Transforms/InvertHashUtils.cs#L397\r\n\r\nthis thing will try to save VBuffer<ReadOnlyMemory<char>> with size of 65536 and empty values and indices arrays.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/bc6d7f463258eb4fc9af5ce55b9b426b626312fe/src/Microsoft.ML.Data/Transforms/InvertHashUtils.cs#L363\r\nthis thing will try to read it and fails on\r\n`ch.CheckDecode(stream.ReadByte() == -1);`\r\n\r\nIn case of empty VBuffer we currently write following information:\r\n4 bytes: How many vectors we have - 1\r\n4 bytes: Size of all vectors - 65536\r\n4 bytes: Counts for each vector - 0\r\n4 bytes: size of indices array  - 0\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d0522f36699f7acf1879645c2570e3c4094946ee/src/Microsoft.ML.Data/DataLoadSave/Binary/Codecs.cs#L1054\r\nprevents stops us from reading further in stream because we determine absence of values.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d0522f36699f7acf1879645c2570e3c4094946ee/src/Microsoft.ML.Data/DataLoadSave/Binary/Codecs.cs#L870\r\nthis code responsible for filling buffer during save\r\nwe write same things:\r\n4 bytes: How many vectors we have - 1\r\n4 bytes: Size of all vectors - 65536\r\n4 bytes: Counts for each vector - 0\r\n4 bytes: size of indices array  - 0\r\nPlus content of value writer which is stream with size of vector and builder you need to use to populate it during reading. \r\n5 bytes: 0 + """"\r\n\r\nWhich brings inconsistency and exception\r\n\r\n\r\n'"
381707652,1653,"b""DifferentiableFunctionAggregator doesn't appear to be used - can we delete it?""","b""See the comment on https://github.com/dotnet/machinelearning/pull/1650/files#r234085400.\r\n\r\nWe don't appear to be using this class at all. We should investigate removing it. And if we decide we need it, we should put it under some tests."""
381672814,1652,b'SCDA Summary Not Sorted',"b'The `Summary()` for `SDCA` does not sort the output by the feature index. This makes it difficult to read. For reference, `OLS` does sort by the feature index and is easy to read.\r\n\r\nVersion: ML.NET 0.7 Release\r\n\r\nExample `Summary()` output:\r\n```\r\nLinear Regression Predictor non-zero weights\r\n\r\n(Bias)  -0.4338956\r\n15      0.8659377\r\n14      0.6250594\r\n0       0.5953168\r\n7       -0.5625336\r\n6       -0.5331995\r\n8       -0.5284117\r\n5       -0.450398\r\n9       -0.430093\r\n13      0.3840194\r\n1       0.3470894\r\n4       -0.3077467\r\n10      -0.2826627\r\n12      0.1388556\r\n3       -0.1202137\r\n2       0.103458\r\n11      -0.09171117\r\n```'"
381630876,1651,b'Monotone_constraints in LightGbm',b'In my ML problem I get significantly better results from `LightGbm` by using the `monotone_constraints`  [parameter](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst#monotone_constraints). I can not see that this is available through the ML.NET interface. Could this be added?'
381419309,1649,"b""Tensorflow Transform Doesn't Accept Key-typed Labels""","b""In the current Tensorflow tests, I tried changing its label type from I8 to U4[0:9] but then I couldn't retrain Tensorflow anymore."""
381417223,1648,b'Change FastTree BinFinder to use floats and remove one data copy',"b""See the conversation here: https://github.com/dotnet/machinelearning/pull/1580#discussion_r233672947\r\n\r\nWith the above change, I made it so the FastTree `BinFinder.FindDistinctCounts` was no longer destructive of the `values` VBuffer during `CalculateBins`.\r\n\r\nNow that it no longer destroys the buffer, we no longer need to copy it here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb9effcd091c60fa291aad96cc18c14ddf841b6f/src/Microsoft.ML.FastTree/FastTree.cs#L1475-L1478\r\n\r\nHowever, I couldn't easily remove this copy because doing the copy also changed the VBuffer from `float` to `double`. This should also be changed, as recognized by this `REVIEW` comment in the code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb9effcd091c60fa291aad96cc18c14ddf841b6f/src/Microsoft.ML.FastTree/FastTree.cs#L2408\r\n\r\nThis issue is to fix both of these things. First, change BinFinder to work on `float` instead of `double`. Then, we can remove this extra copy and just pass in the normal `VBuffer<float>` to `BinFinder`, without worrying if it will destroy the buffer.\r\n\r\n/cc @Zruty0 @TomFinley """
381392159,1645,b'Add Documentation for GAM Trainers',"b""As @sfilipi pointed out on a PR #1642, the GAM trainers don't have samples available in the dynamic API. I suggest that we add samples to show how to use these learners.\r\n\r\n@sfilipi 's comment:\r\n```\r\nMy new comment on every PR that touches the catalogs: how do you feel about writing a sample for this, and referencing it here :)\r\n\r\nsee: https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/SDCA.cs\r\n\r\nand its reference:\r\nhttps://github.com/dotnet/machinelearning/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs\r\n```"""
381384611,1644,b'WhatTheFeature Scorer is Missing in ML.NET',b'The ML.NET codebase has definitions for `IWhatTheFeatureValueMapper` and implementations for linear models and tree models. I would like to see a scorer in ML.NET that can produce these feature importance scores.'
381378302,1643,b'GenerateCodeCommand bug',"b""This command has a replacementMap dictionary, and it uses it to find the keys in the generated code template and replace them with the values. But there is one pair in the dictionary with a key that doesn't exist in the template."""
381360916,1640,"b""'Ignore' not respected in schema""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nRan MML command line: execgraph ""C:\\Benchmarking\\automl_graph.json""\r\n\r\nContents of automl_.graph.json:\r\n\r\n```json\r\n{\r\n  ""Inputs"": {\r\n    ""file_train"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv"",\r\n    ""file_test"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv""\r\n  },\r\n  ""Nodes"": [\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:0 col=Features:R4:1-13 col=Cat:TX:14 col=Cat01:TX:15 col=Ignore:TX:16,25 col=Cat02:TX:17 col=Cat03:TX:18 col=Cat04:TX:19 col=Cat05:TX:20 col=Cat06:TX:21 col=Cat07:TX:22 col=Cat08:TX:23 col=Cat09:TX:24 col=Cat10:TX:26 col=Cat11:TX:27 col=Cat12:TX:28 col=Cat13:TX:29 col=Cat14:TX:30 col=Cat15:TX:31 col=Cat16:TX:32 col=Cat17:TX:33 col=Cat18:TX:34 col=Cat19:TX:35 col=Cat20:TX:36 col=Cat21:TX:37 col=Cat22:TX:38 col=Cat23:TX:39"",\r\n        ""InputFile"": ""$file_train""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_train""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:0 col=Features:R4:1-13 col=Cat:TX:14 col=Cat01:TX:15 col=Ignore:TX:16,25 col=Cat02:TX:17 col=Cat03:TX:18 col=Cat04:TX:19 col=Cat05:TX:20 col=Cat06:TX:21 col=Cat07:TX:22 col=Cat08:TX:23 col=Cat09:TX:24 col=Cat10:TX:26 col=Cat11:TX:27 col=Cat12:TX:28 col=Cat13:TX:29 col=Cat14:TX:30 col=Cat15:TX:31 col=Cat16:TX:32 col=Cat17:TX:33 col=Cat18:TX:34 col=Cat19:TX:35 col=Cat20:TX:36 col=Cat21:TX:37 col=Cat22:TX:38 col=Cat23:TX:39"",\r\n        ""InputFile"": ""$file_test""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_test""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""BatchSize"": 3,\r\n        ""StateArguments"": {\r\n          ""Name"": ""AutoMlState"",\r\n          ""Settings"": {\r\n            ""Engine"": {\r\n              ""Name"": ""Rocket"",\r\n              ""Settings"": {}\r\n            },\r\n            ""Metric"": ""Accuracy"",\r\n            ""TerminatorArgs"": {\r\n              ""Name"": ""IterationLimited"",\r\n              ""Settings"": {\r\n                ""FinalHistoryLength"": 100\r\n              }\r\n            },\r\n            ""TrainerKind"": ""SignatureBinaryClassifierTrainer""\r\n          }\r\n        },\r\n        ""TestingData"": ""$data_test"",\r\n        ""TrainingData"": ""$data_train""\r\n      },\r\n      ""Name"": ""Models.PipelineSweeper"",\r\n      ""Outputs"": {\r\n        ""Results"": ""$output_data"",\r\n        ""State"": ""$xyz""\r\n      }\r\n    }\r\n  ],\r\n  ""Outputs"": {\r\n    ""output_data"": ""C:\\\\Benchmarking\\\\01-ResultsOut.csv""\r\n  }\r\n}\r\n```\r\n\r\n- **What happened?**\r\nEven though Ignore:TX:16,25 is specified in the schema, the learners start expensive / slow text transforms / n-gram extractions on the columns\r\n\r\n- **What did you expect?**\r\nThe columns to be ignored'"
381360693,1639,b'Precedence between main arguments and advancedSettings',"b""In some learnings, for example [GAM](https://github.com/dotnet/machinelearning/blob/8a45f37cf87e380a93146d08acac19f215648f9a/src/Microsoft.ML.FastTree/GamTrainer.cs#L135), the [APIs specify a set of default values](https://github.com/dotnet/machinelearning/blob/8a45f37cf87e380a93146d08acac19f215648f9a/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L110), with an optional advanced settings argument.\r\n\r\nOftentimes, as is the case with GAMs, this means that there are two ways to specify the value for a parameter -- as a main line item, or in the advanced settings. In the GAM code, the main line items are applied, followed by the advanced settings. There is no normalization that occurs., meaning that options in the advanced settings can override options set in the main line items.\r\n\r\nIs there supposed to be precedence here, or is there any way to make the APIs simpler so that there is only one way to specify a parameter? I'd love to hear people's thoughts on this.\r\n\r\nI don't know of any bugs caused by this, but this seems like the kind of thing that can cause unintentional behavior."""
381317493,1636,b'Recovering ITransformers from Predictor Objects',"b'Oftentimes it is necessary to have an actual object of a predictor, such as a `RegressionGAMPredictor` or `LinearRegressionPredictor` to access methods particular to the predictor. However, it is a bit cumbersome to get back to the `ITransformer` interface. One must manually create a `RegressionPredictionTransformer` like so:\r\n\r\n```\r\nvar linearTransformer = new RegressionPredictionTransformer<LinearRegressionPredictor>(mlContext, linearPredictor, trainSet.Schema, ""Features"");\r\n```\r\n\r\nI\'d like to see all the predictor objects support a method like `AsTransformer()` to return an `ITransformer`. It seems like the predictor objects have enough information to automate the process, and it would make the APIs much easier to use.'"
381317275,1635,b'TrainTestSplit random seed',"b'I am repeatedly calling `TrainTestSplit` for a data set (for cross validation) and see that the resulting split is the same every call. In sklearn, the `train_test_split` function has the possibility of taking a seed for a random number generator as an input. Could this be added also in ML.NET?'"
381315599,1634,"b'Normalization option, FixZero, is not available in high-level APIs'","b'When I perform minmax normalization on dense datasets, I like to turn off ""fixzero"". This option is not available in the high-level APIs, e.g. `mlContext.Transforms.Normalize()`.\r\n\r\nTo use this, you need to go back and create `AffineColumn` and `MinMaxArguments` objects and use the old-style `Create` API:\r\n```\r\nvar column = new NormalizeTransform.AffineColumn() { Name = ""Index0"", FixZero = false };\r\nvar minMaxArgs = new NormalizeTransform.MinMaxArguments() { FixZero = false, Column = new NormalizeTransform.AffineColumn[1] { column } };\r\nIDataView transform = NormalizeTransform.Create(mlContext, minMaxArgs, loader);\r\n```\r\n\r\nI think these old-style APIs are very confusing to use, especially since there are two ways to specify `FixZero`, and it\'s unclear which one is used and if there is precedence between them.'"
381309646,1633,b'Marshal.Invoke cannot be called with a method that has a generic return type',b'In DataViewConstructionUtils.cs there is a method GetGetterDelegate() that calls Marshal.Invoke with GetGetter<int> that has a generic return type (ValueGetter<TDst>).\r\n'
381306251,1632,"b""NGramHashTransform doesn't provide slot names""","b""There is an argument in the Arguments class to provide slot names, however the resulting schema doesn't contain this metadata."""
381302940,1631,b'The top-level APIs do not support validation sets',"b'For learners that take validation sets like `GAM` and `FastTree`, there is no way to specify a `validation` set during `Fit()`.\r\n\r\nThis may be by design (because what does a validation set mean to a whole pipeline?), but it is very cumbersome to work around.\r\n\r\nDoes anyone have thoughts on how we can make the `validation` process easy to use and simple to understand?'"
381301341,1630,b'GAM Default Arguments in the Dynamic API are incompatible with GAMs',"b""The new high-level APIs for GAMs are incorrect and not descriptive of the common choices someone will make.\r\n\r\nIncorrect: They contain parameters that don't belong to the learner and contain duplicate parameters:\r\n- `NumTrees` is not a parameter for GAM\r\n- `NumLeaves` is not a parameter for GAM\r\n- There are two options for tuning the learning rate: `learningRate` and `advancedSettings.LearningRates`, each with a different default. It is unclear which one will be used, but the default value for `learningRate` will tend to produce poor fits.\r\n\r\nNot descriptive: The API puts the most basic and most used options into `advancedSettings`:\r\n- `NumIterations`: How many iterations to use to fit\r\n- `NumBins`: How densely to draw the curves."""
381289112,1629,b'StopWordsRemoverTransform uses a dictionary with ReadOnlyMemory<char> keys',"b'This transform contains a dictionary to find the language of each example, and this bug causes the language to not be found in the dictionary.'"
381286268,1628,b'Bug in PKPD',"b'In the GetMapper() method of PkpdPredictor, there is a double[] buffer that holds the scores of each individual predictor, however it is initialized to be the length of _numClasses instead of _mappers.Length.'"
381286178,1627,b'Binary Saving and Loading from MLContext',"b'MLContext should have extensions for loading and saving binary files, like it currently has for text files. Specifically, add:\r\n\r\n- `MLContext.Data.SaveAsBinary`, corresponding to `MLContext.Data.SaveAsText`\r\n- `MLContext.Data.ReadFromBinaryFile`, corresponding to `MLContext.Data.ReadFromTextFile`'"
380997843,1625,b'LightGBM trainer exception',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nRan MML command line: execgraph ""C:\\Benchmarking\\automl_graph.json""\r\n\r\nContents of automl_.graph.json:\r\n\r\n```json\r\n{\r\n  ""Inputs"": {\r\n    ""file_train"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv"",\r\n    ""file_test"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv""\r\n  },\r\n  ""Nodes"": [\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n        ""InputFile"": ""$file_train""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_train""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n        ""InputFile"": ""$file_test""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_test""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""BatchSize"": 3,\r\n        ""StateArguments"": {\r\n          ""Name"": ""AutoMlState"",\r\n          ""Settings"": {\r\n            ""Engine"": {\r\n              ""Name"": ""Rocket"",\r\n              ""Settings"": {}\r\n            },\r\n            ""Metric"": ""Accuracy"",\r\n            ""TerminatorArgs"": {\r\n              ""Name"": ""IterationLimited"",\r\n              ""Settings"": {\r\n                ""FinalHistoryLength"": 100\r\n              }\r\n            },\r\n            ""TrainerKind"": ""SignatureBinaryClassifierTrainer""\r\n          }\r\n        },\r\n        ""TestingData"": ""$data_test"",\r\n        ""TrainingData"": ""$data_train"",\r\n\t\t""IgnoreColumns"": [""cost""]\r\n      },\r\n      ""Name"": ""Models.PipelineSweeper"",\r\n      ""Outputs"": {\r\n        ""Results"": ""$output_data"",\r\n        ""State"": ""$xyz""\r\n      }\r\n    }\r\n  ],\r\n  ""Outputs"": {\r\n    ""output_data"": ""C:\\\\Benchmarking\\\\01-ResultsOut.csv""\r\n  }\r\n}\r\n```\r\n\r\n- **What happened?**\r\nEncountered an exception in LightGBM trainer\r\n\r\n- **What did you expect?**\r\nA run to completion, w/o exception\r\n\r\n### Source code / logs\r\n\r\n--- Command line args ---\r\n`dotnet MML.dll execgraph C:\\Benchmarking\\automl_graph.json`\r\n\r\n--- Exception message ---\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Categorical split features is zero length\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Contracts.Check(Boolean f, String msg) in C:\\MLDotNet\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 497\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree.CheckValid(Action`2 checker) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 469\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree..ctor(Int32[] splitFeatures, Double[] splitGain, Double[] gainPValue, Single[] rawThresholds, Single[] defaultValueForMissing, Int32[] lteChild, Int32[] gtChild, Double[] leafValues, Int32[][] categoricalSplitFeatures, Boolean[] categoricalSplit) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 223\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree.Create(Int32 numLeaves, Int32[] splitFeatures, Double[] splitGain, Single[] rawThresholds, Single[] defaultValueForMissing, Int32[] lteChild, Int32[] gtChild, Double[] leafValues, Int32[][] categoricalSplitFeatures, Boolean[] categoricalSplit) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 189\r\n   at Microsoft.ML.Runtime.LightGBM.Booster.GetModel(Int32[] categoricalFeatureBoudaries) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\WrappedLightGbmBooster.cs:line 241\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.TrainCore(IChannel ch, IProgressChannel pch, Dataset dtrain, CategoricalMetaData catMetaData, Dataset dvalid) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 378\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.TrainModelCore(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 126\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 92\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 254\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 223\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 189\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbm.TrainBinary(IHostEnvironment env, LightGbmArguments input) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmBinaryTrainer.cs:line 189\r\n```'"
380946591,1623,b'GeneralizedAdditiveModels is referred to as GeneralizedAdditiveMethods',"b'`Generalized Additive Models` (aka `GAM`) are referred to as `Generalized Additive Methods` in the new API. See [here](https://github.com/dotnet/machinelearning/blob/851558d93f509372769ba802e0c81364fa6d55ed/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L110) for classification, [here](https://github.com/dotnet/machinelearning/blob/851558d93f509372769ba802e0c81364fa6d55ed/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L133) for regression.\r\n\r\nThe API should be `GeneralizedAdditiveModels`.\r\n'"
380933190,1622,b'Calibration estimators in ML.NET',"b""In the discussions for #1579,  one of the  proposals was to introduce calibration estimators in ML.NET.  \r\n\r\n<snip>  (from #1579)\r\n\r\n.... a calibrator is just one peculiar form of trainer: it learns a monotonous function that transforms 'scores' into 'probabilities', with the goal to minimize the log-loss against the 'target label'. So, it is actually a univariate classification trainer. We should create a `PlattCalibrationEstimator` to train Platt calibrators and a `PavCalibrationEstimator` to train PAV calibrators.\r\n\r\n</snip>\r\n\r\n@Zruty0  @yaeldekel """
380502949,1617,b'How to get data from IDataView',"b'How can I get data from IDataView without a class for the record?\r\nFor instance convert IDataView to object[,] just by querying the Schema\r\nThanks,\r\nNestor'"
380470007,1616,b'Expose the parameters of the NormalizerTransformer',b'The various flavors of the NormalizerTransformer have non-public visibility over the parameters. Users need to be able to inspect those values.  '
380390895,1615,b'Rocket AutoML engine stops very early',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\nThe Rocket AutoML engine stops very early for numerical datasets. For a numerical binary classification problem, the engine always stops after 14 iterations.\r\nThe Rocket engine makes it successfully thru its first stage, running all 12 landmark algorithms. Then, the engine makes it into its second stage, and runs thru one batch of the top 2 two algorithms. After that, the engine stops, never making it to stage 3, 4, etc.\r\n'"
380387202,1614,b'Cannot select accuracy as target metric',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\nCannot select \'Accuracy\' as target metric\r\n\r\n- **What did you do?**\r\nRan MML command line: `dotnet MML.dll execgraph ""C:\\Benchmarking\\automl_graph.json`\r\n\r\nContents of automl_.graph.json:\r\n```json\r\n{\r\n\t""Inputs"": {\r\n\t\t""file_train"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv"",\r\n\t\t""file_test"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv""\r\n\t},\r\n\t""Nodes"": [{\r\n\t\t\t""Inputs"": {\r\n\t\t\t\t""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n\t\t\t\t""InputFile"": ""$file_train""\r\n\t\t\t},\r\n\t\t\t""Name"": ""Data.CustomTextLoader"",\r\n\t\t\t""Outputs"": {\r\n\t\t\t\t""Data"": ""$data_train""\r\n\t\t\t}\r\n\t\t},\r\n\t\t{\r\n\t\t\t""Inputs"": {\r\n\t\t\t\t""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n\t\t\t\t""InputFile"": ""$file_test""\r\n\t\t\t},\r\n\t\t\t""Name"": ""Data.CustomTextLoader"",\r\n\t\t\t""Outputs"": {\r\n\t\t\t\t""Data"": ""$data_test""\r\n\t\t\t}\r\n\t\t},\r\n\t\t{\r\n\t\t\t""Inputs"": {\r\n\t\t\t\t""BatchSize"": 3,\r\n\t\t\t\t""StateArguments"": {\r\n\t\t\t\t\t""Name"": ""AutoMlState"",\r\n\t\t\t\t\t""Settings"": {\r\n\t\t\t\t\t\t""Engine"": {\r\n\t\t\t\t\t\t\t""Name"": ""Rocket"",\r\n\t\t\t\t\t\t\t""Settings"": {}\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Metric"": ""Accuracy"",\r\n\t\t\t\t\t\t""TerminatorArgs"": {\r\n\t\t\t\t\t\t\t""Name"": ""IterationLimited"",\r\n\t\t\t\t\t\t\t""Settings"": {\r\n\t\t\t\t\t\t\t\t""FinalHistoryLength"": 100\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""TrainerKind"": ""SignatureBinaryClassifierTrainer""\r\n\t\t\t\t\t}\r\n\t\t\t\t},\r\n\t\t\t\t""TestingData"": ""$data_test"",\r\n\t\t\t\t""TrainingData"": ""$data_train""\r\n\t\t\t},\r\n\t\t\t""Name"": ""Models.PipelineSweeper"",\r\n\t\t\t""Outputs"": {\r\n\t\t\t\t""Results"": ""$output_data"",\r\n\t\t\t\t""State"": ""$xyz""\r\n\t\t\t}\r\n\t\t}\r\n\t],\r\n\t""Outputs"": {\r\n\t\t""output_data"": ""C:\\\\Benchmarking\\\\01-ResultsOut.csv""\r\n\t}\r\n}\r\n```\r\n\r\n- **What happened?**\r\nAn exception was thrown (below)\r\n\r\n- **What did you expect?**\r\nA successful run\r\n\r\n### Source code / logs\r\n\r\n--- Command line args ---\r\n`dotnet MML.dll execgraph C:\\Benchmarking\\automl_graph.json`\r\n\r\n--- Exception message ---\r\n```\r\n(1) Unexpected exception: Requested value \'Accuracy\' is not a member of the Enum type \'Metrics\', \'System.InvalidOperationException\'\r\n\r\nException context:\r\n    Throwing component: Environment\r\n\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.InputBuilder.ParseJsonValue(IExceptionContext ectx, Type type, Attributes attributes, JToken value, ComponentCatalog catalog) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBuilder.cs:line 441\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.InputBuilder.TrySetValueJson(String name, JToken value) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBuilder.cs:line 181\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.InputBuilder.GetComponentJson(IExceptionContext ectx, Type signatureType, String name, JObject settings, ComponentCatalog catalog) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBuilder.cs:line 559\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.InputBuilder.ParseJsonValue(IExceptionContext ectx, Type type, Attributes attributes, JToken value, ComponentCatalog catalog) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBuilder.cs:line 485\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.InputBuilder.TrySetValueJson(String name, JToken value) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBuilder.cs:line 181\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.CheckAndSetInputValue(KeyValuePair`2 pair) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 680\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode..ctor(IHostEnvironment env, IChannel ch, RunContext context, String id, String entryPointName, JObject inputs, JObject outputs, Boolean checkpoint, String stageId, Single cost, String label, String group, String weight, String name) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 504\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.ValidateNodes(IHostEnvironment env, RunContext context, JArray nodes, String label, String group, String weight, String name) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 929\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph..ctor(IHostEnvironment env, JArray nodes) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 1003\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner..ctor(IHostEnvironment env, JArray nodes) in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\GraphRunner.cs:line 32\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.ExecuteGraphCommand.Run() in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\ExecuteGraphCommand.cs:line 62\r\n   at Microsoft.ML.Runtime.Tools.Maml.MainCore(ConsoleEnvironment env, String args, Boolean alwaysPrintStacktrace) in C:\\MLDotNet\\src\\Microsoft.ML.Maml\\MAML.cs:line 139\r\n```'"
380385102,1613,"b""Exception on 'IgnoreColumns' in input""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nRan MML command line: execgraph ""C:\\Benchmarking\\automl_graph.json""\r\n\r\nContents of automl_.graph.json:\r\n\r\n```json\r\n{\r\n  ""Inputs"": {\r\n    ""file_train"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv"",\r\n    ""file_test"": ""D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv""\r\n  },\r\n  ""Nodes"": [\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n        ""InputFile"": ""$file_train""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_train""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""CustomSchema"": ""sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+"",\r\n        ""InputFile"": ""$file_test""\r\n      },\r\n      ""Name"": ""Data.CustomTextLoader"",\r\n      ""Outputs"": {\r\n        ""Data"": ""$data_test""\r\n      }\r\n    },\r\n    {\r\n      ""Inputs"": {\r\n        ""BatchSize"": 3,\r\n        ""StateArguments"": {\r\n          ""Name"": ""AutoMlState"",\r\n          ""Settings"": {\r\n            ""Engine"": {\r\n              ""Name"": ""Rocket"",\r\n              ""Settings"": {}\r\n            },\r\n            ""Metric"": ""Accuracy"",\r\n            ""TerminatorArgs"": {\r\n              ""Name"": ""IterationLimited"",\r\n              ""Settings"": {\r\n                ""FinalHistoryLength"": 100\r\n              }\r\n            },\r\n            ""TrainerKind"": ""SignatureBinaryClassifierTrainer""\r\n          }\r\n        },\r\n        ""TestingData"": ""$data_test"",\r\n        ""TrainingData"": ""$data_train"",\r\n\t\t""IgnoreColumns"": [""cost""]\r\n      },\r\n      ""Name"": ""Models.PipelineSweeper"",\r\n      ""Outputs"": {\r\n        ""Results"": ""$output_data"",\r\n        ""State"": ""$xyz""\r\n      }\r\n    }\r\n  ],\r\n  ""Outputs"": {\r\n    ""output_data"": ""C:\\\\Benchmarking\\\\01-ResultsOut.csv""\r\n  }\r\n}\r\n```\r\n\r\n- **What happened?**\r\n\'IgnoreColumns\' in file is not respected / throws an exception (more details in logs section below)\r\n\r\n- **What did you expect?**\r\nA run w/o exception\r\n\r\n### Source code / logs\r\n\r\n--- Command line args ---\r\n`dotnet MML.dll execgraph C:\\Benchmarking\\automl_graph.json`\r\n\r\n--- Exception message ---\r\n```\r\n(1) Unexpected exception: Unexpected input: \'IgnoreColumns\', \'System.InvalidOperationException\'\r\n\r\nException context:\r\n    Throwing component: Environment\r\n\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.CheckAndSetInputValue(KeyValuePair`2 pair) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 686\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode..ctor(IHostEnvironment env, IChannel ch, RunContext context, String id, String entryPointName, JObject inputs, JObject outputs, Boolean checkpoint, String stageId, Single cost, String label, String group, String weight, String name) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 505\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.ValidateNodes(IHostEnvironment env, RunContext context, JArray nodes, String label, String group, String weight, String name) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 934\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph..ctor(IHostEnvironment env, JArray nodes) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\EntryPointNode.cs:line 1008\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner..ctor(IHostEnvironment env, JArray nodes) in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\GraphRunner.cs:line 32\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.ExecuteGraphCommand.Run() in C:\\MLDotNet\\src\\Microsoft.ML.Legacy\\Runtime\\EntryPoints\\JsonUtils\\ExecuteGraphCommand.cs:line 62\r\n   at Microsoft.ML.Runtime.Tools.Maml.MainCore(ConsoleEnvironment env, String args, Boolean alwaysPrintStacktrace) in C:\\MLDotNet\\src\\Microsoft.ML.Maml\\MAML.cs:line 139\r\n```'"
380368280,1611,"b""TextLoader should have only one constructor, that doesn't take Arguments as a parameter""","b'`TextLoader` needs to hide the constructor that has `Arguments`, and also expose the `HasHeader` and `SeparatorChars` to be non-advanced parameters.\r\n\r\n-- old description --\r\n`TextLoader` presently accepts a parameter called `column` for the array of columns to read. That seems odd, given that almost always, multiple columns are passed. Hence, it would be more natural to call that parameter `columns`.'"
380342654,1610,b'Make schema comprehension aware of images',"b""Image columns are backed by `Bitmap` objects under the hood. However, our standard schema comprehension is not capable of turning `Bitmap` fields into data view columns and vice versa.\r\n\r\nWe want to be able to add this capability, but without making Core assembly aware of the image type. This potentially calls for another application of MEF: being able to inject custom 'peek/poke generators' for schema comprehension. \r\n\r\n@TomFinley , do you think this is even a reasonable idea?\r\n\r\n@CESARDELATORRE ran into this need for some of the demos they were building. \r\ncc @yaeldekel """
380340740,1609,b'Add a transformer/estimator for loading images out of byte vectors',"b""Right now we can only load images from disk files. I think it's worthwhile to either update `ImageLoadingTransformer` to be able to load from byte vectors (interpreted as streams), or add another estimator/transformer to do this.\r\n\r\ncc @CESARDELATORRE @yaeldekel """
380309806,1608,b'Remove parsing perf bottleneck in WordEmbeddingsTransform',"b'I am currently profiling ML.NET to find performance bottlenecks and places where .NET framework could do a better perf job.\r\n\r\nI started with two the most time-consuming benchmarks from our public benchmark suite.\r\n\r\nAfter some profiling, it turned out that parsing big text files in `WordEmbeddingsTransform` is a performance bottleneck.\r\n\r\nIn the histogram below the red box 2 is parsing.\r\n\r\n![image](https://user-images.githubusercontent.com/6011991/48427146-6a401600-e768-11e8-968b-c923d12f411e.png)\r\n\r\nI optimized the code and then parallelized it. \r\n\r\nBefore:\r\n\r\n|                                         Method |    Mean |\r\n|----------------------------------------------- |--------:|\r\n| WikiDetox_WordEmbeddings_OVAAveragedPerceptron | 286.7 s |\r\n|                WikiDetox_WordEmbeddings_SDCAMC | 184.1 s |\r\n\r\nAfter:\r\n\r\n|                                         Method |     Mean |\r\n|----------------------------------------------- |---------:|\r\n| WikiDetox_WordEmbeddings_OVAAveragedPerceptron | 169.02 s |\r\n|                WikiDetox_WordEmbeddings_SDCAMC |  65.32 s |\r\n\r\nThe PR is #1599\r\n\r\n/cc @shauheen '"
379995458,1604,b'Clean up our auto-caching',"b""Currently, some of our trainers cache the data prior to training, without a possibility to disable that. \r\n\r\nI believe the good incremental step would be to disable all auto-caching, and rely on user to call `AppendCacheCheckpoint` prior to multi-pass training. \r\n\r\nThis is not really ideal, since the default setup for multi-pass trainers will train slower. I still think it is better to have a consistent story about our 'smarts' (that is, we have no auto-normalization, no auto-caching and no auto-calibration), and use extensive documentation (and tooling, in the future) to cover these pitfalls.\r\n\r\ncc @GalOshri @TomFinley @eerhardt """
379979626,1603,b'Confusion between ColumnAttribute and ColumnNameAttribute should be prevented',"b'I just spent nearly a whole hour in front of a class full of students trying to figure out what was wrong with my code. I was demonstrating the SentimentAnalysis classifier and had the working code in split-screen to compare. My faulty code had a Column Attribute instead of ColumnName Attribute in the prediction class.\r\nFirst, not a single pair of eyes noticed the error. For some reason, one does not seem to register the difference, however obvious it should be.\r\nThen, although the subsequent exception did mention something was wrong with columns it was virtually impossible to debug:\r\nColumnAttribute actually has the corresponding ""name"" member, it\'s just that the constructor with the same signature sets the ""ordinal"" member instead, and that without failing unfortunately.\r\nAccordingly, trying to compare the code execution step by step with complete source code, the only visible difference appears pretty late in SchemaDefinition.Create(..), when both attributes are tested for existence and the corresponding ""name"" value, with one of the two missing.\r\nThen the resulting exception is triggered again much later in the TypedCursorable\'s private constructor, where the faulty column is considered missing.\r\nThis is deadly. \r\nIf you don\'t notice the spelling difference visually right away, and again a whole class didn\'t for some reason, there is very little chance even debugging the whole engine will get you anywhere.\r\n\r\nIn short, it should be made impossible or near to impossible to use [Column(""name"")] instead of [ColumnName(""name"")] by mistake, and at least easier to diagnose.'"
379945906,1602,b'Make non-essential members of Core and Data assembly internal',"b""#1519 made it possible to have members that are not public, but still accessible to other ML.NET assemblies. We now plan to use it to reduce the public surface of ML.NET assemblies substantially.\r\n\r\nNamely, let's 'hide' the non-user-facing public members of `Microsoft.ML.Core` assembly"""
379889738,1600,"b""Custom mapping estimator doesn't check input schema""","b""The `CustomMappingEstimator` doesn't correctly check input schema for presence and validity of the columns."""
379397351,1595,b'Sentiment Analysis on Uwp - MissingMethodException',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10 UWP app,   ML 0.7.0\r\n- **.NET Version (eg., dotnet --info)**:  Net standard / Targeting min Fall Creator Update\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nWas trying to run  binary classification example on Uwp.\r\n\r\n- **What happened?**\r\n\r\nSystem.MissingMethodException: Method not found: 'System.ComponentModel.Composition.Hosting.CompositionContainer Microsoft.ML.Runtime.IHostEnvironment.GetCompositionContainer()'.\r\n\r\nIt works fine with  .Net Core Console .\r\n\r\n"""
379329615,1591,b'Error When Building Anomaly Detection Example Using 0.7.0',"b'Hello, I\'m a .NET developer but new to the .NET core world. I was able to verify this on two different machines. I didn\'t see any existing issues open on this. Hopefully I\'m not missing something obvious here, and apologies if I am. Let me know if there\'s any further information I can provide or questions I can answer\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10.0.16299\r\n- **.NET Version (eg., dotnet --info)**: \r\n  Version: 2.1.5\r\n  Commit:  290303f510\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nPulled latest version of ML.NET to play around with the new anomaly detection algorithms. Added using statements from the [example](https://github.com/dotnet/machinelearning/blob/7fb76b026d0035d6da4d0b46bd3f2a6e3c0ce3f1/test/Microsoft.ML.TimeSeries.Tests/TimeSeriesDirectApi.cs) linked to from the [release notes](https://github.com/dotnet/machinelearning/blob/master/docs/release-notes/0.7/release-0.7.md). An example of some step by step command line instructions are below (and the file contents are in source code section):\r\n\r\n`dotnet new console `\r\n`dotnet add package Microsoft.ML --version 0.7.0`\r\n\r\n- **What happened?**\r\nFailed to build, received a missing type or name space `error CS0234: The type or namespace name \'TimeSeriesProcessing\' does not exist in the namespace \'Microsoft.ML.Runtime\' (are you missing an assembly reference?)`\r\nLooking through the object browser in VS I don\'t see any TimeSeriesProcessing namespace present in the 0.7.0 nuget package at all.\r\n\r\n- **What did you expect?**\r\nSuccessful build, finding the indicated namespace.\r\n\r\n### Source code / logs\r\n\r\n```\r\nusing System;\r\nusing System.Collections.Generic; \r\nusing Microsoft.ML.Runtime.Api; \r\nusing Microsoft.ML.Runtime.Data; \r\nusing Microsoft.ML.Runtime.TimeSeriesProcessing;\r\n\r\nnamespace console_dotnetcore\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Hello World!"");\r\n        }\r\n    }\r\n}\r\n```'"
379310526,1589,b'class AssemblyRegistration should be public',b'Currently AssemblyRegistration.RegisterAssemblies(...) is not accessible outside of ML.Legacy assembly. This method is needed for NimbusML to register/load assemblies'
379046800,1585,b'Add multiple input/output support for OnnxTransform',"b'Allow multiple IDV columns to be mapped to multiple input nodes of an Onnx model, and also accomodate models that have multiple outputs.'"
378883906,1581,b'Organize the folder structure',"b'We should make sure that the namespaces and folders are matching each other, especially for public components.\r\n\r\n- All our assemblies should have DefaultNamespace be equal to `Microsoft.ML`\r\n- All other public types should be located in files that match their namespace.\r\n\r\n@TomFinley do you want to comment?'"
378845774,1579,"b'Exception when trying to Evaluate AveragedPerceptronTrainer, LinearSvm'","b'For a couple of Learners, we get an exception during `Evaluate`\r\n- AveragedPerceptronTrainer\r\n- LinearSvm\r\n\r\nException : \r\n\r\nMessage: System.ArgumentOutOfRangeException : Probability column \'Probability\' not found\r\nParameter name: name\r\n\r\nSample : \r\n\r\n        [Fact]\r\n        public void OVA_BC_AP()\r\n        {\r\n            string dataPath = GetDataPath(""breast-cancer.txt"");\r\n\r\n            // Create a new context for ML.NET operations. It can be used for exception tracking and logging, \r\n            // as a catalog of available operations and as the source of randomness.\r\n            var mlContext = new MLContext(seed: 1);\r\n            var reader = new TextLoader(mlContext, new TextLoader.Arguments()\r\n            {\r\n                Column = new[]\r\n                        {\r\n                            new TextLoader.Column(""Label"", DataKind.R4, 0),\r\n                            new TextLoader.Column(""Features"", DataKind.R4, new [] { new TextLoader.Range(1, 9) }),\r\n                        }\r\n            });\r\n\r\n            // Data\r\n            var data = reader.Read(GetDataPath(dataPath));\r\n\r\n            // Pipeline\r\n            var pipeline = new AveragedPerceptronTrainer(mlContext, ""Label"", ""Features"");\r\n\r\n            var model = pipeline.Fit(data);\r\n            var predictions = model.Transform(data);\r\n\r\n            // Metrics\r\n            var metrics = mlContext.BinaryClassification.Evaluate(predictions);\r\n        }\r\n'"
378602425,1577,b'The Timeseries samples need to be each one on its own file',"b'There are 4 samples in the [Timeseries.cs samples](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Timeseries.cs)\r\n\r\nSplit each sample, together with the helper classes in its own file, as it is easier to maintain, and change the references of those samples in the code to reference the new files. \r\n\r\nAlso, move the references from the constructor, to the actual class. \r\nExample reference [here](https://github.com/dotnet/machinelearning/blob/e63669b3228fe932e062983759321a021a660f51/src/Microsoft.ML.TimeSeries/IidSpikeDetector.cs#L185)\r\n\r\n` /// [!code-csharp[MF](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/Timeseries.cs ""Timeseries examples for spike detection."")]`\r\n\r\n\r\n'"
378579525,1576,b'Remove the copyright from the samples files',"b'There is no need for copyright in the docs/Microsoft.Ml.Samples project source files. \r\n1- Remove the copyright from the docs/Microsoft.Ml.Samples project sources.\r\n2- Change the other source files files that reference the samples in the XML to not contain a range\r\n. like [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/TreeTrainersStatic.cs#L41): \r\n\r\nthe reference to the other file is:\r\n\r\n`[!code-csharp[FastTree](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Static/FastTreeRegression.cs?range=6-11,19-69 ""FastTree regression example."")]\r\n`\r\nand it should change to not include a range nor comment anymore:\r\n\r\n`[!code-csharp[FastTree](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Static/FastTreeRegression.cs)]\r\n`\r\n \r\n'"
378559227,1575,b'ClusteringContext should have CrossValidate',"b'Currently, `ClusteringContext` lacks a `CrossValidate` method. We should add this for completeness and parity with the internal code which supports CV on clustering tasks.'"
378530330,1572,b'Some times we may want to provide test set in addition to training and validation sets',"b""Imagining that one day, a user prepares a training set and a validation, and she wants to train a `FastTree` (gradient boosting decision tree) with early stopping. Then, she probably also would like to know how good our early stopping is by calculating a score based on some predictions. If this is the case, she may need another data set (let's call it test set) because it's not fair to use validation set again because the training iteration number is determined by validation set via early stopping."""
378496469,1568,b'Add support for caching and filtering',"b'We need to add the API to cache the data view in memory (via `CacheDataView`).\r\n\r\nAlso, we want to add some filtering functionality: I think `RangeFilter` is enough. We have agreed in #933 to not make estimators/transformers for filtering, so I suggest to have only `MLContext` extensions for these operations.'"
378493367,1567,b'Access whitening transform models',"b'There is no way for the user to access the models produced by the whitening transform (the whitening matrices). We would need to expose that, as well as a function that allows to apply the matrix to new suitable input vectors (something similar to FillValues in the current code).\r\n\r\nFurthermore, we need to have an onFit function for pigsty to pass this class out.\r\n\r\nAdding @Ivanidzo4ka  to the conversation. \r\n'"
378359193,1565,b'Legacy API: Should we migrate its entry-points?',"b'The plan is to deprecate then delete the legacy API. While most items in it are of questionable worth, the legacy API does contain some components that might be worth saving, and some we may have to save.\r\n\r\nConsider this entry-point definition, in the legacy project.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7b2461cfdad150047dbbcbc163290a32e9f4d829/src/Microsoft.ML.Legacy/Runtime/EntryPoints/ModelOperations.cs#L81\r\n\r\nAs it is an entry-point, it was [duly published in NimbusML as we see here](https://github.com/Microsoft/NimbusML/blob/e1004720ec0c252ba87f02c190c33739d9c00f20/src/python/nimbusml/internal/entrypoints/models_ovamodelcombiner.py), and this internal entry-point definition actually [wound up being used here](https://github.com/Microsoft/NimbusML/blob/e1004720ec0c252ba87f02c190c33739d9c00f20/src/python/nimbusml/model_selection/cv.py#L474).\r\n\r\nThere are a couple questions we might want to ask. The legacy pipeline API was entry-point based, so anything that was part of a pipeline had to be an entry-point (I think). So were these entry-points defined in legacy *specifically* intended to be useful beyond legacy?\r\n\r\nIf we want to keep this entry-point, and others like it, we should have a migration plan somewhere, since legacy is to be deleted.'"
378152965,1562,b'Please support Keras',b'Tensor flow is really nice but Keras support would be great!!  We would then get Theano and CNTK.'
378093070,1560,b'Categorical Hash transform Create method ignores the number of HashBits ',"b""Looking at the [Create method](https://github.com/dotnet/machinelearning/blob/850f91c2e67679a825b49d3eefd96dea2cc2c153/src/Microsoft.ML.Transforms/CategoricalHashTransform.cs#L148) it doesn't pass the number of HashBits to the OneHotHashEncodingEstimator. """
378077981,1557,b'The format of the example XML is not correct in a few cases. ',b'The sample link for the NormalizerCatalog.cs has an extra bracket out of place. \r\nThe samples in MatrixFactorization and TimeSeries are missing the surrounding <example> XML  node. \r\n\r\nThose are causing problems with the samples displaying in the APIs documentation site. '
378074610,1556,b'No artifacts produced when CI builds time out',"b'This is related to #1473.\r\n\r\nOur current CI builds hang quite often. #1473 suggests to retain the output files produced during tests and inspect them to help identify the problem. Thanks to #1527 we now produce artifacts. However, we only produce them when the builds fail, and not when they time out. It would be useful to produce the artifacts also when the builds time out as that is a significant part of the current build issues encountered. \r\n\r\nTake https://dnceng.visualstudio.com/public/_build/results?buildId=40590&view=logs for example. You cannot access the artifacts because the build simply timed out. \r\n\r\nHere instead, there was one build failure and one time out. You can only access artifacts for the build that failed. https://dnceng.visualstudio.com/public/_build/results?buildId=40591&view=logs\r\n\r\n\r\n'"
378054234,1554,b'Build failed on Ubuntu 18.04',b'Build failed on Ubuntu 18.04. The ML.NET was forked today 11/6/18. The error msg says tensorflow.redist is not able to be downloaded as shown below. Any guidance to solve it? Thank you.\r\n\r\n![build-fail](https://user-images.githubusercontent.com/18431130/48096873-45c6c580-e1cd-11e8-9736-4ee6e355af0d.PNG)\r\n\r\n\r\n'
378045075,1553,b'Saving a DataView to a file should be simpler and not through to the LocalEnvironment class',"b'I\'m using v0.7.\r\nIssue: Saving a DataView to a file should be simpler and not having to directly use the LocalEnvironment class.\r\nIf there\'s any new way to do this in v0.7 or v08, please tell me, but I haven\'t found it. :)\r\n\r\nAs far as I know, this is the code needed, currently:\r\n\r\n```\r\n                // save test split dataset\r\n                IHostEnvironment env = (IHostEnvironment)mlContext;\r\n                using (var ch = env.Start(""SaveData""))\r\n                using (var file = env.CreateOutputFile(Path.Combine(_outputPath, ""testData.idv"")))\r\n                {\r\n                    var saver = new BinarySaver(mlContext, new BinarySaver.Arguments());\r\n                    DataSaverUtils.SaveDataView(ch, saver, testDataView, file);\r\n                }\r\n```\r\n\r\nFirst, it needs to use the `IChannel` object that has to be obtained from the `IHostEnvironment` object that you can get by casting the `MLContext `object to `IHostEnvironment`. The developer shouldn\'t need to use `IHostEnvironment` in any case, I think.\r\n\r\nThen, still a few more lines for saving the file.\r\n\r\nWe should aim to achieve a simpler API for doing this, just something like:\r\n\r\n`testDataView.SaveToFile(testDataSetFilePath);`\r\n\r\nOr if we need to do it through any utility class:\r\n\r\n`DataSaverUtils.SaveDataViewToFile(testDataView, testDataSetFilePath);`\r\n\r\n\r\n'"
378035743,1550,b'Type mismatch in TransformSamples.SampleInfertDataWithFeatures',"b""Type should be changed from int to float.\r\n\r\nFrom:\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<int> Features { get; set; }\r\n}\r\n```\r\n\r\nTo:\r\n\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<float> Features { get; set; }\r\n}\r\n```\r\n\r\nIt caused exception:\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Can't bind the IDataView column 'Features' of type 'Vec<R4, 3>' to field or property 'Features' of type 'Microsoft.ML.Runtime.Data.VBuffer`1[[System.Int32, System.Private.CoreLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]'.\r\n  Source=Microsoft.ML.Api\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1..ctor(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, InternalSchemaDefinition schemaDefn) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 129\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 249\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsCursorable[TRow](IDataView data, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 550\r\n   at Microsoft.ML.Runtime.Api.PipeEngine`1..ctor(IHostEnvironment env, IDataView pipe, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs:line 98\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsEnumerable[TRow](IDataView data, IHostEnvironment env, Boolean reuseRowObject, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 589\r\n   at Microsoft.ML.Samples.Dynamic.TransformSamples.ConcatTransform() in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Dynamic\\ConcatTransform.cs:line 49\r\n   at Microsoft.ML.Samples.Program.Main(String[] args) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Program.cs:line 13\r\n \r\n"""
378021332,1549,b'Scoring with ONNX does not work as expected',"b'I have an _onnx_ model generated from an MXNet model. I try to use it for scoring a regression problem. It does not work. Here are the steps I followed:\r\n\r\n## Build the MXNet model\r\n\r\n```python\r\nimport pandas as pd\r\n```\r\n\r\n```python\r\ndf_train = pd.read_csv(""train.csv"")\r\ndf_test = pd.read_csv(""test.csv"")\r\n```\r\n\r\n\r\n```python\r\nimport mxnet as mx\r\n```\r\n\r\n\r\n```python\r\ntrain_X = mx.nd.array(df_train.drop(""Target"", axis=1).values)\r\ntrain_y = mx.nd.array(df_train.Target.values)\r\ntest_X = mx.nd.array(df_test.drop(""Target"", axis=1).values)\r\ntest_y = mx.nd.array(df_test.Target.values)\r\ntrain_nd = list(zip(train_X, train_y))\r\ntest_nd = list(zip(test_X, test_y))\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.data import DataLoader\r\n```\r\n\r\n\r\n```python\r\nbatch_size = 64\r\n```\r\n\r\n\r\n```python\r\ntrain_data = DataLoader(train_nd, batch_size, shuffle=True)\r\ntest_data = DataLoader(test_nd, batch_size, shuffle=True)\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.nn import HybridSequential, Dense, Dropout\r\nfrom mxnet.initializer import Xavier\r\nfrom mxnet.gluon.loss import L2Loss\r\nfrom mxnet.gluon.trainer import Trainer\r\n```\r\n\r\n\r\n```python\r\nnet = HybridSequential()\r\nwith net.name_scope():\r\n    net.add(Dense(9))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(16))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(1))\r\n```\r\n\r\n\r\n```python\r\nnet.hybridize()\r\n```\r\n\r\n\r\n```python\r\nctx = mx.cpu()\r\n```\r\n\r\n\r\n```python\r\nnet.collect_params().initialize(Xavier(magnitude=2.24), ctx=ctx)\r\n```\r\n\r\n\r\n```python\r\nloss = L2Loss()\r\n```\r\n\r\n\r\n```python\r\ntrainer = Trainer(net.collect_params(), optimizer=""adam"")\r\n```\r\n\r\n\r\n```python\r\nsmoothing_constant = .01\r\nepochs = 5\r\n```\r\n\r\n\r\n```python\r\ndef measure_performance(model, ctx, data_iter):\r\n    mae = mx.metric.MAE()\r\n    for _, (data, labels) in enumerate(data_iter):\r\n        data = data.as_in_context(ctx)\r\n        labels = labels.as_in_context(ctx)\r\n        output = model(data)\r\n        predictions = output\r\n        mae.update(preds=predictions, labels=labels)\r\n    return mae.get()[1]\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet import autograd\r\n```\r\n\r\n\r\n```python\r\nfor e in range(epochs):\r\n    moving_loss = 0\r\n    for i, (data, label) in enumerate(train_data):\r\n        data = data.as_in_context(ctx)\r\n        label = label.as_in_context(ctx)\r\n        with autograd.record():\r\n            output = net(data)\r\n            loss_result = loss(output, label)\r\n        loss_result.backward()\r\n        trainer.step(batch_size)\r\n\r\n        curr_loss = mx.nd.mean(loss_result).asscalar()\r\n        moving_loss = (curr_loss if ((i == 0) and (e == 0))\r\n                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\r\n\r\n    test_mae = measure_performance(net, ctx, test_data)\r\n    train_mae = measure_performance(net, ctx, train_data)\r\n    print(""Epoch %s. Loss: %s, Train_mae %s, Test_mae %s"" % (e, moving_loss, train_mae, test_mae))\r\n```\r\nOutput:\r\n\r\n    Epoch 0. Loss: 5.848355519538663, Train_mae 1.1675882118595375, Test_mae 1.2460664133482342\r\n    Epoch 1. Loss: 2.8617846590961733, Train_mae 0.8983533112182495, Test_mae 0.9300098409758338\r\n    Epoch 2. Loss: 1.6959465687435336, Train_mae 0.6692642353930274, Test_mae 0.6831557900656627\r\n    Epoch 3. Loss: 0.91648433711298, Train_mae 0.5097093659054811, Test_mae 0.5119943500885481\r\n    Epoch 4. Loss: 0.5725724269757653, Train_mae 0.4398727014996231, Test_mae 0.4710224339667755\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nnet(mx.nd.array(np.expand_dims(np.ones(9), axis=0))).asnumpy().ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\nnet.export(""model"", epoch=epochs - 1)\r\n```\r\n\r\n**7.281115531921387 is what I expect to get when I provide _ones_ as feature.**\r\n\r\n## Export the MXNet model as ONNX\r\n\r\n\r\n\r\n```python\r\nfrom mxnet.contrib import onnx as onnx_mxnet\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nonnx_mxnet.export_model(sym=""model-symbol.json"",\r\n                  params=""model-0004.params"",\r\n                  input_shape=[(1, 9)],\r\n                  input_type=np.float32,\r\n                  onnx_file_path=""model.onnx"",\r\n                  verbose=True)\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    \'model.onnx\'\r\n\r\nThe model as visualized with Netron is as follows (the model is trivial):\r\n\r\n![model](https://user-images.githubusercontent.com/525590/48091230-61e85800-e209-11e8-83fe-4cd66e067e2f.png)\r\n\r\n## Testing with Tensorflow\r\n\r\nBefore loading the onnx model into ML.NET I tested it with Tensorflow\r\n\r\n\r\n\r\n```python\r\nimport onnx\r\n```\r\n\r\n\r\n```python\r\nmodel = onnx.load(""model.onnx"")\r\n```\r\n\r\n\r\n```python\r\nfrom onnx_tf.backend import prepare\r\n```\r\n\r\n\r\n```python\r\ntf_rep = prepare(model)\r\n```\r\n\r\nOutput:\r\n\r\n    c:\\users\\cosmin\\dev\\generate-mxnet-model\\env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:74: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\r\n      handler.ONNX_OP, handler.DOMAIN or ""ai.onnx""))\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\ntf_rep.run(np.expand_dims(np.ones(9), axis=0)).hybridsequential0_dense2_fwd.ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\ntf_rep.export_graph(""model.pb"")\r\n```\r\n\r\n**As you can see running the regression on ones returns the expected result: 7.281115531921387**\r\n\r\n## ML.NET 0.7\r\n\r\nMy programs is as follows:\r\n\r\n`Program.cs`\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    internal static class Program\r\n    {\r\n        private static void Main(string[] args)\r\n        {\r\n            var env = new MLContext();\r\n            var reader = TextLoader.CreateReader(env,\r\n                ctx => (\r\n                    Feature1: ctx.LoadFloat(0),\r\n                    Feature2: ctx.LoadFloat(1),\r\n                    Feature3: ctx.LoadFloat(2),\r\n                    Feature4: ctx.LoadFloat(3),\r\n                    Feature5: ctx.LoadFloat(4),\r\n                    Feature6: ctx.LoadFloat(5),\r\n                    Feature7: ctx.LoadFloat(6),\r\n                    Feature8: ctx.LoadFloat(7),\r\n                    Feature9: ctx.LoadFloat(8),\r\n                    Target: ctx.LoadFloat(9)),\r\n                separator: \',\',\r\n                hasHeader: true);\r\n            var data = reader.Read(new MultiFileSource(""test.csv""));\r\n            \r\n            var learningPipeline = reader.MakeNewEstimator()\r\n                .Append(row => (Target: row.Target, Features: row.Feature1.ConcatWith(\r\n                    row.Feature2, row.Feature3, row.Feature4, row.Feature5, row.Feature6,\r\n                    row.Feature7, row.Feature8, row.Feature9)))\r\n                .Append(row => (Truth: row.Target, Estimate: row.Features.ApplyOnnxModel(""model.onnx"")));\r\n\r\n            var model = learningPipeline.Fit(data);\r\n            \r\n            var predictionFunction = model.AsDynamic.MakePredictionFunction<SearchData, SearchPrediction>(env);\r\n\r\n            var prediction = predictionFunction.Predict(new SearchData()\r\n            {\r\n                Feature1 = 1.0f,\r\n                Feature2 = 1.0f,\r\n                Feature3 = 1.0f,\r\n                Feature4 = 1.0f,\r\n                Feature5 = 1.0f,\r\n                Feature6 = 1.0f,\r\n                Feature7 = 1.0f,\r\n                Feature8 = 1.0f,\r\n                Feature9 = 1.0f\r\n            });            \r\n            Console.WriteLine(prediction.Estimate);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n`SearchData.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n\r\n    public class SearchData\r\n    {\r\n        [ColumnName(""Target"")]\r\n        public float DummyUnused{ get; set; }\r\n        \r\n        public float Feature1{ get; set; }\r\n\r\n        public float Feature2{ get; set; }\r\n\r\n        public float Feature3{ get; set; }\r\n\r\n        public float Feature4{ get; set; }\r\n\r\n        public float Feature5{ get; set; }\r\n\r\n        public float Feature6{ get; set; }\r\n\r\n        public float Feature7{ get; set; }\r\n\r\n        public float Feature8{ get; set; }\r\n\r\n        public float Feature9{ get; set; }\r\n\r\n    }\r\n\r\n}\r\n\r\n```\r\n\r\n`SearchPrediction.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    public class SearchPrediction\r\n    {\r\n        [ColumnName(""Target"")]\r\n        public float Estimate{ get; set; }\r\n    }\r\n}\r\n\r\n```\r\n\r\nWhen running the program, I get 0, which is not great. The training and test sets are just full of 10 columns of floats.\r\n\r\nI also attach the `pip` requirements.txt file, so that you can see the onnx version I\'ve used\r\n\r\n```\r\nabsl-py==0.6.1\r\nastor==0.7.1\r\nbackcall==0.1.0\r\nbleach==3.0.2\r\ncertifi==2018.10.15\r\nchardet==3.0.4\r\ncolorama==0.4.0\r\ndecorator==4.3.0\r\ndefusedxml==0.5.0\r\nentrypoints==0.2.3\r\ngast==0.2.0\r\ngraphviz==0.8.4\r\ngrpcio==1.16.0\r\nh5py==2.8.0\r\nidna==2.6\r\nipykernel==5.1.0\r\nipython==7.1.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.2\r\njedi==0.13.1\r\nJinja2==2.10\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==6.0.0\r\njupyter-core==4.4.0\r\nKeras-Applications==1.0.6\r\nKeras-Preprocessing==1.0.5\r\nMarkdown==3.0.1\r\nMarkupSafe==1.0\r\nmistune==0.8.4\r\nmxnet==1.3.0\r\nnbconvert==5.4.0\r\nnbformat==4.4.0\r\nnotebook==5.7.0\r\nnumpy==1.14.6\r\nonnx==1.3.0\r\nonnx-tf==1.2.0\r\npandas==0.23.4\r\npandocfilters==1.4.2\r\nparso==0.3.1\r\npickleshare==0.7.5\r\nprometheus-client==0.4.2\r\nprompt-toolkit==2.0.7\r\nprotobuf==3.6.1\r\nPygments==2.2.0\r\npython-dateutil==2.7.5\r\npytz==2018.7\r\npywinpty==0.5.4\r\nPyYAML==3.13\r\npyzmq==17.1.2\r\nqtconsole==4.4.2\r\nrequests==2.18.4\r\nSend2Trash==1.5.0\r\nsix==1.11.0\r\ntensorboard==1.11.0\r\ntensorflow==1.11.0\r\ntermcolor==1.1.0\r\nterminado==0.8.1\r\ntestpath==0.4.2\r\ntornado==5.1.1\r\ntraitlets==4.3.2\r\ntyping==3.6.6\r\ntyping-extensions==3.6.6\r\nurllib3==1.22\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.4.2\r\n```'"
378006080,1548,b'Typo in name ExtractWordEmbeedings (extra e)',"b'typo: ExtractWordEmb**ee**dings -> ExtractWordEmb**e**ddings (double **d** instead of double **e**)\r\n\r\nLocation:\r\n        public static WordEmbeddingsExtractorEstimator ExtractWordEmbeedings(this TransformsCatalog.TextTransforms catalog,\r\n            string inputColumn,\r\n            string outputColumn = null,\r\n            WordEmbeddingsTransform.PretrainedModelKind modelKind = WordEmbeddingsTransform.PretrainedModelKind.Sswe)\r\n            => new WordEmbeddingsExtractorEstimator(Contracts.CheckRef(catalog, nameof(catalog)).GetEnvironment(), inputColumn, outputColumn, modelKind);\r\n'"
377964954,1544,b'ConvertTransform bug.',"b'If a column specifies return type of U*, but the arguments specify a key range, the column is converted to key instead to plain old unsigned integer type.\r\n'"
377689131,1542,b'TensorFlow transform would throw on non-vector input',"b""In the process of working on #1533, I found the following code in the tensorflow transform.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73762a8d8f23d27f3c15b4382c0bc374934ccad5/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L834-L844\r\n\r\nConsider the above code. We have at line 834 this assignment to a boolean value depending on whether the input is of type vector, or not. This strongly suggests that the transform can accomodate non-vector types. However at lines 841 and 844, we have this `type.AsVector.DimCount`. Now, `AsVector` will be `null` in the case where the type is not a vector of course, so this would throw a null reference exception if we were to ever feed this transform a non-vector value.\r\n\r\nSo, there's something wrong here. Unfortunately the intent of what the author *meant* to write is somewhat hidden from me, so perhaps whoever wrote this code could check this out. Maybe even write a test to test this condition."""
377674673,1541,b'Please support autodifferentiation',b'This would be a great feature to have.'
377674070,1540,b'IDataView Cleanup: KeyType Simplification',"b'We have by now multiple years of experience with `KeyType`. In the documentation of the `IDatView` type system, [key types](https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewTypeSystem.md#key-types) are described as having the following properties:\r\n\r\nAll of our current transformers produce key-types that are (1) known size and (2) have a minimum value of `0`, and are (3) contiguous, with absolutely no exceptions. Also if we consider how key-types are actually used (always, even in the hash transformer, considered enumerations into a set), then there is no particular rason for this. I therefore suggest that we simplify the key types by removing the properties describing this, and just make it a rule.\r\n\r\nThis does represent a loss of capability, but it is a capability that AFAIK has never been exercised beyond unit tests and small toy demonstrations to clarify to new developers, ""by the way, our key-types have this really, really weird capability...""\r\n\r\nOn the flip side, I feel like having a *count* have the maximum of `int.MaxValue` is arguably too limiting. The reason for this is that it was anticipated that the only real usage of key values would be to project into a vector, but this is not true. I would like to replace it with a `ulong` maximum value instead.'"
377662091,1539,b'Please support XGBoost i.e. gradient boosting machines',b'This is the 2nd most popular model on Kaggle.\r\n\r\nThanks.'
377647196,1537,b'Invalid arguments provided when using Iris dataset with TextLoader ',"b'There are two versions of the Iris data set in the ML.NET repo.\r\n- [iris.data](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.data)\r\n- [iris.txt](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.txt)\r\n\r\nBoth of these datasets do not have a header.  As such, when using these datasets with Textloader, the `HasHeader` field in the `TextLoader.Arguments` class should be `false` . \r\n\r\nInstead, we see several places (e.g. [here](https://github.com/dotnet/machinelearning/blob/453eb57f0cd94d6412b1f8dee76c00c686e2e06e/test/Microsoft.ML.Tests/TrainerEstimators/TrainerEstimators.cs#L178) ) where we have set `HasHeader=true`  while working with the above two datasets. \r\n\r\n\r\n'"
377606569,1534,b'IDataView Cleanup: Rename `UInt128`',"b""The row cursor IDs serve a purpose as described here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Data/ICursor.md#getidgetter\r\n\r\nThese IDs are represented as 128-bit numbers. Correspondingly, I named them `UInt128` back in the long vanished past. However, this is a troubling name: this first of all conflicts with any name .NET would use in the future to represent 128-bit unsigned integers (assuming they ever did so), which is reason enough not to use it. But even without this reason, this type just doesn't *quite* act like a number.\r\n\r\nOn the other hand, I am not certain what a good name would be. Something like `RowId`, `RecordId`, or something like that?\r\n\r\n/cc @Zruty0 @shauheen @terrajobst """
377592001,1533,b'IDataView Cleanup: ColumnType cleanup',"b'The `IDataView` type system is extensible (as we see with [`ImageType`](https://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.ImageAnalytics/ImageType.cs#L12)).\r\n\r\nThis is fine, but there is something confusing about `ColumnType` as well, since there are lots of methods and properties on the base class `ColumnType` that are specific for derived types. For example, `.IsVector`, `.KeyCount`, and other such things, that are only really relevant if the type *is* either vector, key, or whatever.\r\n\r\n## Why clean up?\r\n\r\nThere are lots of things on `ColumnType` that are unappealing. There are things like `AsVector` and `IsVector` which, as the documentation states, are equivalent to `as VectorType` and `is VectorType`. I mean, *why*? You save a few characters here and there, but at the cost of complicating one of the most central classes in the API.\r\n\r\nSome things are just plain old silly. Why `IsTimeSpan`? How useful is that, really? Some things are like this.\r\n\r\nThere\'s also `DataKind`. This is so strange. This has already caused a fair amount of confusion among some people: they see this, and they think, ""oh the types are just from this `enum`."" No, they\'re not.\r\n\r\nThe reality is, these things are *conveniences*, but they\'re conveniences I think that confuse people (multiple smart people have thought their presence meant the type system was *not* extensible), so maybe we ought not to expose them, at least, not in their current form.\r\n\r\n## Why not clean up?\r\n\r\nIn a sense, forming an analogue between the IDV and .NET type systems, there is some precedent for this sort of thing: if we consider `System.Type`. This has the property `IsArray`, with the methods `GetArrayRank`, which is only sensible to to use if the the `IsArray` property was true. However in *our* case, `ColumnType` is an abstract class, and while `System.Type` is abstract, its inheritance structure does not capture specific types of values in the same sense we do, e.g., there is no specific string type descended from `Type`. If, hypothetically, `.GetType` of an `int[]` returned some type `System.ArrayType` that descended from `System.Type`, then we might equally hypothetically imagine that the method to get the array rank would be on that derived `ArrayType`, rather than on `Type` directly.\r\n\r\nThere is also a practical consideration. The reality though is that some types are definitely more important and more heavily used than others.\r\n\r\nLet\'s imagine that we kept the `ColumnType` inheritance structure as it is now, but removed any properties relevant only to any derived type, specifically. What would hypothetically happen? I picked this usage more or less randomly from our codebase.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Data/Evaluators/ClusteringEvaluator.cs#L799-L801\r\n\r\nNow then, let\'s imagine that we have *none* of the ""specialty"" properties on `ColumnType` used above, but instead have a `IsKnownSize` and `ItemType` on `VectorType` *specifically*, that is, not on the root class, and you must rephrase this thing as a `VectorType` if you wished to access these. The most clear way I can imagine to deliver equivalent logic to the linked condition is this:\r\n\r\n```csharp\r\nif (!(type is VectorType vecType && vecType.IsKnownSize && vecType.ItemType == NumberType.Float))\r\n```\r\nThat\'s not *so* bad really... the condition went from 60 to 92 characters, which while not great, is hardly ridiculous.\r\n\r\nIt\'s even conceivable that had we had pattern matching at the time this code is written, we would have done this. Prior to C# 7.0 (and this code is *way* prior to C# 7.0), there was no such things as this pattern matching, as we see used here in the `type is VectorType vecType` expression. So the equivalent in the pre-pattern match days would have been considerably more obnoxious and verbose.\r\n\r\nLet\'s talk about `DataKind`. Unquestionably it is confusing, but if you take a look at it, it is also really, really helpful to have, for the common builtin types, an `enum`.\r\n\r\n## Proposed balance\r\n\r\nI think it\'s possible to sort of have our cake and eat it too. Now that we have #1520, we can sort of make our public surface as sparse as possible, while allowing the conveniences we currently enjoy for the internal implementation to remain more or less unmolested.\r\n\r\n* Let us mark these questionable things as `internal`, but with `BestFriend` attributes on them. The internal code can retain is sparsity, \r\n* Let us add to the public surface the same information that we get from the types on the specific relevant types themselves. (E.g., the vector size would just be *publicly* part of `VectorSize` itself.)\r\n* In any event, some of the properties have no reason to exist in *any* world. For example, a property like `IsTimeSpan` exists just because someone misunderstood what was going on, and thought, ""gee I\'m adding a new class, I see we have tests for things like vector and text, let me just add this."" Nope, we just have those special things as conveniences.\r\n\r\nWe could then, if we *like* either (1) make the conveniences public or (2) remove them altogether, at our own pace, without jeopardizing the public surface of the API at all.\r\n\r\n/cc @Zruty0 @shauheen @terrajobst \r\n'"
377565010,1532,b'IDataView Cleanup: Clear cutting the `IRowCursor` interface jungle',"b'Right now we have a fairly elaborate set of interfaces surrounding `IRowCursor`. These include `ISchematized`, `ICounted`, `IRow`.\r\n\r\nWhile `IRowCursor` and `IRow` are quite useful, it is not clear if separating out `ICursor` and `ICounted` as separate interfaces is actually helpful, and we think we ought to get rid of `ISchematized` anyway (see #1502). The goal would be to refactor this jungle so that there are, relating to row cursors, two types, both abstract ***classes***, corresponding to `IRow` and `IRowCursor`, but of course not named that since they won\'t be interfaces. (What would be a good name is up for debate. `RowCursor` seems probably fine, but just `Row` does not seem like a good name.)\r\n\r\nIt may be that we have the name `Row` for now until we imagine a better name, and treat that renaming as a separate issue from this issue which mostly treats on the proper refactoring of the code.\r\n\r\n`ICursor` does have some implementations that are not also `IRowCursor`, but it is unclear whether this *has* to be this way, or if it is just that way just because it was there.\r\n\r\nThe collapse of `ICounted` into these hypothetical `Row` and `RowCursor` classes would be mostly into `Row`.\r\n\r\n## While we are at it...\r\n\r\nWhile refactoring this code it would be advantageous to at the same time deal with the refactorings of other things methods in cursors, as we will be restructuring them anyway.\r\n\r\n* The utility of `State` on cursors has proven to not be terribly useful. People create and use cursors more or less like they do enumerators -- they create them, move-next over them, then when they stop the thing is disposed. It is valuable for the sake of assert checking, but otherwise I am not aware of any use. Certainly `IEnumerator` gets along just fine without this...\r\n\r\n* The `MoveMany` method *seems* attractive. In many cases, you can in fact move faster than just an exhaustive `MoveNext` to get to where you want to go. The trouble is the utility for such a mechanism has proven to be limited -- sure, a `Skip` filter could be more performant, but beyond that usages are few. We may as well remove it.\r\n\r\n* `GetRootCursor`\'s performs an essential job (bypass nested move-next so that nested cursors, which is to say *most* cursors, have a fast `MoveNext`). By moving this to an abstract class, we can see if this ""bypass"" mechanism can be achieved in a less obnoxious (possibly internal) way to cursors.\r\n\r\n* Possibly not to be done here, it would be nice if instead of `IRowCursor` (or rather, its abstract class descendant) being disposable, that the `IRow` is disposable. This is desirable but may require additional considerations, and might be best achieved in a separate issue.\r\n\r\n* The utility of the `IsActiveColumn` is not immediately clear. Can we get away with simply not providing it? It may be though that we decide to keep it.\r\n\r\n/cc @Zruty0 @shauheen @terrajobst '"
377563947,1531,b'IDataView Cleanup: Remove `lazy` parameter from get row count',"b""How do you tell the number of rows in a data view?\r\n\r\nThere is this very interesting method here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Core/Data/IDataView.cs#L95\r\n\r\nThe semantics of this are somewhat odd (though logical, in their way), and basically boil down to: under the default value of `lazy=true`, only return the row count if it is basically an O(1) operation. But what if this returns `null`? Then you have the `lazy=false` operation! This is a hint that we ought to possibly expend *more* effort, but only if doing so entails less work than just iterating over every row and counting directly.\r\n\r\nIndeed, this is what this utility function does:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Data/Data/DataViewUtils.cs#L78\r\n\r\nFirst it asks (with `lazy=false`!) for the row count, and failing that will actually open a cursors (with no rows active) and directly count the number.\r\n\r\nThis is all fairly logical. However, as a practical matter, no one *ever* bothered to implement a `lazy=false` different code path as far as I am aware. This is not to say they couldn't have -- you might imagine some text-loader that without trying to parse anything merely counts the number of newline characters in a file, which would be much faster than an iteration -- but again, as a practical matter, no one *did*.\r\n\r\nThis suggests removing this `lazy` parameter to simplify the interface. It would still have the same semantics, just without all the complication of explaining `lazy`. (Though we'd still need to make clear to people that they *should* be lazy in the implementation notes.)\r\n\r\n/cc @Zruty0 @shauheen @terrajobst """
377550767,1529,b'IDataView Cleanup: Predicates from int to Column',"b""As seen in #1500, schema is being changed so that schemas contain columns.\r\n\r\nFor various reasons it may be easiest once `IDataView` is a class.\r\n\r\nLet us consider the use of predicates in the `IDataView` system, e.g., when getting a cursor:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Core/Data/IDataView.cs#L103\r\n\r\nor elsewhere when forming a mapper, and getting dependencies:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Core/Data/ISchemaBindableMapper.cs#L77\r\n\r\nThe use of integer indices here has sometimes led to confusion or even bugs. With the change of #1500 under consideration, this suggests a possibly better way.\r\n\r\nIt may be worth considering whether the columns in the new scheme suggested in #1500 should have a backref to the original schema (even as an internal field that is checked by the data-view abstract class), so as to enable an easy way to check whether that column in fact came from that schema, or, even without that backref, to check whether the columns exist.\r\n\r\nWe could also consider this dependency be expressed not as a *delegate*, but instead just some sort of collection of columns, since that would also make this easier to explain.\r\n\r\nNote that while this makes the *interface* to `IDataView` easier, it makes the *implementation* harder, at least, if we suppose that all dataviews are possible for handling these inputs correctly and verifying that there aren't any shenaningans going on with input columns being from a different schema (which we can and so almost certainly should do under this new scheme). This suggests a change to `IDataView`, possibly done once `IDataView` is a class, so that the utility mapping from these column objects back down to indices (which must still happen internally) is handled by common code. It would also enable if these column objects have some sort of internal backreference to the schema, the ability to check that the input schemas are in fact correct. (This we obviously cannot do today with indices!)\r\n\r\n/cc @Zruty0 @shauheen @terrajobst """
377550205,1528,"b'IDataView Cleanup: IDataView as an abstract class, not interface'","b'Let us not have `IDataView` as an interface, but instead just an abstract base class `DataView`. Then instead of implementing this interface, we descend from the base class. This is in line with .NET guidelines preferring abstract classes to interfaces where possible and reasonable.\r\n\r\nAt least internal to ML.NET things that are `IDataView` are primarily that (or some subcase of that).\r\n\r\nFor various reason this *may* have to wait until the `IDataTransform` conversion into the `IEstimator`/`ITransformer` idioms is complete, but we can investigate doing it now, or even temporarily making *that* itself a base class. Nonetheless it woudl be easiest done once `IDataTransform` is disentangled from many of the existing `IDataView` implementations.\r\n\r\n/cc @Zruty0 @shauheen @terrajobst '"
377263917,1525,"b'Minor consistency issue: MLContext.MulticlassClassification has first ""c"" letter as lowercase, but MultiClassClassifierEvaluator.Result has it as uppercase'","b'Minor consistency issue, this class has first ""c"" as lowercase:\r\nMLContext.Multi**c**lassClassification.Evaluate()\r\n\r\nThen, the Evaluate method returns the following type which has the first ""C"" as uppercase:\r\n\r\nMulti**C**lassClassifierEvaluator.Result '"
377128824,1523,b'Test issue - disregard',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
377084661,1522,b'Simplify API: dataPipeline.Fit(data).Transform(data);',"b'For the code on [""How do I look at the intermediate data?""](https://github.com/dotnet/machinelearning/blob/453eb57f0cd94d6412b1f8dee76c00c686e2e06e/docs/code/MlNetCookBook.md#how-do-i-look-at-the-intermediate-data) as explained in the CookBook, it looks weird to have to pass the same DataView object twice in the following code line:\r\n(Scroll down a bit and you\'ll see)\r\n```\r\n// Fit our data pipeline and transform data with it.\r\nvar transformedData = dataPipeline.Fit(data).Transform(data);\r\n```\r\n\r\nThat line of code initially looks like a [""Code smell""](https://en.wikipedia.org/wiki/Code_smell).. \r\n\r\nSince the DataView object is provided to the parent object (pipeline) through the `Fit(data)` method, could it be possible to get/use the DataView from the parent object without having to provide again the DataView object to the Transform(data) method? - Something like:\r\n\r\n`var transformedData = pipeline.Fit(dataView).Transform();`\r\n\r\n'"
377080492,1521,b'Need to make consistent the parameters across the API',"b'**Issue: Similar classes/estimators methods have different parameters\' order for the same concepts.** \r\n\r\nIt looks like a ""silly"" error, but not straightforward to catch because the column\'s name provided as parameters are not typed (just strings, logically, since column names could vary) you get an error in execution time but in addition to that because the pipeline works as lazy loading, you find the error later on when fitting the model, so you initially don\'t know what API is incorrectly configured making it hard to find these kind of ""silly"" errors which are prone to happen because of different parameter\'s order in similar APIs (such as Estimators and Transformers). \r\n\r\nFor instance, when migrating to the estimator by using mlContext, the following ""silly"" case happened to me:\r\n\r\n```\r\n// This line works\r\nvar trainer = new SdcaMultiClassTrainer(mlContext, ""Features"", ""Label"");\r\n// This line doesn\'t work, but you\'ll find out later on when Fitting the model\r\nvar trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(""Features"", ""Label"");\r\n```\r\n\r\nError you get when fitting:\r\n```\r\nSystem.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  **Message=Training label column \'Features\' type is not valid for multi-class: Vec<R4, 69981>. Type must be R4 or R8.**\r\n  Source=Microsoft.ML.Data\r\n```\r\n\r\n```\r\n//This line DOES work when changing to the right order of parameters accepted by the new API:\r\nvar trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(""Label"", ""Features"");\r\n```\r\nBut you can see that is not consistent in order with this very similar line, the same trainer:\r\n```\r\n// This line works\r\nvar trainer = new SdcaMultiClassTrainer(mlContext, ""Features"", ""Label"");\r\n```\r\n\r\nI initially thought that the trainer in the mlcontext catalog was not working for any reason as a very similar API was working by directly creating the class.. But it was simply because the order is vice-versa in the case of the new trainer surfaced on the mlContext. ;)\r\n\r\n**Improvement**\r\n\r\n1. Obvious and already ""work in progress"": It will help if we are consistent in the order of the parameters across all the APIs. ""Label"" first, ""Features"" later, or vice-versa, but consistent.\r\n\r\n2. Not sure if somehow we could use strongly-typed types for the column names or some kind of check/control.. like if for the column names we were able to use the fields in the schema classes and the ""Label"" field was ""marked"" as ""Label"" with an attribute, that could also help, I mean something like the following:\r\n\r\n```\r\nvar trainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscentnameof(\r\n                                                        nameof(MyObservation.MyLabel), \r\n                                                        ""Features"");\r\n```\r\n\r\nThen, the Label field is ""marked"" as Label:\r\n```\r\n    public class MyObservation\r\n    {\r\n        [Column(ordinal: ""0"")]\r\n        public string ID;\r\n\r\n        [Label]\r\n        [Column(ordinal: ""1"")]\r\n        public string MyLabel; // This is an issue label, for example ""area-System.Threading""\r\n\r\n        [Column(ordinal: ""2"")]\r\n        public string Title;\r\n\r\n        [Column(ordinal: ""3"")]\r\n        public string Description;\r\n    }\r\n```\r\n\r\nNot sure though..., this last approach might be too contrived and not realistic because in almost all the cases the Label is also a generated/Dictionarized field, as well as the ""Features"" column, both created/generated as new columns out of the original observation schema class, so this last attempt might not be feasible...\r\n\r\nAny other possible check/control so errors when using strings for the column names could be less prone to happen?... \r\n\r\n'"
377037386,1519,b'Best friends to limit friend access',"b'While we stabilize the API, it is best if we keep hidden as much as possible, since once v1.0 the barrier to changing the public types on a publicly released library will be high. For that reason the thinking is to keep the scope of what we publicly release as limited as possible. If we suppose that *usage* of the library vs. *component authorship* inside the library, one obvious way to reduce the surface area is to ideally hide (or, in the worst case, render useless) all the items related to component authorship.\r\n\r\nThe problem is, over the years we have accumulated have a fairly huge library, so there are a tremendous number of types, and a fair amount of infrastructure. We cannot make that infrastructure internal simply and put everything in one big assembly, because some components or their dependencies are quite large, so we want to keep them in separate nugets, which means separate assemblies. But, that means public classes.\r\n\r\nWe could make the core infrastructure assemblies friends of all leaf assemblies via the `InternalsVisibleTo` attribute, but that would render *all* internal classes usable from the leaf assemblies, which again is not what we want from a code maintainability perspective.\r\n\r\nWe really want to have a mechanism that distinguishes internal to the assembly, and internal to the library. There is no concept in .NET, and based on conversations with the .NET folks there seems to be little belief such a thing might be useful in any other situation, so we\'ll roll our own.\r\n\r\nThe best idea we have settled on so far is that we set things to be friends as described above, make things internal, *but* for these internal items we want to share, make sure that there is an attribute (provisionally called `BestFriend`) on the item, and if not, the code analyzer we have internal to ML.NET will complain.\r\n\r\nSo, e.g.:\r\n\r\n```csharp\r\ninternal sealed class Foo { }\r\n\r\n[BestFriend]\r\ninternal sealed class Bar\r\n{\r\n    [BestFriend]\r\n    internal int A { get; }\r\n    internal int B { get; }\r\n}\r\n\r\npublic abstract class Biz\r\n{\r\n    [BestFriend]\r\n    private internal Biz() { }\r\n}\r\n```\r\n\r\nIn this scenario, if we consider some hypothetical other project code trying to access this, access to `Foo` and `Bar.B` would be restricted (despite being friends!), but access to `Bar`, `Bar.A`, and a class inheriting from `Biz` would be possible, but only from our assemblies.\r\n\r\nNote here, `Biz` itself is still public since we very often have user-accessible classes descend from some class we would like to be ""internal,"" but kind of can\'t, at least, not without introducing a significant absurd amount of wrapping. This level of ""visible but unusable"" though we should try to keep to a minimum.\r\n\r\nYou could imagine this attribute being an opt-out rather than opt-in, but opt-in seems a bit more reasonable since we want to treat these cross-assembly sharings as being somehow special, and it would be nice if in PRs it becomes obvious when there\'s something like this going on.\r\n\r\nThe work then is:\r\n\r\n1. Introduce two attributes, one this `BestFriend` attribute, the other an assembly level attribute whereby an assembly can indicate it wants to be subject to these best-friend controls. (Some assemblies like `CpuMath` that are purely intended for component authors would perhaps share everything without the need for this attribute.)\r\n\r\n2. Write an analyzer that complains when there is a cross-assembly friend access, when the item does not contain this attribute.\r\n\r\nObviously one of these is slightly harder than the other. \xf0\x9f\x98\x84 Note that this work merely covers the *creation* of the infrastructure, not the *use* of the infrastructure. That later work will be considerably more involved and spread across many files, and so will certainly be structured across many PRs.\r\n\r\n/cc @danmosemsft @eerhardt @Zruty0 '"
376923494,1515,b'Be able to create a reader by just specifying an schema class instead of all the columns',"b'In current version (v0.6 and v0.7) when creating a TextLoader we need to provide all the columns explicetely like the following:\r\n\r\n_loader = mlContext.Data.TextReader(new TextLoader.Arguments()\r\n                                                {\r\n                                                    Separator = "","",\r\n                                                    HasHeader = true,\r\n                                                    Column = new[]\r\n                                                                {\r\n                                                                new TextLoader.Column(""Season"", DataKind.R4, 2),\r\n                                                                new TextLoader.Column(""Year"", DataKind.R4, 3),\r\n                                                                new TextLoader.Column(""Month"", DataKind.R4, 4),\r\n                                                                new TextLoader.Column(""Hour"", DataKind.R4, 5),\r\n                                                                new TextLoader.Column(""Holiday"", DataKind.R4, 6),\r\n                                                                new TextLoader.Column(""Weekday"", DataKind.R4, 7),\r\n                                                                new TextLoader.Column(""WorkingDay"", DataKind.R4, 8),\r\n                                                                new TextLoader.Column(""Weather"", DataKind.R4, 9),\r\n                                                                new TextLoader.Column(""Temperature"", DataKind.R4, 10),\r\n                                                                new TextLoader.Column(""NormalizedTemperature"", DataKind.R4, 11),\r\n                                                                new TextLoader.Column(""Humidity"", DataKind.R4, 12),\r\n                                                                new TextLoader.Column(""Windspeed"", DataKind.R4, 13),\r\n                                                                new TextLoader.Column(""Count"", DataKind.R4, 16)\r\n                                                                }\r\n                                                }\r\n\r\nSince you usually also have a schema class for the observations, like the following:\r\n\r\n    public class DemandObservation\r\n    {\r\n        public float Season;\r\n        public float Year;\r\n        public float Month;\r\n        public float Hour;\r\n        public float Holiday;\r\n        public float Weekday;\r\n        public float WorkingDay;\r\n        public float Weather;\r\n        public float Temperature;\r\n        public float NormalizedTemperature;\r\n        public float Humidity;\r\n        public float Windspeed;\r\n        public float Count;   // This is the observed count, to be used a ""label"" to predict\r\n    }\r\n\r\nIt would be very convenient to be able to create a TextReader by just providing the class, like this:\r\n\r\nmlContext.Data.TextReader(DemandObservation);\r\n\r\n'"
376906064,1514,"b""ONNX dlls appearing in VS at the project's root folder""","b'Right after compiling a sample which is scoring with an ONNX model, a bunch of ""low level"" DLLs related to ONNX appear in VS at the project\'s root folder.\r\n\r\nIs there a way not to show all these .DLLs here?\r\n(Ignore the list of image files, of course..)\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/47931063-fc077380-de8a-11e8-8c2b-d1a02b5e8d09.png)\r\n'"
376864964,1510,"b""WordHashBag transform doesn't work when applied to multiple input columns""","b'The WordHashBag transform creates a TokenizeTransform for each of its input columns, but it uses an array with one entry per output column, so if there are multiple input columns, only one TokenizeTransform per output column is created.'"
376660549,1508,b'System.Runtime.InteropServices.SEHException when loading ONNX models',"b""Can someone help me with ONNX estimator.\r\n### System information\r\n\r\n- **OS version/distro**: Windows 10 Version 1709 Build 16299.726\r\n- **.NET Version (eg., dotnet --info)**: .NET core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFollowed the tests and tried to load an existing Onnx model(squeezenet)using \r\nestimator (tried both static and dynamic)\r\n- **What happened?\r\nSystem.Runtime.InteropServices.SEHException: 'External component has thrown an exception\r\n- **What did you expect?**\r\nTo load the onnx model and predict using it\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[OnnxApp.zip](https://github.com/dotnet/machinelearning/files/2540964/OnnxApp.zip)"""
376576402,1506,b'LpGcNormAndWhiteningWorkout test fails only on VSTS Hosted macOS',"b'### Issue\r\n\r\nThe test [LpGcNormAndWhiteningWorkout](https://github.com/dotnet/machinelearning/blob/c2b5e76c699b740e874a9db218828296a23b2ad8/test/Microsoft.ML.Tests/Transformers/NormalizerTests.cs#L123) is failing on VSTS Hosted Mac build agents, but not on DotNetCore build agents or any local Mac machines.  This currently prevents us from being able to switch to Hosted Mac agents which we want to do.\r\n\r\nThis comes out of PR #1240.\r\n\r\nThe test is failing inside WhiteningTransform.cs TrainModels() with ` System.InvalidOperationException : Invalid arguments to LAPACK gesvd, error: -6`.  This is due to `Mkl.Svd` returning -6 and we expected that it would return 0.\r\n\r\n@TomFinley do you have any insights into why we might get this result from MKL? \r\n\r\n### Source code / logs\r\nFrom https://dnceng.visualstudio.com/public/_build/results?buildId=38033&view=logs:\r\n\r\n```\r\nFailed   Microsoft.ML.Tests.Transformers.NormalizerTests.LpGcNormAndWhiteningWorkout\r\nError Message:\r\n System.InvalidOperationException : Invalid arguments to LAPACK gesvd, error: -6\r\nStack Trace:\r\n   at Microsoft.ML.Transforms.WhiteningTransform.TrainModels(Single[][] columnData, Int32[] rowCounts, IChannel ch) in /Users/vsts/agent/2.141.1/work/1/s/src/Microsoft.ML.Transforms/WhiteningTransform.cs:line 327\r\n   at Microsoft.ML.Transforms.WhiteningTransform..ctor(IHostEnvironment env, Arguments args, IDataView input) in /Users/vsts/agent/2.141.1/work/1/s/src/Microsoft.ML.Transforms/WhiteningTransform.cs:line 253\r\n   at Microsoft.ML.Transforms.Whitening.Fit(IDataView input) in /Users/vsts/agent/2.141.1/work/1/s/src/Microsoft.ML.Transforms/WrappedWhiteningTransformer.cs:line 89\r\n   at Microsoft.ML.Runtime.Data.TrainedWrapperEstimatorBase.GetOutputSchema(SchemaShape inputSchema) in /Users/vsts/agent/2.141.1/work/1/s/src/Microsoft.ML.Data/DataLoadSave/TransformWrapper.cs:line 163\r\n   at Microsoft.ML.Runtime.Data.EstimatorChain`1.GetOutputSchema(SchemaShape inputSchema) in /Users/vsts/agent/2.141.1/work/1/s/src/Microsoft.ML.Data/DataLoadSave/EstimatorChain.cs:line 67\r\n   at Microsoft.ML.Runtime.RunTests.TestDataPipeBase.TestEstimatorCore(IEstimator`1 estimator, IDataView validFitInput, IDataView validTransformInput, IDataView invalidInput, IDataView validForFitNotValidForTransformInput) in /Users/vsts/agent/2.141.1/work/1/s/test/Microsoft.ML.TestFramework/DataPipe/TestDataPipeBase.cs:line 79\r\n   at Microsoft.ML.Tests.Transformers.NormalizerTests.LpGcNormAndWhiteningWorkout() in /Users/vsts/agent/2.141.1/work/1/s/test/Microsoft.ML.Tests/Transformers/NormalizerTests.cs:line 142\r\nStandard Output Messages:\r\n Test LpGcNormAndWhiteningWorkout: aborted: passed\r\n```\r\n\r\nFrom [WhiteningTransform.cs, TrainModels()](https://github.com/dotnet/machinelearning/blob/d68388a1c9994a5b429b194b64b2b0782834cb78/src/Microsoft.ML.Transforms/WhiteningTransform.cs#L322)\r\n```\r\nch.Info(""Computing SVD..."");\r\nvar eigValues = new Float[ccol]; // Eigenvalues.\r\nvar unconv = new Float[ccol]; // Superdiagonal unconverged values (if any). Not used but seems to be required by MKL.\r\n// After the next call, values in U will be ovewritten by left eigenvectors.\r\n// Each column in U will be an eigenvector.\r\nint r = Mkl.Svd(Layout, Mkl.SvdJob.MinOvr, Mkl.SvdJob.None,\r\n    ccol, ccol, u, ccol, eigValues, null, ccol, null, ccol, unconv);\r\nch.Assert(r == 0);\r\nif (r > 0)\r\n    throw ch.Except(""SVD did not converge."");\r\nif (r < 0)\r\n    throw ch.Except(""Invalid arguments to LAPACK gesvd, error: {0}"", r);\r\n```\r\n\r\n### System information\r\n\r\n* VSTS Hosted macOS agent: **fails**\r\n```\r\nVSTS Version: 2.141.1\r\nBenchmarkDotNet=v0.11.1, OS=macOS High Sierra 10.13.6 (17G65) [Darwin 17.7.0]\r\nIntel Xeon CPU E5-1650 v2 3.50GHz (Max: 3.34GHz), 2 CPU, 4 logical and 4 physical cores\r\n.NET Core SDK=2.1.401\r\n  [Host] : .NET Core 2.1.3 (CoreCLR 4.6.26725.06, CoreFX 4.6.26725.05), 64bit RyuJIT\r\n  Dry    : .NET Core 2.1.3 (CoreCLR 4.6.26725.06, CoreFX 4.6.26725.05), 64bit RyuJIT\r\n```\r\n\r\n* DotNetCore macOS agent: **passes**\r\n```\r\nVSTS Version: 2.142.1\r\nBenchmarkDotNet=v0.11.1, OS=macOS Sierra 10.12.6 (16G1510) [Darwin 16.7.0]\r\nIntel Core i7-4578U CPU 3.00GHz (Haswell), 1 CPU, 4 logical and 2 physical cores\r\n.NET Core SDK=2.1.401\r\n  [Host] : .NET Core 2.1.3 (CoreCLR 4.6.26725.06, CoreFX 4.6.26725.05), 64bit RyuJIT\r\n  Dry    : .NET Core 2.1.3 (CoreCLR 4.6.26725.06, CoreFX 4.6.26725.05), 64bit RyuJIT\r\n```\r\n\r\n* Monte\'s Macbook Pro: **passes**\r\n```\r\nVSTS Version: <N/A>\r\nBenchmarkDotNet= <N/A> OS=macOS Sierra 10.13.1\r\nIntel Core i7 CPU 2.9GHz, 1 CPU, 4 physical cores\r\n.NET Core SDK=2.1.401\r\n```\r\n\r\n* Monte\'s Mac Mini: **passes**\r\n```\r\nVSTS Version: <N/A>\r\nBenchmarkDotNet= <N/A> OS=macOS Sierra 10.13.6\r\nIntel Core i5 CPU 2.8GHz, 1 CPU, 2 physical cores\r\n.NET Core SDK=2.1.401\r\n```\r\n\r\n\r\nLet me know if there are more details on the hardware that would be helpful.\r\n\r\n\r\n'"
376518554,1504,b'SelectColumnsTransform drops columns that it should not drop',"b'The KeepHidden argument should keep/drop only hidden columns with the same names as ones that are specified in the arguments. Currently, in the ""drop"" mode of the transform, it drops all hidden columns, no matter what their name is.\r\n\r\nI am not sure this argument should even be relevant for drop mode, I think it should automatically drop all columns with the specified names, whether they are hidden or not.\r\n\r\ncc @Zruty0 , @singlis, what do you think?'"
376493090,1503,"b'Azure Web App Can\'t Find ""CpuMathNative.dll""'","b""### System information\r\n\r\n- **OS version/distro**: I'm not quite sure how to find that information on an Azure Web App service\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Deploy a web API project that includes ML.NET functionalities to an Azure Web App\r\n- **What happened?** When training the model, an exception is thrown because CpuMathNative.dll cannot be found.\r\n- **What did you expect?** The same project worked as intended when I tried running it in my local environment, so I expected it to work on Azure too.\r\n\r\n### Source code / logs\r\nThis is the stack trace of the exception:\r\n```\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`2.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Runtime.Learners.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor)\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\n   at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n   at LocationAPI.Controllers.APIControllers.MLTestController.<TrainAsync>d__8.MoveNext() in D:\\home\\site\\repository\\LocationAPI\\Controllers\\APIControllers\\MLTestController.cs:line 95\r\n```\r\n"""
376473990,1502,b'Remove ISchematized interface',"b'`ISchematized` interface is not consumed anywhere: we can safely remove it.\r\n\r\nWhile we are at it, we could also rename `IRowToRowMapper.Schema` to `OutputSchema` to match `InputSchema`.'"
376472742,1501,b'ISchema removal',b'Remove `ISchema` interface altogether. Remove all obsolete methods of `Schema` class.\r\n\r\nThis should really be done after #1500\r\n\r\n'
376472608,1500,b'Final interface of Schema',"b'As we have agreed on the API reviews, we will make the following modifications to `Schema`:\r\n- Make it an `ICollection<Schema.Column>`\r\n- Expand `Column` class to contain 2 fields: `IsHidden` and `Index`.\r\n- Remove all methods except those exposed by collections, `this` accessors and `GetColumnOrNull`.\r\n- Make constructors internal. Create a `SchemaBuilder` (in a different namespace `Microsoft.ML.Schema`) that would be responsible to building the schema. \r\n  - This is to make it more obvious that columns are NOT reused by different schemas.\r\n- Move `Schema.Metadata.Builder` into a separate class `MetadataBuilder` in namespace `Microsoft.ML.Schema`.\r\n- Finally, probably rename to `DataSchema`'"
376470142,1498,b'Trainer always needs to check if label column is good',"b'In factorization machine, a [redundant check](https://github.com/dotnet/machinelearning/blob/7fb76b026d0035d6da4d0b46bd3f2a6e3c0ce3f1/src/Microsoft.ML.StandardLearners/FactorizationMachine/FactorizationMachineTrainer.cs#L501) is added so the check can be bypassed in some cases.'"
376415541,1495,b'the netcoreapp3.0 build is broken',"b""Follow the instructions: https://github.com/dotnet/machinelearning/blob/master/docs/building/netcoreapp3.0-instructions.md\r\n\r\nYou will get a build error:\r\n\r\n```\r\nError\tCS0266\tCannot implicitly convert type 'float*' to 'int'. An explicit conversion exists (are you missing a cast?)\tMicrosoft.ML.CpuMath(netcoreapp3.0)\tF:\\git\\machinelearning2\\src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs\t758\tActive\r\n```\r\n\r\nThis is because of #1177 \r\n\r\n```C#\r\n                float* pDstEnd = pdst + dst.Length;\r\n                float* pDstCurrent = pdst;\r\n                int destinationEnd = pDstEnd - 4;\r\n```\r\n\r\n`pDstEnd` is a `float*`. Subtracting 4 still gives you a `float*`, which is not convertable to `int`.\r\n\r\n/cc @jwood803 @tannergooding """
376222715,1492,b'Cross-Validation experiment needs more parameters and info',"b""When defining a cross validating experiment, I'd like to be able to define the proportion of records in the input set that are used in training vs testing. A common practice is specifying the % of records that need to go in the training set vs the testing set. Then use a random method of picking indexes from the data frame to form the training set based on the percentage defined before. And create a disjoint set (all indexes not picked during the first sweep) for testing.\r\n\r\nIn addition, the output of cross validation should show the size of the training set & fold sets after run."""
376222413,1491,b'Cross-Validation experiment mode: show size of the training set & fold sets after run.',b''
376211948,1490,"b'""warning CS8032: An instance of analyzer ... cannot be created ..."" when running for first time'","b""Testing latest 0.7 release candidate: [0.7.0-preview-27031-8](https://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML/0.7.0-preview-27031-8).\r\n\r\nOS: MacOS 10.14\r\n\r\nI am using VS Code and the dotnet CLI. When I change the code and do `dotnet run`, I see the following warning:\r\n\r\n```\r\nCSC : warning CS8032: An instance of analyzer Microsoft.ML.Analyzer.TypeIsSchemaShapeAnalyzer cannot be created from /Users/gal/.nuget/packages/microsoft.ml/0.7.0-preview-27031-8/analyzers/dotnet/cs/Microsoft.ML.Analyzer.dll : Could not load file or assembly 'Microsoft.CodeAnalysis, Version=2.9.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35'. The system cannot find the file specified.. [/Users/gal/Projects/mlnet0.7/anomalydetection/anomalydetection.csproj]\r\n```\r\n\r\nIf I run again without changing anything, the warning disappears.\r\n\r\nVery simple repro:\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML;\r\n\r\nnamespace anomalydetection\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine();\r\n        }\r\n    }\r\n}\r\n```"""
376201509,1489,"b'Not to use ""default"" in matrix factorization sample'","b'""default"" needs higher version of C#, but it\'s not necessary for documentation.'"
376200461,1488,b'Examples should try not to specify dependencies in csproj file ',"b'As title. Otherwise, user can not run that example by copy-and-paste.'"
376200125,1487,b'Example should start with a very brief introduction to its code organization',"b""As title. For example, in matrix factorization's example, we have two data structures and one function. We need to explain their relation in the very BEGINNING."""
376197774,1485,b'Some parameters need long doc string',"b""Sometime, a short string is not enough for describing an argument, for example, [this](https://github.com/dotnet/machinelearning/blob/273e36cbed0d9dd201c00114e1040c1860330cc1/src/Microsoft.ML.StandardLearners/FactorizationMachine/FactorizationMachineTrainer.cs#L54) may not be 100% clear until the user reads the paper. Do we have any solution for solving this (like adding paper's link into its doc string)?"""
376197196,1484,b'MatrixFactorizationTrainer should include Estimator in its name',"b'MatrixFactorizationTrainer implements IEstimator, and should therefore include ""estimator"" in its name. \r\nIt should be named something like ActionPerformingEstimator as per #1318.\r\n'"
376195024,1483,b'Parameter description for anomaly detection needs more information',"b'Testing latest 0.7 release candidate: [0.7.0-preview-27031-8](https://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML/0.7.0-preview-27031-8).\r\n\r\nThe description for ""changeHistoryLength"" is ""The change history length"". We should provide a more informative description that will help the user understand what value to provide.\r\n\r\nSide question: are there good defaults for these types of parameters? Right now changeHistoryLength and the confidence are required for IidChangePointEstimator.\r\n\r\n<img width=""1036"" alt=""image"" src=""https://user-images.githubusercontent.com/2601900/47823889-89ca4e00-dd27-11e8-83e3-9e5777fa3f9b.png"">'"
376191650,1482,b'Matrix Factorization Dependencies',"b""For matrix factorization, we need to mention all its dependencies. For example, MatrixFactorization's core part is packed in a Nuget, which is not mentioned anywhere."""
376189567,1481,b'Update the Getting Started with ML.NET tutorial to 0.7',"b'We should update the tutorial, as it does not work with 0.7. That is the starting point for many people, so we should make sure it is ready and up to date for when we release 0.7. @CESARDELATORRE If you show me how to do it, I can help with that.\r\n'"
376187248,1480,b'LocalPathReader should live in Microsoft.ML.StaticPipe',b'Otherwise I have to link Microsoft.ML.Runtime.Data in order to read file.'
376184218,1479,b'Timeseries example code is unnecessarily verbose ',b'v.0.7.0-preview-27031-8:\r\nfile: Microsoft.ML.TimeSeries.Tests/TimeSeriesDirectApi.cs\r\n\r\nList<Data> tempData = new List<Data>();\r\nfor (int i = 0; i < size / 2; i++)\r\n     tempData.Add(new Data(5));\r\nfor (int i = 0; i < size / 2; i++)\r\n      tempData.Add(new Data((float)(5 + i * 1.1)));\r\nforeach (var d in tempData)\r\n       data.Add(new Data(d.Value));\r\n\r\nSimplify the code by removing tempData.'
376177405,1478,b'Transform categories in intellisense are missing descriptions ',"b'Testing latest 0.7 release candidate: [0.7.0-preview-27031-8](https://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML/0.7.0-preview-27031-8).\r\n\r\nIt is not clear what is the difference between categorical and conversion transforms (as categorical transforms convert categorical features to numeric vectors). Descriptions are needed to explain these different categories so a user knows what to expect.\r\n\r\n<img width=""945"" alt=""image"" src=""https://user-images.githubusercontent.com/2601900/47821157-f8ee7500-dd1c-11e8-8521-8d8b07911c12.png"">'"
376170893,1477,b'Random build failures: Make test failure output on numerical comparisons semi-useful',"b""Companion issue to #1471, specific to making the test failure messages provide more helpful information than they do right now.\r\n\r\nMany of our tests are baseline tests -- that is, they produce a file, then we compare the two files. A while ago we changed the baseline test infrastructure a bit, so that rather than insisting on a perfect match, they only had to match numbers within a certain tolerance. This is in principle a positive change, but unfortunately the current code to do so is flawed in certain ways that compromise its usefulness.\r\n\r\nConsider this code here, which is the place where many of the test failures actually take place.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a26eca7e9dbec1cb8311db2e8dac7fc11bbf54ea/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs#L549-L550\r\n\r\nThis code is bad for two reasons...\r\n\r\nProbably the most egregious issue is the code, instead of using the `Fail` method as we do everywhere else, instead used xunit's `Assert`. This means that when a difference is detected it fails *immediately*, and stops the test altogether. This is extremely bad. In a given test *many* files to be baselined may be produced, and by failing on the *first* one, we will lack crucial side information that may give us a more complete picture of what is going on.\r\n\r\nThis would be especially bad in the situation where we *expect* that the baselines will be changed, and are running the tests just to produce the new files -- instead of having to run the tests *once*, we must run them *many* times, just to get the files that are baselined.\r\n\r\nThe second reason is that the message produced by this check is totally uninformative.\r\n\r\n, even if we wanted to use this `InRange` method (we don't), it's checking against a range centered around 0. So for example, when I was working on `MulticlassTreeFeaturizedLRTest`, this line was failing with reporting that `-6` was out of some small range centered around 0. But I couldn't just *re-run* the test with a breakpoint or something to figure out what was going wrong, because even *if* the Mac Visual Studio were detecting our tests (for some reason it doesn't, not sure why), the entire problem was that the test was highly non-deterministic, and it had taken me over 100 tries to even get that one repro, and a subsequent run would almost certainly succeed. But at the same time I have absolutely no idea what files.\r\n\r\nSo first I dug in and found what files would be produced in a successful run. Then I wrote a *new* test that would actually just compare these files (crucially, without trying to generate new ones!), while printing out what file failed. And it turned out to be this file here. `MulticlassLogisticRegression-TrainTest-iris-tree-featurized-out.txt`.\r\n\r\n```\r\nL1 regularization selected 78 of 78 weights.\r\n```\r\n\r\nand it should have had this line\r\n\r\n```\r\nL1 regularization selected 72 of 72 weights.\r\n```\r\n\r\nThis whole process took many frustrating minutes.\r\n\r\nSo now I found the reason for this `-6`. Because, I guess, `72-78=-6`, and obviously letting me know that `-6` was not very close to 0 was far, far more important than letting me know what file differed where. \xf0\x9f\x98\x84 \r\n\r\nAnd, to top it all of, because it is an xunit assert, all the *other* files that would be generated by this (e.g., not just train-test but also the CV comparison, were not generated, because the test was stopped right there before they could be generated. So on the whole a very \r\n\r\nSo:\r\n\r\n1. This comparison should *not* use an xunit assert, rather it should use the `Fail` mechanism, to allow the test to continue running once a difference is detected, since obviously *many* differences may be observed and in any event we do not want to stop files from being generated. (It can perhaps stop checking that *one* file, but it shouldn't stop generating files altogether.)\r\n\r\n2. The test message should be enhanced to show additional information, specifically:\r\n\r\n    - *Which* file had the difference,\r\n    - Where in the file, e.g., line and offset?\r\n    - If a numerical comparison, what were the two numbers that were compared? (Not just their difference, the actual numbers)\r\n    - Possibly even some context of the two files (surrounding lines, characters?) to make things more obvious."""
376149350,1474,b'Random build failures: Catalog the failures',"b'Companion issue to #1471. We should investigate more fully at a high level why the builds are failing.\r\n\r\n@eerhardt has helpfully provided a good list of these failures for builds that should have in principle succeeded, since they were against `master`. The task would then to be, somehow, to go through them, and determine why each has failed. This even has an analytics tab that will show the precise test failures, so perhaps this is not so hard of an issue! But getting a sense for why each has failed might itself be worthwhile, I imagine.\r\n\r\nWhile tests are I believe the primary culprit, I don\'t quite have an appreciation for how big of a problem it might be compared to other issues. For those builds that do not appear to be due to a test failure, why did they fail? Timeout? Network resources unavailable? Some other failure to setup? An actual failure to build somehow? (Of course some of these things, especially timeouts, could themselves be test failures.)\r\n\r\nAlso for those things that *are* test failures, which tests are failing, on what environments? I have a sense for some ""usual suspects"" of tests that are problematic, but I am sometimes surprised by new ones, and it would surely help to build a more complete catalog so that the investigation can focus its efforts usefully.'"
376143815,1473,b'Random build failures: Publish the test logs',"b""Companion issue to #1471. As mentioned there we are currently lacking information about test failures.\r\n\r\nOur tests actually do produce sizable logs that could *conceivably* be of help, if we were only able to access them. This includes most notable output files that are compared against baseline files, as well as in many cases the trained models themselves. For example, for a `Debug` build, and the `Microsoft.ML.Core.Tests` test, we would want to publish `bin/AnyCPU.Debug/Microsoft.ML.Core.Tests/netcoreapp2.1/TestOutput` as an artifact of the build. (The same for all tests.) We would of course want the test artifacts for *all* test assemblies to be published, as well as for either debug and release, as well as for all of the currently supported platform.\r\n\r\nWe of course used to do this, but this capability was somehow lost when we moved to the new build infrastructure a few months ago I believe.\r\n\r\nSo for example, if we [view this build](https://devdiv.visualstudio.com/DevDiv/_build/results?buildId=2162533&view=results) (note that some will not be able to access this!), we have published this artifact named `PackageAssets`, as seen below.\r\n\r\n![image](https://user-images.githubusercontent.com/8295757/47815258-1adffb80-dd0d-11e8-8d3e-7d11bc3ff79b.png)\r\n\r\nThis appears at least at first glance to be controlled from this in our repo.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a26eca7e9dbec1cb8311db2e8dac7fc11bbf54ea/build/vsts-ci.yml#L30-L35\r\n\r\n@eerhardt has already provided some assistance in this area, though as of yet I have been unable to find time to follow up on his hints.\r\n\r\n* [Documentation on publishing build artifacts.](https://docs.microsoft.com/en-us/azure/devops/pipelines/build/artifacts?view=vsts)\r\n* [A specific example, from Roslyn (not our repo of course), of doing just that.](https://github.com/dotnet/roslyn/blob/master/.vsts-ci.yml#L56-L72)\r\n\r\nOur specific `.yml` configuration files for doing the continuous integration are at the following locations:\r\n\r\n* [.vsts-dotnet-ci.yml](https://github.com/dotnet/machinelearning/blob/master/.vsts-dotnet-ci.yml)\r\n* [build/ci/phase-template.yml](https://github.com/dotnet/machinelearning/blob/master/build/ci/phase-template.yml)\r\n* [build/vsts-ci.yml](https://github.com/dotnet/machinelearning/blob/master/build/vsts-ci.yml)\r\n\r\nIt may be as simple as following Roslyn's example and modifying `build/vsts-ci.yml` to just publish a few more things, but I'm not altogether confident of this.\r\n\r\nThis may be a task best suited to someone with some experience mucking about in these configuration files."""
376143260,1472,b'How to access internals of transformer via dynamic pipeline?',"b'#1015 \r\nWe quite easily can access internals of transform via OnFit delegate in static extensions.\r\nBut I don\'t see any easy way (one which doesn\'t include tons of casting) to get to internals if I use dynamic Api.\r\n\r\n```\r\nvar est = new NormalizingEstimator(Env,new NormalizingEstimator.MinMaxColumn(""float1""));\r\nvar transformer = est .Fit(validData);\r\n```\r\nI don\'t see any easy way to get offset and scale.\r\n`(transformer.ColumnFunctions[0] as Microsoft.ML.Transforms.Normalizers.NormalizeTransform.AffineColumnFunction.Sng.ImplOne).Scale`\r\n\r\nthis is best I can come up with and I\'m not sure it will work outside of my debug environment considering what pretty much everything is internal.\r\n\r\n@TomFinley  @Zruty0  Do we care about dynamic pipelines?\r\n'"
376136517,1471,"b'Investigate the build issues, focusing on tests'","b'At the time of writing our build system is plagued by a large number of failing tests and other build issues. This impacts our agility since an otherwise valid PR can not pass the test checks for spurious reasons that have nothing to do with the change. It also in turn leads to significant wastage of resources. The goal would be to improve the test error rate.\r\n\r\nHowever, we are vexed somewhat by a lack of information on why these test failures are occurring. In particular, trying to reproduce test failures locally has, at least in my experience, very limited success. For example, in my own investigation into the random failures of `MulticlassTreeFeaturizedLRTest` on MacOS debug, I was only able to achieve a test failure twice out of some hundreds of runs on a Macbook, and what information I was able to gather was limited.\r\n\r\nIn the seeming absence of the ability to reliably produce test failures outside of the build machines, we need more information.\r\n\r\n1. Publish the tests logs as an artifact of the build so that we can gather more information. #1473.\r\n\r\n2. Make the error messages from tests, when they do occur, contain some actually useful information. #1477.\r\n\r\n3. Create a catalog of failures that occur in builds that in principle *should* have succeeded. (E.g., builds of `master`.) This is partially to validate the assumption that tests are the primary problem, as well as to get a sense of what tests are problematic. #1474.\r\n\r\nThe preceding is purely information gathering, but at the same time there are some positive steps that can be taken, pending the above.\r\n\r\n1. We already know of some troublesome tests. These should be investigated for the ""usual suspects,"" e.g., failure to set random seeds to a fixed value, having a variable number of threads in training processes, etc. (Which are known, but innocent, sources of run to run variance.)\r\n\r\n2. That the tests seem to fail so readily on the build machines yet are vexingly difficult to make fail locally suggests that there is something about the build environment that is different -- perhaps a different architecture or performance characteristics raise issues or race conditions that are simply not observed on our more performant developer machines. It may therefore be worthwhile to try to get the test environment machines reproduced exactly (down to the environment, processor, memory, everything) to see if that shows any clues.\r\n\r\n3. Most vague, but still useful, the nature of the failures, while mysterious, have not been entirely devoid of clues as to potential causes. I may write more about them in a comment later.\r\n\r\n/cc @Zruty0 @eerhardt \r\n'"
376106266,1468,b'A public member is not assigned in constructor.',b'Matrix factorization transformer needs to have row index type set...'
376096409,1466,b'Q: Retrieving DataView Schema from a Saved Model',"b""Using the new ML.Net API, say I want to fit an Estimator chain to a DataView to produce a model i.e TransformerChain. After saving the model to a Zip and then reloading from another process, is it possible to retrieve details about the schema of the DataView that the model was initialy fit to?\r\n\r\nBasically, I'd like to use the DataView schema to aid in construction of the Training class, and would preferably want to avoid persisting both the IDataView metadata and the TransformerChain to disk separately."""
375690209,1459,b'LIBMF prediction varys on Mac',b'The `MatrixFactorizationSimpleTrainAndPredict` test frequently fails on Mac with the following message. We need to figure out the reason to reduce the number of rebuilds.\r\n\r\nError message\r\n\r\nAssert.InRange() Failure\r\nRange: (0.60692207960271 - 0.61692207960271)\r\nActual: 0.592577526427063\r\nStack trace at Microsoft.ML.Tests.TrainerEstimators.TrainerEstimators.MatrixFactorizationSimpleTrainAndPredict() in /Users/buildagent/agent/agent/_work/1/s/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs:line 118'
375605387,1451,b'Optimize FastTreeNative',b'It seems FastTree uses native code or managed code based on the config `USE_FASTTREENATIVE`. Currently FastTreeNative uses SSE instructions. It could be optimized with 256 bits AVX/AVX2 instructions. It can be done either using native cpp intrinsics or C# HW intrinsics.\r\n'
375546813,1449,b'README should give guidance where to seek help',"b'Currently, the README gives no indication of where to seek help. This is confusing, as there are at least Gitter, GitHub and StackOverflow to do so. It would be nice to be explicit about where the ML.NET devs hang out and can answer questions.\r\n\r\nThis is related to #1440, but enough off-topic for that thread that I opened an additional issue.'"
375270321,1446,b'Math documents for training modules',"b""I don't see any formulations in field-aware factorization machine document for explaining what its trainer is solving. As a machine learning package, it'd be better to have more details about formulations because applied scientists may not read through our code to figure out those math equations. I guess this comment can be applied to some other modules too."""
375242557,1445,b'Bug in InferRecipes command',"b""If the argument for SchemaDefinitionFile is not null, then the command doesn't check whether the dataset has a header or not.\r\n"""
375227831,1443,b'FastTree has a reference to non-existing assembly',"b'We currently have a bunch of P/Invokes to an assembly that can\'t be found:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/69a549e5119a63c1740cdf2526098337b42a76f5/src/Microsoft.ML.FastTree/BinFile/IniFileParserInterface.cs#L13-L20\r\n\r\nWhen I try running the following code:\r\n\r\n```C#\r\n        static void Main(string[] args)\r\n        {\r\n            var env = new LocalEnvironment();\r\n\r\n            var data = new TextLoader(env, new TextLoader.Arguments\r\n            {\r\n                HasHeader = true,\r\n                Separator = ""\\t"",\r\n                Column = new[]\r\n                {\r\n                    new TextLoader.Column(""Label"", DataKind.R4, 0),\r\n                    new TextLoader.Column(""Workclass"", DataKind.Text, 1),\r\n                    new TextLoader.Column(""NumericFeatures"", DataKind.R4, new [] { new TextLoader.Range(9, 14) })\r\n                }\r\n            }).Read(new MultiFileSource(@""F:\\git\\machinelearning\\test\\data\\adult.tiny.with-schema.txt""));\r\n\r\n            // Pipeline.\r\n            var pipeline = new TermEstimator(env, new[]{\r\n                                    new TermTransform.ColumnInfo(""Workclass"", ""Group""),\r\n                                    new TermTransform.ColumnInfo(""Label"", ""Label0"") })\r\n                .Append(new FastTreeRankingTrainer(env, ""Label0"", ""NumericFeatures"", ""Group"",\r\n                    advancedSettings: s => { s.NumTrees = 10; s.PositionDiscountFreeform = ""foo""; }));\r\n\r\n            pipeline.Fit(data);\r\n        }\r\n```\r\n\r\nI get the exception:\r\n\r\n```\r\n\r\nUnhandled Exception: System.DllNotFoundException: Unable to load DLL \'NeuralTreeEvaluator.dll\': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.FastTree.Internal.IniFileParserInterface.Native.CreateFromFreeform(String freeform)\r\n   at Microsoft.ML.Runtime.FastTree.Internal.IniFileParserInterface.CreateFromFreeform(String freeform)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.LambdaRankObjectiveFunction.FillDiscounts(String positionDiscountFreeform)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.LambdaRankObjectiveFunction..ctor(Dataset trainset, Int16[] labels, Arguments args, IParallelTraining parallelTraining)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.ConstructObjFunc(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.BoostingFastTreeTrainerBase`3.ConstructOptimizationAlgorithm(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.ConstructOptimizationAlgorithm(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeTrainerBase`3.Initialize(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.Initialize(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeTrainerBase`3.TrainCore(IChannel ch)\r\n   at Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Runtime.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at ConsoleApp46.Program.Main(String[] args) in C:\\Users\\eerhardt\\source\\repos\\ConsoleApp46\\ConsoleApp46\\Program.cs:line 38\r\n```\r\n\r\n/cc @codemzs '"
375223185,1442,"b""Matrix Factorization Doesn't Support Key Starting with 0""","b'For row index = 0 or column index = 0, [this mapper](https://github.com/dotnet/machinelearning/blob/ef2bade365a90d926a944ebfc424b8a84374921c/src/Microsoft.ML.Recommender/MatrixFactorizationPredictor.cs#L230) always use NaN as the output score.'"
375222197,1441,b'Matrix factorization should work in x86',b'Matrix factorization fails in x86 (MatrixFactorizationSimpleTrainAndPredict test was disabled as part of #1432).\r\n\r\nThe reason is that the MFModel struct is architecture dependent: https://github.com/dotnet/machinelearning/blob/eae76959e6714af44caa212e102a5f06f0110e72/src/Microsoft.ML.Recommender/SafeTrainingAndModelBuffer.cs#L67-L80\r\n\r\nThe struct matches the output data structure produced by c++ code in the libmf library. \r\n\r\nSee the following comment for how this issue should be solved using P/Invoke instead: https://github.com/dotnet/machinelearning/pull/1432#discussion_r229095196'
375219700,1440,b'ML.NET Dev community should be supported for better success.',"b'We constantly review various ways by which we can help the broader developer community to contribute to ML.NET. There are multiple channels through which we can communicate and help the community (GitHub issues, Gitter, upcoming public Teams, YouTube live, slack, Good old mailing list!, \xe2\x80\xa6).\r\n\r\nThis issue is filed to start a discussion on what would be the good set of tools that the community prefers to use (and we are able to support long term).\r\n\r\n@markusweimer, @Zruty0 , @terrajobst , @GalOshri , @jwood803 , @rauhs , @feiyun0112 , @adamsitnik , @bojanmisic , @danmosemsft , @eerhardt , @CESARDELATORRE , @helloguo , @mjmckp , @fiigii'"
375209040,1438,"b'""Installing dotnet cli..."" Hangs forever'","b'### System information\r\n\r\n- **OS version/distro**: Some Debian 9 based distro\r\n- **.NET Version (eg., dotnet --info)**: 2.1.403\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI just did this after cloning: \r\n`chmod +x ./build.sh`\r\n`$ ./build.sh`\r\n\r\n- **What happened?**\r\n`Installing dotnet cli...`\r\n\r\n- **What did you expect?**\r\nI expected the program not to hang forever on this operation. Nothings happens. I already had dotnet 2.1 btw. \r\n`$ which dotnet`\r\n`/usr/bin/dotnet`\r\n\r\n\r\n### Source code / logs\r\n\r\nBefore executing, I did: \r\n`git clone --recurse-submodules https://github.com/dotnet/machinelearning.git`\r\n`git submodule update --init --recursive`\r\n'"
375173521,1436,b'Bug in KeyToVector conversion to PFA',"b'The condition in the ""if"" clause in line 678 needs to be negated.'"
375147772,1435,b'The LightGBM tests fail on x86',"b'There is no LightGBM available yet on the Windows x86 build, therefore the tests should be marked to not run on x86. \r\n\r\nThe two newly added tests: MultiClassLightGBM and LightGBMRanking need to be executed conditionally. \r\n'"
375119214,1431,b'WordTokenizeTransform ignores per-column definition of separators',"b'It only looks at the separators in the Arguments object, not in the Column object.'"
375109492,1429,b'Bug in MultiOutputRegressionEvaluator metadata',"b'The builder sets the ""ScoreValueKind"" metadata instead of the ""ScoreColumnSetId"" metadata.\r\n'"
374906292,1425,"b""'Value cannot be null' exception on trivial estimator append""","b'The following code throws:\r\n\r\n```csharp\r\n      var env = new ConsoleEnvironment(seed: 1, conc: 0);\r\n      var dataView = env.CreateDataView(new[]{new {A = ""A"", B = ""B""}}).AssertStatic(env, c => (\r\n        A: c.Text.Scalar,\r\n        B: c.Text.Scalar));\r\n\r\n      dataView.MakeNewEstimator().Append(row => (row.A, row.B));\r\n```\r\n\r\nIf this is intentional feel free to close it. Though I found the error at least hard to understand. I needed this step for weird reasons.\r\n\r\nAdding some simple op will make it work:\r\n\r\n```csharp\r\n      dataView.MakeNewEstimator().Append(row => (row.A, row.B, c: row.B));\r\n```\r\n\r\n'"
374859034,1424,b'Incorrect model returned by LightGBM calibration for multiclass with softmax',"b'https://github.com/dotnet/machinelearning/blob/5123aeedb91a435236e8b94ba0f17a6d15a20db5/src/Microsoft.ML.LightGBM/LightGbmMulticlassTrainer.cs#L104\r\n\r\nThe model returned here is only correct if the objective type is `multiclassova`, since the `OvaPredictor` predictor type created here always just normalises the `_numClass` probabilities to sum to one:\r\nhttps://github.com/dotnet/machinelearning/blob/5123aeedb91a435236e8b94ba0f17a6d15a20db5/src/Microsoft.ML.StandardLearners/Standard/MultiClass/Ova.cs#L575\r\n\r\nHowever, when the objective type is `multiclass` (i.e., softmax), what should happen is that the `OvaPredictor` type should be given an array of predictors that return the _raw_ scores from each of the trees (i.e., the result of `CreateBinaryPredictor` instead of the `FeatureWeightsCalibratedPredictor`), and instead of normalising the outputs of these predictors, it should be computing the softmax function of the raw scores, as is done in the LightGBM implementation:\r\nhttps://github.com/Microsoft/LightGBM/blob/087d30623aef4b50592cf528eb50c1c55baeaab8/src/objective/multiclass_objective.hpp#L115\r\n\r\nThese kind of bugs would be easily detected if there were unit tests comparing the results of evaluating the managed ML.NET GBDTs against the original native implementation (i.e., calling `LGBM_BoosterPredictForMat` on the Booster object used to calibrate the model).'"
374832138,1423,b'Local build fails on master ',b'On Windows 10 machine\r\n\r\n> git clone https://github.com/dotnet/machinelearning.git\r\n> cd machinelearning\r\n> build \r\n\r\nBuild Failed.\r\nCMake Error at MatrixFactorizationNative/CMakeLists.txt:14 (add_library):\r\n    No SOURCES given to target: MatrixFactorizationNative\r\n\r\n\r\n\r\n'
374820996,1422,b'Hardwired value of Sigmoid parameter used instead of value specified in parameters',"b'https://github.com/dotnet/machinelearning/blob/5123aeedb91a435236e8b94ba0f17a6d15a20db5/src/Microsoft.ML.LightGBM/LightGbmBinaryTrainer.cs#L133\r\n\r\nThe hardwired value `0.5` in the line above should instead be the value of the `Sigmoid` parameter specified when the model was trained (the default value of which is 1, but used to be 0.5).'"
374812165,1421,"b""LightGBM tests fails in x86 build, but that doesn't stop build""","b""So let's take this build:\r\nhttps://dnceng.visualstudio.com/public/_build/results?buildId=36379&view=logs\r\nIt fails on MacOS and @wschin  working on it https://github.com/dotnet/machinelearning/issues/1395\r\n\r\n![image](https://user-images.githubusercontent.com/1523833/47623415-6eb0d180-dace-11e8-9ba0-654270a11be9.png)\r\nbut if you look into failed tests tab:\r\n![image](https://user-images.githubusercontent.com/1523833/47623417-8425fb80-dace-11e8-9b20-d8eca458e92d.png)\r\nit show you what x86 windows builds also failed, but that didn't affected their successful status.\r\n"""
374738572,1419,b'Need a state of evaluation result after each epoch during training.',"b""### Issue\r\n\r\n- **I'm training my model. But I have no idea how good my model architecture is. And how much pretraining additional efforts required**\r\n- **In some cases it is trained ok, and in others, I cannot go out of 1 % (I'm seeing only final results), but anyway I don't see how right is the evaluation process during the timeline (after each epoch of training). Maybe it has been overfitted after few first epochs? I can't analyze it - too little data.**\r\n- **I would expect to have some object to store this state (I believe it is on a private level, but I don't see it in public API) after each epoch and I suppose to be able to iterate forward until I reach some level of percentile. See how Keras from Python world do it.**\r\n"""
374603754,1411,b'Convenient way of providing LDA topic summary',"b'In the `LdaTransform`,  the details of the learnt model are contained in the `LdaState` object.  When the user wants to introspect the LDA model learnt during the transformation, we return a topic summary vector .\r\n\r\nWe need to find a proper way of returning topic summary information to the user. Specifically the words that map to the topic summary vector \r\n\r\nFor this we need to figure out how to extract details from the `LdaState` object using C#.  Currently  `LdaState` invokes native code behind the scenes to get model info.'"
374592282,1409,b'Clean up TensorFlowTests to not use direct instantiation',"b'The TensorFlowTests is the only reason we have `CreatePredictionEngine` as a public extension method. We should re-work the tests to work via Estimators/Transformers, and remove the extension.'"
374583345,1408,b'Matrix factorization related improvements',"b""ML.NET's matrix factorization is using LIBMF v1.2. We need to sync it with LIBMF's latest release. In addition, we need to modify LIBMF so that SSE code can be enabled (we didn't do that because CI's Mac doesn't support SSE3)."""
374554880,1404,b'Only execute dotnet build-server shutdown at the end of official builds',"b'Currently we run dotnet build-server shutdown at the end of all Windows builds. \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/dd1a92223c50bde8f659f95df0fab6eaaa482234/run.cmd#L27-L29\r\n\r\nAs pointed out by @eerhardt in #1390 we should instead only run it at the end of official builds, by adding the command to the .yml file instead of run.cmd. \r\n'"
374491831,1403,b'Improve error message for missing LightGBM dependencies at runtime.',"b""### System information\r\n\r\n- **macOS 10.13**:\r\n- **.NET Core 2.1.4**: \r\n\r\n### Source code / logs\r\n\r\n`Error: *** System.DllNotFoundException: 'Unable to load DLL 'lib_lightgbm': The specified module or one of its dependencies could not be found.`\r\n\r\n### Issue\r\n\r\nUsing LightGBM on a Mac requires OpenMP as a runtime dependency (libomp.dylib or libgomp.dylib).  The error message does not make it clear that this is the problem.  The user would have to search and determine whether lib_lightgbm.dylib actually does exist, and then use `otool -L lib_lightgbm.dylib` to discover it's dependent libs and then search for them.  Some versions of LightGBM require libgomp (the GCC implementation) while others require libomp.\r\n\r\n@TomFinley, in relation to https://github.com/Microsoft/NimbusML/issues/18 can we do a `dlopen` check in [LightGbmTrainerBase](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs) to verify runtime dependencies and print a more helpful error message?  Or should I open an issue in https://github.com/Microsoft/LightGBM?\r\n\r\n\r\n"""
374489181,1402,"b""[Docs] Explicitly clarify that IEstimator Append() doesn't alter the calling object""","b""In estimator1.Append(estimator2) it's not 100% clear that estimator1 is not changed. The summary comment for Append() should highlight that.\r\n```csharp\r\n        /// <summary>\r\n        /// Append another estimator to the end.\r\n        /// </summary>\r\n        public CompositeReaderEstimator<TSource, TNewTrans> Append<TNewTrans>(IEstimator<TNewTrans> estimator)\r\n```\r\n\r\nShould be \r\n```csharp\r\n        /// <summary>\r\n        /// Create a new reader estimator, by appending another estimator to the end of this reader estimator.\r\n        /// </summary>\r\n        public CompositeReaderEstimator<TSource, TNewTrans> Append<TNewTrans>(IEstimator<TNewTrans> estimator)\r\n```"""
374471519,1401,b'Matrix Factorization Needs Documentation',b'The newly added module only has a test but we definitely need a user-facing document. Users may not read through my test code. Something like [this](https://github.com/dotnet/machinelearning/blob/369bcbbf55ce0c78e9e188434dc235a5dd6233e6/src/Microsoft.ML.StandardLearners/FactorizationMachine/FactorizationMachineTrainer.cs#L35) and the actual [XML file](https://github.com/dotnet/machinelearning/blob/970f401482b2eb2b399766cf10fc418885096440/src/Microsoft.ML.StandardLearners/FactorizationMachine/doc.xml) are required.'
374463185,1399,b'build.sh fails on Linux due to a unitialised Git submodule',"b""### Issue\r\n- `build.sh` fails on Linux as libmf which is included as a Git submodule is not available unless submodules have been initialized.\r\n\r\n### Logs\r\n```\r\n  + cmake /home/tpalohei/machinelearning-foo/src/Native -G 'Unix Makefiles' -DCMAKE_BUILD_TYPE=Debug -DMKL_LIB_PATH=/home/tpalohei/machinelearning-foo/packages/mlnetmkldeps/0.0.0.7/runtimes/linux-x64/native -DMKL_LIB_RPATH=../../../../../microsoft.ml.mkl.redist//runtimes/linux-x64/native -DVERSION_FILE_PATH:STRING=/home/tpalohei/machinelearning-foo/src/Native/../../bin/obj/version.c\r\n  -- The C compiler identification is Clang 7.0.0\r\n  -- The CXX compiler identification is Clang 7.0.0\r\n  -- Check for working C compiler: /usr/lib/llvm/7/bin/clang\r\n  -- Check for working C compiler: /usr/lib/llvm/7/bin/clang -- works\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Check for working CXX compiler: /usr/lib/llvm/7/bin/clang++\r\n  -- Check for working CXX compiler: /usr/lib/llvm/7/bin/clang++ -- works\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Configuring done\r\n  CMake Error at MatrixFactorizationNative/CMakeLists.txt:14 (add_library):\r\n    Cannot find source file:\r\n  \r\n      libmf/mf.cpp\r\n  \r\n    Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm\r\n    .hpp .hxx .in .txx\r\n  \r\n  \r\n  -- Build files have been written to: /home/tpalohei/machinelearning-foo/bin/obj/x64.Debug/Native\r\n  CMake Error at MatrixFactorizationNative/CMakeLists.txt:14 (add_library):\r\n    No SOURCES given to target: MatrixFactorizationNative\r\n```"""
374462854,1398,b'Static TextLoader Cannot Load Key Values',b'The static `TextLoader` (defined in `TextLoaderStatic.cs`) supports float(s) and text(s) but we still need keys for matrix factorization which maps two keys to a number.'
374457985,1397,b'Q: ML Model Builder',b'Is there any update with regards the VisualStudio ML Model Builder prototype; is/will this available as a preview ?'
374435849,1396,b'An internal SaveAsOnnx test fails',"b'The test\r\n```\r\n        public void OnnxNormalize()\r\n        {\r\n            // Some normalize types are not supported. These will be ignored.\r\n            // If they are supported in the future, then this baseline will\r\n            // need to be updated.\r\n            InitOnnxPath(out string onnxName, out string onnxPath, out string jsonPath, out string onnxArg);\r\n            string pathData = GetDataPath(@""..\\UCI\\iris"", ""iris.data"");\r\n            MainForTest(""saveonnx odrop=A domain=ONNX loader=text{col=A:0-3 sep=comma} "" +\r\n                ""xf=minmax{col=MMZ:A zero-} xf=minmax{col=MM:A} "" +\r\n                ""xf=meanvar{col=MV:A} xf=lognormal{col=LN:A} xf=bin{col=BIN:A} "" +\r\n                $""data={{{pathData}}}"" +\r\n                onnxArg);\r\n\r\n            CheckEqualityNormalized(OutRoot, onnxName);\r\n            OnnxSmokeTest(onnxPath);\r\n            Done();\r\n        }\r\n```\r\nfails because a null string `variableName`, is fed into\r\n```\r\nctx.CreateNode(""Identity"", variableName, trueVariableName, ctx.GetNodeName(""Identity""), """");\r\n```\r\nas its input name.\r\nThe following command line can produced a similar error:\r\n```\r\ndotnet mml.dll saveonnx odrop=A domain=ONNX loader=text{col=A:0-3 sep=comma} xf=minmax{col=MMZ:A zero-} xf=minmax{col=MM:A} xf=meanvar{col=MV:A} xf=lognormal{col=LN:A} xf=bin{col=BIN:A} data={C:\\AlgorithmsAndDataScience\\TLC\\Samples\\UCI\\iris\\iris.data} onnx={C:\\AlgorithmsAndDataScience\\TLC\\TestOutput\\SingleDebug\\..\\Common\\Onnx\\OnnxNormalize.pb} json={C:\\AlgorithmsAndDataScience\\TLC\\TestOutput\\SingleDebug\\..\\Common\\Onnx\\OnnxNormalize.json} \r\n```'"
374429407,1395,b'Matrix Factorization Test Occasionally Fails on Mac',"b""For example, [this PR](https://dnceng.visualstudio.com/public/_build/results?buildId=35727&view=logs) didn't get a green light after being merged into mater. Error message is attached below\r\n```\r\n2018-10-26T06:52:07.2739370Z Failed   Microsoft.ML.Tests.TrainerEstimators.TrainerEstimators.MatrixFactorizationSimpleTrainAndPredict\r\n2018-10-26T06:52:07.2739480Z Error Message:\r\n2018-10-26T06:52:07.2739580Z  Assert.True() Failure\r\n2018-10-26T06:52:07.2739680Z Expected: True\r\n2018-10-26T06:52:07.2739770Z Actual:   False\r\n2018-10-26T06:52:07.2739870Z Stack Trace:\r\n2018-10-26T06:52:07.2740110Z    at Microsoft.ML.Tests.TrainerEstimators.TrainerEstimators.MatrixFactorizationSimpleTrainAndPredict() in /Users/buildagent/agent/agent/_work/1/s/test/Microsoft.ML.Tests/TrainerEstimators/MatrixFactorizationTests.cs:line 102\r\n2018-10-26T06:52:07.2740300Z Standard Output Messages:\r\n2018-10-26T06:52:07.2740430Z  Test MatrixFactorizationSimpleTrainAndPredict: aborted: passe\r\n```\r\nSometime it gets passed but it looks like a numerical stability problem on Mac. Maybe we should relax the tolerance used in that test. @shauheen, any comment?"""
374207837,1391,b'BenchmarksProjectIsNotBroken fails on x86',b'When running the below commands BenchmarksProjectsIsNotBroken fails. \r\n\r\nbuild -buildArch=x86 -Release\r\nbuild -buildArch=x86 -Release -runTests\r\n\r\nAs part of #1309 I have added a skip for the test when run in x86. The test should be fixed and re-enabled.\r\n\r\nI am attaching a log of the failure encountered. \r\n\r\n[log_31_34669.zip](https://github.com/dotnet/machinelearning/files/2517465/log_31_34669.zip)'
374194197,1389,b'Add x86 CI PR verification build',"b'This is a follow up to #1295, which took care of the Official x86 build. We now need to add the Windows x86 CI PR verification build.'"
374163492,1387,b'OVA accuracy drop',"b""Running OVA with AveragedPerceptron{lr=0.8} on the iris dataset used to give the following confusion table:\r\n\r\n                   ||========================\r\nPREDICTED ||     0 |     1 |     2 | Recall\r\nTRUTH        ||========================\r\n                0 ||    50 |     0 |     0 | 1.0000\r\n                1 ||     0 |    47 |     3 | 0.9400\r\n                2 ||     0 |     0 |    50 | 1.0000\r\n                   ||========================\r\n\r\nNow it gives this:\r\n\r\n                   ||========================\r\nPREDICTED ||     0 |     1 |     2 | Recall\r\nTRUTH        ||========================\r\n                0 ||    50 |     0 |     0 | 1.0000\r\n                1 ||     0 |    20 |    30 | 0.4000\r\n                2 ||     0 |     0 |    50 | 1.0000\r\n                   ||========================\r\n\r\nNote: currently OVA doesn't calibrate its models since in line 126 this\r\n\r\n                var calibratedModel = transformer.Model as TScalarPredictor;\r\n\r\nshould be this instead:\r\n\r\n                var calibratedModel = transformer.Model as TDistPredictor;\r\n\r\n"""
374161584,1386,b'Need to simplify Data Types to simpler/less common .NET types',"b'In the dynamic API we have too many and not .NET ""standard types"" you need to use when creating the file columns schema for loading data. The list of types is not very ""dotnetty"":\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/47534500-6e190080-d86c-11e8-9553-535625943d47.png)\r\n\r\nThis is what you see in intellisense:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/47534520-7bce8600-d86c-11e8-811a-55c1c4030a61.png)\r\n\r\nFor instance for text you have Text, TX, and TXT, many types not very clear like R4, etc.\r\n\r\nWe need to have a simpler and more standard list of data types.'"
374107627,1382,b'CI build failing due to timeout errors',b'Some of the tests are taking really long time to run which cause the build to run for more than 60 mins and are then declared as failure. Some of tests that Run for a lot of time are\r\n\r\nMicrosoft.ML.Runtime.RunTests.TestPredictors takes 33mins and it only executes 59 tests\r\nTestHyperparameterFreezing -24min\r\nFastTreeBinaryClassificationCategoricalSplitTest -18min\r\nSavePipeWithHeader -4min\r\n\r\n\r\nMaybe we should fix those tests. We can try running the tests in parallel using helix rather than in a chain.\r\n\r\ncc @eerhardt @safern '
374076752,1380,b'Need predictedLabel in binary classification as original string value (not bool)',"b'Using ML.NET NuGet 0.7.0-preview-27025-1.\r\n\r\nI have a binary classification dataset with string labels: ""Spam"", ""Not Spam"". \r\nI need to use the TermEstimator to turn the label into a key for the training to work. \r\nOne output in the prediction from the binary classifier (let\'s say SDCA), is predictedLabel, which is a bool. \r\n\r\nHow do I map the bool back to ""Spam"" or ""Not Spam""? \r\n\r\nThank you!'"
373938316,1379,b'Data.Schema.Column should get a DebuggerDisplay',"b""Background: I'm trying to write something like `TryGetScoreColumnNames` for a `Key<uint, string>` type. I noticed a that a schema in the debugger will just give me a long list of `Data.Schema.Column` (in my case ~60 of them). In the debugger it'd be nice to have the column name displayed and possibly even the data type.\r\n\r\n"""
373756727,1374,"b'TryParse* methods should not throw, but should instead return false in case of failure'","b'Currently methods in Conversion.cs that try to parse text throw on failure, they should instead return false.'"
373751205,1372,b'Bug in check for existence of Group field',"b'https://github.com/dotnet/machinelearning/blob/263a67b94a0747463d3002d0007dbac5257dd58c/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs#L428\r\n\r\nShould be\r\n```\r\nch.Check(factory.Data.Schema.Group != null, ""The data for ranking task should have group field."");\r\n```'"
373715023,1369,b'Add AnomalyDetectionContext to the TrainContext',b'Currently the TrainContext is missing a  TrainContextBase for anomaly detection. \r\nThis is needed in order to do anomaly detection with the new API. \r\n'
373671063,1367,b'Printing training statistics by default discussion',"b'Before the ML.Net Environment changes to Local environment, PR #923 during training of a pipeline, we would see output in the console. \r\n\r\nI am trying a long-ish to train model today; takes about 4 minutes, and I find the absence of any progress reporting unsettling. I am not sure whether things are working as expected, or working at all. \r\nI think this will be off-putting for the users. \r\n\r\n\r\n'"
373629929,1366,b'Text transform discussion',"b'Let\'s continue discussion here (I\'ll edit post by looking into existing factories)\r\n@justinormont  @Zruty0 @TomFinley @yaeldekel @GalOshri \r\nStop words arguments:\r\n```\r\n[Argument(ArgumentType.AtMostOnce, HelpText = ""Dataset language or \'AutoDetect\' to detect language per row."", ShortName = ""lang"", SortOrder = 3)]\r\npublic Language Language = DefaultLanguage;\r\n\r\n[Argument(ArgumentType.Multiple, HelpText = ""Stopwords remover."", ShortName = ""remover"", NullName = ""<None>"", SortOrder = 4)]\r\npublic IStopWordsRemoverFactory StopWordsRemover;\r\n```\r\n\r\nWill get changed into:\r\n```\r\npublic Language Language = DefaultLanguage;\r\n\r\npublic bool UsePredefinedStopWordRemover;\r\n```\r\n'"
373622847,1364,"b""CountFeatureSelection transform doesn't work with text""","b""It uses a generic CountAggregator class which requires the type to be IEquatable, and ReadOnlyMemory<char> is not IEquatable. It doesn't seem like Equals() is used anywhere though, so I think this constraint can be removed.\r\n"""
373620751,1363,b'Add documentation samples for the regression trainers',b'Similar to PR #1361 we need code samples to reference from the new MLContext catalog extensions for all regression trainers.\r\n\r\nYou can use the same scenario and [dataset as the static tests](https://github.com/dotnet/machinelearning/commit/53cdb20358e7ae98cdaf6de198e35f48fbdac269#diff-3e289e9a8934a9319924a1e4ef300bcf) .\r\n\r\nCross reference those samples from the respective extensions on the catalog files like [SDCA is doing](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs#L37) \r\n\r\nTrainers:\r\n[SDCA](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaCatalog.cs#L32)\r\n[Poisson](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/LbfgsCatalog.cs#L69)\r\n[ODG](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/Online/OnlineLearnerStatic.cs#L118)\r\n[FastTree](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeCatalog.cs#L29)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmCatalog.cs#L29)\r\n\r\n'
373615945,1362,b'Add documentation samples for binary classifiers using the dynamic API ',b'Similar to PR #1361 we need code samples to reference from the new MLContext catalog extensions for all binary learners. \r\n\r\nReference to the sample in PR #1361 and add samples for the following binary trainers. \r\nCross reference those samples from the respective extensions on the catalog files.\r\n\r\nTrainers:\r\n[SGD](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SgdCatalog.cs)\r\n[LogisticRegression](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/LbfgsCatalog.cs#L33)\r\n[FFM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/FactorizationMachine/FactorizationMachineCatalog.cs#L26)\r\n[FastTree](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeCatalog.cs#L60)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmCatalog.cs#L63)\r\n\r\n'
373598007,1360,"b""Don't use the default column names in the new API""","b'The usage of the default column names is more of a source of trouble than beneficial in my opinion. \r\nProviding defaults for the numeric values is one think - we know the algorithms, and what ranges might work best for most datasets, and we also want to give a guideline on their range. \r\n\r\nThe columns are unlikely to be called what ML.Net calls them, across datasets, and it is easy to omit them from the signature when they are set to defaults. \r\n\r\nConsider this pipeline:\r\n```\r\n var pipeline = mlContext.Transforms.Text.FeaturizeText(""SentimentText"", ""Features"")\r\n                    .Append(mlContext.BinaryClassification.Trainers.StochasticDualCoordinateAscent(label: ""Sentiment"", features: ""Features"", l2Const: 0.001f));\r\n\r\n            // Step 3: Run Cross-Validation on this pipeline, and dataFile.\r\n            var cvResult = mlContext.BinaryClassification.CrossValidate(data, pipeline);\r\n```\r\nwithout specifying the label on CrossValidate \r\n\r\n `  var cvResult = mlContext.BinaryClassification.CrossValidate(data, pipeline, labelColumn: ""Sentiment"");\r\n`\r\nthis will fail with message: \'Label column \'Label\' not found\'\r\nwhich requires some level of looking aroudn to eventually figure out the mismatch between your data and the defaults on CV. \r\nWhy push that to the users, when we can just guide them towards providing the right names where the apis need them. \r\n\r\ncc @Zruty0  @shauheen @GalOshri @TomFinley for opinions \r\n\r\n'"
373590248,1359,b'Need to add PackageReference to System.Memory from ML.CpuMath nuget',"b'With #1229, we added a new dependency from the ML.CpuMath.csproj to `System.Memory`, however we didn\'t add the dependency to the nuget package.\r\n\r\nIn the .csproj:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d63e21ea1e3f6b950a48deb36045747d67dd02fa/src/Microsoft.ML.CpuMath/Microsoft.ML.CpuMath.csproj#L27-L33\r\n\r\nbut in the .nupkgproj:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/d63e21ea1e3f6b950a48deb36045747d67dd02fa/pkg/Microsoft.ML.CpuMath/Microsoft.ML.CpuMath.nupkgproj#L3-L16\r\n\r\nNOTE: We should also remove the `<PackageReference Include=""System.Runtime.Intrinsics.Experimental"" Version=""4.6.0-preview1-26708-04"" />` as well, as this is no longer needed.'"
373583673,1358,"b'""Can\'t re-use trainer!"" message on CV with AveragePerceptron. '","b'Running CV with Average Perceptron throws: ""Can\'t re-use trainer"":\r\n\r\nDataset: [wikiDetox](https://github.com/dotnet/machinelearning/blob/76cb2cdf5cc8b6c88ca44b8969153836e589df04/test/data/wikipedia-detox-250-line-data.tsv)\r\n\r\nCode:\r\n```\r\nvar data= mlContext.Data.TextReader(new TextLoader.Arguments()\r\n                {\r\n                    Separator = ""tab"",\r\n                    HasHeader = true,\r\n                    Column = new[]\r\n                    {\r\n                        new TextLoader.Column(""Sentiment"", DataKind.BL, 0),\r\n                        new TextLoader.Column(""SentimentText"", DataKind.Text, 1)\r\n                    }\r\n                }).Read(dataFile);\r\n\r\nvar pipeline = mlContext.Transforms.Text.FeaturizeText(""SentimentText"", ""Features"")\r\n                    .Append(mlContext.BinaryClassification.Trainers.AveragedPerceptron(label: ""Sentiment"", features: ""Features""));\r\n```\r\n\r\n\r\n\r\n\r\n'"
373573233,1357,b'Official build fails occasionally during cleaning',"b'Our official build has started failing during the ""Get sources"" step in the `Package Job` leg:\r\n\r\nhttps://devdiv.visualstudio.com/DevDiv/_build?definitionId=8739&_a=summary\r\n\r\n```\r\n2018-10-24T15:20:03.7394442Z ##[warning]Unable to run ""git clean -ffdx"" and ""git reset --hard HEAD"" successfully, delete source folder instead.\r\n2018-10-24T15:20:04.6899315Z ##[error]System.AggregateException: One or more errors occurred. (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\dotnet.exe\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\hostpolicy.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\clrjit.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\netstandard.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\clrcompression.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\Microsoft.DotNet.Build.Tasks.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\coreclr.dll\' is denied.)) (One or more errors occurred. (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\mscorrc.debug.dll\' is denied.)) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\dotnet.exe\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\hostpolicy.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\clrjit.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\netstandard.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\clrcompression.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\Microsoft.DotNet.Build.Tasks.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\coreclr.dll\' is denied.) (Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\shared\\Microsoft.NETCore.App\\2.1.3\\mscorrc.debug.dll\' is denied.) ---> System.UnauthorizedAccessException: Access to the path \'E:\\A\\_work\\327\\s\\Tools\\dotnetcli\\dotnet.exe\' is denied.\r\n   at System.IO.FileSystem.DeleteFile(String fullPath)\r\n```\r\n\r\nWhen this occurs, it appears to happen when the `Windows Job` runs on the same machine as the `Package Job`. So a process must be leaking during the `Windows Job`, and is holding on to `dotnet.exe` and friends. Thus when the `Package Job` executes, and tries cleaning the repo, it fails.\r\n\r\nA possible fix here is to kill any `dotnet` processes after `Windows Job`. See https://github.com/dotnet/corefx/blob/master/buildpipeline/DotNet-CoreFx-Trusted-Windows.json#L26-L45 for an example.\r\n\r\nAnother possible fix is to call `dotnet build-server shutdown` at the end of our build scripts (assuming it is the build-server that is holding `dotnet.exe` open.'"
373492278,1356,b'System.IO.PathTooLongException when Saving Model',"b""### System information\r\n\r\n- **Windows**:\r\n- **.NET Version 4.7.2**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI tried to save a model.\r\n- **What happened?**\r\nI got a 'System.IO.PathTooLongException', and saving was unsuccessful.\r\n- **What did you expect?**\r\nI expected the model to save. When training other models in the same application, they save successfully.\r\n\r\n### Source code / logs\r\n**Exception hit at:**\r\nMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Model.Repository.GetPath(out string pathEnt, out string pathTemp, string dir, string name, bool createDir) Line 270\r\n\\src\\Microsoft.ML.Data\\Model\\Repository.cs(270)\r\n\r\n**In Watch**, 'entityPath' = 'C:\\Users\\Ian Wallace\\AppData\\Local\\Temp\\TLC_4A390CA5\\TransformerChain\\Transform_000\\Transform_000\\Transform_000\\Transform_000\\Transform_000\\Transform_001\\Transform_000\\Transform_000\\Transform_000\\Transform_000\\Transform_000\\Step_002\\Mapper\\Vocabulary\\Model.key' \r\n\r\n**Exception:**\r\nSystem.IO.PathTooLongException\r\n  HResult=0x800700CE\r\n  Message=The specified path, file name, or both are too long. The fully qualified file name must be less than 260 characters, and the directory name must be less than 248 characters.\r\n  Source=mscorlib\r\n  StackTrace:\r\n```\r\n   at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) in f:\\dd\\ndp\\clr\\src\\BCL\\system\\io\\__error.cs:line 168\r\n   at System.IO.Directory.InternalCreateDirectory(String fullPath, String path, Object dirSecurityObj, Boolean checkHost) in f:\\dd\\ndp\\clr\\src\\BCL\\system\\io\\directory.cs:line 374\r\n   at System.IO.Directory.InternalCreateDirectoryHelper(String path, Boolean checkHost) in f:\\dd\\ndp\\clr\\src\\BCL\\system\\io\\directory.cs:line 115\r\n   at Microsoft.ML.Runtime.Model.Repository.GetPath(String& pathEnt, String& pathTemp, String dir, String name, Boolean createDir) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\Repository.cs:line 270\r\n   at Microsoft.ML.Runtime.Model.RepositoryWriter.CreateEntry(String dir, String name) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\Repository.cs:line 329\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext..ctor(RepositoryWriter rep, String dir, String name) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaveContext.cs:line 87\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveSubModel(String dir, Action'1 fn) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 79\r\n   at Microsoft.ML.Runtime.Data.TermTransform.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Transforms\\TermTransform.cs:line 707\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.RowToRowMapperTransform.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataView\\RowToRowMapperTransform.cs:line 299\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TextTransform.Transformer.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Transforms\\Text\\TextTransform.cs:line 627\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.Save(ModelSaveContext ctx) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 159\r\n   at Microsoft.ML.Runtime.Model.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\Model\\ModelSaving.cs:line 38\r\n   at Microsoft.ML.Runtime.Data.TransformerChain'1.SaveTo(IHostEnvironment env, Stream outputStream) in E:\\A\\_work\\292\\s\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformerChain.cs:line 195\r\n```\r\n**Comments**:\r\nWhen the local user's temp folder path is combined with the temporary folder hierarchy created while saving, it can exceed the 260 character limit.\r\nI can save other models successfully using the same code. The folder hierarchy has less depth, so I guess they don't hit the limit.\r\n\r\n**Workaround**:\r\nI can set the local user TMP environment variable to 'C:\\Tmp', reboot, and the model saves successfully."""
373391385,1354,b'ML.Net Bad value at line 7 in column Label',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\nml.net sentiment analysis warning about format errors & bad values But still getting following errors. Most of training is going in errors\r\n\r\n- **What did you do?**\r\nWent through the sample provided as it is at:\r\n[https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/sentiment-analysis](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/sentiment-analysis)\r\n- **What happened?**\r\nErrors reading the input text\r\n- **What did you expect?**\r\nCode should read all input sample text\r\n\r\n### Source code / logs\r\nIssue asked origionally at:\r\n[https://stackoverflow.com/questions/52837792/ml-net-bad-value-at-line-7-in-column-label](https://stackoverflow.com/questions/52837792/ml-net-bad-value-at-line-7-in-column-label)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
373209597,1351,b'Microsoft.ML.FastTree project set to DisableDefaultCompileItems ',"b""https://github.com/dotnet/machinelearning/blob/63a74bbb81753a2a6c0d73acc83fbbdd886f1a28/src/Microsoft.ML.FastTree/Microsoft.ML.FastTree.csproj#L7\r\nthis line basically force us to enumerate all files in project through <CompileItem>\r\nI don't see any reason why we doing so, and it's uncommon for our projects.\r\nSo I suggest to delete that conditions, all CompileItems."""
373206610,1349,b'Add support for resetting progress channels',"b'Progress channels store the names of the components that have been created, and the number of instances of each component. When they print progress they add a counter indicating how many times this component has been created, for example:\r\n""training minmax normalizer #3 ...""\r\n\r\nWe should add an option to reset these counters, to make unit tests reproducible and be able to baseline progress reports.'"
373202432,1348,b'Build failed because of building time larger than 60 mins',b'[My build](https://dnceng.visualstudio.com/public/_build/results?buildId=34123&view=logs) got canceled because it needs more than 60 mins for debug mode. A screen shot is attached below.\r\n\r\n![image](https://user-images.githubusercontent.com/3524474/47390756-f2cd1880-d6cc-11e8-8da0-c3272333915e.png)\r\n'
373104868,1344,b'Wrong Length checks for SseIntrinsics and couple of bugs on the naive Side',b'Some of the matrix multiplication bugs were introduced in native and sse-intrinsics implemenatation.\r\nThey need to be in sync with AvxIntrinsics.cs\r\n'
373074769,1342,b'Change unit tests to use SelectColumnsTransform instead of ChooseColumnsTransform',"b'After serialization, ChooseColumnsTransform is deserialized as a SelectColumnsTransform, causing unit tests to fail.\r\n\r\nWe should also consider changing transforms that use DropColumnsTransform (such as WordHashBag, evaluators etc.) to start using SelectColumnsTransform instead.'"
372740613,1339,b'LightGBM load model generated by python',"b'I have a LightGBM binary classifier trained by Python package, I want to use ML.NET to serve the model and run prediction. So is there a sample that I can follow?'"
372703860,1337,"b""PcaTransform doesn't use seed information""","b'PcaTransform arguments define seed per input column, but that information is never used throughout the PCA algorithm. The seed argument either has to be removed or the PCA algorithm should be updated to use it. '"
372405937,1335,"b'Unhelpful warning ""Term map for output column \'#Temp_3\' contains no entries'","b'For some data sets I\'ve been getting:\r\n\r\n> ""Warning: Term map for output column \'#Temp_3\' contains no entries.""\r\n\r\nWhich is not very helpful. Is there a chance derived/processes columns get a more meaningful name than ""Temp_""?'"
372297211,1331,b'Sepearting Platforms will ease development',"b'Thanks for the great work.\r\nI suggest you make an interface, e.g. IVectorManupulation.\r\nThen make three classes for each platform:\r\nVectorManupulationIntel\r\nVectorManupulationAMD\r\nVectorManupulationSoftware\r\n\r\nThen on first initializing the library, you make a check on the current hardware, and based on that you return the correct implementation:\r\nVectorManupulationFactory.getVectorManup()\r\n\r\nthis will help u in separating the code for each platform, plus it will make the checking of the platform in one place or lesser places.\r\n\r\nthe factory pattern:\r\nhttp://www.blackwasp.co.uk/FactoryMethod.aspx\r\nhttps://sourcemaking.com/design_patterns/factory_method\r\n\r\nin C#:\r\nhttps://www.dofactory.com/net/abstract-factory-design-pattern\r\nhttps://www.dofactory.com/net/factory-method-design-pattern'"
372210802,1329,b'ML Tutorial does not compile on Mac ',"b'### System information\r\n\r\n- **OS version/distro**:\r\nmacOS High Sierra (10.13.6)\r\ntests-iMac:myApp bnl$ uname -a\r\nDarwin tests-iMac.lan 17.7.0 Darwin Kernel Version 17.7.0: Thu Jun 21 22:53:14 PDT 2018; root:xnu-4570.71.2~1/RELEASE_X86_64 x86_64\r\ntests-iMac:myApp bnl$ \r\n\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\ntests-iMac:myApp bnl$ dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.302\r\n Commit:    9048955601\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.13\r\n OS Platform: Darwin\r\n RID:         osx.10.13-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/2.1.302/\r\n\r\nHost (useful for support):\r\n  Version: 2.1.2\r\n  Commit:  811c3ce6c0\r\n\r\n.NET Core SDKs installed:\r\n  2.1.302 [/usr/local/share/dotnet/sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.2 [/usr/local/share/dotnet/shared/Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.2 [/usr/local/share/dotnet/shared/Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.2 [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\r\n\r\nTo install additional .NET Core runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFollowing https://www.microsoft.com/net/learn/machinelearning-ai/ml-dotnet-get-started-tutorial\r\n\r\n- **What happened?**\r\nCode does not compile\r\nMissing assembly references to\r\nLearningPipeLine\r\nTextLoader\r\nDictionarizer\r\nand a couple of others detailed below\r\n\r\n- **What did you expect?**\r\nThe tutorial to be fusional  - thus having compilable examples\r\n\r\nI found a similar issue #309, says it is fixed - but no.\r\n\r\n\r\n### Source code / logs\r\ntests-iMac:ml bnl$ dotnet new console -o myApp\r\nGetting ready...\r\nThe template ""Console Application"" was created successfully.\r\n\r\nProcessing post-creation actions...\r\nRunning \'dotnet restore\' on myApp/myApp.csproj...\r\n  Restoring packages for /Users/bnl/Projects/ml/myApp/myApp.csproj...\r\n  Generating MSBuild file /Users/bnl/Projects/ml/myApp/obj/myApp.csproj.nuget.g.props.\r\n  Generating MSBuild file /Users/bnl/Projects/ml/myApp/obj/myApp.csproj.nuget.g.targets.\r\n  Restore completed in 1,14 sec for /Users/bnl/Projects/ml/myApp/myApp.csproj.\r\n\r\nRestore succeeded.\r\n\r\ntests-iMac:ml bnl$ cd myApp/\r\ntests-iMac:myApp bnl$ dotnet add package Microsoft.ML\r\n  Writing /var/folders/rw/3tm8flcx2z14g2dzd8y5vpl80000gp/T/tmpQsMyRD.tmp\r\ninfo : Adding PackageReference for package \'Microsoft.ML\' into project \'/Users/bnl/Projects/ml/myApp/myApp.csproj\'.\r\nlog  : Restoring packages for /Users/bnl/Projects/ml/myApp/myApp.csproj...\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/microsoft.ml/index.json\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/microsoft.ml/index.json 718ms\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/microsoft.ml/0.6.0/microsoft.ml.0.6.0.nupkg\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/microsoft.ml/0.6.0/microsoft.ml.0.6.0.nupkg 524ms\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/microsoft.ml.cpumath/index.json\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/newtonsoft.json/index.json\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/system.codedom/index.json\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/microsoft.ml.cpumath/index.json 515ms\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/system.threading.tasks.dataflow/index.json\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/microsoft.ml.cpumath/0.6.0/microsoft.ml.cpumath.0.6.0.nupkg\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/newtonsoft.json/index.json 684ms\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/system.codedom/index.json 689ms\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/system.codedom/4.4.0/system.codedom.4.4.0.nupkg\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/newtonsoft.json/10.0.3/newtonsoft.json.10.0.3.nupkg\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/system.threading.tasks.dataflow/index.json 554ms\r\ninfo :   GET https://api.nuget.org/v3-flatcontainer/system.threading.tasks.dataflow/4.8.0/system.threading.tasks.dataflow.4.8.0.nupkg\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/microsoft.ml.cpumath/0.6.0/microsoft.ml.cpumath.0.6.0.nupkg 586ms\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/newtonsoft.json/10.0.3/newtonsoft.json.10.0.3.nupkg 492ms\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/system.codedom/4.4.0/system.codedom.4.4.0.nupkg 532ms\r\ninfo :   OK https://api.nuget.org/v3-flatcontainer/system.threading.tasks.dataflow/4.8.0/system.threading.tasks.dataflow.4.8.0.nupkg 524ms\r\nlog  : Installing Newtonsoft.Json 10.0.3.\r\nlog  : Installing System.Threading.Tasks.Dataflow 4.8.0.\r\nlog  : Installing System.CodeDom 4.4.0.\r\nlog  : Installing Microsoft.ML.CpuMath 0.6.0.\r\nlog  : Installing Microsoft.ML 0.6.0.\r\ninfo : Package \'Microsoft.ML\' is compatible with all the specified frameworks in project \'/Users/bnl/Projects/ml/myApp/myApp.csproj\'.\r\ninfo : PackageReference for package \'Microsoft.ML\' version \'0.6.0\' added to file \'/Users/bnl/Projects/ml/myApp/myApp.csproj\'.\r\ntests-iMac:myApp bnl$ nano iris-data.txt\r\ntests-iMac:myApp bnl$ nano \r\nProgram.cs     iris-data.txt  myApp.csproj   obj/           \r\ntests-iMac:myApp bnl$ nano Program.cs \r\ntests-iMac:myApp bnl$ dotnet run\r\nCSC : warning CS8032: An instance of analyzer Microsoft.ML.Analyzer.TypeIsSchemaShapeAnalyzer cannot be created from /Users/bnl/.nuget/packages/microsoft.ml/0.6.0/analyzers/dotnet/cs/Microsoft.ML.Analyzer.dll : Could not load file or assembly \'Microsoft.CodeAnalysis, Version=2.9.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35\'. The system cannot find the file specified.. [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(47,32): error CS0246: The type or namespace name \'LearningPipeline\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(52,30): error CS0246: The type or namespace name \'TextLoader\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(57,30): error CS0246: The type or namespace name \'Dictionarizer\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(60,30): error CS0246: The type or namespace name \'ColumnConcatenator\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(65,30): error CS0246: The type or namespace name \'StochasticDualCoordinateAscentClassifier\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(68,30): error CS0246: The type or namespace name \'PredictedLabelColumnOriginalValueConverter\' could not be found (are you missing a using directive or an assembly reference?) [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(34,27): warning CS0649: Field \'Program.IrisData.Label\' is never assigned to, and will always have its default value null [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\nProgram.cs(41,27): warning CS0649: Field \'Program.IrisPrediction.PredictedLabels\' is never assigned to, and will always have its default value null [/Users/bnl/Projects/ml/myApp/myApp.csproj]\r\n\r\nThe build failed. Please fix the build errors and run again.\r\ntests-iMac:myApp bnl$ \r\n'"
372151097,1325,b'Fix conditional in for loop of GetDependencies()',b'Just a minor unintended one character change in the condition check of a loop in GetDependencies method of CompositeRowToRowMapper.\r\n'
372150075,1323,b'v0.6 Simple ONNX model initialization failed',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 17134.345\r\n- **.NET Version (eg., dotnet --info)**: 2.1.402\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried to load a ONNX model that generated by Python onnxmltools and want to load the onnx model file, then apply to my test data.\r\n- **What happened?** I got exceptions **System.AccessViolationException: \'Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\'**\r\n- **What did you expect?** The model could be loaded and scored.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```csharp\r\npublic class OnnxRunner\r\n    {\r\n        public class InputData\r\n        {\r\n            [VectorType(10)]\r\n            public float[] data_0;\r\n        }\r\n\r\n        public class PredictionOutput\r\n        {\r\n            [ColumnName(""label"")]\r\n            public uint Label { get; set; }\r\n            [ColumnName(""probabilities"")]\r\n            public float[] Probabilities { get; set; }\r\n        }\r\n\r\n        public void Run()\r\n        {\r\n            using (var env = new ConsoleEnvironment(null, false, 0, 1, null, null))\r\n            {\r\n                var dataPath = Path.Combine(Environment.CurrentDirectory, ""sample_test_data.csv"");\r\n                var modelPath = Path.Combine(Environment.CurrentDirectory, ""sample.onnx"");\r\n                var outputPath = Path.Combine(Environment.CurrentDirectory, ""output.txt"");\r\n\r\n                var inputData = File.ReadLines(dataPath).Skip(1).Select(row => new InputData\r\n                {\r\n                    data_0 = row.Split(new char[] {  \'\\t\' }).Select(token => float.Parse(token)).ToArray()\r\n                }).ToList();\r\n\r\n                var inputName = ""data_0"";\r\n                var outputName = ""label"";\r\n\r\n                var data = ComponentCreation.CreateDataView<InputData>(env, inputData);\r\n                var pipeline = new OnnxEstimator(env, modelPath, inputName, outputName);\r\n                var transformer = pipeline.Fit(data);\r\n                var result = transformer.Transform(data);\r\n            }\r\n        }\r\n    }\r\n```\r\n\r\nSample ONNX file and data are here:\r\n[sample.zip](https://github.com/dotnet/machinelearning/files/2497637/sample.zip)\r\n\r\nI tracked the exception that it throws from here:\r\nhttps://github.com/dotnet/machinelearning/blob/06b5ea6252e2c2766045d5f1436c55c1ccd8929d/src/Microsoft.ML.OnnxTransform/OnnxUtils.cs#L178\r\n\r\nThe ONNX file is generated by Python onnxmltools 1.2.2.129, the classifier in the model is lightgbm multi class classifier (v2.2.1)'"
372123180,1322,b'Hash a vector to a scalar',"b'There is an existing issue #1031 that mentions that hashing a vector input to a scalar as a desirable output. While we can expand the set of types supported by hashing immediately (as done in #1303), the problem of how to hash vectors to a scalar is surprisingly thorny.\r\n\r\nThe fundamental root of all difficulties lies in the idea that a sparse vector must be considered logically equivalent to a dense vector of the same length. So: the length 4 sparse vector `{1:""hello"", 3:""friend""}` should hash to the same value as the dense vector `{"""", ""hello"", """", ""friend""}`. Yet it should not hash to the same value as `{""hello"", """", """", ""friend""}`, or `{"""", ""hello"", """", ""friend"", """"}`, or some other such inputs.\r\n\r\nBeyond handling of how to handle sparse vectors and dense vectors with default values, there is also the problem of how to handle the ""not ordered"" option. The primary reason the not ordered option is valuable is because we want to use the hash transform in place of a dictionary-based term transform, to enable a bag of words representation. Yet if the ability to map both `{""a"", ""b"", ""a""}` and `{""a"", ""a"", ""b""}` to the same output vector (in the case of bag-of-words) is valuable, would mapping both to the same hash also likewise be a valuable property? If we *don\'t* believe this is valuable, what does being unordered in the case of a single hash actually mean? Nothing? Should it be disallowed, ignored?'"
372056279,1319,b'MLContext extensions for trainers',"b""Go over all the trainers and ensure that:\r\n- They are named according to #1318 \r\n- Appropriate extensions are present\r\n- The predictor classes are available in non-`Runtime` namespaces.\r\n\r\nI anticipate that there's going to be some naming or interface decisions here, let's discuss them in this issue."""
372054352,1318,b'Mass rename of transformers and MLContext extensions for them',"b""Let's go over all the existing transforms and make sure that they share the same naming conventions:\r\n\r\n - Estimators \r\n    - Should be named `ActionPerformingEstimator`, or `AlgorithmNameTrainer`\r\n    - Should be placed in `Microsoft.ML.Trainers`, `Transforms` or sub-namespaces if applicable\r\n    - If they take input or output colunms, they should be 'inputColumn' and 'outputColumn', and the outputColumn should be nullable. \r\n - Trainers\r\n    - If they take features/label columns, they should be in the same order (label, features, weights, other), and have defaults.\r\n    - Important parameters should be listed as ctor arguments.\r\n    - Other parameters should be a delegate over advanced settings\r\n      - Generally, trainers should have exactly one constructor. Overload only if necessary.\r\n\t\t\r\n - Transformers \r\n   - Should be named `ActionPerformingTransformer`\r\n   - Should be placed in `Microsoft.Ml.Transforms` or sub-namespaces\r\n   - If they are trainable, they should NOT have a public constructor.\r\n   - If they are NOT trainable, they SHOULD have a public constructor."""
372036524,1317,b'UWP Application',"b""Why Can't I use ML.NET in UWP apps? """
372034702,1316,"b'Remove IRandom, derive Tausworthe from System.Random'","b'Wherever we take an `IRandom` in ML.NET, we should take a `Random`. \r\n\r\nWe should still use `TauswortheRandom` pretty much everywhere, so we make it derive from `System.Random`.\r\n\r\n'"
371818019,1314,"b""LightGBM ranker and multiclass don't have pigsty extensions""",b''
371813950,1313,b'Tests failing in master',"b""As noted on our repo's README.md, the build is failing (in a test), which appears due to [MulticlassTreeFeaturizedLRTest](https://github.com/dotnet/machinelearning/blob/9157ceacffe0106c01580d6b7aa79ce918048434/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs#L199-L207) on OS X:\r\n> ![image](https://user-images.githubusercontent.com/4080826/47199411-54386480-d326-11e8-982d-c08d2d54cbcc.png)\r\n\r\nMulticlassTreeFeaturizedLRTest:\r\nhttps://github.com/dotnet/machinelearning/blob/9157ceacffe0106c01580d6b7aa79ce918048434/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs#L199-L207\r\n\r\nTest error: ([full logs](https://dnceng.visualstudio.com/DotNet-Public/_build/latest?definitionId=104&branch=master))\r\n```\r\n2018-10-18T23:35:15.5213890Z Failed   Microsoft.ML.Runtime.RunTests.TestPredictors.MulticlassTreeFeaturizedLRTest\r\n2018-10-18T23:35:15.5214010Z Error Message:\r\n2018-10-18T23:35:15.5214250Z  System.InvalidOperationException : MTA thread failed\r\n2018-10-18T23:35:15.5215480Z ---- Assert.InRange() Failure\r\n2018-10-18T23:35:15.5216230Z Range:  (-0.0001 - 0.0001)\r\n2018-10-18T23:35:15.5216970Z Actual: -3\r\n2018-10-18T23:35:15.5217100Z Stack Trace:\r\n2018-10-18T23:35:15.5217280Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.RunMTAThread(ThreadStart fn) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 736\r\n2018-10-18T23:35:15.5217490Z    at Microsoft.ML.Runtime.RunTests.TestPredictors.MulticlassTreeFeaturizedLRTest() in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs:line 201\r\n2018-10-18T23:35:15.5218240Z ----- Inner Stack Trace -----\r\n2018-10-18T23:35:15.5218440Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.MatchNumberWithTolerance(MatchCollection firstCollection, MatchCollection secondCollection, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 544\r\n2018-10-18T23:35:15.5219030Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.GetNumbersFromFile(String& firstString, String& secondString, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 513\r\n2018-10-18T23:35:15.5219310Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityFromPathsCore(String relPath, String basePath, String outPath, Int32 skip, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 493\r\n2018-10-18T23:35:15.5219590Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityCore(String dir, String name, String nameBase, Boolean normalize, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 369\r\n2018-10-18T23:35:15.5219830Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityNormalized(String dir, String name, String nameBase, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 339\r\n2018-10-18T23:35:15.5220090Z    at Microsoft.ML.Runtime.RunTests.TestCommandBase.OutputPath.CheckEqualityNormalized(Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/TestCommandBase.cs:line 76\r\n2018-10-18T23:35:15.5220320Z    at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.Run(RunContext ctx, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 167\r\n2018-10-18T23:35:15.5220600Z    at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.Run_TrainTest(PredictorAndArgs predictor, TestDataset dataset, String[] extraSettings, String extraTag, Boolean expectFailure, Boolean summary, Boolean saveAsIni, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 389\r\n2018-10-18T23:35:15.5220900Z    at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.RunOneAllTests(PredictorAndArgs predictor, TestDataset dataset, String[] extraSettings, String extraTag, Boolean summary, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 357\r\n2018-10-18T23:35:15.5221170Z    at Microsoft.ML.Runtime.RunTests.TestPredictors.<MulticlassTreeFeaturizedLRTest>b__15_0() in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs:line 203\r\n2018-10-18T23:35:15.5221390Z    at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.<>c__DisplayClass92_0.<RunMTAThread>b__0() in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 721\r\n2018-10-18T23:35:15.5221830Z Standard Output Messages:\r\n2018-10-18T23:35:15.5222710Z  Running 'MulticlassLogisticRegression' on 'iris-tree-featurized'\r\n2018-10-18T23:35:15.5224910Z    Running as: TrainTest tr=MulticlassLogisticRegression{l1=0.001 l2=0.1 ot=1e-3 nt=1} data=/Users/buildagent/agent/_work/1/s/test/data/iris.txt seed=1 test=/Users/buildagent/agent/_work/1/s/test/data/iris.txt loader=Text{col=Label:U4[0-2]:0 col=Features:1-*} xf=TreeFeat{lps=0 trainer=ftr{iter=3}} xf=copy{col=Features:Leaves} out={/Users/buildagent/agent/_work/1/s/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/netcoreapp2.1/TestOutput/MulticlassLogisticRegression/MulticlassLogisticRegression-TrainTest-iris-tree-featurized-model.zip} dout={/Users/buildagent/agent/_work/1/s/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/netcoreapp2.1/TestOutput/MulticlassLogisticRegression/MulticlassLogisticRegression-TrainTest-iris-tree-featurized.txt} norm=no\r\n2018-10-18T23:35:15.5226910Z  *** Failure: The test threw an exception - Xunit.Sdk.InRangeException: Assert.InRange() Failure\r\n2018-10-18T23:35:15.5227350Z  Range:  (-0.0001 - 0.0001)\r\n2018-10-18T23:35:15.5227700Z  Actual: -3\r\n2018-10-18T23:35:15.5227810Z     at Xunit.Assert.InRange[T](T actual, T low, T high, IComparer`1 comparer) in C:\\Dev\\xunit\\xunit\\src\\xunit.assert\\Asserts\\RangeAsserts.cs:line 41\r\n2018-10-18T23:35:15.5228220Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.MatchNumberWithTolerance(MatchCollection firstCollection, MatchCollection secondCollection, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 544\r\n2018-10-18T23:35:15.5228390Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.GetNumbersFromFile(String& firstString, String& secondString, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 513\r\n2018-10-18T23:35:15.5228560Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityFromPathsCore(String relPath, String basePath, String outPath, Int32 skip, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 493\r\n2018-10-18T23:35:15.5228720Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityCore(String dir, String name, String nameBase, Boolean normalize, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 369\r\n2018-10-18T23:35:15.5228970Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.CheckEqualityNormalized(String dir, String name, String nameBase, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 339\r\n2018-10-18T23:35:15.5229110Z     at Microsoft.ML.Runtime.RunTests.TestCommandBase.OutputPath.CheckEqualityNormalized(Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/TestCommandBase.cs:line 76\r\n2018-10-18T23:35:15.5229250Z     at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.Run(RunContext ctx, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 167\r\n2018-10-18T23:35:15.5229410Z     at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.Run_TrainTest(PredictorAndArgs predictor, TestDataset dataset, String[] extraSettings, String extraTag, Boolean expectFailure, Boolean summary, Boolean saveAsIni, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 389\r\n2018-10-18T23:35:15.5229590Z     at Microsoft.ML.Runtime.RunTests.BaseTestPredictors.RunOneAllTests(PredictorAndArgs predictor, TestDataset dataset, String[] extraSettings, String extraTag, Boolean summary, Int32 digitsOfPrecision) in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestPredictorsMaml.cs:line 357\r\n2018-10-18T23:35:15.5229890Z     at Microsoft.ML.Runtime.RunTests.TestPredictors.<MulticlassTreeFeaturizedLRTest>b__15_0() in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs:line 203\r\n2018-10-18T23:35:15.5230030Z     at Microsoft.ML.Runtime.RunTests.BaseTestBaseline.<>c__DisplayClass92_0.<RunMTAThread>b__0() in /Users/buildagent/agent/_work/1/s/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs:line 721\r\n2018-10-18T23:35:15.5230140Z  Test MulticlassTreeFeaturizedLRTest: aborted: failed\r\n2018-10-18T23:35:15.5230190Z \r\n2018-10-18T23:35:15.5230230Z \r\n```"""
371811471,1312,b'Hyperparameter suggestions in Visual Studio',"b'Is it possible to have Visual Studio\'s IntelliSense/HelpText for each learner\'s hyperparameters inform the user of the `max` (absolute limits) and `good` (generally useful) ranges for the hyperparameter?\r\n\r\nCurrently we show nothing: _(though we can show the added text)_\r\n> > >    ![image](https://user-images.githubusercontent.com/4080826/47199065-7c26c880-d324-11e8-80c2-13f05586d68a.png)\r\n\r\n\r\n\r\nWe do note the good ranges in the code for each component: \r\nhttps://github.com/dotnet/machinelearning/blob/b270b4d6b774a37e08321ba766aa8c15e81dfe77/src/Microsoft.ML.FastTree/FastTreeArguments.cs#L375\r\n\r\nWhy\r\n----\r\nShowing the `max` and `good` ranges/values for hyperparameters encourages the users to explore the ranges. While our defaults are good (honed on many datasets), the user will see gains on any particular dataset by exploring other values.\r\n\r\nHow\r\n----\r\nOne way to accomplish this is generating the XML param comments from the attributes automatically, eg: `/// <param name=""l2Const"">The L2 regularization hyperparameter. A useful range is 0.025f\xe2\x80\x930.4f</param>`. Another option is hand maintaining both locations and some sort of static analysis of our code that checks that the attribute and the XML param comments match, and gives a build error if they didn\'t.\r\n\r\nThanks to @eerhardt for ideas on how to accomplish.'"
371771635,1308,"b'LightGBM 2.1.2.2 can not be installed on .net 4.6 ,LightGBM 2.2.1.1 can be installed ,but it does not work in ML.Net'",b''
371746492,1307,"b""Binary fast tree doesn't return tree predictor in pigsty""",b'https://github.com/dotnet/machinelearning/blob/a285f8d5db15cd8bf77f3c03763bce16642f902b/src/Microsoft.ML.FastTree/FastTreeStatic.cs#L93\r\nIt returns IPredictorWithFeatureWeights<float> which I found weird since I expect tree predictor from fast tree.\r\nRegression and Multiclass returns FastTreeRegressionPredictor and FastTreeRankingPredictor which is right.'
371721158,1304,b'Need a non-generic version of the IModelCombiner interface',"b'In order to be able to define arguments that are factories of ""IModelCombiner"" where any kind of IModelCombiner can be specified, we need a non-generic version of this interface. '"
371672308,1302,b'Functions needed to be changed to use our new algorithm for aligned and unaligned loads',"b'Currently these functions are just using Unaligned Loads, we can make them after by aligning the data and doing aligned loads.\r\n\r\n- [ ] AddScalerU\r\n- [ ] ScaleSrcU\r\n- [ ] AddScaleU\r\n- [ ] ScaleAddU\r\n- [ ] AddU\r\n- [ ] AddScaleCopyU\r\n- [ ] AddSU\r\n- [ ]  MulElementWiseU\r\n- [ ] SumU\r\n- [ ] SumSqU\r\n- [ ] SumSqDiffU\r\n- [ ] SumAbsU\r\n- [ ] SumAbsDiffU\r\n- [ ] MaxAbsU\r\n- [ ] MaxAbsDiffU\r\n- [ ] DotU\r\n- [ ] DotSU\r\n- [ ] Dist2\r\n- [ ] SdcaL1UpdateU\r\n- [ ] SdcaL1UpdateSU\r\n\r\nReference for algorithm https://github.com/dotnet/machinelearning/pull/1143\r\n\r\ncc @danmosemsft @tannergooding @eerhardt '"
371635121,1300,b'Bug in ConcatTransform legacy loading',"b'When loading a ConcatTransform with an older version, we need to read an additional int, for sizeof(float) that used to be serialized with the transform.'"
371632719,1298,b'Null reference exception in InternalSchemaDefinition.cs',"b'There is a Create() method in line 217 of InternalSchemaDefinition.cs that calls AssertValue on its userSchemaDefinition parameter, but its value can actually be null.\r\n '"
371608223,1297,b'Add NOTICE file',"b'We are consuming a large block of code from another project in #1263. Its license requires us to keep it available in all binary and source distributions of it. The common way to do this is to have a `NOTICE` file in the root of the source repo, and in the NuGets produced. We should add the NOTICE file in that way, and update it as part of #1263 if we indeed end up copying that code into our repo.'"
371333640,1295,b'Add Official x86 CI builds',"b'Currently, there is no Official CI build for x86. We should add Debug and Release builds for x86, and make sure that all tests succeed. This should involve changing the phase-template.yml.'"
371293099,1289,b'Exception loading an older model file with no strings ',"b""When I changed our model format for the ComponentCatalog changes (#970), I refactored some model loading code incorrectly. There are some existing models that are breaking our validation checks:\r\n\r\nThe old code was doing:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/655c2e29421f5c44133ed6515374e48cf42868a2/src/Microsoft.ML.Data/Model/ModelHeader.cs#L419-L424\r\n\r\nThe new code now does:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a44e131b8010024d024197db4cc22a546c554fdf/src/Microsoft.ML.Data/Model/ModelHeader.cs#L482-L486\r\n\r\nNotice that it doesn't return early in the new code. Lower in the method there are checks here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a44e131b8010024d024197db4cc22a546c554fdf/src/Microsoft.ML.Data/Model/ModelHeader.cs#L538-L541\r\n\r\nThese checks are now failing with older model files. They were never run in the old code when there were no strings, so we shouldn't be running them anymore when reading older model files.\r\n\r\n/cc @yaeldekel """
371282969,1288,b'Improve constructor for TextLoader',"b""We currently have \r\n```csharp\r\npublic TextLoader(IHostEnvironment env, Column[] columns, Action<Arguments> advancedSettings, IMultiStreamSource dataSample = null)\r\npublic TextLoader(IHostEnvironment env, Arguments args, IMultiStreamSource dataSample = null)\r\n```\r\nWe need to:\r\n1) Make the second constructor internal or private (it's used only by cmdline/dependency injection.\r\n2) Add 'separator chars' and 'has header' as non-advanced parameters\r\n\r\nThe first change will naturally trigger a lot of changes in the code that creates the `TextLoader`, this is by design."""
371282185,1287,b'LocalEnvironment to stop being IDisposable',"b'The only reason we have `IHostEnvironment` as an `IDisposable` is because we clean up the temp files created using `CreateTempFile`. This functionality is not really very useful. We should remove the functionality, remove the `IDisposable` and fix all the `using` calls in the codebase (preferably to just `new MLContext`, if possible)'"
371280045,1286,b'`MLContext.Model.Save` should accept statically typed models too',b'Add an extension method in `Microsoft.ML.StaticPipe` for that'
371217003,1284,b'Make ConsoleEnvironment internal',"b""We don't expect external users to use the `ConsoleEnvironment` class. It should only be used for the command line tool.\r\n\r\nWe should make this class internal so it isn't part of our public API. That way we don't need to support it as a public API forever.\r\n\r\nSee https://github.com/dotnet/machinelearning/pull/1252#discussion_r225986842\r\n\r\n/cc @Zruty0 @TomFinley """
371205197,1283,b'Support Key Types in Input Data Structures of Prediction Function',"b'Key types currently are not supported in input data structure of a prediction function ([an example](https://github.com/dotnet/machinelearning/blob/23659b013eb2d0233cd92072f32a6daddfe613e3/test/Microsoft.ML.Benchmarks/PredictionEngineBench.cs#L19) of prediction function). However, for recommender systems like matrix factorization, we have user and item IDs which are input keys. Do you have any plan to support key-typed input data structures?'"
371199117,1282,b'Update build script and/or instructions to check for libomp on OS X',"b""### System information\r\n\r\n- **OS version/distro**: OS X 10.12.6\r\n\r\n### Issue\r\nLightGBM fails to run on OS X unless `libomp` is installed. \r\n\r\nA change 6 days ago added the requirement for `libomp` and we haven't updated the build instructions or build script.\r\n\r\nError:\r\n```\r\nUnexpected exception: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(liblib_lightgbm, 1): image not found, 'System.DllNotFoundException'\r\n   at Microsoft.ML.Runtime.LightGBM.WrappedLightGbmInterface.DatasetCreateFromSampledColumn(IntPtr sampleValuePerColumn, IntPtr sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String parameters, IntPtr& ret)\r\n   at Microsoft.ML.Runtime.LightGBM.Dataset..ctor(Double[][] sampleValuePerColumn, Int32[][] sampleIndicesPerColumn, Int32 numCol, Int32[] sampleNonZeroCntPerColumn, Int32 numSampleRow, Int32 numTotalRow, String param, Single[] labels, Single[] weights, Int32[] groups) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.LightGBM/WrappedLightGbmDataset.cs:line 45\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs:line 660\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs:line 343\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.TrainModelCore(TrainContext context) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.LightGBM/LightGbmTrainerBase.cs:line 103\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.Data/Training/TrainerEstimatorBase.cs:line 155\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 259\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.RunFold(Int32 fold) in /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Microsoft.ML.Data/Commands/CrossValidationCommand.cs:line 551\r\n   at System.Threading.Tasks.Task`1.InnerInvoke()\r\n   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\r\n```\r\n\r\n#### Temporary solution _(fix it once for the current user)_\r\nOn OS X, we can install libomp:\r\n```bash\r\n$ brew install libomp \r\n```\r\n\r\n#### Longer term solutions _(fix it again for all future users)_\r\n* Update our build instructions to tell the user to run `brew install libomp`\r\n* Update our build script to check for `libomp` and fail the build if missing\r\n* (maybe) Automatically install `libomp` if missing--installing global system software during a build is bad though; is there a way to do a local install? \r\n* Add runtime check for `libomp` and produce a helpful error--this issue affects **nuget users** ; perhaps a change to the upstream LightGBM (@guolinke, thoughts?)\r\n\r\nWe should check if the `libomp` requirement increases the difficultly to **distribute apps** which call into ML.NET. Do the end-users (or the apps install script) have to install `libomp`?\r\n\r\nThanks to @eerhardt for finding the `brew install libomp` solution and providing much of the above background information."""
371136561,1280,"b""Evaluation result classes shouldn't be nested under the Evaluator classes""","b'When using our evaluation API:\r\n\r\n```C#\r\nBinaryClassificationContext binClassificationCtx = new BinaryClassificationContext(env);\r\nBinaryClassifierEvaluator.CalibratedResult metrics = binClassificationCtx.Evaluate(predictions, ""Label"");\r\n```\r\n\r\nIt is quite odd for the `metrics` object to be a nested class in the `BinaryClassifierEvaluator`. I didn\'t even use the `BinaryClassifierEvaluator` class at all, why am I dealing with a nested class inside of it?\r\n\r\nI think these result classes should be moved to no longer be nested classes. Instead we should just have a `BinaryClassifierEvaluationResult` class.\r\n\r\n/cc @Zruty0 @TomFinley @KrzysztofCwalina @terrajobst '"
371076498,1279,b'Doc: PredictionEngine.Predict claims it creates a new object for each call.',"b'In:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8e77d0f0ce74cdb8b10fa545830972a4525d5dab/src/Microsoft.ML.Api/PredictionEngine.cs#L201-L205\r\n\r\n> ""<returns>The result of prediction. A new object is created for every call.</returns>""\r\n\r\nShouldn\'t this be the exact opposite? It\'s very confusing. IMO the docs & classes could need some more explanations.\r\n\r\n\r\nAlso, regarding: https://github.com/dotnet/machinelearning/blob/8cfa2ed503c1cca78972d79b393fbffe13bde173/docs/code/SchemaComprehension.md#predictionengine-and-predictormodel\r\n\r\nThis could probably use some guidlines. When to use PredictionEngine? When PredictionFunction? How to actually use BatchPredictionEngine? At first one thinks it\'s the same as PredictionEngine except that you can pass an IEnumerable. But not so. Very different API.\r\n\r\nIs there anything in the pipeline to clarify all this? Also how this all plays together with saving/loading a model would be nice.'"
370724007,1273,b'Exception messages with TLC references in ModelHeader.cs',"b""The exception messages in ModelHeader.cs have TLC references. We have to remove references to TLC and replace them with corresponding ML.NET references.\r\n\r\nIn this, I think it should be sufficient to replace 'TLC' with 'ML.NET' in the string. \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a02807c7a805b72ef12970a37279c8cec4ea667d/src/Microsoft.ML.Data/Model/ModelHeader.cs#L352-L365\r\n"""
370703001,1272,b'Upgrade to OnnxRuntime Library',b'Upgrade Sonoma to OnnxRuntime Library'
370676181,1271,b'Fit of IEstimator Needs One Extra Argument',"b""The signature of Fit is `TTransformer Fit(IDataView input);` which doesn't allow the use of validation set. It prevents learning algorithms (e.g., FFM and GBDT) from using early stopping. Is it ok to change it to `Fit (IEnumerable<IDataView> inputs)`?"""
370343842,1268,b'Micro-accuracy for Multiclass Classification tests',"b'Micro-accuracy is _generally_ better aligned with the business needs of ML predictions. If we are only choosing one metric to report for a multiclass classification task, it should be micro-accuracy. \r\n\r\nExample, for a support ticket classification task: _(maps incoming tickets to teams)_\r\n* Micro-accuracy -- how often does an incoming ticket get classified to the right team?\r\n* Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?\r\n\r\nMacro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year. Micro-accuracy in this case correlates better with the business need of, ""how much time/money can the company save by automating my ticket routing process"". \r\n\r\nBelow we are reporting only macro-accuracy:\r\nhttps://github.com/dotnet/machinelearning/blob/23659b013eb2d0233cd92072f32a6daddfe613e3/test/Microsoft.ML.Benchmarks/StochasticDualCoordinateAscentClassifierBench.cs#L42-L43\r\n\r\nBenchmark output: ([src](https://github.com/dotnet/machinelearning/pull/1229#issuecomment-429892852))\r\n```\r\n              Method |         Mean |      Error |     StdDev |        Extra Metric |\r\n-------------------- |-------------:|-----------:|-----------:|--------------------:|\r\n         PredictIris |     1.650 ms |  0.0151 ms |  0.0141 ms | AccuracyMacro: 0.98 |\r\n PredictIrisBatchOf1 |     1.599 ms |  0.0362 ms |  0.0339 ms | AccuracyMacro: 0.98 |\r\n PredictIrisBatchOf2 |     1.646 ms |  0.0179 ms |  0.0167 ms | AccuracyMacro: 0.98 |\r\n PredictIrisBatchOf5 |     1.635 ms |  0.0192 ms |  0.0179 ms | AccuracyMacro: 0.98 |\r\n```\r\n\r\nFor this Iris dataset benchmark, the difference between macro/micro-accuracy are non-important, though it sets a bad precedent which will be replicated in further benchmarks.\r\n\r\nWork: \r\n* The [above test](https://github.com/dotnet/machinelearning/blob/23659b013eb2d0233cd92072f32a6daddfe613e3/test/Microsoft.ML.Benchmarks/StochasticDualCoordinateAscentClassifierBench.cs#L42-L43) should be changed to report micro-accuracy\r\n* See if other benchmarks are reporting macro-accuracy\r\n* (future) Report additional metrics instead of just one'"
370316590,1267,"b""Schema mismatch for input column 'Structure': expected I4, got Key<U4, 0-1>""","b'### System information\r\n\r\n### Issue\r\nSchema mismatch for input column \'Structure\': expected I4, got Key<U4, 0-1>\r\nParameter name: inputSchema\r\n\r\n### Source code / logs\r\n static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(""Machine Learning Code Started..."");\r\n\r\n            //Create a learning pipeline\r\n            var pipeline = new LearningPipeline();\r\n\r\n\r\n            //Load the data into the pipeline\r\n            string filepath = ""fruit_data.txt"";\r\n            pipeline.Add(new TextLoader(filepath).CreateFrom<FruitData>(useHeader: false, separator: \',\'));\r\n\r\n\r\n            //Transform the data\r\n            pipeline.Add(new Dictionarizer(""Structure""));\r\n            pipeline.Add(new Dictionarizer(""Fruit""));\r\n            Console.WriteLine(""Transformation of data has been completed..."");\r\n\r\n\r\n            //Put all the data into vector\r\n            pipeline.Add(new ColumnConcatenator(""Features"", ""Weight"", ""Structure""));\r\n\r\n            //add the classifier \r\n            pipeline.Add(new FastTreeBinaryClassifier());\r\n\r\n            //Convert the label back to text\r\n\r\n\r\n            //Train the model\r\n            var model = pipeline.Train<FruitData, PredictedFruit>();\r\n\r\n            Console.WriteLine(""Training of the model has been completed"");\r\n\r\n        }\r\n\r\nHere is the data i have:-\r\n\r\n140,pulpi, orange\r\n120,pulpi, orange\r\n130,hard, apple\r\n156,hard, apple\r\n131,pulpi, orange\r\n142,hard, apple\r\n95,hard, apple'"
370291047,1265,b'Add xml summary comments and argument validation to CpuMathUtils',"b""Our `CpuMathUtils` class is public with public methods, but we don't have any xml summary comments, and only use `asserts` for argument checking.\r\n\r\nSince these are public members, we should have xml doc comments and real argument checking.\r\n\r\nSee example:\r\nhttps://github.com/dotnet/machinelearning/blob/7e9e4687284786ae241b2e8c8457a02686e639e9/src/Microsoft.ML.CpuMath/CpuMathUtils.netcoreapp.cs#L198-L207\r\n\r\nAlso, see PR comment here: https://github.com/dotnet/machinelearning/pull/1229#discussion_r224550873"""
370258070,1262,b'Nice to have matrix factorization',"b""It'd be nice to have a matrix factorization, like [LibMF](https://www.csie.ntu.edu.tw/~cjlin/libmf/), for large-scale recommender systems."""
370248232,1260,b'Fix the formatting of the XML documentation for the OnnxConverter',"b'All the information for the [ONNX Converter](https://github.com/dotnet/machinelearning/blob/160b0dfa8de334c8c6db3e0bf58653def0cea171/src/Microsoft.ML.Legacy/Models/OnnxConverter.cs) is placed inside the summary tag, which causes formatting issues like in [here](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.legacy.models.onnxconverter.convert?view=ml-dotnet#Microsoft_ML_Legacy_Models_OnnxConverter_Convert_Microsoft_ML_Legacy_PredictionModel_). \r\n\r\n\r\nRestructure the XML to have most of the content inside the <remarks> tag. Structure lists and paragraphs using [the dotnet XML tags](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/xmldoc/recommended-tags-for-documentation-comments)'"
370237352,1259,"b'OVA does not work if features column is not ""Features""'","b'### System information\r\n\r\n- **Windows**: 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: 2.1.402\r\n\r\n### Issue\r\n\r\nOVA still looks for columns ""Features"" and cannot find it in the Following test. \r\n\r\n### Source code / logs\r\n\r\n        [Fact]\r\n        public void New_MetacomponentsFeaturesRenamed()\r\n        {\r\n            using (var env = new LocalEnvironment())\r\n            {\r\n                var data = new TextLoader(env, MakeIrisTextLoaderArgs())\r\n                    .Read(new MultiFileSource(GetDataPath(TestDatasets.irisData.trainFilename)));\r\n\r\n                var sdcaTrainer = new LinearClassificationTrainer(env, ""Vars"", ""Label"", advancedSettings: (s) => { s.MaxIterations = 100; s.Shuffle = true; s.NumThreads = 1; });\r\n                var pipeline = new ConcatEstimator(env, ""Vars"", ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth"")\r\n                    .Append(new TermEstimator(env, ""Label""), TransformerScope.TrainTest)\r\n                    .Append(new Ova(env, sdcaTrainer))\r\n                    .Append(new KeyToValueEstimator(env, ""PredictedLabel""));\r\n\r\n                var model = pipeline.Fit(data);\r\n            }\r\n        }\r\n\r\n'"
370008862,1257,b'Documentation samples for binary classifiers',"b'Similar to the sample code for [SDCA regression](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L19), we need samples for the binary classifiers:\r\n[SDCA](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs#L97)\r\n[AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/Online/OnlineLearnerStatic.cs#L40)\r\n[FastTree](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeStatic.cs#L87)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmStatic.cs#L87)\r\n\r\nThere are two things to do, to resolve this issue:\r\n1. Add a sample for each of the trainers in [Microsoft.ML.Samples/Trainers.cs](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L1)\r\nThe samples can look similar to the [cookbook example](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/Scenarios/Api/CookbookSamples/CookbookSamples.cs#L369)\r\nDownload the [adult dataset](https://raw.githubusercontent.com/dotnet/machinelearning/master/test/data/adult.train) for the data to use. \r\nTake a look at the  [SDCA example](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L19), for reference.\r\n\r\n2. Add a link to the xml documentation of [SDCA](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs#L97)\r\n[AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/Online/OnlineLearnerStatic.cs#L40)\r\n[FastTree](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeStatic.cs#L87)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmStatic.cs#L87)\r\n to reference the new sample methods, like the one in [SDCA](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs#L38) has. \r\n'"
370004029,1256,b'Documentation snippets for regressor trainers',"b'Similar to the sample code for [SDCA regression](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L19), we need samples for the other regressors:\r\n[FastTreeRegression](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeStatic.cs#L39)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmStatic.cs#L38)\r\n\r\nSo there are two things to do, to resolve this issue:\r\n1. Add a sample for LightGBM and FastTree in [Microsoft.ML.Samples/Trainers.cs](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L1)\r\nThe samples can look exactly as the [SDCA one](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L19), but substituting [the trainer](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Trainers.cs#L48) with FastTree or LightGBM. \r\n2. Add a documentaiton link to \r\n\r\n2. Add a link to the xml documentaiton of [FastTreeRegression](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTreeStatic.cs#L39)\r\n[LightGBM](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.LightGBM/LightGbmStatic.cs#L38) to reference the new sample methods, like the one [SDCA](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs#L38) has. \r\n\r\n'"
369929710,1255,"b'Q: Feature Importance, new API'","b'Hi there,\r\n\r\nI have been looking forward to getting my hands on the new API and taking a look at using it to discover feature scores/importance used. Several requests were raised with this in mind and there is an implementation now. But I am struggling to find an example or test by way of illustration. Can someone please forward a link or any snippets. Thanks!\r\n\r\nBest regards\r\nFig\r\n'"
369751433,1251,b'Make Binary classification evaluator configurable',"b'The following method:\r\n```csharp\r\n        public BinaryClassifierEvaluator.CalibratedResult Evaluate(IDataView data, string label = DefaultColumnNames.Label, string score = DefaultColumnNames.Score,\r\n            string probability = DefaultColumnNames.Probability, string predictedLabel = DefaultColumnNames.PredictedLabel)\r\n```\r\nneeds to expose additional parameters from `BinaryClassifierEvaluator.Arguments`, or a delegate to set them.'"
369748577,1250,b'Improve testing on ONNX exporting',"b'Currently, tests for saving models as ONNX just check to make sure the ONNX models themselves are as expected by comparing them to a pre-saved version of that ONNX model. These tests do not actually check that these models are runnable or that they produce the same results as the original transform. With the new ONNXTransform, this testing framework could be improved to ensure correct exportability.\r\n'"
369742927,1248,b'Export WordEmbeddingsTransform to ONNX',"b'WordEmbeddingsTransform applies a series of simple matrix/tensor operations based on a pretrained model, as is therefore exportable to ONNX using a combination of existing ONNX ops.'"
369739043,1247,b'Remove unnecessary JIT SBCG workaround',"b""```c#\r\n        public static uint GetLo(ulong uu)\r\n        {\r\n            // REVIEW: Work around Dev10 Bug 884217: JIT64  -Silent bad codegen for accessing 4-byte parts of 8-byte locals\r\n            // http://vstfdevdiv:8080/WorkItemTracking/WorkItem.aspx?artifactMoniker=884217\r\n            // return (uint)uu;\r\n            return (uint)(uu & 0xFFFFFFFF);\r\n        }\r\n```\r\n\r\nI dug up this bug, it was fixed in a dev branch in 4/2010 and it looks like it reached 4.0 - certainly would be fixed in 4.5.0 which shipped in 8/2012. Although we don't explicitly state what .NET Framework versions we support, is probably reasonable for us to expect 4.5 or later and safe for us to remove this workaround."""
369735798,1246,"b""FastTreeRanking doesn't have non-advanced args""","b'Consider the following constructors:\r\n```csharp\r\n        public FastTreeBinaryClassificationTrainer(IHostEnvironment env,\r\n            string labelColumn,\r\n            string featureColumn,\r\n            string weightColumn = null,\r\n            int numLeaves = Defaults.NumLeaves,\r\n            int numTrees = Defaults.NumTrees,\r\n            int minDocumentsInLeafs = Defaults.MinDocumentsInLeafs,\r\n            double learningRate = Defaults.LearningRates,\r\n            Action<Arguments> advancedSettings = null)\r\n\r\n        public FastTreeRegressionTrainer(IHostEnvironment env,\r\n            string labelColumn,\r\n            string featureColumn,\r\n            string weightColumn = null,\r\n            int numLeaves = Defaults.NumLeaves,\r\n            int numTrees = Defaults.NumTrees,\r\n            int minDocumentsInLeafs = Defaults.MinDocumentsInLeafs,\r\n            double learningRate = Defaults.LearningRates,\r\n            Action<Arguments> advancedSettings = null)\r\n\r\n        public FastTreeRankingTrainer(IHostEnvironment env, string labelColumn, string featureColumn, string groupIdColumn,\r\n            string weightColumn = null, Action<Arguments> advancedSettings = null)\r\n```\r\n\r\nThere is no reason to have disparity here: ranker should expose the same `numLeaves`, `numTrees` etc.\r\n\r\nThe only difference should be the presence of required `groupId` in the ranker constructor.'"
369720097,1245,b'Dead Add Flag in Matrix Multiplication',"b'we are not using the ```Add``` Flag in Matrix multiplication.\r\n\r\nShould we go ahead and remove it ?\r\n\r\n```public static void MatTimesSrc(bool tran, bool add, AlignedArray mat, AlignedArray src, AlignedArray dst, int crun)```\r\n\r\ncc @danmosemsft @eerhardt @tannergooding @TomFinley '"
369702794,1244,b'Add property to Environment class which would indicate can we use disk operations or not',"b'In some environments we can be limited by access to disk, so we need to perform all operations in memory. We already has code which specify should we use file system or not for loading/unloading model\r\nhttps://github.com/dotnet/machinelearning/blob/f8f3873958a0a8114df49bb6d8dc292dc071820b/src/Microsoft.ML.Data/Model/Repository.cs#L438\r\n\r\nor HybridMemoryStream should respect that parameter as well.\r\n\r\nAny temporary file creations need to respect this property and create memory streams instead.'"
369684645,1242,"b""Debugger visualizer for DataView's""","b'1. Implement a custom data view debug visualizer.\r\n - It should have a column view and a row view\r\n - Column view will present values as `IEnumerable<object>`\r\n - Row view will present values as `Dictionary<string, object>\r\n\r\n2. Implement custom `ToString` for schema columns and for metadata.\r\n- For `Schema.Column` it should be something like `{ColumnName: ColumnType}`\r\n- For `Schema.Metadata` we would probably want to visualize that as `Dictionary<string, object>`\r\n\r\n3. Custom visualizers for `VBuffer`\r\n- Similar to the code in TLC GUI\r\n\r\n4. Custom visualizer for key values in a column view\r\n- For example, display as `KeyValue (Key)`\r\n'"
369672201,1241,b'Remove IndentingTextWriter in favor of the existing IndentedTextWriter ',"b""Remove ML.NET's IndentingTextWriter in favor of System.CodeDom.Compiler.IndentedTextWriter (a mainstream type in S.Runtime.Extensions.dll just in an oddly chosen namespace)\r\n\r\nThe main thing IndentedTextWriter doesn't have is the little IDisposable Scope helper that ML.NET uses in a decent number of places, that lets you write code like `using (writer.Nest()) { /* indented */ }` rather than explicitly indenting and outdenting before and after.\xc2\xa0 For now it could be left as an 8-line helper in ML.NET, but based on IndentedTextWriter instead of their IndentingTextWriter, and optionally open an API proposal in the CoreFX repo to add such a small feature.\r\n\r\nPer discussions w/ @stephentoub @Zruty0 \r\n\r\n"""
369613840,1239,b'An ONNX variable name not correct',"b'To declare intermediate ONNX variables in ONNX graph, we should do\r\n`var nameZ = ctx.AddIntermediateVariable(null, ""Z"", true); `\r\ninstead of\r\n`var nameZ = ""Z"";`\r\n\r\n\r\n'"
369608471,1237,"b""Sweep command doesn't work""","b'The method ""GetFullExePath"" on line 91 in ConfigRunner.cs sets the default executable to be ""maml.exe"", which doesn\'t exist.'"
369549063,1235,b'Training regression model from DataView',"b""How do I train a regression models if I bring in the data via a DataView from a custom end point via the IEnumerable<>?  I tried following the cookbook example but I couldn't find the right trainer to do this."""
369319822,1233,b'Dead Matrix Multiplication Code',"b'We are not currently using  Some of the matrix multiplication code anywhere\r\nparticularly \r\n```C#\r\npublic static void MatTimesSrc(bool tran, bool add, AlignedArray mat, int[] rgposSrc, AlignedArray srcValues, int posMin, int iposMin, int iposLim, AlignedArray dst, int crun)\r\n```\r\nwhich is the sparse matrix multiplication. Is it okay to remove it ?\r\n Another thing we are not using the ```add = true``` flag in any of the existing implementations.\r\n\r\nCan I go ahead and remove that too ?\r\n\r\ncc @eerhardt @danmosemsft @shauheen @codemzs \r\n'"
369313040,1232,b'Pretrained DNN Image Featurization',"b'Support for a DNN Image Featurizer Transform is to be added to ML.NET. This will allow users to use 1 of 4 pretrained DNN models (ResNet18, ResNet50, ResNet101, and AlexNet) trained on ImageNet in order to featurize an input image. \r\n\r\nThis transform will use the ONNX Transform as the backbone of doing input preprocessing and applying the pretrained DNN model.\r\n'"
369299546,1231,b'Factorization Machine Better to Support Regression',"b""ML.NET's (field-aware) factorization machine doesn't support regression problems while SageMaker [does](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html). Rating prediction is an important application about this."""
369229133,1228,b'ONNX Transform Crashing or Freezing',"b'ONNX Transform occasionally crashes or freezes when running certain onnx models (currently found with the Split operator). \r\n\r\n- The error is non deterministic and varies based on different machines\r\n- On some machines, the ML.NET process will freeze, while on others it will simply silently crash without producing any output\r\n- The larger the input, the more likely the issue seems to occur - almost never happens with <100 inputs, sometimes happens with 100-300 inputs, and almost always happens with >300 inputs\r\n- When ML.NET is built in debug mode, the error will never occur. It only happens if it is built in release mode\r\n- The issue is not tied to any specific input. Smaller inputs will never produce an error, while larger ones almost always will (in release mode)'"
369013823,1226,b'SelectFeaturesBasedOnCount is extremely slow',"b'I\'m using the new static pipeline and adding a `SelectFeaturesBasedOnCount(2)` slows down the pipeline by orders of magnitude.\r\n\r\nJust using ~8000 samples and doing some simple One hot encoding will prepare my data ready for learning in about 200ms. If I just add `SelectFeaturesBasedOnCount(2)` on a single one hot encoded feature it will run in 4 seconds. Adding another one to a second feature will run it in 12 seconds. I\'d like to add it to about 7 features but this will run for hours and never finish.\r\n\r\nAlso, just pressing ""Brake all"" while it runs it will often stop in the `RepositoryWriter`/`Reader` and thousands of temporary folders/files are create in my temp directory. In case that helps.'"
369000530,1225,"b""Pigsty for VarVector doesn't have hash one hot""","b'I\'m trying to convert my `LearningPipeline` to 0.6 static pipeline. I have some *variable* length features in my input instances.\r\n\r\nWith the pipeline I did:\r\n\r\n```C#\r\nnew CategoricalHashOneHotVectorizer(nameof(TransportOrderInstance.PosAmount)) { OutputKind = CategoricalTransformOutputKind.Bag, Ordered = false, HashBits = 5},\r\n```\r\n\r\nWhat is the equivalent in the new static pipeline? The `VarVector` doesn\'t have a whole lot of extension functions. Shouldn\'t it also have `OneHotEncoding`? Though, it\'s not ""One"" necessarily.\r\n'"
368957195,1223,b'Error MSB4019 when adding package Microsoft.ML',"b'### System information\r\n\r\n- **Windows 10**:\r\n- **MS Visual Studio Community 2017 Preview**: \r\n\r\n### error MSB4019: The imported project ""C:\\Users\\Owner\\source\\repos\\machinelearning\\tools\\clean.target"" was not found.\r\n\r\n- **Clone package from github: https://github.com/dotnet/machinelearning.git using Visual Studio Preview\r\n- **From CLI executed: dotnet add package Microsoft.ML**\r\n- **Got the error message referenced above**\r\n- **This is one of my first projects I am trying to download from github, and I am not sure where to find information to be able to download this project correctly.  I appreciate any assistance I could get.  Thank you**\r\n'"
368894895,1222,b'Debugger views of estimators',"b""We are already committed to improving how our data looks like in the debugger.\r\n\r\nFor instance, #1167 will turn the schema into an 'eagerly computed' object, so you can look at it in the debugger:\r\n![schema](https://user-images.githubusercontent.com/41337831/46771152-2c525c80-cca7-11e8-949e-b728eda5b5b3.PNG)\r\n\r\nNow a different question is: how do we make `Estimators` somehow 'debugger-inspectable'?\r\n\r\nWe cannot really inspect 'the algorithm'. But we can inspect 'how the algorithm will transform data'. In the world of `LearningPipeline`, every pipeline was 'duct-taped' to a specific data file. That was a mistake, of course, but it did allow for nice debugger views of pipeline steps.\r\n\r\nWith the new API, the pipeline is no longer bound to any data. It can be 'fitted' on any data of 'reasonable' shape. But now the debugger view is useless.\r\n\r\nOne possible suggestion is to add an extension method to our estimators, called something along the lines of `Preview`. It would have a signature `IDataView Preview(IDataView data)` in case of a transformer or an estimator, or `IDataView Preview(T source)` in case of an `IDataReader<T>`.\r\n\r\nThis method would return some form 'lazy approximation of `Fit`':\r\n```csharp\r\nIDataView Preview(IDataView data) => Fit(data.Take(100)).Transform(data.Take(100))\r\n```\r\n\r\nThen, at least, we can have the watch window experience more or less palatable: you just add `pipeline.Preview(trainData)` and you can see an approximation of how the pipeline would transform `trainData`.\r\n\r\ncc: @GalOshri @CESARDELATORRE @TomFinley @eerhardt """
368892947,1221,b'Update CI to support building and testing x86',b'The support for building against x86 was added on https://github.com/dotnet/machinelearning/pull/1008.\r\n\r\nWe still need to update CI to ensure that it is tested on a regular basis and update the `-RunTests` command to pull down the appropriate test host.'
368892543,1220,"b'Clean up `[ConditionalFact(typeof(Environment), nameof(Environment.Is64BitProcess))]`'","b'It was suggested that creating explicit attributes for the various cases (Such as Onnx, TensorFlow, LightGBM, etc) may be a better long term solution to manage these tests across the various platforms.\r\n\r\nSee https://github.com/dotnet/machinelearning/pull/1008#discussion_r221985876 for more details.'"
368890071,1219,b'Time Series predictors need to be stateful',b'We need to make components such as SSA spike and changepoint detector stateful so that when we do predictions using them the state is updated with the new observations that are seen at prediction phase.\r\n\r\nMore details on the design to come here.'
368868254,1216,"b'Investigate why two predictor tests fail with ""Unknown command: \'train\'"" on x86'","b'There are currently two `TestPredictors` tests disabled on x86 due to: `[ConditionalFact(typeof(Environment), nameof(Environment.Is64BitProcess))] // x86 fails with ""Unknown command: \'train\'; Format error at (83,3)-(83,4011): Illegal quoting""`.\r\n\r\nThis issue needs further investigation.'"
368867582,1215,b'Investigate and deal with the remaining x86 baseline differences',"b'The x86 build of ML.NET has some remaining baseline differences that need investigation and fixing.\r\n\r\nFrom initial investigation, the remaining differences have fewer than 4 matching significant digits and this may be caused by known bugs in the double parsing code (which have already been fixed or are actively being fixed in .NET Core). Other differences are due to the implementation (between x86 and x64) of some floating-point Math functions that the tests depend on.'"
368855979,1214,b'Is there a way to train my model with multiple coaches?',"b""### System information\r\nIs there a way to train my model with multiple coaches?\r\n\r\nSo, for example, i want to create a model to calculate a salary based in years of experience. To do this i used Regression, but has more than one trainers. I want to test all of this trainers and compare the results. \r\nI researched a lot, but i don't finded one way to do this with the ML.NET.\r\n\r\n- **What did you do?**\r\nFor did that  I execute one time, change the trainers and execute again... It's not very good.\r\n\r\n- **What did you expect?**\r\n\r\nCreate a way to initialize a array of ILearningPipelineItem and train my model with each one and show the results\r\n\r\n### Source code / logs\r\nI do some experiments using the version 0.3, and I think this could be something native to this api, if it does not already exist.\r\nhttps://github.com/pictos/MLParalel\r\n\r\n"""
368777115,1211,b'Export Kmeans to ONNX',"b""Kmeans is a series of matrix operations in prediction phase, so it's onnxable. Due to Kmeans' popularity, ONNX exporter might want to cover it.\r\n\r\n"""
368762937,1209,b'API reference - Samples for Transforms',"b""We need to add samples on how to use the new transformer, and estimators than reference those samples from the XML documentation so that in docs.microsoft.com users can copy/paste the sample and have a head-starts. \r\n\r\nMot of the tests that got added as part of the transformer work are a good start for creating a sample.  \r\n\r\n# MLContext Catalogs\r\n\r\n\r\nCatalog | Total APIs | Samples Owner | Samples Status /   ETA | \r\n-- | -- | -- | -- |\r\nMLContext.Transforms   (root) | 19 | Senja | Remaining:   4 overrides for the normalizer multicolumn examples | \r\nMLContext.Transforms.Categorical | 2 | ZeeshanA | Done v1 | \r\nMLContext.Transforms.Conversion | 6 | Senja | DoneV1 | \r\nMLContext.Transforms.FeatureSelection | 4 | ZeeshanA | Done v1 | \r\nMLContext.Transforms.TimeSeries | 4 | Senja | Done V1 | \r\nMLContext.Transforms.Text | 29 | ZeeshanA | Done  V1 | \r\nMLContext.Data | 10 | Senja | DoneV1 | \r\nMLContext.Model   (root) | 4 | ZeeshanS\xc2\xa0 | DoneV1 \xc2\xa0 | \r\n\r\n# P0+P1 Public API (extension methods) per Catalog \r\n\r\n| MLContext.Transforms (root) | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\nCopyColumns| 2 | Yes | 2 Can remove dependency on DatasetUtils. | Zeeshan|\r\nConcatenate| 1 | Yes, needs improvement.| 1 - Can remove dependency on DatasetUtils.| Zeeshan |\r\nDropColumns| 1 | Yes| 1 Can remove dependency on DatasetUtils.|Zeeshan |\r\nSelectColumns|2 | Yes, needs improvement. | 2 - Can remove dependency on DatasetUtils.|Zeeshan |\r\nNormalize| 1 | Done. | 1  #3244 |Ivan|\r\nCustomMapping | 1 | Yes, needs improvement. | Done-v1 #3275| Artidoro |\r\nIndicateMissingValues |  2|  |  Done-v1 #3275 | Artidoro | \r\nReplaceMissingValues  | 2 |  | Done-v1 #3275 | Artidoro | \r\nConvertToGrayscale  | 1 |  Yes, needs fixes. Example not displaying.| 1 #3165 | Abhishek | \r\nLoadImages  | 1 | Yes, needs fixes. Example not displaying. | 1 #3165 | Abhishek | \r\nExtractPixels | 2 | Yes, needs fixes. Example not displaying. | 1 #3165 | Abhishek | \r\nResizeImages | 2 | Yes. Example not displaying. | 1 #3165 | Abhishek  |\r\nConvertToImage  | 2 | Yes. | 1 #3165 | Abhishek  | \r\nIidChangePointEstimator  | 1 |  | 1- Done | Senja| \r\nIidSpikeEstimator | 1 |  |  1 - Done| Senja | \r\nSsaChangePointEstimator  | 1 |  | 1 - Done | Senja | \r\nSsaSpikeEstimator  | 1 |  | 1 - Done | Senja| \r\nApplyOnnxModel |  3| DoneV1 | #3349 | Gani | \r\nDnnFeaturizeImage | 1 | Yes, needs improvement. | 1 - Done | Senja | \r\nNormalizeGlobalContrast| 1 | Done | 0 #3232 | Ivan| \r\nNormalizeLpNorm| 1 | Done. | 0  #3232| Ivan | \r\nApproximatedKernelMap| 1 | Done | 0 #3232 | Ivan | \r\nmlContext.Transforms. CalculateFeatureContribution | 1 | Yes, needs improvement | Rogan\r\n\r\n| MLContext.Transforms.Categorical | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| OneHotEncoding | 2 |  | 2 #3179  | Abhishek |\r\n| OneHotHashEncoding | 2 |  |  2 #3179  | Abhishek |\r\n|  |  |  |  |  |\r\n\r\n\r\n| MLContext.Transforms.Conversion | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| Hash | 2 | can't find the API | Done | Senja |\r\n| ConvertType | 2 | Yes, needs improvement. |  Done  | Senja |\r\n| MapKeyToValue |  2 | Yes, needs improvement. | Done  |  Senja |\r\n| MapKeyToVector | 2 | Yes, needs improvement. | Done  |  Senja |\r\n| MapValueToKey | 2 | Yes. | Done  |  Senja |\r\n| MapKeyToBinaryVector | 2 | Yes, needs improvement. | Done  | Senja |\r\n\r\n| MLContext.Transforms.FeatureSelection | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| SelectFeaturesBasedOnMutualInformation  |  2  | need a better example to show MI computation. something like [this  ](https://www.researchgate.net/post/How_can_i_calculate_Mutual_Information_theory_from_a_simple_dataset)|  2 #3184   | Abhishek |\r\n| SelectFeaturesBasedOnCount |  2  |  | 2 #3184  | Abhishek |\r\n|  |  |  |  |  |\r\n\r\n| MLContext.Transforms.Text| Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| FeaturizeText |  2  |  | #3120 | Zeeshan |\r\n| TokenizeCharacters |  1  |  | #3123 |Zeeshan |\r\n| NormalizeText |  1  |  |  #3133| Zeeshan |\r\n| ExtractWordEmbeddings |  1  |  | #3142 | Zeeshan |\r\n| TokenizeWords |  1  |  | #3156 | Zeeshan |\r\n| ProduceNgrams |  3  |  | #3177 | Zeeshan |\r\n| RemoveDefaultStopWords |  2  |  | #3156 |  Zeeshan|\r\n| RemoveStopWords |  2  |  | #3156 |Zeeshan  |\r\n| ProduceWordBags |  3  |  | #3183 | Zeeshan |\r\n| ProduceHashedWordBags |  3  |  | #3183 |  Zeeshan|\r\n| ProduceHashedNgrams |  3  |  | #3177 | Zeeshan |\r\n| LatentDirichletAllocation |  2  |  |#3191  | Zeeshan |\r\n\r\nFor the Data catalog, all API's documentations needs to be augmented with suggestions for when would one use this API.\r\n\r\n| MLContext.Data | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| LoadFromEnumerable | 1 | Done.| 1 - Done. | Senja  |\r\n| CreateEnumerable | 2 | Done. The second overload of this API is a P4 scenario. the use case for that API would be: users has a model which has slot names preserved for the features, and when they load the models, they also get the schema out of the loaded model and pass that schema, together with the TRow type they want to load the data to this API. This API will then populate the Annotations (former metadata) for the feature column. | 1 | Senja  |\r\n| BootstrapSample | 1 | Done. | 1 - Done.  | Senja  |\r\n| Cache | 1 | Done. | 1 - Done. | Senja  |\r\n| FilterRowsByColumn | 1 | Done.| 1 - Done. | Senja  |\r\n| FilterRowsByKeyColumnFraction | 1 | Done. | 1 - Done. | Senja  | \r\n| FilterRowsByMissingValues | 1 | Done. | 1 - Done. | Senja  | \r\n| ShuffleRows | 1 | Done. | 1 - Done. | Senja  | \r\n| SkipRows | 1 | Done. | 1 - Done. | Senja  | \r\n| TakeRows | 1 | Done. | 1 - Done.| Senja | \r\n\r\n| Other | Num Overloads | Documentation | Sample | API Owner |\r\n| --------------------------------  | ------------- | ------------  | -----  | ----- |\r\n| Permutation Feature Importance | 4 |  Yes, but needs work | Yes, but needs work | Rogan |\r\n"""
368445821,1207,b'FastTreeBinaryClassificationCategoricalSplitTest taking very long to execute...',b'The following test is taking 15-25mins (depending on system) alone to execute.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/8ca1c9386587aa4ef77c56f605f8244debefce93/test/Microsoft.ML.Predictor.Tests/TestPredictors.cs#L711\r\n\r\nIs there any policy for test execution time in ML.Net build system?'
368403656,1205,"b""Logistic Regression doesn't work with training stats""","b""Stats that are being computed at training time aren't passed to the predictor."""
368390657,1204,b'Classification stratificationColumn not supported for boolean column',"b'For not balanced datasets, with stratified splitting, the data is divided in such a way that a percentage of each target column value is put in both training and test dataset.\r\n\r\nHowever, the following line of code throws an error if the column \'Label\' is Boolean, which is very common for binary classification.\r\n\r\n`(trainData, testData) = classification.TrainTestSplit(data, testFraction: 0.2, stratificationColumn: ""Label"");`\r\n\r\nIt would work if the Label column would be float or other types.\r\n\r\nI might be missing something, but why is Boolean not supported for the `stratificationColumn`?\r\nCan we support it since it can be a common scenario for binary classifications?'"
368367808,1203,b'ML.NET command line tool',"b""I think we should consider making ML.NET command-line tool an actual first-class citizen.\r\n\r\nA bit of insider knowledge: we currently already have a commandline tool, that is a port of `maml.exe`. You can launch it as follows (this shows the 'help' command, or the `?` command).\r\n```\r\ndotnet .\\bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.1\\MML.dll ?\r\n```\r\n\r\nGenerally, the syntax is `dotnet MML.dll <command> <arguments>`, and the current list of commands include things like `train`, `CV`, `showdata` etc. (full list is available via `dotnet MML.dll ? kind=command`).\r\n\r\nThis command-line tool is actually very powerful (although the language is clunky). \r\n\r\nWe could easily expand the command-line tool to handle common programming sub-tasks, like:\r\n- Generate prediction code from model (actually, we already have `codegen`, but it needs some retouch to work with the new API);\r\n- Inspect the contents of the model (which transformers are there and how they are set up);\r\n- Introspect into the TensorFlow or other external model format (`Microsoft.ML.Tensorflow` could have a commandline interface to list the nodes of the graph;\r\n- etc.\r\n"""
368363826,1202,b'ML.NET to use appsettings.json for seed and concurrency level',"b""When `LocalEnvironment` is created using default constructor, it should look into `appsettings.json` for random seed and concurrency level.\r\n\r\n(Original issue description below)\r\n\r\nIn case an ML.NET model is already trained and persisted, we can still control to some degree the behavior of the model at prediction time. For example, we could:\r\n- limit the model to only one thread or let it run multi-threaded\r\n- use GPU or CPU for math\r\n- specify a location for temporary / transient resources.\r\n\r\netc. \r\nWe could consider having a ML.NET dedicated session in `app.config` for the application to control these, or we could use system environment variables, or we could have a 'ML.NET config' text file that the `MLContext` will initialize with.\r\n\r\nThis came up in the process of the API discussion, so creating the issue for future consideration."""
368362325,1201,b'Is Estimator a good enough name?',"b""As @CESARDELATORRE pointed out, the term `Estimator` means two different things in Spark and in sklearn. \r\n\r\nOur terminology is in line with Spark one: the `Estimator` is a 'factory for a `Transformer`', or 'a components that trains a `Transformer` based on the data.\r\n\r\nHowever, it would be even better if we avoided the naming clash with sklearn. So far, the other alternative names for `Estimator` have been taken from generic .NET architecture: `TransformerBuilder`, `TransformerFactory` etc.\r\n\r\nI am personally not a big fan of either of the above, but they do have the benefit of mapping the behavior to other known .NET concepts. \r\n\r\nIn any case, let's see if there are better suggestions, or if there is strong preference to the existing names."""
368345583,1199,b'Regex Number Parsing Errors for netcoreapp 3.0',b'There are two issue that we face while matching the baseline files while running tests for netcoreapp3.0\r\n\r\n- The regex treats -0 and 0 differently. We may need to modify the regex for filtering the numbers to treat -0 and 0 same.\r\n- Some numbers are in written in the baseline file in the form of exponentials eg ```5.011722E-35``` They are not  picked up by the regex. so while matching these numbers we do an exact match rather than a floating number comparison with some buffer which fails for netcoreapp3.0\r\n\r\n\r\ncc @danmosemsft @tannergooding @eerhardt @shauheen @codemzs \r\n\r\n\r\n'
368313620,1198,b'Revise type mappings in MLNET-to-ONNX conversion',"b""Currently, for ONNX, we are mapping a `U4` datatype (an unsigned 32-bit integer) to an `Int64`.\r\n\r\nShould we be instead mapping the `U4` datatype to `Uint32` in ONNX? Or is there no support for a `Uint32`, and we're storing in an `Int64`?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/96439752cbaad099093ca0e8c770576bf3a53ad4/src/Microsoft.ML.Onnx/OnnxUtils.cs#L329-L331\r\n\r\nIn the [above code](https://github.com/dotnet/machinelearning/blob/96439752cbaad099093ca0e8c770576bf3a53ad4/src/Microsoft.ML.Onnx/OnnxUtils.cs#L329-L331), you'll notice the mapping is currently:\r\n* `BL` to `Float` \r\n* `TX` to `String`\r\n* `I1` to `Int8`\r\n* `U1` to `Uint8`\r\n* `I2` to `Int16`\r\n* `U2` to `Uint16`\r\n* `I4` to `Int32`\r\n* `U4` to `Int64`   <- **This one is odd**\r\n* `I8` to `Int64`\r\n* `U8` to `Uint64`\r\n* `R4` to `Float`\r\n* `R8` to `Double`\r\n\r\nThe `BL` to `Float` & `U4` to `Int64` seem odd.\r\n\r\n@wschin noted we have been mapping `U4` to `Int64` for the last two releases of WinML: https://github.com/dotnet/machinelearning/pull/947#discussion_r223443413 """
368311945,1197,b'Fix duplicate params in entrypoints',"b'Following entrypoints have duplicate param names:\r\nData.DataViewReference \r\nModels.CrossValidator\r\nModels.CrossValidationResultsCombiner\r\nModels.PipelineSweeper\r\nModels.PipelineSweeper\r\nModels.SweepResultExtractor\r\nModels.TrainTestEvaluator\r\nTransforms.TwoHeterogeneousModelCombiner\r\nTransforms.ManyHeterogeneousModelCombiner\r\n\r\nThis is not a bug per se. This is about how to make entrypoint API easy to use by 3rd parties/clients. Since I have been implementing such a client, I can share my experience. We have viewed ""entrypoint"" as a function, sort of RPC that you can call. All the parameters for ""entrypoint"" are parameters of such a function. \r\nOn example of TensorFlowScorer (fixed by #1169 ) : even though Model is set as ""Output"" param, its actually required to set this param to a filepath so ML.NET can output zipped model there. Therefore entrypoint needs 2 model params: one to specify filepath for input model, another one to specify path for output model. I am not sure if I know any programming language where function can accept parameters with the same name.\r\nOf course its possible to view ""entrypoint"" not as a method but some sort of class, or break up params into separate Input and Output structs and populate separately, but in the end, on a highest level, what is going to surface to user is a function with params to specify input and output model paths. It would be easier to avoid intermediates and being able to have that high level function built right on top of manifest.json specs.\r\n\r\n'"
368266865,1196,b'Improve `AvxIntrinsics.DotSU` performance',b'Our profiles show that DotSU which should be faster with AVX is actually slower and takes more time. This can be confirmed running our CpuMathBenchmarks:\r\n\r\n`..\\..\\Tools\\dotnetcli\\dotnet.exe run -c Release-Intrinsics -f netcoreapp3.0 -- -f *.DotSU --join`\r\n\r\n|                   Type | Method |     Mean |     Error |    StdDev | Extra Metric |\r\n|----------------------- |------- |---------:|----------:|----------:|-------------:|\r\n|    AvxPerformanceTests |  DotSU | 2.545 ms | 0.0590 ms | 0.0580 ms |            - |\r\n| NativePerformanceTests |  DotSU | 2.463 ms | 0.0612 ms | 0.0704 ms |            - |\r\n|    SsePerformanceTests |  DotSU | 2.494 ms | 0.0480 ms | 0.0449 ms |            - |\r\n\r\n'
368263066,1195,b'Remove the `AddScaleSU` performance regression for AVX',b'Our profiles show that `AddScaleSU` which should be faster with AVX is actually slower and takes more time. This can be confirmed running our CpuMathBenchmarks:\r\n\r\n`..\\..\\Tools\\dotnetcli\\dotnet.exe run -c Release-Intrinsics -- -f *.AddScaleSU --join`\r\n\r\n|                   Type |     Method |     Mean |\r\n|----------------------- |----------- |---------:|\r\n|    AvxPerformanceTests | AddScaleSU | 4.012 ms |\r\n| NativePerformanceTests | AddScaleSU | 2.966 ms |\r\n|    SsePerformanceTests | AddScaleSU | 2.916 ms |\r\n\r\nThis issue has been spotted by @eerhardt in August https://github.com/dotnet/machinelearning/pull/691#issuecomment-414364378\r\n\r\n@helloguo suggested https://github.com/dotnet/machinelearning/pull/691#issuecomment-414375034 that `GatherVector256` intrinsic should be used'
368255541,1194,b'Benchmark results analysis for .NET Core 2.1 vs 3.0',"b'I took all of our benchmarks and run them for:\r\n\r\n1.  .NET Core 2.1 using **native** `CpuMathNative` which uses **SSE**\r\n2. .NET Core 3.0 using new **managed** Hardware Intrinsics API which uses **AVX** with Tiered compilation **enabled**\r\n3. .NET Core 3.0 using new **managed** Hardware Intrinsics API which uses **AVX** with Tiered compilation **disabled**\r\n\r\nI will add a separate comment for every benchmark in this issue with some analysis.\r\n\r\nEnvironment info (updated):\r\n\r\n```\r\nBenchmarkDotNet=v0.11.1.786-nightly, OS=Windows 10.0.17134.285 (1803/April2018Update/Redstone4)\r\nIntel Xeon CPU E5-1650 v4 3.60GHz, 1 CPU, 12 logical and 6 physical cores\r\nFrequency=3507500 Hz, Resolution=285.1033 ns, Timer=TSC\r\n.NET Core SDK=2.2.100-preview2-009404\r\n  [Host]             : .NET Core 2.1.4 (CoreCLR 4.6.26814.03, CoreFX 4.6.26814.02), 64bit RyuJIT\r\n  Core 2.1           : .NET Core 2.1.4 (CoreCLR 4.6.26814.03, CoreFX 4.6.26814.02), 64bit RyuJIT\r\n  Core 3.0 NonTiered : .NET Core 3.0.0-preview1-27004-04 (CoreCLR 4.6.27003.04, CoreFX 4.6.27003.02), 64bit RyuJIT\r\n```'"
367989943,1190,b'What should be our strategy to handle failure in transformer',"b""So pretty much every transformer has a GetGetter delegate which looks on source column, get value from that column and handles it.\r\n```cs\r\n var getSrc = input.GetGetter<TSrc>(colIndex);\r\nValueGetter<TDst> retVal =\r\n     (ref TDst dst) =>\r\n     {\r\n      getSrc(ref src);\r\n      DoMagic(ref src, ref dst);\r\n    };\r\n```\r\nIn ideal world, that DoMagic procedure would always give us proper results, but unfortunately in real world some cases can't be handled and if we rely on code written by 3rd party we can't even fix it.\r\n\r\nMy question is following, what should be our strategy for that cases?\r\nI see few options:\r\n\r\n1.   Just throw exception if you can't handle it. This is quite straightforward, but in same time I think it not user friendly, especially during scoring for huge file.\r\n\r\n2. Force each transform to handle src ==null case and just set dst to null as well (i'm talking mostly about src is VBuffer<T> class) and in learner/ scorer ignore such rows. I would also add threshold to learner/ scorer to throw in case if percentage/absolute values of such rows exceed it. For me this feels like more user friendly approach. \r\n\r\nAny one willing to discuss? @Zruty0 @TomFinley @markusweimer @shauheen @eerhardt @CESARDELATORRE  @GalOshri @justinormont """
367972357,1188,b'Sweeper: ConfigRunner runs ResultProcessor without loading any assemblies into ComponentCatalog',"b'ExeConfigRunner uses ResultProcessor to summarize the metrics of the different runs, however, ResultProcessor needs to find components in the ComponentCatalog, so they should be loaded before calling it.'"
367969120,1187,b'Conversion: TryParseKey() throws an exception',"b'The method checks that IsStdMissing() returns false, but it is called without doing that check.\r\nWe should remove this check and return false if IsStdMissing().'"
367967990,1186,"b'ResultProcessor.cs: code under ""#if TLCFULLBUILD"" doesn\'t build'","b'Old code had result.Trainer.Kind, new syntax is result.TrainerKind.'"
367879957,1183,b'The link of the sdca examples is not being populated in the documentation. ',"b""The Sdca regression extension is referencing the code snippet from Microsoft.ML.Samples/Trainers.cs for the example in the documentation, but the documentation website doesn't pull the code.  The format of the link needs to be fixed. \r\n\r\n\r\n"""
367859715,1181,b'Unable to Install Microsoft.ML on target framework .NET Framework 4.6.1',"b""### System information\r\n\r\n- **OS version/distro**: Windows 7\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n- **Studio Version**: Visual Studio 2015\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempt to install Microsoft.ML v0.6.0.\r\n\r\n- **What happened?**\r\nError message was thrown as: Could not install package 'Microsoft.ML 0.6.0'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.6.1', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\r\n\r\n- **What did you expect?**\r\nPackage should have been installed successfully.\r\n\r\nNote: I have already installed Latest NuGet VSIX for VS 2015 & NET Standard Build Support.\r\n\r\n###Error\t\tCould not install package 'Microsoft.ML 0.6.0'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.6.1', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\t\t\t0\t\r\n"""
367839462,1180,b'Static Pipeline throws `IndexOutOfRangeException` with multiple column mappings',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro v1803, build 17134.285\r\n- **.NET Version (eg., dotnet --info)**: 2.1.402 @ commit 3599f217f4\r\n\r\n### Issue\r\n\r\n- **What did you do?** Translated an existing pipeline for text classification from the ""legacy"" pipeline builder to the new static API. Starting off with 2 text fields, we\'d tokenize them and feed the results into a classifier. The classifier we are using is the FAFM which allows variable number of float vectors to be passed as the input.\r\n\r\n- **What happened?** Code throws a `System.IndexOutOfRangeException` exception during training. Removing the second column from the tokenization **and** from the classifier fixes the issue.\r\n- **What did you expect?** Applying the same operation twice and passing 2 `Vector<float>` inputs to the FAFM classifier should train a model using both of these, not crash.\r\n\r\n### Source code / logs\r\n\r\n```\r\nSystem.IndexOutOfRangeException: \'Index was outside the bounds of the array.\'\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetDependencies(Func`2 predicate)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Data.CompositeRowToRowMapper.GetRow(IRow input, Func`2 active, Action& disposer)\r\n   at Microsoft.ML.Runtime.Api.PredictionEngine`2..ctor(IHostEnvironment env, Func`2 makeMapper, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.CreatePredictionEngine[TSrc,TDst](IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Data.PredictionFunction`2..ctor(IHostEnvironment env, ITransformer transformer)\r\n   at Microsoft.ML.Runtime.Data.PredictionFunctionExtensions.MakePredictionFunction[TSrc,TDst](ITransformer transformer, IHostEnvironment env)\r\n   at OpenRent.ML.Spam2.SpamTrainer.Foo(IList`1 source)\r\n   at OpenRent.Utils.Scripts.Spam.SpamEvaluator.Run() in C:\\OpenRent\\OpenRent\\OpenRent.Utils\\Scripts\\Spam\\SpamEvaluator.cs:line 99\r\n   at OpenRent.Utils.Program.runScript() in C:\\OpenRent\\OpenRent\\OpenRent.Utils\\Program.cs:line 66\r\n   at OpenRent.Utils.Program.Main() in C:\\OpenRent\\OpenRent\\OpenRent.Utils\\Program.cs:line 39\r\n```\r\n\r\n### Proposed Fix\r\n - There is what looks like a typo on L39, in the `CompositeRowToRowMapper.cs` file, in the `Microsoft.ML.Data` project. \r\n - The line reads: `for (int i = _innerMappers.Length - 1; i <= 0; --i)`\r\n - In order to loop through all `_innerMappers` the `<=` comparison should be changed to a `>=` . \r\n - After changing the sign the code compiles, tests pass and training completes as expected.'"
367434528,1175,b'PROSE SDK',"b""Hi!\r\n\r\nNow with #563 we have Infer.NET integrated into ML.NET and available with a commercial license - can the same be done with PROSE?\r\n\r\nhttps://microsoft.github.io/prose/\r\n\r\nIt currently also has a non-commercial license - but over the last year I've seen dozens of use-cases within our customers who could use PROSE to improve data wrangling (and much more) used to feed ML models etc - but we can't use it because of the non-commercial license.\r\n\r\nIf it were integrated under the ML.NET umbrella - it would be another amazing tool for the .NET ecosystem.\r\n\r\nMany thanks!\r\n\r\nHoward"""
367403879,1171,b'ImageLoaderTransform can load corrupted images',"b'ImagerLoaderTransform can load corrupted images if the file path of an image it is attempting to load has special characters. Not finding a file also returns a null. In both of these cases, no error messages are propagated to the user until the invalid values cause further issues down the line in other transforms or training.'"
367393047,1170,b'Add 3.0 to CI',"b'We plan to ship codepaths that are specific to .NET Core 3.0, which will presumably be out in previews when we ship. We have some tests (albeit [incomplete](https://github.com/dotnet/machinelearning/issues/1156)) but they do not run unless the special build is performed locally.\r\n\r\nIt is too early to require contributors to have any build of 3.0 on their machines but it is not too early to add protection for the build and tests at the point of checkin. We should install some version of 3.0 on the CI machines, and add a leg to CI that builds and tests for 3.0. \r\n\r\ncc @eerhardt \r\n\r\n'"
367370743,1168,"b""Solution file don't have references for all package projects""","b'https://github.com/dotnet/machinelearning/tree/master/pkg\r\nwe have quite a lot of packages, but solution file has reference only for 3 of them\r\nhttps://github.com/dotnet/machinelearning/blob/d5175899b604d852dab08107e583c78cbe5d6948/Microsoft.ML.sln#L52\r\n\r\nShould we update solution and have policy to add new packages into it, or should we just remove them from solution?\r\n\r\nAny thoughts?'"
367073289,1162,b'Trainer extensions should be in the Microsoft.ML.Trainers namespace',"b'We moved the trainers from the Microsoft.Ml.Trainers namespace, to the Microsoft.Ml.StaticPipe namespace, so that they display on Ctrl+Space of the trainingContext object. We chose this namespace since we are suggesting the users to opt in to this namespace for Pigsty Api usage. \r\n\r\nBut the docs.microsoft.com site is hard to navigate this way; where users starts from namespaces. \r\nThat namespace is not intuitive, as a placeholder for the list of trainers, and it also contains a bunch of other unrelated utilities. Revert back and add a note to the cookbook.  '"
367026855,1159,"b""OVA and PKPD don't have pigsty extensions.""","b'Not sure was it intentional, or we just forgot to add them\r\n'"
367016237,1157,b'Manage TensorFlow model loading so that it is not loaded twice; first for schema then for use in TFTransform.',"b'TFSession/TFGraph is loaded twice if user is interested in query the model schema first and then creating TensorFlowTransform. \r\n\r\nCurrently, there is no way to pass existing TFSession information which was loaded during schema probing to TensorFlowTransform. Furthermore, TFSession is internal to the assembly and there is no plan to expose this object.\r\n\r\nThe solution would be to create a `TensorFlowModelContext` wrapper class as follows that will carry the TFSession as internal object. A convenience constructor will created in TensorFlowTransform that will accept this object as input instead of model location.\r\n\r\n``` C#\r\npublic class TensorFlowModelContext\r\n{\r\n    internal TFSession TFSession { get; private set; }\r\n    public string ModelPath { get; private set; }\r\n    public ISchema Schema { get; private set; }\r\n\r\n    internal TensorFlowModelContext(TFSession tFSession, string modelLocation, ISchema schema)\r\n    {\r\n        TFSession = tFSession;\r\n        ModelPath = modelLocation;\r\n        Schema = schema;\r\n    }\r\n}\r\n```'"
367001971,1156,b'Enable tests against .NET Core 3.0 SSE and software-only paths',"b'Seems we have 4 possible code paths in cpumath:\r\n\r\n1) sse.cpp  -- used when not on .NET Core 3.0\r\n2) avxintrinsics.cs  -- on .NET Core 3.0 with AVX available\r\n3) sseintrinsics.cs\t -- on .NET Core 3.0 with SSE but not AVX\r\n4) software fallback in cpumathutils.netcoreapp.cs -- on .NET Core 3.0 with no SIMD (eg., on ARM). There seems to be no software fallback when not on .NET Core 3.0.\r\n\r\nFor tests we have\r\nA) CpuMath.UnitTests.netcoreapp. Executes whichever of (2), (3), (4) applies at run time. Which will almost surely be (2) in all cases.\r\nB) CpuMath.UnitTests.netstandard. Same tests as above, but against (1).\r\nC) Microsoft.ML.CpuMath.PerformanceTests. Perf, not functional, tests for about 20 entry points in (1), (2), and (3) explicitly.\r\n\r\nWe need to have tests for anything we ship and support, which I think means we have a gap for (3) and (4) ie on older x86 machines and on non x86 machines.\r\n\r\n@tannergooding how commonly would the non AVX path (3) be encountered on typical customer x86 machines? Am I correct that (4) is not relevant to x86?\r\n\r\ncc @Anipik \t \r\n\r\n'"
366908826,1154,b'How to create an Estimator without using a DataReader?',"b""### System information\r\nUsing the new API (PiGSTy/Typed) API.\r\n\r\n### Context\r\nThis is confirmed by Tom that the needed API is still not surfacing in the new PiGSTy/Typed API for this scenario. Will come soon, I'm just opening the issue to track it down.\r\n\r\n### Problem \r\nLet\xe2\x80\x99s say I\xe2\x80\x99m not reading/loading data from a text file (using a DataReader) but from a Database or any other channel, like the following code:\r\n \r\n```\r\nvar env = new LocalEnvironment();\r\nIEnumerable<Orders> myData = GetDataFromDatabase();\r\nvar trainData = env.CreateStreamingDataView(myData);\r\n```\r\n \r\n\xe2\x80\xa6.\r\n \r\nFor the whole training process, I could do something like the following, with the new API:\r\n \r\n```\r\nvar dataReader = TextLoader.CreateReader(env,\r\n                c => (\r\n                    CustomerId: c.LoadText(0),\r\n                    ProductId: c.LoadText(1),\r\n                    Quantity: c.LoadFloat(2),\r\n                    Label: c.LoadBool(3)),\r\n                    separator: ',', hasHeader: true);\r\n \r\nFieldAwareFactorizationMachinePredictor pred = null;\r\nvar ctx = new BinaryClassificationContext(env);\r\n \r\nvar est = dataReader.MakeNewEstimator()\r\n    .Append(row => (CustomerId_OHE: row.CustomerId.OneHotEncoding(), ProductId_OHE: row.ProductId.OneHotEncoding(), row.Label))\r\n    .Append(row => (Features: row.CustomerId_OHE.ConcatWith(row.ProductId_OHE), row.Label))\r\n    .Append(row => (row.Label,\r\n    preds: ctx.Trainers.FieldAwareFactorizationMachine(\r\n        row.Label,\r\n        new[] { row.Features },\r\n        advancedSettings: ffmArguments => ffmArguments.Shuffle = false,\r\n        onFit: p => pred = p)));\r\n \r\n// NO NEED FOR THIS SINCE I\xe2\x80\x99M NOT READING FROM A FILE\r\n//var dataSource = reader.Read(new MultiFileSource(orderItemsLocation));\r\n \r\n// Load data in IDataView from a Database\r\nIEnumerable<Orders> myData = GetDataFromDatabase();\r\nvar trainData = env.CreateStreamingDataView(myData);\r\n \r\nvar model = est.Fit(trainData);\r\n \r\n```\r\n \r\nHowever, since we\xe2\x80\x99re not reading/loading from a file, I should be able to create an Estimator by using a different way instead of a \xe2\x80\x9cdataReader\xe2\x80\x9d, since in the code above that dataReader is *not* reading anything and is just being used to create the estimator.\r\n\r\nI\xe2\x80\x99d like to create the \xe2\x80\x9cschema\xe2\x80\x9d provided to the DataReader and create the Estimator without anything related to a DataReader, because I\xe2\x80\x99m not reading anything with it in the code above.\r\n\r\n"""
366879987,1153,b'Rename Microsoft.ML.StaticPipe.Vector<T> type',"b'We currently have:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/161b450a68a3f47eaf8abd4ce4778e417814b20f/src/Microsoft.ML.Data/StaticPipe/PipelineColumn.cs#L48-L52\r\n\r\nWhich is more of a schema type that says ""the column I represent is a vector type"". Which means this type isn\'t actually a ""vector"", but more of a ""vector column"".\r\n\r\nWe should rename this type (and the other XXColumn types), so we can ""make room"" for an actual `Vector<T>` type, which really does represent a ""vector"" object.\r\n\r\n/cc @TomFinley '"
366846455,1150,b'Model Backwards Compatability ',"b'Hi\r\n\r\nFollowing up from issue #569 - when using the latest nightly builds `0.7.0-preview-27004-1` models trained using the previous ML.NET release (0.5) fail to load, with the following exception:\r\n\r\n``` csharp\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Runtime.Data.CompositeDataLoader.LoadSelectedTransforms(ModelLoadContext ctx, IDataView srcView, IHostEnvironment env, Func`2 isTransformTagAccepted)\r\n   at Microsoft.ML.Runtime.Model.ModelFileUtils.LoadTransforms(IHostEnvironment env, IDataView data, RepositoryReader rep)\r\n   at Microsoft.ML.Runtime.Model.ModelFileUtils.LoadTransforms(IHostEnvironment env, IDataView data, Stream modelStream)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.LoadTransforms(IHostEnvironment env, Stream modelStream, IDataView data)\r\n   at Microsoft.ML.Runtime.Api.DataViewConstructionUtils.LoadPipeWithPredictor(IHostEnvironment env, Stream modelStream, IDataView view)\r\n   at Microsoft.ML.Runtime.Api.BatchPredictionEngine`2..ctor(IHostEnvironment env, Stream modelStream, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.CreateBatchPredictionEngine[TSrc,TDst](IHostEnvironment env, Stream modelStream, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Legacy.PredictionModel.ReadAsync[TInput,TOutput](Stream stream)\r\n   at Demo.Program.<Main>d__0.MoveNext() in C:\\_Projects\\OSS\\MLNETPreviousModelLoadingError\\Demo\\Program.cs:line 25\r\n```\r\n\r\nI\'ve attached a small demo that reproduces the above. The zip also contains a model trained on ML.NET 0.5 using the following code:\r\n\r\n``` csharp\r\nnamespace Endjin.Expenses.Demo\r\n{\r\n    #region Using Directives\r\n\r\n    using System.Collections.Generic;\r\n\r\n    using Endjin.FreeAgent.Expenses.MachineLearning.Domain;\r\n\r\n    using Microsoft.ML.Legacy;\r\n    using Microsoft.ML.Legacy.Data;\r\n    using Microsoft.ML.Legacy.Trainers;\r\n    using Microsoft.ML.Legacy.Transforms;\r\n\r\n    #endregion \r\n\r\n    public class ExpenseModelTrainer\r\n    {\r\n        public PredictionModel<TransactionModel, Prediction> Train(IEnumerable<TransactionModel> input)\r\n        {\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                CollectionDataSource.Create(input),\r\n                new TextFeaturizer(""Features"", nameof(TransactionModel.Description), nameof(TransactionModel.Reference), nameof(TransactionModel.Amount)),\r\n                new Dictionarizer(nameof(TransactionModel.Label)),\r\n                new StochasticDualCoordinateAscentClassifier(),\r\n                new PredictedLabelColumnOriginalValueConverter { PredictedLabelColumn = nameof(Prediction.PredictedLabel) }\r\n            };\r\n\r\n            return pipeline.Train<TransactionModel, Prediction>();\r\n        }\r\n    }\r\n}\r\n```\r\n(The ""legacy"" namespaces changed in the latest version, but if you change them back to the 0.5 version namespaces - nothing else changed)\r\n\r\n[MLNETPreviousModelLoadingError.zip](https://github.com/dotnet/machinelearning/files/2446874/MLNETPreviousModelLoadingError.zip)\r\n\r\nMany thanks,\r\n\r\nHoward\r\n'"
366772332,1148,b'Saving of Prediction Function',"b'We are currently working with the 0.50 release and looking to move to the new API. One of the questions that has surfaced is in regards to the new PredictionFunction \r\n\r\n`// Use the model for one-time prediction.\r\n// Make the prediction function object. Note that, on average, this call takes around 200x longer\r\n// than one prediction, so you might want to cache and reuse the prediction function, instead of\r\n// creating one per prediction.\r\nvar predictionFunc = model.MakePredictionFunction<IrisInput, IrisPrediction>(env);`\r\n\r\nWe are currently working with a set of models that we are saving/restoring from in order to get predictions. Sometimes these models are taking up a large amount of memory \xe2\x80\xa6 on the order of ~8GB for some of the more complicated ones that are using various ngram lengths. \r\n\r\nSo the question would be \xe2\x80\xa6 Would there be any reason we could not save off the PredictionFunction in addition to the model in order to possibly shave off memory consumption or should we expect that the PredictionFunction created by a model with a given memory footprint will be relatively the same size? \r\n\r\nThanks!\r\n'"
366636399,1146,b'Regression learning with constrains ',"b'Hello Team, \r\n\r\nI just was thinking about the follow scenario and questions:\r\n\r\n- you have a normal regression Problem with n features \r\n- you build a Model based on this known features \r\n- **how does ML.NET handle constrains like ""feature 1 and 2 always must satisfy a equation""?**  \r\n- **Is there an easy way to fit non-linear function based models without feature transform?** (something like f(x) = sin(p_1*x_1) * p_2 * exp(P_3 * x_2) * x_3, here are my data and what are the parameters?) \r\n\r\nI am from automotive engineering area and unfortunately we always facing this issues and unfortunately again most here are old school and MATLAB users. \r\n\r\nSo most engineers expect something MATLAB like, e.g. Regression.Fit(sin(p_1*x_1) * p_2 * exp(P_3 * x_2) * x_3, x_vector, y_vector) . \r\n\r\nSo this ML.NET have already something like this? I could image a model class could have something like constrains fields ... :D \r\n'"
366580982,1144,b'Inconsistancy in Training With Multiple Threads ',"b'We are currently using version 0.50 in creating some classifier models but are seeing some strange behavior. We are currently setting the number of threads in our classifiers due to #217 and wanting to be able to control the CPU usage on the server. \r\nSo when using a classifier like so .. \r\n`var algo = new StochasticDualCoordinateAscentClassifier()\r\n                    {\r\n                        Caching = CachingOptions.Disk,\r\n                        MaxIterations = 100,\r\n                        LossFunction = new SmoothedHingeLossSDCAClassificationLossFunction(),\r\n                        Shuffle = false,\r\n                        NumThreads = System.Environment.ProcessorCount - 1 //We use one less than the number of processors available,\r\n                    };`\r\n\r\nWhat we are noticing is that if we run this from a box with 4 cores on it then we get a decent model where the microaccuracy is above 90%. However, when we move this same code over to a larger server with 8 cores we are getting wildly different results. The microaccuracy drops down to around <60%. \r\nYikes! \r\n\r\nIs there possibly something we are missing in the documentation that would address this? '"
366481392,1138,b'PredictionFunction should not reuse the output object',"b'`PredictionFunction` should create an instance of output object on every call.\r\nThe current behavior of reusing the object from call to call is confusing, and the performance gain is questionable.\r\n\r\n(original bug description below)\r\n\r\n### System information\r\n- Using ML.NET v0.6 and PiGSTy/Static API\r\n\r\n### Issue\r\nWe have migrated the sample using **TensorFlow as featurizer** and using the **pre-trained Inception v3 TF model**, then using an ML.NET SDCA learner for the classification.\r\n\r\nThis is the original LearningPipeline API-based sample that was working ok:\r\nhttps://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/examples/DeepLearning_TensorFlowMLNETInceptionv3ModelScoring\r\n\r\nThe new code you can test is here:\r\nrepo: https://github.com/franperezlopez/machinelearning-samples\r\nbranch: features/samples-new-api\r\n\r\nHere\xe2\x80\x99s an screenshot showing the execution:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432381-fccdae00-c702-11e8-84ed-794cde3d6398.png)\r\n\r\n\xe2\x80\xa2\tFirst, basically, the variables temp1 and temp2 and really the same object in memory (in Watcher, after ""make object ID"", you can see that both are pointing to the same position in memory. These variables come  from the object returned by **predictor.Predict()**. See the code in order to understand the code flow.\r\n\r\nIf `model.AsDynamic.MakePredictionFunction<ImageNetData, ImageNetStaticPrediction>(env).Predict(testData)` is meant to always return the same object in memory, it would be advisable to show that explicitly in the API, doing something like:\r\n\r\n`model.AsDynamic.MakePredictionFunction<ImageNetData, ImageNetStaticPrediction>(env, testData).Predict()`\r\n\r\nThat way, testData is provided through the constructor instead as parameter for the function/method, so it is clearer that you can only use it \xe2\x80\x9conce\xe2\x80\x9d. But I\'m not sure if the behavior is a bug, though...\r\n\r\nCan you confirm if we need to \xe2\x80\x9ccopy by value\xe2\x80\x9d the PredictionFunction to a new object whenever we want to do a different prediction with new test/sample data? For example, in a loop with multiple predictions, etc.\r\n\r\n\xe2\x80\xa2\tSecond. The predictions we are getting are much worse in quality/probability than when using the LearningPipeline API. In the Watcher, looking at the metrics, you can see what\xe2\x80\x99s going on. Basically, we\xe2\x80\x99re exploring the preds.score returned by the SDCA, but it looks weird we\xe2\x80\x99re getting numbers like **0.2** \xe2\x80\xa6?  --> When we were using the LearningPipeline for this same example we were getting probabilities around 0.999 or 0.0001.\r\no\tYou can also see in the screenshot the value for \xe2\x80\x9c**softmax2_pre_activation**\xe2\x80\x9d, which is the features vector coming from the neural network. \r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432660-a3b24a00-c703-11e8-85bd-93db619c348b.png)\r\n\r\nLooks like the SDCA is not learning anything, it is always classifying as \xe2\x80\x9cbroccoli\xe2\x80\x9d. So, we don\xe2\x80\x99t know what\xe2\x80\x99s going on here.\r\nWe might be doing something wrong or it might be a bug?\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432696-b7f64700-c703-11e8-8354-3c03a4448b80.png)\r\n\r\n\r\nBottom line, we\xe2\x80\x99re blocked with this sample. It is not working properly with the new Static API after migrating a working sample with the LearningPipeline. \r\nEither we\xe2\x80\x99re doing something wrong or there\xe2\x80\x99s an issue/bug here?\r\n\r\nThanks,\r\n'"
366464164,1137,b'Package the datasets needed for the samples in a nuget',"b""The samples in docs.microsoft.com need to be fully self-contained like other MSDN code samples, so the users can copy-paste and run them. \r\n\r\nFor this we could either package the datasets needed for the samples in a NuGet, or download them from this repo, via aka.ms links. \r\nI prefer the NuGet option, since the package creation and its updates are on the repository, and we can track history. We can't do the same for the links, afaik, and it is a separate system. \r\n\r\nThis issue will be considered complete when we publish the NuGet containing one dataset that we can reference from the samples. """
366461191,1136,b'Better error message for non-existing columns when executing graph',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: Latest master branch \r\n\r\n### Issue\r\n\r\nExecuting a graph with wrong LabelColumn name, the error messages is not very clear:\r\n\r\nMessage: System.ArgumentOutOfRangeException : Specified argument was out of the range of valid values.\r\nParameter name: Column\r\n\r\nIf the FeatureColumn name is wrong, the error message indicates Column not found, which is better.\r\n[infert.txt](https://github.com/dotnet/machinelearning/files/2443223/infert.txt)\r\n[graph_1.txt](https://github.com/dotnet/machinelearning/files/2443224/graph_1.txt)\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
366197302,1133,"b""docs.microsoft.com don't display all the extension methods for trainers""","b'The training methods are extensions of the TrainingContext object, organized in partial classes (ex. RegressionTrainers), that are part of the same namespace (Microsoft.ML.StaticPipe), but packaged in different dlls . \r\nSo across the dlls there are several RegressionTrainers.xml (for the partial classes)\r\n\r\nOn the documents repo, there is only one RegressionTrainers.xml file (maybe the first encountered)\r\nhttps://github.com/dotnet/ml-api-docs/tree/smoke-test/dotnet/xml/Microsoft.ML.StaticPipe\r\n\r\nIf the docs CI cannot gather all those .xml in one. \r\nWe might have to keep the extension methods  within the namespaces  of the trainers, and rely on search for discoverability.\r\nIntellisense  might suffer, as the users would have to add all namespaces to get all trainers in the suggestions. \r\n\r\nWe can keep the extensions, on classes with the same names in those namespaces. \r\n\r\n'"
366167777,1131,b'Investigate and fix test failures',"b""Our commit success rate is below 50% at this point. \r\n\r\nWe no longer have the annoying deadlock plaguing the builds, but somehow the builds are still failing quite often. Let's spend some time and improve that story.\r\n\r\nFrom casual look, there is no single culprit: we seem to randomly fail to initialize build environment, and random tests seem to fail in random places. I guess this may have to do with resource-constrained runs: maybe we should actually try running xUnit tests sequentially and see if the sporadic failures go away?"""
366141556,1130,b'Sample for data from relational database?',"b""Do we have a sample that demonstrates how to use ML.NET with data from a relational database, such as SQL Server? I don't need a complete sample but just how to pass such a dataset, instead of using TextLoader?\r\n\r\nAlso, from what I can see, the samples use LearningPipeline which I've read is deprecated. Do we have a sample that demonstrates the new API?"""
366129850,1129,b'Build errors involving `Microsoft.ML.InternalCodeAnalyzer`',"b'There seems to be an issue with how the build treats `Microsoft.ML.InternalCodeAnalyzer.dll`. After `build` from the command line, I did a rebuild in VS 2017. This results in many copies of this message in the error list:\r\n\r\n```\r\nSeverity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tIDE1001\tThe analyzer assembly \'C:\\src\\machinelearning\\bin\\AnyCPU.Debug\\Microsoft.ML.InternalCodeAnalyzer\\netstandard1.3\\Microsoft.ML.InternalCodeAnalyzer.dll\' has changed. Diagnostics may be incorrect until Visual Studio is restarted.\tMicrosoft.ML.Core\t\t1\tActive\r\n```\r\n\r\nAfter restarting VS and doing a mere Build instead of Rebuild, I don\'t get this error. Rebuilding recreates the issue.\r\n\r\nI also get some weird behavior when trying to build in Ryder, which might illuminate the issue in VS. As far as I know, Ryder uses `msbuild` directly to issue a build. When I select Build (or Rebuild) in its UI, I get this error, involving the same `Microsoft.ML.InternalCodeAnalyzer.dll`:\r\n\r\n```\r\n  Microsoft.Common.CurrentVersion.targets(4187, 5): [MSB3021] Unable to copy file ""C:\\src\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.InternalCodeAnalyzer\\netstandard1.3\\Microsoft.ML.InternalCodeAnalyzer.dll"" to ""C:\\src\\machinelearning\\bin/AnyCPU.Debug\\Microsoft.ML.InternalCodeAnalyzer\\netstandard1.3\\Microsoft.ML.InternalCodeAnalyzer.dll"". The process cannot access the file \'C:\\src\\machinelearning\\bin/AnyCPU.Debug\\Microsoft.ML.InternalCodeAnalyzer\\netstandard1.3\\Microsoft.ML.InternalCodeAnalyzer.dll\' because it is being used by another process.\r\n```\r\n\r\nI\'d assume Ryder itself loads that DLL on solution load. Hence, this might be a bug in it as opposed to the ML.NET build.\r\n\r\nThat being said, the VS issue is a nuisance we should investigate.'"
366125329,1128,b'Quickstart Tutorial is out of date (version 0.4.0)',"b""The first tutorial mentioned on the docs site (https://docs.microsoft.com/en-us/dotnet/machine-learning/) uses ML.NET version 0.4.0, as does the example on main GitHub readme page.  These examples require the Microsoft.ML.Legacy namespace.\r\n\r\nSnippet from example:\r\n`var pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader(dataPath).CreateFrom<SentimentData>(separator: ','));\r\n`\r\n"""
366089236,1124,b'Provide API to estimate memory consumption by models',b'Provide an API to estimate memory consumption by model training on a single node (for models for which it is possible).'
366081820,1121,b'SDCA regression trainer context extension ',"b""The SDCA extensions on the various TrainContext objects don't follow the pattern of exposing an Action<advancedSettings> for the advanced arguments; therefore there is no way to set any of the other arguments, that are not directly exposed in that method signature, like the BiasLearningRate .  \r\n\r\n\r\nfile: Microsoft.ML.StandardLearners/Standard/SdcaStatic.cs"""
366070417,1120,b'Need real time series dataset for tests',b'Currently we have a fake excel generated dataset and this causes asserts to fire in two of the SSA forecasting tests.'
365696074,1113,"b'EntryPointGraph,GraphRunner and ComponentCatalog'","b'as example:\r\nhttps://github.com/dotnet/machinelearning/blob/59a90e7b2974ac857d3fd62c2f9a3dba9384eb85/src/Microsoft.ML.Legacy/Runtime/EntryPoints/JsonUtils/GraphRunner.cs#L26\r\n\r\nConstructor accepts IHostEnvironment, and ComponentCatalog, but recently we made changes where ComponentCatalog become part of IHostEnvironment.\r\n\r\nI think we should simplify our constructors and just accept IHostEnviroment.'"
365684656,1110,b'Convert TensorFlowEstimator into Non-TrivialEstimator.',"b'The `TensorFlowEstimator` is currently a `TrivialEstimator`. Recently, model retraining feature was added to `TensorFlowTransform` which requires the `TensorFlowEstimator` to be non-trivial estimator.\r\n'"
365684154,1109,b'Issue with WordEmbeddings using service accounts. ',"b'### System information\r\n\r\n- **Windows Server**:\r\n- **.NET Version - Core 2.1**: \r\n\r\n### Issue\r\nI built a demo web application that runs locally but breaks on the server. I am using WordEmbeddings. The error message is:\r\n\r\n""Error downloading resource: Error trying to create directory : Path cannot be the empty string or all whitespace.\r\nParameter name: path.\r\nPlease fix your filesystem permissions, or try setting the \'MICROSOFTML_RESOURCE_PATH\' environment variable to a writable folder""\r\n\r\nI am using a service account on the IIS server and the GetFilePath method is is getting an empty string for ""Environment.SpecialFolder.LocalApplicationData"". I have the Environment Variable set to the appropriate folder. The issue is that the GetFilePath method is not checking for the Environment variable path at the right time and throwing the error reaching before that part of the code.\r\n```csharp\r\n            if (!Directory.Exists(appDataBaseDir))\r\n            {\r\n                try\r\n                {\r\n                   //**for service accounts, appDataBaseDir is empty and this through the error that is caught. Perhaps need to check for empty string here?** \r\n                    Directory.CreateDirectory(appDataBaseDir);\r\n\r\n                    // On unix, create with 0700 perms as per XDG base dir spec\r\n                    if (Environment.OSVersion.Platform == PlatformID.Unix)\r\n                        chmod(appDataBaseDir, 448);\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    error = $""Error trying to create directory {appDataBaseDir}: {e.Message}.\\nPlease fix your "" +\r\n                        ""filesystem permissions, or try setting the "" +\r\n                        $""\'{Utils.CustomSearchDirEnvVariable}\' environment variable to a writable folder"";\r\n                    return filePath;\r\n                }\r\n            }\r\n\r\n           \r\n            if (!Directory.Exists(absDir))\r\n            {\r\n                try\r\n                {\r\n                    Directory.CreateDirectory(absDir);\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    error = $""Error trying to create directory {absDir}: {e.Message}.\\nPlease try setting the "" +\r\n                        $""\'{Utils.CustomSearchDirEnvVariable}\' environment variable to a writable folder"";\r\n                }\r\n            }\r\n            return filePath;\r\n        }\r\n```\r\n\r\n'"
365667574,1108,b'Add support for stopping criteria other than training iterations in TensorFlowTransform.',"b'Currently, training in TensorFlowTransform stops when specified umber of iterations are done. \r\nIt will also be interesting to add support for following stopping criteria.\r\n- Increase in training loss (or no change in the loss over the last few iterations)\r\n- Stop training based on performance on validation set.'"
365662268,1107,b'Need the ability to view transformed data outside of the library',"b'\r\n\r\n### There is currently no easy way to view data from an external application after a number of transforms have been applied using a LearningPipeline. The LearningPipelineDebugProxy class is a sealed internal class. Using reflection, I can only see the first 10 rows of data. It would be very helpful if the LearningPipelineDebugProxy class were public or if there was some other way to view transformed data from an external application\r\n\r\n'"
365659138,1106,b'Error due to ShuffleTransform in pipeline.',"b'Need to convert `ShuffleTransform` into Transformer/Estimator design. Currently, when it is used in `TensorFlowTransform` to enable shuffling of data during training, it gives error regarding <b>`ShuffleTransform is not RowToRowMapper`</b>.\r\n\r\n### Update\r\nIt seems like the transform works fine during training. The error is somewhere when creating prediction engine.\r\n\r\nThe following is the exact location where assertion fails during creation of prediction engine.\r\nhttps://github.com/dotnet/machinelearning/blob/8ca1c9386587aa4ef77c56f605f8244debefce93/src/Microsoft.ML.Data/DataLoadSave/TransformWrapper.cs#L133\r\n\r\nHere is the test failure log\r\n```\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8050239]         E:\\TLC_git\\machinelearning\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs(70,0): at Microsoft.ML.Runtime.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8060923]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(777,0): at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8064869]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(786,0): at Microsoft.ML.Runtime.Contracts.DbgFail(IExceptionContext ctx)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8067575]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(841,0): at Microsoft.ML.Runtime.Contracts.Assert(IExceptionContext ctx, Boolean f)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8070263]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\TransformWrapper.cs(133,0): at Microsoft.ML.Runtime.Data.TransformWrapper.GetRowToRowMapper(ISchema inputSchema)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8073429]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs(190,0): at Microsoft.ML.Runtime.Api.PredictionEngine`2..ctor(IHostEnvironment env, Func`2 makeMapper, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8076450]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs(172,0): at Microsoft.ML.Runtime.Api.PredictionEngine`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8078831]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs(166,0): at Microsoft.ML.Runtime.Api.PredictionEngine`2..ctor(IHostEnvironment env, IDataView dataPipe, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8081564]         E:\\TLC_git\\machinelearning\\src\\Microsoft.ML.Api\\ComponentCreation.cs(190,0): at Microsoft.ML.Runtime.Api.ComponentCreation.CreatePredictionEngine[TSrc,TDst](IHostEnvironment env, IDataView dataPipe, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8084805]         E:\\TLC_git\\machinelearning\\test\\Microsoft.ML.Tests\\ScenariosWithDirectInstantiation\\TensorflowTests.cs(438,0): at Microsoft.ML.Scenarios.ScenariosTests.ExecuteTFTransformMNISTLRTrainingTest(Boolean shuffle, Nullable`1 shuffleSeed, Double expectedMicroAccuracy, Double expectedMacroAccruacy)\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8087841]         E:\\TLC_git\\machinelearning\\test\\Microsoft.ML.Tests\\ScenariosWithDirectInstantiation\\TensorflowTests.cs(365,0): at Microsoft.ML.Scenarios.ScenariosTests.TensorFlowTransformMNISTLRTrainingTest()\r\n[10/9/2018 4:18:27 PM Informational] [xUnit.net 00:00:10.8586866]   Finished:    Microsoft.ML.Tests\r\n```\r\n'"
365556704,1104,"b'How to use EntryPoint saved .zip files with the ""new API""?'","b'### System information\r\n\r\n- **OS version/distro**: all\r\n- **.NET Version (eg., dotnet --info)**:  \r\n```\r\n> dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   3.0.100-alpha1-009622\r\n Commit:    5a14412a49\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\3.0.100-alpha1-009622\\\r\n\r\nHost (useful for support):\r\n  Version: 3.0.0-preview1-26924-01\r\n  Commit:  4b8641b848\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempt to load a .zip file that was created by EntryPoints using `TransformerChain.LoadFrom`.\r\n\r\n- **What happened?**\r\n```\r\nAn unhandled exception was thrown by the application.\r\nMicrosoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Function1 ---> System.FormatException: Corrupt model file\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Data.TransformerChain.LoadFrom(IHostEnvironment env, Stream stream)\r\n   at MLFunction.Predictor.PredictAsync(GitHubIssue issue, TraceWriter log) in F:\\git\\MLFunction\\Predictor.cs:line 69\r\n```\r\n\r\n- **What did you expect?**\r\nI expected to be able to use a .zip file that was created using the EntryPoints API with the ""new API"".\r\n\r\n### Notes\r\n\r\nIf we are keeping the EntryPoints API, users will be creating model files using EntryPoints. We need to have an API that allows C#/.NET developers to use those model files.'"
365547793,1103,b'The MlNetMklDeps nuget package should include exports used by the time series code',"b'As part of the #977 work, the custom DLL for MKL that we package on the MlNetMklDeps nuget should include the following functions:\r\n\r\nLAPACKE_shseqr\r\nLAPACKE_dhseqr\r\nLAPACKE_ssytrd\r\nLAPACKE_dsytrd\r\nLAPACKE_ssteqr\r\nLAPACKE_dsteqr\r\nLAPACKE_sorgtr\r\nLAPACKE_dorgtr\r\n'"
365179553,1101,b'All Last names are Scottish ? :)',"b'### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 2.1\r\n- **ML.NET Version**: 0.5\r\n\r\n### Issue\r\n\r\n- **What did I do?**\r\nUsed SDCA to classify last names\r\n\r\n- **What happened?**\r\nNo matter what last name I gave , it is predicted to be Scottish\r\n\r\n- **What did you expect?**\r\nCorrect classification\r\n\r\n### Source code / logs\r\nHere is an excerpt from the output:\r\n\r\nLast Name: Abbracciabene\r\nPredicted probability: Arabic.txt:      0\r\nPredicted probability: Chinese.txt:      0\r\nPredicted probability: Czech.txt:      0\r\nPredicted probability: Dutch.txt:      0.0025\r\nPredicted probability: English.txt:      0.0001\r\nPredicted probability: French.txt:      0.0036\r\nPredicted probability: German.txt:      0.0015\r\nPredicted probability: Greek.txt:      0.0012\r\nPredicted probability: Irish.txt:      0.0113\r\nPredicted probability: Italian.txt:      0.0013\r\nPredicted probability: Japanese.txt:      0.0038\r\nPredicted probability: Korean.txt:      0.0001\r\nPredicted probability: Polish.txt:      0\r\nPredicted probability: Portuguese.txt:      0.0002\r\nPredicted probability: Russian.txt:      0\r\nPredicted probability: Scottish.txt:      0.9737\r\nPredicted probability: Spanish.txt:      0\r\nPredicted probability: Vietnamese.txt:      0.0006\r\nPredicted probability: :      0\r\n\r\nSee the attached source code for more details.\r\n[LastNamePlay.zip](https://github.com/dotnet/machinelearning/files/2431123/LastNamePlay.zip)\r\n\r\n'"
365169598,1100,"b'Getting SDCA multiclass weights requires using a MulticlassLogisticRegressionPredictor, which is strange'","b'As shown [here](https://github.com/dotnet/machinelearning/blob/3cdd3c8b32705e91dcf46c429ee34196163af6da/test/Microsoft.ML.StaticPipelineTesting/Training.cs#L268), getting the predictor weights from multiclass-SDCA requires using `MulticlassLogisticRegressionPredictor`. This is counter-intuitive as I would expect that predictor to be used just for Logistic Regression. Perhaps something more general like `MulticlassLinearPredictor` should be created/used?'"
365069754,1098,b'MLContext to create them all',"b""During one of the in-person API reviews we agreed that it would be a good idea to have a single object `MLContext` that would serve as a 'factory of everything' (similar to the HTTP context / DB context in the .NET world).\r\n\r\n- `MLContext` will explicitly implement `IHostEnvironment`, so you can create all the existing estimators by giving the context as the first argument.\r\n- `MLContext` will have properties `BinaryClassification`, `Regression`, `Clustering` etc. for canonical ML tasks (the ones that are currently classes in themselves), complete with `Evaluate` and all corresponding trainers.\r\n- It will have *extension methods* for non-canonical tasks like recommendation or anomaly detection etc.\r\n- It will have properties `Transformation`, `Filtering`, `Loading` to instantiate all known transform estimators, filters and data readers (again via extension methods).\r\n- It will have a pair of methods `SaveModel` and `LoadModel` that handle model serialization.\r\n\r\n/cc @KrzysztofCwalina @TomFinley @eerhardt @markusweimer @asthana86 """
365067994,1097,"b""Static pipe doesn't validate sufficiently""","b""Here is an example:\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/Scenarios/Api/CookbookSamples/CookbookSamples.cs#L657\r\n\r\nIf I change the line to be `PredictedLabel: c.KeyU4.TextValues.Vector` , I will essentially (wrongly) claim that the model's `PredictedLabel` is a vector of keys. But `Fit` will work just fine, although even the basic `GetOutputSchema` call would verify that this is an invalid pipeline.\r\n\r\n/cc @TomFinley """
365065710,1096,b'BaseLine Mismatching for various tests when run against Release-Intrinsics',b'The List of the tests that fail are\r\n\r\n- [x] TestCrossValidationMacro\r\n- [x] BinaryClassifierLogisticRegressionBinNormTest\r\n- [x] BinaryClassifierLogisticRegressionGaussianNormTest\r\n- [x] BinaryClassifierLogisticRegressionNonNegativeTest\r\n- [x] BinaryClassifierLogisticRegressionNormTest\r\n- [x] BinaryClassifierTesterThresholdingTest\r\n- [x] BinaryClassifierSymSgdTest\r\n- [x] BinaryClassifierLogisticRegressionTest\r\n- [x] BinaryClassifierPerceptronTest\r\n- [ ] MulticlassLRNonNegativeTest\r\n- [ ] DefaultCalibratorPerceptronTest\r\n- [ ] PAVCalibratorPerceptronTest\r\n- [ ] FastTreeBinaryClassificationCategoricalSplitTest\r\n- [x] LinearClassifierTest\r\n- [x] NoCalibratorLinearSvmTest\r\n- [x] PAVCalibratorLinearSvmTest\r\n- [x] PcaAnomalyTest\r\n- [x] RandomCalibratorPerceptronTest\r\n- [x] RegressorOlsTestOne\r\n- [x] LpGcNormAndWhiteningWorkout\r\n- [x] MultiClassificationLRSaveModelToOnnxTest\r\n- [x] BinaryClassificationLRSaveModelToOnnxTest\r\n- [x] EntryPointLinearPredictorSummary\r\n- [x] EntryPointPcaPredictorSummary\r\n- [x] BinaryClassifierFieldAwareFactorizationMachineTest\r\n- [x] PcaWorkout\r\n- [x] RffWorkout\r\n- [x] SavePipeSsaSpikeNoData // unhandled exception\r\n- [x] ChangePointDetectionWithSeasonality\r\n- [ ] EntryPointPipelineEnsemble\r\nAll of these tests fail because the baseline numbers are different on netcoreapp3.0\r\n\r\ncc @danmosemsft @eerhardt @shauheen @Ivanidzo4ka \r\n'
365060904,1095,b'Deadlock when running TestAutoInference and TestPipelineSweeper in parallel',"b""To reproduce:\r\n\r\nOn an Azure [Standard_DS2_v2](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general) machine (the same that is used in the Hosted VS2017 pool in Azure DevOps), run the `Microsoft.ML.Predictor.Tests` tests in a loop for a while. (it took me 3 runs)\r\n\r\nSometimes the tests will hang indefinitely.\r\n\r\nI was able to attach a debugger when this happens, and there are 2 tests running:\r\n\r\n* TestPipelineSweeper.PipelineSweeperRocketEngine\r\n* TestAutoInference.TestLearnerConstrainingByName\r\n\r\nAnd both tests were in the same callstack:\r\n\r\n```\r\n \tSystem.Private.CoreLib.dll!System.Threading.ManualResetEventSlim.Wait(int millisecondsTimeout, System.Threading.CancellationToken cancellationToken) Line 635\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task.SpinThenBlockingWait(int millisecondsTimeout, System.Threading.CancellationToken cancellationToken) Line 2978\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task.InternalWaitCore(int millisecondsTimeout, System.Threading.CancellationToken cancellationToken) Line 2917\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(System.Threading.Tasks.Task task) Line 146\tC#\r\n \tSystem.Threading.Tasks.Dataflow.dll!System.Threading.Tasks.Dataflow.DataflowBlock.Receive<int>(System.Threading.Tasks.Dataflow.ISourceBlock<int> source, System.TimeSpan timeout, System.Threading.CancellationToken cancellationToken) Line 982\tC#\r\n \tSystem.Threading.Tasks.Dataflow.dll!System.Threading.Tasks.Dataflow.DataflowBlock.Receive<int>(System.Threading.Tasks.Dataflow.ISourceBlock<int> source) Line 888\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.ShuffleTransform.RowCursor.MoveNextCore() Line 649\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Data.RootCursorBase.MoveNext() Line 70\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Training.TrainingCursorBase.MoveNext() Line 492\tC#\r\n \tMicrosoft.ML.StandardLearners.dll!Microsoft.ML.Runtime.Learners.OnlineLinearTrainer<Microsoft.ML.Runtime.Data.BinaryPredictionTransformer<Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>, Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>.TrainCore(Microsoft.ML.Runtime.IChannel ch, Microsoft.ML.Runtime.Data.RoleMappedData data) Line 188\tC#\r\n \tMicrosoft.ML.StandardLearners.dll!Microsoft.ML.Runtime.Learners.OnlineLinearTrainer<Microsoft.ML.Runtime.Data.BinaryPredictionTransformer<Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>, Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>.TrainModelCore(Microsoft.ML.Runtime.TrainContext context) Line 135\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Training.TrainerEstimatorBase<Microsoft.ML.Runtime.Data.BinaryPredictionTransformer<Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>, Microsoft.ML.Runtime.Learners.LinearBinaryPredictor>.Train(Microsoft.ML.Runtime.TrainContext context) Line 89\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.TrainerExtensions.Train<Microsoft.ML.Runtime.IPredictorProducing<float>>(Microsoft.ML.Runtime.ITrainer<Microsoft.ML.Runtime.IPredictorProducing<float>> trainer, Microsoft.ML.Runtime.Data.RoleMappedData trainData) Line 95\tC#\r\n \tMicrosoft.ML.Ensemble.dll!Microsoft.ML.Runtime.Ensemble.EnsembleTrainerBase<float, Microsoft.ML.Runtime.IPredictorProducing<float>, Microsoft.ML.Runtime.Ensemble.Selector.IBinarySubModelSelector, Microsoft.ML.Runtime.Ensemble.OutputCombiners.IBinaryOutputCombiner>.TrainCore.AnonymousMethod__0(Microsoft.ML.Runtime.Ensemble.Subset subset, System.Threading.Tasks.ParallelLoopState state, long index) Line 153\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.Parallel.PartitionerForEachWorker.AnonymousMethod__1(ref System.Collections.IEnumerator partitionState, int timeout, out bool replicationDelegateYieldedBeforeCompletion) Line 3224\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.TaskReplicator.Replica<System.__Canon>.ExecuteAction(out bool yieldedBeforeCompletion) Line 124\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.TaskReplicator.Replica.Execute() Line 80\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.TaskReplicator.Replica..ctor.AnonymousMethod__4_0(object s) Line 40\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state) Line 167\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task.ExecuteWithThreadLocal(ref System.Threading.Tasks.Task currentTaskSlot) Line 2440\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.ThreadPoolTaskScheduler.TryExecuteTaskInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued) Line 75\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.TaskScheduler.TryRunInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued) Line 209\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task.InternalRunSynchronously(System.Threading.Tasks.TaskScheduler scheduler, bool waitForCompletion) Line 1126\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.TaskReplicator.Run<System.Collections.IEnumerator>(System.Threading.Tasks.TaskReplicator.ReplicatableUserAction<System.Collections.IEnumerator> action, System.Threading.Tasks.ParallelOptions options, bool stopOnFirstFailure) Line 138\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.Parallel.PartitionerForEachWorker<Microsoft.ML.Runtime.Ensemble.Subset, object>(System.Collections.Concurrent.Partitioner<Microsoft.ML.Runtime.Ensemble.Subset> source, System.Threading.Tasks.ParallelOptions parallelOptions, System.Action<Microsoft.ML.Runtime.Ensemble.Subset> simpleBody, System.Action<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState> bodyWithState, System.Action<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, long> bodyWithStateAndIndex, System.Func<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, object, object> bodyWithStateAndLocal, System.Func<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, long, object, object> bodyWithEverything, System.Func<object> localInit, System.Action<object> localFinally) Line 3157\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.Parallel.ForEachWorker<Microsoft.ML.Runtime.Ensemble.Subset, object>(System.Collections.Generic.IEnumerable<Microsoft.ML.Runtime.Ensemble.Subset> source, System.Threading.Tasks.ParallelOptions parallelOptions, System.Action<Microsoft.ML.Runtime.Ensemble.Subset> body, System.Action<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState> bodyWithState, System.Action<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, long> bodyWithStateAndIndex, System.Func<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, object, object> bodyWithStateAndLocal, System.Func<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, long, object, object> bodyWithEverything, System.Func<object> localInit, System.Action<object> localFinally) Line 2139\tC#\r\n \tSystem.Threading.Tasks.Parallel.dll!System.Threading.Tasks.Parallel.ForEach<Microsoft.ML.Runtime.Ensemble.Subset>(System.Collections.Generic.IEnumerable<Microsoft.ML.Runtime.Ensemble.Subset> source, System.Threading.Tasks.ParallelOptions parallelOptions, System.Action<Microsoft.ML.Runtime.Ensemble.Subset, System.Threading.Tasks.ParallelLoopState, long> body) Line 1776\tC#\r\n \tMicrosoft.ML.Ensemble.dll!Microsoft.ML.Runtime.Ensemble.EnsembleTrainerBase<float, Microsoft.ML.Runtime.IPredictorProducing<float>, Microsoft.ML.Runtime.Ensemble.Selector.IBinarySubModelSelector, Microsoft.ML.Runtime.Ensemble.OutputCombiners.IBinaryOutputCombiner>.TrainCore(Microsoft.ML.Runtime.IChannel ch, Microsoft.ML.Runtime.Data.RoleMappedData data) Line 143\tC#\r\n \tMicrosoft.ML.Ensemble.dll!Microsoft.ML.Runtime.Ensemble.EnsembleTrainerBase<float, Microsoft.ML.Runtime.IPredictorProducing<float>, Microsoft.ML.Runtime.Ensemble.Selector.IBinarySubModelSelector, Microsoft.ML.Runtime.Ensemble.OutputCombiners.IBinaryOutputCombiner>.Train(Microsoft.ML.Runtime.TrainContext context) Line 111\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Training.TrainerBase<Microsoft.ML.Runtime.IPredictorProducing<float>>.Microsoft.ML.Runtime.ITrainer.Train(Microsoft.ML.Runtime.TrainContext context) Line 31\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.IChannel ch, Microsoft.ML.Runtime.Data.RoleMappedData data, Microsoft.ML.Runtime.ITrainer trainer, Microsoft.ML.Runtime.Data.RoleMappedData validData, Microsoft.ML.Runtime.Internal.Calibration.ICalibratorTrainer calibrator, int maxCalibrationExamples, bool? cacheData, Microsoft.ML.Runtime.IPredictor inputPredictor) Line 259\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.TrainUtils.Train(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.IChannel ch, Microsoft.ML.Runtime.Data.RoleMappedData data, Microsoft.ML.Runtime.ITrainer trainer, Microsoft.ML.Runtime.Internal.Calibration.ICalibratorTrainerFactory calibrator, int maxCalibrationExamples) Line 227\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train<Microsoft.ML.Runtime.Ensemble.EnsembleTrainer.Arguments, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.BinaryClassificationOutput>(Microsoft.ML.Runtime.IHost host, Microsoft.ML.Runtime.Ensemble.EnsembleTrainer.Arguments input, System.Func<Microsoft.ML.Runtime.ITrainer> createTrainer, System.Func<string> getLabel, System.Func<string> getWeight, System.Func<string> getGroup, System.Func<string> getName, System.Func<System.Collections.Generic.IEnumerable<System.Collections.Generic.KeyValuePair<Microsoft.ML.Runtime.Data.RoleMappedSchema.ColumnRole, string>>> getCustom, Microsoft.ML.Runtime.Internal.Calibration.ICalibratorTrainerFactory calibrator, int maxCalibrationExamples) Line 189\tC#\r\n \tMicrosoft.ML.Ensemble.dll!Microsoft.ML.Ensemble.EntryPoints.Ensemble.CreateBinaryEnsemble(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.Ensemble.EnsembleTrainer.Arguments input) Line 24\tC#\r\n \t[Native to Managed Transition]\t\r\n \t[Managed to Native Transition]\t\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run() Line 834\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(Microsoft.ML.Runtime.EntryPoints.EntryPointNode node) Line 1034\tC#\r\n \tMicrosoft.ML.Legacy.dll!Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros() Line 68\tC#\r\n \tMicrosoft.ML.Legacy.dll!Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll() Line 56\tC#\r\n```\r\n\r\nBoth tests were waiting in the `ShuffleTransform.RowCursor.MoveNextCore` function waiting for `_toConsume.Receive();` to return:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a02807c7a805b72ef12970a37279c8cec4ea667d/src/Microsoft.ML.Data/Transforms/ShuffleTransform.cs#L646-L650\r\n\r\nHowever, there were no background threads running that would be producing anything to consume. I'm not sure where they went or why they weren't running.\r\n\r\nI've captured a .dmp file, which is ~200 MB, so I can't link it here. Please contact me if you'd like it and I can get it to you.\r\n\r\n/cc @TomFinley @Zruty0 \r\n"""
365023915,1092,b'MKL binaries should not be included twice in HAL learner and TS packages',"b'Currently, MKL binaries are included in HAL learner and TS packages. We should either create a MKL Package and have both HAL and TS packages reference it but this is known to break SymSGD native code in HAL package. A second option is to split the MKL binary into two and use them separately in HAL learner and TS package.'"
364957957,1090,b'IMuliStreamSource to be a class',"b'I want to be able to call `textReader.Read(""file.txt"")`, instead of having to explicitly create a `MultiFileSource`. \r\n\r\nI think this can be achieved by turning the `IMultiStreamSource` into a base class.'"
364729086,1087,b'Symbolic SGD should support training from initial predictor',"b'In the estimator conversion, the functionality of training with weights taken from a previously trained predictor was lost. It should be restored. This was identified by Tom in his comment: \r\n\r\nhttps://github.com/dotnet/machinelearning/pull/1012/files/f7f666615e8befc0cd8b6925efe0a4c1c5e14101#r220340515'"
364721659,1085,"b""Expand PiGSTy's schema shape type support""","b'PiGSTy\'s (#632) schema propagation system relies on a static type that is currently restricted to be a value-tuple. There is, however, no fundamental reason for it to be value-tuples, or only value-tuples; my motivation was merely just that if we consider the C# syntax for declaring value-tuples vs. anonymous types:\r\n\r\n```csharp\r\nvar x = (a: 1, b: 2);\r\nvar y = new { A = 1, B = 2 };\r\n```\r\n\r\none clearly had more elegant syntax than the other. Yet there are reasons to *also* support classes with `PipelineColumn` properties. (This includes but is not limited to anonymous classes).\r\n\r\n1. Intellisense for value-tuples, especially in the context of generics and especially *especially* in the context of delegates, is currently not the best. [This may be addressed, or it may not.](https://github.com/dotnet/roslyn/issues/29949) At any rate even if addressed we would want our API to have a good experience in older versions of Visual Studio.\r\n\r\n2. My possibly imperfect understanding from @dsyme is that F# can work with anonymous types gracefully, but as far as I am aware cannot yet work with value-tuples at all. Considering that the intersection of F# developers and ML.NET potential users is high at least when compared to the general population of .NET developer, this may be viewed as a priority.\r\n\r\n3. For explicitly defined (i.e., non-anonymous) classes, it allows one to define something like `DataView<MyData>`, which has the advantage of being easily expressable as a return value and a parameter to a function. Could someone write something like `DataView<(Scalar<bool> label, Vector<float> features)>` as a return value or parameter? Yes, absolutely, I suppose, but it\'s not very pretty. Also one thing I learnt to my surprise is that, at least as of C# 7.3, one *cannot* merely do something like `using Foo = (int bar, float biz)`, so even a shorthand based on type aliases even within a single file is not possible.\r\n\r\nCurrently the set of allowed ""schema shape"" types is the following:\r\n\r\n1. Any of the public subclasses of `PipelineColumn`.\r\n2. A value-tuple whose items are of an allowed ""schema shape"" type.\r\n\r\nWhat I am proposing is that we expand this definition to include:\r\n\r\n3. Classes whose only publicly accessible members are properties that are one of the basic abstract subtypes of `PipelineColumn` and a single public constructor in one of the following two subtypes:\r\n\r\n    * The properties are get-only, and the single constructor has parameters where a one-to-one correspondence with each of the properties, where the parameter and property have identical types, and this constructor sets the properties, and no other work.\r\n\r\n    * The properties have get-set accessors, and the single construct has no arguments. (Note that this can be a default constructor.)\r\n\r\n    In each case, whether the property is set via constructor parameter or just by assigning it, the property should always be exactly the object that was either passed in or assigned.\r\n\r\nNote that due to the way the validation code works, and for several practical reasons, it is best and easiest to allow a mix of these types -- that is, just as you can have nested value-tuples, you could have, for example, a value-tuple nested in a class, nested in a value-tuple.\r\n\r\nI am considering the wisdom of allowing fields. On the one hand, we allow fields on the classes for `PredictionEngine`. These of course cannot be the same object (one describes values of a column, whereas one describes the properties of the columns themselves and how they are meant to be configured), but it may be that allowing fields in one but not the other may lead to confusion. Not sure about this. For now I am thinking to only allow properties, and if someone complains we can consider adding it then.\r\n\r\n## Work\r\n\r\nWe might identify five things that should be done. The first three should probably be in one PR. The fourth can happen in a subsequent PR. The fifth is sort of a ""nice to have"" but strictly speaking unnecessary. One of those things to be done in someone\'s copious spare time.\r\n\r\n1. The methods of `StaticPipeInternalUtils` should be expanded to also accommodate the aforementioned types.\r\n\r\n2. The code analyzer that checks the type parameters with `IsShapeAttribute` should be similarly expanded.\r\n\r\n3. In several places throughout the code base the generic type parameter has `Tuple` in its name, e.g., `TTupleShape`, `TTupleInShape`, and so forth. These ought to be changed to things like `TShape` or `TInShape` and the like to make them less specific to tuples.\r\n\r\n4. Part of the reasons why we are doing this is to make the structure work better in F#. F# support for value tuples is limited. This suggests that those so-called ""pigstentions"" where we return a set of columns (e.g., binary classification), where we currently have a value-tuple (e.g., `(Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)`) we may be better served by instead having a definite type, `BinaryClassificationOutput` looking something like this:\r\n\r\n   ```csharp\r\n   public sealed BinaryClassificationOutput\r\n   {\r\n       public Scalar<float> Score { get; }\r\n       public Scalar<float> Probability { get; }\r\n       public Scalar<bool> PredictedLabel { get; }\r\n\r\n       public BinaryClassificationOutput(...) { ... }\r\n   }\r\n   ```\r\n\r\n5. Having a user responsible for defining the types is fairly obnoxious in its own right. So, we might imagine a code action through a Roslyn code-fix provider that can take an `Estimator<T>` where `T` is some sort of inline type (either value-tuple or anonymous class), based on that class defines an explicit type (by default perhaps some `private` nested class), and then uses it to provide `Estimator<T2>` over this new hypothetical type `T2`. This would be relatively easy for the user to call, and then they could modify it as they like. (E.g., make it public, move it somewhere else, add XML docs, and so forth.)'"
364668461,1081,b'TensorFlowTransform & ONNXTransform not displaying in command-line',"b""The `TensorFlowTransform` & `ONNXTransform` are not displayed in the command-line, and don't appear to be accessible.\r\n\r\nListed DataTransforms: (_note the missing `TensorFlowTransform`)_\r\n```bat\r\n$ dotnet bin/AnyCPU.Release/Microsoft.ML.Console/netcoreapp2.0/MML.dll ? kind=DataTransform\r\n\r\nAvailable components for kind 'DataTransform':\r\n  BinNormalizer: Binning Normalizer\r\n    Aliases: Bin\r\n  BootstrapSampleTransform: Bootstrap Sample Transform\r\n    Aliases: BootstrapSample\r\n  CategoricalHashTransform: Categorical Hash Transform\r\n    Aliases: CatHashTransform, CategoricalHash, CatHash\r\n  CategoricalTransform: Categorical Transform\r\n    Aliases: CatTransform, Categorical, Cat\r\n  CharTokenize: Character Tokenizer Transform\r\n    Aliases: CharToken\r\n  ChooseColumnsTransform: Choose Columns Transform\r\n    Aliases: ChooseColumns, Choose\r\n  Concat: Concat Transform\r\n    Aliases: ConcatTransform\r\n  Convert: Convert Transform\r\n    Aliases: ConvertTransform\r\n  CopyColumns: Copy Columns Transform\r\n    Aliases: CopyColumnsTransform, Copy\r\n  CountFeatureSelectionTransform: Count Feature Selection Transform\r\n    Aliases: CountFeatureSelection\r\n  CustomStopWordsRemoverTransform: Custom Stopwords Remover Transform\r\n    Aliases: CustomStopWords\r\n  DropColumns: Drop Columns Transform\r\n    Aliases: DropColumnsTransform, Drop\r\n  DropSlots: Drop Slots Transform\r\n    Aliases: DropSlotsTransform\r\n  Evaluate: Evaluate Predictor\r\n  GcnTransform: Global Contrast Normalization Transform\r\n    Aliases: Gcn\r\n  GenerateNumberTransform: Generate Number Transform\r\n    Aliases: GenerateNumber, Generate\r\n  Group: Group Transform\r\n  HashJoinTransform: Hash Join Transform\r\n    Aliases: HashJoin\r\n  HashTransform: Hash Transform\r\n    Aliases: Hash\r\n  ImageGrayscaleTransform: Image Greyscale Transform\r\n    Aliases: ImageGrayscale\r\n  ImageLoaderTransform: Image Loader Transform\r\n    Aliases: ImageLoader\r\n  ImagePixelExtractorTransform: Image Pixel Extractor Transform\r\n    Aliases: ImagePixelExtractor\r\n  ImageResizerTransform: Image Resizer Transform\r\n    Aliases: ImageResizer\r\n  KeepColumns: Keep Columns Transform\r\n    Aliases: KeepColumnsTransform, Keep\r\n  KeyToBinaryVectorTransform: Key To Binary Vector Transform\r\n    Aliases: KeyToBinary, ToBinaryVector\r\n  KeyToValueTransform: Key To Value Transform\r\n    Aliases: KeyToValue, KeyToVal, Unterm\r\n  KeyToVectorTransform: Key To Vector Transform\r\n    Aliases: KeyToVector, ToVector\r\n  LabelIndicatorTransform: Label Indicator Transform\r\n    Aliases: LabelIndicator\r\n  LdaTransform: Latent Dirichlet Allocation Transform\r\n    Aliases: LightLda\r\n  LearnerFeatureSelectionTransform: Learner Feature Selection Transform\r\n    Aliases: LearnerFeatureSelection\r\n  LoadTransform: Load Transform\r\n    Aliases: Load\r\n  LogMeanVarNormalizer: LogMeanVar Normalizer\r\n    Aliases: LogMeanVar, LogNormalNormalizer, LogNormal\r\n  LpNormNormalizer: Lp-Norm Normalizer\r\n    Aliases: lpnorm\r\n  MeanVarNormalizer: MeanVar Normalizer\r\n    Aliases: MeanVar, ZScoreNormalizer, ZScore, GaussianNormalizer, Gaussian\r\n  MinMaxNormalizer: Min-Max Normalizer\r\n    Aliases: MinMax\r\n  MutualInformationFeatureSelection: Mutual Information Feature Selection Transform\r\n    Aliases: MutualInformationFeatureSelectionTransform, MIFeatureSelection\r\n  NADrop: NA Drop Transform\r\n    Aliases: NADropTransform\r\n  NAFilter: NA Filter\r\n    Aliases: MissingValueFilter, MissingFilter\r\n  NAHandleTransform: NA Handle Transform\r\n    Aliases: NAHandle, NA\r\n  NAIndicatorTransform: NA Indicator Transform\r\n    Aliases: NAIndicator, NAInd\r\n  NAReplaceTransform: NA Replace Transform\r\n    Aliases: NAReplace, NARep\r\n  NgramHashTransform: Ngram Hash Transform\r\n    Aliases: NgramHash\r\n  NgramTransform: Ngram Transform\r\n    Aliases: Ngram\r\n  OptColTransform: Optional Column Transform\r\n    Aliases: optional\r\n  PcaTransform: Principal Component Analysis Transform\r\n    Aliases: Pca\r\n  RangeFilter: Range Filter\r\n  RffTransform: Random Fourier Features Transform\r\n    Aliases: Rff\r\n  Score: Score Predictor\r\n  SentimentAnalyzingTransform: Sentiment Analyzing Transform\r\n    Aliases: SentimentAnalyzer, Senti\r\n  ShuffleTransform: Shuffle Transform\r\n    Aliases: Shuffle, shuf\r\n  SkipFilter: Skip Filter\r\n    Aliases: Skip\r\n  SkipTakeFilter: Skip and Take Filter\r\n    Aliases: SkipTake\r\n  StopWordsRemoverTransform: Stopwords Remover Transform\r\n    Aliases: StopWordsRemover, StopWords\r\n  TakeFilter: Take Filter\r\n    Aliases: Take\r\n  Term: Term Transform\r\n    Aliases: AutoLabel, TermTransform, AutoLabelTransform\r\n  TermLookup: Term Lookup Transform\r\n    Aliases: Lookup, LookupTransform, TermLookupTransform\r\n  TextNormalizerTransform: Text Normalizer Transform\r\n    Aliases: TextNormalizer, TextNorm\r\n  TextTransform: Text Transform\r\n    Aliases: Text\r\n  TrainScore: Train and Score Predictor\r\n  TreeFeat: Tree Ensemble Featurization Transform\r\n    Aliases: TreeFeaturizationTransform\r\n  Ungroup: Un-group Transform\r\n  VectorToImageTransform: Vector To Image Transform\r\n    Aliases: VectorToImage\r\n  WhiteningTransform: Whitening Transform\r\n    Aliases: Whitening\r\n  WordBagTransform: Word Bag Transform\r\n    Aliases: WordBag\r\n  WordEmbeddingsTransform: Word Embeddings Transform\r\n    Aliases: WordEmbeddings\r\n  WordHashBagTransform: Word Hash Bag Transform\r\n    Aliases: WordHashBag\r\n  WordTokenizeTransform: Word Tokenizer Transform\r\n    Aliases: DelimitedTokenizeTransform, WordToken, DelimitedTokenize, Token\r\n```"""
364657267,1078,b' ML.Ensemble assembly is not part of any NuGet',b'ML.NET 0.6\r\n\r\nML.Ensemble is not put into any of ML.NET NuGets'
364573526,1073,b'Tests hang due to MKL loading blocking all threads',"b'We are seeing some tests hanging randomly in CI on Windows.\r\n\r\nI was able to catch a few hangs (~10-15) on my machine as well. Every time the process was hung, it was during loading of MklImports, which was calling `LoadLibraryA(""libittnotify"")`, and then on a different thread MklImports was also on the stack. I am unable to get debugging symbols for MKL, but the two stacks look like this:\r\n\r\nThread 1, calling into MKL from ML.NET:\r\n\r\n```\r\n0:024> kn\r\n # Child-SP          RetAddr           Call Site\r\n00 0000004f`828fb448 00007ffc`2af8c199 ntdll!NtWaitForSingleObject+0x14\r\n01 0000004f`828fb450 00007ffc`2af80e3e ntdll!LdrpDrainWorkQueue+0x15d\r\n02 0000004f`828fb490 00007ffc`2af84387 ntdll!LdrpLoadDllInternal+0xc2\r\n03 0000004f`828fb510 00007ffc`2af8a724 ntdll!LdrpLoadDll+0x10b\r\n04 0000004f`828fb6c0 00007ffc`27352a7b ntdll!LdrLoadDll+0xa4\r\n05 0000004f`828fb7c0 00007ffc`273814f1 KERNELBASE!LoadLibraryExW+0x17b [minkernel\\kernelbase\\module.c @ 1207] \r\n06 0000004f`828fb830 00007ffc`273814a9 KERNELBASE!LoadLibraryExA+0x31 [minkernel\\kernelbase\\module.c @ 1249] \r\n*** ERROR: Symbol file could not be found.  Defaulted to export symbols for MklImports.DLL - \r\n07 0000004f`828fb870 00007ffb`ba4b8854 KERNELBASE!LoadLibraryA+0x39 [minkernel\\kernelbase\\module.c @ 878] \r\n08 0000004f`828fb8a0 00007ffb`ba4b908b MklImports+0x8854\r\n09 0000004f`828fb8e0 00007ffb`ba4c64f1 MklImports+0x908b\r\n0a 0000004f`828fb9b0 00007ffb`ba4be343 MklImports!vslDeleteStream+0x4d91\r\n0b 0000004f`828fbbc0 00007ffb`823903d3 MklImports!cblas_sgemm+0x213\r\n0c 0000004f`828fbc60 00007ffb`8238f446 0x00007ffb`823903d3\r\n0d 0000004f`828fbd80 00007ffb`8238d91a 0x00007ffb`8238f446\r\n0e 0000004f`828fbf90 00007ffb`8238d330 0x00007ffb`8238d91a\r\n0f 0000004f`828fc0a0 00007ffb`8238d0b3 0x00007ffb`8238d330\r\n10 0000004f`828fc160 00007ffb`81e10837 0x00007ffb`8238d0b3\r\n11 0000004f`828fc1e0 00007ffb`81e0f88e 0x00007ffb`81e10837\r\n12 0000004f`828fc250 00007ffb`82389736 0x00007ffb`81e0f88e\r\n13 0000004f`828fc520 00007ffb`e0063ba3 0x00007ffb`82389736\r\n14 0000004f`828fc760 00007ffb`dff4f4fe coreclr!CallDescrWorkerInternal+0x83 [E:\\A\\_work\\164\\s\\src\\vm\\amd64\\CallDescrWorkerAMD64.asm @ 101] \r\n15 0000004f`828fc7a0 00007ffb`dff4f9fb coreclr!CallDescrWorkerReflectionWrapper+0x1a [e:\\a\\_work\\164\\s\\src\\vm\\reflectioninvocation.cpp @ 740] \r\n16 0000004f`828fc7f0 00007ffb`d94ee791 coreclr!RuntimeMethodHandle::InvokeMethod+0x4bb [e:\\a\\_work\\164\\s\\src\\vm\\reflectioninvocation.cpp @ 1355] \r\n17 0000004f`828fce30 00007ffb`816c173b System_Private_CoreLib!System.Reflection.RuntimeMethodInfo.Invoke(System.Object, System.Reflection.BindingFlags, System.Reflection.Binder, System.Object[], System.Globalization.CultureInfo)$##60034D3+0xb1\r\n18 0000004f`828fcea0 00007ffb`816c1000 0x00007ffb`816c173b\r\n19 0000004f`828fcee0 00007ffb`816c012f 0x00007ffb`816c1000\r\n1a 0000004f`828fcf70 00007ffb`816bfdd7 0x00007ffb`816c012f\r\n1b 0000004f`828fcff0 00007ffb`816bf9e4 0x00007ffb`816bfdd7\r\n1c 0000004f`828fd060 00007ffb`816bf4f9 0x00007ffb`816bf9e4\r\n1d 0000004f`828fd0d0 00007ffb`816bf47d 0x00007ffb`816bf4f9\r\n1e 0000004f`828fd140 00007ffb`816bec15 0x00007ffb`816bf47d\r\n1f 0000004f`828fd1b0 00007ffb`816be679 0x00007ffb`816bec15\r\n20 0000004f`828fd210 00007ffb`816be31d 0x00007ffb`816be679\r\n21 0000004f`828fd280 00007ffb`816bde59 0x00007ffb`816be31d\r\n22 0000004f`828fd2e0 00007ffb`816bd01f 0x00007ffb`816bde59\r\n23 0000004f`828fd3d0 00007ffb`816bccfc 0x00007ffb`816bd01f\r\n24 0000004f`828fd450 00007ffb`816ba722 0x00007ffb`816bccfc\r\n25 0000004f`828fd4d0 00007ffb`816ba2af 0x00007ffb`816ba722\r\n26 0000004f`828fd5d0 00007ffb`816ba1b7 0x00007ffb`816ba2af\r\n27 0000004f`828fd650 00007ffb`816b9f18 0x00007ffb`816ba1b7\r\n28 0000004f`828fd6d0 00007ffb`816b9da9 0x00007ffb`816b9f18\r\n29 0000004f`828fd780 00007ffb`816b9d2d 0x00007ffb`816b9da9\r\n2a 0000004f`828fd7f0 00007ffb`816b91f6 0x00007ffb`816b9d2d\r\n2b 0000004f`828fd850 00007ffb`816b8ff9 0x00007ffb`816b91f6\r\n2c 0000004f`828fd8e0 00007ffb`816b8f7d 0x00007ffb`816b8ff9\r\n2d 0000004f`828fd950 00007ffb`816b8cde 0x00007ffb`816b8f7d\r\n2e 0000004f`828fd9c0 00007ffb`816b89bf 0x00007ffb`816b8cde\r\n2f 0000004f`828fda30 00007ffb`816b88a9 0x00007ffb`816b89bf\r\n30 0000004f`828fdab0 00007ffb`816b83d7 0x00007ffb`816b88a9\r\n31 0000004f`828fdb30 00007ffb`816b78ef 0x00007ffb`816b83d7\r\n32 0000004f`828fdc20 00007ffb`816b77e7 0x00007ffb`816b78ef\r\n33 0000004f`828fdca0 00007ffb`816b629f 0x00007ffb`816b77e7\r\n34 0000004f`828fdd20 00007ffb`816b5eff 0x00007ffb`816b629f\r\n35 0000004f`828fdde0 00007ffb`816b5df7 0x00007ffb`816b5eff\r\n36 0000004f`828fde60 00007ffb`816b58b5 0x00007ffb`816b5df7\r\n37 0000004f`828fdee0 00007ffb`816b5518 0x00007ffb`816b58b5\r\n38 0000004f`828fdf60 00007ffb`816b4eef 0x00007ffb`816b5518\r\n39 0000004f`828fdfd0 00007ffb`816b4de7 0x00007ffb`816b4eef\r\n3a 0000004f`828fe050 00007ffb`816b4879 0x00007ffb`816b4de7\r\n3b 0000004f`828fe0d0 00007ffb`816b459f 0x00007ffb`816b4879\r\n3c 0000004f`828fe180 00007ffb`816b4497 0x00007ffb`816b459f\r\n3d 0000004f`828fe200 00007ffb`816b2917 0x00007ffb`816b4497\r\n3e 0000004f`828fe270 00007ffb`816b211f 0x00007ffb`816b2917\r\n3f 0000004f`828fe300 00007ffb`816b2017 0x00007ffb`816b211f\r\n40 0000004f`828fe380 00007ffb`816b0b29 0x00007ffb`816b2017\r\n41 0000004f`828fe410 00007ffb`816b039f 0x00007ffb`816b0b29\r\n42 0000004f`828fe4c0 00007ffb`816b0297 0x00007ffb`816b039f\r\n43 0000004f`828fe540 00007ffb`816afa66 0x00007ffb`816b0297\r\n44 0000004f`828fe5c0 00007ffb`816af6ef 0x00007ffb`816afa66\r\n45 0000004f`828fe650 00007ffb`816af5e7 0x00007ffb`816af6ef\r\n46 0000004f`828fe6d0 00007ffb`816ade30 0x00007ffb`816af5e7\r\n47 0000004f`828fe750 00007ffb`816ad61f 0x00007ffb`816ade30\r\n48 0000004f`828fe800 00007ffb`816ad427 0x00007ffb`816ad61f\r\n49 0000004f`828fe880 00007ffb`816acb85 0x00007ffb`816ad427\r\n4a 0000004f`828fe900 00007ffb`d9549e3c 0x00007ffb`816acb85\r\n4b 0000004f`828fe930 00007ffb`d945cda9 System_Private_CoreLib!System.Threading.Tasks.Task`1[System.__Canon].InnerInvoke()$##600286D+0x4c\r\n4c 0000004f`828fe980 00007ffb`d950f8e7 System_Private_CoreLib!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object)$##60027BC+0x89\r\n4d 0000004f`828fea00 00007ffb`d950f674 System_Private_CoreLib!System.Threading.Tasks.Task.ExecuteWithThreadLocal(System.Threading.Tasks.Task ByRef)$##600294B+0x197\r\n4e 0000004f`828feaa0 00007ffb`d957c4cb System_Private_CoreLib!System.Threading.Tasks.Task.ExecuteEntry()$##6002948+0x84\r\n4f 0000004f`828feae0 00007ffb`816aca97 System_Private_CoreLib!System.Threading.Tasks.SynchronizationContextTaskScheduler+<>c.<.cctor>b__8_0(System.Object)$##6002AB3+0x2b\r\n50 0000004f`828feb10 00007ffb`d945cda9 0x00007ffb`816aca97\r\n51 0000004f`828feb60 00007ffb`816aabe7 System_Private_CoreLib!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object)$##60027BC+0x89\r\n52 0000004f`828febe0 00007ffb`8169bc34 0x00007ffb`816aabe7\r\n53 0000004f`828fec30 00007ffb`d945cda9 0x00007ffb`8169bc34\r\n54 0000004f`828fec80 00007ffb`d950f8e7 System_Private_CoreLib!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object)$##60027BC+0x89\r\n55 0000004f`828fed00 00007ffb`d945cda9 System_Private_CoreLib!System.Threading.Tasks.Task.ExecuteWithThreadLocal(System.Threading.Tasks.Task ByRef)$##600294B+0x197\r\n56 0000004f`828feda0 00007ffb`e0063ba3 System_Private_CoreLib!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object)$##60027BC+0x89\r\n57 0000004f`828fee20 00007ffb`dff29839 coreclr!CallDescrWorkerInternal+0x83 [E:\\A\\_work\\164\\s\\src\\vm\\amd64\\CallDescrWorkerAMD64.asm @ 101] \r\n58 (Inline Function) --------`-------- coreclr!CallDescrWorkerWithHandler+0x53 [e:\\a\\_work\\164\\s\\src\\vm\\callhelpers.cpp @ 78] \r\n59 0000004f`828fee60 00007ffb`e004fe03 coreclr!MethodDescCallSite::CallTargetWorker+0x2b5 [e:\\a\\_work\\164\\s\\src\\vm\\callhelpers.cpp @ 628] \r\n5a (Inline Function) --------`-------- coreclr!StressLog::InlinedStressLogOn+0x5 [e:\\a\\_work\\164\\s\\src\\utilcode\\stresslog.cpp @ 594] \r\n5b (Inline Function) --------`-------- coreclr!StressLog::LogOn+0x5 [e:\\a\\_work\\164\\s\\src\\utilcode\\stresslog.cpp @ 628] \r\n5c 0000004f`828fefb0 00007ffb`dff293d1 coreclr!ThreadNative::KickOffThread_Worker+0x143 [e:\\a\\_work\\164\\s\\src\\vm\\comsynchronizable.cpp @ 260] \r\n5d (Inline Function) --------`-------- coreclr!ManagedThreadBase_DispatchInner+0xf0 [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 8850] \r\n5e 0000004f`828ff120 00007ffb`dff291c3 coreclr!ManagedThreadBase_DispatchMiddle+0x179 [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 8901] \r\n5f 0000004f`828ff250 00007ffb`e005cbb7 coreclr!ManagedThreadBase_DispatchOuter+0xaf [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 9140] \r\n60 0000004f`828ff2f0 00007ffb`dff8c64a coreclr!ManagedThreadBase_FullTransitionWithAD+0x2f [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 9200] \r\n61 (Inline Function) --------`-------- coreclr!ManagedThreadBase::KickOff+0x20 [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 9234] \r\n62 0000004f`828ff350 00007ffb`dff8c516 coreclr!ThreadNative::KickOffThread+0x10a [e:\\a\\_work\\164\\s\\src\\vm\\comsynchronizable.cpp @ 380] \r\n63 0000004f`828ff430 00007ffc`2acd3034 coreclr!Thread::intermediateThreadProc+0x86 [e:\\a\\_work\\164\\s\\src\\vm\\threads.cpp @ 2255] \r\n64 0000004f`828ffdf0 00007ffc`2afc1461 kernel32!BaseThreadInitThunk+0x14\r\n65 0000004f`828ffe20 00000000`00000000 ntdll!RtlUserThreadStart+0x21\r\n```\r\n\r\nThread 2, what looks like a background thread running a `DllMain` (`ntdll!LdrpCallInitRoutine` is what invokes `DllMain`):\r\n\r\n```\r\n0:076> kn\r\n # Child-SP          RetAddr           Call Site\r\n00 0000004f`8487f268 00007ffc`27372f1d ntdll!NtYieldExecution+0x14\r\n01 0000004f`8487f270 00007ffb`ba4b882d KERNELBASE!SwitchToThread+0x1d [minkernel\\kernelbase\\thread.c @ 3327] \r\n02 0000004f`8487f2a0 00007ffb`ba4b69a8 MklImports+0x882d\r\n03 0000004f`8487f2e0 00007ffb`ba4b1132 MklImports+0x69a8\r\n04 0000004f`8487f7c0 00007ffb`be8679d4 MklImports+0x1132\r\n05 0000004f`8487f7f0 00007ffc`2af84053 MklImports!vslDeleteStream+0x43a6274\r\n06 0000004f`8487f850 00007ffc`2af8167f ntdll!LdrpCallInitRoutine+0x6b\r\n07 0000004f`8487f8c0 00007ffc`2afc14ce ntdll!LdrShutdownThread+0x16f\r\n08 0000004f`8487f9c0 00007ffc`2acd303c ntdll!RtlExitUserThread+0x3e\r\n09 0000004f`8487fa00 00007ffc`2afc1461 kernel32!BaseThreadInitThunk+0x1c\r\n0a 0000004f`8487fa30 00000000`00000000 ntdll!RtlUserThreadStart+0x21\r\n```\r\n\r\nNote that Thread 1 is calling `MklImports!cblas_sgemm`, and eventually MklImports is calling `LoadLibraryA`. Printing the variables at `LoadLibraryA`:\r\n\r\n```\r\n0:024> dv\r\n  lpLibFileName = 0x00007ffb`bea0eb2c ""libittnotify.dll""\r\n      StrLength = <value unavailable>\r\n      pszBuffer = 0x00007ffb`bee40148 """"\r\n           hMod = 0x00000000`00000000\r\n```\r\n\r\nThere are other threads running at this point (and some of those threads are spawning new threads as well). I assume there is some race condition happening with MklImports loading while other threads are doing other work.\r\n\r\nTo attempt to fix this, I am loading `MklImports` very early in the tests (in the base test class static initializer, I am calling into MklImports to ensure it is loaded). This appears to fix the issue - I\'ve run the tests 30 times without it hanging on my machine.\r\n\r\nI also have a few .dmp files, if anyone wants to investigate themselves, you can ping me.\r\n\r\n## Repro steps\r\n\r\n1.\tEnsure your Windows machine can build ML.NET - https://github.com/dotnet/machinelearning/blob/master/docs/building/windows-instructions.md\r\n2.\tgit clone https://github.com/dotnet/machinelearning.git\r\n3.\tcd machinelearning\r\n4.\tgit checkout 70b3c3b2ede7321c40aad6ab14de673bc9a962d7\r\n5.\t.\\build.cmd\r\n6.\tcd test\\Microsoft.ML.Tests\r\n7.\t`..\\..\\Tools\\dotnetcli\\dotnet.exe test`\r\na.\tThe tests take a little over a minute. But it doesn\xe2\x80\x99t repro every time, so you need to run it a few times. If the test hangs for over 2 minutes, you know you have a deadlock. Attach a debugger to investigate.\r\n8.\tOr if using powershell:\r\na.\t`for ($i=0; $i -lt 20;$i++) {..\\..\\Tools\\dotnetcli\\dotnet.exe test}`\r\n'"
364560064,1072,b'The new API does not work on .NET Framework < 4.7.1',"b'It relies on the extension method in System.Linq ""Append"" that was added only in 4.7.1.\r\n'"
364557520,1071,b'OnnxTransform: Add entrypoint',b'Estimator and transform are available. \r\n\r\nNeed to make it an entrypoint for use in pytlc'
364334551,1069,b'SDCA (LinearClassificationTrainer) should be called SDCA in the codebase',"b""For historic reasons, `SDCA` is named [`LinearClassificationTrainer`](https://github.com/dotnet/machinelearning/blob/044a6d3cf35a8076ecbbcca5cdb61b2f722f94e1/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs#L1359) in the codebase.\r\n\r\nSDCA (Stochastic Dual Coordinate Ascent), while quite good at many datasets, isn't the final answer for linear classification tasks as implied by the `LinearClassificationTrainer` moniker. For example, [`AveragedPerceptron`](https://github.com/dotnet/machinelearning/blob/b88d3460398c5b95745b476e40dd836f8f788cf6/src/Microsoft.ML.StandardLearners/Standard/Online/AveragedPerceptron.cs) tends to win on NLP tasks (ngrams and/or chargrams). \r\n\r\nNow is a great time to break with history and call SDCA, simply, `SDCA`."""
364264009,1067,b'Update LightGBM nuget so that there is no dependency on GCC',b'Currently lightgbm nuget depends on a binary for openmp that comes from gcc compiler but having to install gcc compiler on build machines causes slowdown. Update the nuget to the newest version that removes this dependency because lightgbm native code is compiled using clang.'
364255963,1065,"b'WeightColumn name defaults to ""Weights"" in one of the constructors of the estimators'","b'Estimators that are instantiated through MAML without specifying a weightcolumn are instead created with default weightcolumn named ""Weights"".\r\n\r\n**More details:**\r\nThe constructor for estimator objects that is used by MAML takes an Arguments object, which has a weight column name that defaults to ""Weights"". To be precise it defaults to an Optional<string> with implicit value of ""Weights"".\r\n\r\nWhen we instantiate the estimator through that constructor, we need to pass a SchemaShape.Column object to the base class TrainerEstimatorBase. This column is in most cases constructed with a method that takes the column name as specified in the Arguments object. As the default value in the Arguments object is not null, it is ""Weights"", this method does not return null, but returns a new SchemaShape.Column named Weights.\r\n\r\n\r\n**The rational:**\r\nThe new API\'s rational is as follows:\r\n1.  the user needs to specify a weight column name, if the name is not null we check the presence of the column\r\n2.  if the user does not define a weight column name (it is null), we assume there is no weight column\r\n\r\nThe old MAML\'s rational:\r\n1.  same as above\r\n2. if the user does not specify a weight column name:\r\n    -  if there is a column named ""Weights"" it will be taken as the weights column automatically\r\n    - if there is no column name ""Weights"", we assume that there is no weight column\r\n\r\n\r\n**What we have to do:**\r\nWe have to fix the current instantiation of estimators through MAML, and decide if we want to continue using a different behavior for the command line and the C# API. '"
364248147,1064,b'File name collision during parallel tests execution.',b'In our routine shared across multiple tests we ask for test name and then create file based on it.\r\nWhere is no limitation on having tests with same name which leads to sporadic crashes on build machines like this:\r\nhttps://dnceng.visualstudio.com/public/_build/results?buildId=24407&view=ms.vss-test-web.test-result-details  '
364243775,1062,b'0.6: Legacy Entry point Transforms.TextFeaturizer not found',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core SDK (reflecting any global.json):\r\n Version:   2.1.401\r\n Commit:    91b1c13032\r\n\r\n### Issue\r\n\r\n- **What did you do?** Ran old sentiment analysis example, updated all using to use legacy namespace\r\n- **What happened?** Legacy Entry point Transforms.TextFeaturizer not found\r\n- **What did you expect?** Expected all entrypoints to work\r\n\r\n### Source code / logs\r\n/* This template shows the building blocks for training a machine learning model with ML.NET (https://aka.ms/mlnet).\r\n * This model predicts whether a sentence has a positive or negative sentiment. It is based on a sample that can be \r\n * found at https://aka.ms/mlnetsentimentanalysis, which provides a more detailed introduction to ML.NET and the scenario.*/\r\n\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Legacy;\r\nusing Microsoft.ML.Legacy.Data;\r\nusing Microsoft.ML.Legacy.Models;\r\nusing Microsoft.ML.Legacy.Trainers;\r\nusing Microsoft.ML.Legacy.Transforms;\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace MLNETConsoleApp2\r\n{\r\n    class Program\r\n    {\r\n        static void Main()\r\n        {\r\n\r\n            //1. Build an ML.NET pipeline for training a sentiment analysis model\r\n            Console.WriteLine(""Training a model for Sentiment Analysis using ML.NET"");\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                // 1a. Load the training data using a TextLoader.\r\n                new TextLoader(@""Data\\wikipedia-detox-250-line-data.tsv"").CreateFrom<SentimentData>(useHeader: true),\r\n\r\n                // 1b. Featurize the text into a numeric vector that can be used by the machine learning algorithm.\r\n                new TextFeaturizer(""Features"", ""SentimentText""),\r\n\r\n                // 1c. Add AveragedPerceptron (a linear learner) to the pipeline.\r\n                new AveragedPerceptronBinaryClassifier() { NumIterations = 10 }\r\n            };\r\n\r\n            // 1d. Get a model by training the pipeline that was built.\r\n            PredictionModel<SentimentData, SentimentPrediction> model = pipeline.Train<SentimentData, SentimentPrediction>();\r\n\r\n            // 2. Evaluate the model to see how well it performs on different data (output the percent of examples classified correctly).\r\n            Console.WriteLine(""Training of model is complete \\nTesting the model with test data"");\r\n            var testData = new TextLoader(@""Data\\wikipedia-detox-250-line-test.tsv"").CreateFrom<SentimentData>(useHeader: true);\r\n            var evaluator = new BinaryClassificationEvaluator();\r\n            BinaryClassificationMetrics metrics = evaluator.Evaluate(model, testData);\r\n            Console.WriteLine($""Accuracy of trained model for test data is: {metrics.Accuracy:P2}"");\r\n\r\n            // 3. Save the model to file so it can be used in another app.\r\n            model.WriteAsync(""sentiment_model.zip"");\r\n\r\n            // 4. Use the model for a single prediction.\r\n            SentimentData testInput = new SentimentData { SentimentText = ""ML.NET is fun, more samples at https://github.com/dotnet/machinelearning-samples"" };\r\n            var sentiment = model.Predict(testInput).Sentiment ? ""Positive"" : ""Negative"";\r\n\r\n            /* This template uses a minimal dataset to build a sentiment analysis model which leads to relatively low accuracy. \r\n             * Building good Machine Learning models require large volumes of data. This template comes with a minimal dataset (Data/wikipedia-detox) for sentiment analysis. \r\n             * In order to build a sentiment analysis model with higher accuracy please follow the walkthrough at https://aka.ms/mlnetsentimentanalysis*/\r\n            Console.WriteLine($""Predicted sentiment for \\""{testInput.SentimentText}\\"" is: {sentiment}"");\r\n        }\r\n\r\n        /// <summary>\r\n        /// Input class that tells ML.NET how to read the dataset (which columns are included)\r\n        /// </summary>\r\n        public class SentimentData\r\n        {\r\n            [Column(ordinal: ""0"", name: ""Label"")]\r\n            public float Sentiment;\r\n            [Column(ordinal: ""1"")]\r\n            public string SentimentText;\r\n        }\r\n\r\n        /// <summary>\r\n        /// Output class for the prediction, in this case including only the predicted sentiment.\r\n        /// </summary>\r\n        public class SentimentPrediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public bool Sentiment;\r\n        }\r\n    }\r\n}\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
364241914,1061,b'Our linear models are unbiased (at least in public)',"b""You can extract weights out of the `MulticlassLogisticRegressionPredictor` now:\r\n\r\n```c#\r\nMulticlassLogisticRegressionPredictor predictor;\r\nVBuffer<float>[] weights = null;\r\npredictor.GetWeights(ref weights, out int numClasses);\r\n```\r\n\r\nThere is no way to extract `_biases` out of the predictor though.  And we should have a way.\r\nThere's an `internal` method that accessed biases, but no `public` method to do so."""
364239221,1060,b'TensorFlowTransform does not work on Scalar column...',b'The following line throws exception when using with scalar columns (non-pigsty case).\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/759ac33ef064c75cb977bfd6e6081186b295c6f5/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L419\r\n\r\n[I will add a concrete example here.]'
364237922,1059,b'Warning messages when using types not supporting missing values as labels',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version**: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.402\r\n Commit:    3599f217f4\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.402\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.4\r\n  Commit:  85255dde3e\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI updated [this tutorial ](https://www.microsoft.com/net/learn/machinelearning-ai/ml-dotnet-get-started-tutorial#install-package) to the new API (see code below), and ran it. \r\n\r\n- **What happened?**\r\nI got the following output and **warning**:\r\n```\r\nAuto-tuning parameters: UseCat = False\r\nAuto-tuning parameters: LearningRate = 0.2\r\nAuto-tuning parameters: NumLeaves = 20\r\nAuto-tuning parameters: MinDataPerLeaf = 5\r\nAuto-tuning parameters: UseSoftmax = False\r\nLightGBM objective=multiclassova\r\nWarning: There is no NA value for type \'I4\'. The missing key value will be mapped to the default value of \'I4\'\r\nWarning: There is no NA value for type \'I4\'. The missing key value will be mapped to the default value of \'I4\'\r\nWarning: There is no NA value for type \'I4\'. The missing key value will be mapped to the default value of \'I4\'\r\nPredicted flower type is: 2\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nI did not expect any warning for using integers as labels. It is a warning from [KeyToValueTransform](https://github.com/dotnet/machinelearning/blob/759ac33ef064c75cb977bfd6e6081186b295c6f5/src/Microsoft.ML.Data/Transforms/KeyToValueTransform.cs#L332). The same warning appears when using string labels instead of integer labels. \r\n\r\nI think the reason for the warning is that KeyToValue might be lossy, since we do not support missing values for integers, and we warn the user every time integer labels are used. We currently map missing values to the default value of int which is 0. If we are using 0 as a label, which is a very reasonable thing to do with int labels, we would be mapping missing labels to an existing label. \r\n\r\nWe don\'t want this warning to be displayed every time, since integer labels are reasonable to have. A possible solution might be **not to warn** the user every time that integer labels are used, but instead **only warn when missing integer labels are mapped to an existing label**.\r\n\r\n\r\n\r\n\r\n\r\n___________________________________________\r\nCode that I ran:\r\n```\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.Runtime.LightGBM;\r\nusing System;\r\n\r\nnamespace myApp\r\n{\r\n    class Program\r\n    {\r\n        // STEP 1: Define your data structures\r\n\r\n        // IrisData is used to provide training data, and as \r\n        // input for prediction operations\r\n        // - First 4 properties are inputs/features used to predict the label\r\n        // - Label is what you are predicting, and is only set when training\r\n        public class IrisData\r\n        {\r\n            [Column(""0"")]\r\n            public float SepalLength;\r\n\r\n            [Column(""1"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""2"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""3"")]\r\n            public float PetalWidth;\r\n\r\n            [Column(""4"")]\r\n            [ColumnName(""Label"")]\r\n            public int Label;\r\n        }\r\n\r\n        // IrisPrediction is the result returned from prediction operations\r\n        public class IrisPrediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public int PredictedLabels;\r\n        }\r\n\r\n        static TextLoader.Arguments GetIrisLoaderArgs()\r\n        {\r\n            return new TextLoader.Arguments()\r\n            {\r\n                Separator = ""comma"",\r\n                HasHeader = true,\r\n                Column = new[]\r\n                {\r\n                    new TextLoader.Column(""SepalLength"", DataKind.R4, 0),\r\n                    new TextLoader.Column(""SepalWidth"", DataKind.R4, 1),\r\n                    new TextLoader.Column(""PetalLength"", DataKind.R4, 2),\r\n                    new TextLoader.Column(""PetalWidth"", DataKind.R4, 3),\r\n                    new TextLoader.Column(""Label"", DataKind.I4, 4)\r\n                }\r\n            };\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            // STEP 2: Create a pipeline and load your data\r\n            //var pipeline = new LearningPipeline();\r\n            var env = new ConsoleEnvironment();\r\n\r\n            // If working in Visual Studio, make sure the \'Copy to Output Directory\' \r\n            // property of iris-data.txt is set to \'Copy always\'\r\n            string dataPath = ""iris-data.txt"";\r\n            var data = new TextLoader(env, GetIrisLoaderArgs()).Read(new MultiFileSource(dataPath));\r\n\r\n            // STEP 3: Transform your data\r\n            // Assign numeric values to text in the ""Label"" column, because only\r\n            // numbers can be processed during model training\r\n            var pipeline = new TermEstimator(env, ""Label"")\r\n                // Puts all features into a vector\r\n                .Append(new ConcatEstimator(env, ""Features"", new string[] { ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth"" }))\r\n                // STEP 4: Add learner\r\n                // Add a learning algorithm to the pipeline. \r\n                // This is a classification scenario (What type of iris is this?)\r\n                .Append(new LightGbmMulticlassTrainer(env, ""Label"", ""Features""))\r\n                // Convert the Label back into original text (after converting to number in step 3)\r\n                .Append(new KeyToValueEstimator(env, ""PredictedLabel""));\r\n\r\n            // STEP 5: Train your model based on the data set\r\n            var model = pipeline.Fit(data);\r\n            var engine = model.MakePredictionFunction<IrisData, IrisPrediction>(env);\r\n\r\n            // STEP 6: Use your model to make a prediction\r\n            // You can change these numbers to test different predictions\r\n            var prediction = engine.Predict(new IrisData()\r\n            {\r\n                SepalLength = 3.3f,\r\n                SepalWidth = 1.6f,\r\n                PetalLength = 0.2f,\r\n                PetalWidth = 5.1f,\r\n            });\r\n\r\n            Console.WriteLine($""Predicted flower type is: {prediction.PredictedLabels}"");\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n}\r\n```'"
364229993,1057,b'Some components do not have descriptions (or useful descriptions) in intellisense',"b'Some components do not have a description when looking at them in intellisense (images below). A few examples: `ToPrincipalComponents`, `ReplaceWithMissingValues`, `FeaturizeText`. \r\n\r\nFor components like `FastTree` and `LightGBM`, the description just says this is an extension method for FastTree/LightGBM. Perhaps this should at least mention that these are decision trees or some other information? SDCA has a more helpful description.\r\n\r\nExplanation:\r\n![image](https://user-images.githubusercontent.com/2601900/46111518-22efcd00-c19c-11e8-9b2e-3f6400b5da3e.png)\r\n\r\nNo explanation:\r\n![image](https://user-images.githubusercontent.com/2601900/46111536-3864f700-c19c-11e8-8852-63a9c5fb2686.png)\r\n'"
364227739,1056,b'ReplaceWithMissingValues is a confusing name for handling missing values',"b'The `ReplaceWithMissingValues` transform handles missing values in the data, but the name makes it sound like the transform will replace my data with missing values.'"
364225330,1055,"b""can't instantiate loadable class IDataView with name - warning on using transforms""","b""Running the [Tensorflow sample]\r\n(https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/examples/DeepLearning_TensorFlowMLNETInceptionv3ModelScoring) prints a bunch of warnings on the transforms it uses. \r\n\r\nThey are discouraging to sample users :) \r\n\r\nList of warnings for that sample:\r\nCacheClassesFromAssembly: can't instantiate loadable class IDataView with name KeyToVectorTransform\r\nCacheClassesFromAssembly: can't instantiate loadable class IDataView with name TermTransform\r\nCacheClassesFromAssembly: can't map name ToVector to IDataTransform, already mapped to IDataTransform\r\nCacheClassesFromAssembly: can't instantiate loadable class IDataView with name KeyToBinaryTransform"""
364215147,1054,b'The Trainers list for any training context is empty',b'nuget: 0.6.0-preview-26926-9\r\n\r\nImport the NuGet package. \r\nInstantiate any training context. \r\nCtrl+Space after context.Trainers \r\n\r\nBug: notice that the list of trainers is empty. \r\n\r\n  var ctx = new Microsoft.ML.RegressionContext(env).Trainers.  <= no trainers display. \r\n'
364214338,1053,"b'OnnxTransform: Let user pick the output column name from the transform, instead using the same name as the one the model has.'",b''
364213459,1052,b'FieldAwareFactorizationMachine should be able to take single float vector features',"b'ML.NET NuGet version: 0.6.0-preview-26925-3\r\n\r\nFFM today requires the features to be passed in as a Vector<float>[]. (I believe this is to enable interaction between the fields, right?)\r\n\r\nSince it is possible to include just a single Vector<float> as a feature, should there be an overload to enable that? \r\n'"
364212525,1051,"b'OnnxTransform: Make Create() method public, for use via Nuget package'","b'We need this method to be public, instead of private:\r\nIDataView trans = OnnxTransform.Create(env, pixels, model_location, ""Output"", ""Input"" });'"
364212010,1050,b'OnnxTransform: Change namespace to Microsoft.ML.Transforms (currently Microsoft.ML.OnnxScoring)',b''
364210602,1049,b'Assembly fails to load when running a pipeline from console app',"b'dotnet MML.dll train data=""E:\\dataset\\day_0_sample.txt"" loader=TextLoader{col=Label:R4:0 col=NumFeatures:R4:1-13 col=LowCardCat:TX:19,22,30,33 col=HighCardCat:TX:~} xf=CategoricalTransform{col=LowCardCat} xf=CategoricalHashTransform{col=HighCardCat bits=16} xf=MissingValueIndicatorTransform{col=NumFeatures} xf=Concat{ col=Features:NumFeatures,LowCardCat,HighCardCat } cache- tr=ap{iter=10} out=e:\\data\\model.zip\r\n\r\nCould not load assembly E:\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Console\\netcoreapp2.1\\CpuMathNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in E:\\machinelearning\\src\\Common\\AssemblyLoadingUtils.cs:line 207\r\nCould not load assembly E:\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Console\\netcoreapp2.1\\FactorizationMachineNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in E:\\machinelearning\\src\\Common\\AssemblyLoadingUtils.cs:line 207\r\nSkipping assembly \'E:\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Console\\netcoreapp2.1\\FastTreeNative.dll\' because its name was filtered.\r\nCould not load assembly E:\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Console\\netcoreapp2.1\\LdaNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in E:\\machinelearning\\src\\Common\\AssemblyLoadingUtils.cs:line 207\r\n\r\nI see these errors but I can still run the pipeline.\r\n\r\nCC: @eerhardt '"
364208272,1048,"b""Text featurizer Pigstension has auxiliary outputs, but they're not returned anywhere""","b""One thing I noticed about the `FeaturizeText` pigstension specified here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/759ac33ef064c75cb977bfd6e6081186b295c6f5/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L711\r\n\r\nI was attempting to translate the following pipeline. Perhaps not everything is there yet, which is fine, but that I could not just directly address `LDAText_TransformedText` without going *out* of pigsty, then redeclaring the entire schema just to get the column that was missed is not good. Another method with more return values to cover this case would probably be the most helpful thing we could do.\r\n\r\n```\r\nloader=TextLoader{quote=- col=IncidentId:TX:0 col=Title:TX:1 col=Status:TX:2 col=Severity:TX:3 col=SourceName:TX:5\r\ncol=SourceCreatedBy:TX:6 col=SiloId:TX:7 col=OriginatingTenantId:TX:8 col=OwningTenantName:TX:9 col=OwningTenantId:TX:10 col=OwningTeamName:TX:11\r\ncol=OwningTeamId:TX:12 col=FirstOwningTeamId:TX:13 col=SecondOwningTeamId:TX:14 col=ThirdOwningTeamId:TX:15 col=ResponsibleTenantId:TX:16\r\ncol=IncidentType:TX:17 col=ImpactStartDate:TX:18 col=CustomerName:TX:19 col=ImpactedScenarios:TX:20 col=IsCustomerImpacting:TX:21 col=Keywords:TX:22\r\ncol=OccurringDatacenter:TX:23 col=OccurringDeviceGroup:TX:24 col=OccurringDeviceName:TX:25 col=OccurringServiceInstanceId:TX:26\r\ncol=RaisingDatacenter:TX:27 col=RaisingDeviceGroup:TX:28 col=RaisingDeviceName:TX:29 col=RaisingServiceInstanceId:TX:30 col=Description:TX:31 header=+}\r\n\r\ndata=\\\\vivekserver\\G$\\AIRTrainigData\\Portal\\2018-08-06\\IncidentData_0.tsv\r\n\r\nxf=Convert{col=OwningTeamId col=Severity col=OwningTenantId type=R4}\r\n\r\nxf=CopyColumns{col=Label:OwningTeamId}\r\n\r\nxf=CopyColumns{col=LabelTenant:OwningTenantId}\r\n\r\nxf=Term{col=Label}\r\n\r\nxf=Term{col=LabelTenant}\r\n\r\nxf=CopyColumns{col=text:Description}\r\n\r\nxf=TextTransform{col=LDAText:Description remover=PredefinedStopWordsRemover punc=- num=- tokens=+ wordExtractor={} charExtractor={} norm=None}\r\n\r\nxf=NltLemmatizerTransform{col=LDAText:LDAText_TransformedText}\r\n\r\nxf=WordEmbeddingsTransform{col=FeatureWordEmbedding:LDAText_TransformedText model=FastTextWikipedia300D}\r\n\r\nxf=NltKeyPhraseExtractorTransform{src=Title dst=KeyPhrasesTitle thres=5 idf=+ lemma=+}\r\n\r\nxf=NltKeyPhraseExtractorTransform{src=text dst=KeyPhrases thres=5 idf=+ lemma=+}\r\n\r\nxf=Concat{col=text:CustomerName,ImpactedScenarios,Keywords,KeyPhrasesTitle,Title}\r\n\r\nxf=TextTransform{col=FeaturesText1:text  remover=PredefinedStopWordsRemover  norm=L1  wordExtractor={} charExtractor=NGramHashExtractorTransform{ngram=7 bits=15 all=+ skips=0}}\r\n\r\nxf=Concat{col=text:Description,KeyPhrases}\r\n\r\nxf=TextTransform{col=FeaturesText2:text   norm=L2  wordExtractor=NGramExtractorTransform{ngram=2 weighting=Idf all=+ skips=1} charExtractor={}}\r\n\r\nxf=Concat{col=Features:FeaturesText1,FeaturesText2,FeatureWordEmbedding}\r\n\r\nxf=CopyColumns{col=FeaturesTenant:Features} xf=CountFeatureSelectionTransform{col=FeaturesTenant c=10}\r\n\r\nxf=TrainScore{tr=SDCAMC feat=FeaturesTenant lab=LabelTenant} xf=MutualInformationFeatureSelection{col=Features topk=50000} xf=Concat{col=Features:Features,Score}\r\n```\r\n\r\nSecondary note while we're at it, it looks like there's no actually usage of `usedNames` in the reconciler to avoid name collisions, which is sort of a nasty bug just waiting to happen."""
364207232,1047,b'Label column is required again in static pipe',"b'We didn\'t add any provision to make certain estimators \'train-only\'.\r\n\r\nCompare the following:\r\n```c#\r\nvar pipeline = new ConcatEstimator(env, ""Features"", ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth"")\r\n    .Append(new TermEstimator(env, ""Label""), TransformerScope.TrainTest)\r\n    .Append(new SdcaMultiClassTrainer(env, new SdcaMultiClassTrainer.Arguments { MaxIterations = 100, Shuffle = true, NumThreads = 1 }, ""Features"", ""Label""))\r\n    .Append(new KeyToValueEstimator(env, ""PredictedLabel""));\r\n\r\nvar model = pipeline.Fit(data).GetModelFor(TransformerScope.Scoring); // <-- that\'s how we can clean up the pipeline\r\nvar engine = model.MakePredictionFunction<IrisDataNoLabel, IrisPrediction>(env);\r\n```\r\nAnd here is the static one:\r\n```c#\r\nvar learningPipeline = reader.MakeNewEstimator()\r\n    .Append(r => (\r\n        r.Label,\r\n        Features: r.SepalLength.ConcatWith(r.SepalWidth, r.PetalLength, r.PetalWidth)))\r\n    .Append(r => (\r\n        r.Label,\r\n        Predictions: classification.Trainers.Sdca(r.Label.ToKey(), r.Features)))\r\n    .Append(r => r.Predictions.predictedLabel.ToValue());\r\n```\r\nCan we keep the concise pipeline description, yet allow for something like \'GetModelForScoring\' in some way?\r\n\r\n/cc @TomFinley  @markusweimer '"
364201441,1046,b'Finish the sentence on documentation ',b'Update https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoaderStatic.cs#L18 to complete the description of the TTupleShape param. '
364196882,1045,b'Creating both environment and context is annoying',"b""This is what I have to write in the docs all the time:\r\n```c#\r\n// Create a new environment for ML.NET operations. It can be used for exception tracking and logging, \r\n// as well as the source of randomness.\r\nvar env = new LocalEnvironment();\r\n\r\n// We know that this is a classification task, so we create a multiclass classification context: it will give us the algorithms\r\n// we need, as well as the evaluation procedure.\r\nvar classification = new MulticlassClassificationContext(env);\r\n```\r\n\r\nCan we make context create the environment if they aren't provided one? And also expose it as a property?\r\n\r\n/cc @TomFinley """
364194444,1044,"b""ReplaceWithMissingValues and ToPrincipalComponents doesn't have summary comments, so it's unclear what it does.""",b''
364191117,1043,b'ConcatWith and AsVector need to be more restrictive regarding types they can be applicable.',"b""```\r\nvar pipe = data.MakeNewEstimator().Append(row => (label: row.label.ToKey(), features: row.image.LoadAsImage()));\r\n```\r\nI'm loading images. As soon as I hit dot after LoadAsImage I get suggestions to Resize and  AsGreyscale \r\nwhich make sense. But I also got suggestion from intellisence to apply AsVector and ConcatWith. Which doesn't make much sense for me."""
364190624,1042,b'Legacy pipeline API needs to be loaded after subcomponent changes',"b'Running legacy API against the new 0.6 nugets will cause ""System.InvalidOperationException has been thrown"". ""Entry point \'...\' not found"".\r\n\r\nThe entry points don\'t seem to be loaded for the pipeline and workaround is to manually load them, but the issue needs to be fixed.\r\n\r\nI created a new project and added the 0.6 nugets then tried something like this:\r\n\r\n```C#\r\n\r\nusing Microsoft.ML.Legacy.Models;\r\nusing Microsoft.ML.Legacy.Trainers;\r\nusing Microsoft.ML.Legacy.Transforms;\r\nusing Microsoft.ML.Legacy.Data;\r\nusing Microsoft.ML.Legacy;\r\nusing System;\r\nusing Microsoft.ML.Runtime.Api;\r\n         \r\nvar pipeline = new LearningPipeline();\r\n\r\n            //var n = new Microsoft.ML.Runtime.Data.CategoricalEstimator.ColumnInfo(""foo"", """");\r\n           //new Microsoft.ML.Runtime.Learners.SdcaMultiClassTrainer.Arguments();\r\n\r\n\t\t\tpipeline.Add(new TextLoader(dataPath).CreateFrom<HousePriceData>(useHeader: true, separator: \',\'));\r\n\r\n            pipeline.Add(new ColumnConcatenator(outputColumn: ""NumericalFeatures"", \r\n...\r\n\t\t\t                                    ""SqftLot15""));\r\n\r\n            pipeline.Add(new ColumnConcatenator(outputColumn: ""CategoryFeatures"",\r\n...\r\n\t\t\t                                    ""Zipcode""));\r\n\r\n            pipeline.Add(new CategoricalOneHotVectorizer(""CategoryFeatures""));\r\n            pipeline.Add(new ColumnConcatenator(outputColumn: ""Features"",\r\n                ""NumericalFeatures"", ""CategoryFeatures""));\r\n            pipeline.Add(new StochasticDualCoordinateAscentRegressor());\r\n\r\n            PredictionModel<HousePriceData, HousePricePrediction> model = pipeline.Train<HousePriceData, HousePricePrediction>();\r\n\r\n```\r\n\r\nnote the two commented new lines.\r\n@eerhardt , @Zruty0 '"
364184340,1041,"b""Why I can't just pass file name to DataReader.Read method?""","b'```\r\nConsoleEnvironment env = new ConsoleEnvironment();\r\nvar reader = TextLoader.CreateReader(env, row => (label: row.LoadText(0), image: row.LoadText(1));\r\nvar data = reader.Read(""file.csv"");\r\n```\r\nwill force me to cast file name to MultifileSource. Can I just pass filename if I have only one file?'"
364184089,1040,b'Simple example for getting input and output nodes of TF graph',"b""#862 enabled extracting information about nodes in a TF model. However, it's not completely clear how to extract the most important information for using the model with the TF Transform: what are the input and output nodes? \r\n\r\nThe [`DnnAnalyzer`](https://github.com/dotnet/machinelearning/blob/a627d5b02d14ff21c1a31a94b1904261211431f6/src/Microsoft.ML.DnnAnalyzer/Microsoft.ML.DnnAnalyzer/DnnAnalyzer.cs) shows how to view all the nodes, but this can be improved to identify which are the input and output nodes (based on the other links) to make this easier.\r\n\r\nProposal: either modify `DnnAnalyzer` to identify the input and output nodes, or provide a separate sample that does this.\r\n\r\n\r\n"""
364179470,1039,b'TensorFlowScorer has duplicate parameter Model',"b'ML.NET version 0.6.0\r\n\r\n\r\nSee [manifest.json](https://github.com/dotnet/machinelearning/blob/master/test/BaselineOutput/Common/EntryPoints/core_manifest.json) \r\n\r\nOne Model is Input param, another Model is output param. This causes issues in auto code generators that automatically create method signatures based on manifest. Pls use model_location for input param\r\n\r\n\r\n'"
364173477,1038,b'Tensorflow documentation issues',"b'https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.TensorFlow/doc.xml\r\n\r\nA) Look in example: ```var pipeline = new LearningPipeline(seed: 1);``` LearningPiepline actually don\'t have seed parameter\r\n\r\nB) ```OutputColumns = ""Output""``` OutputColumns is actually array, so you can\'t pass just string to it.\r\n\r\nC) ```This transform requires the <a href=""https://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML.TensorFlow/0.5.0-preview-26830-5"">Microsoft.ML.TensorFlow</a> nuget to be installed.```\r\nI\'m not sure we should include links to preview nuget package\r\n\r\nD)  ```The transform currently accepts the <a href=""https://www.tensorflow.org/mobile/prepare_models"">frozen TensorFlow model</a> file as input.```\r\nI think we support frozen and non frozen models.\r\n'"
364137529,1034,b'Error Message Returned by Command Line Tool (Fail to Load Native Assembly)',"b""Btw, running the following command `dotnet bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\MML.dll showdata data=machinelearning\\x1 loader=text{sep=space col=C0:TX:0-2} xf=term{col=C0}`, I got three error messages (shown below) about failing to load assembly.\r\n\r\nCould not load assembly D:\\Repos\\machinelearning1\\bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\CpuMathNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in D:\\Repos\\machinelearning1\\src\\Common\\AssemblyLoadingUtils.cs:line 207\r\nCould not load assembly D:\\Repos\\machinelearning1\\bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\FactorizationMachineNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in D:\\Repos\\machinelearning1\\src\\Common\\AssemblyLoadingUtils.cs:line 207\r\nSkipping assembly 'D:\\Repos\\machinelearning1\\bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\FastTreeNative.dll' because its name was filtered.\r\nCould not load assembly D:\\Repos\\machinelearning1\\bin\\AnyCPU.Debug\\Microsoft.ML.Console\\netcoreapp2.0\\LdaNative.dll:\r\nSystem.BadImageFormatException: Bad IL format.\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromPath(IntPtr ptrNativeAssemblyLoadContext, String ilPath, String niPath, ObjectHandleOnStack retAssembly)\r\n   at System.Runtime.Loader.AssemblyLoadContext.LoadFromAssemblyPath(String assemblyPath)\r\n   at System.Reflection.Assembly.LoadFrom(String assemblyFile)\r\n   at Microsoft.ML.Runtime.AssemblyLoadingUtils.LoadAssembly(IHostEnvironment env, String path) in D:\\Repos\\machinelearning1\\src\\Common\\AssemblyLoadingUtils.cs:line 207"""
363779757,1031,b'Need to be able to hash most column types',"b""Previously, we relied on HashJoin transform to hash all kinds of column types, and this was our story for 'stratification column' functionality: any stratification column is first hashed, then it's a legal input to `RangeFilter`.\r\n\r\nI feel that we shouldn't have *two* hashing operations, but instead we should have *one*, call it 'hashing', and make it capable of computing a hash of\r\n- any primitive type\r\n- any key type (that's currently the case)\r\n- any vector of the above."""
363742275,1027,b'Microsoft.ML.TensorFlow is currently broken',"b""### System information\r\n\r\n- **OS version/distro**: all\r\n- **.NET Version (eg., dotnet --info)**:  any\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate a .NET Core console project that references the latest version of `Microsoft.ML.TensorFlow`.\r\n- **What happened?**\r\nI don't get a reference to the `Microsoft.ML.TensorFlow.dll`. I only get a reference to `DnnAnalyzer.dll`\r\n![image](https://user-images.githubusercontent.com/8291187/46039356-1f444380-c0d3-11e8-8e69-3e1ade0a9dc8.png)\r\n\r\n- **What did you expect?**\r\nI expected to get a reference to `Microsoft.ML.TensorFlow.dll` so I could call methods in it.\r\n\r\n### Notes\r\n\r\nThe reason this happens is because we are including the `DnnAnalyzer.dll` in the `lib\\netcoreapp2.0` directory of the `Microsoft.ML.TensorFlow` nuget package:\r\n\r\n![image](https://user-images.githubusercontent.com/8291187/46039442-5dd9fe00-c0d3-11e8-965d-da3080f91a41.png)\r\n\r\n\r\nNuGet only picks assets from 1 of these folders. And since my app is .NET Core, it only picks the assemblies from the `lib\\netcoreapp2.0` directory.\r\n\r\n/cc @ericstj @yaeldekel @abgoswam \r\n"""
363714030,1026,b'Rolling Cross-validation for Time-series',"b'To properly handle time-series (and time-dependent data in general), we should implement a Rolling Cross-validation to add to our existing CV & TrainTest modes.\r\n\r\nWe are currently merging various time-series functionality from the internal repo to this repo via https://github.com/dotnet/machinelearning/pull/977 _""Port Time Series""_. This PR does not include a rolling cross-validation, used heavily in time-series tasks.\r\n\r\nRolling CV is better for time dependent datasets by always testing on data which is _newer_ than the training data. Standard CV leaks future data in to the training set. Other names of Rolling CV include { walk-forward / roll-forward / rolling origin / window } CV.\r\n\r\nBackground on method:\r\nhttp://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\r\nhttps://otexts.org/fpp2/accuracy.html#time-series-cross-validation\r\nhttps://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection\r\nhttps://robjhyndman.com/hyndsight/tscv/\r\nhttps://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/46602\r\nhttps://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\r\n\r\n\r\nTo further investigate missing time-series components, the [Azure ML Forecasting Toolkit](https://docs.microsoft.com/en-us/python/api/azuremlftk/) is a good package listing components needed for this task:  \r\n* Metrics: [MAPE, MASE_single_grain, SMAPE](https://docs.microsoft.com/en-us/python/api/azuremlftk/ftk.metrics.metrics?view=azure-forecasting-py)\r\n* Models: [ARIMA, etc](https://docs.microsoft.com/en-us/python/api/azuremlftk/ftk.models?view=azure-forecasting-py)\r\n* etc\r\n\r\n'"
363699164,1023,b'TrainUtils.Train does not have consistent API usage for the calibrator argument',"b'### Issue\r\nTrainUtils.Train has two different API signatures, in one case the calibrator is an IComponentFactory<ICablibratorTrainer> where in the other case it is an ICalibratorTrainerFactory. \r\n\r\nThis should be consistent with the ICalibratorTrainerFactory becoming IComponentFactory<ICalibratorTrainer>.\r\n\r\n\r\n### Source code / logs\r\n        public static IPredictor Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData,\r\n            IComponentFactory<ICalibratorTrainer> calibrator, int maxCalibrationExamples, bool? cacheData, IPredictor inputPredictor = null)\r\n\r\n        public static IPredictor Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer,\r\n            ICalibratorTrainerFactory calibrator, int maxCalibrationExamples)\r\n\r\n'"
363406101,1019,b'Backslash encoded in filenames for model zip',"b""### System information\r\n\r\n- **OS version/distro**: OSX 10.12\r\n\r\nWhen storing the created models in a zip file, we are adding slashes to the filename instead of actual folders. This leads to the **cross-platform oddity** where on OSX (and likely linux) the folder structure isn't created when unzipping a model.\r\n\r\nOn OSX, the entire model unzips to a single monolithic folder: _(note slashes in the actual filename)_\r\n![unzipped_model_on_osx](https://user-images.githubusercontent.com/4080826/45992299-e312d380-c03d-11e8-999d-fb0b87f6f0f4.png)\r\n\r\nUnder Win10, the model unzips to a folder structure: _(see left side of image)_\r\n> ![win10_model_unzip](https://user-images.githubusercontent.com/4080826/45992550-523cf780-c03f-11e8-869c-181fa8e80f03.png)\r\n\r\nModel shown is from: https://github.com/dotnet/machinelearning/blob/a22c4e63cf269eccd19dbb97492346ca3da34db3/test/data/sentiment_model.zip\r\n\r\nFrom quick searching, it looks like the slash is added here:\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Data/Model/Repository.cs#L223-L229\r\n\r\nWe should look if this is actually necessary, as this is the first I've run into encoding slashes directly in to a filename in a zip file."""
363399388,1018,b'substitute AlignedArray with a regular array',b'This issue tracks the progress with removing the aligned array.\r\n\r\nThe aligned array wont make much difference here as we do a lot of move operation.\r\n\r\n\r\nMore Discussion https://github.com/dotnet/machinelearning/pull/383\r\n\r\nRough Implementation :- https://github.com/Anipik/machinelearning/tree/temp\r\n\r\n\r\nThis branch removes all the aligned array code from src as well as implementation. All the tests are passing\r\nWill update the issue with performance numbers soon\r\n\r\ncc @danmosemsft @tannergooding @TomFinley @eerhardt '
363365800,1015,b'Cannot get parameters for transforms?',"b'### System information\r\n\r\n- **OS version/distro**: Win 10 / ML.NET 0.5.0\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nCreated an affine transform, e.g.,\r\n```\r\nNormalizeTransform.Create(environment, new NormalizeTransform.MeanVarArguments { Column = normalizeTransformColumns.ToArray(), UseCdf = true }, data);\r\n```\r\n\r\n- **What happened?**\r\n\r\nThe scale and offset of the actual transform created cannot be retrieved (or can only be retrieved via reflection).\r\n\r\n- **What did you expect?**\r\n\r\nA way to retrieve parameters of transforms.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
363362558,1013,b'PredictionEngine benchmark test',b'Add benchmark test to measure performance of single predictions made by PredictionEngine.\r\n\r\n'
363354830,1011,b'How to build for netcoreapp3.0',"b""We should document how to build to run on .NET Core 3.0 (so as to use the .NET hardware intrinsics)\r\n\r\nI tried various ideas such as `build -- /p:targetframework=netcoreapp3.0` but didn't succeed yet.\r\n\r\n@eerhardt  ? """
363351849,1010,"b""Another Update in KeyToVector's ONNX exporter""","b'The key range should starts with zero. The following change fixes this bug with the latest runtime.\r\n-`node.AddAttribute(""cats_int64s"", Enumerable.Range(1, info.TypeSrc.ItemType.KeyCount).Select(x => (long)x));`\r\n+`node.AddAttribute(""cats_int64s"", Enumerable.Range(0, info.TypeSrc.ItemType.KeyCount).Select(x => (long)x));`'"
363330400,1006,b'LinearPredictor.Statistics is always null',"b""### System information\r\n\r\n- **OS version/distro**: Win 10 / ML.NET 0.5.0\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI train a model using logistic regression:\r\n```\r\nvar trainer = new LogisticRegression(\r\n                        environment,\r\n                        new LogisticRegression.Arguments() { ShowTrainingStats = true });\r\nvar trainRoles = ...\r\nvar predictor.Train(trainRoles)\r\n```\r\n\r\n- **What happened?**\r\n`predictor.Statistics` is null\r\n\r\n- **What did you expect?**\r\nTo be able to retrieve model statistics\r\n\r\n\r\n### Source code / logs\r\n\r\n`LogisticRegression.CreatePredictor` does not pass its `_stats` `LinearModelingStatistics` field when it creates a `LinearBinaryPredictor`: https://github.com/dotnet/machinelearning/blob/1e7b8be855210f2bd8adbd532396a1840a20541d/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/LogisticRegression.cs#L327.\r\n\r\nIf I do change that, then `predictor.Statistics.GetCoefficientStatistics` still returns null. It appears that you calculate the inverted Hessian, but then do not use it to calculate standard errors (and pass these in the constructor of `LinearModelStatistics'): https://github.com/dotnet/machinelearning/blob/1e7b8be855210f2bd8adbd532396a1840a20541d/src/Microsoft.ML.StandardLearners/Standard/LogisticRegression/LogisticRegression.cs#L189.\r\n\r\n"""
363316124,1004,b'Consistency issue with LdaTransform',"b'Despite setting the `seed` in the ML.Net environment, LdaTransform does not produce consistent result which is a hurdle to writing a end-to-end functional test.\r\n\r\nResults are consistent when setting `ResetRandomGenerator=true` in LdaTransform on single box. However, on build server test is failing.\r\n\r\nPlease see the following test for more detail.\r\nhttps://github.com/dotnet/machinelearning/blob/5874e16fd652d93630e0622a756f1b913ca8ea55/test/Microsoft.ML.Tests/Transformers/TextFeaturizerTests.cs#L239\r\n '"
363309590,1003,b'ML.Net needs to publish nuget information to the dotnet versions repo post build',"b'### Issue\r\nML.Net needs to use the dotnet/versions repo to post the latest nuget information when a build is complete. This follows a common pattern for dotnet projects that allows users to subscribe for new changes, triggering a build of their own.'"
363274673,1000,b'CDN Compression Needs to be Enabled',"b'Enable CDN content compression. Content sourced from our CDN arrives without gzip/deflate/brotli compression enabled. \r\n\r\nLarger content from our CDN (like the 6GB fastText word embedding) takes too long to download, and can hit the [10min timeout](https://github.com/dotnet/machinelearning/blob/1e7b8be855210f2bd8adbd532396a1840a20541d/src/Microsoft.ML.Transforms/Text/WordEmbeddingsTransform.cs#L149) before finishing. \r\n\r\nOur CDN content lacks the `Content-Encoding: ...` header:\r\n```bash\r\n$ curl -L -I --compress https://aka.ms/tlc-resources/WordVectors/wiki.en.vec\r\nHTTP/1.1 301 Moved Permanently\r\nContent-Length: 0\r\nLocation: https://express-tlcresources.azureedge.net/wordvectors/wiki.en.vec\r\nServer: Kestrel\r\nRequest-Context: appId=cid-v1:26ef1154-5995-4d24-ad78-ef0b04f11587\r\nX-Powered-By: ASP.NET\r\nExpires: Mon, 24 Sep 2018 18:39:45 GMT\r\nCache-Control: max-age=0, no-cache, no-store\r\nPragma: no-cache\r\nDate: Mon, 24 Sep 2018 18:39:45 GMT\r\nConnection: keep-alive\r\nStrict-Transport-Security: max-age=31536000 ; includeSubDomains\r\n\r\nHTTP/1.1 200 OK\r\nCache-Control: no-cache\r\nContent-Type: application/octet-stream\r\nDate: Mon, 24 Sep 2018 18:39:44 GMT\r\nEtag: 0x8D5AEF4AA45D753\r\nExpires: Mon, 24 Sep 2018 18:39:44 GMT\r\nLast-Modified: Mon, 30 Apr 2018 23:46:59 GMT\r\nServer: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\r\nx-ms-blob-type: BlockBlob\r\nx-ms-lease-status: unlocked\r\nx-ms-request-id: ef682e2a-b01e-0113-2235-5442d7000000\r\nx-ms-version: 2009-09-19\r\nContent-Length: 6597238061\r\n```\r\n\r\nCompare to content from bing.com, which does have its `Content-Encoding: gzip` header:\r\n```bash\r\n$ curl -L -I --compress https://www.bing.com\r\nHTTP/1.1 200 OK\r\nCache-Control: private, max-age=0\r\nContent-Length: 0\r\nContent-Type: text/html; charset=utf-8\r\nContent-Encoding: gzip\r\nVary: Accept-Encoding\r\nP3P: CP=""NON UNI COM NAV STA LOC CURa DEVa PSAa PSDa OUR IND""\r\nSet-Cookie: SRCHD=AF=NOFORM; domain=.bing.com; expires=Thu, 24-Sep-2020 18:41:32 GMT; path=/\r\n  ... trimmed for brevity\r\n```\r\n\r\n\r\n'"
363173813,997,b'ColumnNameAttribute not working for TextLoader',"b'### Issue\r\n\r\n[ML.NET Tutorial](https://www.microsoft.com/net/learn/machinelearning-ai/ml-dotnet-get-started-tutorial) define IrisData class like this:\r\n```\r\n       public class IrisData\r\n        {\r\n            [Column(""0"")]\r\n            public float SepalLength;\r\n\r\n            [Column(""1"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""2"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""3"")]\r\n            public float PetalWidth;\r\n\r\n            [Column(""4"")]\r\n            [ColumnName(""Label"")]\r\n            public string Label;\r\n        }\r\n```\r\n\r\nIf I changed field name from Label to other name(like Label_1) \r\n```\r\n        public class IrisData\r\n        {\r\n            [Column(""0"")]\r\n            public float SepalLength;\r\n\r\n            [Column(""1"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""2"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""3"")]\r\n            public float PetalWidth;\r\n\r\n            [Column(""4"")]\r\n            [ColumnName(""Label"")]\r\n            public string Label_1;\r\n        }\r\n```\r\n\r\nIt will throw Exception(Source column \'Label\' not found):\r\n```\r\nAn unhandled exception of type \'System.Reflection.TargetInvocationException\' occurred in System.Private.CoreLib.dll: \'Exception has been thrown by the target of an invocation.\'\r\n Inner exceptions found, see $exception in variables window for more details.\r\n Innermost exception \t System.ArgumentOutOfRangeException : Source column \'Label\' not found\r\n   at Microsoft.ML.Runtime.Data.OneToOneTransformBase.Bindings.Create(OneToOneTransformBase parent, OneToOneColumn[] column, ISchema input, ITransposeSchema transInput, Func`2 testType)\r\n   at Microsoft.ML.Runtime.Data.OneToOneTransformBase..ctor(IHostEnvironment env, String name, OneToOneColumn[] column, IDataView input, Func`2 testType)\r\n   at Microsoft.ML.Runtime.Data.TermTransform..ctor(ArgumentsBase args, ColumnBase[] column, IHostEnvironment env, IDataView input)\r\n   at Microsoft.ML.Runtime.Transforms.TextAnalytics.TermTransform(IHostEnvironment env, Arguments input)\r\n```\r\n\r\n\r\n### Fix\r\nIt can be fixed by setting name in ColumnAttribute\r\n```\r\n[Column(""4"",""Label"")]            \r\npublic string Label_1;\r\n```\r\n'"
362830045,995,b'ML.NET 0.5.0 not getting installed on VS2017 ',"b""### System information\r\n\r\n- **OS version/Windows 10**:\r\n- **.NET Version (VS2017)**: \r\n\r\n### Issue\r\n\r\n- Trying to Install ML.NET 0.5\r\n\r\n-Severity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\t\tCould not install package 'Microsoft.ML 0.5.0'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.5.2', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\r\n"""
362805360,990,"b""DnnAnalyzer does not work with TensorFlow's SavedModel format""","b""Currently the DnnAnalyzer only works with frozen models.\r\n\r\nWe need to fix it so it also works for TensorFlow's SavedModel format"""
362792239,989,b'ONNX converter needs to acccess shapes in addition to variable names',"b""Some conversion strategies are shape-sensitive. ML.NET only passes input and output names to the each transform's conversion function, and it'd be better if shapes can be accessed as well."""
362766483,987,b'Need some markdown documentation for the new APIs',"b""We have a bunch of tests against the new API, but we should have some more text-heavy explanations. For example a 'overview of API concepts' and a 'cookbook' with samples'recipes for common scenarios."""
362762747,986,"b'`ITransformer` yields `IRowToRowMapper`, make prediction engine faster'","b""Things like `ITransformer` (or its predecessor, `IDataTransform`) given an `IDataView` can produce another `IDataView`. This works well for doing things like streaming over billions of records, but for just one record, the whole machinery around setting up a cursor.\r\n\r\nFor example, consider the prediction engine.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecb9126691401a3142e59139290bf78ed9bc68ad/src/Microsoft.ML.Api/PredictionEngine.cs#L149\r\n\r\nWhat this does currently is it basically composes an `IDataView` consisting of *one* item, then applies the transform chain to it, and so on. But this is pretty heavyweight. The setting up the dynamically typed delegates, binding to the appropriate types, and so on, on every single point absolutely dwarfs any actual computation that happens in many pipelines. Again, this system is fine if you're doing what it was designed to do, stream efficiently over billions of records, but on a small scale it's not great.\r\n\r\nThere is an existing `IRowToRowMapper` interface that we might be able to exploit.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecb9126691401a3142e59139290bf78ed9bc68ad/src/Microsoft.ML.Core/Data/ISchemaBindableMapper.cs#L91\r\n\r\nThis interface is somewhat analogous to `IDataView`, and the `IRowToRowMapper.GetRow` method is somewhat analogous to `IDataView.GetRowCursor`. This is something many existing `IDataTransform` interfaces would implement, to enable faster mapping. We can exploit this same functionality through `ITransformer`.\r\n\r\nSo we can do this:\r\n\r\n* Allow `ITransformer` to, in addition to providing `IDataView`s through transformation of datasets, *optionally* allow them to also provide `IRowToRowMapper` implementors.\r\n\r\n* Exploit this new functionality to make `PredictionEngine` faster, on applicable pipelines.\r\n\r\nThis will also allow us to check in prediction engine if a pipeline really is able to be expressed in a row-to-row capacity.\r\n\r\n"""
362762137,985,b'Improve data view inspectability',"b""Because the `IDataView` is lazy, it is hard to stop in the debugger and see what does this 'data' variable contain.\r\n\r\nWe need to add programmatic ways to scan some of the data (in addition to `AsEnumerable<MyRowClass>`), as well as debugger convenience classes to improve the IDE experience."""
362732809,984,b'Porting Missing Tests and Enabling Disabled Tests',"b'Many of the tests in machineLearning repo are disabled due to missing baseline files, datasets or components.\r\n\r\nThis issue tracks the development of enabling these tests and porting more tests from the TLC repo\r\n'"
362731486,983,b'Test changed incorrectly',b'PR #855 incorrectly changed the New_DecomposableTrainAndPredict and the New_Metacomponents; as a result of a merge operation. \r\n\r\nRe-establish those tests to the pre- PR#855 state. \r\n'
362728587,982,b'Reduce Running time of Machinelearning Benchmarks ',"b'Currently some of the benchmarks take an hour or two to run , which makes difficult for developers to get the instant results.\r\n\r\nOur target is to reduce the running time to 5~15 mins at max\r\n'"
362715952,980,b'Avoids pointer overflow in bound checking of SSE/AVX intrinsics',"b'#821 references and aims to solve this issue.\r\n---\r\nSuggested by @ahsonkhan to avoid integer overflow in bound checking inside SSE/AVX intrinsics implementation, i.e. change all `while (pCurrent + 8 OR 4 <= pEnd)` into `while (pEnd - pCurrent >= 8 OR 4)`.\r\n\r\nPerf tests results before and after the change are shown below:\r\n## Before the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |    StdDev |\r\n|----------------------- |------- |---------:|---------:|----------:|\r\n|    AvxPerformanceTests |   SumU | 159.4 us | 1.104 us | 0.9784 us |\r\n| NativePerformanceTests |   SumU | 283.5 us | 5.492 us | 4.8687 us |\r\n|    SsePerformanceTests |   SumU | 281.2 us | 1.472 us | 1.3045 us |\r\n|    AvxPerformanceTests |   AddU | 276.1 us | 3.018 us | 2.520 us |\r\n| NativePerformanceTests |   AddU | 330.1 us | 3.585 us | 3.178 us |\r\n|    SsePerformanceTests |   AddU | 325.6 us | 6.883 us | 7.926 us |\r\n\r\n## After the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |   StdDev |\r\n|----------------------- |------- |---------:|---------:|---------:|\r\n|    AvxPerformanceTests |   SumU | 183.5 us | 3.621 us | 3.023 us |\r\n| NativePerformanceTests |   SumU | 281.6 us | 5.261 us | 4.921 us |\r\n|    SsePerformanceTests |   SumU | 294.1 us | 2.080 us | 1.946 us |\r\n|    AvxPerformanceTests |   AddU | 296.3 us | 5.185 us | 4.850 us |\r\n| NativePerformanceTests |   AddU | 335.1 us | 3.053 us | 2.707 us |\r\n|    SsePerformanceTests |   AddU | 345.0 us | 2.155 us | 1.800 us |\r\n\r\nBoth SSE and AVX implementations are slower by 10-20% after this change.\r\n\r\nIn my opinion, after seeing the perf results, I may not recommend merging this PR.  I may wait until the alternative suggested by @tannergooding in an earlier PR review has been implemented (2nd item under ""Functionality"" in https://github.com/briancylui/machinelearning/issues/2):\r\n``` log\r\nvar remainder = count % elementsPerIteration;\r\nfloat* pEnd = pdst + (count - remainder);\r\nwhile (pDstCurrent < pEnd)\r\n{ \xe2\x80\xa6 }\r\n```\r\n\r\nAnother question I have is: would `pDstCurrent + 8 OR 4` ever have the possibility to result in integer overflow?  According to my knowledge, `pEnd` is initialized as `pDstCurrent + count`, and there are `Contract.Asserts` in the wrapper class to check that `count` does not exceed the original array length.  I\'m not sure, and am open to any PR comments and advice.\r\n\r\ncc: @danmosemsft @eerhardt @tannergooding @ahsonkhan @markusweimer '"
362707403,978,b'Time Series',"b'**Time Series in ML.NET**\r\n* Forecasting\r\n  * Singular Spectrum Analysis\r\n    * Modeling univariate time series. Implementation based on the model taken from http://arxiv.org/pdf/1206.6910.pdf. \r\n\r\n* Anomaly Detection \r\n  * Spike Detector\r\n    * Detects spikes in an independent and identical(IID) sequence using adaptive kernel density estimation\r\n  * Change Point Detector\r\n    * Detects the change-points in an independent and identical(IID) sequence using adaptive kernel density estimation and martingales\r\n\r\n* Smoothing transforms\r\n  * Exponential Average Transform\r\n    * Is a weighted average of the values: ExpAvg(yt) = a * yt + (1-a) * ExpAvg(yt-1).\r\n  * Moving Average Transform\r\n    * Applies a moving average on a time series\r\n  * Percentile Threshold Transform\r\n    * Is a sequential transform that decides whether the current value of the time-series belongs to the \'percentile\' % of the top values in the sliding window. The output of the transform will be a boolean flag.\r\n  * P Value Transform\r\n    * Calculates the p-value of the current input in the sequence with regard to the values in the sliding window.\r\n\r\n**New Features to come**\r\n* **Estimator and PiGSTy APIs** for the below components\r\n  * |Component|Priority|\r\n     |---|---|\r\n     | IidChangePointDetector | 0 |\r\n     | IidSpikeDetector  | 0 |\r\n     | SsaChangePointDetector| 0 |\r\n     | ExponentialAverageTransform| 1 |\r\n     | MovingAverageTransform| 1 |\r\n     | PercentileThresholdTransform| 1 |\r\n     | PValueTransform| 1 |\r\n     | SlidingWindowTransform| 1 |\r\n     \r\n     Example:\r\n      ```csharp\r\n      var data = new[] { new Data() { Feature = 2 }, new Data() { Feature = 1} }; \r\n      var dataView = ComponentCreation.CreateDataView(Env, data); \r\n      var pipe = new SpikeDetectorEstimator(Env, new[]{ \r\n      new SpikeDetectorTransformer.ColumnInfo(""Feature"", ""Anomaly"", twnd:500, swnd:50) \r\n       }); \r\n      var result = pipe.Fit(dataView).Transform(dataView); \r\n      var resultRoles = new RoleMappedData(result);\r\n      ```\r\n* **Prediction Engine**\r\n  * The prediction engine we have today is a stateless one. For time series it is important we update the state of the model as we make prediction in the case of SSA models that have temporal relation between data points. This will require creating a new variant of prediction engine that will be used by time series components listed above. #163 \r\n  * Currently to achieve stateful prediction engine users have to write the below code and then create checkpoints by saving the model every so often. \r\n    ```csharp\r\n               const int size = 10;\r\n                List<Data> data = new List<Data>(size);\r\n                var dataView = env.CreateStreamingDataView(data);\r\n                List<Data> tempData = new List<Data>();\r\n                for (int i = 0; i < size / 2; i++)\r\n                    tempData.Add(new Data(5));\r\n\r\n                for (int i = 0; i < size / 2; i++)\r\n                    tempData.Add(new Data((float)(5 + i * 1.1)));\r\n\r\n                foreach (var d in tempData)\r\n                    data.Add(new Data(d.Value));\r\n\r\n                var args = new IidChangePointDetector.Arguments()\r\n                {\r\n                    Confidence = 80,\r\n                    Source = ""Value"",\r\n                    Name = ""Change"",\r\n                    ChangeHistoryLength = size,\r\n                    Data = dataView\r\n                };\r\n               \r\n               //Train\r\n                var detector = TimeSeriesProcessing.IidChangePointDetector(env, args);\r\n                //Anomaly Detection\r\n                var output = detector.Model.Apply(env, dataView);\r\n                var enumerator = output.AsEnumerable<Prediction>(env, true).GetEnumerator();\r\n               //Save the updated model \r\n               detector.Model.Save();\r\n      ```\r\n  * Instead we could have a below API that allows the user to save the model at fixed intervals to a disk or a stream while updating the model. \r\n```csharp \r\n           using (var env = new LocalEnvironment(seed: 1, conc: 1))\r\n            {\r\n                // Pipeline\r\n                var loader = TextLoader.ReadFile(env, MakeArgs(), new MultiFileSource(GetDataPath(TestDatasets.AnomalyDetection)));\r\n                var cachedTrain = new CacheDataView(env, loader, prefetch: null);\r\n\r\n                // Train.\r\n                var IidDetector = new IidChangePointDetector(env, new IidChangePointDetector.Arguments\r\n                {\r\n                   Confidence = 80,\r\n                    Source = ""Features"",\r\n                    Name = ""Change"",\r\n                    ChangeHistoryLength = size,\r\n                    Data = dataView\r\n                });\r\n                var trainRoles = new RoleMappedData(cachedTrain, feature: ""Features"");\r\n                var predictor = IidDetector.Train(new Runtime.TrainContext(trainRoles));\r\n\r\n                PredictionEngine<Input, Prediction> model;\r\n                using (var file = env.CreateTempFile())\r\n                {\r\n                    // Save model. \r\n                    var roles = new RoleMappedData(trans, feature: ""Features"");\r\n                    using (var ch = env.Start(""saving""))\r\n                        TrainUtils.SaveModel(env, ch, file, predictor, roles);\r\n\r\n                    // Load model.\r\n                    using (var fs = file.OpenReadStream())\r\n                        model = env.CreatePredictionEngine<Input, Prediction>(fs);\r\n                }\r\n\r\n                // Take a couple examples out of the test data and run predictions on top.\r\n                var testLoader = TextLoader.ReadFile(env, MakeArgs(), new MultiFileSource(GetDataPath(TestDatasets.AnomalyDetection));\r\n                var testData = testLoader.AsEnumerable<Input>(env, false);\r\n                foreach (var input in testData.Take(10))\r\n                {\r\n                   //Anomaly detection + update the model.\r\n                    var prediction = model.Predict(input);\r\n                }                \r\n               \r\n               //Save the model with updated state.\r\n                model.Save();\r\n            }\r\n```\r\n\r\n* **Online Training**\r\n   Currently we have to train the model with the entire train dataset to update the model but instead it would be nice if the model got updated as the data came in. #163\r\n\r\n* **Evaluator**\r\n  * Currently we don\xe2\x80\x99t have any evaluator for time series. Rolling CV is better for time dependent datasets by always testing on data which is newer than the training data. Standard CV leaks future data in to the training set. Other names of Rolling CV include { walk-forward / roll-forward / rolling origin / window } CV. Refer to #1026\r\n\r\n* **ARIMA model** \r\nIt seems the first thing novice time series users look for in a toolkit when doing a forecasting task is ARMIA model because it is the first thing that comes up in search results for forecasting. While ARMIA model isn\xe2\x80\x99t the most accurate or performant model but it is the most well-known forecasting model. We should consider bringing in a simple implementation of ARIMA in ML.NET. #929 \r\n\r\n* **Time Series Featurizer**  \r\nThe more performant models are the one that combine the features from a time series transform with non-time series features and feed in the resulting vector into a black-box regression learning algorithm. For example, one could have two features A and B, where A will contain data points that have temporal relationship between them, example, stock price and B contains non-temporal feature like country or zip code. We could feed A into SSA transform that will extract various components from an individual feature value such as trend, level, seasonality and then repeat this for all the feature values of A and then combine the result vector with feature B that could be feed into a regressor for prediction. The feature extraction step could be SSA or it could be a deep learning model such as LSTM. The regressor could be any regression based learner.  #929 \r\n\r\n\r\n... and many more with `time`.'"
362679401,976,b'Missing System.Collections.Immutable from ML.Net 0.6.0-preview nuget package dependencies',b'### Issue\r\nThe latest ML.Net (0.6.0-preview) has a dependency on System.Collections.Immutable but the ML.Net nuget package does not list System.Collections.Immutable as a dependency. This results in a crash in ML.Net because of the missing assembly. \r\n'
362553901,975,b'ComponentCatalog logging errors',"b""### System information\r\n\r\n- **OS version/distro**: OSX 10.12\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core SDK 2.1.401\r\n\r\n### Issue\r\nWhen running a simple showSchema command, `dotnet ./bin/AnyCPU.Release/Microsoft.ML.Console/netcoreapp2.0/MML.dll showSchema data=test/data/breast-cancer.txt`, as taken from https://github.com/dotnet/machinelearning/issues/593#issuecomment-408582190, many errors are displayed.\r\n\r\nOutput:\r\n```\r\nCacheClassesFromAssembly: can't map name ModuleGenerator to ModuleGenerator, already mapped to ModuleGenerator\r\nCacheClassesFromAssembly: can't map name Module to ModuleGenerator, already mapped to ModuleGenerator\r\nCacheClassesFromAssembly: can't map name CrossValidationBinaryMacro to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name CrossValidationMacro to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name CVSplit to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name DataViewReference to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name FeatureCombiner to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name ImportTextData to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name ExecGraph to ExecuteGraphCommand, already mapped to ExecuteGraphCommand\r\nCacheClassesFromAssembly: can't map name ModelOperations to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name OneVersusAllMacro to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name TrainTestBinaryMacro to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name TrainTestMacro to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name TrainTestSplit to Void, already mapped to Void\r\nCacheClassesFromAssembly: can't map name CSGenerator to CSharpApiGenerator, already mapped to CSharpApiGenerator\r\nCacheClassesFromAssembly: can't map name CS to CSharpApiGenerator, already mapped to CSharpApiGenerator\r\n2 columns:\r\n  Label: R4\r\n  Features: Vec<R4, 9>\r\n```\r\n\r\nThis error is logged within the ComponentCatalog:\r\nhttps://github.com/dotnet/machinelearning/blob/6812cb565ebaa522685571103a4e441ee908dbb0/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L491-L493"""
362389288,971,b'Potential bug in ONNX exporter of KeyToVectorTransform',"b""[KeyToVectorTransform](https://github.com/dotnet/machinelearning/blob/1e7b8be855210f2bd8adbd532396a1840a20541d/src/Microsoft.ML.Data/Transforms/KeyToVectorTransform.cs#L711) is mapped to a single [OneHotEncoder](https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#aionnxmlonehotencoder )in ONNX now. It's correct if `bag-` but if `bag+`, we need to sum up the produced one-hot vectors with one extra `ReduceSum`."""
362363086,969,b'TestEstimatorCore fails when training on EmptyDataView for the listed transforms.',"b'`TestEstimatorCore` method tests the schema of estimator that of transformer. It trains estimator on EmptyDataView and get the schema. Then, it fits the estimator on actual data, and get the schema from transformer.\r\n\r\n#### Ngram\r\nIt then verifies of both schema are same. However for the case of ngram transform, schema learnt from EmptyDataView is different from actually learned from data. The actual cause is size of ngram is zero in case of training on EmptyDataView which causes output vector type to be variable length. Additionally, some other meta are not filled properly in this case.\r\n\r\n#### PCA Transform\r\nCan not applied on EmptyDataView. Exception is thrown regrading empty data view.\r\n\r\nBecause of this following tests are failing right now.\r\n\r\nWordBagWorkout\r\nNgramWorkout\r\nPcaWorkout\r\n\r\nNeed to think how to fix it.'"
362359358,968,b'Handle unreachable ONNX variables when saving as ONNX',"b""As title. Sometime, we end up with a computation graph with unreachable variables. We have `inputsToDrop` and `outputsToDrop` for manually removing them but it'd be better to have an automatic mechanism. #952 includes a solution."""
362310803,966,"b'Use the actual argument name, in addition to the short name in error messages. '","b'For TrainerEstimators, assigning a ""bad"" value to the arguments will result in an error like:\r\n\r\n""Message: System.ArgumentOutOfRangeException : Illegal input value\r\nParameter name: p""\r\n\r\nWhere p is the ShortName of the respective argument. \r\nIn addition to the short name, the error messages should also include the full argument name, because short names are not API user-facing.\r\n\r\n'"
362245477,964,b'Need to add SequenceClassifierEvaluator to ML.NET',"b""In EvaluatorUtils, we used to try to find a `SequenceClassifierEvaluator` Component using `SubComponent` instances. See\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5a6fdedcc235deb02da72526097e5d0b9955ed2c/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L45-L47\r\n\r\nWhen removing `SubComponent` I discovered that this copmonent is not part of ML.NET, and so I couldn't make a `SequenceClassifierEvaluator` instance.\r\n\r\nWe should either port this evaluator to ML.NET, or remove the commented out line here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/86f4d932b47fbd5abc3e9df89dd7ab3d9aacd07b/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L47"""
361983370,959,"b'Convert LpNorm, GcNorm and Whitening Transforms to transformers/estimators.'","b'\r\nIn this work item, following transforms will be converted into transformer/estimators.\r\n\r\n- LpNormNormalizerTransform\r\n- GcnTransform\r\n- WhiteningTransform'"
361970644,958,"b""ONNX Conversion Framework Needs a Way to Create Tensors as ONNX Graph's Initializers""","b""As title. Currently, we're not able to create elements in [this field](https://github.com/onnx/onnx/blob/c0ec417e219ff4ce22b94998bbe570e9b9b0c34a/onnx/onnx-ml.proto#L256). #965 provides a solution."""
361956023,956,"b'Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators'","b'Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.'"
361949146,955,b'Experimental Exporter of CopyColumnTransform to ONNX',"b""Following the same strategy of converting ConvertTransform, we should be able export CopyColumnTransform to ONNX as well. #952 demonstrates a possible approach. Note that we assume that somehow the ONNX runtime used can recognize the unofficial operator we're producing."""
361924820,951,b'Implement transfer learning functionality in TensorFlowTransform.',"b""There are couple of hurdles in implementing a transfer learning scenario (where tf model is actually modified) using TF#.\r\n\r\n- [SOLVED] There is no way to serialized TF model back to file using TF C-API (also TF#).\r\n- It seems impossible to load checkpoint models using C-API (also TF#) because the graph saved with checkpoint models is saved in meta_graph format for which straightforward API is currently missing to load/save.\r\n- When using frozen model, there are no training ops like optimizations or loss operations. Also, frozen model don't have variables because those are converted into constant while the model is frozen. So, frozen models can't be retrained.\r\n-  When using un-frozen model (saved with simple_save method in python), training operations must be included in the graph so that training can happen from TensorFlowTransform.\r\n"""
361919430,950,b'Convert all text transforms into transformers/estimators.',b'Following is the list of transforms that will converted in this work item.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n\r\n'
361903092,949,b'API: Binary Classification Training Context',"b'There seems to be something appealing about a convenience object whose purpose is to help ""guide"" people on the path to a successful experiment. So for example, someone might have a pipeline where they featurize, then learn, then evaluate on a test set. Each of these is of course naturally implemented in separate classes, which is good. But it also means that the ingredients necessary to compose a successful experiment are naturally spread hither and yon.\r\n\r\nYou might imagine that in addition to the components, there might be some sort of ""task context"" object, like for example, a `BinaryClassifierContext`. This might have common facilities: for example, a common way to ""browse"" binary classifier trainers, and to evaluate binary classification outputs.\r\n\r\nThere is something appealing about doing this:\r\n\r\n```csharp\r\nvar data = ...\r\nvar ctx = new BinaryClassificationContext();\r\nvar prediction = ctx.Trainers.FastTree(data, ...);\r\nvar metrics = ctx.Evaluate(prediction, ...);\r\n```\r\n\r\nvs. this\r\n\r\n```csharp\r\nvar data = ...\r\nvar prediction = new FastTreeBinaryClassifierEstimator(data, ...);\r\nvar eval = new BinaryClasifierEvaluator(...);\r\nvar metrics = eval.Evaluate(prediction, ...)\r\n```\r\n\r\nThe latter case is certainly no less powerful, but if I imagine someone tooling around in intellisense, the sheer number of things you\'ll get by including the key namespaces and saying `new` is absolutely dizzying, vs. this context which can be very, very focused.\r\n\r\nIn the case of static pipelines the story is a little bit better, ""we provide extension methods on `Scalar<bool>`"", which is OK *if you know that*, but if you don\'t happen to know that, I see no reasonable way you could discover that without reading documentation and samples. (Of course for that matter I see ). But requiring knowledge at the level of, ""if you want to do something related to binary classifiers, please say `new BinaryClassifierContext`"" or something, that seems kind of reasonable to me.\r\n\r\nThis hypothetical `Context` object would contain at least two things: the first is a property. (It must be an actual instance because the only way external assemblies could ""add"" their learners to it would be via extension methods.) The second is one or more `Evaluate` methods to produce metrics.\r\n\r\nThese ""objects"" do have state in the sense that they must have an `IHostEnvironment`, but aside from this are more or less like ""namespaces,"" with the important difference possibly that you can\'t have a top level function as a namespace. (Though perhaps we don\'t care about doing functions.) There was some thought that if we also defined pipelines through them we could avoid having environments in the dynamic pipelines altogether (as we already do for static pipelines), but how this would be accomplished is not clear to me.\r\n\r\nAlso because the only reasonable way things can add themselves is via an extension method, this `Trainers` object would have to be an actual instance... now then, it needn\'t actually be instantiable -- one can call extension methods on the `null` of an object as well as anything so long as we don\'t want to get any information out of it -- but that is a little awkward. If we could just put extension methods on, say, a static class or something that would be nice, but we can\'t.\r\n\r\n# Work Item\r\n\r\nThe first thing I will do is create a binary classification training context object, as an exploration of the idea. If we like the idea, we can extend it to the other tasks as well.'"
361876572,948,b'Public space such as Wiki for accumulating knowledge about ML.NET',"b'Do we have any places like a Wiki? I\'d like to have a place to share some small knowledge related to ML.NET. Here is an example.\r\nToday, I changed the signature of SaveOnnx and then got two tests failed, TestGeneratedCSharpAPI and EntryPointCatalog. The solution is very straightforward, when you know the answer.\r\n\r\nSolution:\r\n\r\n1. Open Microsoft.ML.sln under Visual Studio\r\n2. Go to Test Explorer\r\n3. Find the test code of `RegenerateEntryPointCatalog()` in TestEntryPoints.cs and change its `[Fact(Skip = ""....."")]` to `[Fact()]`\' and then run it. Then, you will see (via `git diff`) core_mainfest.json gets changed. Include those changes into your commit. Note that with the existence of `Skip =`, Test Explorer may not execute your test anyway.\r\n4. Find the test code of `RegenerateCSharpApi()` in CSharpCodeGen.cs and change its `[Fact(skip = ""....."")]` to `[Fact()]` and also commit the changes (CSharpApi.cs) induced by running this test.\r\n\r\nI personally like GitHub issues with a better tag name such as ""knowledge"" so that we have one place for all.'"
361856168,946,b'Is NATransform still onnxable?',"b""Just notice that the code of exporting NAReplaceTransform to ONNX is missing comparing with the version pointed by internal TLC. The root reason is that OneToOneTransformerBase doesn't have ITransformCanSaveOnnx anymore."""
361849014,945,b'Experimental Conversion of ConvertTransform to ONNX format',"b""We're experimenting for exporting more transforms to ONNX. ConvertTransform is the first one we're working on. #947 """
361515350,938,b'Find a new regression dataset',"b'Some regression tests rely on a machine generated regression dataset (Gaussian noise on top of a linear function of a vector input). The file was introduced by #937.\r\n\r\nWe should replace this dataset with a real dataset. Justin @justinormont suggested to find something from [data.gov](https://catalog.data.gov/dataset), for example predicting the SF employee pay: https://catalog.data.gov/dataset/employee-compensation-53987\r\n'"
361500432,936,b'Substituting UCI Wine Quality dataset with machine generated dataset',b'There are two problems with the UCI Wine Quality dataset:\r\n\r\n- it is not reachable (which breaks the build)\r\n- it is intended to be used for research purposes only\r\n\r\nIt should be substituted with another regression dataset.'
361389167,935,b'Fix separators for word tokenizer',"b'Currently, the separators property for `WordTokenizer` is a string, that is parsed as a comma-separated list of characters. It was appropriate for command-line parsing, but not appropriate for API use.\r\n\r\nA better solution is to have a `char[]`.'"
361267055,934,b'Release 0.5 feedback',"b'Firstly, a very big thank you and congratulations to all involved with the latest release. I am, particularly looking forward to exploring the new API and specifically accessing model feature selection/scores.\r\n\r\nIn the meantime, we have incomplete MI generated and am not sure if this is related to the changes. ..\r\nDisplayng metrics for Momentum Model Regression\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nProcessed 423 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 363168 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n*************************************************\r\n*       Metrics for Fast Tree\r\n*------------------------------------------------\r\n*       R2 Score: -1.05\r\n*       Absolute loss:\r\n*       Squared loss:\r\n*       RMS loss:\r\n*************************************************\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nProcessed 423 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 363168 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n*************************************************\r\n*       Metrics for Fast Forest\r\n*------------------------------------------------\r\n*       R2 Score: 0.05\r\n*       Absolute loss:\r\n*       Squared loss:\r\n*       RMS loss:\r\n*************************************************\r\n\r\nI have a theory though - that this is related to some data points being not sufficiently linear. Could this be correct?'"
361072980,933,"b'De-transformation of samplers, filters'","b""As we transition the code from being exclusively for a tool to being more appropriate for an API, one of the most crucial parts of the work is that summarized in #581 where we take the concept `IDataTransform` and split it into three concepts `IEstimator`/`ITransformer`/`IDataView` -- currently, an [`IDataTranform` fills all three roles](https://github.com/dotnet/machinelearning/blob/4e0800c652e981d12a04099262aadea1181aa76a/src/Microsoft.ML.Data/Data/IDataLoader.cs#L91) (it is both the transforming model and an `IDataView`), which leads to a great deal of confusion when using this as an API.\r\n\r\nThe working assumption is that most things that are `IDataTranform` will transition to being this triad of estimator, transformer, and data-view. There are however some probably desirable exceptions that we do not want to *fully* convert:\r\n\r\n* All row filter transforms (skip, take, NA filter),\r\n* The shuffle transform,\r\n* The bootstrap sampler transform.\r\n\r\nCurrently they are `IDataTransform`, because everything that transforms data in this fashion is an `IDataTransform`. However this means that there is a data model associated with it, and it is serialized just alongside every other transform.\r\n\r\nPeople have historically found this confusing. For example, people want to train and test based on the same dataset, so they apply bootstrap sampling transform in their transform list -- but then the same is done to their test set so the results are all screwed up. Or, they want to train on only some of it, so they apply the `Take` filter -- but then their test set evaluation happens only over the first however many. There are lots of examples like this that I've seen over the years. My belief is that generally this sort of row-wise filtering/sampling being part of the data pipeline really does more harm than good.\r\n\r\nNow that we have the estimator/transformer/data triad of #581, we can make these operations exclusively as `IDataView`s, *not* actual fully blown `ITransformer` implementors (where someone might make the mistake of serializing them to a data pipeline).\r\n\r\nIt does ***technically*** represent a loss of capability, but I am not aware that I have ever seen a valid usecase where any of these entities was used as a data-model component deliberately, and it is very difficult for me to imagine a case where people would want to do so. Every usecase I have ever seen has been accidental and ultimately deeply harmful to the integrity of the user's experiments.\r\n\r\nWe will also need to decide what to do when we deserialize these models, when we deserialize what had been an `IDataTransform` into the new `ITransformer`. My own preference would be that they be replaced with a no-op transformer, since again I've never seen anything valid done with them.\r\n\r\nThis will also incidentally mean less work as we perform the conversion work."""
361069105,932,b'ComponentCatalogue: private constructors for estimators',"b'Only one constructor per estimator should be **public** and presented to the end user. The constructor should require the arguments that are needed to initialize the estimator.\r\n\r\nWe also need to have another constructor with arguments (IHostEnvironment env, Arguments args) for MAML to work. This constructor should be **private**, so that it does not appear as an option to the end user.\r\n\r\nCurrently the ComponentCatalogue does not recognize any private constructors. '"
360901380,930,b'PipeBase<TMessage> should implement the Dispose Pattern correctly',"b""The PipeBase class implements IDisposable, but doesn't implement the basic pattern correctly.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Core/Environment/HostEnvironmentBase.cs#L205-L213\r\n\r\nSee https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern for the basic dispose pattern.\r\n\r\nWe should follow the design guidelines here."""
360841297,929,b'Time series and forecasting',b'Ml.net version 0.5\r\n- When you plan to release a versione that include a Time series forecasting trainer ??\r\n'
360593094,927,b'Convert WordEmbeddingsTransform into Estimator.',b'This is the workitem related to #754.'
360491448,925,b'Tests need their own environment implementation',"b""Right now we use TlcEnvironment (or ConsoleEnvironment) which outputs everything to console.\r\nAnd XUnit don't care about console, and if you want to look on output during test execution you need to do something like this:\r\nhttps://github.com/dotnet/machinelearning/blob/4cb7dd9047b4c456e81ba014c664c27efe217351/test/Microsoft.ML.StaticPipelineTesting/StaticPipeTests.cs#L31\r\n\r\nWe should have XUnitEnvironment or TestEnvironment and redirect all output to ITestOutputHelper."""
360486115,924,"b'Significant time difference between linux, macos and windows test executions on build machines'","b""Let's look on this [build](https://dnceng.visualstudio.com/public/_build/results?buildId=21056&view=logs)\r\n\r\nMacOS Release  - tests: 19:08\r\nMacOS Debug  - tests: 22:59\r\nLinux Release - test 17:02\r\nLinux Debug - test 21:02\r\nWindows Release - test 5:00\r\nWindows Debug - test 7:53\r\n\r\nWindows machine:\r\n2018-09-14T22:47:22.5353796Z Results File: D:\\a\\1\\s\\bin/AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\VssAdministrator_factoryvm-az366_2018-09-14_22_43_12.trx\r\n2018-09-14T22:47:22.5354312Z \r\n2018-09-14T22:47:22.5355746Z Total tests: 105. Passed: 49. Failed: 0. Skipped: 56.\r\n2018-09-14T22:47:22.5356035Z Test Run Successful.\r\n2018-09-14T22:47:22.5357667Z Test execution time: 4.2240 Minutes\r\n\r\nLinux machine:\r\n\r\n2018-09-14T22:59:26.1088812Z Results File: /__w/1/s/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/_5438db60ae8a_2018-09-14_22_41_24.trx\r\n2018-09-14T22:59:26.1096444Z \r\n2018-09-14T22:59:26.1109704Z Total tests: 105. Passed: 49. Failed: 0. Skipped: 56.\r\n2018-09-14T22:59:26.1124041Z Test Run Successful.\r\n2018-09-14T22:59:26.1137781Z Test execution time: 18.0608 Minutes\r\n\r\nIt looks like we run same set of tests but for some reason where is huge difference in execution.\r\nAny one willing to investigate?"""
360467932,921,b'ComponentCatalog and public constructors',"b'In current moment our component catalog looking for constructor methods only if they public which force us to have lot of public constructors and static Create methods, which is bad from API point of view.\r\nWe should change ComponentCatalog to look for private methods as well and change visibility of public constructors.\r\n\r\n```\r\n // Factory method for SignatureDataTransform.\r\n        public static IDataTransform Create(IHostEnvironment env, Arguments args, IDataView input)\r\n```\r\nor \r\n```\r\n // Factory method for SignatureLoadDataTransform.\r\n        public static IDataTransform Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n```\r\n\r\n'"
360455082,919,b'Categorical Feature and FastTree',"b'FastTree has a very powerful mechanism to process categorical features. However, which feature is considered as categorical is not described anywhere in doc. Some questions a data scientist may want to ask:\r\n1. How to make feature categorical if they are stored as floats such as 1.00 and 128.00?\r\n2. How does categorical metadata propagate through the learning pipeline? For example, some transforms may drop those metadata so that categorical features are no longer categorical after them.\r\n3. How to make categorical not considered as categorical in FastTree?\r\n\r\nNote that [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-API.html) has a nice description for how they handle categorical features. Let me just copy it here.\r\n_categorical_feature (list of strings or int, or \'auto\', optional (default=""auto"")) \xe2\x80\x93 Categorical features. If list of int, interpreted as indices. If list of strings, interpreted as feature names (need to specify feature_name as well). If \xe2\x80\x98auto\xe2\x80\x99 and data is pandas DataFrame, pandas categorical columns are used._ \r\n\r\nThanks,'"
360436709,918,b'Flaky assert failure in SDCA test ',"b'```\r\n2018-09-13T23:25:02.4332634Z Failed   Microsoft.ML.Scenarios.ScenariosTests.TrainAndPredictIrisModelWithStringLabelTest\r\n2018-09-13T23:25:02.4332936Z Error Message:\r\n2018-09-13T23:25:02.4333077Z  Assert failed: longIdx=37, invariants.Length=37\r\n2018-09-13T23:25:02.4333210Z Expected: True\r\n2018-09-13T23:25:02.4333341Z Actual:   False\r\n2018-09-13T23:25:02.4333453Z Stack Trace:\r\n2018-09-13T23:25:02.4333653Z    at Microsoft.ML.Runtime.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in D:\\a\\1\\s\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs:line 47\r\n2018-09-13T23:25:02.4333951Z    at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 770\r\n2018-09-13T23:25:02.4334183Z    at Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 783\r\n2018-09-13T23:25:02.4334404Z    at Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 841\r\n2018-09-13T23:25:02.4334962Z    at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`2.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\LinearClassificationTrainer.cs:line 514\r\n2018-09-13T23:25:02.4335278Z    at Microsoft.ML.Runtime.Learners.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\StochasticTrainerBase.cs:line 42\r\n2018-09-13T23:25:02.4335567Z    at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 88\r\n2018-09-13T23:25:02.4336480Z    at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 154\r\n2018-09-13T23:25:02.4336826Z    at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 260\r\n2018-09-13T23:25:02.4337494Z    at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 228\r\n2018-09-13T23:25:02.4337856Z    at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 189\r\n2018-09-13T23:25:02.4338176Z    at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\SdcaMultiClass.cs:line 437\r\n```\r\n\r\nThe data  pipeline has a `TextLoader`, a `Dictionarizer` and `ColumnConcatenator`, then it trains SDCA classifier.\r\n\r\n@TomFinley suggests that it could be related to the difference in ID generation between iterations. \r\nThe fact that the test is not failing every time suggests that either there is a race condition somewhere (in the `TextLoader`?), or somehow the data is sometimes modified mid-run.'"
360407021,916,"b'\xe2\x80\x9cScore Column\xe2\x80\x9d is missing, System.Reflection.TargetInvocationException'","b'### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Version: 2.0.7**: \r\n\r\n### Issue\r\n\r\nI try to build ML.NET app that working on [Wisconsin Prognostic Breast Cancer Dataset](https://www.kaggle.com/sarahvch/breast-cancer-wisconsin-prognostic-data-set). Whatever i do i get \r\n\r\n> ArgumentOutOfRangeException: Score column is missing\r\n\r\nEven if i add `Score` Column. The error showing on `ClassificationMetrics metrics = evaluator.Evaluate(model, testData);` line. \r\n\r\nMy data looks like this:\r\n\r\n```\r\ndiagnosis;radius_mean;texture_mean;perimeter_mean;area_mean;smoothness_mean;compactness_mean;concavity_mean;concave points_mean;symmetry_mean;fractal_dimension_mean;radius_se;texture_se;perimeter_se;area_se;smoothness_se;compactness_se;concavity_se;concave points_se;symmetry_se;fractal_dimension_se;radius_worst;texture_worst;perimeter_worst;area_worst;smoothness_worst;compactness_worst;concavity_worst;concave points_worst;symmetry_worst;fractal_dimension_worst\r\nB;11.62;18.18;76.38;408.8;0.1175;0.1483;0.102;0.05564;0.1957;0.07255;0.4101;1.74;3.027;27.85;0.01459;0.03206;0.04961;0.01841;0.01807;0.005217;13.36;25.4;88.14;528.1;0.178;0.2878;0.3186;0.1416;0.266;0.0927\r\nB;9.667;18.49;61.49;289.1;0.08946;0.06258;0.02948;0.01514;0.2238;0.06413;0.3776;1.35;2.569;22.73;0.007501;0.01989;0.02714;0.009883;0.0196;0.003913;11.14;25.62;70.88;385.2;0.1234;0.1542;0.1277;0.0656;0.3174;0.08524\r\n```\r\n\r\nCode can be pretty long, i posted my question into StackOverflow too: [ML.NET, \xe2\x80\x9cScore Column\xe2\x80\x9d is missing](https://stackoverflow.com/questions/52335066/ml-net-score-column-is-missing?noredirect=1#comment91619986_52335066)\r\n\r\n### Source code / logs\r\n\r\n**My CancerData.cs looks like this:**\r\n\r\n\r\n```\r\nclass CancerData\r\n{\r\n\r\n    [Column(ordinal: ""0"")]\r\n    public string Diagnosis;\r\n\r\n    [Column(ordinal: ""1"")]\r\n    public float RadiusMean;\r\n\r\n    [Column(ordinal: ""2"")]\r\n    public float TextureMean;\r\n\r\n    [Column(ordinal: ""3"")]\r\n    public float PerimeterMean;\r\n\r\n   //.........\r\n\r\n   [Column(ordinal: ""28"")] \r\n    public float ConcavPointsWorst;\r\n\r\n    [Column(ordinal: ""29"")]\r\n    public float SymmetryWorst;\r\n\r\n    [Column(ordinal: ""30"")]\r\n    public float FractalDimensionWorst;\r\n\r\n    [Column(ordinal: ""31"", name: ""Label"")]\r\n    public string Label;\r\n}\r\n```\r\n\r\n**CancerPrediction.cs**\r\n\r\n```\r\nclass CancerPrediction\r\n{\r\n    [ColumnName(""PredictedLabel"")]\r\n    public string Diagnosis;\r\n\r\n    [ColumnName(""Score"")]\r\n    public float Score;\r\n}\r\n```\r\n**Main.cs**\r\n```\r\nclass Program\r\n{\r\n\r\n    static void Main(string[] args)\r\n    {\r\n        PredictionModel<CancerData, CancerPrediction> model = Train();\r\n        Evaluate(model);\r\n    }\r\n\r\n    public static PredictionModel<CancerData, CancerPrediction> Train()\r\n    {\r\n        var pipeline = new LearningPipeline();\r\n        pipeline.Add(new TextLoader(""Cancer-train.csv"").CreateFrom<CancerData>(useHeader: true, separator: \';\'));\r\n        pipeline.Add(new Dictionarizer((""Diagnosis"", ""Label"")));\r\n        pipeline.Add(new ColumnConcatenator(outputColumn: ""Features"",\r\n            ""RadiusMean"",\r\n            ""TextureMean"",\r\n            ""PerimeterMean"",\r\n            //... all of the features\r\n            ""FractalDimensionWorst""));\r\n        pipeline.Add(new StochasticDualCoordinateAscentBinaryClassifier());\r\n        pipeline.Add(new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = ""PredictedLabel"" });\r\n        PredictionModel<CancerData, CancerPrediction> model = pipeline.Train<CancerData, CancerPrediction>();\r\n        model.WriteAsync(modelPath);\r\n        return model;\r\n\r\n    }\r\n\r\n    public static void Evaluate(PredictionModel<CancerData, CancerPrediction> model)\r\n    {\r\n        var testData = new TextLoader(""Cancer-test.csv"").CreateFrom<CancerData>(useHeader: true, separator: \';\');\r\n        var evaluator = new ClassificationEvaluator();\r\n        ClassificationMetrics metrics = evaluator.Evaluate(model, testData);\r\n        var accuracy = Math.Round(metrics.AccuracyMicro, 2);\r\n        Console.WriteLine(""The accuracy is: "" + accuracy);\r\n        Console.ReadLine();\r\n    }\r\n}\r\n```'"
360386989,915,b'Trying to left-outer join two datasets using a PK/FK',b'Is there any way to manipulate the input data in order to join two distinct datasets using a primary key/foreign key?  Is the expectation that the input from the TextLoader is always partially pre-processed?'
360195071,913,b'Feature request: get reasons behind predictions made by Decision Trees',"b'My team had long conversation with ML.NET\'s team (based on issue #599) and we came up with this feature request as the result.\r\n\r\nFor a model based on decision trees we\'d like to have public API method similar to Scikit Learn\'s ""decision_path"" which does the following: for each input sample in outputs route traveled from root to leaf in each tree (i.e. list of nodes and edges).\r\n\r\nWe need that to understand reasons behind each prediction our model made.\r\n'"
360150496,911,b'TLS Links for Improved Security',"b'For general web security, we should use HTTP**S** links instead of HTTP. \r\n\r\nWithin the ML.NET repo, I see ~60 locations where we use HTTP:\r\n  https://github.com/dotnet/machinelearning/search?p=3&q=http%3A%2F%2F&unscoped_q=http%3A%2F%2F\r\n\r\nTask:\r\n* Verify that HTTPS links are equivalent\r\n* Where possible, change links to utilize HTTPS\r\n\r\nQ: Assuming we can alter all HTTP links to HTTPS, should we block new HTTP links as part of a git check-in test? A check-in test would help reduce unintentional HTTP links; for example, I missed [this http://aka.ms link](https://github.com/dotnet/machinelearning/blob/f0f04ef8854bd1ae05987072e2f0fd660d4be662/build.proj#L84)  as a reviewer.'"
360110315,910,b'Fix AP and OGD metadata propagation and behavior',"b'In the process of writing #909 I discovered that AP is now seemingly uncalibrated, and cannot accept float labels, and OGD throws at training. \r\n\r\nEnable the `OnlineLinearWorkout` test in #909 and fix the resulting bugs.'"
360104699,908,b'Command Line Usages',"b""Are command line tool exposed to users with some docs? It looks it's not straightforward for external users to use command line to train a model. Thanks."""
360096062,907,"b'Evaluator.Evaluate throws ""Expected exactly one column with role \'Score\', but found 0.\'""'","b'Windows 10 Enterprise 1803\r\n.net 4.7.2\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoaded Data, Created FastForestRegression Predictor, Trained Model Successfully\r\nCreated Regression Evaluator under new Direct API\r\nCalled Evaluated on Training or Validation Data Set\r\n- **What happened?**\r\nthrew  ""Expected exactly one column with role \'Score\', but found 0.\'""\r\n- **What did you expect?**\r\nRegression Metrics Dictionary returned\r\n\r\n### Source code / logs\r\nSentimentPredictionTests contains comments to what seems to be similar effect for another evaluator. \r\n\r\n`          // Evaluate.\r\n            // It does not work. It throws error ""Failed to find \'Score\' column"" when Evaluate is called`\r\n\r\nMy cursory review of the source makes it seem it is not possible to specify a ""Score"" role column at the moment. Attempted to decorate the model class a number of different ways to no effect. This could be a redundant issue covered somewhere else I wasn\'t able to identify.\r\n\r\n'"
360079284,906,b'TensorFlowTransform does not implement IDisposable.',b'TensorFlowTransform does not implement IDisposable. \r\n\r\nInstead the Finalizer directly calls the private Dispose() method to free resources. We need to understand the reasoning behind ML.NET Transforms not implementing IDisposable\r\n\r\n[Discussion](https://github.com/dotnet/machinelearning/pull/853#issuecomment-423236224)\r\n\r\n\r\n'
360023244,905,b'Model Saving / Loading memory usage',"b""In reviewing the TensorFlow saving/loading code [PR](https://github.com/dotnet/machinelearning/pull/853) I noticed that we were creating very large byte arrays in the [frozen model case](https://github.com/dotnet/machinelearning/blob/52aff025df29cc02c00999c5ca4a0833a658d142/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L123).  I believe these can be *very* large models (100MB - many GB) so we might approach the upper limit of the size of managed arrays, not to mention the memory usage of shuttling these bytes into a managed array, just so that they can then be interpreted/read into TensorFlow's object model.\r\n\r\nMy understanding of the ModelSaveContext / ModelLoadContext get backed with a ZipArchive.  This will be backed by a stream (file or memory) and thus not load the entire ML.NET model into memory at one time.  As entries are accessed these get loaded as streams which load from disk on demand / decompress on demand.  As such the backing stack for model loading/saving permits a minimal memory footprint for loading and saving models.  The problem comes in with usage.  Many cases where folks are using ReadByteArray they should instead be using a Stream that is constrained to the length of the entry.\r\n\r\nI discussed this a bit with @abgoswam and prototyped a sample stream that would wrap the context's BinaryReader/Writer stream and only expose a region.  I'm sure we have a better impl floating around somewhere.\r\n\r\nI looked a a few of the usage cases of `ReadByteArray` and the following all look suspect of containing large payloads:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Api/SerializableLambdaTransform.cs#L66-L74\r\n\r\nI imagine they payload passed to the `LoadDelegate` could be arbitrarily large and should be streamed.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/307b38f4c86cc31a6a0dbff8c1a302d66f4fe7e7/src/Microsoft.ML.Data/DataLoadSave/PartitionedFileLoader.cs#L226-L234\r\n\r\nIt looks like the byte array gets stored off in a memory stream until it later gets read as files.  I don't see much value in the additional byte-array.  Why not instead keep a stream open to the entry in the ModelLoadContext for the lifetime of the loader?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Transforms/OptionalColumnTransform.cs#L99-L103\r\n\r\nSimilar to above.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Parquet/ParquetLoader.cs#L193-L195\r\n\r\nSimilar to above.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/52aff025df29cc02c00999c5ca4a0833a658d142/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L123-L141\r\nIn the TensorFlowTransform case I don't see a great alternative since the [TF API](https://github.com/tensorflow/tensorflow/blob/3be04971716fcaf0c11ad9262e60efa428553e14/tensorflow/c/c_api.h#L1018-L1020) we call expects a byte buffer and doesn't have a stream-like API for importing the graph (as far as I can tell).  It's possible I'm missing something though.  A slightly hacky alternative would be to make a memory mapped file, write to that, and pass the [pointer](https://docs.microsoft.com/en-us/dotnet/api/microsoft.win32.safehandles.safememorymappedviewhandle?view=netframework-4.7.2#methods) of the memory mapped file to tensorflow.  That way we're never dealing in large byte arrays.  We could have some size threshold at which we switch from using a byte array to a memory mapped file. Since there would likely be some tradeoff to creating the MMF.\r\n\r\n/cc @Zruty0 """
359947109,904,b'Enable unit tests using Inception and ssd_mobilenet TensorFlow models',"b'Upload the models to MyGet with the appropriate license, and enable the unit tests which are currently skipped.'"
359944478,903,b'Pixel extractor transform needs to have a per-channel offset argument',"b'Some TensorFlow models require preprocessing of the image where a different offset is subtracted from every channel. For example: https://github.com/pudae/tensorflow-densenet/blob/master/preprocessing/densenet_preprocessing.py#L39. \r\nThe ML.NET pixel extractor transform only has a global offset parameter, which means that preprocessing would need to be done outside of ML.NET.'"
359855211,902,b'Feature Importance with ML.NET',"b'Hi all,\r\n\r\nI have been revisiting some models recently to deduce feature importance. To remove highly correlated items, features of no importance etc.\r\n\r\nAnd judging from the issues raised so far, this theme has come up already. Such as Feature Importance with ML.NET #599.\r\n\r\nIdeally, it should be possible to run a pipeline task not to generate a full model, but to profile the model data using a method such as nearest neighbour or PCA before rather than after the event.\r\n\r\nWould it be possible to add such a feature (no pun intended:)) to the release road map?\r\n\r\nThanks\r\nFig'"
359666507,898,b'Need to have vector trimming and padding functionality to deal with fixed size text inputs for DNNs.',"b'Convolution based text classification models and fixed length seq2seq models in Tensorflow ( or in any other DNN platform in general) requires fixed length vector of integers as input. However, in ML.Net sentences/documents transform into variable length vectors when split into words/characters.\r\n\r\nTo enable these scenarios, we need to find out a way to trim/pad vector to make them fixed length. May be make a trimming and padding transform.\r\n\r\nThis task item was derived from the investigation of issue #747 '"
359641403,897,b'Bug in pixel extractor transform',b'The values of the blue and green channels are mixed up in lines 530-531 of ImagePixelExtractorTransform.cs.'
359578778,895,b'Native dependencies of ML.NET',"b""We should review and try to unify and document the native dependencies of ML.NET, in particular the VC-runtime.\r\n\r\nIdeally we should try and build the native components in the same way that .NET Core does so that we don't impose any new requirements (eg: installing a different / specific version of the VC redist).\r\n\r\nI checked a few DLLs using link /dump /imports and noticed a lot of instances of VCRUNTIME140 which we do not depend on for coreclr/clrcompression/clrjit/etc.\r\n\r\nI just did this check for Windows but we should also look at a similar thing on linux.\r\n\r\nWe should also examine binary redists (like TensorFlow) so that we can understand if they are different and at least document their dependencies.\r\n\r\n/cc @shauheen @tannergooding @danmosemsft @eerhardt """
359508125,894,"b'Build is failing (CMake issue for VS Dev console, VS version issue for Windows console)'","b'### System information\r\n\r\n- **OS version/distro**:  Microsoft Windows [Version 10.0.16299.492]\r\n- **.NET Version (eg., dotnet --info)**:   2.1.401\r\n\r\n### Issue\r\n\r\n- **What did you do?**  cloned the repo\r\n- **What happened?**   build.cmd failed :(\r\n- **What did you expect?**   build.cmd not to fail \r\n\r\n### Source code / logs\r\nTried both Developer CMD for VS 2017, then vanilla cmd.   \r\nBelow is the log for Developer CMD (CMake issue).   \r\nFor Vanilla CMD, the error is that it incorrectly identifies VS version and tries to look for 14.0 (pasted below after ""=======""). \r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning>build.cmd\r\nInstalling dotnet cli...\r\nRestoring BuildTools version 3.0.0-preview1-03129-01...\r\nInitializing BuildTools...\r\nDone initializing tools.\r\nRunning: c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\Tools\\dotnetcli\\dotnet msbuild /nologo /verbosity:minimal /clp:Summary /maxcpucount /l:BinClashLogger,Tools\\Microsoft.DotNet.Build.Tasks.dll;LogFile=binclash.log /p:Configuration=Debug  /flp:v=normal  /flp2:warningsonly;logfile=msbuild.wrn  /flp3:errorsonly;logfile=msbuild.err  build.proj\r\n  Restoring all projects...\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\Microsoft.ML.Api.csproj...\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj...\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj...\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj...\r\n  Installing StyleCop.Analyzers 1.1.0-beta008.\r\n  Installing NETStandard.Library 2.0.3.\r\n  Installing System.Threading.Tasks.Dataflow 4.8.0.\r\n  Installing System.CodeDom 4.4.0.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj.nuget.g.targets.\r\n  Restore completed in 8,89 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj...\r\n  Restore completed in 8,89 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Api\\Microsoft.ML.Api.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Api\\Microsoft.ML.Api.csproj.nuget.g.targets.\r\n  Restore completed in 9,48 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\Microsoft.ML.Api.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj...\r\n  Restore completed in 498,26 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.HalLearners\\Microsoft.ML.HalLearners.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj.nuget.g.targets.\r\n  Restore completed in 75,34 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj.\r\n  Restore completed in 648,76 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj...\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj.nuget.g.targets.\r\n  Restore completed in 208,36 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj.\r\n  Installing System.Drawing.Common 4.5.0.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.LightGBM\\Microsoft.ML.LightGBM.csproj...\r\n  Installing LightGBM 2.1.2.2.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.LightGBM\\Microsoft.ML.LightGBM.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.LightGBM\\Microsoft.ML.LightGBM.csproj.nuget.g.targets.\r\n  Restore completed in 1,8 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.LightGBM\\Microsoft.ML.LightGBM.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj.nuget.g.targets.\r\n  Restore completed in 7,31 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Onnx\\Microsoft.ML.Onnx.csproj...\r\n  Installing Google.Protobuf 3.5.1.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj.nuget.g.targets.\r\n  Restore completed in 2,9 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Onnx\\Microsoft.ML.Onnx.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Onnx\\Microsoft.ML.Onnx.csproj.nuget.g.targets.\r\n  Restore completed in 318,75 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Onnx\\Microsoft.ML.Onnx.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj.nuget.g.targets.\r\n  Restore completed in 52,38 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PipelineInference\\Microsoft.ML.PipelineInference.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.PipelineInference\\Microsoft.ML.PipelineInference.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.PipelineInference\\Microsoft.ML.PipelineInference.csproj.nuget.g.targets.\r\n  Restore completed in 57,72 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PipelineInference\\Microsoft.ML.PipelineInference.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj.nuget.g.targets.\r\n  Restore completed in 43,02 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.StandardLearners\\Microsoft.ML.StandardLearners.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.StandardLearners\\Microsoft.ML.StandardLearners.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.StandardLearners\\Microsoft.ML.StandardLearners.csproj.nuget.g.targets.\r\n  Restore completed in 46,57 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.StandardLearners\\Microsoft.ML.StandardLearners.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj.nuget.g.targets.\r\n  Restore completed in 52,58 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj.nuget.g.targets.\r\n  Restore completed in 49,52 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj...\r\n  Installing Parquet.Net 2.1.3.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj.nuget.g.targets.\r\n  Restore completed in 77,24 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML\\Microsoft.ML.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML\\Microsoft.ML.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML\\Microsoft.ML.csproj.nuget.g.targets.\r\n  Restore completed in 58,42 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML\\Microsoft.ML.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj.nuget.g.targets.\r\n  Restore completed in 1,15 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj...\r\n  Installing System.Security.Cryptography.Cng 4.2.0.\r\n  Installing System.Security.Cryptography.Csp 4.0.0.\r\n  Installing System.Security.Cryptography.OpenSsl 4.0.0.\r\n  Installing System.Diagnostics.DiagnosticSource 4.0.0.\r\n  Installing runtime.native.System.Net.Http 4.0.1.\r\n  Installing runtime.native.System.Security.Cryptography 4.0.0.\r\n  Installing runtime.native.System.IO.Compression 4.1.0.\r\n  Installing System.Buffers 4.0.0.\r\n  Installing System.Xml.XmlSerializer 4.0.11.\r\n  Installing System.Globalization.Extensions 4.0.1.\r\n  Installing System.Security.Cryptography.X509Certificates 4.1.0.\r\n  Installing System.Net.Http 4.1.0.\r\n  Installing System.Security.Cryptography.Algorithms 4.2.0.\r\n  Installing System.Security.Cryptography.Encoding 4.0.0.\r\n  Installing System.IO.Compression 4.1.0.\r\n  Installing System.Collections.Concurrent 4.0.12.\r\n  Installing xunit.runner.visualstudio 2.3.1.\r\n  Installing xunit 2.3.1.\r\n  Installing System.IO.Compression.ZipFile 4.0.1.\r\n  Installing System.Threading.Timer 4.0.1.\r\n  Installing Microsoft.NETCore.App 2.1.0.\r\n  Installing Microsoft.NET.Test.Sdk 15.8.0.\r\n  Installing xunit.analyzers 0.7.0.\r\n  Installing xunit.assert 2.3.1.\r\n  Installing xunit.core 2.3.1.\r\n  Installing Microsoft.NETCore.Platforms 2.1.0.\r\n  Installing BenchmarkDotNet 0.11.0.\r\n  Installing Microsoft.NETCore.Targets 2.1.0.\r\n  Installing Microsoft.NETCore.DotNetHostPolicy 2.1.0.\r\n  Installing Microsoft.CSharp 4.5.0.\r\n  Installing System.Composition 1.2.0.\r\n  Installing Microsoft.CodeAnalysis.CSharp.Workspaces 2.8.2.\r\n  Installing Microsoft.CodeCoverage 15.8.0.\r\n  Installing Microsoft.TestPlatform.TestHost 15.8.0.\r\n  Installing xunit.extensibility.execution 2.3.1.\r\n  Installing System.Reflection.Metadata 1.5.0.\r\n  Installing xunit.extensibility.core 2.3.1.\r\n  Installing Microsoft.NETCore.DotNetHostResolver 2.1.0.\r\n  Installing System.Xml.XPath.XmlDocument 4.3.0.\r\n  Installing System.Xml.XmlSerializer 4.3.0.\r\n  Installing System.Composition.Hosting 1.2.0.\r\n  Installing System.Composition.Convention 1.2.0.\r\n  Installing System.Collections.Immutable 1.4.0.\r\n  Installing System.Management 4.5.0.\r\n  Installing System.Composition.AttributedModel 1.2.0.\r\n  Installing System.Composition.Runtime 1.2.0.\r\n  Installing Microsoft.DotNet.InternalAbstractions 1.0.0.\r\n  Installing System.Composition.TypedParts 1.2.0.\r\n  Installing Microsoft.CodeAnalysis.Workspaces.Common 2.8.2.\r\n  Installing Microsoft.CodeAnalysis.CSharp 2.8.2.\r\n  Installing Microsoft.DotNet.PlatformAbstractions 1.1.1.\r\n  Installing Microsoft.Extensions.DependencyModel 1.0.3.\r\n  Installing Newtonsoft.Json 9.0.1.\r\n  Installing Microsoft.TestPlatform.ObjectModel 15.8.0.\r\n  Installing Microsoft.Win32.Registry 4.5.0.\r\n  Installing CommandLineParser 2.2.1.\r\n  Installing xunit.abstractions 2.0.1.\r\n  Installing Microsoft.NETCore.DotNetAppHost 2.1.0.\r\n  Installing Microsoft.CodeAnalysis.Common 2.8.2.\r\n  Installing System.Diagnostics.Contracts 4.3.0.\r\n  Installing System.Net.Primitives 4.0.11.\r\n  Installing System.Linq.Parallel 4.3.0.\r\n  Installing System.CodeDom 4.5.0.\r\n  Installing Microsoft.DotNet.PlatformAbstractions 1.0.3.\r\n  Installing System.Linq 4.1.0.\r\n  Installing System.AppContext 4.1.0.\r\n  Installing System.Dynamic.Runtime 4.0.11.\r\n  Installing System.Reflection.TypeExtensions 4.1.0.\r\n  Installing System.Reflection.Extensions 4.0.1.\r\n  Installing System.Runtime.InteropServices.RuntimeInformation 4.0.0.\r\n  Installing Microsoft.CSharp 4.0.1.\r\n  Installing System.Security.Principal.Windows 4.5.0.\r\n  Installing System.Security.AccessControl 4.5.0.\r\n  Installing System.ObjectModel 4.0.12.\r\n  Installing System.Reflection.TypeExtensions 4.1.0-rc2-24027.\r\n  Installing System.Collections 4.0.11-rc2-24027.\r\n  Installing System.Text.Encoding.Extensions 4.0.11.\r\n  Installing System.Linq 4.1.0-rc2-24027.\r\n  Installing System.Reflection.Extensions 4.0.1-rc2-24027.\r\n  Installing System.Linq.Expressions 4.1.0.\r\n  Installing System.Text.RegularExpressions 4.1.0.\r\n  Installing System.Diagnostics.Debug 4.0.11-rc2-24027.\r\n  Installing System.Resources.ResourceManager 4.0.1-rc2-24027.\r\n  Installing System.Runtime.Serialization.Primitives 4.1.1.\r\n  Installing System.Xml.XDocument 4.0.11.\r\n  Installing System.Globalization 4.0.11-rc2-24027.\r\n  Installing System.Console 4.0.0-rc2-24027.\r\n  Installing System.Xml.ReaderWriter 4.0.11.\r\n  Installing System.Reflection 4.1.0-rc2-24027.\r\n  Installing System.Runtime.Extensions 4.1.0-rc2-24027.\r\n  Installing System.IO 4.1.0-rc2-24027.\r\n  Installing System.Linq.Expressions 4.0.11-rc2-24027.\r\n  Installing System.Runtime 4.1.0-rc2-24027.\r\n  Installing System.ComponentModel.EventBasedAsync 4.0.11.\r\n  Installing System.Threading.Thread 4.0.0.\r\n  Installing System.Reflection.Metadata 1.3.0.\r\n  Installing System.Diagnostics.TextWriterTraceListener 4.0.0.\r\n  Installing System.Runtime.Loader 4.0.0.\r\n  Installing System.Diagnostics.TraceSource 4.0.0.\r\n  Installing System.Diagnostics.Process 4.1.0.\r\n  Installing System.Xml.XPath.XmlDocument 4.0.1.\r\n  Installing System.ComponentModel.TypeConverter 4.1.0.\r\n  Installing System.Runtime.Serialization.Json 4.0.2.\r\n  Installing NETStandard.Library 1.6.0.\r\n  Installing System.Reflection.Emit 4.0.1.\r\n  Installing System.Reflection.Emit.ILGeneration 4.0.1.\r\n  Installing System.Reflection.Emit.Lightweight 4.0.1.\r\n  Installing System.Diagnostics.Tools 4.0.1.\r\n  Installing System.Threading.Tasks.Extensions 4.0.0.\r\n  Installing System.Collections.Immutable 1.2.0.\r\n  Installing Microsoft.Win32.Primitives 4.0.1.\r\n  Installing runtime.native.System 4.0.0.\r\n  Installing System.Threading.ThreadPool 4.0.10.\r\n  Installing Microsoft.Win32.Registry 4.0.0.\r\n  Installing System.Text.Encoding 4.0.11-rc2-24027.\r\n  Installing System.Reflection.Primitives 4.0.1-rc2-24027.\r\n  Installing System.Security.Cryptography.Primitives 4.0.0.\r\n  Installing System.Xml.XPath 4.0.1.\r\n  Installing System.Xml.XmlDocument 4.0.1.\r\n  Installing System.ComponentModel 4.0.1.\r\n  Installing System.Threading.Tasks 4.0.11-rc2-24027.\r\n  Installing System.ComponentModel.Primitives 4.1.0.\r\n  Installing System.Collections.Specialized 4.0.1.\r\n  Installing System.Reflection.Emit 4.0.1-rc2-24027.\r\n  Installing System.Private.DataContractSerialization 4.1.1.\r\n  Installing System.Threading 4.0.11-rc2-24027.\r\n  Installing System.ObjectModel 4.0.12-rc2-24027.\r\n  Installing System.Console 4.0.0.\r\n  Installing System.Reflection.Emit.ILGeneration 4.0.1-rc2-24027.\r\n  Installing System.Diagnostics.Tracing 4.1.0.\r\n  Installing System.Net.Sockets 4.1.0.\r\n  Installing System.Globalization.Calendars 4.0.1.\r\n  Installing System.Runtime.Numerics 4.0.1.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj.nuget.g.targets.\r\n  Restore completed in 1,11 min for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj.nuget.g.targets.\r\n  Restore completed in 1,14 min for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CpuMath.UnitTests.netstandard\\Microsoft.ML.CpuMath.UnitTests.netstandard.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CpuMath.UnitTests.netstandard\\Microsoft.ML.CpuMath.UnitTests.netstandard.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CpuMath.UnitTests.netstandard\\Microsoft.ML.CpuMath.UnitTests.netstandard.csproj.nuget.g.targets.\r\n  Restore completed in 712,12 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CpuMath.UnitTests.netstandard\\Microsoft.ML.CpuMath.UnitTests.netstandard.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj...\r\n  Installing FSharp.Core 4.5.2.\r\n  Installing System.ValueTuple 4.4.0.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj.nuget.g.targets.\r\n  Restore completed in 1,94 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.InferenceTesting\\Microsoft.ML.InferenceTesting.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.InferenceTesting\\Microsoft.ML.InferenceTesting.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.InferenceTesting\\Microsoft.ML.InferenceTesting.csproj.nuget.g.targets.\r\n  Restore completed in 331,06 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.InferenceTesting\\Microsoft.ML.InferenceTesting.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj...\r\n  Installing Microsoft.Win32.SystemEvents 4.5.0.\r\n  Installing MlNetMklDeps 0.0.0.5.\r\n  Installing Microsft.ML.TensorFlow.TestModels 0.0.2-test.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.HalLearners\\Microsoft.ML.HalLearners.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.HalLearners\\Microsoft.ML.HalLearners.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj.nuget.g.targets.\r\n  Restore completed in 1,99 min for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.HalLearners\\Microsoft.ML.HalLearners.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj...\r\n  Restore completed in 2,15 min for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj...\r\n  Restore completed in 48,56 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj...\r\n  Restore completed in 43,41 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj.\r\n  Restoring packages for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\tools-local\\Microsoft.ML.CodeAnalyzer\\Microsoft.ML.CodeAnalyzer.csproj...\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj.nuget.g.targets.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj.nuget.g.targets.\r\n  Restore completed in 193,08 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj.\r\n  Restore completed in 204,37 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj.\r\n  Restore completed in 294,5 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj.\r\n  Installing System.Reflection.TypeExtensions 4.4.0.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CodeAnalyzer\\Microsoft.ML.CodeAnalyzer.csproj.nuget.g.props.\r\n  Generating MSBuild file c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.CodeAnalyzer\\Microsoft.ML.CodeAnalyzer.csproj.nuget.g.targets.\r\n  Restore completed in 3,6 sec for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\tools-local\\Microsoft.ML.CodeAnalyzer\\Microsoft.ML.CodeAnalyzer.csproj.\r\n  Building redist components...\r\n  Downloading \'https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.10.0.zip\' to \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0.zip\'.\r\n  Downloading \'https://github.com/tensorflow/tensorflow/blob/master/LICENSE\' to \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\LICENSE\'.\r\n  Generating checksum for \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0.zip\' into \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0.zip.sha\'...\r\n  Decompressing \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0.zip\' into \'c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\'...\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\lib\\tensorflow.dll -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\runtimes\\win-x64\\native\\tensorflow.dll\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\include\\tensorflow\\c\\LICENSE -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\THIRD_PARTY_NOTICES.txt\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\\\LICENSE -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\LICENSE.txt\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\lib\\tensorflow.dll -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/x64.Debug\\Native\\tensorflow.dll\r\n  Building native components...\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native\r\n  **********************************************************************\r\n  ** Visual Studio 2017 Developer Command Prompt v15.0.26430.15\r\n  ** Copyright (c) 2017 Microsoft Corporation\r\n  **********************************************************************\r\n  [vcvarsall.bat] Environment initialized for: \'x86_x64\'\r\n  Commencing native build of dotnet/machinelearning\r\n\r\n  Calling ""c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\\\gen-buildsys-win.bat"" ""c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\"" ""15 2017"" x64\r\n  -- Selecting Windows SDK version 10.0.15063.0 to target Windows 10.0.16299.\r\n  -- The C compiler identification is unknown\r\n  -- The CXX compiler identification is unknown\r\n  CMake Error in CMakeLists.txt:\r\n    No CMAKE_C_COMPILER could be found.\r\n\r\n\r\n\r\n  CMake Error in CMakeLists.txt:\r\n    No CMAKE_CXX_COMPILER could be found.\r\n\r\n\r\n\r\n  -- Configuring incomplete, errors occurred!\r\n  See also ""C:/Users/mbilenko/Documents/GitHub/machinelearning/bin/obj/x64.Debug/Native/CMakeFiles/CMakeOutput.log"".\r\n  See also ""C:/Users/mbilenko/Documents/GitHub/machinelearning/bin/obj/x64.Debug/Native/CMakeFiles/CMakeError.log"".\r\n  Failed to generate native component build project!\r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj(61,5): error MSB3073: The command """"c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd"" Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native"" exited with code 1.\r\n\r\nBuild FAILED.\r\n\r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj(61,5): error MSB3073: The command """"c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd"" Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native"" exited with code 1.\r\n    0 Warning(s)\r\n    1 Error(s)\r\n\r\nTime Elapsed 00:02:45.35\r\nCommand execution failed with exit code 1.\r\n \r\n=========   Vanilla CMD log: \r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning>build.cmd\r\nTools are already initialized.\r\nRunning: c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\Tools\\dotnetcli\\dotnet msbuild /nologo /verbosity:minimal /clp:Summary /maxcpucount /l:BinClashLogger,Tools\\Microsoft.DotNet.Build.Tasks.dll;LogFile=binclash.log /p:Configuration=Debug  /flp:v=normal  /flp2:warningsonly;logfile=msbuild.wrn  /flp3:errorsonly;logfile=msbuild.err  build.proj\r\n  Restoring all projects...\r\n  Restore completed in 51,9 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Core\\Microsoft.ML.Core.csproj.\r\n  Restore completed in 51,9 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.CpuMath\\Microsoft.ML.CpuMath.csproj.\r\n  Restore completed in 59,8 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Console\\Microsoft.ML.Console.csproj.\r\n  Restore completed in 59,8 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\Microsoft.ML.Api.csproj.\r\n  Restore completed in 3 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.FastTree\\Microsoft.ML.FastTree.csproj.\r\n  Restore completed in 3,02 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.HalLearners\\Microsoft.ML.HalLearners.csproj.\r\n  Restore completed in 3,27 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Ensemble\\Microsoft.ML.Ensemble.csproj.\r\n  Restore completed in 2,76 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Data\\Microsoft.ML.Data.csproj.\r\n  Restore completed in 1,65 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Maml\\Microsoft.ML.Maml.csproj.\r\n  Restore completed in 2,08 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\Microsoft.ML.ImageAnalytics.csproj.\r\n  Restore completed in 25,71 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.KMeansClustering\\Microsoft.ML.KMeansClustering.csproj.\r\n  Restore completed in 3,67 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.LightGBM\\Microsoft.ML.LightGBM.csproj.\r\n  Restore completed in 7,48 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Onnx\\Microsoft.ML.Onnx.csproj.\r\n  Restore completed in 2,37 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PCA\\Microsoft.ML.PCA.csproj.\r\n  Restore completed in 3,08 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Parquet\\Microsoft.ML.Parquet.csproj.\r\n  Restore completed in 3,51 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.PipelineInference\\Microsoft.ML.PipelineInference.csproj.\r\n  Restore completed in 10,09 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.StandardLearners\\Microsoft.ML.StandardLearners.csproj.\r\n  Restore completed in 2,44 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.ResultProcessor\\Microsoft.ML.ResultProcessor.csproj.\r\n  Restore completed in 3,77 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Sweeper\\Microsoft.ML.Sweeper.csproj.\r\n  Restore completed in 2,64 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.TensorFlow\\Microsoft.ML.TensorFlow.csproj.\r\n  Restore completed in 7,89 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Transforms\\Microsoft.ML.Transforms.csproj.\r\n  Restore completed in 9,61 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML\\Microsoft.ML.csproj.\r\n  Restore completed in 16,14 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CpuMath.UnitTests.netstandard\\Microsoft.ML.CpuMath.UnitTests.netstandard.csproj.\r\n  Restore completed in 11,33 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Core.Tests\\Microsoft.ML.Core.Tests.csproj.\r\n  Restore completed in 27,55 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Benchmarks\\Microsoft.ML.Benchmarks.csproj.\r\n  Restore completed in 27,41 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.CodeAnalyzer.Tests\\Microsoft.ML.CodeAnalyzer.Tests.csproj.\r\n  Restore completed in 3,56 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.InferenceTesting\\Microsoft.ML.InferenceTesting.csproj.\r\n  Restore completed in 3,9 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Sweeper.Tests\\Microsoft.ML.Sweeper.Tests.csproj.\r\n  Restore completed in 6,47 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Predictor.Tests\\Microsoft.ML.Predictor.Tests.csproj.\r\n  Restore completed in 21,44 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.FSharp.Tests\\Microsoft.ML.FSharp.Tests.fsproj.\r\n  Restore completed in 4,05 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.TestFramework\\Microsoft.ML.TestFramework.csproj.\r\n  Restore completed in 4,36 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\tools-local\\Microsoft.ML.CodeAnalyzer\\Microsoft.ML.CodeAnalyzer.csproj.\r\n  Restore completed in 4,97 ms for c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\test\\Microsoft.ML.Tests\\Microsoft.ML.Tests.csproj.\r\n  Building redist components...\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\lib\\tensorflow.dll -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\runtimes\\win-x64\\native\\tensorflow.dll\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\include\\tensorflow\\c\\LICENSE -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\THIRD_PARTY_NOTICES.txt\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\\\LICENSE -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj//packages/Microsoft.ML.TensorFlow.Redist\\LICENSE.txt\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/obj/AnyCPU.Debug\\Microsoft.ML.TensorFlow.Redist\\libtensorflow-cpu-windows-x86_64-1.10.0\\lib\\tensorflow.dll -> c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\bin/x64.Debug\\Native\\tensorflow.dll\r\n  Building native components...\r\n  c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native\r\n  """"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools\\\\VsDevCmd.bat"""" \xd0\xbd\xd0\xb5 \xd1\x8f\xd0\xb2\xd0\xbb\xd1\x8f\xd0\xb5\xd1\x82\xd1\x81\xd1\x8f \xd0\xb2\xd0\xbd\xd1\x83\xd1\x82\xd1\x80\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xb5\xd0\xb9 \xd0\xb8\xd0\xbb\xd0\xb8 \xd0\xb2\xd0\xbd\xd0\xb5\xd1\x88\xd0\xbd\xd0\xb5\xd0\xb9\r\n  \xd0\xba\xd0\xbe\xd0\xbc\xd0\xb0\xd0\xbd\xd0\xb4\xd0\xbe\xd0\xb9, \xd0\xb8\xd1\x81\xd0\xbf\xd0\xbe\xd0\xbb\xd0\xbd\xd1\x8f\xd0\xb5\xd0\xbc\xd0\xbe\xd0\xb9 \xd0\xbf\xd1\x80\xd0\xbe\xd0\xb3\xd1\x80\xd0\xb0\xd0\xbc\xd0\xbc\xd0\xbe\xd0\xb9 \xd0\xb8\xd0\xbb\xd0\xb8 \xd0\xbf\xd0\xb0\xd0\xba\xd0\xb5\xd1\x82\xd0\xbd\xd1\x8b\xd0\xbc \xd1\x84\xd0\xb0\xd0\xb9\xd0\xbb\xd0\xbe\xd0\xbc.\r\nEXEC : error : Visual Studio 2015 or 2017 required [c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj]\r\n         Please see https://github.com/dotnet/machinelearning/tree/master/Documentation for build instructions.\r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj(61,5): error MSB3073: The command """"c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd"" Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native"" exited with code 1.\r\n\r\nBuild FAILED.\r\n\r\nEXEC : error : Visual Studio 2015 or 2017 required [c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj]\r\nc:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.proj(61,5): error MSB3073: The command """"c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\src\\Native\\build.cmd"" Debug x64 --mkllibpath c:\\Users\\mbilenko\\Documents\\GitHub\\machinelearning\\packages/mlnetmkldeps\\0.0.0.5\\runtimes\\win-x64\\native"" exited with code 1.\r\n    0 Warning(s)\r\n    2 Error(s)\r\n\r\nTime Elapsed 00:00:03.63\r\nCommand execution failed with exit code 1.\r\n\r\n\r\n'"
359315860,893,b'ONNX/Sonoma - add strong name signing to dlls.',b'ML.Net requires strong-name signed assemblies for loading dlls.'
359315596,892,b'ONNX/Sonoma -- Port to .NetStandard',b'Replace the windows only  C++/CLI layer for unmanged code interop with Pinvoke calls to  comply with .NetStandard and remove .NetFramework dependency'
359315191,891,b'ONNX/Sonoma - remove dependency on Python model_export utility',"b""Sonoma ships with a model_export utility to generates a manifest.json file containing input/output shapes, names, and types.\r\n\r\nIt's not required for ONNX models in ml.net, and causes extra user hops -- this dependency needs to be removed."""
359246664,889,b'Hot linking to a UCI dataset',"b'I noticed we are hot linking to a UCI dataset:\r\nhttps://github.com/dotnet/machinelearning/blob/a6e3c0a79c225c84f882cb8c8c6013f070cf0e7a/build.proj#L80\r\n\r\nWe should get CELA approval for hot linking, and if possible get approval to redistribute the full dataset in either the [/test/data/](https://github.com/dotnet/machinelearning/tree/6ed90b713f0dbf51a355dab189988554991a7b16/test/data) folder (if small), or the CDN (if large). \r\n\r\nWe should still explore Git LFS for hosting datasets. [[relevant discussion](https://github.com/dotnet/machinelearning/pull/198#issuecomment-391042287)]\r\n\r\n\r\n'"
359167602,885,b'Create IDataView from unsafe pointer like float*',"b""There is a CreateDataView function which can accept a customized data type (`IList<TRow> data`) and optionally a schema (`SchemaDefinition schemaDefinition`). Is it possible to pass a data structure like\r\n`class NativeTensor{\r\n  long size;\r\n  float* addr;\r\n};`\r\nto `IList<TRow> data` with a proper definition of schema. I have searched through the code base but didn't find any test with `schemaDefinition!=null`."""
359004976,884,b'Setting column weights in KmeansPlusPlus',"b""I find no clue as to how column weights can be adjusted for KmeansPlusPlus or any other type of ML. Gitter board shows no answer after several days. Is there an example? I did download the source code for ML.net and found nothing in the KMeans constructors. I assume ML.net will be doing this on the import or is it something not implemented so far? What is the road map to making this usable for where  KmeansPlusPlus needs to be tuned?\r\n\r\nIn Accord.net it's WeightColumn = (new double[] { .95, 0.05, .05, .95 }) . There is some WeightColumn to as a string, but no documentation how it would be used.\r\n\r\npublic Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }\r\n"""
358831623,878,b'Remove public CmdParser.GetConsoleWindowWidth()',"b""See https://github.com/dotnet/machinelearning/blob/510382d2e3685fcf76ff22ea311c025df0f8fb27/src/Microsoft.ML.Core/CommandLine/CmdParser.cs#L506-L568\r\n\r\nThis function is available on the `System.Console` class. We don't need to provide an API for this ourselves, plus we are returning the wrong thing in ML.NET (which builds with `CORECLR` defined)."""
358814814,875,b'Convert Prior and Random trainers to estimators',"b'Convert Prior and Random trainers to estimators as part of the API overhaul project, and write tests for the new estimators.'"
358786355,873,b'Failure while using WordEmbeddings [Regression]',"b""I am using Maml.MainAll(string cmd) for producing the benchmark results.\r\n\r\nThe command that I tried is \r\n```\r\nmaml.exe CV \r\ntr=OVA{p=AveragedPerceptron{iter=10}}\r\nk=5 \r\nloader=TextLoader{quote=- sparse=- col=Label:R4:0 col=rev_id:TX:1 col=comment:TX:2 col=logged_in:BL:4 col=ns:TX:5 col=sample:TX:6 col=split:TX:7 col=year:R4:3 header=+}\r\ndata=c:\\git\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Benchmarks\\netcoreapp2.1\\491da934-573a-4301-bb13-570ecee3aed2\\bin\\Release\\netcoreapp2.1\\external\\WikiDetoxAnnotated160kRows.tsv \r\nxf=Convert{col=logged_in type=R4} xf=CategoricalTransform{col=ns} xf=TextTransform\r\n{col=FeaturesText:comment tokens=+ wordExtractor=NGramExtractorTransform{ngram=2}} \r\nxf=WordEmbeddingsTransform{col=FeaturesWordEmbedding:FeaturesText_TransformedText \r\nmodel=FastTextWikipedia300D} xf=Concat\r\n{col=Features:FeaturesText,FeaturesWordEmbedding,logged_in,ns}\r\n```\r\nThe error I get is \r\n```\r\n--- Command line args ---\r\nCV tr=OVA{p=AveragedPerceptron{iter=10}} k=5 loader=TextLoader{quote=- sparse=- col=Label:R4:0 col=rev_id:TX:1 col=comment:TX:2 col=logged_in:BL:4 col=ns:TX:5 col=sample:TX:6 col=split:TX:7 col=year:R4:3 header=+} data= c:\\git\\machinelearning\\bin\\AnyCPU.Release\\Microsoft.ML.Benchmarks\\netcoreapp2.1\\95c44c13-fcff-45f8-8427-370a4bb30f47\\bin\\Release\\netcoreapp2.1\\external\\WikiDetoxAnnotated160kRows.tsv xf=Convert{col=logged_in type=R4} xf=CategoricalTransform{col=ns} xf=TextTransform{col=FeaturesText:comment tokens=+ wordExtractor=NGramExtractorTransform{ngram=2}} xf=WordEmbeddingsTransform{col=FeaturesWordEmbedding:FeaturesText_TransformedText model=FastTextWikipedia300D} xf=Concat{col=Features:FeaturesText,FeaturesWordEmbedding,logged_in,ns}\r\n--- Exception message ---\r\n(1) Unexpected exception: One or more errors occurred. (Exception has been thrown by the target of an invocation.) (Exception has been thrown by the target of an invocation.) (Exception has been thrown by the target of an invocation.) (Exception has been thrown by the target of an invocation.) (Exception has been thrown by the target of an invocation.), 'System.AggregateException'\r\n   at System.Threading.Tasks.Task.WaitAllCore(Task[] tasks, Int32 millisecondsTimeout, CancellationToken cancellationToken)\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.GetCrossValidationTasks() in c:\\git\\machinelearning\\src\\Microsoft.ML.Data\\Commands\\CrossValidationCommand.cs:line 503\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.RunCore(IChannel ch, String cmd) in c:\\git\\machinelearning\\src\\Microsoft.ML.Data\\Commands\\CrossValidationCommand.cs:line 200\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.Run() in c:\\git\\machinelearning\\src\\Microsoft.ML.Data\\Commands\\CrossValidationCommand.cs:line 130\r\n   at Microsoft.ML.Runtime.Tools.Maml.MainCore(TlcEnvironment env, String args, Boolean alwaysPrintStacktrace) in c:\\git\\machinelearning\\src\\Microsoft.ML.Maml\\MAML.cs:line 140\r\n(2) Unexpected exception: Exception has been thrown by the target of an invocation., 'System.Reflection.TargetInvocationException'\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs) in c:\\git\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 212\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra) in c:\\git\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 977\r\n   at Microsoft.ML.Runtime.ComponentCatalog.CreateInstance[TRes](IHostEnvironment env, Type signatureType, String name, String options, Object[] extra) in c:\\git\\machinelearning\\src\\Microsoft.ML.Core\\ComponentModel\\ComponentCatalog.cs:line 901\r\n   at Microsoft.ML.Runtime.CommandLine.CmdParser.ComponentFactoryFactory.ComponentFactory`2.CreateComponent(IHostEnvironment env, TArg1 argument1) in c:\\git\\machinelearning\\src\\Microsoft.ML.Core\\CommandLine\\CmdParser.cs:line 2659\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.CreateRoleMappedData(IHostEnvironment env, IChannel ch, IDataView data, ITrainer trainer) in c:\\git\\machinelearning\\src\\Microsoft.ML.Data\\Commands\\CrossValidationCommand.cs:line 265\r\n   at Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.RunFold(Int32 fold) in c:\\git\\machinelearning\\src\\Microsoft.ML.Data\\Commands\\CrossValidationCommand.cs:line 524\r\n   at System.Threading.Tasks.Task`1.InnerInvoke()\r\n   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\r\n(3) Unexpected exception: Source array was not long enough. Check the source index, length, and the array's lower bounds.\r\nParameter name: sourceArray, 'System.ArgumentException'\r\n   at System.Array.Copy(Array sourceArray, Int32 sourceIndex, Array destinationArray, Int32 destinationIndex, Int32 length, Boolean reliable)\r\n   at Microsoft.ML.Runtime.Internal.Utilities.BigArray`1.AddRange(T[] src, Int32 length) in c:\\git\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\BigArray.cs:line 337\r\n   at Microsoft.ML.Runtime.Data.WordEmbeddingsTransform.GetVocabularyDictionary() in c:\\git\\machinelearning\\src\\Microsoft.ML.Transforms\\Text\\WordEmbeddingsTransform.cs:line 436\r\n   at Microsoft.ML.Runtime.Data.WordEmbeddingsTransform..ctor(IHostEnvironment env, Arguments args, IDataView input) in c:\\git\\machinelearning\\src\\Microsoft.ML.Transforms\\Text\\WordEmbeddingsTransform.cs:line 154\r\n\r\n```\r\n\r\nI also tried it using Microsoft.console proj  but I get similar results.\r\n\r\nlonger call stack\r\n```\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Contracts.DbgFailCore(string msg, Microsoft.ML.Runtime.IExceptionContext ctx) Line 772\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Contracts.DbgFail(Microsoft.ML.Runtime.IExceptionContext ctx) Line 779\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.Contracts.Assert(Microsoft.ML.Runtime.IExceptionContext ctx, bool f) Line 834\tC#\r\n>\tMicrosoft.ML.Transforms.dll!Microsoft.ML.Runtime.Data.WordEmbeddingsTransform.Model.AddWordVector(Microsoft.ML.Runtime.IChannel ch, string word, float[] wordVector) Line 101\tC#\r\n \tMicrosoft.ML.Transforms.dll!Microsoft.ML.Runtime.Data.WordEmbeddingsTransform.GetVocabularyDictionary() Line 433\tC#\r\n \tMicrosoft.ML.Transforms.dll!Microsoft.ML.Runtime.Data.WordEmbeddingsTransform.WordEmbeddingsTransform(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.Data.WordEmbeddingsTransform.Arguments args, Microsoft.ML.Runtime.Data.IDataView input) Line 154\tC#\r\n \t[Native to Managed Transition]\t\r\n \t[Managed to Native Transition]\t\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(object[] ctorArgs) Line 209\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(Microsoft.ML.Runtime.IHostEnvironment env, object args, object[] extra) Line 233\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance<Microsoft.ML.Runtime.Data.IDataTransform>(Microsoft.ML.Runtime.IHostEnvironment env, System.Type signatureType, out Microsoft.ML.Runtime.Data.IDataTransform result, string name, string options, object[] extra) Line 977\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.ComponentCatalog.CreateInstance<Microsoft.ML.Runtime.Data.IDataTransform>(Microsoft.ML.Runtime.IHostEnvironment env, System.Type signatureType, string name, string options, object[] extra) Line 901\tC#\r\n \tMicrosoft.ML.Core.dll!Microsoft.ML.Runtime.CommandLine.CmdParser.ComponentFactoryFactory.ComponentFactory<Microsoft.ML.Runtime.Data.IDataView, Microsoft.ML.Runtime.Data.IDataTransform>.CreateComponent(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.Data.IDataView argument1) Line 2659\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.CrossValidationCommand.CreateRoleMappedData(Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.IChannel ch, Microsoft.ML.Runtime.Data.IDataView data, Microsoft.ML.Runtime.ITrainer trainer) Line 266\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.RunFold(int fold) Line 524\tC#\r\n \tMicrosoft.ML.Data.dll!Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.GetCrossValidationTasks.AnonymousMethod__0() Line 494\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task<Microsoft.ML.Runtime.Data.CrossValidationCommand.FoldHelper.FoldResult>.InnerInvoke() Line 621\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state) Line 145\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.Tasks.Task.ExecuteWithThreadLocal(ref System.Threading.Tasks.Task currentTaskSlot) Line 2454\tC#\r\n \tSystem.Private.CoreLib.dll!System.Threading.ThreadPoolWorkQueue.Dispatch() Line 582\tC#\r\n\r\n```\r\nIt works perfectly fine with TLC 3.10 . I ran the same command using that version and it runs perfectly fine\r\n\r\n# Debugging\r\nThe array that is being getting created is of size 1 https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/Text/WordEmbeddingsTransform.cs#L431\r\n\r\narray[0] = 300 //dimension of the word vector being downloaded which leads to failure later on.\r\nThere is no change in the file from the internal repo\r\n\r\ncc @danmosemsft @sfilipi @eerhardt @shauheen """
358672414,872,b'Need a strong name for the Microsoft.ML.Scoring NuGet',b'ML.NET requires all referenced assemblies to be signed with a strong name.'
358444942,871,b'ML.Net is not able to load Tensorflow GPU DLL...',"b'I am trying work with TF GPU native dll so that I can speed up the scoring process. I replaced the tensorflow.dll in `microsoft.ml.tensorflow.redist\\0.5.0\\runtimes\\win-x64\\native` with gpu version but ML.Net throws `DLL not found exception`.\r\n\r\nI did the same with TensorflowSharp and it loads the GPU version perfectly fine.\r\n\r\n### SOLVED\r\n#### Updating To TensorFlow GPU DLL\r\nIf you want to use TF GPU dll during scoring follow the steps below\r\n- In your ML.Net nuget, replace the `tensorflow.dll` in `microsoft.ml.tensorflow.redist\\<ML.Net-Version>\\runtimes\\win-x64\\native` with gpu version (please keep the name same).\r\n- You can grap the prebuilt gpu dll from https://github.com/fo40225/tensorflow-windows-wheel. \r\n- Update the graphics card drivers, CUDA and CuDNN according the Tensorflow gpu version you are using.\r\n- TensorFlowScorer will automatically pick up the TF GPU version.\r\n'"
358332894,868,b'Statically Piped Evaluators for Binary Classification and Regression',"b'Now that we have a few trainers/scorers as part of the static pipelines, the next step might be evaluators. This is somewhat different than other components, since evaluators are not pipeline components (excepting per-instance evaluators, perhaps), as we see here in the aspirational examples.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/df499aa9ea1d671e0df1c432622745c295e3e675/test/Microsoft.ML.Tests/Scenarios/Api/AspirationalExamples.cs#L133\r\n\r\nOne interesting part of the work is the introduction of a method of identifying columns. We already have this somewhat in the `.Append` method, where we are given an instance of the shape type, and select columns from it to show what to append. Here the technique looks identical, but we\'re in this case selecting a single item.\r\n\r\nWhat makes me a little nervous about this approach is that if the operations are extension methods on the column types, I see absolutely no way to prevent someone from calling one of those extension methods inside that ""indexer"" delegate, short of adding more protections in the analyzer. (And, maybe \r\nthis is fine, since the analyzer is clear and really this is probably a mistake a sensible person might plausibly make once.) More generally I talked about this in my remarks on [""context"" here](https://github.com/dotnet/machinelearning/issues/632#issuecomment-416391466).\r\n\r\nRelated to #632.'"
358305182,866,b'The documentation page for the TensorFlow transform needs to include the examples',"b'A few things to fix on the documentation page:\r\nThe documentation page for the TensorFlow transform currently does not include the examples. \r\nThere is more documentation on the Create method, than on the class itself. \r\nInternal fields, like ShortName, Summary and UserName are currently listed as public.'"
358231396,861,b'Move IComponentFactory from EntryPoints namespace',"b""The current `IComponentFactory` types are in the `Microsoft.ML.Runtime.EntryPoints` namespace.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/841ba785c58eb84fa0ce07de324f25d6e3dcbf94/src/Microsoft.ML.Core/EntryPoints/ComponentFactory.cs#L7-L12\r\n\r\nWe should move them to a more appropriate namespace, since `EntryPoint` doesn't really make sense, they are used outside of `EntryPoints`. I think they should go in the same namespace as the `ComponentCatalog`.\r\n\r\nAlso, we should remove the `IArgsComponent` interface, as I don't see it serving any purpose.\r\n\r\n/cc @TomFinley @Zruty0 @codemzs """
358229458,859,b'Update MlNetMklDeps Package Version',b'Update the NlNetMklDeps package to the new version 0.0.0.6. The new package version contains x86 binaries.\r\n'
358159111,854,b'Any chance to get access to [Microsft.ML.TensorFlow.TestModels] ? ',"b'### Issue\r\n\r\n- **What did you do?**\r\nNeed to run the tests for TensorFlow new features\r\n\r\n- **What happened?**\r\nIt seems that the ""cifar_model"" folder and some TF files are included in this package.\r\n\r\n- **What did you expect?**\r\nDownload and have access to [cifar_model/frozen_model.pb]\r\n\r\nThanks in advance.\r\n\r\n![image](https://user-images.githubusercontent.com/3533489/45235197-1f0c1180-b2a6-11e8-83d9-e51a7c9a7ad0.png)\r\n'"
357830543,850,b'Update Matrix multiplication test for multi-output.',b''
357748392,848,b'TensorFlowScorer in ML.NET does not support input tensor of unknown shape ',"b""Using Microsoft.ML 0.5.0\r\nYael told me she's already working on a PR to fix this issue. \xf0\x9f\x91\x8d \r\n\r\n**Issue/Bug:** \r\nWe\xe2\x80\x99d like to extend your test case TensorFlowTransformCifarLearningPipelineTest for making a demo, but instead of loading your \xe2\x80\x9ccifar\xe2\x80\x9d frozen model, we\xe2\x80\x99ll be using an inception model trained for imagenet (downloaded from https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip  ).\r\n\r\nThe main issue is that when executing the Train method of the pipeline, we get an error related to the initialization of the TensorFlowScorer, which I believe is related with using an input tensor of unknown shape. \r\n\r\nDetails of the bug/issue are below, but the main question is if we\xe2\x80\x99ll be able to use an input tensor of unknown shape.\r\n \r\nvar shape = tfShapes[i].ToIntArray().Skip(tfShapes[i][0] == -1 ? BatchSize : 0)\r\n\r\nFormer code is executed in the method TensorFlowMapper.GetInputMetaData(). tfShapes[i] is an object of type TFShape; if the shape is unknown, accessing by the indexer to the first dimension ( tfSfapes[i][0] ) throws a null exception. I checked that most of the methods in TFShape have a guard condition on dims == null, but the overridden indexer doesn\xe2\x80\x99t have this guard, what could be the culprit of the NullReferenceException\r\n\r\nBut even if you fix the indexer, then the method tfShapes[i].ToIntArray() it will return null for an unknown tensor, so this will throw again an exception.\r\n\r\nFull source code of the demo (and the crash) is available here:\r\nhttps://github.com/CESARDELATORRE/TensorFlowMLNETSamples/blob/master/src/TensorFlowMLNETInceptionv3ModelScoring/Program.cs\r\n"""
357708950,847,b'Proof of concept for debugger visualization',"b'We need to play around and see how we will visualize these things: \r\n- Data view\r\n- Row \r\n- Schema (including metadata)\r\n\r\nI think we should do this for static-typed things first, but for non-static-typed ones as well.\r\n\r\n/cc @TomFinley  @eerhardt \r\n'"
357596640,844,b'Train operation should be cancellable.',"b'### System information\r\n\r\n- **OS version/distro**: All supported\r\n- **.NET Version (eg., dotnet --info)**: All supported.\r\n\r\n### Issue\r\n\r\n- I attempt to write training of the models using API as part of internal pipeline\r\n- After I run `pipeline.Train()` I was not able to stop training using standard .NET CancellationToken API\r\n- Please provide ability to cancel such long running operation as training.\r\n\r\n'"
357426408,841,"b'The ""Area"" should not be provided as input when predicting a GitHub issue\'s label/area'","b'https://github.com/dotnet/machinelearning/blob/f89908708f81ae28ad23c7574d405c525ce61b62/test/Microsoft.ML.Tests/Scenarios/Api/AspirationalExamples.cs#L124\r\n\r\nI don\'t think the ""area"" (such as ""area-System.Net"") should be provided as input data when predicting the GitHub issue label/area because that is precisely what we want to predict. \r\n\r\nThe input data to provide when predicting in this case should just be:\r\n- Issue ID\r\n- Issue name/title\r\n- Issue description'"
357390701,839,b'The file [frozen_model.pb] is missing in the repo',"b'### Issue\r\n\r\n- **What did you do?** \r\nI\'m trying to run the test [ machinelearning/test/Microsoft.ML.Tests/Scenarios/TensorflowTests.cs]\r\n\r\n- **What happened?** \r\nIt seems that I need the file [var model_location = ""cifar_model/frozen_model.pb""] and it\'s not in the repo.\r\n\r\n- **What did you expect?**\r\nI can\'t train the sample test pipeline without the TensorFlow frozen model.\r\n\r\nAny guidance or help?\r\n\r\nThanks'"
357379233,838,"b""Make TextFeaturizer's extractors etc. configurable again""","b""#801 is making the parameters default and hardcoded for the following options of Text featurizer:\r\n- Stop word remover (defaults to none) - Fixed in #2962 \r\n- Custom term dictionary (defaults to none) - This parameter is hidden\r\n- Word feature extractor (defaults to unigrams) - Fixed in #2911 \r\n- Char feature extractor (defaults to 3-char) - Fixed in #2911 \r\n\r\nOnce individual building blocks become estimators, we should bring these parameters back (in a form of estimator for word/char extractor etc.). \r\n\r\nOr maybe we shouldn't, and instead just demonstrate how to compose your version of text transform from the individual building blocks?"""
357036296,836,b'CpuMath Enhancement: Double-compute input elements in hardware intrinsics',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\nAfter implementing ""double-compute"", it is expected to make hardware intrinsics more efficient.\r\n\r\n## Details (mostly from @tannergooding)\r\n- In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`, change the last loop of the existing 3-loop code pattern into the following:\r\n    1. Saving the stored result (`dstVector`) from the last iteration of the vectorized code\r\n    2. Moving `pDstCurrent` back such that `pDstCurrent + elementsPerIteration == pEnd`\r\n    3. Doing a single iteration for the remaining elements\r\n    4. Mix the saved result from the last iteration of the vectorized code with the result from the remaining elements\r\n    5. Write the result\r\n\r\nThis generally results in more performant code, depending on the exact algorithm and number of remaining elements\r\n\r\n-  On handling unpadded parts in AVX intrinsics:\r\n\r\nFor some algorithms (like `Sum`), it is possible to \xe2\x80\x9cdouble-compute\xe2\x80\x9d a few elements in the beginning and end to have better overall performance. See the following pseudo-code:\r\n```\r\nif addr not aligned\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero\'s elements after the first aligned address\r\n              result = tmp\r\n              move addr forward to the first aligned address \r\n\r\nwhile addr is aligned and remaining bits >= 128\r\n              result += aligned load\r\n              addr += 128-bits\r\n\r\nif any remaining\r\n              addr = endAddr - 128\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero\'s elements already processed\r\n              result += tmp\r\n\r\nSum the elements in result (using ""horizontal add"" or ""shuffle and add"")\r\n```\r\n\r\nSo, your overall algorithm will probably look like:\r\n```\r\nif (Avx.IsSupported && (Length >= AvxLimit))\r\n{\r\n    // Process 256-bits, we have a limit since 256-bit \r\n    // AVX instructions can cause a downclock in the CPU\r\n    // Algorithm would be similar to the SSE pseudo-code\r\n}\r\nelse if (Sse.IsSupported && (Length >= SseLimit))\r\n{\r\n    // Pseudo-code algorithm given above\r\n\r\n    // 128-bit instructions operate at full frequency\r\n    // and don\'t downclock the CPU, we can only use\r\n    // them for more than 128-bits so we don\'t AV\r\n}\r\nelse\r\n{\r\n    // Software Implementation\r\n}\r\n```\r\n\r\nIf you can\xe2\x80\x99t \xe2\x80\x9cdouble-compute\xe2\x80\x9d for some reason, then you generally do the \xe2\x80\x9csoftware\xe2\x80\x9d processing for the beginning (to become aligned) and end (to catch stray elements).\r\n\xe2\x80\xa2\t`AvxLimit` is generally a number that takes into account the \xe2\x80\x9cdownclocking\xe2\x80\x9d that can occur for heavy 256-bit instruction usage\r\n\xe2\x80\xa2\t`SseLimit` is generally 128-bits for algorithms where you can \xe2\x80\x9cdouble-compute\xe2\x80\x9d and some profiled number for other algorithms\r\n\r\n\r\ncc: @tannergooding since he suggested this approach.\r\n'"
357035453,835,b'CpuMath Enhancement: Make bound checking of loops in hardware intrinsics more efficient',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`, changing `while (pDstCurrent + 4 <= pDstEnd)` for the loop bound checking into `while (pDstCurrent <= pDstEnd - 4)` to save an instruction (ref: https://github.com/dotnet/machinelearning/pull/668#issuecomment-412121893)\r\n- It may probably be a CoreCLR issue'"
357035024,834,b'CpuMath Enhancement: Add unit tests for software fallbacks of hardware intrinsics',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Add unit tests for software fallback implementations, particularly for `MatTimesSrc`.\r\n\r\nReference:\r\n- The software fallback implementations are in `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs`, encapsulated in the following switching paradigm:\r\n``` log\r\nif (Avx.IsSupported)\r\n{\r\n    // AvxIntrinsics\r\n}\r\nelse if (Sse.IsSupported)\r\n{\r\n    // SseIntrinsics\r\n}\r\nelse\r\n{\r\n    // Software fallback\r\n}\r\n```\r\n\r\n- Unit tests are implemented in `test\\Microsoft.ML.CpuMath.UnitTests.netcoreapp/UnitTests.cs`\r\n- To turn on the software fallback implementation in unit tests, you may have to turn off the environment variable `COMPlus_FeatureSimd`.\r\n'"
357034000,833,b'CpuMath Enhancement: Optimize codegen of inlining in hardware intrinsics APIs',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  (from Intel partners) In the original code of `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, even though `VectorSum` is inlined, the codegen is not optimized due to register spill and reload. It seems JIT has optimization opportunity over there. Do you mind opening an issue to discuss about it on CoreCLR github repo?\r\n\r\ncc: @tannergooding since you might already have addressed this issue.'"
357031811,832,b'CpuMath Enhancement: Use FusedMultiplyAdd in hardware intrinsics APIs',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, Use `FusedMultiplyAdd` to replace `srcVector = Sse.Multiply(srcVector, scaleVector);` in `AddScaleU`.  It would be part of any AVX related code-work.'"
357031545,831,b'CpuMath Enhancement: Accelerate loops in hardware intrinsics implementation',b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Make while loops more efficient in `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs` with modified bound checking:\r\n``` log\r\nvar remainder = count % elementsPerIteration;\r\nfloat* pEnd = pdst + (count - remainder);\r\nwhile (pDstCurrent < pEnd)\r\n{ \xe2\x80\xa6 }\r\n```'
357031155,830,b'CpuMath Enhancement: Preamble for hardware intrinsics implementation',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Do ""preamble"" for the implementation of SSE/AVX intrinsics in `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`:\r\n\r\n[Preamble](https://github.com/dotnet/coreclr/blob/b896dd14830b600043a99c2626ea848ad679fb4f/src/System.Private.CoreLib/shared/System/SpanHelpers.Char.cs#L96-L102): \r\n1. while (!aligned) { do scalar operation; } // preamble\r\n2. Do vectorized operation using Read**Aligned**\r\n3. while (!end) { do scalar operation; }\r\nFor large arrays, especially those that cross cache line or page boundaries, doing this should save some measurable amount of time. \r\n\r\nReference: https://github.com/dotnet/machinelearning/pull/562/files/f0f81a5019a3c8cbd795a970e40d633e9e1770c1#r204061074\r\n https://github.com/dotnet/machinelearning/pull/1143\r\n\r\nCurrently these functions are just using Unaligned Loads, we can make them after by aligning the data and doing aligned loads.\r\n\r\n- [ ] AddScalerU\r\n- [ ] ScaleSrcU\r\n- [ ] AddScaleU\r\n- [ ] ScaleAddU\r\n- [ ] AddU\r\n- [ ] AddScaleCopyU\r\n- [ ] AddSU\r\n- [ ]  MulElementWiseU\r\n- [ ] SumU\r\n- [ ] SumSqU\r\n- [ ] SumSqDiffU\r\n- [ ] SumAbsU\r\n- [ ] SumAbsDiffU\r\n- [ ] MaxAbsU\r\n- [ ] MaxAbsDiffU\r\n- [ ] DotU\r\n- [ ] DotSU\r\n- [ ] Dist2\r\n- [ ] SdcaL1UpdateU\r\n- [ ] SdcaL1UpdateSU\r\n'"
357030705,829,b'CpuMath Enhancement: Fix naming of non-constant privates in perf tests for hardware intrinsics',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `test\\Microsoft.ML.CpuMath.PerformanceTests\\PerformanceTests.cs`, regarding the line `private float[] src, dst, original, src1, src2;`, all these **non-constant privates** should be prefixed with `_` but it can be updated in the future PR.\r\n'"
357030008,828,b'CpuMath Enhancement: Add Debug.Assert to check matching lengths of arguments to SSE/AVX intrinsics',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, it may make sense to add some `Debug.Asserts` to check the `src` and `dst` Lengths match. However, these are internal functions that are only called from functions that guarantee the arguments are checked, so it might not be a blocking issue. It just may be some nice documentation on the expectations of these methods. And in case they get new callsites in the future.\r\n'"
357029201,827,b'CpuMath Enhancement: Remove any unnecessary Contracts.Assert covered by Span<T> in hardware intrinsics APIs',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs`, `Span<T>` might already do the checks (`Contracts.Assert`) in the public functions.  Reference:\r\nhttps://github.com/dotnet/machinelearning/blob/e443e2afcd39a8a363321d423e087c0569c0d4af/src/Microsoft.ML.CpuMath/CpuMathUtils.netcoreapp.cs#L237-L245'"
357029132,826,b'remove trailing dot from the OnnxNodeImpl.cs',b''
357027619,824,b'CpuMath Enhancement: Rename input arguments of CpuMath SSE/AVX intrinsics',"b'Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n- Rename input arguments of methods in `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs` and `src\\Microsoft.ML.CpuMath\\Sse.cs`, to make them more informative, e.g.:\r\n* for `MatTimesSrc`, change `tran` into `transpose`\r\n\r\n* for `a` and `b`, change them into `src` and `dst`\r\n'"
357026910,823,b'Suggestions on CpuMath Enhancement',"b'Listed below are CpuMath enhancement suggestions raised during PR reviews for SSE and AVX intrinsics but only documented for future follow-up.\r\n\r\nThe individual issue pages that expand each issue are https://github.com/dotnet/machinelearning/issues/824 and #827 - #836.\r\n\r\n## Style\r\n- [ ] Big-scale renaming of input arguments of Microsoft.ML.CpuMath\\Sse.cs and CpuMathUtils.netcoreapp.cs, e.g. for `MatTimesSrc`, change `tran` into `transpose`.\r\n- [x] Change `0 < count` into `count > 0` and `offset < dst.Length - count` into `offset < (dst.Length - count)`\r\n- [x] Split `&&` asserts into two separate asserts\r\n- [ ] In `CpuMathUtils.netcoreapp.cs`, `Span<T>` might already do the checks (`Contracts.Assert`) in the public functions.\r\n- [ ] (minor) In `SseIntrinsics.cs`, it may make sense to add some `Debug.Asserts` to check the `src` and `dst` Lengths match. However, these are internal functions that are only called from functions that guarantee the arguments are checked, so I don\'t believe it is a blocking issue. It just may be some nice documentation on the expectations of these methods. And in case they get new callsites in the future.\r\n- [ ] In `SsePerformanceTests.cs`, regarding the line `private float[] src, dst, original, src1, src2;`, all these non-constant privates should be prefixed with `_` but it can be updated in the next PR to not block the current one.\r\n\r\n## Functionality\r\n- [ ] [Preamble](https://github.com/dotnet/coreclr/blob/b896dd14830b600043a99c2626ea848ad679fb4f/src/System.Private.CoreLib/shared/System/SpanHelpers.Char.cs#L96-L102): \r\n1. while (!aligned) { do scalar operation; } // preamble\r\n2. Do vectorized operation using Read**Aligned**\r\n3. while (!end) { do scalar operation; }\r\nFor large arrays, especially those that cross cache line or page boundaries, doing this should save some measurable amount of time. \r\nReference: https://github.com/dotnet/machinelearning/pull/562/files/f0f81a5019a3c8cbd795a970e40d633e9e1770c1#r204061074\r\n- [ ] In \'SseIntrinsics.cs\', do the following two things to make while loops more efficient:\r\n* Bound checking:\r\n`var remainder = count % elementsPerIteration;` and then `float* pEnd = pdst + (count - remainder);`. Your loop check then just does `while (pDstCurrent < pEnd)`\r\n\r\n* Double-computing:\r\nFinish off the remaining indices one of two ways.\r\n1. drop down to a scalar algorithm or, \r\n2. ""double compute"" a couple of the indices, that involves:\r\n\r\n- Saving the stored result (`dstVector`) from the last iteration of the vectorized code\r\n- Moving `pDstCurrent` back such that `pDstCurrent + elementsPerIteration == pEnd`\r\n- Doing a single iteration for the remaining elements\r\n- Mix the saved result from the last iteration of the vectorized code with the result from the remaining elements\r\n- Write the result\r\nThis generally results in more performant code, depending on the exact algorithm and number of remaining elements\r\n\r\n- [ ] In `SseIntrinsics.cs`, Use `FusedMultiplyAdd` to replace `srcVector = Sse.Multiply(srcVector, scaleVector);` in `AddScaleU`.  It would be part of any AVX related code-work.\r\n\r\n- [ ] In the original code of `SseIntrinsics.cs`, even though `VectorSum` is inlined, the codegen is not optimized due to register spill and reload. It seems JIT has optimization opportunity over there. Do you mind opening an issue to discuss about it on CoreCLR github repo? (from Intel partners)\r\n\r\n- [x] (probably) Try the default static void Main(string[] args) => BenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args); in Program.cs of perf tests.  It will work, but we will need to decide how to parse arguments from the command line.\r\n\r\n- [ ] Add unit tests for software fallback implementations, particularly for `MatTimesSrc`.\r\n\r\n- [ ] Change `while (pDstCurrent + 4 <= pDstEnd)` for the loop bound checking into `while (pDstCurrent <= pDstEnd - 4)` to save an instruction (ref: https://github.com/dotnet/machinelearning/pull/668#issuecomment-412121893).\r\n\r\n- [ ] (@tannergooding) On handling unpadded parts in AVX intrinsics:\r\nIt can be that simple, but that is often not the best way to handle it.\r\n\r\nFor some algorithms (like `Sum`), it is possible to \xe2\x80\x9cdouble-compute\xe2\x80\x9d a few elements in the beginning and end to have better overall performance. See the following pseudo-code:\r\n```\r\nif addr not aligned\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero\'s elements after the first aligned address\r\n              result = tmp\r\n              move addr forward to the first aligned address \r\n\r\nwhile addr is aligned and remaining bits >= 128\r\n              result += aligned load\r\n              addr += 128-bits\r\n\r\nif any remaining\r\n              addr = endAddr - 128\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero\'s elements already processed\r\n              result += tmp\r\n\r\nSum the elements in result (using ""horizontal add"" or ""shuffle and add"")\r\n```\r\n\r\nSo, your overall algorithm will probably look like:\r\n```\r\nif (Avx.IsSupported && (Length >= AvxLimit))\r\n{\r\n    // Process 256-bits, we have a limit since 256-bit \r\n    // AVX instructions can cause a downclock in the CPU\r\n    // Algorithm would be similar to the SSE pseudo-code\r\n}\r\nelse if (Sse.IsSupported && (Length >= SseLimit))\r\n{\r\n    // Pseudo-code algorithm given above\r\n\r\n    // 128-bit instructions operate at full frequency\r\n    // and don\'t downclock the CPU, we can only use\r\n    // them for more than 128-bits so we don\'t AV\r\n}\r\nelse\r\n{\r\n    // Software Implementation\r\n}\r\n```\r\n\r\nIf you can\xe2\x80\x99t \xe2\x80\x9cdouble-compute\xe2\x80\x9d for some reason, then you generally do the \xe2\x80\x9csoftware\xe2\x80\x9d processing for the beginning (to become aligned) and end (to catch stray elements).\r\n\xe2\x80\xa2\t`AvxLimit` is generally a number that takes into account the \xe2\x80\x9cdownclocking\xe2\x80\x9d that can occur for heavy 256-bit instruction usage\r\n\xe2\x80\xa2\t`SseLimit` is generally 128-bits for algorithms where you can \xe2\x80\x9cdouble-compute\xe2\x80\x9d and some profiled number for other algorithms'"
357022872,819,b'Bring back Supervised binning normalizer',b'This is a unique kind of normalizer that requires label column. We should have a component for it in the new API.'
356931777,810,"b""Tests failing when repository in folder named 'source'""","b'### System information\r\n\r\n- OS: Windows 10\r\n- .NET Version: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\nVersion:   2.1.401\r\nCommit:    91b1c13032\r\n\r\nRuntime Environment:\r\nOS Name:     Windows\r\nOS Version:  10.0.17134\r\nOS Platform: Windows\r\nRID:         win10-x64\r\nBase Path:   C:\\Program Files\\dotnet\\sdk\\2.1.401\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.3\r\n  Commit:  124038c13e\r\n```\r\n\r\n### Issue\r\n\r\n- I ran all tests after successfully building ML.NET\r\n- I had errors in several tests\r\n- Since the code passed all automated tests online, I was expecting the same to happen on my machine locally\r\n\r\nWith the help of @codemzs we found out that the name of the folder in which I had cloned my repository was causing the errors. I used the **default path** that Visual Studio gave me:\r\n`C:\\Users\\myUsername\\source\\repos\\artidoro-machinelearning`\r\n\r\n### Source code / logs\r\n\r\nExample with LogisticRegression-bin-norm-CV-breast-cancer unit test in Microsoft.ML.Predictor.Tests:\r\n\r\n- Here is the file path in the output of my unit test:\r\n`dout=%Source%\\repos\\artidoro-machinelearning\\bin\\AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\netcoreapp2.1\\TestOutput\\LogisticRegression\\LogisticRegression-bin-norm-CV-breast-cancer.txt`\r\n\r\n- Vs what the test was expecting:\r\n`dout=%Output%`\r\n\r\nThe code that normalizes file paths in the output files of unit tests picked up on the folder name `source` and replaced it with `%Source%` instead of replacing the entire file path correctly. This introduces a difference with the expected output. \r\n\r\nHere is the function that performs the path normalization:\r\nhttps://github.com/dotnet/machinelearning/blob/622e0283f70ed53af4e17bffd730807789641ab1/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs#L285-L305\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
356769394,807,b'Help needed with Multi-label string classification',"b'### Issue\r\nI am new to ML (and i don\'t know if i chose a correct subject for the issue) and I need some help classifying some text into several emotion labels. My model has 6 emotions (anger, disgust, fear, happiness, sadness, and surprise) and i want to label many sentences/strings by these emotions to train the model. Later i will need check some string against the model to predict the emotions within the text. The data looks like this:\r\n\r\n```\r\n""Sentence #1"" : Sad (10%), Fear (90%), Disgust (0%), Anger (0%), ...\r\n""Sentense #2: : Happy (60%), Surprised (40%), Disgust (0%), Anger (0%), ...\r\n```\r\n\r\nI don\'t know which learner to start with and how to build my input class (class as in a `public class InData`). The ""Features"" and ""Label"" things look magics to me.\r\n\r\nI will be happy to contribute a sample after i get my sample working.'"
356308385,806,b'Example for NormalizeTransformLogNormalColumn',"b""I can see that there is this class `NormalizeTransformLogNormalColumn`, which seems like it should do exactly what I need, apply a log transform to a column. I have looked and tried everything to get it working with an existing pipeline, but failed miserably. Can anyone help me with an example of how to use it? Here is my pipeline:\r\n\r\n```\r\nvar pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader(DataPath).CreateFrom<SearchData>(useHeader: true, separator: ','));\r\npipeline.Add(new NormalizeTransformLogNormalColumn()); // This does not work\r\n```"""
356248575,805,b'Positive and Negative Values from Binary Classification',"b'Is there any way to get a list of positive vs. negative values from a model if using binary classification? Also, a follow-up question. When getting a prediction on a binary classification can any information be passed as to why the engine selected positive vs. negative?\r\n\r\n'"
356246453,804,"b""Bug/typo in namespace: Missing the second 'o' of Microsoft in Microsft.ML.TensorFlow.TestModels""","b""Looks like a Bug/typo in namespace: Missing the second 'o' of Microsoft in Micro**sft**.ML.TensorFlow.TestModels:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5ef7a082e2718874477d2f6e0119512ca0af9820/test/Microsoft.ML.Tests/Microsoft.ML.Tests.csproj#L38"""
356235191,803,b'Make IChannel `.Done` Done',"b'One of the most fun design decisions w.r.t. `IChannel` is that it should have a `.Done()` method, analogous perhaps to things we see in databases like commits and whatnot. The purpose is to indicate that the channel actually reached the end of the code block successfully, in the way that the code writer thought it would, and thus distinguish between the case where the channel was disposed because we reached the end vs. the channel was disposed for some other reason. (Because, I guess, the alternative, an exception being thrown and interrupting the flow of code, wasn\'t conspicuous enough of a signal.)\r\n\r\nThat\'s fine if a little redundant. However, this *does* incur a cost to code. Consider for example this code here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a3b67d393714ebeb873a41af82cd22ea7311e44c/src/Microsoft.ML.Core/Data/IHostEnvironment.cs#L229-L235\r\n\r\nNow, it *could* have been written like this:\r\n\r\n```csharp\r\nusing (var ch = host.Start(channelName))\r\n    return func(ch);\r\n```\r\n\r\nBut we can\'t, because, of course, we need to make sure we call `ch.Done()`, which means we have to store the return value somewhere else, etc. etc.\r\n\r\nBy itself that isn\'t that bad, except we use channels literally everywhere. So we see this pattern repeated over, and over, and over again. I\'ve done this so often I even have a standard variable name I personally use to work around this thing, `retval`.\r\n\r\nYet, despite being used everywhere in the codebase, over the years I can count the number of times that check has been useful on exactly zero of my hands. In fact it is so useless that we never actually bothered to consider it an error condition, since there are far more examples of people forgetting to do that than examples where it actually signaled a problem -- refer to the example above, the ""mistake"" is far more obvious than the correct actually implemented pattern -- and again, the alternative, an exception being thrown, was far more obvious anyway. So it just writes an easily ignored warning to the *trace* stream if it\'s detected (which is a logging layer people by default cannot visibly access anyway).\r\n\r\nMaybe we ought to get rid of it, just rely on the fact that the channel is being disposed (which contrary to this `Done` thing does convey very useful information), and simplify a bunch of code.'"
356185236,802,b'InvalidOperationException: numClasses must be at least 2.',"b'### System information\r\n\r\nMl.Net version : 0.4.0\r\n\r\n### Issue\r\n\r\nI have written a multi classification code using ml.net 0.4.0. When I run the code, it throws following exception:\r\n\r\nInvalidOperationException: numClasses must be at least 2.\r\n\r\n### Source code / logs\r\n\r\n\r\nLearningPipeline pipeline = new LearningPipeline();\r\n\r\n\t\t\tpipeline.Add(new TextLoader(datapath).CreateFrom<WETRelevanceScore>(useHeader: true));\r\n\r\n\t\t\tpipeline.Add(new Dictionarizer(""Label""));\r\n\r\n\t\t\tpipeline.Add(new TextFeaturizer(""FeaturesA"", ""SubjectiveAnswer"") {\r\n\t\t\t\tKeepPunctuations = false, \r\n\t\t\t\tOutputTokens = true, \r\n\t\t\t\tKeepNumbers = false, \r\n\t\t\t\tKeepDiacritics = false, \r\n\t\t\t\tTextCase = TextNormalizerTransformCaseNormalizationMode.Lower, \r\n\t\t\t\tVectorNormalizer = TextTransformTextNormKind.L2, \r\n\t\t\t\tStopWordsRemover = new PredefinedStopWordsRemover(), \r\n\t\t\t\tCharFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = false}, \r\n\t\t\t\tWordFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = true},\r\n\t\t\t});\r\n\r\n\t\t\tpipeline.Add(new WordEmbeddings((""FeaturesA_TransformedText"", ""FeaturesB"")));\r\n\t\t\t// Combine the features from word embeddings and text featurizer into one column \r\n\t\t\tpipeline.Add(new ColumnConcatenator(""Features"", ""FeaturesA"", ""FeaturesB""));\r\n\t\t\tpipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n\t\t\tpipeline.Add(new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = ""PredictedLabel"" });\r\n\r\n\t\t\tvar model = pipeline.Train<WETRelevanceScore, WETRelevancePredictor>();\r\n\r\nthe data I am using for training is in following format:\r\n\r\n\r\nSubjectiveAnswer | Score\r\n-- | --\r\nBeing a professional in your chosen field   means much more than wearing a coat and tie or possesing a college degree and   a noted tittle. Professionalism also has to do with how you conduct yourself   during your business affairs. True professionals posses a number of   importance characteristics that can apply to virtually any type of business.  | 9\r\nA corporate professional life we should   be aware of some things : reliability : To come in corporate professional   life first should get job done and responsible to the people and following   through the promises in timely manner. competence: professional strive to   become expert in this field which sets them apart from the rest of the   pack. | 9\r\n\r\n\r\n'"
356122913,794,b'ImageAnalytics entry points are not loaded when using the Microsoft.ML.ImageAnalytics nuget',"b'The issue is that the ModuleCatalog loads only entry points that are in assemblies used directly in the code. When using the pipeline API we instantiate objects that are defined in the Microsoft.ML assembly, so the assembly where the actual entry points are located does not get loaded.'"
356076078,792,b'Error Executing Graph with ImageLoader',"b'### System information\r\n\r\n- **OS version/distro**: windows\r\n- **.NET Version (eg., dotnet --info)**: latest master branch\r\n\r\n### Issue\r\n\r\nWhen executing a graph generated with ImageLoader, bombed with an error:\r\n\r\n[8/30/2018 5:06:37 PM Error] [xUnit.net 00:00:12.4271461] Microsoft.ML.Runtime.RunTests.TestEntryPoints.EntryPointExecGraphCommand [FAIL]\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4294784] System.FormatException : One of the identified items was in an invalid format.\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4311870] Stack Trace:\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4325847] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(706,0): at Microsoft.ML.Runtime.Contracts.CheckDecode(IExceptionContext ctx, Boolean f)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4330332] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Model\\ModelLoadContext.cs(153,0): at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadNonEmptyString()\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4331477] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Transforms\\TransformBase.cs(354,0): at Microsoft.ML.Runtime.Data.OneToOneTransformBase.Bindings.Create(OneToOneTransformBase parent, ModelLoadContext ctx, ISchema input, ITransposeSchema transInput, Func2 testType) [8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4332460] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Transforms\\TransformBase.cs(508,0): at Microsoft.ML.Runtime.Data.OneToOneTransformBase..ctor(IHost host, ModelLoadContext ctx, IDataView input, Func2 testType)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4333372] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(92,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform..ctor(IHost host, ModelLoadContext ctx, IDataView input)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4334287] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(110,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform.<>c__DisplayClass11_0.b__0(IChannel ch)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4335158] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IHostEnvironment.cs(232,0): at Microsoft.ML.Runtime.HostExtensions.Apply[T](IHost host, String channelName, Func`2 func)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4336053] D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(110,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform.Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4349911] Output:\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4350922] Test EntryPointExecGraphCommand: aborted: passed\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4543727] Finished: Microsoft.ML.Core.Tests\r\n\r\n### Source code / logs\r\n\r\nPlease use any random images for testing and modify the test.txt to test.csv.\r\n\r\n[test.txt](https://github.com/dotnet/machinelearning/files/2341082/test.txt)\r\n[image_graph.txt](https://github.com/dotnet/machinelearning/files/2341083/image_graph.txt)\r\n'"
356058832,791,b'Add a C# API to ML.NET to extract input/output layers information from DNN models',b'We need to add functionality to ML.NET to be able to extract information about the names/types/sizes of the input and output layers in a DNN model (this applies to both TensorFlow and ONNX models).\r\n\r\nOne possible way to do this is to add to ML.NET an auxiliary console application that can list that information given a model. Another option is to add a utility method that returns this information as a schema object that can be explored by the user.'
356044934,789,b'Add Date Transform/Vectorizers',"b'It naturally makes sense to be able to take a date column and break it into the common sub components used in data analysis. As a very common workflow, it makes sense to build a vectorizer that does this internally effectively adding columns to the dataset from a single source date column which can then be Concatenator to the features.\r\n\r\nI was thinking perhaps a vectorizer that takes a flags enum of various types of date transform (e.g. Day, Month, Year, Day of Week, Day of Year, Quarter, ISO Week of Year, etc). Obviously there are many ways to slice a date so maybe ultimately the best option is a builtin user defined formula transform which can solve this but Dates are a very common workflow as lots of real world data is actually time series.\r\n'"
355771464,787,b'Differences in FastTreeBinaryClassifier between versions',"b""In the Sentiment Analysis sample, when running 0.3.0 or  0.4.0 you get different results.\r\n\r\n**Both results in the console are positive** for 0.4.0. The **first result should be negative** if it is supposed to be the same as 0.3.0, which I'd assume it would.\r\n\r\nhttps://github.com/dotnet/docs/issues/7024 """
355704156,786,b'Porting the tests for Different Sweepers',"b'Currently there are just tests for UniformRandomSweeer And RandomGridSweeper.\r\n\r\nThere are no tests for DeterministicSweeper,  SimpleSweeper,  SmacSweeper and NelderMeadSweeper. This will increase code coverage and will help to catch any current or future bugs in these Sweeper classes.\r\n\r\n\r\n\r\n'"
355703140,785,b'Documentation fixes for .5 release',b'List of api docs needing revision:\r\n* [ ] - [LearningPipeline](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.learningpipeline?view=ml-dotnet&branch=smoke-test-preview)\r\n* [ ] - [OnnxConverter.Convert(PredictionModel) Method](https://review.docs.microsoft.com/en-us/dotnet/api/microsoft.ml.models.onnxconverter.convert?view=ml-dotnet&branch=smoke-test-preview#Microsoft_ML_Models_OnnxConverter_Convert_Microsoft_ML_PredictionModel_)'
355701021,784,b'Using TensorFlowTransform with pre-trained models that are not frozen.',b'Currently the TensorFlowTransform works with frozen TensorFlow models as input.\r\n\r\nWe need to investigate what it takes to get it to work with models that are not frozen.\r\nThis will also help if in the future we want to do transfer learning via fine-tuning of pre-trained models.'
355679894,781,b'Error Executing Graph with ImageLoader',"b'### System information\r\n\r\n- **OS version/distro**: windows\r\n- **.NET Version (eg., dotnet --info)**: latest master branch\r\n\r\n### Issue\r\n when executing a graph generated with ImageLoader, bombed with an error:\r\n[8/30/2018 5:06:37 PM Error] [xUnit.net 00:00:12.4271461]     Microsoft.ML.Runtime.RunTests.TestEntryPoints.EntryPointExecGraphCommand [FAIL]\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4294784]       **System.FormatException : One of the identified items was in an invalid format.**\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4311870]       Stack Trace:\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4325847]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs(706,0): at Microsoft.ML.Runtime.Contracts.CheckDecode(IExceptionContext ctx, Boolean f)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4330332]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Model\\ModelLoadContext.cs(153,0): at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadNonEmptyString()\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4331477]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Transforms\\TransformBase.cs(354,0): at Microsoft.ML.Runtime.Data.OneToOneTransformBase.Bindings.Create(OneToOneTransformBase parent, ModelLoadContext ctx, ISchema input, ITransposeSchema transInput, Func`2 testType)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4332460]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Data\\Transforms\\TransformBase.cs(508,0): at Microsoft.ML.Runtime.Data.OneToOneTransformBase..ctor(IHost host, ModelLoadContext ctx, IDataView input, Func`2 testType)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4333372]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(92,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform..ctor(IHost host, ModelLoadContext ctx, IDataView input)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4334287]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(110,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform.<>c__DisplayClass11_0.<Create>b__0(IChannel ch)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4335158]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.Core\\Data\\IHostEnvironment.cs(232,0): at Microsoft.ML.Runtime.HostExtensions.Apply[T](IHost host, String channelName, Func`2 func)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4336053]         D:\\mldotnet0823\\machinelearning\\src\\Microsoft.ML.ImageAnalytics\\ImageLoaderTransform.cs(110,0): at Microsoft.ML.Runtime.ImageAnalytics.ImageLoaderTransform.Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4349911]       Output:\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4350922]         Test EntryPointExecGraphCommand: aborted: passed\r\n[8/30/2018 5:06:37 PM Informational] [xUnit.net 00:00:12.4543727]   Finished:    Microsoft.ML.Core.Tests\r\n\r\n[image_graph.txt](https://github.com/dotnet/machinelearning/files/2337169/image_graph.txt)\r\n\r\n[test.txt](https://github.com/dotnet/machinelearning/files/2337195/test.txt)\r\n![microsoftlogo](https://user-images.githubusercontent.com/33538664/44867992-4592d280-ac3e-11e8-9e4b-140c8d1e9e3d.png)\r\n![revolutionanalyticslogo](https://user-images.githubusercontent.com/33538664/44867993-4592d280-ac3e-11e8-9759-052795f2e4f1.png)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
355677888,780,b'Delete dead code related to AVX',"b'Some of the original code relating to AVX and SSE is dead and can be deleted including\r\n\r\n* all of avx.cpp and avx.cs\r\n* functions in thunk.cs that exposed avx.cpp functions, eg MatMulDX\r\n\r\nI checked in TLC as well and the above were only used by code in NeuralNetworks/*, which will not migrate to ML.NET.\r\n\r\nI also notice some functions in sse.cs seem dead eg MeanOfSrc \r\n'"
355671163,779,b'Address additional comments on the TensorFlowTransform PR',"b'Post merge, there are some additional comments that were added to the TensorFlowTransform PR #704 . \r\nAlso, during the bug bash there was a request to update the documentation in a few places. \r\n\r\nCreating an issue to address these asks.  \r\n\r\nListing down the issues being addressed:\r\n\r\n1.  Check for number of rows in unit test `TensorFlowTransformCifar` . [comment](https://github.com/dotnet/machinelearning/pull/704#discussion_r214075997)\r\n\r\n2.  Fix `TensorFlowTransformCifarLearningPipelineTest` test. [comment](https://github.com/dotnet/machinelearning/pull/704#discussion_r214075714)\r\n\r\n3. Update the TensorFlowTransform documentation to include a pointer to the nugets required for running the TensorFlowTransform.\r\n'"
355544873,776,b'Provide an example of LightgbmRanker?',b'@codemzs '
355392744,772,"b""Test system doesn't actually run in MTA apartment state""","b""https://github.com/dotnet/machinelearning/blob/9258be22e3338dec18075c6e66048b1861533ec8/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs#L804\r\nWe don't run tests in MTA, since for quite a while coreclr didn't support MTA.\r\n\r\nIt was fixed in https://github.com/dotnet/coreclr/pull/15652, so I think we should enable it.\r\n"""
355374642,770,b'Bug in deserialization of ImageLoaderTransform',"b'When it is deserialized, the base class is deserialized first, but when it is serialized, the base class is serialized last.'"
355336508,769,b'Enable specifying a mapping between data view column names and TensorFlow inputs',b'Currently the column names have to match the input names that are stored in the TensorFlow model. We should enable users to provide a mapping from the data view columns to the TensorFlow inputs.\r\nWe should also enable users to specify a new name for the output column.\r\n'
355258177,766,b'Need to change our Copyright on NuGet packages',b'nuget.org has new requirements for Microsoft owned packages. One of these compliance checks is that the Copyright matches exactly the same string they expect. Our current Copyright does not match their exact string - see https://github.com/dotnet/buildtools/pull/2136 for the fix.'
355228267,765,"b'Add ""Reshape Transform""'","b""We need the following functionalities in order to score TensorFlow models:\r\n\r\n1. Change the ColumnType of the column to be a different shape \xe2\x80\x93 this would not do anything to the data, it would just change the type of the column, to match the input dimensions the model expects (for example, if the data contains a column of length 784, and the model expects a 28x28 input).\r\n2. Actually reshape the data \xe2\x80\x93 (C,H,W) to (H,W,C). This transform would also have to move data around in addition to changing the ColumnType.\r\n3. Reshape data from RGB to other ordering of the channels. This transform would move the data around, but leave the ColumnType as it was.\r\n\r\n2 is already implemented as an option in the PixelExtractorTransform, and 3 could also be implemented as an option in that transform, but it may be useful to have them as a separate transform, for cases where the input data doesn't necessarily come from the PixelExtractorTransform.\r\n"""
355223254,764,b'Rework schema and metadata',"b""We wanted to change the following about the schema:\r\n- Formally make it a collection of 'columns'.\r\n- Turn metadata into an instance of `IRow`.\r\n- (maybe) introduce 'global metadata' in addition to 'column metadata'.\r\nBelow is the sketch of the new interface for schema: \r\n\r\n```c#\r\n    public interface ISchema : IReadOnlyList<ISchemaColumn>\r\n    {\r\n        /// <summary>\r\n        /// Dataset-wide metadata.\r\n        /// </summary>\r\n        IRow Metadata { get; }\r\n    }\r\n\r\n    public interface ISchemaColumn\r\n    {\r\n        /// <summary>\r\n        /// The name of a column. This string should always be non-empty.\r\n        /// </summary>\r\n        string Name { get; }\r\n\r\n        /// <summary>\r\n        /// The type of the column.\r\n        /// </summary>\r\n        ColumnType Type { get; }\r\n\r\n        /// <summary>\r\n        /// The metadata for a column, or <c>null</c> if this column has no metadata.\r\n        /// </summary>\r\n        IRow Metadata { get; }\r\n    }\r\n```\r\n\r\nIn addition, we might want to rework `IRow` to not include the notion of 'Row ID' and 'active columns'. Maybe this calls for another interface, like `IMovingRow` that would include these.\r\n\r\n/cc @TomFinley"""
354980619,763,b'ML.NET packages are missing third party notices',b'Packages which include source / binaries that come from a third party need to be documented via a third party notices file in the root of the package.  The source repository should also contain a third party notices file in the root.\r\n\r\nFor example see https://github.com/dotnet/corefx/blob/master/THIRD-PARTY-NOTICES.TXT'
354940505,762,b'ONNX/Sonoma - upgrade to RS5 Lotus runtime and onnx 1.2 version support',b'Upgrade to latest Lotus runtime and onnx model format'
354940288,761,b'ONNX/Sonoma - add API to retrieve shapes/dims of input and output layers',b'Access shape info programatically instead of via user input'
354939964,760,b'Test for parquet loader because type system has changed',b'We need to verify parquet loader works with the .NET standard type system.'
354838907,758,b'Do not duplicate test output where there is no need to.',b'Often times Debug and Release builds have identical test outputs but we create two seperate baselines for that. We should avoid doing this and instead have a common baseline.\r\n\r\nI believe @sfilipi was going to look into this?'
354780092,756,b'Move LearningPipeline API to a legacy namespace',"b'In order to free up `Microsoft.ML.*` names, we should move the auto-generated components into a different namespace, like `Microsoft.ML.Legacy`.\r\n\r\nWe also plan to deprecate the LearningPipeline API in 0.6 and remove it in 0.7.'"
354528325,755,"b""SchemaShape's metadata to also be SchemaShape""","b""Currently, the 'metadata shape' associated with the column is a list of strings.\r\n\r\nIt is already somewhat problematic, because it doesn't have the associated types. \r\n\r\nWe should instead make it a `SchemaShape` on its own."""
354511634,754,b'New API for ML.NET',"b'We are creating a stable API that:\r\n- Uses parallel terminology with other well-known ML libraries (Spark, sklearn);\r\n- Takes advantage of strong types of .NET to shorten path to success;\r\n- Is going to be present from now till 1.0 and beyond;\r\n- Keeps simple ML scenarios concise;\r\n- Allows advanced ML scenarios: see #584 .\r\n\r\nTo that end, we are going to expose a selection of Estimators and Transformers (see #581 ) that cover existing transforms, learners and loaders. \r\n\r\nThis issue will be used to track the overall [project](https://github.com/dotnet/machinelearning/projects/9) status: what is planned to be done, what is done, etc.'"
354472261,752,b'Early stopping in LightGbm',"b'I am trying to implement a LightGbm classifier with early stopping, but I can not figure how to enter a validation set into the pipeline. I can see that EarlyStoppingRound can be set for LightGbm, so I suppose there should be a way to set a validation set. My current code:\r\n\r\n```\r\nvar pipeline = new LearningPipeline\r\n{\r\n    new TextLoader(TrainDataPath).CreateFrom<MyFeature>(useHeader: true),\r\n    new ColumnConcatenator(""Features"", ... ),\r\n    new LightGbmBinaryClassifier\r\n    {\r\n        NumLeaves = 31, \r\n        NumBoostRound = 100, \r\n        EarlyStoppingRound = 10,\r\n    },\r\n};\r\n_model = pipeline.Train<MyFeature, MyPrediction>();\r\n\r\n```'"
354467929,751,b'Add checks on input between ML.Net and Tensorflow model.',"b'Add checking for input name, type, size and shape between ML.Net and Tensorflow model when the transform is being created so that user is able to pass correct input.'"
354385595,749,b'Feature Selection',"b'\r\nHi all,\r\n\r\nFeature selection is an important part of any ML workflow. This is required to exclude too highly correlated labels from model fitting.  So rather than a process of trial and error I was hoping to select the best training model/evaluator based on running an initial feature selection action.\r\n\r\nJudging from the API documentation this may well be possible. For instance, we have the\r\n\r\nRankerEvaluator Class  \r\n\r\nHas anyone used this or any other aspect of the framework to help identify over fitting labels or best model to run?\r\n\r\nIn python I would manually do some correlation analysis and perhaps try something like TPOT to make a recommendation but would far prefer to stay in the world of C# and this excellent tool.\r\n\r\nBest regards\r\n\r\nFig '"
354380290,748,b'Documentation for TensorFlow transform',b''
354379467,747,b'Investigate using text and sparse input in TensorFlow',"b'We should know how TF handles text inputs, and whether it supports sparse inputs.'"
354379015,746,b'Enable specifying order of channels in Pixel Extractor',"b'TensorFlow models can have different ordering of the channels. ML.NET currently only supports specifying channel first/last, but not the order.'"
354377912,745,b'Handle additional types as input and output in TF models',"b'Initially only floats/doubles will be handled, and we should investigate which other types are commonly used in TF models.'"
354279106,744,b'Calculating multiple TopK accuracies is slow/inefficient',"b'When calculating the top-k accuracy for multi-class classifiers the current evaluation code is pretty slow. Especially if multiple Top-K accuracies are desired (this will re-do a lot of the work unnecessarily).\r\n\r\nCurrent implementation will first sort (`N logN`):\r\n\r\n* https://github.com/dotnet/machinelearning/blob/f85e722fbd6b1710d104e85e6b3bcef4e593b5d2/src/Microsoft.ML.Data/Evaluators/MulticlassClassifierEvaluator.cs#L442-L446\r\n\r\nThen get the index:\r\n\r\n* https://github.com/dotnet/machinelearning/blob/f85e722fbd6b1710d104e85e6b3bcef4e593b5d2/src/Microsoft.ML.Data/Evaluators/MulticlassClassifierEvaluator.cs#L345-L350\r\n\r\nA more efficient algorithm would be to just calculate the rank (`O(N)` and no memory needed) of the correct label and keeping track of the seen ranks (0 being the best-case, correct prediction). Then the Top-k accuracy can be easily returned for any `k`. Possibly changing the API to returning a vector of top-k predictions.\r\n\r\nOne issue to discuss: What happens when the score is equal for multiple values? There would be a ""best-case"" and ""worst-case"" top-k accuracy.'"
354261400,742,b'General Additive Model (GAM) has no summary to extract features at runtime',"b'### Issue\r\n\r\nThe `Generalized Additive Model` (`GAM`) learner provides a save-as-text option [1], but no option to view the summary at runtime.\r\n\r\n[1] https://github.com/dotnet/machinelearning/blob/60ae981223e83b174ecaaf528bd51814a6b0835c/src/Microsoft.ML.FastTree/GamTrainer.cs#L820'"
354260495,741,b'FastTree Gradient of Logistic Loss prohibits small learning rates',"b'### Issue\r\n\r\nThe gradient of the Logistic Loss implemented in `FastTree` uses the `LambdaRank`-style `sigmoid` parameter, set to the learning rate. This quashes the gradients for small learning rates. While this works well for classification tasks, when used by the `General Additive Model` (`GAM`) trainer, it prohibits learning with small learning rates. However, the `GAM` learning-by-boosting technique implemented here requires small learning rates to be stable.'"
354259243,740,b'General Additive Models do not allow pruning with a validation set',"b""### Issue\r\n\r\nIn the standard formulation of GAMs by Rich Caruana's research group [[Lou et al. 2012](http://www.cs.cornell.edu/~yinlou/papers/lou-kdd12.pdf)], the features are pruned post-learning based on a validation set.\r\n\r\nIn ML.NET, pruning is not allowed.\r\n"""
354258708,739,b'General Additive Model features are not centered after learning.',"b""### Issue\r\n\r\nIn the standard formulation of GAMs by Rich Caruana's research group [[Lou et al. 2012](http://www.cs.cornell.edu/~yinlou/papers/lou-kdd12.pdf)], the feature responses are centered around the average response in the training set, and an intercept term is added to capture the average response.\r\n\r\nIn the ML.NET formulation of GAMs, the feature values are not centered.\r\n\r\nThis is an issue when scoring terms with missing values, as those terms will then deviate from the average by an un-calibrated amount."""
354257147,738,"b'General Additive Models (GAM) for Classification learn the logit, not class probability'","b'### System information\r\n\r\n_independent of system_\r\n\r\n### Issue\r\n\r\nThe `GAM Binary Classifier` in `ML.NET` learns to predict the *Logit*, but it is not calibrated to produce a probability. This goes against the standard pattern that we have for classifiers in `ML.NET`.\r\n\r\n### Source code / logs\r\n\r\nSee the `Create` function: https://github.com/dotnet/machinelearning/blob/60ae981223e83b174ecaaf528bd51814a6b0835c/src/Microsoft.ML.FastTree/GamTrainer.cs#L140\r\n'"
354243218,737,b'Binary Classification Results',"b'Hi all,\r\n\r\nI have a quick question and would appreciate your thoughts regarding what could be a dubious score. I have been training/testing some bin classification models and the results look too promising. For instance,\r\n\r\nNot training a calibrator because it is not needed.\r\n*************************************************\r\n*       Metrics for Logistic Regression Binary\r\n*------------------------------------------------\r\n*       Accuracy: 1\r\n*       Entropy: 0.999316959634874\r\n*       Auc: 100.00%\r\n\r\nThis is not a software issue but rather a query. I would have expected accuracy to have been reported to decimal places (less than 1).\r\n\r\nThanks\r\n\r\nFig'"
354199480,736,b'How to get auto tuned parameters to train final model',"b'Hi,\r\n\r\nafter training many models on time series data (multi class pred) I\'d like to train a final model on all available data (including the test set).\r\n\r\nSpecifically I use SDCA multi class trainers and set some parameters while leaving other to ""auto-tune"".\r\n\r\nExample output:\r\n\r\n```\r\nAutomatically choosing a check frequency of 4.\r\nAuto-tuning parameters: maxIterations = 104.\r\nAuto-tuning parameters: L2 = 2.719283E-05.\r\nAuto-tuning parameters: L1Threshold (L1/L2) = 0.25.\r\nUsing best model from iteration 104.\r\n```\r\n\r\nHow would I train my final model? I\'d like to set the iterations to 104 and the other hyper parameters to their respective values. Is there an API to get the estimated/used parameters?\r\n\r\nI can\'t just read stdout and manually train the model since I dynamically train ML models on our customer\'s servers.\r\n\r\nThanks for all work!'"
354131777,733,"b'NelderMeadSweeper has unmet dependency to ""ldrandpl"" sweeper'","b'The NelderMeadSweeper has a default `FirstBatchSweeper` set to `ldrandpl`.  However, that component is not found in the `dotnet/machinelearning` repo.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Sweeper/Algorithms/NelderMead.cs#L27-L28\r\n\r\n\r\nhttps://github.com/dotnet/machinelearning/search?q=ldrandpl&unscoped_q=ldrandpl -- only returns a single result - the reference from NelderMeadSweeper.\r\n\r\nWe should find another default for this sweeper, or move the `ldrandpl` component to `dotnet/machinelearning`.\r\n\r\n/cc @TomFinley '"
354104714,732,"b'Question: In what situations will ""InvalidOperationException: All instances skipped due to missing features"" occur?'",b'### System information\r\n\r\n- Windows 10\r\n- Dotnet Core 2.1.301\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempting to train a `FastTreeRegressor` model on a dataset.\r\n- **What happened?**\r\nReceived `System.InvalidOperationException: All instances skipped due to missing features.` for my dataset\r\n- **What did you expect?**\r\nThe model would train successfully and output a model archive\r\n\r\n### Source Code\r\n\r\nPresumably this situation is occurring: https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/FastTree.cs#L1885\r\n'
353622297,726,b'Indirect references in ML.NET using Dependency Injection',"b""I've found 2 indirect references in our product that I'm not sure how to proceed on.\r\n\r\n1. `LearnerFeatureSelectionTransform` depends on `SDCA`, but `ML.Transforms` doesn't have a reference to `ML.StandardLearners`.\r\n2. The 'train' commands in `ML.Data` (`CV`, `Train`, `TrainTest`) all have a default Trainer of `AveragedPerceptron`.  but `AveragedPerceptron` lives in the `ML.StandardLearners` assembly. And `ML.StandardLearners` references `ML.Data`, but this dependency is in the wrong order.\r\n\r\nA couple of options:\r\n1. Change these parameters to be 'user required', i.e. they don't have a default and fail if you didn't specify it.\r\n2. Move some code around so the dependencies line up correctly.  For example, we could move our 'train' commands out of `ML.Data` and into a higher assembly.\r\n3. For (1) above, we could move `LearnerFeatureSelectionTransform` into `ML.StandardLearners` instead of being in `ML.Transforms`. Or we could add the dependency from `ML.Transforms` to ML.StandardLearners.\r\n4. Continue to use Dependency Injection and just assume/hope the component is there at runtime.\r\n\r\nFrom an internal conversation with @TomFinley, we are thinking of taking option (1) above - make these parameters required and not have a default.\r\n\r\nThoughts?\r\n\r\ncc @TomFinley @Zruty0 @codemzs @Ivanidzo4ka """
353621181,725,"b""CustomStopWordsRemoverTransform shouldn't hard-code its column name""","b'See the conversation here:\r\nhttps://github.com/dotnet/machinelearning/pull/700/files/e30785ff454627c7b74e3b6873d70b9e6de28bdf#r212152727\r\n\r\n![image](https://user-images.githubusercontent.com/8291187/44561816-2ff04b00-a71c-11e8-95bf-9f015ab9ce4f.png)\r\n\r\nWe should consider making the column name configurable instead of hard-coding the column name, which may be hiding an existing column.\r\n\r\n/cc @codemzs '"
353504477,721,b'Main package has MKL dependency',b'Microsoft.ML.Runtime.Data in the main package has WhiteningTransform which uses exports of MKL. If we want to segregate MKL users into Microsoft.ML.HalLearners then WhiteningTransform may need to move into an assembly in that package.\r\n\r\n@eerhardt '
353428133,719,b'IRowMapper to use IRow for metadata',b'Change the interface of `IRowMapper` to use `IColumn` (or something akin to it) to convey the schema information. \r\n\r\nThis will simplify the usage of `IRowMapper` in cases where it emits metadata for the new columns. '
353424245,718,b'Estimator for TextLoader',b'Convert `TextLoader` to a pair of `DataReaderEstimator` / `DataReader`.\r\n\r\nGet rid of `MyTextLoader` in `Wrappers`.'
353252630,717,b'Installing package Microsoft.ML on target framework .NET Framework 4.6.2 fails.',"b""### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to install Nuget Package `Microsoft.ML` on a `.NET 4.6.2` project in Visual Studio 2013 (Version 12.0.40629.00 Update 5)\r\n\r\n- **What happened?**\r\nNuget Package installation failed with error.\r\n\r\n- **What did you expect?**\r\nNuget Package should have been installed successfully as `netstandard 2.0` supports `.NET Framework 4.6.2`.\r\n\r\n### Source code / logs\r\n````\r\nInstalling 'Microsoft.ML 0.4.0'.\r\nSuccessfully installed 'Microsoft.ML 0.4.0'.\r\nAdding 'Microsoft.ML 0.4.0' to XXX.\r\nUninstalling 'Microsoft.ML 0.4.0'.\r\nSuccessfully uninstalled 'Microsoft.ML 0.4.0'.\r\nInstall failed. Rolling back...\r\nCould not install package 'Microsoft.ML 0.4.0'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.6.2', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\r\n````"""
353129833,715,b'Create a C# API for extracting input/output metadata from ONNX models',"b'This will be needed for implementing an ONNX transform, so that we can validate the names and sizes of the inputs, and be able to know the sizes of the outputs in advance (before we see any data).'"
353128512,714,b'Test TensorFlow pre-trained models',b'We should run some TensorFlow pre-trained models using the TensorFlowTransform and validate the results.'
353126659,713,b'Package TF binaries in a separate nuget package for distribution',b''
353126229,712,b'Enable outputting multiple layers in one call to TF',b'Users should be able to specify a list of output names to the TF transform arguments.'
353047060,711,b'Perf benchmarks for optimization',"b'We want to have a couple ML scenarios to be used for tracking performance. We can use it to detect regression from build to build, as well as improve performance.'"
352958681,710,"b'Is there any way to make it the same as the vector created by the TextFeaturizer in ML.NET(ex. korean, chinese) unsupported language?'","b'pipeline.Add(New TextFeaturizer(""Features"", ""Text""))\r\n\r\nWhen  language(like Korean, Chinese) support is not available, it seems that i can create a learning model by using  my own vector(based on the language text). If possible, I hope that the relevant content is shared.'"
352906101,709,b'Data preprocessing question',"b""I'd like to ask a few question regarding data preprocessing in ML.NET.\r\n\r\n1.) Is there a possibility of getting rid of **outliers** in case of input data?\r\n2.) Is it possible to perform a **normalization** or **standardization** on the input data?\r\n\r\nThank you in advance."""
352857147,708,b'Sentinemt Analysis - ML prediction wrong',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10  Pro x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET version 4.7/ C# 7.2\r\n\r\n### Issue\r\nI used the ""sentiment analysis"" tutorial and wrote the console application as described.\r\nIt seems to be working, but the predictions are wrong. The model predicts ""positive"" every time.\r\nI used the training and testing data from github of course.\r\n\r\n\r\n### Source code / logs\r\n`using System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing System.Threading.Tasks;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Models;\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace MyML\r\n{\r\n    class Program{\r\n        \r\n        //Variables for training and testing\r\n        static readonly string _dataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""wikipedia-detox-250-line-data.tsv"");\r\n        static readonly string _testDataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""wikipedia-detox-250-line-test.tsv"");\r\n        static readonly string _modelpath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""Model.zip"");\r\n\r\n        //starting the program\r\n        static async Task Main(string[] args){\r\n            var model = await Train();\r\n            Evaluate(model);\r\n            Predict(model);\r\n\r\n            //keeps the console open until enter is pressed\r\n            Console.WriteLine(""Done. Press \'Enter\' to exit."");\r\n            Console.ReadLine();\r\n        }\r\n\r\n        //Creating and training the model. Writes learned data into a .zip file\r\n        public static async Task<PredictionModel<SentimentData, SentimentPrediction>> Train(){\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader(_dataPath).CreateFrom<SentimentData>());\r\n            pipeline.Add(new TextFeaturizer(""Features"", ""SentimentText""));\r\n            pipeline.Add(new FastTreeBinaryClassifier() { NumLeaves = 5, NumTrees = 5, MinDocumentsInLeafs = 2 });\r\n            PredictionModel<SentimentData, SentimentPrediction> model =\r\n            pipeline.Train<SentimentData, SentimentPrediction>();\r\n            await model.WriteAsync(_modelpath);\r\n            return model;\r\n        }\r\n\r\n        //Evaluating data after model training\r\n        public static void Evaluate(PredictionModel<SentimentData, SentimentPrediction> model){\r\n            var testData = new TextLoader(_testDataPath).CreateFrom<SentimentData>();\r\n            var evaluator = new BinaryClassificationEvaluator();\r\n            BinaryClassificationMetrics metrics = evaluator.Evaluate(model, testData);\r\n\r\n            //Console user information\r\n            Console.WriteLine();\r\n            Console.WriteLine(""PredictionModel quality metrics evaluation"");\r\n            Console.WriteLine(""------------------------------------------"");\r\n            Console.WriteLine($""Accuracy: {metrics.Accuracy:P2}"");\r\n            Console.WriteLine($""Auc: {metrics.Auc:P2}"");\r\n            Console.WriteLine($""F1Score: {metrics.F1Score:P2}"");\r\n        }\r\n\r\n        //Method for sentiment prediction. Use after training & evaluation\r\n        public static void Predict(PredictionModel<SentimentData, SentimentPrediction> model){\r\n            //Small testdata for prediction\r\n            IEnumerable<SentimentData> sentiments = new[] {\r\n                new SentimentData{\r\n                    SentimentText = ""Please refrain from adding nonsense to Wikipedia.""},\r\n                new SentimentData{\r\n                    SentimentText = ""He is the best, and the article should say that.""}\r\n            };\r\n\r\n            IEnumerable<SentimentPrediction> predictions = model.Predict(sentiments);\r\n\r\n            //User information header\r\n            Console.WriteLine();\r\n            Console.WriteLine(""Sentiment Predictions"");\r\n            Console.WriteLine(""---------------------"");\r\n\r\n            var sentimentsAndPredictions = sentiments.Zip(predictions, (sentiment, prediction) => (sentiment, prediction));\r\n\r\n            //Write prediction to console for the user\r\n            //Error! The model predicts ""Positive"" every time!\r\n            foreach (var item in sentimentsAndPredictions)\r\n            {\r\n                Console.WriteLine($""Sentiment: {item.sentiment.SentimentText} | Prediction: {(item.prediction.Sentiment ? ""Positive"" : ""Negative"")}"");\r\n            }\r\n            Console.WriteLine();\r\n        }\r\n    }\r\n}\r\n`\r\n`using System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing System.Threading.Tasks;\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace MyML\r\n{\r\n    public class SentimentData\r\n    {\r\n        [Column(ordinal: ""0"", name: ""Label"")]\r\n        public float Sentiment;\r\n        [Column(ordinal: ""1"")]\r\n        public string SentimentText;\r\n    }\r\n\r\n    public class SentimentPrediction\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public bool Sentiment;\r\n    }\r\n}\r\n`\r\n'"
352756926,707,"b""Need a 'workout test' for estimators""","b'Pretty much any `IEstimator` needs to adhere to certain properties, which we should enforce in a test:\r\n\r\nEstimator `est`:\r\n- `est.Fit()` throws on a data if `est.GetOutputSchema()` throws on its schema.\r\n  - The opposite may not be true.\r\n- `est.Fit()` on the same data produces identical transformers.\r\n- Schema validation errors should look properly (same message).\r\n\r\nFitted transformer `xf = est.Fit(data)`:\r\n- `xf` should be able to transform the data it was fitted on.\r\n- `xf.GetOutputSchema()` should match `est.GetOutputSchema()`.\r\n- `xf.Transform()` throws on a data if `xf.GetOutputSchema()` throws on its schema.\r\n  - The opposite may not be true.\r\n- Save/load should be transparent for `xf`. \r\n- Subject the outputs of `xf.Transform()` to the same workouts as we do for transforms: `CheckSameSchema`, `CheckSameValues`.\r\n'"
352429217,702,b'Can I get an example of simple naive bayes based on ML.NET?',"b'I would like to use NaiveBayesClassifier instead of StochasticDualCoordinateAscentBinaryClassifier, but the example [here ](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.naivebayesclassifier?view=ml-dotnet)is not detailed and has limitations.\r\n\r\nI want to do various tests with ML.NET, but there are not many examples, I can not find any explanation, and there are many restrictions on learning. In particular, I wonder how to useFeatureColumn, LabelColumn, and TrainingData.\r\n\r\nI think it will be improvement in the future, but I want to know when the plan will be.\r\n\r\n\r\n'"
352317080,699,b'RffTransform has undesirable coupling to its MatrixGenerator',"b'`RffTransform` has an undesirable coupling to which kind of MatrixGenerator it is using (gaussian or not). \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e77f24e68d92f033910a5d783576d1879763d979/src/Microsoft.ML.Transforms/RffTransform.cs#L421-L425\r\n\r\nIt is using the ComponentCatalog to determine which type of MatrixGenerator it was working with before actually creating it. And then depending on the Type, it is doing a different distance scaling algorithm.\r\n\r\nThis type of decision (which algorithm to use for distance scaling) should be done by the MatrixGenerator itself, and not necessarily decided by the RffTransform.\r\n\r\nI am changing RffTransform to no longer use SubComponent. However, I can no longer tell which type of MatrixGenerator is going to be created without actually creating the generator, so I needed to make a ""dummy"" instance. I spoke with @yaeldekel, and we decided this was ""OK"" for now, since it typically only used with a small number of columns (i.e. 1).\r\n\r\nWe should consider refactoring RffTransform and the IFourierDistributionSampler types to allow RffTransform to not have to switch based on whether Gaussian sampling is used or not.'"
352284689,697,b'Attribution of Wikipedia images',b'Images in https://github.com/dotnet/machinelearning/tree/master/test/data/images/ need citations to their Wikipedia sources. \r\n\r\n![Banana](https://github.com/dotnet/machinelearning/blob/bdb742d3cc2bc273b18831e7e778f95a81e96a56/test/data/images/banana.jpg?raw=true)\r\n\r\nPerhaps listing in the [README.md](https://github.com/dotnet/machinelearning/blob/5e812d166d01d9cbd4c9ed16d4648041fbb7c83a/test/data/README.md) file? '
352216279,696,b'Enable scoring of TensorFlow models in ML.NET',b''
352215404,695,b'Enable scoring of ONNX models in ML.NET',b''
351917460,694,"b""Confusion matrices didn't have enough matrices""","b""We are running into this error when we try to do a cross validation of a classifier.. \r\n```\r\nnew StochasticDualCoordinateAscentClassifier()\r\n                {\r\n                    Caching = CachingOptions.Memory,\r\n                    MaxIterations = 100,\r\n                    LossFunction = new SmoothedHingeLossSDCAClassificationLossFunction(),\r\n                    NumThreads = System.Environment.ProcessorCount - 1  //We use one less than the number of processors available\r\n                }\r\n\r\n```\r\nSystem.InvalidOperationException: 'Confusion matrices didn't have enough matrices.'\r\n\r\n\r\nThis seems to be thrown only at the very end.. because it seems to be rolling through just fine ..outputting the below on each iteration.. \r\n\r\n`Not training a calibrator because it is not needed.\r\nAutomatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.\r\nUsing 3 threads to train.\r\nAutomatically choosing a check frequency of 3.\r\nAuto-tuning parameters: L2 = 8.341675E-05.\r\nAuto-tuning parameters: L1Threshold (L1/L2) = 1.\r\nUsing best model from iteration 33.`\r\n\r\n\r\nIs there something that we are doing incorrectly such as we need to specify the number of folds to use? \r\n\r\nThanks,\r\nAJ"""
351703424,689,"b'Consider removing Sweeper, PipelineInference, and ResultProcessor assemblies from Microsoft.ML nuget'","b""We currently have a few assemblies in our `Microsoft.ML` nuget package that aren't part of what we want in our public API surface area.\r\n\r\nThese assemblies include:\r\n\r\n* Microsoft.ML.Maml\r\n* Microsoft.ML.ResultProcessor\r\n* Microsoft.ML.PipelineInference\r\n* Microsoft.ML.Sweeper\r\n\r\nThe last two may some day be part of our public API, but in their current form we don't want to expose them as public API.\r\n\r\nWe should remove these assemblies from our nuget package (maybe put them in a separate nuget package), so external users don't depend on these types. That way we are free to update the API until we are ready to ship it as an official API.\r\n\r\n/cc @Zruty0 @TomFinley """
351395002,685,b'This is not issue - How can I get more learners/Algorithms?',"b""Hi Team,\r\n\r\nI am .NET developer and ML.NET is great start for me to learn Machine Learning.\r\n\r\nBeing .NET developer, I always wanted to do ML in .NET and find TensorFlow and other libraries difficult to understand on first glance.\r\n\r\nTo learn ML.NET, I am working on prediction model, best use case would be Stock prediction. As I can easily get historical data. \r\n\r\nI have following questions,\r\n\r\n1. What is the best algorithm in ML.NET for such use case? In TensorFlow and other libraries, I can see LSTM, Time Series Model and ARIMA etc...\r\n\r\n2.  How can I use one of the below in ML.NET? If available or what is alternative available?\r\n- ARIMA Model\r\n- Long Short Term Memory\r\n- Neural Net - Neural Network for prediction\r\n\r\n3. How can I use ML.NET for Neural Network? For above use case? I know below URL but I don't find proper use cases that will explain when to use which trainer.\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers?view=ml-dotnet\r\n\r\n4. Rather than predicting single output value, how can I predict series of values i.e. stock prices for next weeks or month? \r\n\r\nI am very much interested in ML.NET but being newbie I don't know from where to start. Learning things by implementing is best way and that is why I have choose Stock Prediction.\r\n\r\nRegards,\r\nParag"""
351006515,682,b'Consider defaulting Ensemble Stacking to a trainer in StandardLearners',"b""See the conversation here: https://github.com/dotnet/machinelearning/pull/681#discussion_r210432412\r\n\r\nEnsemble Stacking defaults to using FastTree when users don't specify an underlying trainer. This results in a non-ideal dependency from `Microsoft.ML.Ensemble` to `Microsoft.ML.FastTree`, and would cause problems if we ever considered separating FastTree into its own NuGet package.\r\n\r\nWe should consider making a different default trainer under our Stacking use something in the StandardLearners assembly.\r\n\r\n/cc @TomFinley """
350937028,680,b'Predict similar scheme',"b'_Sorry for my English._\r\n\r\n### Dataset\r\n\r\nThere is dataset which contains files which describe scheme:\r\n\r\nsample #1.txt\r\n```\r\n3103686, 2590304, 2022230, 838696\r\n5530360, 1916721, 2022230, 430823\r\n3103686, 3807071, 2022230, 430823\r\n5705725, 4022485, 2022230, 975943\r\n8043677, 3697167, 2022230, 430823\r\n8043677, 2761756, 2022230, 430823\r\n```\r\n\r\nsample #2.txt\r\n```\r\n2994926, 3072910, 2022230, 1752477\r\n7396944, 3072911, 2022230, 1752476\r\n2994926, 1981531, 5573177, 558310\r\n\r\n```\r\nEach row is rectangle element (on scheme) feature vector (x, y, width, height).\r\n\r\n### Data to predict\r\n\r\nI need train a model which can predict for such input data\r\n\r\ninput.txt\r\n```\r\n3313321, 3259181, 2022230, 558310\r\n7039277, 3454335, 2022230, 558310\r\n5253403, 4207799, 2022231, 558310\r\n4073770, 2445894, 2022230, 558310\r\n6569923, 2445894, 2022230, 558310\r\n```\r\n\r\nsimilar scheme.\r\n\r\nFor example, in the above example for input.txt prediction would be quite if model say that sample #1 most similar for input scheme.\r\n\r\n### Question\r\n\r\nWhich algorithm from ML.NET should I use to solve my task? Of cause I do not expect complete solution, just put me right way.\r\nI have a little bit sub-questions to clarify my problem:\r\n\r\n- How preparing dataset to train: by feature describe or matrix?\r\n\r\n- Before some classifier should I clustering data?'"
350526340,679,b'CategoricalHashTransform should accept Floats and Doubles',"b""Currently CategoricalHashTransform accepts only Text or Key types.\r\n\r\nIf Double is passed in for ex, below error message is shown:\r\nError: *** System.ArgumentOutOfRangeException: 'Source column 'workclass1' has invalid type ('R8'): Expected Text or Key item type.\r\n\r\nIt would be good if it can accept numbers: Ints and Floats. \r\n\r\n\r\n"""
350284502,678,b'Incremental Learning\\Training',b'Is there a possibility of adding incremental training a model?\r\n'
350146246,676,b'Q: Workflow',"b""Hi,\r\n\r\nNot an issue defect to report, but more of an expression of appreciation for an excellent project.\r\n\r\nIn addition, I have a query in terms of process...\r\n\r\nMy csv files tend to be large and the fields likely to be changing on a frequent basis. However, when building models its just so time intensive having to update the class definitions and keep in sync.\r\n\r\nDoes anyone have any suggestions please to optimise this process. Can this be done, perhaps by automated template generation. Alternatively break cv files with many fields down to more granular files. I don't know so I would welcome your thoughts.\r\n\r\nTa\r\nFig   """
350101322,675,"b'Docs on CategoricalOneHotVectorizer are not clear, incomplete'","b""The 'remarks' section on the docs is really unclear about what  the outputs do, what happens if the value is not found in the dictionary.\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.categoricalonehotvectorizer?view=ml-dotnet\r\n\r\nIn addition, only 3 out of 4 options for output kind are listed, and the documentation for the enum is a stub: \r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.categoricaltransformoutputkind?view=ml-dotnet\r\n\r\n\r\n"""
349934829,674,b'How to use intput data maybe not sure type.',b'I want predict  power line of my pv equipment is Healthy. so the input data is a list power data(count may be not ensure). \r\n i did not find the dynamic input of the document.  can you help me. '
349913029,673,b'.NET data type system instead of DvTypes',"b'# .NET data type system instead of DvTypes\r\n## Motivation\r\nMachine Learning datasets often have missing values and to accommodate them along with C# native\r\ntypes without increasing the memory footprint DvType system was created. If we were to use\r\n`Nullable<T>` then we are looking at additional memory for `HasValue` boolean field plus another 3\r\nbytes for 4 byte alignment. The C# native types that are replaced using DvTypes are bool as DvBool,\r\nsbyte as DvInt1, int16 as DvInt2, int32 as DvInt4, int64 as DvInt8, DvDateTime as System.DateTime,\r\nDvDateTimeZone as combination of DvDateTime and DvInt2 offset, DvTimeSpan as SysTimeSpan and string\r\nas DvText. Float and Double types already have a special value called NaN that can be used for\r\nmissing value. DvType system achieves a smaller memory footprint by denoting special value for\r\nmissing value which is usually the smallest number that can be represented by the native type that\r\nis encapsulated by DvType, example, DvInt1\'s missing value indicator would be SByte.MinValue and in\r\nthe case of types that represent date/time types it is a value that represent maximum ticks. \r\n\r\nWe plan to remove DvTypes to make IDataView a general commodity that can be used in other products\r\nand for this to happen it would be nice if it did not having a dependency on a special type system.\r\nIf in future we find having DvTypes was useful then we can consider exposing it natively from .NET\r\nplatform. Once we remove DvTypes then ML.NET platform will be using native non-nullable C# types.\r\nFloat or double types can be used to represent missing value.\r\n\r\n## Column Types \r\nColumns in ML.NET make up the dataset and `ColumnType` defines a column. At high level there are two\r\nkinds of column, first is `PrimitiveType` and that comprises of types such as `NumberType`,\r\n`BoolType`, `TextType`, `DateTimeType`, `DateTimeZoneType`, `KeyType`, second is `Structured type`\r\nand it comparises of `VectorType`. `ColumnType` is primarily made up of `Type` and `DataKind`.\r\n`Type` could refer to any type but it is instantiated with a type referred by `DataKind` which is an\r\nidentifer for data types that comprises of DvTypes, native C# types such as float, double and custom\r\nbig integer UInt128.  \r\n\r\n## Type conversion\r\nDvTypes have implicit and explicit override for assignment operator that handles type conversion.\r\nLets consider DvInt1 for example:\r\n\r\n| To  | From | Current behavior\r\n|:-:|:-:|:-:\r\n| DvInt1 | sbyte | Copy the value as it is \r\n| DvInt1 | sbyte? | Assign missing value if null otherwise copy the value as it is \r\n| sbyte | DvInt1 | Copy if not a missing value otherwise throw exception \r\n| sbyte? | DvInt1 | Assign null for missing values otherwise copy over \r\n| DvInt1 | DvBool | Assign missing value for a missing value otherwise copy value over | sbyte = bool?\r\n| DvInt1 | DvInt2 | Cast raw value from short to sbyte and compare it with original value if they are not same assign missing value otherwise casted value \r\n| DvInt1 | DvInt4 | Same as above\r\n| DvInt1 | DvInt8 | Same as above \r\n| DvInt1 | Float |\r\n| DvInt1 | Double | Same as above \r\n| Float | DvInt1 | Assign NaN for missing value \r\n| Double | DvInt1 | Same as above\r\n\r\nSimilar conversion rules exist for DvInt2, DvInt4, DvInt8 and DvBool. \r\n\r\n## Logical, bitwise and numerical operators\r\nOperations such as `==`, `!=`, `!`, `>`, `>=`, `<`, `<=`, `+`,`-`,`*`,`pow`,`|`,`&` take place\r\nbetween same DvTypes only. They also handle missing values and in the case of arithmetic operators\r\noverflow is also handled. Most of these overrides are implemented but only few are actively used.\r\nWhenever there is an overflow the resulting value is represented as missing value and the same goes\r\nwhen one of the operands is a missing value.\r\n\r\n## Serialization\r\nDvTypes have their own codecs for efficiently compressing data and writing it to disk, for example,\r\nto write DvBool to disk, two bits are used to represent a boolean value, 0x00 is false, 0x01 is true\r\nand 0x10 is missing value indicator. Boolean values are written at the level of int32 which has 32\r\nbits that can accommodate 32/2 or 16 boolean values in 4 bytes as opposed to using 1 byte per\r\nboolean value using the naive approach that does not even handle missing value. We can reuse this\r\napproach to serialize bool by using one bit instead of two. DvInt* codecs need not be changed at\r\nall. DateTime and DvText codecs will require some changes.\r\n\r\n## Intermediate Language(IL) code generation\r\nML.NET contains a mini compiler that generates IL code at runtime for peak and poke functions that\r\nbasically perform reflection of objects to set and get values in a more performant manner. Here we\r\ncan use OpCodes.Stobj to emit IL code for `DvTimeSpan`,`DvDateTime`, `DvDateTimeZone` and\r\n`ReadOnlyMemory<char>` types.\r\n\r\n# New Behavior \r\n* `DvInt1`, `DvInt2`, `DvInt4`, `DvInt8` will be replaced with `sbyte`, `short`, `int` and `long`\r\n  respectively.\r\n  * Conversions will conform to .NET standard conversions.\r\n  * Types will be converted using casting and this might cause underflow and overflow and therefore\r\n    behavior is undefined here, example, casting `long` to `sbyte` will result in assigning of low 8\r\n    bits from long to sbyte. ML.NET projects by default are unchecked because checked is expensive\r\n    and hence used in code blocks where it is needed.\r\n    ```\r\n    > unchecked((sbyte)long.MaxValue)\r\n    -1\r\n    ```\r\n  * Conversion from `Text` to `Integer` type is done by first converting `Text` to `long` value in\r\n    the case of positive number and `ulong` in the case of negative number and then validating this\r\n    value is within the legal bounds of the type that it is being converted to from `Text` type,\r\n    example, legal bound for `sbyte` is -128 to 127, so converting ""-129"" or ""128"" will result in an\r\n    exception, also converting a value that is out of legal bounds for a `long` type will also\r\n    result in an exception.\r\n    ``` \r\n    var c = Convert.ToSByte(""129"");\r\n    Value was either too large or too small for a signed byte.\r\n    sbyte.Parse(string, System.Globalization.NumberStyles, System.Globalization.NumberFormatInfo)\r\n    System.Convert.ToSByte(string)\r\n    ```\r\n\r\n* `DvTimeSpan`, `DvDateTime` and `DvDateTimeZone` will be replaced with `TimeSpan`, `DateTime` and\r\n  `DateTimeOffset` respectively.\r\n  * Offset in `DataTimeOffset` is represented as long because it records the ticks. Previously this\r\n    was represented as DvInt2 or short in `DvDateTimeZone` because it was recorded as minutes and\r\n    due to this it had a smaller footprint on the disk. With offset being long the footprint will\r\n    increase, one work around is to convert it to minutes before writing and then converting minutes\r\n    back to ticks but this might lead to loss in precision. Since DataTime is very rarely used in\r\n    Machine Learning so I\'m not sure if it is worth making an optimization here.\r\n\r\n* `DvText` will be replaced with `ReadOnlyMemory<char>`.\r\n  * `ReadOnlyMemory<char>` does not implement `IEquatable<T>` and due to this it cannot be be used a\r\n    type in `GroupKeyColumnChecker` in `Cursor` in GroupTransform. The workaround for this is to\r\n    remove the `IEquatable<T>` contraint on the type and instead use if else to check if the type\r\n    implements `IEquatable<T>` then cast and call `Equals` method otherwise check if the type is of\r\n    `ReadOnlyMemory<char>` then use its utility method for equality otherwise throw an exception.\r\n  * `ReadOnlyMemory<char>` does not implement `GetHashCode()` and due to this it cannot be used as a\r\n    key in a dictionary in `ReconcileSlotNames<T>` in EvaluatorUtils.cs. The workaround for this is\r\n    to use string representation of `ReadOnlyMemory<char>` as a key. While this is wastage of memory\r\n    but its not too bad because this is only used at the end of evaluation phase and the number of\r\n    strings allocated here will be roughly proportional to the number of classes.\r\n\r\n* `DvBool` will be replaced with bool.       \r\n  * `GetPredictedLabel` and `GetPredictedLabelCore` will result in an undefined behavior in the case\r\n    where score contains a missing value represented as NaN. Here we will default to false.\r\n\r\n* Backward compatiblity when reading `IDV` files written with `DvTypes`.\r\n  * `Integers` are read as they were written to disk, i.e minimum value of the corresponding data\r\n      type in the case of missing value.\r\n  * `Boolean` is read using the old codec, where two bits are used per value and missing values are\r\n      converted to `false` to fit in `bool` type.\r\n  * `DateTime`, `DateTimeSpan`, `DateTimeZone` use `long` and `short` type underneath to represent\r\n      ticks and offset and they are converted using the `Integer` scheme defined above. In the case\r\n      where ticks or offset is read and found to contain missing value represented as a minimum of\r\n      the underlying type then it is converted to default value of that type to prevent an exception\r\n      from `DateTime` or `TimeSpan` or `DateTimeOffset` class as such minimum values indicate an\r\n      invalid date. \r\n  * `DvText` is read as it is. Missing values when being converted to Integer types are converted to\r\n    minimum value of that `integer` type and empty string is converted to `default` value of that\r\n    `integer` type.\r\n\r\n* TextLoader\r\n  * Will throw an exception if it encounters missing value.\r\n  * Will convert empty string to `default` values of type it is being converted to.\r\n\r\n* Parquet Loader\r\n  * Will throw an exception for nullables or overflow.\r\n\r\n# Future consideration\r\nIntroduce an option in the loader whether to throw an exception in the case of missing value or just\r\nreplace them with `default` values. With the current design we will throw an exception in the case\r\nof missing for Text Loader and Parquet loader but not IDV(Binary Loader).\r\n\r\n# Benchmarking the type system changes \r\n### (this section was written by @najeeb-kazmi )\r\n\r\n`ReadOnlyMemory<char>` is a data type introduced recently that allows management of strings without unnecessary memory allocation. Strings in C# are immutable. Hence, when we take a string operation such as `substring`, the resulting string is copied to a new memory location. To prevent unnecessary allocation of memory, `ReadOnlyMemory` keeps track of the substring via start and end offsets relative to the original string. Hence, for every `substring` operation, the memory allocated is constant. In `ReadOnlyMemory`, if one needs to access independent elements, they do it by calling the `Span` property, which returns a `ReadOnlySpan` object, which is a stack only concept. It turns out that this `Span` property is an expensive operation, and our initial benchmarks showed that runtimes of the pipelines regressed by 100%. Upon further performance analysis, we decide to cache the returned `ReadOnlySpan` as much as we could, and that brought the runtimes on par with `DvText`.\r\n\r\nThese benchmarks are intended to compare performance after these optimizations on `Span` were done, in order to investigate whether we hit parity with `DvText` or not.\r\n\r\n## Datasets and pipelines\r\nWe chose datasets and pipelines to test to cover a variety of scenarios, including:\r\n- numeric data only\r\n- numeric + categorical data with categorical transform\r\n- numeric + categorical data with categorical and categorical hash transforms\r\n- categorical + text data with categorical and text transforms\r\n- text transform only on a very large text dataset\r\n\r\nThe table below shows the datasets and their characteristics, as well as the pipeline that we executed on each dataset. All datasets were ingested in text format, which makes heavy use of `DvText` / `ReadOnlyMemory<char>`.  Other data types are also involved in the pipelines, although the performance of the pipelines are dominated by `DvText` / `ReadOnlyMemory<char>`.\r\n\r\n| Dataset                     | Size         | Rows       | Features                            | Pipeline                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | Comments                                                                        |\r\n|-----------------------------|--------------|------------|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\r\n|    Criteo                   |    230 MB    |    1M      |    13 numeric   26 categorical      |    Train    data={\\\\ct01\\data\\Criteo\\Kaggle\\train-1M.txt}    loader=TextLoader{   col=Label:R4:0    col=NumFeatures:R4:1-13    col=LowCardCat:TX:19,22,30,33    col=HighCardCat:TX:~   }    xf=CategoricalTransform{col=LowCardCat}    xf=CategoricalHashTransform{col=HighCardCat bits=16}   xf=MissingValueIndicatorTransform{col=NumFeatures}   xf=Concat{ col=Features:NumFeatures,LowCardCat,HighCardCat   }    tr=ap{iter=10}    seed=1    cache=-                                                                                                                                                                                                                                                                                                                 | Numeric + categorical features with categorical and categorical hash transforms |\r\n|    Bing Click Prediction    |    3 GB      |    500k    |    3076 numeric                     |    Train    data={\\\\ct01\\data\\TeamOnly\\NumericalDatasets\\Ranking\\BingClickPrediction\\train-500K}   loader=TextLoader{col=Label:R4:0 col=Features:R4:8-3083   header=+ quote=-}   xf=NAHandleTransform{col=Features ind=-}    tr=SDCA    seed=1    cache=-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Numeric features only                                                           |\r\n|    Flight Delay             |    227 MB    |    7M      |    5 numeric   3 categorical        |    Train    data={\\\\ct01\\data\\PerformanceAnalysis\\Data\\Flight\\New\\FD2007train.csv}       loader=TextLoader{    sep=,    col=Month:R4:0    col=DayofMonth:R4:1    col=DayofWeek:R4:2    col=DepTime:R4:3    col=Distance:R4:4    col=UniqueCarrier:TX:5    col=Origin:TX:6    col=Dest:TX:7    col=Label:R4:9    header=+    }    xf=CategoricalTransform{ col=UniqueCarrier col=Origin   col=Dest }   xf=Concat{ col=Features:Month,DayofMonth,DayofWeek,DepTime,Distance,UniqueCarrier,Origin,Dest   }   tr=SDCA    seed=1    cache=-                                                                                                                                                                                                                                   | Numeric + categorical features with categorical transform                       |\r\n|    Wikipedia Detox          |    74 MB     |    160k    |    1 categorical   1 text column    |    Train    data={\\\\ct01\\data\\SCRATCH_TO_MOVE\\BinaryClassification\\WikipediaDetox\\toxicity_annotated_comments.merged.shuf-75MB,_160k-rows.tsv}      loader=TextLoader{   quote=-    sparse=-    col=Label:R4:0    col=rev_id:TX:1    col=text:TX:2    col=year:TX:3    col=logged_in:BL:4    col=ns:TX:5    col=sample:TX:6    col=split:TX:7    header=+   }    xf=Convert{col=logged_in type=R4}    xf=CategoricalTransform{col=ns}    xf=NAFilter{col=Label}    xf=Term{col=Label:Label}    xf=TextTransform{   col=FeaturesText:text    wordExtractor=NgramExtractorTransform{ngram=2}      charExtractor=NgramExtractorTransform{ngram=3}   }    xf=Concat{col=Features:logged_in,ns,FeaturesText}   tr=OVA {p=AveragedPerceptron{iter=10}}    seed=1    cache=-    | Categorical transform + text featurization                                      |\r\n|    Amazon Reviews           |    9 GB      |    18M     |    1 text column                    |    Train    data={\\\\ct01\\users\\prroy\\dataset\\cleandata_VW\\Amazon_reviews_cleaned.tsv}    loader=TextLoader{col=Label:TX:0 col=text:TX:1 header=+   sparse=-}    xf=NAFilter{col=Label}    xf=Term{col=Label:Label}    xf=TextTransform{   col=Features:text    wordExtractor=NgramExtractorTransform{ngram=2}      charExtractor=NgramExtractorTransform{ngram=3}   }    tr=OVA {p=AveragedPerceptron{iter=10}}    seed=1   cache=-                                                                                                                                                                                                                                                                                                                                      | Text featurization on a very large dataset                                      |\r\n\r\n## Methodology and experimental setup\r\n\r\n- The two builds of ML.NET (one using DvTypes and the other using .NET data types) were built to target .NET Core 2.1. \r\n- Pipelines were executed from the Microsoft.ML.Console project: `dotnet MML.dll <pipeline>`\r\n- All pipelines were executed on Azure Standard F72s_v2 VMs running Windows Server 2016, which offer an instance isolated to dedicated hardware (Intel Xeon Platinum 8168).\r\n- We killed background processes that were not needed to run the experiments, including closing Visual Studio, ensuring that only one console window was open on the VM.\r\n- For each pipeline, we discarded the results of the first two runs for each pipeline to control for runtime variability due to a cold start, keeping only the subsequent runs for analysis.\r\n\r\n## Results\r\nWe present the results of the benchmarks here. The deltas indicate performance gap of .NET data types relative to DvTypes: negative values indicate slower performance of .NET data types compared to DvTypes, and percentage deltas are based off the mean runtime for DvTypes. Finally, we did an independent samples t-test with unequal variances for the two builds, and present the p-values for each test. We chose a significance threshold of 0.05, with a smaller p-value indicating significant differences.\r\n\r\nWe can see that for all the pipelines except the one with Amazon Reviews dataset, the deltas were within 1% of the speed of DvTypes, and were not significant. For Amazon Reviews, the delta was 1.85% of the speed of DvTypes and significant. The statistical significance is not particularly concerning here because the long runtimes on this dataset were bound to return significantly different runtimes even with a small percentage difference. More important thing here is that the performance gap was reduced from ~100% to within 2%. We expect the performance to only improve with further optimizations in future .NET Core runtimes.\r\n\r\n### Criteo 1M\r\n\r\n| Run #   | .NET data types    | DvTypes         |\r\n|---------|--------------------|-----------------|\r\n| 1       | 12.907             | 12.634          |\r\n| 2       | 12.635             | 12.847          |\r\n| 3       | 12.989             | 12.546          |\r\n| 4       | 12.708             | 12.713          |\r\n| 5       | 12.789             | 12.463          |\r\n| 6       | 12.565             | 12.751          |\r\n| 7       | 12.828             | 12.73           |\r\n| 8       | 12.688             | 12.425          |\r\n| 9       | 12.791             | 13.009          |\r\n| 10      | 12.858             | 12.584          |\r\n|         |                    |                 |\r\n| Mean    | 12.7758            | 12.6702         |\r\n| S.D.    | 0.128720887        | 0.178014232     |\r\n|         |                    |                 |\r\n| Delta   | -0.1056            | -0.83%          |\r\n| p-value | 0.073767344        | Not significant |\r\n\r\n### Flight Delay 7M \r\n\r\n| Run #   | .NET data types    | DvTypes         |\r\n|---------|--------------------|-----------------|\r\n| 1       | 52.536             | 51.562          |\r\n| 2       | 52.667             | 52.501          |\r\n| 3       | 52.175             | 52.475          |\r\n| 4       | 52.076             | 51.773          |\r\n| 5       | 54.19              | 51.786          |\r\n| 6       | 51.678             | 52.698          |\r\n| 7       | 52.647             | 52.338          |\r\n| 8       | 52.426             | 52.704          |\r\n| 9       | 51.703             | 51.214          |\r\n| 10      | 51.742             | 52.407          |\r\n|         |                    |                 |\r\n| Mean    | 52.384             | 52.1458         |\r\n| S.D.    | 0.74152            | 0.520013632     |\r\n|         |                    |                 |\r\n| Delta   | -0.2382            | -0.46%          |\r\n| p-value | 0.208863           | Not significant |\r\n\r\n\r\n### Bing Click Prediction 500K\r\n| Run #   | .NET data types            | DvTypes         |\r\n|---------|----------------------------|-----------------|\r\n| 1       | 222                        | 221             |\r\n| 2       | 222                        | 222             |\r\n| 3       | 220                        | 223             |\r\n| 4       | 221                        | 223             |\r\n| 5       | 220                        | 220             |\r\n| 6       | 223                        | 219             |\r\n| 7       | 222                        | 222             |\r\n| 8       | 223                        | 220             |\r\n| 9       | 223                        | 223             |\r\n| 10      | 222                        | 222             |\r\n|         |                            |                 |\r\n| Mean    | 221.8                      | 221.5           |\r\n| S.D.    | 1.135292                   | 1.433721        |\r\n|         |                            |                 |\r\n| Delta   | -0.3                       | -0.14%          |\r\n| p-value | 0.305291                   | Not significant |\r\n\r\n### Wikipedia Detox\r\n| Run #   | .NET data types | DvTypes         |\r\n|---------|-----------------|-----------------|\r\n| 1       | 65.992          | 65.265          |\r\n| 2       | 66.042          | 65.308          |\r\n| 3       | 65.6            | 67.457          |\r\n| 4       | 65.146          | 66.011          |\r\n| 5       | 66.196          | 65.788          |\r\n| 6       | 65.683          | 67.611          |\r\n| 7       | 65.498          | 65.191          |\r\n| 8       | 65.819          | 66.636          |\r\n| 9       | 65.896          | 65.412          |\r\n| 10      | 66.564          | 66.381          |\r\n| 11      | 66.392          | 66.074          |\r\n| 12      | 65.862          | 65.155          |\r\n| 13      | 65.958          | 64.808          |\r\n| 14      | 66.085          | 65.157          |\r\n| 15      | 66.085          | 66.116          |\r\n| 16      | 66.116          | 66.189          |\r\n| 17      | 66.086          | 65.748          |\r\n| 18      | 66.822          | 66.066          |\r\n| 19      | 66.227          | 65.009          |\r\n| 20      | 65.278          | 65.911          |\r\n|         |                 |                 |\r\n| Mean    | 65.96735        | 65.86465        |\r\n| S.D.    | 0.402667        | 0.758248        |\r\n|         |                 |                 |\r\n| Delta   | -0.1027         | -0.16%          |\r\n| p-value | 0.29838         | Not significant |\r\n\r\n### Amazon Reviews\r\n| Run #   | .NET data types | DvTypes     |\r\n|---------|-----------------|-------------|\r\n| 1       | 5121            | 4992        |\r\n| 2       | 5121            | 5016        |\r\n| 3       | 5090            | 5036        |\r\n| 4       | 5163            | 4981        |\r\n| 5       | 5112            | 5003        |\r\n| 6       | 5075            | 5008        |\r\n| 7       | 5097            | 5022        |\r\n| 8       | 5093            | 4991        |\r\n| 9       | 5071            | 5040        |\r\n| 10      | 5090            | 5019        |\r\n|         |                 |             |\r\n| Mean    | 5103.3          | 5010.8      |\r\n| S.D.    | 27.10084        | 19.46393    |\r\n|         |                 |             |\r\n| Delta   | -92.5           | -1.85%      |\r\n| p-value | 7.05E-08        | Significant |\r\n\r\nCC: @eerhardt @Zruty0 @Ivanidzo4ka @TomFinley @shauheen @najeeb-kazmi @markusweimer \r\n'"
348931057,669,b'Binary learners need to have IComponentFactory implementation in order to work with OVA.',"b'With #622 OVA expects predictor type to be IComponentFactory, and in current moment only learner which exposed itself as  component is FastTree, and it exposes itself only as ITrainer instead of ITrainer<IPredictorProducing<Float>> required for OVA.\r\n\r\nWhich mean we have to go through all our Binary learners and expose them as ComponentKind and create proper factories. Same probably states for Regression, MultiClass, and Ranking.'"
348835803,666,"b""Entry point 'Transforms.CategoricalOneHotVectorizer' not found""","b""I built my first dummy ml.net console app from my dev box and ensured it worked as expected.\r\n \r\nThen I copied the binaries (console app + a bunch of [136] Micrososft.ML.* and its dependencies) to a windows server machine and I see the following exception.\r\n \r\nUnhandled Exception: System.InvalidOperationException: Entry point 'Transforms.CategoricalOneHotVectorizer' not found\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode..ctor(IHostEnvironment env, IChannel ch, ModuleCatalog moduleCatalog, RunContext context, String id, String entryPointName, JObject inputs, JObject outputs, Boolean checkpoint, String stageId, Single cost, String label, String group, String weight, String name)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.ValidateNodes(IHostEnvironment env, RunContext context, JArray nodes, ModuleCatalog moduleCatalog, String label, String group, String weight, String name)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph..ctor(IHostEnvironment env, ModuleCatalog moduleCatalog, JArray nodes)\r\n   at Microsoft.ML.Runtime.Experiment.Compile()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n   at MyMLApp2.Program.Train() in E:\\ML\\MyMLApp2\\MyMLApp2\\Program.cs:line 111\r\n   at MyMLApp2.Program.Main(String[] args) in E:\\ML\\MyMLApp2\\MyMLApp2\\Program.cs:line 64\r\n \r\nany idea why?\r\n"""
348723847,664,b'Documentation fixes',"b""The xml documentation has a few things to fix. \r\n\r\n- MissingValuesRowDropper.Complement link in the MissingValuesRowDropper page. \r\n- List of links on the 'more information' of the FastTree pages because of the missing type in the list. \r\n- Symsgd documentation needs to be wired to the CSharpAPI.cs\r\n - Indentation fixes for some of the examples. \r\n- Paragraphing text for CategoricalOneHotVectorizer.  \r\n"""
348580141,663,"b""System.TypeLoadException: Could not load type 'Microsoft.ML.Runtime.ITrainer`2'""","b""### System information\r\n\r\n- **OS version/distro**: 10.0.14\r\n- **.NET Version (eg., dotnet --info)**: 2.1.202\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUpgraded my pipeline to v0.4. It used SDCA multi classification.\r\n\r\nOn the *first* `Train` call it always throws a\r\n\r\n```\r\nSystem.TypeLoadException: Could not load type 'Microsoft.ML.Runtime.ITrainer`2' from assembly 'Microsoft.ML.Core, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51'.\r\n   at System.Reflection.CustomAttribute._CreateCaObject(RuntimeModule pModule, IRuntimeMethodInfo pCtor, Byte** ppBlob, Byte* pEndBlob, Int32* pcNamedArgs)\r\n   at System.Reflection.CustomAttribute.CreateCaObject(RuntimeModule module, IRuntimeMethodInfo ctor, IntPtr& blob, IntPtr blobEnd, Int32& namedArgs)\r\n   at System.Reflection.CustomAttribute.GetCustomAttributes(RuntimeModule decoratedModule, Int32 decoratedMetadataToken, Int32 pcaCount, RuntimeType attributeFilterType, Boolean mustBeInheritable, IList derivedAttributes, Boolean isDecoratedTargetSecurityTransparent)\r\n   at System.Reflection.CustomAttribute.GetCustomAttributes(RuntimeAssembly assembly, RuntimeType caType)\r\n   at System.Attribute.GetCustomAttributes(Assembly element, Type attributeType, Boolean inherit)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.CacheLoadedAssemblies()\r\n   at Microsoft.ML.Runtime.ComponentCatalog.FindLoadableClasses[TSig]()\r\n   at Microsoft.ML.Runtime.EntryPoints.ModuleCatalog..ctor(IExceptionContext ectx)\r\n   at Microsoft.ML.Runtime.EntryPoints.ModuleCatalog.CreateInstance(IExceptionContext ectx)\r\n   at Microsoft.ML.Runtime.Experiment..ctor(IHostEnvironment env)\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n```\r\n\r\nIt works fine on subsequent training calls to similar pipelines. It worked fine under 0.3"""
348521748,661,"b""Microsoft.ML.ImageAnalytics nuget doesn't produce dlls for transforms/learners.""","b'After installing the Microsoft.ML.ImageAnalytics nuget and building, the packages folder for ImageAnalytics is empty.  This is due to the fact that it is not referenced by the Microsoft.ML.ImageAnalytics.csproj file.  The fix would be to add the following line to the .csproj:\r\n\r\n`<IncludeInPackage>Microsoft.ML.ImageAnalytics</IncludeInPackage>`'"
348381909,659,b'Cannot create entry point for a new learner in a package with depends on Microsoft.ML.',"b'The Following instruction ``_jsonNodes.Add(Serialize(""Data.DataViewReference"", input, output));`` is automatocally generated for every entrypoint but _jsonNodes is private member. I did not find a way to add a custom learner in a package which takes Microsoft.ML as a dependency.'"
348287385,657,b'Adding MP3 processing support porting pyAudioAnalysis library',"b'This is a feature request. Currently, I have to use Python libraryhttps://github.com/tyiannak/pyAudioAnalysis in order to process MP3 files and retrieve feature set. I would like to see this library ported to ML.NET functionality.\r\n'"
348126800,655,b'OpenMP support for MKL library and SymSGD.',b'Current MKL library was not built with parallel option to not have dependency on OpenMP because we are still waiting for guidance from legal department on redistributing open mp binary.'
348120663,654,b'Default value of sigmoid parameter for LightGBM',"b""[The default value of the `sigmoid` parameter for LightGBM is 1](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst#sigmoid), however in the ML.Net wrapper it is hardwired to 0.5:\r\nhttps://github.com/dotnet/machinelearning/blob/f9d3973a056ad26bc6cc15c2d7a09f8ae47e30da/src/Microsoft.ML.LightGBM/LightGbmArguments.cs#L404\r\n\r\nWhy is this the case? Shouldn't this parameter either be 1 or exposed on the ML.Net API instead?"""
347946590,650,b'There is a miss spelling of a `CONTRIBUTING.md` file.',"b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\nfixed a spelling of a `CONTRIBUTING.md` file.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
347894183,649,"b""Multi class prediction: Best score doesn't always match prediction""","b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 2.1.202\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI wanted to get ""top-k"" or ""best predictions"" from a multi classification problem. The code:\r\n\r\n```C#\r\nmodel.TryGetScoreLabelNames(out var classMapping);\r\n        foreach (var toEval in dataTrain)\r\n        {\r\n          var prediction = model.Predict(toEval);\r\n          var sortedScores = prediction.Score.Zip(classMapping, Tuple.Create).OrderBy(sk => -sk.Item1).ToArray();\r\n          var sum = prediction.Score.Sum(); // correctly usually ~1\r\n          var topPrediction = sortedScores.First().Item2;\r\n          if (topPrediction != prediction.CarrierId)\r\n          {\r\n            Console.WriteLine(""Dont match. Bad!"");\r\n          }\r\n        }\r\n```\r\nwhere `CarrierId` is my predicted label (a string).\r\n\r\nI\'m using `SDCA` with (roughly):\r\n\r\n```C#\r\nreturn new LearningPipeline()\r\n      {\r\n        CollectionDataSource.Create(dataTrain),\r\n        new Dictionarizer((""CarrierId"", ""Label"")),\r\n       ....\r\n    } \r\n```\r\n\r\n- **What happened?**\r\nSometimes, the predicted label doesn\'t match the to score in `Scores`.\r\n\r\nNote: The class in `CarrierId` is usually the correct class and the top scored class is not correct.'"
347801684,648,b'Pass MKL version to CMAKE from MSBUILD',b'CMAKE uses MKL library to build native SymSGD library. Currently MKL version is hard-coded to 0.0.0.5 but it would be better it this version information is passed from MSBUILD to CMAKE. MSBUILD would retrieve MKL version that is being used from dependencies.prop file in build directory under root.'
347352033,642,b'How to build transform-only pipelines',"b'I found comments, that there should be a way to use transforms without the need of a trainer/learner (i.e., building a ""processing / transform - pipeline instead of an LearningPipeline, cp.  https://github.com/dotnet/machinelearning/issues/259#issuecomment-393362342). Unfourtunately, I could not find out, how to achieve this.\r\n\r\nIn my usecase, I want to determine similarity of documents with n-gram vectorization and cosine distance. The functionalty for featurization is given by the TextFeaturizer (https://docs.microsoft.com/de-de/dotnet/api/microsoft.ml.transforms.textfeaturizer). In this usecase I don\'t want to do a training (yet), but am interessted in the output in the result of the TextFeaturizer itself.\r\n\r\nAccessing the results of partial steps could be helpful for debugging LearningPipelines too (cp. discussion here: https://github.com/dotnet/machinelearning/issues/259).\r\n@TomFinley \r\n'"
347204945,638,b'Package mkl binaries with Hal Learners nuget.',b'Native SymSGD code depends on Mkl libraries during runtime hence both of them should be packaged together to prevent dependency not found issue on macOS and linux.'
347167178,637,"b'Examples in the documentation need  to reference code, rather than embedding C# in the XML'","b""Our examples in the documentation currently aren't very comprehensive, because they live in XML, and it is not easily maintainable to write longer code snippets embedded in XML. \r\n\r\nThe infrastructure for docs.microsoft.com supports cross-referencing other files within the XML. \r\nThose other files can be C# files and have more fully fledged examples, that compile. \r\n\r\nSetup another folder within Microsoft.ML.Tests, similar to scenarios, that will contain examples for each components. More than one component can be used for the scenario, but they should be kept simple. \r\nThose methods can be reused by the tests.\r\n\r\nThis issue will be considered resolved after  setting up one such example end-to-end. """
347096233,633,"b""CpuMath and HalLearners packages don't work with packages.config""","b""### System information\r\n\r\n- **OS version/distro**: Windows.  Visual Studio 15.8\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate a new NET Framework console app.  Ensure it uses `packages.config`.\r\nInstall the `Microsoft.ML` package.\r\nTry to run through a ML.NET scenario - https://www.microsoft.com/net/learn/machine-learning-and-ai/get-started-with-ml-dotnet-tutorial\r\n\r\n- **What happened?**\r\n```\r\nUnhandled Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`1.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Runtime.Learners.LinearTrainerBase`1.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerBase`1.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, String name, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor)\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\n   at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n```\r\n\r\n- **What did you expect?**\r\nIt should work\r\n\r\n### Notes\r\n\r\nThis is because we need the same .targets files we have in the `Microsoft.ML` package:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f6934a0705b8ff2b7ad2d51c9cf4f82f7d1cbd94/pkg/Microsoft.ML/build/netstandard2.0/Microsoft.ML.props#L7-L15\r\n"""
347092277,632,b'Direct API: Static Typing of Data Pipelines',"b'Currently in all iterations of the pipeline concept, whether they be based on the v0.1 idiom of `LearningPipeline`, or the #371 proposal where `IDataView` is directly created, or the refinement of that in #581, or the convenience constructors, or whatever, there is always this idea of a pipeline being a runtime-checked thing, where each stage has some output schema with typed columns indexed by a string name, and all of this is known only at runtime -- at compile time, all the compiler knows is you have *some* estimator, or *some* data view, or something like that, but has no idea what is in it.\r\n\r\nThis makes sense from a practical perspective, since there are many applications where you cannot know the schema until runtime. E.g.: loading a model from a file, or loading a Parquet file, you aren\'t going to know anything until the code actually runs. So we want the underlying system to remain dynamically typed to serve those scenarios, and I do not propose changing that. That said, there are some definite usability costs:\r\n\r\n* Typos on those column names are found at runtime, which is unfortunate.\r\n* Application of the wrong transform or learner is found at runtime.\r\n* Discoverability is an issue. You just sort of have to know what transforms are applicable to your case, which is somewhat difficult since if we were to collect all the things you could apply to data (transform, train a learner), there are probably about 100 of these or thereabouts. Intellisense will be of no help to you here, because at compile time, the only thing the language knows is you have *some*.\r\n\r\nIt\'s sort of like working with `Dictionary<string, object>` as your central data structure, and an API that just takes `Dictionary<string, object>` everywhere. In a way that\'s arbitrarily powerful, but the language itself can give you no help at all about what you should do with it, which is kind of a pity since we have this nice statically typed language we\'re working in.\r\n\r\nSo: a statically typed helper API on top of this that was sufficiently powerful would help increase the confidence that if someone compiles it might run, and also give you some help in the form of proper intellisense of what you can do, while you are typing before you\'ve run anything. Properly structured, if you had strong typing at the columnar level, nearly everything you can do can be automatically discoverable through intellisense. The documentation would correspondingly become a lot more focused.\r\n\r\nThe desire to have something like this is very old, but all prior attempts I recall ran into some serious problems sooner or later. In this issue I discuss such an API that I\'ve been kicking around for a little bit, and at least so far it doesn\'t seem to have any show-stopping problems, at least so far as I\'ve discovered in my initial implementations.\r\n\r\nThe following proposal is built on top of #581. (For those seeking actual code, the current exploratory work in progress is based out of [this branch](https://github.com/TomFinley/machinelearning/tree/tfinley/StrongPipe), which in turn is a branch based of @Zruty0\'s [branch here](https://github.com/Zruty0/machinelearning/tree/feature/estimators/src/Microsoft.ML.Core/Data).)\r\n\r\n# Simple Example\r\n\r\nIt may be that the easiest way to explain the proposal is to show a simple example, then explain it. This will be where we [train sentiment classification](https://github.com/dotnet/machinelearning/blob/89dfc82f5edcfe23015dc2c1291bc7a836188e80/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/SentimentPredictionTests.cs#L24), though I\'ve simplified the text settings to just the diacritics option\r\n\r\n```csharp\r\n// We load two columns, the boolean ""label"" and the textual ""sentimentText"".\r\nvar text = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: \'\\t\', header: true);\r\n\r\n// We apply the text featurizer transform to ""sentimentText"" producing the column ""features"".\r\nvar transformation = text.CreateTransform(r =>\r\n    (r.label, features: r.sentimentText.TextFeaturizer(keepDiacritics: true)));\r\n\r\n// We apply a learner to learn ""label"" given ""features"", which will in turn produce\r\n// float ""score"", float ""probability"", and boolean ""predictedLabel"".\r\nvar training = transformation.CreateTransform(r =>\r\n    r.label.TrainLinearClassification(r.features))\r\n```\r\n\r\nAn alternative is we might do a continuous, non-segmented form (where they are all merged into a single thing):\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: \'\\t\', header: true)\r\n    .ExtendWithTransform(r => (r.label, features: sentimentText.TextFeaturizer(keepDiacritics: true)))\r\n    .ExtendWithTransform(r => r.label.TrainLinearClassification(r.features));\r\n```\r\n\r\nor even the following:\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(c =>\r\n    c.LoadBool(0).TrainLinearClassification(c.LoadText(1).TextFeaturizer(keepDiacritics: true)));\r\n```\r\n\r\n## Developer Story\r\n\r\nHere\'s how I imagine this playing out by someone maybe like me. So: first we have this `TextLoader.Create` method. (Feel free to suggest better names.)\r\n\r\n* The developer knows they have some data file, a TSV with two fields, a label, and some sentiment text. They write `TextLoader.Create`. The first argument is delegate, with a text loader context input, and is responsible for producing a tuple out of things composed out of that context. (Both the method signature, and the XML doc commentary, can explain this.) When they write `c => c.`, intellisense hits them with what they can do... `c.LoadBool`, `c.LoadDouble`, `c.LoadFloat`, etc. These methods produce things like `Scalar<bool>`, `Vector<bool>`, `Scalar<double>`, etc., depending on which is called, what overload is used, and so on. The developer ultimately creates a value-tuple out of all this stuff, with the bool and text loading values.\r\n\r\n* Then they have this object, here called `text`. So they type `text.`, and Intellisense pops up again. They know they want to do *something* with the data they\'ve told the framework to load, and they see `CreateTransform` or `ExtendWithTransform`. Even if they haven\'t read a bit of documentation, that has enough of a name that they think, maybe, ""heck, maybe this is where I belong."" So they choose that.\r\n\r\n* Again they are hit with a delegate. But this time, the input type is the value-tuple created in the loader. And they might type, `text.CreateTransform(r => r.label.TrainLinearClassification`. They try to feed in their `sentimentText`, but the compiler complains at them, saying, I want a `Vector<float>`, not a `Scalar<text>`. So maybe they now do `r.sentimentText.TextFeaturizer` as something sufficiently promising, since it has a promising sounding name and also returns the `Vector<float>` that the classifier claims to want. In VS it looks something like this (click the image to see zoomed in version, sorry that the screenshot is so wide):\r\n\r\n![image](https://user-images.githubusercontent.com/8295757/43598024-96326f6e-9638-11e8-992d-f72e882efe7d.png)\r\n\r\nGiven that setup, there is I think only one thing here that cannot be plausibly discovered via intellisense, or the XML docs that pop up with intellisense, and that is the fact that you would want to start the pipeline with something like `TextLoader.Create`. But I figure this will be so ubiquitous even in ""example 1"" that we can get away with it. There\'s also the detail about training happening through a ""label,"" and unless they happen to have the right type (`Scalar<bool>`) it simply won\'t show up for them. But someone reading documentation on the linear classifier would surely see that extension method and figure out what to do with it.\r\n\r\n# More Details\r\n\r\nNow we drill a little bit more into the shape and design of this API.\r\n\r\n## `PipelineColumn` and its subclasses\r\n\r\nAs we saw in the example, many transformations are indicated by the type of data. For this we have the abstract class `PipelineColumn`, which are manifested to the user through the following abstract subclasses.\r\n\r\n* `Scalar<>` represents a scalar-column of a particular type.\r\n* `Vector<>` represents a vector-valued column of a particular type, where the vector size will be fixed and known (though we might not know the actual size at compiled time)\r\n* `VarVector<>` is similar, but on known size.\r\n* `Key<>`, indicating a key type, which are essentially enumerations into a set.\r\n* `Key<,>`, indicating a key type with a known value, which are essentially enumerations into a set.\r\n* `VarKey<>` which is a key type of unknown cardinality. (These are fairly rare.)\r\n\r\n## `ValueTuple`s of `PipelineColumn`s\r\n\r\nThe pipeline  are the smallest granularity structures. Above that you have collections of these representing the values present at any given time, upon which you can apply more transformations. That value, as mentioned earlier, is a potentially nested value tuple. By potentially nested, what I mean is that you can have as many `ValueTuple`s as you want. So all of the following are fine, if we imagine that `a`, `b`, and `c` are each some sort of `PipelineColumn`:\r\n\r\n```csharp\r\n(a, b)\r\n(a, x: (b, c))\r\na\r\n```\r\n\r\nIn the first case the actual underlying data-view, when produced, would have two columns named `a` and `b`. In the second, there would be three columns, `a`, `x.b`, and `x.c`. In the last, since there is no way as near as I can tell to have a named `ValueTuple<>`, I just for now picked the name `Data`. (Note that in the case where value-tuples are present, the names of the items become the names of the output columns in the data-view schema.)\r\n\r\nThe reason for supporting nesting is, some estimators produce multiple columns (notably, in the example, the binary classification trainer produces three columns), and as far as I can tell there is no way to ""unpack"" a returned value-tuple into another value-tuple. Also it provides a convenient way to just bring along all the inputs, if we wanted to do so, by just assigning the input tuple itself as an item in the output tuple.\r\n\r\n## The Pipeline Components\r\n\r\nAt a higher level of the columns, and the (nested) tuples of columns, you have the objects that represent the pipeline components that describe each step of what you are actually doing with these things. That is, those objects mappings into those value tuples, or between them. To return to the example with `text` and `transformation` and `training`, these have the following types, in the sense that all the following statements in code would be true:\r\n\r\n```csharp\r\ntext is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<bool> label, Scalar<string> sentimentText)>;\r\n\r\ntransformation is Estimator<\r\n    (Scalar<bool> label, Scalar<string> sentimentText),\r\n    (Scalar<bool> label, Scalar<float> features)>;\r\n\r\ntraining is Estimator<\r\n    (Scalar<bool> label, Scalar<float> features),\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nand also in those ""omnibus"" equivalents;\r\n\r\n```csharp\r\npipeline is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nOne may note that the statically-typed API is strongly parallel to the structures proposed in #581. That is, for every core structure following the `IEstimator` idiom laid out in #581, I envision a strongly typed variant of each type. In the current working code, in fact, the objects actually implement those interfaces, but I might go to having them actually wrap them.\r\n\r\nLike the underlying dynamically typed objects, they can be combined in the usual way to form cohesive pipelines. So for example: one could take a `DataReaderEstimator<TIn, TA>` and an `Estimator<TA, TB>` to produce a `DataReaderEstimator<TIn, TB>`. (So for example, when I was using `ExtendWithTransform` instead of )\r\n\r\nThis duality is deliberate. While the *usage* of the static estimators will necessarily not resemble the dynamically typed estimators, based as it is on actual .NET types and identifiers, the structure that is being built up *is* an estimator based pipeline, and so will resemble it structurally. This duality enables one to use static-typing for as long as is convenient, then when done drop back down to the dynamically typed one. But you could also go in reverse, start with something dynamically typed -- perhaps a model loaded from a file -- essentially assert that this dynamically typed thing has a certain shape (which of course could only be checked at runtime), and then from then on continue with the statically-typed pipe. So as soon as the static typing stops being useful, there\'s no cliff -- you can just stop using it at that point, and continue dynamically.\r\n\r\nHowever if you can stay in the statically typed world, that\'s fine. You can fit a strongly typed `Estimator` to to get a strongly typed `Transformer`. You can then further get a strongly typed `DataView` out of a strongly typed `Transformer`. In the end this is still just a veneer, kind of like the `PredictionEngine` stuff, but it\'s a veneer that has a strong likelihood of working.\r\n\r\n## One or Two Implementation Details\r\n\r\nThe following is not something that most users will need to concern themselves with, and we won\'t go into too many details. However at least a loose idea of how the system works might help clear up some of the mystery.\r\n\r\nThe `Scalar<>`, `Vector<>`, etc. classes are abstract classes. The `PipelineColumn`s that are created from the helper extension methods have actual concrete implementations intended to be nested private classes in whatever estimator they\'re associated with. A user never sees those implementations. The component author is responsible for calling the `protected` constructor on those objects, so as to feed it the list of dependencies (what `PipelineColumn` it needs to exist before it would want to chain its own estimator), as well as a little factory object for now called a ""reconciler"" that the analyzer can call once it has satisfied those dependencies.\r\n\r\nThe analyzer itself takes the delegate. It constructs the input object, then pipes it thorugh the delegate. In the case of the estimator,  these are *not* the ones returned from any prior delegate (indeed we have no requirement that there *be* a prior delegate -- estimators can function as independent building blocks), but special instances made for that analysis task). The resulting output will be a value-tuple of `PipelineColumn`s, and by tracing back the dependencies, until we get the graph of dependencies.\r\n\r\nThe actual constructed inputs have no dependencies, and are assumed to just be there already. We then iteratively ""resolve"" dependencies -- we take all columns that have their dependencies resolved, and take some subset that all have the same ""reconciler."" That reconciler is responsible for returning the actual `IEstimator`. Then anything that depends on *that* column gets resolved. And so on.\r\n\r\nIn this way these delegates are declarative structures. Each extension method provides these `PipelineColumn` implementations, which as objects, but it is the analyzer that goes ahead and figures out in what sequence those factory methods will be called, with what names, etc.\r\n\r\nIt might be more clear if we saw that actual engine.\r\n\r\nhttps://github.com/TomFinley/machinelearning/blob/8e0298f64f0a9f439bb83426b09e54967065793b/src/Microsoft.ML.Core/StrongPipe/BlockMaker.cs#L13\r\n\r\nThe system mostly has fake objects everywhere as standins right now just to validate the approach, so for example if I were to actually run the code in the first example, I get the following diagnostic output. (It should be relatively easy to trace back the diagnostic output.)\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name sentimentText\r\nConstructing TextTransform estimator!\r\n    Will make \'features\' out of \'sentimentText\'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make \'score\' out of \'label\', \'features\'\r\n    Will make \'probability\' out of \'label\', \'features\'\r\n    Will make \'predictedLabel\' out of \'label\', \'features\'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nIf I had another example, like this:\r\n\r\n```csharp\r\nvar text = TextLoader.Create(\r\n    ctx => (\r\n    label: ctx.LoadBool(0),\r\n    text: ctx.LoadText(1),\r\n    numericFeatures: ctx.LoadFloat(2, 9)\r\n    ));\r\n\r\nvar transform = text.CreateTransform(r => (\r\n    r.label,\r\n    features: r.numericFeatures.ConcatWith(r.text.Tokenize().Dictionarize().BagVectorize())\r\n    ));\r\n\r\nvar train = transform.CreateTransform(r => (\r\n    r.label.TrainLinearClassification(r.features)\r\n```\r\n\r\nthen the output looks a little something like this:\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name numericFeatures\r\nUsing input with name text\r\nConstructing WordTokenize estimator!\r\n    Will make \'#Temp_0\' out of \'text\'\r\nConstructing Term estimator!\r\n    Will make \'#Temp_1\' out of \'#Temp_0\'\r\nConstructing KeyToVector estimator!\r\n    Will make \'#Temp_2\' out of \'#Temp_1\'\r\nConstructing Concat estimator!\r\n    Will make \'features\' out of \'numericFeatures\', \'#Temp_2\'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make \'score\' out of \'label\', \'features\'\r\n    Will make \'probability\' out of \'label\', \'features\'\r\n    Will make \'predictedLabel\' out of \'label\', \'features\'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nYou can sort of trace though what the analyzer is doing as it resolves dependencies, constructs `IEstimator`s, etc. etc. (Obviously the real version won\'t have all those little console writelines everywhere.)\r\n\r\n## Stuff Not Covered\r\n\r\nThere\'s a lot of stuff I haven\'t yet talked about. We create these blocks, how do we mix and match? What does the strongly typed `Transformer` or `DataView` look like? We talked about the text loader, what about sources that come from actual .NET objects? These we might cover in future editions on this, or in subsequent comments. But I think perhaps this writing has gone on long enough...\r\n\r\n/cc @Zruty0 , @ericstj , @eerhardt , @terrajobst , @motus '"
347079547,631,b'Support read-only properties somehow',"b""As mentioned in #254 , now that we are supporting both fields and properties for the purposes of schema comprehension, it is possible to create properties that act like 'calculated fields':\r\n\r\n```c#\r\n        public class MyDataRow\r\n        {\r\n            private DateTime _dateTime;\r\n\r\n            public float Day { get { return _dateTime.Day; } }\r\n            public float DayOfWeek { get { return (float)_dateTime.DayOfWeek; } }\r\n            // etc\r\n        }\r\n```\r\nBut the above code is not sufficient, because currently we require both **getter and setter** to be present (and public). So you have to add the fake setters that throw.\r\n\r\nIs there a way to have it both ways somehow? We want to ensure that we'll be able to write to a property (in case when we use the underlying class as output), but we also want to allow read-only properties (in case when we use it as input).\r\n\r\n@TomFinley , do you have a recommendation? I am leaning towards allowing getter-only (or private-setter) properties to live, but only for input classes. This means that `SchemaDefinition` / `InternalSchemaDefinition` should have some `IsReadOnly` tracking, and corresponding error/warning messages in case we attempt to generate a 'poke' method for a read-only property ."""
346850249,630,b'Named Entity Recognizer',"b'Hello ML.NET,\r\n\r\nIs there any way I can use ML.NET to created named entities?\r\n\r\nThanks,\r\n-Max'"
346548268,623,b'Port SymSGD',b'This changes adds parallel Stochastic gradient descent trainer know as SymSGD(https://arxiv.org/abs/1705.08030)'
346314170,619,b'Make tests baseline comparison more lenient ',"b""There are a few tests that are disabled because the baseline comparisons fail on the 5th decimal for some of the numbers generated, on some OS. \r\n\r\nAs an example, the RegressorOlsTest() in PredictorTests fails just on the Mac debug version, because only one out of the generated 4896 predictions   doesn't match:\r\n\r\nbaseline:\r\n`2625\t5\t5.09176636\t0.091766357421875\t0.0084210643544793129`\r\n\r\nMac debug run predictions:\r\n`2625\t5\t5.091751\t0.0917510986328125\t0.0084182641003280878`\r\n\r\nI think we should make the tests more lenient to failures like this, modifying the comparison with the baseline to:\r\n1- Have a sensitivity threeshold. Compare up to the 4th, or 6th decimal digit. \r\n2- Count the failures, and declare the test as failed if 3% o the predictions/lines differ?\r\n\r\n@justinormont @TomFinley  @Zruty0  @zeahmed are those acceptable ranges?\r\n"""
346299942,618,"b""System.InvalidOperationException: Entry point 'Trainers.OrdinaryLeastSquaresRegressor' not found""","b""If you add the ML.Net package version 0.0.0.4 to the project, trainers Like `OrdinaryLeastSquaresRegressor`, and `LightGbmRegressor` will be visible, and you can add them to the pipeline. \r\nIf you run a  pipeline with those trainers, and just the ML.Net package on the project, you'll get a runtime exception, with message like: \r\n\r\n`System.InvalidOperationException: Entry point 'Trainers.OrdinaryLeastSquaresRegressor' not found   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode`\r\n\r\nThis is because the actual implementation for those learners lives in additional packages, like Microsoft.ML.LightGBM, or Microsoft.ML.HadLearners. \r\n\r\nTo get those trainers to work with the pipeline, one needs to: \r\n1- Add the respective package to the project\r\n2- Add the following like to their   <PropertyGroup> section in the .csproj file\r\n`<CopyLocalLockFileAssemblies>true</CopyLocalLockFileAssemblies>`\r\n\r\nThis will gather all the dlls in the bin folder, and everything should work correctly. \r\n"""
346250613,617,b'How to dump intermediate data in pipeline?',"b""Hi,\r\n\r\nWhat would be the best way to get intermediate data in a pipeline? I'd like to debug data transformation steps.\r\n\r\nLooking forward for reply\r\n"""
345991586,615,b'Word embeddings',"b'We need to port the existing transform that utilizes well-known word embedding models (GloVe, fastText etc.) to complement our set of one-hot-like text featurization.\r\n'"
345985301,613,b'Hyper-parameter tuning',b'Is there a plan to support hyper-parameter tuning as pipeline step? '
345983359,612,b'Training Statistics for linear learners.',"b""When trying to split OLS as a separate  learner, on PR #611, we noticed that LogisticRegression has a dependency on MKL to generate training stats. \r\n\r\nSince we don't want the core ML.Net package to have dependencies on other large packages, i am removing the stats generation through PR #611 and should introduce a Utility, in the AdditionalLearners package, (or the package that has a reference to Mkl) and produce those stats post training. """
345908562,609,b'Dracula detected in documentation',"b""https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/transforms#feature-selection mentions 'Dracula'. We are not planning to expose this component.\r\n\r\nWe should sadly remove the Dracula mention from the docs."""
345897065,608,b'What to do with VBuffer?',"b'`VBuffer` is a very critical, fundamental type in ML.NET. And as such, it has some critical performance considerations and characteristics it needs to adhere to.\r\n\r\nHowever, it is not as intuitive of a type as it could be. We even wrote a [Care and Feeding doc](https://github.com/dotnet/machinelearning/blob/master/docs/code/VBufferCareFeeding.md) that describes some common pitfalls and other things to be aware of when using the type.\r\n\r\nAt its core, `VBuffer` has 2 responsibilities:\r\n\r\n1. It is a vector that can be either dense or sparse.\r\n2. It is a reusable/cached ""buffer"" to allow minimal allocations and garbage collections.\r\n\r\nWe should do some investigation into what types of improvements we can make to this type.\r\n* Is there something ""base class library""-ish that can be introduced in .NET that would make this type better?\r\n    * Potentially can we use `ArrayPool` to take care of the ""buffer""-ness?  (see https://github.com/dotnet/corefx/issues/4547)\r\n    * Are there other BCL types we could use or introduce?\r\n* Are there alternative API designs that we should consider/incorporate here to make the type more intuitive and less error prone by users?\r\n    * i.e. should some members be encapsulated?\r\n    * Should we split `VBuffer` into two types `SparseVector` and `DenseVector`?\r\n\r\n/cc @TomFinley @Zruty0 '"
345853661,606,b'[Part 4] Create convenience constructors for the Score and TrainAndScore transforms.',"b'This work item is related to #371 and is the 3rd work item in series of creating convenience constructor (cf. #380, #487 and #518). In this work item, convenience constructors will be created following set of transforms. There is also a possibility that the creation of convenience constructors for these transforms is not possible due to complex nature of these transform.\r\n\r\n- TrainAndScoreTransform\r\n- ScoreTransform'"
345831787,605,b'ML Console application throwing native dll not found error',"b""### System information\r\n\r\n- **Windows Server 2016**:\r\n- **Dotnet core\r\nI created one Dotnet core application using VS 2017 and then published it and then copied the published folder having runtimes folder and my application dll to Windows server 2016 where I had installed the dotnet core framework.\r\n\r\nEven time I run the application from command line I get the below error. (I found this dll is under the runtimes folder but somehow application is not able to load)\r\n\r\n Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)"""
345814014,604,b'Investigate using Span<T> and ReadOnlySpan<T>',"b'The framework recently added support for `Span<T>` and `ReadOnlySpan<T>`, which allow you to efficiently work with arrays, subsets of arrays, and unmanaged memory through a single interface. When working with subsets of arrays, it has the added benefit of not needing to create a copy of said data.\r\n\r\nML should investigate using these types where applicable in order to reduce complexity, improve maintainability, improve perf, and improve interop with other frameworks using these types.'"
345812016,603,b'Investigate using ImmutableArray<T> where arrays need to be immutable',b'CoreFX exposes the `ImmutableArray<T>` to allow expressing that an array should be immutable.\r\n\r\nML.NET should investigate using this feature to improve interop with other frameworks and to reduce overhead of maintaining a custom implementation.'
345811229,602,b'Investigate using `readonly struct` and `ref readonly` parameters',"b'C# added support for explicitly declaring structs as `readonly` and allowing you to pass them and return them while preserving the readonly semantic (`in` and `ref readonly`).\r\n\r\nInvestigate using this feature, where appropriate, in order to reduce allocations, increase maintainability, and potentially to improve perf.'"
345809322,601,b'Investigate using ReadOnlySequence<T> to support large array indices.',b'The `ReadOnlySequence<T>` type is designed for working with native buffers with lengths greater than `int.MaxValue`. We should investigate using it to support large arrays.'
345677211,599,b'Feature Importance with ML.NET',"b""Dear ML.NET team and community members,\r\n\r\nI'm so excited about ML.NET. It helps me easily integrate ML capabilities in a C# projects.\r\nBut as evolving project it lacks documentation and code examples. Therefore I'd like to ask the following question.\r\n\r\nMy current project requires not only prediction but reasoning behind it as well. I tried my approach with decision trees in Python/Sklearn and have proved my PoC. Now I'm going to implement the same approach with ML.NET and I'd like to know:\r\n- what is the best way to derive feature importance out of a trained tree/forest?\r\n- what is the best way to implement a method similar to DecisionTreeClassifier.decision_path with ML.NET?\r\n\r\n"""
345556173,598,b'Prediction Error: An attempt was made to keep iterating after the pipe has been reset.  ',"b""### System information\r\n\r\n- **Windows version**: Windows 10 Pro 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**:  2.1.104\r\n- **ML.NET version**: 0.3\r\n\r\n### Issue\r\n\r\n- **What did you do?**: Run a prediction by reusing a predictor model. \r\n![image](https://user-images.githubusercontent.com/1039795/43369838-a86aa910-9329-11e8-8ba6-b80f1d82e65c.png)\r\n\r\nI use this code to get the predictor and cache it in the LanguageModel property. I don't want to open a stream every time I need it. \r\n\r\n- **What happened?**: I randomly get this error. I think it has something to do with multiple threads using the same predictor model object instance. \r\n\r\n![image](https://user-images.githubusercontent.com/1039795/43369851-e1a3ff2e-9329-11e8-87e2-21f9aeab85b2.png)\r\n\r\n\r\n- **What did you expect?**: I expect it not to crash here. Not having to load the zip each time seems like it should make my code faster. \r\n\r\n"""
345515935,596,b'SDCA Error w/ L2=0',"b""When using l2=0 in SDCA, our warning message throws, as it doesn't have enough parameters.\r\n\r\nError:\r\n```\r\n Unexpected exception: Index (zero based) must be greater than or equal to zero and less than the size of the argument list., 'System.FormatException'\r\n   at System.Text.StringBuilder.AppendFormatHelper(IFormatProvider provider, String format, ParamsArray args)\r\n   at System.String.FormatHelper(IFormatProvider provider, String format, ParamsArray args)\r\n   at System.String.Format(String format, Object[] args)\r\n   at Microsoft.ML.Runtime.Data.TlcEnvironment.ConsoleWriter.PrintMessage(IMessageSource sender, ChannelMessage msg) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.Core\\Environment\\TlcEnvironment.cs:line 53\r\n   at Microsoft.ML.Runtime.Data.TlcEnvironment.PrintMessage(IMessageSource src, ChannelMessage msg) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.Core\\Environment\\TlcEnvironment.cs:line 396\r\n   at Microsoft.ML.Runtime.Data.HostEnvironmentBase`1.Dispatcher`1.DispatchCore(IMessageSource sender, TMessage message) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.Core\\Environment\\HostEnvironmentBase.cs:line 338\r\n   at Microsoft.ML.Runtime.Data.HostEnvironmentBase`1.ChannelBase.Warning(MessageSensitivity sensitivity, String fmt, Object[] args) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.Core\\Environment\\HostEnvironmentBase.cs:line 276\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`1.ArgumentsBase.Check(IHostEnvironment env) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.StandardLearners\\Standard\\LinearClassificationTrainer.cs:line 219\r\n   at Microsoft.ML.Runtime.Learners.SdcaMultiClassTrainer..ctor(IHostEnvironment env, Arguments args) in E:\\TLC_git\\TLC\\OpenSource\\src\\Microsoft.ML.StandardLearners\\Standard\\SdcaMultiClass.cs:line 68\r\n```\r\n\r\nCause:\r\n`L2LowerBound` needs to be added to the warning's params.\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs#L210-L212\r\n\r\n\r\n\r\n"""
345456425,595,b'Calculated Feature',"b""Hello,\r\n\r\nis there a way to add a calculated feature?\r\nI get the data in a CSV-File which is loaded with a TextLoader. I'm not able to affect the data in the file. For My model I would use a calculated feature (e. g. NewFeature = Feature1 + Feature2) or any other calculations like manual binning (e. g. if Feature1 < 10 then NewFeature = 1 else if Feature1 >= 10 and Feature1 < 20 then NewFeature = 2 else NewFeature = 3).\r\n\r\nIn the Azure Machine Learning Studio are some tasks which can be used for e. g. SQL Transformation, R-Scripts ..."""
345356862,593,"b""DataCommand classes shouldn't be part of the API""","b'Today we have classes like:\r\n\r\n* [TrainCommand](https://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L35)\r\n* [CrossValidationCommand](https://github.com/dotnet/machinelearning/blob/0e37508501b974cd4779014e6319438d33845dbd/src/Microsoft.ML.Data/Commands/CrossValidationCommand.cs#L22)\r\n* Etc\r\n\r\nThese classes are meant to be invoked from the MAML command line, and not from a normal ""API"" user.\r\n\r\nHowever, this isn\'t possible to tell these shouldn\'t be used because these classes are in the same assembly as the ""TextLoader"" class (`Microsoft.ML.Data.dll`), which is obviously part of the core API and is shown in almost all examples.\r\n\r\nWe should decide what to do with these classes. If we should move them out into a separate assembly/nuget package/etc, so users aren\'t confused that they shouldn\'t be using them.\r\n\r\n/cc @TomFinley @Zruty0 '"
345287036,591,b'Fix documentation formatting',"b'Testing the documentation on the staging environment of docs.microsoft.com, there are a couple things to fix:\r\n\r\n- lists elements need a type attribute present, to be rendered properly\r\n- OGD, and Poisson regressor had the name attribute misplaced. \r\n'"
345165243,590,b'Cannot combine OneVersusAll with FieldAwareFactorizationMachine',"b""The following:\r\n\r\n```C#\r\nOneVersusAll.With(new FieldAwareFactorizationMachineBinaryClassifier(), false);\r\n```\r\n\r\nthrows a `Predictor doesn't implement the expected interface`. How could I combine the two?"""
345157215,589,b'FastForestBinaryClassifier always return same prediction',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 17134.165\r\n- **.NET Version (eg., dotnet --info)**: 4.7.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI tried to use FastForestBinaryClassifier for a learning application and a bool parameter as label.\r\n- **What happened?**\r\nPredicted Label always returns false despite most of my learning data is true. 5000/7000 result of train data true and data quantity is increasing while working. New results are real answers of previous predictions. Prediction always same as what it was at first the time for all kind of prediction input.\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nclass MLData\r\n    {\r\n        public class IrisPrediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public bool PredictedLabels;\r\n        }\r\n\r\n        public class IrisData\r\n        {\r\n            [Column(""0"", name: ""Label"")] public bool Label;\r\n            [Column(""1"")] [VectorType(1000)] public float[] param1;\r\n            [Column(""2"")] [VectorType(1000)] public float[] param2;\r\n            [Column(""3"")] [VectorType(1000)] public float[] param3;\r\n            [Column(""4"")] [VectorType(1000)] public float[] param4;\r\n            [Column(""5"")] [VectorType(1000)] public float[] param5;\r\n            [Column(""6"")] [VectorType(1000)] public float[] param6;\r\n        }\r\n\r\n        public static List<IrisData> History = new List<IrisData>() { };\r\n    }\r\n```\r\n\r\n```\r\nclass MLCore\r\n    {\r\n        private static string AppPath => Path.GetDirectoryName(Environment.GetCommandLineArgs()[0]);\r\n        private static string ModelPath => Path.Combine(AppPath, ""IrisModel.zip"");\r\n        private static PredictionModel<MLData.IrisData, MLData.IrisPrediction> readyModel;\r\n\r\n        internal static async Task<PredictionModel<MLData.IrisData, MLData.IrisPrediction>> TrainAsync()\r\n        {\r\n            var data = MLData.History;\r\n            var collection = CollectionDataSource.Create(data);\r\n\r\n            var pipeline = new LearningPipeline()\r\n            {\r\n                collection,\r\n                new ColumnConcatenator(""Features"", ""param1"",""param2"", ""param3"",""param4"", ""param5"", ""param6""),\r\n\r\n                new FastForestBinaryClassifier(),\r\n\r\n                new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = ""PredictedLabel"" }\r\n            };\r\n\r\n            PredictionModel<MLData.IrisData, MLData.IrisPrediction> model;\r\n\r\n            try\r\n            {\r\n                model = pipeline.Train<MLData.IrisData, MLData.IrisPrediction>();\r\n                await model.WriteAsync(ModelPath);\r\n                PGlobals.learnSuccesfull = true;\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                model = null;\r\n                PGlobals.learnSuccesfull = false;\r\n            }\r\n\r\n            return model;\r\n        }\r\n\r\n        public static async void Learn()\r\n        {\r\n            readyModel = await TrainAsync();\r\n        }\r\n\r\n        public static void Think()\r\n        {\r\n            if (readyModel != null)\r\n            {\r\n                try\r\n                {\r\n                    var prediction = readyModel.Predict(new MLData.IrisData()\r\n                    {\r\n                        param1 = PGlobals.param1,\r\n                        param2 = PGlobals.param2,\r\n                        param3 = PGlobals.param3,\r\n                        param4 = PGlobals.param4,\r\n                        param5 = PGlobals.param5,\r\n                        param6 = PGlobals.param6\r\n                    });\r\n\r\n                    PGlobals.predictedResult = prediction.PredictedLabels;\r\n                }\r\n\r\n                catch\r\n                {\r\n                    //Nothing\r\n                }\r\n            }\r\n        }\r\n    }\r\n```\r\n'"
345153053,588,b'Manually applying ColumnCopier to be able to use OnnxConverter',"b'How do I manually apply the ColumnCopier to the ""taxi-fare-train.csv"" test data from here [https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/taxi-fare](url) so that I can export the PredictionModel using the OnnxConverter?\r\n'"
345132712,586,b'Cursor creation fails on a dataview with sparse vectors',"b'### System information\r\n\r\n- **Windows 10.0.17134**:\r\n- **.NET Version 2.1.301**: \r\n\r\n### Issue\r\n\r\n- The creation of a cursor on a dataview with sparse vectors does not work anymore.\r\n- Expected getter type is VBuffer<float>, produced getter type is VBuffer<VBuffer<float>>.\r\n\r\n### Source code / logs\r\n\r\nThe following code fails.\r\n\r\nclass ExampleASparse\r\n        {\r\n            [VectorType(5)]\r\n            public VBuffer<float> X;\r\n        }\r\n \r\n        [Fact]\r\n        [TestCategory(Cat)]\r\n        public void SparseDataView()\r\n        {\r\n            var inputs = new[] {\r\n                new ExampleASparse() { X = new VBuffer<float> (5, 3, new float[] { 1, 10, 100 }, new int[] { 0, 2, 4 }) },\r\n                new ExampleASparse() { X = new VBuffer<float> (5, 3, new float[] { 2, 3, 5 }, new int[] { 0, 1, 3 }) }\r\n            };\r\n            var host = new TlcEnvironment();\r\n            var data = host.CreateStreamingDataView(inputs);\r\n            VBuffer<float> value = new VBuffer<float>();\r\n            int n = 0;\r\n            using (var cur = data.GetRowCursor(i => true)) // it fails here\r\n            {\r\n                var getter = cur.GetGetter<VBuffer<float>>(0);\r\n                while (cur.MoveNext())\r\n                {\r\n                    getter(ref value);\r\n                    Assert.True(value.Count == 3);\r\n                    ++n;\r\n                }\r\n            }\r\n            Assert.True(n == 2);\r\n            Done();\r\n        }\r\n'"
344956204,585,b'Replace SubComponent with IComponentFactory',"b'When a component is structured in a way that it can use some other component, we are currently using a `SubComponent` object to specify which other component to use. For example, our One-Versus-All (Ova) class can turn any binary classifier into a multi-class classifier. So it has a `SubComponent PredictorType` field on its `Arguments` class, and users can specify which binary classifier that Ova should use.\r\n\r\nThe issues with SubComponent are:\r\n\r\n1. They depend on Dependency Injection in order to create the object.\r\n2. They use ""magic strings"" in order to create the object (since SubComponents are just strings to tell the DI system how to create the object).\r\n\r\nIn our main API, we shouldn\'t be using magic strings, or dependency injection, when you can simply just create objects, or delegates/factories, like a normal OOP API would work.'"
344661222,584,b'Direct API: Scenarios to light up for V1',"b'The following is a preliminary list of required scenarios for the direct access API, that we will use to focus the work. The goal is we want the experience for these to be good and unproblematic. Strictly speaking everything here is *possible* to do right now using the components as they stand implemented today. However, I would say that it isn\'t necessarily a joy to do them, and there are lots of potential ""booby traps"" lurking in the code unless you do everything exactly correctly (e.g., #580).\r\n\r\n* *Simple train and predict*: Start with a dataset in a text file. Run text featurization on text values. Train a linear model over that. (I am thinking sentiment classification.) Out of the result, produce some structure over which you can get predictions programmatically (e.g., the prediction does not happen over a file as it did during training)..\r\n\r\n* *Multi-threaded prediction*. A twist on ""Simple train and predict"", where we account that multiple threads may want predictions at the same time. Because we deliberately do not reallocate internal memory buffers on every single prediction, the PredictionEngine (or its estimator/transformer based successor) is, like most stateful .NET objects, fundamentally not thread safe. This is deliberate and as designed. However, some mechanism to enable multi-threaded scenarios (e.g., a web server servicing requests) should be possible and performant in the new API.\r\n\r\n* *Train, save/load model, predict*: Serve the scenario where training and prediction happen in different processes (or even different machines). The actual test will not run in different processes, but will simulate the idea that the ""communication pipe"" is just a serialized model of some form.\r\n\r\n* *Train with validation set*: Similar to the simple train scenario, but also support a validation set. THe learner might be trees with early stopping.\r\n\r\n* *Train with initial predictor*: Similar to the simple train scenario, . The scenario might be one of the online linear learners that can take advantage of this, e.g., averaged perceptron.\r\n\r\n* *Evaluation*: Similar to the simple train scenario, except instead of having some predictive structure, be able to score another ""test"" data file, run the result through an evaluator and get metrics like AUC, accuracy, PR curves, and whatnot. Getting metrics out of this shoudl be as straightforward and unannoying as possible.\r\n\r\n* *Auto-normalization and caching*: It should be relatively easy for normalization and caching to be introduced for training, if the trainer supports or would benefit from that.\r\n\r\n* *File-based saving of data*: Come up with transform pipeline. Transform training and test data, and save the featurized data to some file, using the `.idv` format. Train and evaluate multiple models over that pre-featurized data. (Useful for sweeping scenarios, where you are training many times on the same data, and don\'t necessarily want to transform it every single time.)\r\n\r\n* *Decomposable train and predict*: Train on Iris multiclass problem, which will require a transform on labels. Be able to reconstitute the pipeline for a prediction only task, which will essentially ""drop"" the transform over labels, while retaining the property that the predicted label for this has a key-type, the probability outputs for the classes have the class labels as slot names, etc. This should be do-able without ugly compromises like, say, injecting a dummy label.\r\n\r\n* *Cross-validation*: Have a mechanism to do cross validation, that is, you come up with a data source (optionally with stratification column), come up with an instantiable transform and trainer pipeline, and it will handle (1) splitting up the data, (2) training the separate pipelines on in-fold data, (3) scoring on the out-fold data, (4) returning the set of evaluations and optionally trained pipes. (People always want metrics out of xfold, they *sometimes* want the actual models too.)\r\n\r\n* *Reconfigurable predictions*: The following should be possible: A user trains a binary classifier, and through the test evaluator gets a PR curve, the based on the PR curve picks a new threshold and configures the scorer (or more precisely instantiates a new scorer over the same predictor) with some threshold derived from that.\r\n\r\n* *Introspective training*: Models that produce outputs and are otherwise black boxes are of limited use; it is also necessary often to understand at least to some degree what was learnt. To outline critical scenarios that have come up multiple times:\r\n\r\n  * When I train a linear model, I should be able to inspect coefficients.\r\n  * The tree ensemble learners, I should be able to inspect the trees.\r\n  * The LDA transform, I should be able to inspect the topics.\r\n\r\n  I view it as essential from a usability perspective that this be discoverable to someone without having to read documentation. E.g.: if I have `var lda = new LdaTransform().Fit(data)` (I don\'t insist on that exact signature, just giving the idea), then if I were to type `lda.` in Visual Studio, *one* of the auto-complete targets should be something like `GetTopics`.\r\n\r\n* *Exporting models*: Models when defined ought to be exportable, e.g., to ONNX, PFA, text, etc.\r\n\r\n* *Visibility*: It should, possibly through the debugger, be not such a pain to actually see what is happening to your data when you apply this or that transform. E.g.: if I were to have the text `""Help I\'m a bug!""` I should be able to see the steps where it is normalized to `""help i\'m a bug""` then tokenized into `[""help"", ""i\'m"", ""a"", ""bug""]` then mapped into term numbers `[203, 25, 3, 511]` then projected into the sparse float vector `{3:1, 25:1, 203:1, 511:1}`, etc. etc.\r\n\r\n* *Meta-components*: Meta-components (e.g., components that themselves instantiate components) should not be booby-trapped. When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\r\n\r\n* *Extensibility*: We can\'t possibly write every conceivable transform and should not try. It should somehow be possible for a user to inject custom code to, say, transform data. This might have a much steeper learning curve than the other usages (which merely involve usage of already established components), but should still be possible.\r\n\r\nCompanion piece for #583.\r\n\r\n/cc @Zruty0 , @eerhardt , @ericstj , @zeahmed , @CESARDELATORRE .'"
344652836,583,b'Full scope of API review',"b""Let us list all issues that we want to handle during the work on 'final user API for ML.NET'.\r\n\r\nThis way we can scope it to something of a *finite* project, a point that @shauheen brought up.\r\n\r\nSo, we spoke with @TomFinley today and arrived at this list. After all the below is done, we can safely call it the 1.0 API.\r\n\r\n- [x] (#581) **Estimators and Transformers** \r\n  - The most challenging part is how to expose the most complicated components, like validating trainers, ensembles, model inspectability etc. through this. It might not even be possible.\r\n  - This work also includes more convenience constructors, like the work in #371 \r\n- [x] (#632) **Type-checked pipelining**. This is @TomFinley 's idea for compile-time schema propagation. \r\n- [x] (TBD) **Saving and loading transformer models**. Make sure that we can save and load models with the same expressive power as before, using the new API.\r\n- [x] (#585) **Replace SubComponent with IComponentFactory**. The only place where dependency injection will take place in the API is during model loading. We are going to remove the remnants of the old string-based system (SubComponents) in favor of the new one.\r\n  - [x] Completely removing SubComponents will probably be breaking the 'maml.exe commandline language', so we'll have to make some decision here.\r\n- [x] (TBD) **Move our type system closer to the C# one**.\r\n  - [x] Replace `DvXXX` with native C# types wherever possible. This means `DvInts` into integers, `DvTimeSpan` into `TimeSpan` etc. \r\n  - Potentially use `Nullable<>` to provide missing values to types that don't have them.\r\n  - [x] (#608) Consider splitting `VBuffer` into two types `SparseVector` and `DenseVector`. \r\n  - If the above is done, the only difference between our type systems will be our vectors (sparse or dense, fixed or variable), and key types.\r\n\r\nAgain, if we do all of the above, we can safely call it API v1.\r\n\r\n@TomFinley @shauheen @ericstj @eerhardt """
344538938,582,b'Support Parquet data format',"b'Is there a way to use [Apache Parquet](https://parquet.apache.org/) file format? If so, is there and example somewhere or can someone provide one?'"
344270480,581,"b'Three major concepts: Estimators, Transformers and Data'","b'This is still an incomplete proposal, but I played for a bit with what I had, and it looks promising to me so far.\r\n\r\nThe general idea is that we narrow our \'zoo\' of components (transforms, predictors, scorers, loaders etc) down to three kinds:\r\n\r\n- The **data**. An `IDataView` with schema, like before.\r\n- The **transformer**. This is an object that can transform data and output data.\r\n```C#\r\n    public interface IDataTransformer\r\n    {\r\n        IDataView Transform(IDataView input);\r\n        ISchema GetOutputSchema(ISchema inputSchema);\r\n    }\r\n```\r\n- The **estimator**. This is the \'trainer\'. The object that can \'train\' a transformer using data.\r\n```C#\r\n    public interface IDataEstimator\r\n    {\r\n        IDataTransformer Fit(IDataView input);\r\n        SchemaShape GetOutputSchema(SchemaShape inputSchema);\r\n    }\r\n```\r\n\r\nObviously, a chain of transformers can itself behave as a transformer, and a chain of estimators can behave like estimators.\r\n\r\nWe also introduce a \'data reader\' (and its estimator), responsible for bringing the data \'from outside\' (think loaders):\r\n```C#\r\n    public interface IDataReader<TIn>\r\n    {\r\n        IDataView Read(TIn input);\r\n        ISchema GetOutputSchema();\r\n    }\r\n\r\n    public interface IDataReaderEstimator<TIn>\r\n    {\r\n        IDataReader<TIn> Fit(TIn input);\r\n        SchemaShape GetOutputSchema();\r\n    }\r\n```\r\n\r\n| Old component | New component |\r\n| ----------------- | ------------------- |\r\n| Data | Data |\r\n| Transform | Transformer |\r\n| Trainable transform (before it is trained) |  Estimator |\r\n| Trainable transform (after it is trained) |  Transformer |\r\n| Trainer | Estimator |\r\n| Predictor | **not sure yet**. I\'m thinking like \'a field of the scoring transformer?\' |\r\n| Scorer | Transformer |\r\n| Untrainable loader | Data reader |\r\n| Trainable loader | Estimator of data reader |\r\n\r\nI have gone through the motions of creating a \'pipeline estimator\' and \'pipeline transformer\' objects, which then allows me to write this code to train and test:\r\n\r\n```C#\r\n            var env = new TlcEnvironment();\r\n\r\n            var pipeline = new EstimatorPipe<IMultiStreamSource>(new MyTextLoader(env, MakeTextLoaderArgs()));\r\n            pipeline.Append(new MyConcatTransformer(env, ""Features"", ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth""))\r\n                    .Append(new MyNormalizer(env, ""Features""))\r\n                    .Append(new MySdca(env));\r\n\r\n            var model = pipeline.Fit(new MultiFileSource(@""e:\\data\\iris.txt""));\r\n\r\n            IrisPrediction[] scoredTrainData = model.Transform(new MultiFileSource(@""e:\\data\\iris.txt""))\r\n                .AsEnumerable<IrisPrediction>(env, reuseRowObject: false)\r\n                .ToArray();\r\n```\r\n\r\nHere, the only catch is the \'MakeTextLoaderArgs\', which is an obnoxiously long way to define the original schema of the text loader. But it is obviously subject to improvement.\r\n\r\nThe full \'playground\' is available at https://github.com/Zruty0/machinelearning/tree/feature/estimators '"
344188667,580,"b""CacheDataView and PredictionEngine don't interact well""","b'### System information\r\n\r\n- **OS version/distro**: all\r\n- **.NET Version (eg., dotnet --info)**:  all\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI\'m trying to port https://www.microsoft.com/net/learn/machine-learning-and-ai/get-started-with-ml-dotnet-tutorial to the \xe2\x80\x9cdirect access\xe2\x80\x9d API.\r\n\r\n```C#\r\n        public class IrisData\r\n        {\r\n            [Column(""0"")]\r\n            public float SepalLength;\r\n\r\n            [Column(""1"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""2"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""3"")]\r\n            public float PetalWidth;\r\n\r\n            [Column(""4"")]\r\n            [ColumnName(""Label"")]\r\n            public string Label;\r\n        }\r\n\r\n        public class IrisPrediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            [KeyType]\r\n            public uint PredictedLabels;\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            using (var env = new TlcEnvironment(seed: 0))\r\n            {\r\n                string dataPath = ""iris-data.txt"";\r\n\r\n                var loader = new TextLoader(env, new TextLoader.Arguments()\r\n                {\r\n                    HasHeader = false,\r\n                    SeparatorChars = new char[] { \',\' },\r\n                    Column = new[] {\r\n                        ScalarCol(""SepalLength"", 0),\r\n                        ScalarCol(""SepalWidth"", 1),\r\n                        ScalarCol(""PetalLength"", 2),\r\n                        ScalarCol(""PetalWidth"", 3),\r\n                        ScalarCol(""Label"", 4, DataKind.Text),\r\n                        }\r\n                }, new MultiFileSource(dataPath));\r\n\r\n                IDataTransform trans = new TermTransform(env, loader, ""Label"");\r\n\r\n               trans = new ConcatTransform(env, trans, ""Features"",\r\n                    ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth"");\r\n\r\n                var trainer = new SdcaMultiClassTrainer(env, new SdcaMultiClassTrainer.Arguments());\r\n\r\n                var cached = new CacheDataView(env, trans, prefetch: null);\r\n                var trainRoles = new RoleMappedData(cached, label: ""Label"", feature: ""Features"");\r\n                var pred = trainer.Train(trainRoles);\r\n\r\n                // Score.\r\n                IDataView scoredData = ScoreUtils.GetScorer(pred, trainRoles, env, trainRoles.Schema);\r\n\r\n                // Do a simple prediction.\r\n                var engine = env.CreatePredictionEngine<IrisData, IrisPrediction>(scoredData);\r\n\r\n                var prediction = engine.Predict(new IrisData()\r\n                {\r\n                    SepalLength = 3.3f,\r\n                    SepalWidth = 1.6f,\r\n                    PetalLength = 0.2f,\r\n                    PetalWidth = 5.1f,\r\n                });\r\n                Console.WriteLine($""Predicted flower type is: {prediction.PredictedLabels}"");\r\n            }\r\n        }\r\n```\r\n\r\n- **What happened?**\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Feature column \'Features\' not found\r\nParameter name: name\r\n   at Microsoft.ML.Runtime.Data.ColumnInfo.CreateFromName(ISchema schema, String name, String descName)\r\n   at Microsoft.ML.Runtime.Data.RoleMappedSchema.MapFromNames(ISchema schema, IEnumerable`1 roles, Boolean opt)\r\n   at Microsoft.ML.Runtime.Data.RoleMappedSchema..ctor(ISchema schema, IEnumerable`1 roles, Boolean opt)\r\n   at Microsoft.ML.Runtime.Data.PredictedLabelScorerBase.BindingsImpl.ApplyToSchema(ISchema input, ISchemaBindableMapper bindable, IHostEnvironment env)\r\n   at Microsoft.ML.Runtime.Data.PredictedLabelScorerBase..ctor(IHostEnvironment env, PredictedLabelScorerBase transform, IDataView newSource, String registrationName)\r\n   at Microsoft.ML.Runtime.Data.MultiClassClassifierScorer..ctor(IHostEnvironment env, MultiClassClassifierScorer transform, IDataView newSource)\r\n   at Microsoft.ML.Runtime.Data.MultiClassClassifierScorer.ApplyToData(IHostEnvironment env, IDataView newSource)\r\n   at Microsoft.ML.Runtime.Data.ApplyTransformUtils.ApplyTransformToData(IHostEnvironment env, IDataTransform transform, IDataView newSource)\r\n   at Microsoft.ML.Runtime.Data.ApplyTransformUtils.ApplyAllTransformsToData(IHostEnvironment env, IDataView chain, IDataView newSource, IDataView oldSource)\r\n   at Microsoft.ML.Runtime.Api.BatchPredictionEngine`2..ctor(IHostEnvironment env, IDataView dataPipeline, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.PredictionEngine`2..ctor(IHostEnvironment env, IDataView dataPipe, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.CreatePredictionEngine[TSrc,TDst](IHostEnvironment env, IDataView dataPipe, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at myApp.Program.Main(String[] args) in C:\\Users\\eerhardt\\source\\repos\\MLNetCore30Test\\Program.cs:line 182\r\n```\r\n- **What did you expect?**\r\nI expected it to work.\r\n\r\n### Notes\r\nThe reason (AFAICT) is because of the CacheDataView usage.  When PredictionEngine is trying to apply all the transforms:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Data/Utilities/ApplyTransformUtils.cs#L84\r\n\r\nIt hits that CacheDataView, which isn\xe2\x80\x99t an IDataTransform, and it escapes out.  Thus, the only transform that gets applied is the Scorer transform, and not any of the transforms used before (like adding the \xe2\x80\x9cFeatures\xe2\x80\x9d column).\r\n\r\nWe work around this [in the tests](https://github.com/dotnet/machinelearning/blob/0e37508501b974cd4779014e6319438d33845dbd/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/IrisPlantClassificationTests.cs#L190-L207) by serializing the IDV out and then reading it back in:\r\n\r\n```C#\r\n        private IDataScorerTransform GetScorer(IHostEnvironment env, IDataView transforms, IPredictor pred, string testDataPath = null)\r\n        {\r\n            using (var ch = env.Start(""Saving model""))\r\n            using (var memoryStream = new MemoryStream())\r\n            {\r\n                var trainRoles = new RoleMappedData(transforms, label: ""Label"", feature: ""Features"");\r\n\r\n\r\n                // Model cannot be saved with CacheDataView\r\n                TrainUtils.SaveModel(env, ch, memoryStream, pred, trainRoles);\r\n                memoryStream.Position = 0;\r\n                using (var rep = RepositoryReader.Open(memoryStream, ch))\r\n                {\r\n                    IDataLoader testPipe = ModelFileUtils.LoadLoader(env, rep, new MultiFileSource(testDataPath), true);\r\n                    RoleMappedData testRoles = new RoleMappedData(testPipe, label: ""Label"", feature: ""Features"");\r\n                    return ScoreUtils.GetScorer(pred, testRoles, env, testRoles.Schema);\r\n                }\r\n            }\r\n        }\r\n```\r\n\r\nI would not expect a user to have to do this.  Any thoughts on how to make this better?\r\n\r\nI removed the CacheDataView from my pipeline, which makes the code work but the training got super slow.  So that seems to be a non-starter.\r\n\r\n/cc @TomFinley @Zruty0 '"
344063866,577,b'Mysterious System.NullReferenceException when attempting Cross Validation.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 17134.167\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\nProduct Information:\r\n Version:  2.1.302\r\n Commit : 9048955601\r\n\r\nHost (useful for support):\r\n  Version: 2.1.2\r\n  Commit:  811c3ce6c0\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAttempted to run cross validation on a pipeline for multiclass classification (MNIST digit recognition dataset).\r\n- **What happened?**\r\nOn the line where I call the `CrossValidate` method, I get a `System.NullReferenceException` exception whose source isn\'t obvious.\r\n- **What did you expect?**\r\nFor the Cross Validation to take place without a hitch, or get a more explicit error.\r\nIf this is actually a simple fixable error on my part, I\'ll be glad to fix it.\r\n\r\n### Source code / logs\r\n```cs\r\nvar pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader(_dataPath)\r\n{\r\n    Arguments = new TextLoaderArguments\r\n    {\r\n        Separator = new[] { \',\' },\r\n        HasHeader = true,\r\n        Column = new[]\r\n        {\r\n            new TextLoaderColumn()\r\n            {\r\n                Name = ""Label"",\r\n                Source = new [] { new TextLoaderRange(0) },\r\n                Type = DataKind.Num\r\n            },\r\n\r\n            new TextLoaderColumn()\r\n            {\r\n                Name = ""Features"",\r\n                Source = new [] { new TextLoaderRange(1, 784) },\r\n                Type = DataKind.Num\r\n            }\r\n        }\r\n    }\r\n});\r\npipeline.Add(OneVersusAll.With(  new FastForestBinaryClassifier() { MinDocumentsInLeafs = 1, NumTrees = 150})); \r\n            \r\nvar crossValidator = new CrossValidator()\r\n{\r\n    NumFolds = 5,\r\n    Kind = MacroUtilsTrainerKinds.SignatureMultiClassClassifierTrainer\r\n};\r\n            \r\nvar crossValidatorOutput = crossValidator.CrossValidate<MNISTData, MNISTPrediction>(pipeline);\r\n```\r\n![image](https://user-images.githubusercontent.com/13185436/43144220-dc677106-8f5c-11e8-91f9-e7634a35eaf4.png)\r\n\r\nI made sure both `pipeline` and `crossValidator` weren\'t `null`. I\'m guessing it has something to do with some of the content of `pipeline` but the documentation and other examples I\'ve seen of the usage of Cross Validation did not allow me to guess what the exact problem was.'"
343933071,576,b'Feature importance for LightGBM',b'Is there a way to provide a LightGBM Feature importance demo code ?'
343762766,573,b'Make sure custom predictors are possible to write using the API',"b""I'd like to leverage the evaluators with custom predictors (specifically a `PredictionModel` not built from ML.Net), though right now that isn't possible as `PredictionModel`'s constructor is internal.\r\n\r\n## Scenario\r\n\r\nWe have a number of what I think are great scenario fits for ML.Net (lot of C# experience, a few models based on static rules currently deployed), but as both a pedagogical aid and a way of comparing any new work vs. existing work I'd like to plug some of our existing models into the ML.Net ecosystem, specifically doing something along the following lines:\r\n\r\n- Model the input, predicted datasets\r\n- Write the code to pull various sets of data\r\n- Instantiate my own `PredictionModel` (with predict ranging from something as simple as returning a hardcoded value, to calling an existing prediction endpoint we have)\r\n- Evaluate the model using one of the existing ML.Net validators, probably saving results\r\n- Evaluate the model using a custom evaluator specific to our projects (though re-usable within the ML.Net ecosystem)\r\n\r\nIteration could then take place on building a model & training it with ML.Net components.\r\n\r\nIs this a workflow that you think is best performed in some other manner, or is it a scenario you'd like to support with ML.Net?  We can evaluate models without using ML.Net, though the more we can keep things in the same ecosystem, the stronger the internal network effect is likely to be (particularly when targeting an engineering team almost exclusively comprised of devs and not data scientists)."""
343364747,571,b'Unsupervised learning in ML.NET and association rules',"b""Hi All,\r\nI was looking at the available trainers in ML.NET on the Microsoft docs website and couldn't find anything for unsupervised learning with association rules.\r\nIs this currently available? If not, do you have plans of adding support for association rules as it is something very interesting to work with.\r\n\r\nThank you"""
343325259,570,b'CrossValidation RegressionMetrics has two more entries than number of folds',"b'I might be incorrect on this, but wouldn\'t the number of `RegressionMetrics` be the same as the number of folds specified in the `CrossValidator`?\r\n\r\n### System information\r\n- Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\n.NET Command Line Tools (2.1.202)\r\n\r\nProduct Information:\r\n Version:            2.1.202\r\n Commit SHA-1 hash:  281caedada\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.202\\\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.9\r\n  Build    : 1632fa1589b0eee3277a8841ce1770e554ece037\r\n```\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan cross validation against a pipeline.\r\n- **What happened?**\r\nThe `RegressionMetrics` count is two more than the number of folds specified.\r\n- **What did you expect?**\r\nThe `RegressionMetrics` count to be the same as the number of folds.\r\n\r\n### Source code / logs\r\n```csharp\r\nvar pipeline = new LearningPipeline\r\n{\r\n    new TextLoader(dataset).CreateFrom<SalaryData>(useHeader: true, separator: \',\'),\r\n    new ColumnConcatenator(""Features"", ""YearsExperience""),\r\n    new GeneralizedAdditiveModelRegressor()\r\n};\r\n\r\nvar crossValidator = new CrossValidator()\r\n{\r\n    Kind = MacroUtilsTrainerKinds.SignatureRegressorTrainer,\r\n    NumFolds = 2\r\n};\r\nvar crossValidatorOutput = crossValidator.CrossValidate<SalaryData, SalaryPrediction>(pipeline);\r\n\r\ncrossValidatorOutput.RegressionMetrics.ForEach(m => Console.WriteLine(m.Rms));\r\n```\r\n\r\n![2018-07-20 14_44_23-clipboard](https://user-images.githubusercontent.com/1578160/43036237-6c8bf9a8-8ccb-11e8-8a79-82f45ccd18cc.png)\r\n\r\n![2018-07-20 14_45_12-clipboard](https://user-images.githubusercontent.com/1578160/43036238-73ff4eb0-8ccb-11e8-9f3b-e4c3b71cbbf9.png)\r\n\r\nLooking at `sklearn`, it seems to have the same number of results as the number of folds:\r\n\r\n```python\r\nfrom sklearn.model_selection import cross_val_score\r\n\r\ncross_val_score(lin_reg, train_set, train_labels, cv=3)\r\n```\r\n\r\n```bash\r\narray([0.96044449, 0.97351702, 0.92777218])\r\n```'"
343305250,569,b'Hosting a pre-trained ML Model in Azure Functions',"b""Hi,\r\n\r\nML.NET + Azure Functions seems like the perfect combination. There's only one problem; ML.NET is x64 and Functions is x86. There is an x64 version of Functions available https://github.com/Azure/azure-functions-core-tools/releases but there is no documentation on how to set it up locally or configure it in Azure.\r\n\r\nI have many scenarios where we'd like to process incoming data / files using ML.NET pre-trained models (I've been working on a sample that combines Cognitive Services OCR to extract bank transactions from screengrabs, and then uses a ML.NET model for classifying the bank transactions into spend categories, but it all falls down when you try and host the model in Functions). when you combine them with Function Bindings to automatically run when new data is added.\r\n\r\nHave you ever tried this hosting scenario? Can you reach out to the Functions team internally (I've raised the question, but have got no response)?\r\n\r\nIt seems like the perfect combination of technologies - but frustratingly it just doesn't work (yet)."""
343298325,568,b'Temporary filename collision',"b""### System information\r\n\r\n- **OS version/distro**: Windows Server 2016\r\n\r\n### Issue\r\n\r\nWhen running simultaneous sweeps (multiple processes), one process tried to open a new temp file which already exists. \r\n\r\n`Unexpected exception: The file 'C:\\Users\\jormont\\AppData\\Local\\Temp\\2\\TLC_25553D77\\0' already exists`\r\n\r\n- **What did you do?**\r\nRunning an AutoML macro sweep w/ four processes on the same machine. \r\n\r\nPerhaps our temporary path names aren't unique enough? \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/211c0439aa7bec33747536a273f90b1718ead24a/src/Microsoft.ML.Data/Model/Repository.cs#L507\r\n\r\nUnsure which call is used to create the `TLC_...` folder, but could be this one:\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Core/Environment/TlcEnvironment.cs#L398\r\n\r\n\r\n### Source code / logs\r\n\r\nError:\r\n```\r\nUnexpected exception: The file 'C:\\Users\\jormont\\AppData\\Local\\Temp\\2\\TLC_25553D77\\0' already exists., 'System.IO.IOException'\r\n   at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath)\r\n   at System.IO.FileStream.Init(String path, FileMode mode, FileAccess access, Int32 rights, Boolean useRights, FileShare share, Int32 bufferSize, FileOptions options, SECURITY_ATTRIBUTES secAttrs, String msgPath, Boolean bFromProxy, Boolean useLongPath, Boolean checkHost)\r\n   at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n   at System.IO.Compression.ZipFileExtensions.ExtractToFile(ZipArchiveEntry source, String destinationFileName, Boolean overwrite)\r\n   at Microsoft.ML.Runtime.Model.RepositoryReader.OpenEntryOrNull(String dir, String name) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\Model\\Repository.cs:line 507\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\Model\\ModelLoading.cs:line 55\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\Model\\ModelLoading.cs:line 89\r\n   at Microsoft.ML.Runtime.Data.ApplyTransformUtils.ApplyTransformToData(IHostEnvironment env, IDataTransform transform, IDataView newSource) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\Utilities\\ApplyTransformUtils.cs:line 47\r\n   at Microsoft.ML.Runtime.Data.ApplyTransformUtils.ApplyAllTransformsToData(IHostEnvironment env, IDataView chain, IDataView newSource, IDataView oldSource) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\Utilities\\ApplyTransformUtils.cs:line 101\r\n   at Microsoft.ML.Runtime.EntryPoints.TransformModel..ctor(IHostEnvironment env, IDataView result, IDataView input) in D:\\TLC\\OpenSource\\src\\Microsoft.ML.Data\\EntryPoints\\TransformModel.cs:line 62\r\n   at Microsoft.ML.Runtime.Data.TextAnalytics.TextTransform(IHostEnvironment env, Arguments input) in D:\\TLC\\source\\TextAnalytics\\TextTransform.cs:line 549\r\n```"""
343255171,567,b'Sweep Range of L2RegularizerWeight in AveragedPerceptron',"b'### Issue\r\n\r\n- **What did you do?**\r\nAutoML macro sweep using the AveragedPerceptron learner\r\n\r\n- **What happened?**\r\nCrashed due to the AutoML sweeper picking exactly 0.5 for L2RegularizerWeight.\r\n\r\n**Error**:\r\n```\r\n  must be in range [0, 0.5)\r\n  Parameter name: L2RegularizerWeight\r\n```\r\n\r\nThe hyperparameter range need to be changed to exclude 0.5 from its range:\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.StandardLearners/Standard/Online/AveragedLinear.cs#L39\r\n'"
343126820,564,b'ML.net timeline on NLP tasks',b'I see in the roadmap there are a lot of NLP things coming soon. \r\n\r\nAny approximate timeline? Or what version they should be in? '
343109861,563,b'Infer.NET',b'Are there any plans to include Infer.NET (from Microsoft Research) in ML.NET? http://infernet.azurewebsites.net/'
342913050,561,b'API to create a TextLoader from class metadata',"b'In the `LearningPipeline` API, we have the ability to create a TextLoader object using metadata applied to a regular C# class:\r\n\r\n```C#\r\npipeline.Add(new TextLoader(dataPath).CreateFrom<HousePriceData>(useHeader: true, separator: \',\'));\r\n\r\npublic class HousePriceData\r\n{\r\n    [Column(ordinal: ""0"")]\r\n    public string Id;\r\n    [Column(ordinal: ""1"")]\r\n    public string Date;\r\n    [Column(ordinal: ""2"", name: ""Label"")]\r\n    public float Price;\r\n    [Column(ordinal: ""3"")]\r\n    public float Bedrooms;\r\n    [Column(ordinal: ""4"")]\r\n    public float Bathrooms;\r\n    [Column(ordinal: ""5"")]\r\n    public float SqftLiving;\r\n    [Column(ordinal: ""6"")]\r\n    public float SqftLot;\r\n    ...\r\n```\r\n\r\nI find it more intuitive to have a class decorated with metadata to use to load data instead of imperatively building up a schema in code, like the following:\r\n\r\n```C#\r\nprivate static TextLoader.Column ScalarCol(string name, int ordinal, DataKind kind = DataKind.Num)\r\n    => new TextLoader.Column() { Name = name, Type = kind, Source = new[] { new TextLoader.Range() { Min = ordinal, Max = ordinal } } };\r\n\r\nvar loader = new TextLoader(env, new TextLoader.Arguments()\r\n{\r\n    HasHeader = true,\r\n    SeparatorChars = new char[] { \',\' },\r\n    // These column declarations are meant to mirror those that appear in HousePriceData.\r\n    Column = new[] {\r\n        ScalarCol(""Id"", 0, DataKind.Text),\r\n        ScalarCol(""Date"", 1, DataKind.Text),\r\n        ScalarCol(""Label"", 2),\r\n        ScalarCol(""Bedrooms"", 3),\r\n        ScalarCol(""Bathrooms"", 4),\r\n        ScalarCol(""SqftLiving"", 5),\r\n        ScalarCol(""SqftLot"", 6),\r\n}, new MultiFileSource(dataPath));\r\n```\r\n\r\nThis issue is being opened to ensure we preserve this behavior with the new direct access API design proposed in #371 (possibly using a different API design, but preserving the functionality).\r\n\r\n/cc @ericstj @TomFinley @Zruty0 @terrajobst '"
342909287,560,b'Simple API to go from a trainer to something that can make predictions',"b'With the API proposal change in https://github.com/dotnet/machinelearning/issues/371, the current proposed API looks something like:\r\n\r\n```C#\r\n... // load data and make transforms\r\n\r\n// Train.\r\nvar trainer = new SdcaRegressionTrainer(env, new SdcaRegressionTrainer.Arguments());\r\nvar cached = new CacheDataView(env, trans, prefetch: null);\r\nvar trainRoles = TrainUtils.CreateExamples(cached, label: ""Label"", feature: ""Features"");\r\nvar pred = trainer.Train(trainRoles);\r\n\r\n// Score.\r\nIDataView scoredData = ScoreUtils.GetScorer(pred, trainRoles, env, trainRoles.Schema);\r\n\r\n// Do a simple prediction.\r\nvar engine = env.CreatePredictionEngine<HousePriceData, HousePricePrediction>(scoredData);\r\n\r\nHousePricePrediction prediction = engine.Predict(new HousePriceData()\r\n....\r\n```\r\n\r\nCompare and contrast the similar code what what we have in the LearningPipeline API:\r\n\r\n```C#\r\n... // load data and make transforms\r\n\r\npipeline.Add(new StochasticDualCoordinateAscentRegressor());\r\n\r\nPredictionModel<HousePriceData, HousePricePrediction> model = pipeline.Train<HousePriceData, HousePricePrediction>();\r\n\r\nHousePricePrediction prediction = model.Predict(new HousePriceData()\r\n....\r\n```\r\n\r\nYou can see the proposed API has what feels like boilerplate code (create a cache data view, create examples, call train, get a scorer, create an engine).  Where the LearningPipeline API simplifies this into roughly one call: call train, get something that can make predictions.\r\n\r\nI don\'t think our simplest API example should have so many concepts in it.  In my mind, the main concepts a new user needs to know about are:\r\n\r\n* Load data\r\n* Do transforms\r\n* Pick a learning algorithm\r\n* Train\r\n* Predict\r\n\r\nHowever, in the current proposed API, they also need to think/learn about:\r\n\r\n* Whether or not they need a cached data view\r\n* Creating roles/examples\r\n    - I\'m not sure which is it. The type is `RoleMappedData`, but the method is named `CreateExamples`.\r\n* An IPredictor object\r\n    - which doesn\'t make predictions\r\n* Calling `GetScorer`, which returns an `IDataView` that we call `scoredData`.\r\n    - Is this object really data, or is it something that does `scoring` as implied by the method name: `GetScorer`?\r\n\r\nIn my opinion, this API is too complex and non-intuitive for first time users. We should investigate ways to make it simpler and see if we can come up with a design with less concepts to learn when first interacting with ML.NET.\r\n\r\n/cc @ericstj @TomFinley @Zruty0 @terrajobst '"
342846651,559,b'LoadTransform and LinearClassificationTrainer doesnot work in AzureFunctions',"b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.400-preview-009063\r\n Commit:    dd0179a67c\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.400-preview-009063\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.1\r\n  Commit:  6985b9f684\r\n```\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to use the ML.net package in azure functions. I am running this https://github.com/dotnet/machinelearning-samples/tree/master/samples/end-to-end-apps/github-labeler inside an azure function.\r\n\r\n- **What happened?**\r\nThe entry point map for these  ```Microsoft.ML.Runtime.Data.LoadTransform``` and ```Microsoft.ML.Runtime.Learners.LinearClassificationTrainer```  types are not getting loaded properly. As a result I am not able to train or test using ML.net inside the Azure Function.\r\n\r\nErrors\r\n```\r\nSystem.Private.CoreLib: Exception while executing function: GithubIssueLabeler. Microsoft.ML.Data: Couldn\'t load model: \'DataLoaderModel\\Transform_001\r\nSystem.Private.CoreLib: Exception while executing function: GithubIssueLabeler. System.Private.CoreLib: Exception has been thrown by the target of an invocation. Microsoft.ML.Data: Couldn\'t load model: \'DataLoaderModel\\Transform_020\\SchemaBindableMapper\\InnerMapper\\Predictor\'.\r\n```\r\n- **What did you expect?**\r\nExpect to work properly.\r\n\r\n### Source code / logs\r\n``` C#\r\n        [FunctionName(""GithubIssueLabeler"")]\r\n        public static async Task<IActionResult> Run([HttpTrigger(AuthorizationLevel.Function, ""get"", ""post"", Route = null)]HttpRequest req, TraceWriter log)\r\n        {\r\n            //var type = typeof(Microsoft.ML.Runtime.Data.LoadTransform);\r\n            //var type1 = typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer);\r\n            log.Info(""Http Issue Webhook Request is Being Processed"");\r\n\r\n            string requestBody = new StreamReader(req.Body).ReadToEnd();\r\n            dynamic data = JsonConvert.DeserializeObject(requestBody);\r\n\r\n            string Action = data?.action;\r\n            dynamic issue = data?.issue;\r\n            dynamic labels = issue?.labels;\r\n\r\n            if (Action == ""opened"" && labels.Count == 0)\r\n            {\r\n                string title = issue?.title;\r\n                int number = issue?.number;\r\n                string body = issue?.body;\r\n                log.Info($""A {number.ToString()} issue with {title} has been opened."");\r\n\r\n                Configuration = new ConfigurationBuilder()\r\n                    .SetBasePath(Directory.GetCurrentDirectory())\r\n                    .AddJsonFile(""appsettings.json"").Build();\r\n\r\n                var labeler = new Labeler(Configuration[""GitHubRepoOwner""], Configuration[""GitHubRepoName""], Configuration[""GitHubToken""]);\r\n                await labeler.PredictAndApplyLabelAsync(number, title, body, log); // can do training or prediting using already load model\r\n                log.Info(""Labeling completed"");\r\n            }\r\n            else\r\n            {\r\n                log.Info(""The issue is already opened or it already has a label"");\r\n            }\r\n\r\n            Console.ReadLine();\r\n            log.Info($""Issue Label request handled"");\r\n            return Action != null\r\n                ? (ActionResult)new OkObjectResult($""Issue Label request handled"")\r\n                : new BadRequestObjectResult(""Please pass a name on the query string or in the request body"");\r\n        }\r\n```\r\n# WorkArounds\r\n\r\nAdding these lines to the function helps the app to run perfectly fine.\r\n```\r\nvar type = typeof(Microsoft.ML.Runtime.Data.LoadTransform);\r\nvar type1 = typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer);\r\n```\r\n\r\ncc @eerhardt \r\n'"
342719538,558,"b""Invalid type ('Vec<R4>') error on Training.""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10 17134.165\r\n- **.NET Version (eg., dotnet --info)**: 4.7.03056\r\n\r\n### Issue\r\nI\'m getting this exception while Train. Couldn\'t find any tip, please help.\r\n\r\n`ArgumentOutOfRangeException: Source column \'Features\' has invalid type (\'Vec<R4>\'): Expected known size vector.`\r\n\r\n- **What did you do?**\r\nCopied some code from iris sample to my project.\r\n- **What happened?**\r\nCouldn\'t train my model.\r\n\r\n\r\n### Source code / logs\r\n\r\n\r\n        public class IrisData\r\n        {\r\n            [Column(""0"")] public float[] param1 = new float[1];\r\n            [Column(""1"")] public float[] param2 = new float[1000];\r\n            [Column(""2"")] public float[] param3 = new float[1000];\r\n            [Column(""3"")] public float[] param4 = new float[1000];\r\n            [Column(""4"")] public float[] param5 = new float[1000];\r\n            [Column(""5"", name: ""Label"")] public string Label;\r\n        }\r\n\r\n        public class IrisPrediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public string PredictedLabels;\r\n        }\r\n\r\n        //Program adds some irisData to this list while working\r\n        public static List<IrisData> History = new List<IrisData>()  { };\r\n        \r\n        private static PredictionModel<IrisData,IrisPrediction> readyModel;\r\n\r\n\r\nWorking code\r\n\r\n        public static async void Learn()\r\n        {\r\n            readyModel = await TrainAsync();\r\n        }\r\n\r\n        internal static async Task<PredictionModel<IrisData, IrisPrediction>> TrainAsync()\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            var data = History;\r\n            var collection = CollectionDataSource.Create(data);\r\n\r\n            pipeline.Add(collection);\r\n            pipeline.Add(new ColumnConcatenator(""Features"", ""param1"", ""param2"", ""param3"", ""param4"", ""param5""));\r\n            pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n\r\n            var model = pipeline.Train<IrisData, IrisPrediction>();\r\n            return model;\r\n        }\r\n\r\n'"
342531912,554,b'Need a doc on Type-to-DataView schema mapping',"b'We should have a doc that describes exactly how we go from \r\n```(csharp)\r\n        public class IrisData\r\n        {\r\n            [Column(""0"")]\r\n            public float Label;\r\n\r\n            [Column(""1"")]\r\n            public float SepalLength;\r\n\r\n            [Column(""2"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""3"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""4"")]\r\n            public float PetalWidth;\r\n        }\r\n```\r\nto the schema of the data view. It should cover:\r\n* Why field types are important, and how they are used\r\n* What exactly is `ColumnAttribute`, `ColumnNameAttribute`\r\n* Handling of vectors and `VectorTypeAttribute`\r\n* Handling of key types and `KeyTypeAttribute`\r\n* `SchemaDefinition` as a means of runtime schema hints.\r\n* Limitations / what can not be done.\r\n'"
342469916,553,b'Introduce code analyzer',"b""Like most sufficiently large codebases the ML.NET project is guilty of having acquired a set of idioms. Internally we had a code analyzer, to help catch some of the most common issues that tended to come up in PRs, but sometimes we don't do this, and need to fix issues later (e.g., #271, #442, #478). I want to migrate that analyzer to the open source repository, to hopefully automate some of this.\r\n\r\nThere are of course other things we could do with an analyzer, once we have one.\r\n\r\n/cc @ericstj """
342443150,552,b'Port native SIMD algorithms for SSE to managed code',"b'### Summary (July 19)\r\n1. Finished preparation work to check in code to ML.NET repo, with:\r\n* [C# implementations](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/CpuMathUtils.DotNetCoreApp.cs) of [SSE intrinsics](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/SseIntrinsics.cs) living in [src/Microsoft.ML.CpuMath](https://github.com/briancylui/machinelearning/tree/SseKey/src/Microsoft.ML.CpuMath)\r\n* [Unit tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.UnitTests/UnitTests.cs) and [performance tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.PerformanceTests/SsePerformanceTests.cs) living in [test/Microsoft.ML.CpuMath.[Unit/Performance]Tests](https://github.com/briancylui/machinelearning/tree/SseKey/test)\r\n2. Resolved multi-targeting issue of targeting two different frameworks: .NET Core App 3.0 and .NET Standard 2.0\r\n3. Added additional unit tests\r\n4. Link to working repo (forked): https://github.com/briancylui/machinelearning\r\n5. Link to original issue page for 12-week timeline: https://github.com/briancylui/machinelearning/issues/1\r\n\r\n### Goals\r\n1.\tPort ML.NET C++ SIMD algorithms for SSE to C#\r\n2.\tEnsure C# Hardware Intrinsics feature for SSE meets the needs of ML.NET\r\n3.\tUnit test all functions and get performance benchmark numbers for before and after changes\r\n4.\t(Stretch) Provide software fallback implementations to support more architectures\r\n\r\n[Keeping only the relevant, high-level details below from original [progress](https://github.com/briancylui/machinelearning/issues/1) page to give a general sense of progress]\r\n### Progress\r\n\r\n**Week 2 (Jun 25-29): Port SIMD operations in .NET to managed code outside of ML.NET**\r\n- [x] Implement SSE support and software fallbacks in managed code for all key intrinsics\r\n- [x] Comply with coding style standard\r\n- [x] Implement working unit tests for all key intrinsics\r\n- [x] Implement working performance tests for all key intrinsics using [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) ([slides](https://microsoft.sharepoint.com/:p:/r/teams/netfx/corefx/_layouts/15/Doc.aspx?sourcedoc=%7Bf4cdc660-09d2-40ae-a099-4c6bf213bec1%7D&action=default) and [recording](https://microsoft.sharepoint.com/teams/netfx/corefx/Documents/Forms/AllItems.aspx?id=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL%2Fmodern%20BCL%20talk%20series%20%2D%20Benchmark%2ENET%204%2027%202018%2Emp4&parent=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL&p=true&slrid=1efa769e-e056-0000-7f34-41a0941dbef8))\r\n- [x] Present performance results in a table ([SsePerf-report-github.pdf](https://github.com/briancylui/machinelearning/files/2157186/SsePerf-report-github.pdf))\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.15063.1155 (1703/CreatorsUpdate/Redstone2)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\nFrequency=3515623 Hz, Resolution=284.4446 ns, Timer=TSC\r\n.NET Core SDK=2.1.300\r\n  [Host]     : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n  DefaultJob : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n\r\n\r\n```\r\n|                    Method |       Mean |      Error |     StdDev |\r\n|-------------------------- |-----------:|-----------:|-----------:|\r\n|            NativeDotUPerf |   363.2 us |  7.7293 us | 18.8143 us |\r\n|                MyDotUPerf |   340.2 us |  6.7218 us |  8.0018 us |\r\n|           NativeDotSUPerf | 2,178.3 us | 43.4641 us | 40.6563 us |\r\n|               MyDotSUPerf | 2,144.7 us | 19.1638 us | 16.0027 us |\r\n|          NativeSumSqUPerf |   540.6 us |  3.0299 us |  2.8342 us |\r\n|              MySumSqUPerf |   538.8 us |  2.5507 us |  2.3859 us |\r\n|            NativeAddUPerf |   313.9 us |  2.5163 us |  2.3537 us |\r\n|                MyAddUPerf |   303.3 us |  4.5125 us |  4.2210 us |\r\n|           NativeAddSUPerf | 2,691.8 us | 29.4588 us | 27.5558 us |\r\n|               MyAddSUPerf | 2,658.1 us | 51.3336 us | 64.9206 us |\r\n|       NativeAddScaleUPerf |   300.0 us |  5.5529 us |  5.1941 us |\r\n|           MyAddScaleUPerf |   309.8 us |  5.3974 us |  4.7846 us |\r\n|      NativeAddScaleSUPerf | 2,550.9 us | 21.8322 us | 20.4218 us |\r\n|          MyAddScaleSUPerf | 2,805.3 us | 20.5171 us | 19.1917 us |\r\n|          NativeScaleUPerf |   131.4 us |  0.6347 us |  0.5626 us |\r\n|              MyScaleUPerf |   130.7 us |  1.2159 us |  1.1373 us |\r\n|           NativeDist2Perf |   336.4 us |  2.0555 us |  1.9227 us |\r\n|               MyDist2Perf |   335.2 us |  8.3427 us | 11.4196 us |\r\n|         NativeSumAbsUPerf |   258.0 us |  1.6470 us |  1.5406 us |\r\n|            MySumAbsqUPerf |   258.9 us |  0.9447 us |  0.7889 us |\r\n| NativeMulElementWiseUPerf |   466.4 us |  1.9625 us |  1.6388 us |\r\n|     MyMulElementWiseUPerf |   467.2 us |  4.3560 us |  4.0747 us |\r\n\r\n**Week 3-5 (Jul 2-20): Port algo to C#, write unit tests and performance tests, check in code**\r\n- [x] Apply real data to test implemented managed code using BenchmarkDotNet\r\n- [x] Integrate local code into ML.NET repo to prepare for checking in code, including:\r\n* C# implementations of intrinsics\r\n* Unit tests\r\n* Performance tests\r\n- [x] Implement additional unit tests to test the complete code paths for two different target frameworks\r\n- [x] Enable multi-targeting\r\n- [x] Make the switch to turn on or off implemented code at will with the UseIntrinsics build attribute\r\n- [x] Check in code with PR #562 \r\n\r\n**Week 6 (Jul 23-27)**\r\n- [x] Participate in Microsoft Hackathon\r\n- [x] Attend IEEE conference\r\n\r\n**Week 7 (Jul 30-Aug 3)**\r\n- [x] Respond to PR comments and Intel partners\r\n- [x] Fix build issues in multi-targeting and disabling netcoreapp3.0 test projects\r\n- [x] Hard-code unit tests\r\n- [x] Introduced a custom random seed in perf tests based on environmental variables for better testing\r\n- [x] Major style changes to best utilize existing libraries and ensure aggressive inlining wherever needed\r\n- [x] Document follow-up action items for performance enhancement in an issue page (https://github.com/briancylui/machinelearning/issues/2)\r\n- [x] Fix perf issues of some SSE intrinsics in compliance with C# 7.3 updates\r\n- [x] Fix merge conflicts and obtain green builds for PR\r\n- [x] PR on SSE key intrinsics, as well as their unit tests and perf tests, with multi-targeting, is approved\r\n\r\n**Week 8-9 (Aug 6-17)**\r\n- [x] PR is merged\r\n- [x] Scale up implementation, unit tests, and performance tests to cover all SSE intrinsics\r\n- [x] Write AVX implementations \r\n- [x] Performance test before and after. We should see some perf gains here.\r\n- [x] Check in code to ML.NET (submitted PR)\r\n\r\nPerf test results for all active SSE hardware intrinsics:\r\n``` ini\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.17134\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                     Method |        Mean |      Error |     StdDev |      Median |\r\n|--------------------------- |------------:|-----------:|-----------:|------------:|\r\n|       NativeAddScalarUPerf |    221.7 us |   4.323 us |   5.467 us |    220.8 us |\r\n|      ManagedAddScalarUPerf |    217.3 us |   4.207 us |   3.729 us |    215.5 us |\r\n|           NativeScaleUPerf |    219.0 us |   2.368 us |   2.215 us |    218.9 us |\r\n|          ManagedScaleUPerf |    182.2 us |   2.677 us |   2.504 us |    182.4 us |\r\n|        NativeScaleSrcUPerf |    252.4 us |   4.404 us |   3.904 us |    250.8 us |\r\n|       ManagedScaleSrcUPerf |    271.5 us |   5.357 us |   6.377 us |    272.0 us |\r\n|        NativeScaleAddUPerf |    230.6 us |   3.230 us |   3.021 us |    230.5 us |\r\n|       ManagedScaleAddUPerf |    232.3 us |   3.281 us |   2.908 us |    231.8 us |\r\n|        NativeAddScaleUPerf |    317.5 us |   4.360 us |   4.079 us |    316.0 us |\r\n|       ManagedAddScaleUPerf |    317.1 us |   4.778 us |   3.990 us |    317.5 us |\r\n|       NativeAddScaleSUPerf |  4,135.9 us |  66.596 us |  62.294 us |  4,126.9 us |\r\n|      ManagedAddScaleSUPerf |  4,812.6 us |  39.148 us |  34.704 us |  4,803.0 us |\r\n|    NativeAddScaleCopyUPerf |    505.4 us |   5.658 us |   4.725 us |    503.8 us |\r\n|   ManagedAddScaleCopyUPerf |    481.7 us |   9.140 us |   8.550 us |    480.0 us |\r\n|             NativeAddUPerf |    316.5 us |   5.698 us |   5.330 us |    314.7 us |\r\n|            ManagedAddUPerf |    335.2 us |  12.130 us |  23.944 us |    321.9 us |\r\n|            NativeAddSUPerf |  4,249.0 us |  58.001 us |  54.255 us |  4,254.0 us |\r\n|           ManagedAddSUPerf |  4,583.9 us |  78.739 us |  73.652 us |  4,556.6 us |\r\n|  NativeMulElementWiseUPerf |    552.5 us |   7.078 us |   5.911 us |    551.5 us |\r\n| ManagedMulElementWiseUPerf |    507.9 us |   7.059 us |   6.258 us |    507.8 us |\r\n|             NativeSumUPerf |    289.2 us |   5.435 us |   5.084 us |    287.6 us |\r\n|            ManagedSumUPerf |    288.3 us |   2.815 us |   2.350 us |    287.8 us |\r\n|           NativeSumSqUPerf |    283.2 us |   1.572 us |   1.393 us |    283.3 us |\r\n|          ManagedSumSqUPerf |    289.8 us |   2.493 us |   2.210 us |    288.8 us |\r\n|       NativeSumSqDiffUPerf |    289.4 us |   3.621 us |   3.387 us |    289.4 us |\r\n|      ManagedSumSqDiffUPerf |    290.9 us |   2.772 us |   2.593 us |    290.0 us |\r\n|          NativeSumAbsUPerf |    289.2 us |   4.836 us |   4.524 us |    287.0 us |\r\n|         ManagedSumAbsUPerf |    293.1 us |   1.338 us |   1.186 us |    293.2 us |\r\n|      NativeSumAbsDiffUPerf |    290.7 us |   5.000 us |   4.677 us |    288.8 us |\r\n|     ManagedSumAbsDiffUPerf |    294.4 us |   5.242 us |   4.903 us |    293.0 us |\r\n|          NativeMaxAbsUPerf |    288.0 us |   3.924 us |   3.671 us |    285.8 us |\r\n|         ManagedMaxAbsUPerf |    290.1 us |   2.614 us |   2.317 us |    289.0 us |\r\n|      NativeMaxAbsDiffUPerf |    292.1 us |   4.805 us |   4.495 us |    289.6 us |\r\n|     ManagedMaxAbsDiffUPerf |    290.6 us |   2.083 us |   1.846 us |    290.3 us |\r\n|             NativeDotUPerf |    328.8 us |   3.844 us |   3.407 us |    328.6 us |\r\n|            ManagedDotUPerf |    333.8 us |   2.154 us |   1.910 us |    333.3 us |\r\n|            NativeDotSUPerf |  3,414.2 us |  67.058 us |  68.864 us |  3,393.7 us |\r\n|           ManagedDotSUPerf |  3,753.1 us |  37.440 us |  33.189 us |  3,737.5 us |\r\n|            NativeDist2Perf |    332.3 us |   3.152 us |   2.632 us |    332.0 us |\r\n|           ManagedDist2Perf |    333.7 us |   4.368 us |   3.647 us |    332.0 us |\r\n|    NativeSdcaL1UpdateUPerf |    607.5 us |   8.506 us |   7.957 us |    608.7 us |\r\n|   ManagedSdcaL1UpdateUPerf |    600.8 us |  12.003 us |  27.820 us |    591.3 us |\r\n|   NativeSdcaL1UpdateSUPerf | 13,445.5 us | 116.336 us | 108.821 us | 13,447.1 us |\r\n|  ManagedSdcaL1UpdateSUPerf | 13,824.3 us |  97.564 us |  86.488 us | 13,795.3 us |\r\n\r\nPerf tests results for all managed intrinsics with AVX enhancement:\r\n``` ini\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.17134\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                     Method |        Mean |       Error |      StdDev |\r\n|--------------------------- |------------:|------------:|------------:|\r\n|      ManagedAddScalarUPerf |    157.3 us |   1.3138 us |   1.1647 us |\r\n|          ManagedScaleUPerf |    177.0 us |   3.5143 us |   7.5649 us |\r\n|       ManagedScaleSrcUPerf |    260.5 us |   0.9317 us |   0.8715 us |\r\n|       ManagedScaleAddUPerf |    170.3 us |   1.6569 us |   1.5499 us |\r\n|       ManagedAddScaleUPerf |    272.5 us |   5.4200 us |   9.2035 us |\r\n|      ManagedAddScaleSUPerf |  5,253.6 us | 105.0419 us | 163.5375 us |\r\n|   ManagedAddScaleCopyUPerf |    448.2 us |  11.0005 us |  19.8362 us |\r\n|            ManagedAddUPerf |    263.4 us |   2.5347 us |   2.2469 us |\r\n|           ManagedAddSUPerf |  4,256.5 us |  38.0944 us |  33.7697 us |\r\n| ManagedMulElementWiseUPerf |    441.7 us |   3.2423 us |   2.8742 us |\r\n|            ManagedSumUPerf |    161.0 us |   1.3688 us |   1.2134 us |\r\n|          ManagedSumSqUPerf |    165.0 us |   0.4772 us |   0.4230 us |\r\n|      ManagedSumSqDiffUPerf |    179.5 us |   1.1673 us |   1.0919 us |\r\n|         ManagedSumAbsUPerf |    174.9 us |   3.4667 us |   5.9799 us |\r\n|     ManagedSumAbsDiffUPerf |    178.7 us |   0.6264 us |   0.4529 us |\r\n|         ManagedMaxAbsUPerf |    168.2 us |   1.1892 us |   1.0542 us |\r\n|     ManagedMaxAbsDiffUPerf |    179.7 us |   1.9884 us |   1.7626 us |\r\n|            ManagedDotUPerf |    258.1 us |   2.6630 us |   2.2237 us |\r\n|           ManagedDotSUPerf |  3,297.7 us |  23.2337 us |  19.4012 us |\r\n|           ManagedDist2Perf |    258.8 us |   3.9883 us |   3.5355 us |\r\n|   ManagedSdcaL1UpdateUPerf |    545.0 us |  10.7959 us |  17.1234 us |\r\n|  ManagedSdcaL1UpdateSUPerf | 13,624.1 us |  34.6645 us |  32.4252 us |\r\n\r\n**Week 10-11 (Stretch) (Aug 20-31)**\r\n- [x] Provide software fallback implementations (stretch goals)\r\n- [x] Respond to PR feedback for AVX intrinsics\r\n- [x] Streamlined perf test layout\r\n- [x] Report improvement in running time of intrinsics: averaged 17.78%\r\n- [x] Report improvement in running time of end-to-end real-life user scenarios: 13.88%\r\n- [x] Get ML.NET to run on Raspberry Pi\r\n- [x] Present on August 31 (11am-12nn 25/3365, also on Skype)\r\n\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=2.2.100-refac-20180613-1\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type |          Method |        Mean |      Error |     StdDev |\r\n|----------------------- |---------------- |------------:|-----------:|-----------:|\r\n|    AvxPerformanceTests |      AddScalarU |    152.8 us |   3.200 us |   2.993 us |\r\n| NativePerformanceTests |      AddScalarU |    183.6 us |   1.962 us |   1.739 us |\r\n|    SsePerformanceTests |      AddScalarU |    188.7 us |   2.526 us |   2.363 us |\r\n|    AvxPerformanceTests |          ScaleU |    172.6 us |   3.406 us |   3.497 us |\r\n| NativePerformanceTests |          ScaleU |    185.1 us |   3.683 us |   3.941 us |\r\n|    SsePerformanceTests |          ScaleU |    189.8 us |   5.175 us |   5.083 us |\r\n|    AvxPerformanceTests |       ScaleSrcU |    260.7 us |   4.639 us |   5.156 us |\r\n| NativePerformanceTests |       ScaleSrcU |    273.6 us |   4.780 us |   4.237 us |\r\n|    SsePerformanceTests |       ScaleSrcU |    275.8 us |   3.545 us |   3.142 us |\r\n|    AvxPerformanceTests |       ScaleAddU |    153.8 us |   3.020 us |   2.522 us |\r\n| NativePerformanceTests |       ScaleAddU |    204.2 us |   2.024 us |   1.794 us |\r\n|    SsePerformanceTests |       ScaleAddU |    201.3 us |   2.281 us |   2.133 us |\r\n|    AvxPerformanceTests |       AddScaleU |    277.9 us |   5.266 us |   6.268 us |\r\n| NativePerformanceTests |       AddScaleU |    321.4 us |   9.161 us |   7.650 us |\r\n|    SsePerformanceTests |       AddScaleU |    322.5 us |   8.266 us |  16.121 us |\r\n|    AvxPerformanceTests |      AddScaleSU |  4,433.3 us |  80.711 us |  75.498 us |\r\n| NativePerformanceTests |      AddScaleSU |  4,129.7 us |  81.846 us |  76.559 us |\r\n|    SsePerformanceTests |      AddScaleSU |  4,718.3 us |  59.922 us |  50.038 us |\r\n|    AvxPerformanceTests |   AddScaleCopyU |    447.0 us |   8.758 us |  10.086 us |\r\n| NativePerformanceTests |   AddScaleCopyU |    479.4 us |   5.484 us |   4.861 us |\r\n|    SsePerformanceTests |   AddScaleCopyU |    481.8 us |   3.736 us |   3.312 us |\r\n|    AvxPerformanceTests |            AddU |    283.1 us |   4.842 us |   4.292 us |\r\n| NativePerformanceTests |            AddU |    345.2 us |   2.573 us |   2.281 us |\r\n|    SsePerformanceTests |            AddU |    343.6 us |   2.210 us |   2.067 us |\r\n|    AvxPerformanceTests |           AddSU |  4,220.7 us |  56.154 us |  52.526 us |\r\n| NativePerformanceTests |           AddSU |  4,099.2 us |  51.729 us |  45.856 us |\r\n|    SsePerformanceTests |           AddSU |  4,582.3 us |  46.382 us |  41.116 us |\r\n|    AvxPerformanceTests | MulElementWiseU |    452.8 us |   4.688 us |   4.156 us |\r\n| NativePerformanceTests | MulElementWiseU |    461.9 us |   7.896 us |   7.000 us |\r\n|    SsePerformanceTests | MulElementWiseU |    461.7 us |   2.374 us |   1.982 us |\r\n|    AvxPerformanceTests |            SumU |    164.5 us |   3.516 us |   4.186 us |\r\n| NativePerformanceTests |            SumU |    285.2 us |   3.615 us |   3.205 us |\r\n|    SsePerformanceTests |            SumU |    283.0 us |   3.259 us |   2.889 us |\r\n|    AvxPerformanceTests |          SumSqU |    165.2 us |   1.658 us |   1.550 us |\r\n| NativePerformanceTests |          SumSqU |    262.4 us |   2.580 us |   2.413 us |\r\n|    SsePerformanceTests |          SumSqU |    261.7 us |   1.935 us |   1.810 us |\r\n|    AvxPerformanceTests |      SumSqDiffU |    177.9 us |   2.384 us |   1.991 us |\r\n| NativePerformanceTests |      SumSqDiffU |    289.5 us |   2.508 us |   2.095 us |\r\n|    SsePerformanceTests |      SumSqDiffU |    290.5 us |   1.844 us |   1.725 us |\r\n|    AvxPerformanceTests |         SumAbsU |    178.5 us |   2.198 us |   1.948 us |\r\n| NativePerformanceTests |         SumAbsU |    260.4 us |   2.086 us |   1.951 us |\r\n|    SsePerformanceTests |         SumAbsU |    268.2 us |   4.085 us |   3.821 us |\r\n|    AvxPerformanceTests |     SumAbsDiffU |    186.0 us |   1.551 us |   1.451 us |\r\n| NativePerformanceTests |     SumAbsDiffU |    289.1 us |   1.975 us |   1.649 us |\r\n|    SsePerformanceTests |     SumAbsDiffU |    299.8 us |   2.306 us |   2.044 us |\r\n|    AvxPerformanceTests |         MaxAbsU |    177.1 us |   2.103 us |   1.864 us |\r\n| NativePerformanceTests |         MaxAbsU |    263.5 us |   1.667 us |   1.560 us |\r\n|    SsePerformanceTests |         MaxAbsU |    267.9 us |   4.266 us |   3.562 us |\r\n|    AvxPerformanceTests |     MaxAbsDiffU |    185.6 us |   1.796 us |   1.592 us |\r\n| NativePerformanceTests |     MaxAbsDiffU |    289.0 us |   2.099 us |   1.963 us |\r\n|    SsePerformanceTests |     MaxAbsDiffU |    301.7 us |   3.368 us |   2.986 us |\r\n|    AvxPerformanceTests |            DotU |    264.1 us |   4.975 us |   5.323 us |\r\n| NativePerformanceTests |            DotU |    344.0 us |   1.875 us |   1.662 us |\r\n|    SsePerformanceTests |            DotU |    350.5 us |   2.387 us |   2.116 us |\r\n|    AvxPerformanceTests |           DotSU |  3,289.4 us |  36.279 us |  32.160 us |\r\n| NativePerformanceTests |           DotSU |  3,381.5 us |  41.831 us |  39.129 us |\r\n|    SsePerformanceTests |           DotSU |  3,766.5 us |  32.342 us |  28.670 us |\r\n|    AvxPerformanceTests |           Dist2 |    266.8 us |   5.161 us |   4.310 us |\r\n| NativePerformanceTests |           Dist2 |    357.5 us |   3.980 us |   3.722 us |\r\n|    SsePerformanceTests |           Dist2 |    373.4 us |   7.129 us |   7.321 us |\r\n|    AvxPerformanceTests |   SdcaL1UpdateU |    559.8 us |   8.247 us |   7.311 us |\r\n| NativePerformanceTests |   SdcaL1UpdateU |    616.0 us |   9.798 us |   8.685 us |\r\n|    SsePerformanceTests |   SdcaL1UpdateU |    630.3 us |  18.576 us |  54.772 us |\r\n|    AvxPerformanceTests |  SdcaL1UpdateSU | 13,510.0 us | 104.569 us |  97.814 us |\r\n| NativePerformanceTests |  SdcaL1UpdateSU | 12,786.0 us |  70.993 us |  66.407 us |\r\n|    SsePerformanceTests |  SdcaL1UpdateSU | 12,874.8 us | 391.218 us | 401.752 us |\r\n``` ini\r\n// * Warnings *\r\nMultimodalDistribution\r\n  SsePerformanceTests.SdcaL1UpdateU: Toolchain=InProcessToolchain -> It seems that the distribution is multimodal (mValue = 4.25)\r\n\r\n// * Legends *\r\n  Mean   : Arithmetic mean of all measurements\r\n  Error  : Half of 99.9% confidence interval\r\n  StdDev : Standard deviation of all measurements\r\n  1 us   : 1 Microsecond (0.000001 sec)\r\n```\r\n\r\n**Week 12 (Sept 3-7)**\r\n- [x] Write blog post on how ML.NET is taking advantage of .NET Core hardware intrinsics, and AVX vs SSE comparisons (both implementation and runtime perf)\r\n- [x] Documented future perf enhancement measures (e.g. optimizing loops and alignment issues at the assembly/instruction level) in https://github.com/briancylui/machinelearning/issues/2\r\n- [x] Clean up, presentation, close out remaining issues'"
342210925,551,b'Score column is missing. Parameter name ScoreColumn.',b'### Issue\r\nThrows an exception \r\n- **What did you do?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866807-475cd2a8-8a76-11e8-9509-d8d147534fa7.png)\r\n\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866529-6e75a5d2-8a75-11e8-8aaf-b4a609affc96.png)\r\n\r\n- **What did you expect?**\r\nTo train without errors or warnings that I have.\r\n### Source code / logs\r\n**ML.NET Version: 0.3.0**\r\n![image](https://user-images.githubusercontent.com/35253870/42866497-59a16876-8a75-11e8-80c8-dfe0ca695d56.png)\r\n![image](https://user-images.githubusercontent.com/35253870/42866716-0f85de24-8a76-11e8-8da4-8cd233d3f7d3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/35253870/42866191-96d304a8-8a74-11e8-99da-4eb762792eb0.png)\r\n'
342139834,549,b'Ensure ONNX export is Windows RS5 compatible.',b'Added more tests for ONNX export and ran the model on RS5 machine to ensure model loads and evaluates.'
342110400,547,b'ColumnType not properly implements IEquatable',"b""https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Data/ColumnType.cs\r\nAccording to https://msdn.microsoft.com/en-us/library/ms131190(v=vs.110).aspx (see Notes to Implementers:) we suppose to also override GetHashCode which we don't do.\r\n"""
342077809,546,b'Rename tlcresources in Resource manager',"b'```\r\n        private const string DefaultUrl = ""https://aka.ms/tlc-resources/"";\r\n      \r\n        private static string TlcResourcesUrl\r\n```\r\nwe have this TLC mentions in https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs\r\nand it would be nice to rename them to something ml.net specific.\r\n\r\nIn same time we need to make sure default url should point to valid location (we can\'t just rename it in code, we also need to update aka.ms)'"
342056815,544,b'CrossValidation fails with a valid pipeline',"b'### System information\r\n\r\n- **Windows 10 Home (1803) - 64bit**:\r\n- **.NET Version 2.1.202**: \r\n- **WPF application with includes class libraries in .net 4.7 framework version**:\r\n\r\n### Issue\r\n\r\nIt is not possible for me to perform a CrossValidation on a Pipline, which I use for training my model. The training is performed without any issues. Normal evaluation works correctly (using classes like BinaryClassificationEvaluator or RegressionEvaluator) but the CrossValidation ends with an error. The error is as follows:\r\n> InvalidOperationException: No valid training instances found, all instances have missing features.\r\n\r\n\r\n### Source code / logs\r\n\r\n- Pipeline body is like:\r\n`          \r\n     \r\n                new TextLoader(filePath).CreateFrom<ReopenedIssueData>(),\r\n                new TextFeaturizer(Columns.Environment, Columns.Environment),\r\n                new TextFeaturizer(Columns.Type, Columns.Type),\r\n                new TextFeaturizer(Columns.ProjectName, Columns.ProjectName),\r\n                new TextFeaturizer(Columns.AsigneeEmail, Columns.AsigneeEmail),\r\n                new TextFeaturizer(Columns.ReporterEmail, Columns.ReporterEmail),\r\n                new ColumnConcatenator(\r\n                    Columns.Features,\r\n                    Columns.Environment,\r\n                    Columns.Type,\r\n                    Columns.CommentsCount,\r\n                    Columns.CommentsLenght,\r\n                    Columns.ReporterCommentsCount,\r\n                    Columns.ProjectName,\r\n                    Columns.AsigneeEmail,\r\n                    Columns.ReporterEmail),\r\n                new FastTreeBinaryClassifier(),\r\n                new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn=Columns.PredictedLabel   }\r\n                    \r\n`\r\n\r\n- And the StackTrace is as follows:\r\n\r\n>  at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.Models.CrossValidator.CrossValidate[TInput,TOutput](LearningPipeline pipeline)\r\n   at RepositoryAnalyser.MachineLearning.Services.TrainingModelEvaluator.CrossValidate[TData,TPrediction](LearningPipeline pipeline, MachineLearningMechanism mechanism, Int32 numOfFolds)\r\n\r\n'"
341998856,543,b'Rename properties of `ITrainerEx` (`TrainerInfo`)',"b'`ITrainerEx` (or its functional successor `TrainerInfo` from #522) contains the following properties.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ef169b2c67ef394b65d5bedbebd378913789fd9c/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L35-L58\r\n\r\nAs the comment suggests, we ought to be consistent in naming. There are several things we might consider doing here.\r\n\r\nThe first thing we might consider is getting rid of `NeedCalibration` specifically. It is I believe always true when the predictor returned from this is a binary predictor, but does not itself return probabilities. This is a trait that I believe can be directly derived from the predictor object itself, so we might be able to simplify the code here. (Certainly the code to detect whether a predictor produces probabilities might potentially be somewhat involved, and the situation here may be less simple than I suspect.)\r\n\r\nThe other thing is reconciling `Need` and `Want`. The prefix `Need` is a bit odd, since certainly you don\'t *need* to do any of those things for things to work, it\'s just a suggestion that it might work better *if* you do those things.\r\n\r\nHowever rather than just reconciling the prefix, we might consider renaming them altogether. They\'re very oddly named in the sense that they don\'t describe a property of the trainer they are attached to, they describe an action we suggest a user of the trainer should do to use them (or in the case of `NeedCalibration`, an action to take on the result of training). That is, they are *prescriptive* as opposed to *descriptive*, which seems undesirable.\r\n\r\nSo take `NeedNormalization`... trainers don\'t just need normalization randomly for no reason, they need normalization because they have parametric assumptions about feature data -- maybe a property could be devised to explain that, with the understanding that if it\'s true a user may benefit from normalizing features. Similarly, caching tends to be useful if an algorithm could perform many passes over the data (therefore making it better to keep in memory).\r\n\r\nHowever maybe this is a bit too goofy... `NeedNormalization` is easy for more people to reach the desired action vs. some complicated multi-step process of reasoning (""it has parametric assumptions about features, I think my data is not, the way people tend to fix this is apply normalizers, so I will apply a normalizer"" vs. just ""ah, needs normalization, I will normalize.""). Despite the fact that the name is prescriptive and not descriptive, maybe that does not in itself make it inferior to the alternative?\r\n\r\nNot sure about this.\r\n\r\n/cc @eerhardt , @ericstj , @Zruty0 '"
341657323,541,b'Need to rename TlcEnvironment',"b'Our only public, concrete environment class is named ""TlcEnvironment"", which uses the internal ""TLC"" acronym/name and has no meaning anymore.\r\n\r\nWe should come up with a better name for our default environment class.\r\n\r\n/cc @ericstj @TomFinley '"
341599530,540,b'Plan for F# bug and testing',"b'I\'ve been asked to fix some issues related to F# in this repo, especially #180. This is a planning note regarding this work.\r\n\r\nTODO:\r\n\r\n* [ ] Add one F# compiled-project ""smoke test"" under `tests\\FSharpProjects\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on both Windows and Linux and only require .NET Core\r\n\r\n* [ ] Add one F# scripting ""smoke test"" under `tests\\FSharpScripting\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on Windows. It will currently require .NET Framework or Mono.  \r\n\r\nWhen futher API updates and re-designs are made it is up to the person doing the re-design to adjust these tests :) Ask for help if you need it, but the F# code will be simple and I\'m sure all contributors are capable of adjusting trivial F# code, F# is dead simple to learn.\r\n\r\nThen, when [this bug](https://github.com/dotnet/machinelearning/issues/180) is fixed, a test will be added to both tests\\FSharpScripting\\SmokeTest and tests\\FSharpProjects\\SmokeTest.\r\n\r\nSeparately I will propose updates for documentation for F#, and we can later look at more comprehensive documentation, samples and testing.'"
341569557,538,b'PipelineSweeping fails for MultiClass classification',"b""### Issue\r\n\r\n- **PipelineSweeper fails for 'TrainerKind': 'SignatureMultiClassClassifierTrainer'**\r\n- **System.InvalidOperationException : Requested value 'Accuracy(micro-avg)' is not a member of the Enum type 'Metrics'**\r\n\r\n"""
341403566,537,b'`const` on the instance class will throw',"b'Adding a:\r\n\r\n```\r\n    public const string MagicNone = "" NONE "";\r\n```\r\n\r\nto an ""instance"" class (ie the class used to feed ML.NET the instances) will throw an ugly exception which is hard to figure out.\r\n\r\nI think there is another issue where more careful reflecting of the class is suggested. Can\'t find it right now though'"
341354477,536,b'WASM support',b'Hello folks!\r\n\r\nTrying to make ML.Net to work on mono-wasm but I just figured out the hard way that it only works on x64:\r\n\r\n![image](https://user-images.githubusercontent.com/4714040/42738687-1104bf6e-885e-11e8-813b-e55a91976ccc.png)\r\n\r\nIs there any chance to get the native part built to wasm?\r\n\r\nThanks!'
341193133,535,b'How would I concatenate columns of different types?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Combined numeric columns with FeaturizedText Columns\r\n- **What happened?** I received an exception about mismatched column Types\r\n- **What did you expect?** I\'m not 100% sure. I am hoping to find a way to combine a text featurizer with numeric values into the ""Features"" column to take multiple data types into account. I saw that we have the categorical vectorizers and Hash Transform Columns available, but I from what i understand, that is for a distinct number of categories.\r\n\r\nWhat I am trying to accomplish is utilizing numeric and text values in the prediction. Maybe this is just a lack of understanding on my part for this and it is not possible, but I\'m kind of hoping to post the pieces of my business object that that I think could impact the result, and I cannot figure out how to do that effectively.\r\n\r\nNote: I am using a FastTreeRegressor predicting a float value.'"
341175974,534,b'Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core',"b'.NET Core 2.1 [introduced hardware intrinsics APIs](https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md) that allow C# code to take full advantage of the CPU. For example, you can now write algorithms using SSE or AVX instructions purely from C# code.\r\n\r\nThe CpuMathNative assembly exists solely so ML.NET can take advantage of SSE and AVX instructions in its algorithms. When running on .NET Core 2.1+, we can remove our dependency on this native assembly, and instead port the C++ SIMD code to using the new C# intrinsics APIs.\r\n\r\nHowever, to do this (and still support the full .NET Framework), we need to do some refactoring to our assemblies and NuGet packages.\r\n\r\nThe first thing we need to do is allow `Microsoft.ML.CpuMath` to be multi-targeted for `netstandard2.0;netcoreapp2.1`. This will allow us to compile against the netcoreapp2.1 specific SSE APIs.\r\n\r\nHowever, doing that affects our `Microsoft.ML` nuget package. This is because when you make a nuget package, you put your assemblies into TFM specific folders `lib\\netstandard2.0`, `lib\\netcoreapp2.1`, etc. And the way asset picking works is that once it finds assets for a specific TFM, it stops looking.  (The reasoning is typically there is a single assembly per nuget package.) So if we have a single assembly, CpuMath, that needs to go into both `lib\\netstandard2.0` and `lib\\netcoreapp2.1`, we have a problem. It means ALL our assemblies need to go into BOTH folders, which is unnecessary duplication.\r\n\r\nTo solve this duplication, I propose to split CpuMath into its own nuget package.  So we will have this structure:\r\n\r\n* `Microsoft.ML.CpuMath`\r\n    - Contains the CpuMath managed assemblies (one for each TFM) and the CpuMathNative assemblies.\r\n* `Microsoft.ML`\r\n    - Has a dependency on `Microsoft.ML.CpuMath`.\r\n\r\nIn order to do this correctly, we need to remove the assembly reference from `Microsoft.ML.CpuMath.dll` on `Microsoft.ML.Core.dll`. This is because the nuget dependency goes the other way.  The only reason `Microsoft.ML.CpuMath.dll` depends on `Microsoft.ML.Core.dll` is so it can use the `Contracts` class.  We can break this dependency by using the `PRIVATE_CONTRACTS` define constant, and source linking the `Contracts.cs` file into CpuMath.\r\n\r\n/cc @TomFinley @ericstj @briancylui @tannergooding '"
341148843,533,"b""Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.""","b'### System information\r\nIssue changing model from TaxiFareExample. \'Features\' must be a known-size vector of R4, but has type: Vec<I4, 2>.\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I started with the TaxiFare Example and that works. But then I changed the model and added my own values and my data. I got the error about the ""Features"" above. I played with it for a while and tried limiting my data. Even tried predicting the Fare Amount again.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
341147669,532,b'LightGBM on ML.NET trains slower than LightGBM command line',"b'### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\nHardware:\r\nGoogle Cloud default 64 core machine.\r\n\r\n### Issue\r\n\r\nRan training on same dataset with same params.\r\nDataset: 25k features x 140k rows (balanced binary classes)\r\nParams: \r\nCommand Line: \r\n```\r\n./lightgbm metric=binary_logloss min_data_in_leaf=500 bagging_fraction=0.8 boosting_type=gbdt bagging_freq=5 max_bin=255 objective=binary valid_data=../../../pedata/test.csv max_depth=10 feature_fraction=0.8 num_leaves=70 output_result=prediction.txt num_machines=1 learning_rate=0.1 output_model=LightGBM_model.txt data=../../../pedata/train.csv num_threads=64 task=train is_training_metric=true num_iterations=500 metric_freq=1 tree_learner=serial\r\n```\r\nML.NET\r\n```\r\nvar lclassifier = new LightGbmBinaryClassifier() { UseCat=false, MaxBin= 255, EvalMetric= LightGbmArgumentsEvalMetricType.Logloss , NumLeaves= 70, NThread= 64,LearningRate= 0.1, NumBoostRound= 500, MinDataPerLeaf= 500};\r\n            lclassifier.Booster = new GbdtBoosterParameterFunction() { \r\n                MaxDepth = 10,\r\n                FeatureFraction=0.8,\r\n                SubsampleFreq=5 };\r\n            pipeline.Add(lclassifier);\r\n```\r\n- **What happened?**\r\n\r\nBoth use all the 64 cores (As seen on htop).\r\nData Loading + Training Time: Command Line: 10mins, ML.NET: 17mins\r\n\r\n- **What did you expect?**\r\nSince both were build on my machine from source, I expected that the training time would be comparable.  \r\n\r\nWhy is the ML.NET implementation slower? Is there something I can do to speed it up?\r\n\r\n```\r\nStopwatch stopwatch = new Stopwatch();\r\nstopwatch.Start();\r\n// STEP 5: Train your model based on the data set\r\nvar model = pipeline.Train<IrisData, IrisPrediction>();\r\nstopwatch.Stop();\r\n```\r\nThe above stopwatch gives me time taken for Loading+Training. Is there a way to check the time taken only for the training step. Right now I am not sure if the data loading is slow or the training is slow.\r\n\r\n-----------------\r\nEdit: I got approximate training time by assuming that when CPU usage spikes, thats when training starts.\r\nTraining Time: Command Line: 335s, ML.NET:680s (approx)\r\nData Loading: Command Line: 265s, ML.NET: 340s (approx)'"
341144408,531,b'How to get the accuracy when using a FastTreeRegressor?',"b'When predicting a flight delay, I would like to let the user know how accurate is the prediction. I was not able to find a way to ouput that information with a regression algorithm:\r\n\r\n```\r\n         static void Main(string[] args)\r\n        {\r\n\r\n            string trainDataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""Flight Delay Prediction-TrainData.csv"");\r\n            string testDataPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""Flight Delay Prediction-TestData.csv"");\r\n            string modelPath = Path.Combine(Environment.CurrentDirectory, ""Data"", ""Model.zip"");\r\n            Console.WriteLine(Environment.CurrentDirectory);\r\n\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                new TextLoader(trainDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: \',\'),\r\n                new ColumnCopier((""ArrivalDelay"", ""Label"")),\r\n                new CategoricalOneHotVectorizer(""Airline"", ""OriginAirport""),\r\n                new ColumnConcatenator(""Features"", ""Airline"", ""OriginAirport""),\r\n                new FastTreeRegressor()\r\n            };\r\n\r\n            var model = pipeline.Train<FlightInfo, FlightDelayPrediction>();\r\n\r\n            model.WriteAsync(modelPath).Wait();\r\n\r\n\r\n            var testData = new TextLoader(testDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: \',\');\r\n\r\n            var evaluator = new RegressionEvaluator();\r\n\r\n            var metrics = evaluator.Evaluate(model, testData);\r\n\r\n            Console.WriteLine($""Rms = {metrics.Rms}"");\r\n            Console.WriteLine($""RSquared = {metrics.RSquared}"");\r\n\r\n            var predictDelay = new FlightInfo();\r\n\r\n            Console.WriteLine(""Let\'s try to predict an airline and departing city delay:"");\r\n            Console.Write(""Airline: "");\r\n            predictDelay.Airline = Console.ReadLine();\r\n            Console.Write(""Departing City: "");\r\n            predictDelay.OriginAirport = Console.ReadLine();\r\n\r\n            var prediction = model.Predict(predictDelay);\r\n            Console.WriteLine($""Predicted Arrival Delay: {prediction.ArrivalDelay}"");\r\n            Console.ReadKey();\r\n        }\r\n    }\r\n    public class FlightInfo\r\n    {\r\n        [Column(""0"")]\r\n        public string Airline;\r\n        [Column(""1"")]\r\n        public float ArrivalDelay;\r\n        [Column(""2"")]\r\n        public string OriginAirport;\r\n\r\n    }\r\n\r\n    public class FlightDelayPrediction\r\n    {\r\n        [ColumnName(""Score"")]\r\n        public float ArrivalDelay;\r\n    }\r\n```'"
341133131,530,b'[TextTransform] Char n-grams are different when using with/without word n-grams.',"b'### System information\r\n\r\n`Not relevant`\r\n\r\n### Issue\r\nWhen using TextTransform to compute n-grams, it has been observed that character n-grams produced are not consistent when computing it with/without word n-grams option. For example, for the following sentence \r\n```\r\nThis is a cat\r\n```\r\nThe character n-grams produced are as follows. where `<STX>`, `<ETX>` and `<SP>` are start of sentence, end of sentence and space control characters respectively.\r\n\r\n| Char 3-gram | Char 3-gram + Word 3-gram|\r\n|-|-|\r\n|\\<STX\\>\\|t\\|h | \\<STX\\>\\|t\\|h\r\n| t\\|h\\|i | t\\|h\\|i\r\n| h\\|i\\|s | h\\|i\\|s\r\n| i\\|s\\|\\<SP\\> | i\\|s\\|\\<ETX\\>\r\n| s\\|\\<SP\\>\\|i | s\\|\\<ETX\\>\\|\\<STX\\>\r\n| \\<SP\\>\\|i\\|s | \\<ETX\\>\\|\\<STX\\>\\|i\r\n| s\\|\\<SP\\>\\|a | \\<STX\\>\\|i\\|s\r\n| \\<SP\\>\\|a\\|\\<SP\\> | \\<ETX\\>\\|\\<STX\\>\\|a\r\n| a\\|\\<SP\\>\\|c | \\<STX\\>\\|a\\|\\<ETX\\>\r\n| \\<SP\\>\\|c\\|a | a\\|\\<ETX\\>\\|\\<STX\\>\r\n| c\\|a\\|t | \\<ETX\\>\\|\\<STX\\>\\|c\r\n| a\\|t\\|\\<ETX\\> | \\<STX\\>\\|c\\|a\r\n|-| c\\|a\\|t\r\n|-| a\\|t\\|\\<ETX\\>\r\n\r\n### Source code / logs\r\nThe cause of the problem is word tokenizer which is applied at the following location in the code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L266\r\n\r\nThe `NeedsWordTokenizationTransform` property is set according to following criteria\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L169\r\n\r\nThis means whenever word n-grams are being computed the tokenization is performed first and character n-gram extractor computes n-grams on words instead of sentences i.e. \r\n\r\ninstead of computing char n-grams on \r\n```\r\n<STX>This<SP>is<SP>a<SP>cat<ETX>\r\n```\r\nit computes char n-grams on\r\n```\r\n<STX>This<ETX>\r\n<STX>is<ETX>\r\n<STX>a<ETX>\r\n<STX>cat<ETX>\r\n```\r\nFirst of all, is the expected behavior?\r\nI my point of view `NOT` because in this way character n-gram is adding noise and losing important information regarding the sentence which in some cases may give superior performance.\r\n\r\n### Solution\r\nApply char n-gram extractor on `IDataView` that was not used for word processing in the code.'"
341030146,526,b'Fix TrainAndPredictIrisModelUsingDirectInstantiationTest test from commit #428',"b'PR #428 was merged July 12, many days after PR #468 which added a new test on the Iris dataset July 2. The changes in #428 were not applied to that new test, and with the merge that test is failing.'"
340825260,525,b'Rename the NGramNgramExtractor class to a better name. ',b'I think the NGramNgramExtractor class in the CSharpApi.cs should have a better name. \r\n\r\nCirca line 17990: \r\n`public sealed class NGramNgramExtractor : NgramExtractor` '
340734090,524,b'Add description to convenience constructors.',"b'Recently, convenience constructors were added to different components to help easily create these components in the pipeline (cf. #380 #487 and #520).\r\n\r\nIt is also desirable to add helpful comments/description to these constructor to help user understand the components purpose and possible usage.\r\n\r\nTo be more precise, here is list of transforms that needs description for convenience constructors.\r\n\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs'"
340727915,523,b'ML.NET exports to ONNX v1.2.2 file which is not supported in current released Windows 10 RS4 but only in RS5',"b""### System information\r\n- **Windows RS4 vs. RS5**\r\n- **ML.NET 0.3**\r\n\r\n### Issue\r\nThe current released Windows (RS4) with WinML, supports only ONNX v1.0 models while Windows RS5 WinML supports only ONNX v1.2.2 models.\r\n\r\nThis is an issue since ML.NET exports ONNX 1.2.2 files which therefore don't work on current released Windows (RS4) with WinML, but only on the next version of Windows (RS5), which is still not publicly available.\r\n\r\nSince this issue might be happening depending on the target platforms, it would be advisable to parametrize the ONNX version of the model to export/generate (ONNX v1.0, v1.2.2, etc.), so it can work on multiple target platforms depending on the version. \r\n\r\n\r\n"""
340248576,521,b'Structure of a regression tree',b'I want to visualize a regression tree.\r\nSo i got one form my trained model.\r\n\r\nBut now i am wondering how the object (RegressionTree from Microsoft.ML.Runtime.FastTree.Internal) is structured and how i can obtain a connected tree from that object.\r\n\r\nOnly for display purposes i have a class like this:\r\n\r\n```\r\npublic class TreeNode\r\n{\r\n     public List<TreeNode> Children;\r\n     public TreeNode Parent;\r\n     public string Content;\r\n     [...]\r\n}\r\n```\r\n\r\nand i am struggling to connect the values of the arrays in RegressionTree to a TreeNode based tree.\r\n\r\nThank you for your time!'
339990673,519,b'Is a simulation model not also a kind of machine learning model?',"b'Hello ML.NET Team, \r\n\r\nthis week I was talking with some guys from simulation and a question come up into my mind. **It is more a general question about machine learning**. Why simulation models are not part of models for machine learning? A simulation model like from MATLAB/Simulink, Amesim, Modellica, .... are basically a text based description (XML or sth else) in form of mathematical formulas for prediction. \r\n\r\nYou see - yeah maybe they look different but they are not too different from each others. A simulation model also has a signal flow / topology and parameters which need to be ""trained"" just like a neuronal network. This ""training"" is mostly done by measurement signals and by finding the parameter which produce the smallest error (like traditional regression problem). As you can see - like neuronal network. Actual in last years I often saw some articles which suggested neuronal networks for simulation - okay nice idea but .... if you think about car or airplane simulation .... such measurements are extrem expensive and most articles I saw did not connect physical laws with the network (which is a pity).\r\n\r\nI just ask myself - is such a model + parameter finding algorithm not also a kind of ""Learner""? And if so - why most frameworks like Spark, Scikit etc. ignore them? If it is because there are too many model formats (file formats) - then just let you know : there is ""Functional Mockup Interface (FMI)"" --> a model format to rule all other formats. .NET brings different programming languages together, FMI brings different models. \r\n\r\nDo not see it as task or critical wish. I just want to discuss with others and see their opinion. :D\r\n\r\n  \r\n\r\n\r\n'"
339961735,518,b'[Part 3] Create convenience constructor for the listed Transforms.',"b'This work item is related to #371 and is the 3rd work item in series of creating convenience constructor (cf. #380 and #487). In this work item, convenience constructors will be created following set of transforms. \r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs\r\n'"
339919247,517,b'How to continue training based on the existing model?',b''
339802189,515,b'NA Handling ',"b'### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  2.1.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI was trying to work on Titanic kaggle problem and trying to train and I am looking for an example of how to handle Null values. \r\nI have seen handling option but not able to find how to use it in Pipeline.\r\n\r\nBetween one difference I have seen between Python interfaces and .net is the ability to experiment easily and I am finding it bit harder to do here. If you have any practices it will be helpful if we can discuss here. \r\n\r\n\r\n\r\n'"
339673667,513,b'Remove commented code',"b'While digging into the source code, I discovered a large amount of commented out code throughout the solution.\r\n\r\nUnless there is a reason behind this that I am not aware of, I think it is best to remove this. In a worst-case scenario, we have the git history to take care of this.\r\n\r\nOne example is in UnbufferedStream.cs, the following code is all commented out:\r\n\r\n    //}\r\n    //if (checkStream == null)\r\n    //{\r\n    //    checkStream = new FileStream(fileName, FileMode.Open, FileAccess.Read, FileShare.Read);\r\n    //}\r\n    //byte[] cbuf = new byte[count];\r\n    //int checkRead = checkStream.Read(cbuf, 0, cbuf.Length);\r\n    //if (checkRead != read)\r\n    //{\r\n    //    Console.WriteLine(""!!! bytes read mismatch at "" + fileName + "": ""  + checkStream.Position + "" / "" + Position + "": "" +\r\n    //        ""read = "" + read + ""; checkRead = "" + checkRead);\r\n    //}\r\n    //else\r\n    //{\r\n    //    Console.WriteLine("">>> bytes read match at "" + fileName + "": "" + checkStream.Position + "" / "" + Position + "": "" +\r\n    //        ""read = "" + read + ""; checkRead = "" + checkRead);\r\n    //}\r\n\r\nI haven\'t yet discovered the extent of this, but I think some work should be done on this.'"
339640745,512,b'Make grid search of parameter space more efficient',"b'The ML.Net library suffers from a lack of decoupling between data preparation and model training, required to do an efficient grid search over training parameters.\r\n\r\nThat is, ideally the API should be structured in such a way that it is possible to do the following:\r\n\r\n1. Prepare the data set once, so that it can be **re-used multiple times**.  As much as possible, any pre-training calculations should be done up front (or perhaps cached to be re-used).  For large data sets, the overhead of repeating this step each time is significant, taking as long or longer than the training itself.\r\n2. For algorithms with multiple training iterations, it should be straightforward to **retain the intermediate trained models** at each iteration (or at a specified set of iterations).  This way, it is then easy to compute metrics for the intermediate models on training and validation data sets, and ultimately select one of the intermediate models for use in production without having to re-run the training.\r\n\r\nFor example, consider training a LightGBM model.  This is the training method in `LightGbmTrainerBase.cs`:\r\n```csharp\r\n        public void Train(RoleMappedData data)\r\n        {\r\n            Dataset dtrain;\r\n            CategoricalMetaData catMetaData;\r\n            using (var ch = Host.Start(""Loading data for LightGBM""))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(""Loading data for LightGBM""))\r\n                    dtrain = LoadTrainingData(ch, data, out catMetaData);\r\n                ch.Done();\r\n            }\r\n            using (var ch = Host.Start(""Training with LightGBM""))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(""Training with LightGBM""))\r\n                    TrainCore(ch, pch, dtrain, catMetaData);\r\n                ch.Done();\r\n            }\r\n            dtrain.Dispose();\r\n            DisposeParallelTraining();\r\n        }\r\n```\r\n\r\nIn order to address point 1) above, the `dtrain` object returned by `LoadTrainingData` should be available to be re-used.  This would require that the configuration parameters for data preparation are specified separately to those for training, instead of all thrown in together into the `LightGbmArguments` type.\r\n\r\nNow, in regards to point 2) above, note that the `TrainCore` method calls `WrappedLightGBMTraining.Train`, which has the following structure:\r\n```csharp\r\n        public static Booster Train(IChannel ch, IProgressChannel pch,\r\n            Dictionary<string, object> parameters, Dataset dtrain, Dataset dvalid = null, int numIteration = 100,\r\n            bool verboseEval = true, int earlyStoppingRound = 0)\r\n        {\r\n            // create Booster.\r\n            Booster bst = new Booster(parameters, dtrain, dvalid);\r\n\r\n            for (int iter = 0; iter < numIteration; ++iter)\r\n            {\r\n                // training logic\r\n            }\r\n            return bst;\r\n        }\r\n```\r\nIn order to get the intermediate models, this method should return `Booster []` instead of just the final `Booster` (or perhaps instead in this case, the `Booster` object should support extraction of a prediction model which only contains the first `N` trees of the ensemble).\r\n\r\nPerhaps there is already the facility to do this in ML.Net, but I\'m unable to find anything from my reading of the source or any of the examples.\r\n\r\nI think 99.9% of all machine learning research requires doing a parameter grid search at some stage, and hence this is essential functionality that should be as efficient as possible.'"
339553215,511,b'Suggestion - Make Machine Learning Models explainable by design with ML.NET',"b""It's often difficult to understand how Machine Learning applications come to a decision. Some Developers reuse model samples without knowing how it works and is considered a black box to many.\r\n\r\nThis is an opportunity for ML.NET to stand out and automatically make models explainable. \r\n- ML.NET framework could keep a stack trace of some kind that keeps an audit of decisions\r\n- Including how confident it was in that decision (a rating or percentage)\r\n- With a fairness rating, evaluating the bias contained in the data supplied to the model\r\n- This could be output to the application upon request. Much like you can output a trace of an Exception.\r\n- Extend these peek abilities in Visual Studio so you can inspect what 3rd party models are doing (just like Resharpers decompile capabilities with libraries)\r\n\r\nA framework that automatically keeps a self-audit of decisions would be way ahead of the rest and could help developers understand what the model is doing under the hood. Especially if they are relying on models supplied by third parties.\r\n\r\nThis could boost the development of ML using ML.NET and is exactly the kind of thing that made .NET such an easy framework to work with."""
339537461,509,b'Direct API discussion: ITrainer proposed changes',"b'There are two changes proposed here for `ITrainer`. Due to the nature of the changes, assuming we agree they are good ideas, it really makes sense that they ought to happen in one go, since they involve changes to the same core functionality.\r\n\r\nI am quite certain the first thing is a good idea, but the second thing I am less certain about. (Of course my confidence could be misplaced. :smile:) People that occur to me as potentially being good contributors to the discussion would be @eerhardt , @zeahmed , @shauheen , @ericstj , @glebuk . (To be clear, this is not exclusionary. Anyone can and should feel free to comment. I just want these people to get flagged is all. :smile: )\r\n\r\n## `ITrainer<TData, TPred>.Train` ought to return the predictor\r\n\r\nCurrently in order to train a predictor, there is a two step process. You call `ITrainer.Train` then call `ITrainer.GetPredictor`. As near as I can tell this arrangement was meant as some scheme to support [online training](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L164), but of course that vision never came to pass, and if we were to actually support online training I have to imagine it would be through some separate interface anyway.\r\n\r\nThis arrangement seems unambiguously bad. It necessitates making `ITrainer` objects stateful for no particularly good reason. This complicates both the implementation and usage of the class, since (1) the caller can\'t do things like call `Train` multiple times even though a developer, seeing this interface, might reasonably suppose such a thing were possible and (2) the author of the `ITrainer` component has to protect against that misuse.\r\n\r\n## Get rid of `IValidatingTrainer`, `IIncrementalTrainer`, `IValidatingIncrementalTrainer`\r\n\r\n### The problem\r\n\r\nFirst let\'s talk about the problem...\r\n\r\nMost (all?) trainers implement `ITrainer<RoleMappedData>`, based on this interface here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L105\r\n\r\nWe have historically followed adding more inputs to the training process by declaring specialized interfaces that represent the Cartesian product of all possible permutations of inputs, as we see:\r\n\r\n* There was a discussion about adding a validation set. So we *doubled* the number of interfaces to two, `ITrainer`, and `IValidatingTrainer`.\r\n\r\n* Later on there was a discussion about adding continued training based on an initialization. So we again doubled the number of interfaces, introducing `IIncrementalTrainer` and `IValidatingIncrementalTrainer`.\r\n\r\n* There have been discussions of adding a test set to allow computing metrics as training progresses. Following the same strategy we would of course again double the number of interfaces (the full set being represented, perhaps, by `IValidatingIncrementalTestingTrainer`), for a total of eight.\r\n\r\n* If hypothetically we were to somehow allow for one more input beyond that, we\'d have a total of sixteen interfaces.\r\n\r\nEtc. etc. That there is this exponential cost makes clear something is misdesigned. This has cost not only here and in the implementations of `ITrainer`, but in the usage as well. [Here we see a method that explores the cartesian product of possible interfaces so it can call the right one.](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L287) It seems to me something is wrong here when just calling ""train"" requires a fairly non-obvious utility method to make sure we call the ""right"" train.\r\n\r\nThis issue incidentally is the primary reason why we haven\'t done anything like add support for test set metrics during training (despite the many requests). That is, it is not any technical difficulty with the idea itself, it\'s just that writing such a thing would make the code unmaintainable.\r\n\r\n### The possible solution(s)\r\n\r\n***So***: instead we might just have one interface, with one required input (the training dataset), and all these other things are optional.\r\n\r\nThere are two obvious ways I could imagine doing this, first explicitly as part of the method signature on `ITrainer<...>`:\r\n\r\n```csharp\r\npublic interface ITrainer<TDataset, TPredictor> {\r\n    TPredictor Train(TDataset train, TDataset validation = null, TDataset testSet = null, IPredictor initPredictor = null); }\r\n```\r\n\r\nOr else have some sort of context object. (I\'m not married to any of these names, to be clear. :smile: )\r\n\r\n```csharp\r\npublic sealed class TrainContext {\r\n    public RoleMappedData Train { get; }\r\n    public RoleMappedData Validation { get; }\r\n    public RoleMappedData Test { get; }\r\n    public IPredictor InitPredictor { get; }\r\n}\r\n```\r\n\r\nand all trainers implement `ITrainer<TrainContext>` instead of `ITrainer<RoleMappedData>`.\r\n\r\nThe latter is perhaps a bit more awkward since it involves the addition of a new abstraction (the hypothetical `TrainContext`), but it is more flexible in a forward-looking sense, since if we add more ""stuff"" to how we initialize trainers, we won\'t break all existing `ITrainer` implementations. (My expectation is that trainers that can\'t support something would simply ignore.)'"
339362364,508,b'How to mix categorical and numerical features in LightGbm?',"b""I am implementing a LightGBM example where I have a mix of categorical and numerical features, and can't figure how this should be done in ML.NET.\r\n\r\nIn Python, LightGBM accepts a 'categorical_feature' parameter, giving the possibility to specify if a feature should be handled as categorical or numerical/ordinal. I can not find that this parameter is available in the ML.NET version. Could this be added?"""
339336146,507,b'PipelineInference creates invalid JSON',"b'Currently, PipelineInference creates an EntryPoint JSON graph beginning with:\r\n```json\r\n{\'Nodes\' : [{\r\n  ""Name"": ""TextAnalytics.TextTransform"",\r\n  ""Inputs"": {\r\n    ""Column"": {\r\n      ""Name"": ""text_tf"",\r\n      ""Source"": [\r\n        ""text""\r\n      ]\r\n    },\r\n    \r\n}}]}\r\n```\r\n\r\nThe initial `\'Nodes\'` should have double-quotes like `""Nodes""`. JSON spec requires double quotes on keys. \r\n\r\nAs is, this fails a JSON.parse(), which makes the created JSON difficult to work with in NodeJS.\r\n\r\nSource of the issue:\r\nhttps://github.com/dotnet/machinelearning/blob/9d19d0e7058e328ead93f549205e5c329324ec05/src/Microsoft.ML.PipelineInference/PipelinePattern.cs#L276\r\n'"
339287199,506,b'the link error',"b'Hi, the link \xe2\x80\x9chttps://dot.net/ml\xe2\x80\x9d on the top is error \xef\xbc\x8c add  some space in the end \xef\xbc\x8c\xe2\x80\x9chttps://dot.net/ml%20%20%20%20%20%20%20\xe2\x80\x9d'"
339118249,504,b'[BUG] Unable to load model file in MVC project. Same file works in console app.',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 1803 (17134.112)\r\n- **.NET Version (eg., dotnet --info)**: .Net Framework 4.6.1 (ASP.Net MVC hosted in local IIS, Console App)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have a console application that trains a ML model then writes it to a specific location. The model file is then used by an ASP.Net MVC website.\r\n\r\n- **What happened?**\r\nWhen the website calls ```PredictionModel.ReadAsync<T1, T2>(filePath);``` to load the model I get the following exception:\r\n\r\n""Message"": ""An error has occurred."",\r\n                            ""ExceptionMessage"": ""Couldn\'t load model: \'DataLoaderModel\\\\Transform_005\\\\SchemaBindableMapper\\\\InnerMapper\\\\Predictor\'"",\r\n                            ""ExceptionType"": ""System.FormatException"",\r\n                            ""StackTrace"": ""   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapperBase..ctor(IHostEnvironment env, ModelLoadContext ctx)\\r\\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapper.Create(IHostEnvironment env, ModelLoadContext ctx)""\r\n\r\n\r\n- **What did you expect?**\r\nI expected the model to load from the file as it has done in my initial tests in the console app.\r\nAfter getting that exception, I tried to load the model from a different console app to simply run a prediction and the same model file loaded successfully and provided me with predictions.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
339002308,503,b'Example of multiclass classification with random forest?',"b'Looking to train multiclass classification with random forest and hyperparameter tuning.\r\n\r\nTried (on dotnetcore with either the latest [LightGbm nuget](https://www.nuget.org/packages/Microsoft.ML.LightGBM/) or cloning the repo directly):\r\n```C#\r\nvar pipeline = new LearningPipeline();\r\n\r\npipeline.Add(new TextLoader(_dataFilePath).CreateFrom<MyDataClass>());\r\n\r\n // for features\r\npipeline.Add(new TextFeaturizer(""My_Feature1_Vectorized"",""My_Feature1""));\r\npipeline.Add(new TextFeaturizer(""My_Feature2_Vectorized"",""My_Feature2""));\r\n\r\n// for the label\r\npipeline.Add(new TextFeaturizer(""Label_Vectorized"", ""Label""));\r\n\r\n// ** CAN\'T FIND FAST FOREST MULTI CLASS CLASSIFIER ** //\r\npipeline.Add(new LightGbmClassifier() { NumLeaves = 5, NumTrees = 5, MinDocumentsInLeafs = 2 });\r\n\r\nvar model = pipeline.Train<MyDataClass, MyPredictionClass>();\r\n```\r\n\r\nThis code crashes with `System.InvalidOperationException: Entry point \'Trainers.LightGbmClassifier\' not found`\r\n\r\nAlso, if I\'m missing any crucial steps (say around conversion from numbers to text or vice versa), please point them out.'"
338929031,502,b'How to ignore a column',"b'### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**:  2.1.201\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI added a custom column in my input data type. It holds a `DateTime`. I need it for stats but not for learning. I never ""copy"" it to the `""Features""` column. I also added\r\n\r\n```\r\nnew ColumnDropper() { Column = new []{ ""PlannedStart""} }\r\n```\r\n\r\n- **What happened?**\r\nI got an `ArgumentOutOfRangeException`: Could not determine an IDataView type for member ...\r\n\r\n- **What did you expect?**\r\n\r\nI expected it to just ignore the column.\r\n'"
338798894,501,b'Load data without a class?',"b""Is there a way to load data without creating a c# class before?\r\nIn this case I had to create the class SentimentData ahead of time:\r\n\r\n`...CreateFrom<SentimentData>(separator: ',')`\r\n\r\nWhat if I want to determine the fields/data types at run time. E.g. From an excel range, or from a DataTable"""
338702162,500,b'GPU support for LightGBM wrapper',"b'The LightGBM wrapper currently only allows CPU based training, however it is possible to build an instance of the LightGBM dlls which [support GPU training.](https://github.com/Microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version).'"
338644435,498,b'Which model type should I use for financial price prediction?',"b'First of all thank you for the great library!\r\nMy question is simple: I want to predict next period price with pre-computed history values.\r\nI have over 30 rows data for each price.\r\nPrice and datas are decimal.\r\n\r\nFor example history:\r\nIndicator1 - Indicator 2 - Indicator 3 - Price - **Trend**\r\n10,01121 - 23,56540 - 12.00001 - 12,23321 - UP\r\n9,00001 - 3,00040 - 2.00001 - 1,23300 - DOWN\r\n...\r\n...\r\nAnd data to predict coming like\r\n8,11211 - 1,00020 - 0.00021 - 3,5555 - ?\r\nI want to get **TREND** field.\r\n\r\nWhich model should I use? Any example will be perfect?\r\nRegards!'"
338641876,497,b'Missing MKL',"b'Issue #234 , was resolved by disabling the modules that had a dependance on MKL. We need to address the missing MKL issue.'"
338584198,495,b'Time Series support',b'Quick question: I know that right now there is no real support for time series.... ( both on the data input side as well as in the implemented Learners ) \r\n\r\nHowever before i could often solve my case by windowing over the sequential stream of events i wanted to base my prediction on e.g \r\n\r\nFor this i would need Collection support for columns... is this possible right now ? \r\n\r\nE.g \r\n\r\nclass MeasurementTick  {\r\n\r\n   DateTime TimeStamp { get; set; }\r\n   float Temperature { get; set; }\r\n   float Pressure { get; set; }\r\n}\r\n\r\nclass FixedSizeMeasureMentWindow {\r\n   IList<MeasurementTick> Ticks { get; set; }\r\n}\r\n\r\nUsing FixedSizeMeasureMentWindow as my input data type.... \r\n\r\n'
338487375,494,b'Not able to use LightGBM in .NET Framework 4.6.1',"b'### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Framework 4.6.1\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am using the 0.3.0 version NuGet package.\r\nI tried to replicate the example at https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows, with the small change of replacing the classifier with a LightGbmClassifier. I was able to do this with a .NET Core application (after I understood I had to add the Microsoft.ML.LightGBM Nuget package). But I need to run this in a full .NET framework application. So I followed the same procedure for a .NET Framework 4.6.1 console application. But this failed when I tried to add the Microsoft.ML.LightGBM Nuget package.\r\n\r\n- **What happened?**\r\nMicrosoft.ML.LightGBM depends on \'LightGBM 2.1.2.2\', and I get the following error:\r\n\r\n""Could not install package \'LightGBM 2.1.2.2\'. You are trying to install this package into a project that targets \'.NETFramework,Version=v4.6.1\', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.""\r\n\r\n\r\n- **What did you expect?**\r\nI expected this to work, ML.NET generally works on .NET Framework 4.6.1, right?\r\n'"
338425893,493,"b'Concatenating a range of columns in the data class into the ""Features"" column will lead to exception thrown'","b'Hello!\r\n\r\nI often have CSV files with more than 50 float columns, so it\'s not feasible to specify each of them individually. I\'ve failed to load them in one shot using a range/sweep specifier. To test things out in smaller scale, I used the Iris example because it ends with 4 float columns.\r\n\r\nHere\'s the data class, I only added 2 lines at the end:\r\n\r\n```\r\n    public class IrisData\r\n    {\r\n        [Column(""0"")]\r\n        public float Label;\r\n\r\n        [Column(""1"")]\r\n        public float SepalLength;\r\n\r\n        [Column(""2"")]\r\n        public float SepalWidth;\r\n\r\n        [Column(""3"")]\r\n        public float PetalLength;\r\n\r\n        [Column(""4"")]\r\n        public float PetalWidth;\r\n\r\n        [Column(""1-*"", name: ""Features"")] // New\r\n        public float[] Features; // New\r\n    }\r\n```\r\n\r\nHere\'s the simplified pipeline, I only commented out the normal way with ColumnConcatenator:\r\n```\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader(DataPath).CreateFrom<IrisData>(useHeader: true, separator: \'\\t\'));\r\n            //pipeline.Add(new ColumnConcatenator(""Features"",\r\n            //                                    ""SepalLength"",\r\n            //                                    ""SepalWidth"",\r\n            //                                    ""PetalLength"",\r\n            //                                    ""PetalWidth""));\r\n            pipeline.Add(new KMeansPlusPlusClusterer() { K = 3 });\r\n            var model = pipeline.Train<IrisData, ClusterPrediction>();\r\n```\r\n\r\nSo it worked when I load each column individually and then concatenate them in the pipeline, like the sample code says. But it always throws an exception when I use my above code:\r\n\r\n```\r\nSystem.Reflection.TargetInvocationException: \'Exception has been thrown by the target of an invocation.\'\r\nInner Exception:\r\nInvalidOperationException: Column \'Features\' is a vector of variable size, which is not supported for normalizers\r\n```\r\n\r\nPlease help! Thank you!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n=============================================================\r\n### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Framework 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**: trying to load a CSV\'s multiple float columns by specifying a range in the data class\'s declaration, for example: ""1-4""\r\n- **What happened?**: I got an exception on the Features\' size. \r\n- **What did you expect?**: that concatenating columns by specifying a range would work the same as adding a ColumnConcatenator to the pipeline.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
338041406,489,b'Image support in IDataView and transforms.',"b'Currently only way to work with images is by manually loading pixels arrays into array field in the class and wrap that class into collection data source. Which is not pleasant.\r\n\r\nI propose to add support for type Image in DataView type system which can be based on System.Drawing.Bitmap This way user can specify Bitmap image in their class and it will be properly consumed by CollectionDataSource. \r\n\r\nAlso I suggest to implement transform which would accept column with file paths and load this images during pipeline execution. Which allow you to save memory in case of streaming dataview, some trainers support streaming structure of data, and this way you need to keep in memory only one image for current row instead of images for all rows.\r\n\r\nSince quite often you need to modify images (Re-scale them, transform image into Grayscale, etc) it make sense to keep Image format as ""image"" and not directly convert it into vector of floats which we require for learners. Which means we need transform which would convert Image type into feature vector.\r\n\r\nTo summarize I propose to create following:\r\n\r\nImage type based on Bitmap.\r\nImageLoader transform\r\nImageResizer transform\r\nImageGrayscale transform\r\nImageToPixels transform \r\n\r\n@shauheen @TomFinley  @glebuk \r\n'"
338010262,487,b'[Part 2] Create convenience constructor for the listed Transforms.',"b'This work item is related to #371 and is the 2nd work item in series of creating convenience constructor (cf. #380). In this work item, convenience constructors will be created following set of transforms. \r\n\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n'"
337934338,484,b'We should set our PackageTags in the NuGet packages',"b'If we set the `$(PackageTags)` property in our NuGet package projects, the tags will automatically be defined in our .nupkg. And those values will be shown in nuget.org.\r\n\r\nWe are currently leaving this property blank in our packages.\r\n\r\n/cc @shauheen '"
337930926,483,"b""We should publish our NuGet packages to VSTS's artifacts""","b""When doing an official build, we only publish our NuGet packages to MyGet. We should also publish them to VSTS's artifacts tab. This way they aren't only on MyGet, and when we push our official packages to `nuget.org`, we can pull them from VSTS's artifacts drop of the build."""
337929799,482,"b""LightGBM doesn't work during F5 of a .NET Core application""","b""### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n```\r\n> dotnet --info\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.400-preview-009063\r\n Commit:    dd0179a67c\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.400-preview-009063\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.1\r\n  Commit:  6985b9f684\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsing the latest `0.3.0-preview` NuGet package, I tried using LightGBM in a .NET Core application.  I did the walk through: https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows, only changing:\r\n\r\n```C#\r\n            // STEP 4: Add learner\r\n            // Add a learning algorithm to the pipeline. \r\n            // This is a classification scenario (What type of iris is this?)\r\n            pipeline.Add(new LightGbmClassifier());\r\n//            pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n```\r\n- **What happened?**\r\n\r\n```\r\nUnhandled Exception: System.InvalidOperationException: Entry point 'Trainers.LightGbmClassifier' not found\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode..ctor(IHostEnvironment env, IChannel ch, ModuleCatalog moduleCatalog, RunContext context, String id, String entryPointName, JObject inputs, JObject outputs, Boolean checkpoint, String stageId, Single cost, String label, String group, String weight)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.ValidateNodes(IHostEnvironment env, RunContext context, JArray nodes, ModuleCatalog moduleCatalog, String label, String group, String weight)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph..ctor(IHostEnvironment env, ModuleCatalog moduleCatalog, JArray nodes)\r\n   at Microsoft.ML.Runtime.Experiment.Compile()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n   at MLLightGBMSmokeTest.Program.Main(String[] args) in C:\\Users\\eerhardt\\source\\repos\\MLLightGBMSmokeTest\\Program.cs:line 72\r\n```\r\n\r\n- **What did you expect?**\r\nI expected the walk through app to run successfully.\r\n\r\n### Notes\r\nWhen F5 debugging a .NET Core app in VS, or using `dotnet run` on the command line, .NET Core doesn't have all the dependencies copied to the output directory. Instead, references that come from NuGet packages are executed from the NuGet package cache folder.\r\nSince LightGBM comes from a separate NuGet package than the rest of the Microsoft.ML, it is loaded from a separate folder than the rest of the Microsoft.ML package.\r\n\r\nI've looked through the [ComponentCatalog](https://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L393-L425) code, and it appears if I force the `Microsoft.ML.LightGBM.dll` to be loaded first, I can workaround the issue.\r\n\r\nSo I added \r\n\r\n```C#\r\n        static void Main(string[] args)\r\n        {\r\n            // workaround to ensure LightGbm assembly is loaded\r\n            new LightGbmArguments();\r\n```\r\n\r\nAnd I am able to successfully use LightGBM on .NET Core during F5.\r\n\r\n### Workarounds\r\n\r\nAny of these should allow you to workaround the issue:\r\n\r\n1. forcing the assembly to be loaded, like I did above: `new LightGbmArguments();`\r\n2. `dotnet publish` your application and running it from the published folder (since all dependencies are copied during publish)\r\n3. Using full .NET Framework\r\n\r\n/cc @ericstj @TomFinley @codemzs """
337846609,481,"b""there's an alternative to the TextLoader class?I would like to add the data to the pipeline without to use a file. Regards  ""","b'### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
337753953,480,"b'When will ML.NET support deeplearning network ,such as CNTK ,tensorflow'",b''
337693132,477,b'Additional documentation for the ML.Net types and components should live in xml docs',"b""Through PR #455 we introduced XML strings in the codebase, that flow to the generated CSharpApi, to better document the trainers of the Microsoft.ML.Trainers namespace. \r\n\r\nThe final destination for those XML strings should be xml files, in the 'docs' folder, parallel to the src folder. Those documents should be referenced in the CSharp api, and through the code by xml <includes> tags. """
337662742,475,b'`sentiment_data.tsv` and `sentiment_test.tsv` are missing in the solution.',"b'### Issue\r\n\r\n- **What did you do?**\r\nOpened the solution.\r\n\r\n- **What happened?**\r\nI\'ve found that `test\\data` solution folder contains missing files: `sentiment_data.tsv` and `sentiment_test.tsv`.\r\nAs it looks in [Microsoft.ML.sln](https://github.com/dotnet/machinelearning/blob/master/Microsoft.ML.sln) it has:\r\n```\r\n// Starts at 37.\r\nProject(""{2150E333-8FDC-42A3-9474-1A3956D46DE8}"") = ""data"", ""data"", ""{FDA2FD2C-A708-43AC-A941-4D941B0853BF}""\r\n\tProjectSection(SolutionItems) = preProject\r\n\t>>\ttest\\data\\sentiment_data.tsv = test\\data\\sentiment_data.tsv\r\n\t>>\ttest\\data\\sentiment_test.tsv = test\\data\\sentiment_test.tsv\r\n\tEndProjectSection\r\nEndProject\r\n```\r\nWhile such data actually doesn\'t present in repository, as it looks [here](https://github.com/dotnet/machinelearning/tree/master/test/data).\r\n- **What did you expect?**\r\nI\'d expect that there should be no missing files in solution.\r\n'"
337659926,474,b'Proposal for Fluent API',"b'In this issue I describe a proposal for a fluent API for the building of ML.NET learning pipelines. This API would be consistent with existing .NET patterns such as LINQ, allowing people new to ML.NET to pick it up easily. It would allow clear concise code for simple scenarios, whilst allowing easy extension for more complex situations.\r\n\r\n# Background\r\n\r\nThe `LearningPipeline` API used by the current preview releases of ML.NET has a number of limitations. Theprogramming model does not fit in with other .NET code (we do not write other code as a series of steps added to a list), and follows a linear pipeline without merging/branching (e.g. with data from multiple sources, or train/test splitting of data).\r\n\r\nThe recent proposal for a major API change by @TomFinley in issue #371 is a bit step forward towards a more natural programming model, with each step of the pipeline new-ed up in turn. I would argue however that this no longer reflects the true flow through a learning pipeline, with previous steps being relegated to a parameter of the constructor. This proposal builds on top of #371 with a fluent API.\r\n\r\n# Proposed API\r\n\r\nBy using extension functions (in a similar manner to LINQ) we can pass the previous step of a pipeline as the \'this\' parameter into subsequent steps, preserving the natural flow. For example,\r\n\r\n```\r\nvar loader = new TextLoader(new MultiFileSource(dataPath),\r\n        useHeader: true, separator: \',\',\r\n        cols: new[] { ... });\r\nvar transform = transform.AddConcatTransform(env, trans, ""CategoryFeatures"",\r\n        ""Bedrooms"", ""Bathrooms"", ""Floors"", ""Waterfront"", ""View"", ""Condition"", ""Grade"",\r\n        ""YearBuilt"", ""YearRenovated"", ""Zipcode"");\r\nvar transform = transform.AddCategoricalTransform(""CategoryFeatures"");\r\n```\r\n\r\nThis could be further cleaned up to,\r\n\r\n```\r\nvar pipeline = new TextLoader(new MultiFileSource(dataPath),\r\n        useHeader: true, separator: \',\',\r\n        cols: new[] { ... })\r\n    .AddConcatTransform(env, trans, ""CategoryFeatures"",\r\n        ""Bedrooms"", ""Bathrooms"", ""Floors"", ""Waterfront"", ""View"", ""Condition"", ""Grade"",\r\n        ""YearBuilt"", ""YearRenovated"", ""Zipcode"")\r\n    .AddCategoricalTransform(""CategoryFeatures"");\r\n```\r\n\r\n## More complex examples,\r\n\r\nYou could easily write extension functions that combine multiple steps, but could be consumed in the same way. Something like the following (I\'ve created a hypothetical `IDataPipeline` to represent any pipeline step that produces data),\r\n\r\n```\r\npublic IDataPipeline CreateCategories(this IDataPipeline input)\r\n{\r\n    return input.AddConcatTransform(env, trans, ""CategoryFeatures"",\r\n            ""Bedrooms"", ""Bathrooms"", ""Floors"", ""Waterfront"", ""View"", ""Condition"", ""Grade"",\r\n            ""YearBuilt"", ""YearRenovated"", ""Zipcode"")\r\n        .AddCategoricalTransform(""CategoryFeatures"");\r\n}\r\n```\r\n\r\nYou could easily merge data from two pipelines,\r\n\r\n```\r\nvar input1 = new.TextLoader(...)\r\n        .DoSomeTransforms();\r\nvar input2 = new.TextLoader(...)\r\n        .DoSomeMoreTransforms();\r\n\r\nvar input = input1.ConcatenateRows(input2);\r\n```\r\n\r\nYou could take advantage of tuples to split the data pipeline, such that different steps could be applied before later merging,\r\n\r\n```\r\nvar (train, test) = input.AddTrainTestSplit(...);\r\n\r\ntrain.DoSomeTransforms();\r\ntest.DoSomeMoreTransforms();\r\n```\r\n\r\n# Summary\r\n\r\nThis is an outline proposal for an alternative API that could be used alongside, or instead of that proposed in issue #371. There are still some rough edges here and there, but I hope that this will start a discussion of the posibilites provided by a fluent API.'"
337648300,473,b'Get cluster items',"b'_Sorry for my English :)_\r\n\r\nI am using sample [Clustering Iris Data](https://github.com/dotnet/machinelearning-samples/tree/master/samples/getting-started/Clustering_Iris). Is there anyway except cluster Id also get items which were put in the same cluster?\r\n\r\nThat is, I got prediction:\r\n\r\n`var prediction1 = model.Predict(TestIrisData.Setosa1);`\r\n\r\nand I can get cluster Id by `prediction1.SelectedClusterId`. But I also need to know data about another items with their features SepalLength, SepalWidth, PetalLength, PetalWidth.'"
337645678,471,b'Cannot load a ParquetLoader without a file.',"b'### Issue\r\n1. Save a ParquetLoader model context.\r\n2. Load the model context with an empty IMultiStreamSource.\r\n\r\nExpected result:\r\nThe model can be loaded to inspect the schema.\r\n\r\nActual result:\r\nThe model will throw the error ""Parquet loader must be created with one file"".'"
337634294,470,b'How to add new data to existing trained data model?',"b""Hi,\r\nI am very new to this subject. Maybe there might be a problem with my point of view. Thank you for all the reviews.\r\n\r\nI have 10 million rows * 60 columns of data.\r\nAnd every 1 minute new/fresh data coming. And it is really unstable. So I need to train all data every 1 minute.\r\nI would like to learn if it is possible: I want to change trained data model with new data;\r\nload it, change it and write it again.\r\n\r\nLike:\r\n```\r\n            PredictionModel.ReadAsync(_modelpath).Wait();\r\n            PredictionModel<IrisData, IrisPrediction> model = pipeline.Train<IrisData, IrisPrediction>();\r\n            model.WriteAsync(_modelpath).Wait();\r\n```\r\n\r\nI'm not sure if it is working?\r\n\r\nThans advance!"""
337618807,469,b'How to load data from variable?',"b'Hi,\r\nI want to load data from memory, so I can connect it with sql server, webservice etc.\r\n\r\n`pipeline.Add(new TextLoader(dataPath).CreateFrom<IrisData>(separator: \',\'));`\r\nbut this is only method that I can find! It only works with file on the disk!\r\n\r\nI want to add data from variable like:\r\n`string x = ""116.76000,0.00000,116.76000,0.00000,116.76000,UP""`\r\n\r\nI hope it is possible right now?\r\n\r\nThanks advance!'"
337582568,466,b'CV macro should be able to pass a name column to the evaluator',"b'When running in CV mode, the per-instance results data view contains the results from all folds. Having a name column enables identifying the examples, since they are not in the same order as the input data. Currently, there is no way to pass a name column to the evaluator in the CV macro.'"
337580150,465,b'Create EntryPoint for LightGBM',"b""Currently LightGBM is part of ML.Net Trainers, but there is no [entry point](https://github.com/dotnet/machinelearning/blob/master/docs/code/EntryPoints.md) it. \r\n\r\nOther languages, that interface with ML.Net through Entry Points won't have access to it, until there is an entry point for it. \r\n"""
337177138,460,b'PipelineSweeperMacro incorrect column purpose inference',"b'PipelineSweeperMacro tries to infer the Purpose of the columns in the data-set, and then generates the parameter space to sweep over.  \r\n\r\nFor several datasets, it infers the purpose incorrectly e.g.  for some datasets, the PipelineSweeperMacro ended up using the label column as a feature.  There is currently no way for the user to override this behavior.  \r\n\r\nThe proposal is to add arguments to the PipelineSweeperMacro, corresponding to the intended purpose for a particular column.  Purpose inference will be done only on columns which were not specified by the user. \r\n'"
337164537,459,b'Resources for getting started with ML',"b'I am just beginning to try utilizing this framework, and by following the [Github Labeler Sample](https://github.com/dotnet/machinelearning-samples/tree/master/samples/end-to-end-apps/github-labeler) I have been able to build some proof of concept applications within my organization (with surprisingly high accuracy).\r\n\r\nHowever, we are starting to look at taking this a step further. One example is to utilize a StochasticDualCoordinateAscentClassifier along with a PredictedLabelColumnOriginalValueConverter to suggest the top 3 predicted labels, rather than just 1. For example, to not automatically label a github issue, but recommend labels that can be applied.\r\n\r\nThe description of this project says:\r\n\r\n> ML.NET allows .NET developers to develop their own models and infuse custom ML into their applications without prior expertise in developing or tuning machine learning models, all in .NET.\r\n\r\nBut when I am trying to dig into the documentation, all of the information is very technical, using math and science terms that are way above my understanding. **Are there good resources for people who have high development experience, but no ML experience that I can reference to learn more without feeling like I need a degree in mathematics?** From the little amount of time that I have spent using ML.NET, I am thrilled with the results. Many of our models have had 75% accuracy without much tweaking at all to be necessary, but I am hoping we will be able to use this to take our understanding to the next level.'"
337164295,458,b'LightLda documentation should be more specific.',"b""Currently it doesn't explain how trainer works and don't provide example how to use it"""
337158185,457,b'Enable ML.NET to support open access healthcare models',b'Please update ML.NET so it will support existing open access healthcare datasets and add tools that would easily enable comparison of genomic data and overlapping data (which could be used to detect cancer patterns) pythons bedtools is a good example of this\r\n\r\nAllow us to train our models using open datasets e.g. this example with azure ml.\r\nhttps://blogs.msdn.microsoft.com/cdndevs/2016/05/31/getting-started-with-machine-learningwisconsin-breast-cancer-dataset/'
337155849,456,"b""Cross validation macro doesn't work with non-default group column name""","b'Related to #292. When the fix for this bug was checked in (#291) there was a bug related to the GroupId and Weight columns, which causes the specified column names not to be passed to the evaluation entry point. \r\n'"
337069244,453,b'OneVersusAll documentation should be more specific.',"b""Currently it doesn't explain how trainer works and don't provide example how to use it."""
336826111,451,b'Console dll is missing references to binaries of learners/transforms and native code.',"b'Console dll allows ML.NET pipelines to be created and executed via command line. It is currently missing references to dlls of some learners, transforms and native code. '"
336825851,450,b'Update LightGBM API documentation.',b'LightGBM APIs require Micorosoft.ML.LightGBM nuget and this information needs to include in the documentation.'
336715723,445,"b'Direct API: RoleMappedSchema/Data Cleanup, Improvement'","b'Another followup to #371, in which we discuss changes to `RoleMappedSchema` and `RoleMappedData` to make them less idiosyncratic.\r\n\r\n`RoleMappedSchema` and `RoleMappedData` are structures that solve the following problem: Once you create a pipeline, before you feed it to an `ITrainer` or similar structure, you must have some mechanism to communicate to consumers of that pipeline, what all the columns were actually for... e.g., which column(s) were feature columns, which the label, and so on. (Before this structure existed, our ""solution"" to this was that every component consumed an `IDataView` directly and had configurable options for someone to declare which was which. This is good in that each trainer had the chance to be explicit about what it wanted, but still was somewhat troublesome since having to tell absolutely every component we wanted to use, ""OK, these are still the feature columns"" became somewhat troublesome, and a source of user error. So a structure to make this assignment more ""sticky"" was invented.\r\n\r\nSo that is all fine, more or less. And, I\'d say on the whole it is a pretty good class, insofar that it seems to have worked well for its purpose. However there are wrinkles we probably ought to clean up.\r\n\r\nNearly all architecture effort went into making it easy to consume, as opposed to being easy or sensible to create. Previously, this made sense, since it was only instantiated in a handful of places, and used in hundreds of places. With API usage, the situation is reversed: we expect everyone to create it, and there will be ""only"" hundreds of consumers.\r\n\r\n* On that subject, creation is somewhat odd: there are `Create` and `CreateOpt` methods, as opposed to how most people would imagine an object is created, through an actual constructor (maybe with a `bool opt = false` parameter.)\r\n\r\n* ""Reapplication"" of an existing role-mapping to new data is a common operation performed in the code-base, yet there is no convenience for it, and it\'s something we\'d want people to be able to do relatively easily. (E.g., when applying caching, for example.)\r\n\r\n* The common convenience helpers for the most common cases of creating `RoleMappedData` exist (e.g., ""these are my features, these are my labels) exist in a `TrainUtils` class. This makes them impossible to discover unless you know where to look. Probably the easiest to discover place to have these conveniences would be on the classes themselves. (This would also be a start at cleaning up `TrainUtils`, which is basically a haphazard bag of vaguely useful things.)\r\n\r\n* General cleanup of the code. A relic from a bygone time, `Id`, was never removed, despite being irrelevant and never used any more. It\'s been years since it was replaced with ids on `IRowCursor` directly. Also a fair amount of code exists in the class to detect conditions that cannot possibly happen.'"
336378080,443,b'Ensembles code required small cleanup',"b""Some files doesn't comply with our internal code policies (i.e. no consecutive new lines).\r\nDiversity Measurement for binary and regression classification are indistinguishable.\r\nWeighted average has wrong friendly name.\r\nMultivoting doesn't required arguments and should always use normalize option as false."""
336349907,440,b'Wrong Culture when passing arguments to LightGBM',"b'### System information\r\n\r\n- Win 10\r\n- dotnet core\r\n\r\n### Issue\r\n\r\nWhen calling the Train Method the arguments are parsed with the local culture instead of en or us, which leads to an Error:\r\n\r\n![41993623-57553e14-7a4c-11e8-9d75-12d423f54f8e](https://user-images.githubusercontent.com/5176531/41993935-1bdfc5ec-7a4d-11e8-899c-7d4f62cc85f1.png)'"
336348153,438,b'Remove MML.dll from Microsoft.ML nuget',"b""We shouldn't have been adding an assembly to the Microsoft.ML package with netcoreapp2.0 TFM.  Doing this causes the project system to only reference the assemblies from`netcoreapp2.0` and not from netstandard2.0."""
336335185,436,"b""Folder and file names don't match Namespaces and Type names""","b""### System information\r\n\r\n- **OS version/distro**: Windows 10 v1803\r\n- **.NET Version (eg., dotnet --info)**: 2.1.201 \r\n\r\n### Issue\r\n\r\n- **What did you do?** Open the solution in Jetbrains Rider\r\n- **What happened?** Rider pointed out many cases where type and file names differed, as well as cases where name spaces and folder names weren't in sync."""
336334329,435,b'Problem with the EvaluatorUtils method that appends per-instance data views',"b'When appending the per-instance data views, we create create new key columns containing the union of the key values of the keys in the individual data views. Columns of type key that have text key values get reconciled twice, resulting in wrong values in these columns:\r\n\r\nelse if (dvNumber == 0 && dv.Schema.HasKeyNames(i, type.KeyCount))\r\n          firstDvKeyWithNamesColumns.Add(name);\r\nelse if (type.KeyCount > 0 && name != labelColName)\r\n{ ...\r\n\r\nColumns that go into the first ""else-if"" should not go into the second ""else-if"" which is supposed to handle key columns without text key values.\r\n'"
336333719,434,b'Documentation `cref`s point to nonexisting classes',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 v1803\r\n- **.NET Version (eg., dotnet --info)**: 2.1.201\r\n\r\n### Issue\r\n\r\n- **What did you do?** I opened the solution in Jetbrains Rider.\r\n- **What happened?** Rider pointed out a great many mistakes in the `cref` elements of XMLDocs\r\n- **What did you expect?** Perfect documentation, of course :-)'"
336327242,433,b'Direct API: Auto-normalization',"b""One of the details of training that happen after a loader/transform pipeline is created, but before the cache. We've typically automatically done this for users. While usage in the API is very distinct in that people tend to like implicit behavior in tools but dislike implicit behavior in APIs, at least offering a convenience for normalization is appropriate.\r\n\r\n## Existing Method\r\n\r\nSome familiar with this codebase are aware of this existing method, in the `TrainUtils` utility class, that serves a similar function.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2501049f5cb60ed2c9ec191d2937cab7b59824da/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L492\r\n\r\nThe goal of *that* method is not to provide a convenient API, so much as to factor out code common to the various commands that train models (e.g., train, traintest, cross-validation, some transforms like train-and-score). The same is true of many methods in that `TrainUtils` class. This as we see in the first few lines:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/2501049f5cb60ed2c9ec191d2937cab7b59824da/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L499-L506\r\n\r\nWhile beneficial in providing consistent behavior across all of these things from a command-line perspective, the condition where it just exits would be inappropriate to have in an ML.NET API -- you might imagine someone designing a method with a parameter `bool doNothing` where the first thing is, if it's true, the method returns without doing anything. Again, appropriate from the point of view of factoring out common code, but not appropriate for an API. Also the method of communicating important information to the user is via the console, which again is not the most helpful option for an API.\r\n\r\n## Proposed API Helpers\r\n\r\nNonetheless, this function has several things that are helpful to do: it detects if a trainer wants normalization, if data is normalized, and if appropriate and necessary applies normalization.\r\n\r\nThis would probably take the form of a static method on the `NormalizerTransform` class, perhaps following this signature:\r\n\r\n```csharp\r\npublic static bool CreateIfNeeded(IHostEnvironment env, ref RoleMappedData data, ITrainer trainer)\r\n```\r\n\r\nWe could also have two additional methods to provide key information.\r\n\r\n```csharp\r\npublic static bool FeatureVectorIsNormalized(RoleMappedData data)\r\npublic static bool NeedsNormalization(this ITrainer trainer)\r\n```"""
336290301,432,b'Add documentation and examples for Factorization Machines',"b'The Factorization Machine trainer/predictor got added to ML.NET, but we need to complement with documentation, and examples on how to use it. \r\n'"
336260665,429,b'How do I use the newly added LightGBM classifier?',"b'### System information\r\n\r\n.NET Core SDK:\r\nVersion: 2.1.301\r\nCommit: 59524873d6\r\n\r\nRuntime Environment:\r\nOS Name: ubuntu\r\nOS Version: 16.04\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCloned the master. \r\nRan ./build.sh\r\n\r\n- **What happened?**\r\nThe build was successful.\r\n\r\n-**My Code**\r\n```\r\n<PropertyGroup>\r\n    <OutputType>Exe</OutputType>\r\n    <TargetFramework>netcoreapp2.1</TargetFramework>\r\n  </PropertyGroup>\r\n\r\n  <PropertyGroup>\r\n  <TreatWarningsAsErrors>false</TreatWarningsAsErrors>\r\n  <NoWarn>CS0649;CS0168;CS0219</NoWarn>\r\n  <AllowUnsafeBlocks>true</AllowUnsafeBlocks>\r\n  </PropertyGroup>\r\n  \r\n  <ItemGroup>\r\n    <PackageReference Include=""Microsoft.ML"" Version=""0.2.0"" />\r\n  </ItemGroup>\r\n...\r\n```\r\nI\'m using the example on iris with my dataset. My code works with `FastTreeBinaryClassifier`, how do I replace this and use `LightGbmBinaryClassifier`, from the code that I just built.\r\n```\r\n            string dataPath = ""../../../data/train.csv"";\r\n            string testPath = ""../../../data/test.csv"";\r\n            pipeline.Add(new TextLoader(dataPath).CreateFrom<IrisData>(separator: \',\'));\r\n            pipeline.Add(new ColumnConcatenator(""Features"", ""NumericFeatures""));\r\n            pipeline.Add(new FastTreeBinaryClassifier() { NumLeaves = 15, NumTrees = 10, MinDocumentsInLeafs = 100 });\r\n\r\n```'"
336034114,424,b'Write a test case for New API',"b""The work on new API (#371) has been started #380.\r\n\r\nIt would be nice to convert one of the already available test case into new API format. \r\n\r\nInitially, it won't be possible to implement it elegantly using new API. However, the objective in future will be to improve the end-user experience using this test case.\r\n"""
336027644,423,b'Make Onnx path parameter mandatory in OnnxConverter',"b'\r\nAccording to the documentation, both `Onnx` and `Json` paths are optional. Make at least `Onnx` path mandatory for conversion.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML/Models/OnnxConverter.cs\r\n\r\n``` C#\r\nOnnxConverter converter = new OnnxConverter()\r\n{\r\n    InputsToDrop = new[] { ""Label"" },\r\n    OutputsToDrop = new[] { ""Label"", ""Features"" },\r\n    Onnx = onnxPath,\r\n    Json = onnxAsJsonPath,\r\n    Domain = ""Onnx""\r\n};\r\n\r\nconverter.Convert(model);\r\n```'"
335989667,421,b'Is predition model thread safe?',b'Should I use single instance or a pool of objects? Thanks in advance!'
335981637,420,b'how to load 25k features using TextLoader?',"b'### System information\r\n\r\n.NET Core SDK:\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nLoaded a subset of columns of my data using one of the examples (Iris data). I have a total of 25k features in the CSV file. I don\'t want to list all 25k of them in `public class IrisData`. Is there a better way to load this dataset?\r\n\r\n```\r\npublic class IrisData\r\n{\r\n    [Column(""0"")]\r\n    [ColumnName(""Feature0"")]\r\n    public float Feature0;\r\n    [Column(""1"")]\r\n    [ColumnName(""Feature1"")]\r\n    public float Feature1;\r\n    [Column(""2"")]\r\n    [ColumnName(""Feature2"")]\r\n    public float Feature2;\r\n    [Column(""3"")]\r\n    [ColumnName(""Feature3"")]\r\n    public float Feature3;\r\n    [Column(""4"")]\r\n    [ColumnName(""Label"")]\r\n    public bool Label;\r\n}\r\n```\r\n\r\n```\r\nstring dataPath = ""../../../data/train.csv"";\r\nstring testPath = ""../../../data/test.csv"";\r\npipeline.Add(new TextLoader(dataPath).CreateFrom<IrisData>(separator: \',\'));\r\npipeline.Add(new ColumnConcatenator(""Features"", ""Feature0"", ""Feature1"", ""Feature2"", ""Feature3""));\r\n```'"
335940815,418,b'Documentation for convert to ONNX API',b'Add documentation for convert to ONNX API explaining how the convert process works and what each argument stands for. Also provide a link to an example that shows how to train a model and then convert it ONNX.'
335930374,417,b'Enable LightGBM macOS tests',b'Currently lightgbm tests in #392 are disabled for macOS since lightGBM native binary depends on OpenMP dll that comes from gcc and is not available on build machines. The engineering systems team is tracking the issue dotnet/core-eng#3753 to have openmp binaries on the build machines. I have verified these macOS tests work and their results are consistent with Linux and Windows by installing brew and gcc on the build machines.'
335778614,416,b'Example for parameter sweeping using pipeline',"b'Hi,\r\n\r\nquick question: Is there somewhere docs or an example for how to grid/random sweep a parameter using the pipeline API?\r\n\r\nThanks'"
335688751,415,b'Optimize FactorizationMachinesNative.cpp',"b'Optimize the FactorizationMachinesNative.cpp, by:\r\n1- switching the control variables of the for loops from post-increment to pre-increment, to avoid the extra storage \r\n2- Optimize the intermediate calculations on the current tight loops for better performance. \r\n\r\nExample: \r\nfor (int fprime = 0; fprime < m; fprime++)\r\n        {\r\n            const int vBias = j * m * d + fprime * d;\r\n            const int qBias = f * m * d + fprime * d;\r\n\r\n3- Potentially substitute AlignedArray with a regular array. See the discussion on PR #383 '"
335673076,414,b'MinDocsPerLeaf always zero for Microsoft.ML.Runtime.FastTree.DataConverter.DiskImpl',"b""Of the two implementations of `Microsoft.ML.Runtime.FastTree.DataConverter`, the `minDocsPerLeaf` argument is used by `MemImpl`, but not `DiskImpl`, where this argument to `CalculateBins` is hardwired to zero:\r\nhttps://github.com/dotnet/machinelearning/blob/ecc6857410f56cdc67c666de4e08844df3a1e288/src/Microsoft.ML.FastTree/FastTree.cs#L1435\r\n\r\nIs this intentional? Shouldn't the two implementations give the same result?"""
335637640,412,b'FastTree Ranking revert gradient calculation to native code',"b""Currently the FastTree ranking code has an `#if` to control whether it uses native or .NET code, as declared here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecc6857410f56cdc67c666de4e08844df3a1e288/src/Microsoft.ML.FastTree/Microsoft.ML.FastTree.csproj#L6\r\n\r\nNormally this takes the form of `#if USE_FASTTREENATIVE`, except for here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecc6857410f56cdc67c666de4e08844df3a1e288/src/Microsoft.ML.FastTree/FastTreeRanking.cs#L770\r\n\r\nThat `2`, I'm somewhat embarrassed to report, is an unintentional mistake I made some time ago. It was part of a change involving some hundreds of files, and I think I just made a small error.\r\n\r\nNow, somehow, this didn't get noticed. It however differs in its support of a few arguments. These arguments are hidden and not recommended to be used for general users, but nonetheless they may be important, and having it not be supported was unintentional.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecc6857410f56cdc67c666de4e08844df3a1e288/src/Microsoft.ML.FastTree/FastTreeRanking.cs#L854-L857\r\n\r\nThis is not to say we shouldn't shift to *not* use the native library, but I'd rather it be done in a controlled fashion to ensure compatibility (which this thing does not do), rather than unintentionally as I did here.\r\n\r\nThis issue is directly relevant to @najeeb-kazmi and @rogancarr ."""
335611942,410,b'Suggestion for test framework improvements.',"b'No reason to have same baselines for Debug and Release if they are same.\r\n\r\nCurrently we have /test/BaselineOutput folder which contains folders Common, SingleDebug and SingleRelease and they filled with pretty much same files. We need to modify our test framework so it will look first in Common folder and if file is not found then it should look in respectful folders.\r\nAlso word Single is legacy artifact and can be omitted. \r\n\r\nThis would reduce size of repo, and simplify peoples life. Also it give more room to have platform specific tests since many of our tests disabled because we verify everything with windows output, which sometimes differ because of native code implementation.'"
335602397,409,b'Pass standard output / error message  from native code up the stack to .NET instead of printing it',"b'In LdaNative code, for example, we have  a lot of printf(...) & std::cout statements that output to console / standard output. Better design is to pass the output up the stack to calling code in .NET and allow it to decide how and where to output it.\r\nBesides LdaNative we need to scan all native code for this issue. '"
335584859,407,b'Slot Reconciliation Transform',"b'In ML.NET, a predictor that is trained on N features, can be applied to any column with N features. This is fine, and normally works well. However, imagine that you have a model trained over ""old"" data. Then you have a new pipeline, or new data-file, perhaps with new features, or some other such thing. In order to apply the ""old"" model to the ""new"" data, a user would need to figure out how exactly to map that data to the new model. Sometimes this can be easy, but it at least involves some in-depth dissection of the old and new schemas, and the user would need to do this themselves by specifying indices. Even when this information is readily available it can be annoying to do.\r\n\r\nWe can imagine a more convenient way: if both the old and new feature vectors had slot names metadata (which is of course entirely possible), it would be a simple enough matter to figure out how to map the new feature vectors so that they looked like the old schema, and so that application of the old model would be then straight-forward.\r\n\r\n# Definition\r\n\r\nWe can describe this in the form of a slot-mapping. Let `m` be the function mapping input slot indices to the set of output slot indices and null. (Null, because some input slots could be dropped.) Let `I` and `O` be the arrays of input metadata (usually `SlotNames`) that we are using to construct this mapping.\r\n\r\n1. `m(i) == j` if and only if `I[i] == O[j]`.\r\n2. `m(i) == null` if `I[i]` occurs nowhere in `O`.\r\n3. Any uncovered output slot index will be handled either by allowing that value to have the default value for the output type (i.e., 0.0 for floating point values), or by throwing an error.\r\n\r\nFor any value `X` in *both* `I` and `O`, that value must occur exactly once. Otherwise, obviously, the mapping would be ambiguous.\r\n\r\nWe could imagine the following examples of reconciliations, where I provide slot names as an array like [A,B,C] to indicate slots named ""A"", ""B"", and ""C"", for example:\r\n\r\n1. If we reconcile [A,B,C] to [A,C], we\'d map slots 0,2 to slots 0,1, respectively, and drop slot 1.\r\n2. If we reconcile [A,B,C] to [A,C,D], we\'d map slots 0,2 to slots 0,1, respectively, drop slot 1, and either throw with the error that we could not find a slot named D, or else, have the output map to the default value for that column. (This might be a configurable `bool` option.)\r\n3. If we reconcile [A,A,B,C] to [A,B,C,C], we\'d have to throw with the error that the mapping is ambiguous, both on the grounds that we have no idea which of the two A to take, or which of the C to map to.\r\n4. If we reconcile [A,A,B,C] to [B,C,D,D], we\'d map slots 2,3 to slots 0,1, and assign the default value for that column to output slots 2,3. (Whether we\'d want to output a warning that there\'s something fishy going on with the names, is another matter to consider.)\r\n\r\n# Implementation\r\n\r\nThe interface to this transform would take:\r\n\r\n* The normal one-to-one column transform inputs (`IDataView` to transform, name of output column, name of source column),\r\n* The source schema and name of the column to reconcile that input to... if that name is left unspecified it can default to the source column name,\r\n* The name of the metadata kind along which reconciliation will happen, by default `SlotNames`. (For the sake of the discussion we will treat this as the standard scenario.)\r\n\r\nThe resulting output\'s new column will contain a mapping of slots from the input column. (Normally reconciled along `SlotNames` metadata, though this should be configurable.)\r\n\r\nAn open question is whether the deserialize model merely holds the learnt reconciliation (that is, the index mapping), or whether the reconciliation should happen each time it is deserialized. The latter is the more principled design, but is considerably less efficient since it implies the serialization of the resulting metadata\r\n\r\n## Related Work\r\n\r\nNote that this task bears some resemblance to what is done in the code here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ecc6857410f56cdc67c666de4e08844df3a1e288/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L452\r\n\r\nThere are some substantial differences though.\r\n\r\n* That involves a reconciliation among multiple data-views, whereas this issue describes a reconciliation between two data-views.\r\n* Also in the existing case the output is to get the union of all slots, whereas here we just want the input data view\'s column to resemble the input schema\'s column.\r\n* We want this to be a transform, that is, it can be saved as part of a data model. That code above is primarily for reconciling different cross-validation folds for per-instance output, and so did not need to be saved as part of a data model.\r\n'"
335536239,406,b'Add documentation for Field-Aware Factorization Machine',"b'Following porting the code for fafm, we should add documentation and examples. '"
335507007,404,b'Fluctuation in calculations precision ',"b'Trying to enable the `BinaryClassifierFieldAwareFactorizationMachineTest` test, I am seeing the build fail in Linux because of the mismatch of the results with the numbers in the baseline file. \r\n\r\nWhen the test runs as part of the linux builds, a good number of the values emitted in the Score, Probability and Log-loss columns of the  ""FieldAwareFactorizationMachine-CV-breast-cancer.txt "" file start diverging from the baselines after the 6th decimal digit. \r\nThe values generated across several runs in linux are consistent; and they are consistent across rhl and ubuntu distros. \r\n\r\nThe values generated from the OSx runs are consistent with the values generated on Windows. There is only three numbers that diverge on the 17th decimal digit.  \r\n\r\nThis is not due to random number generation issues, as when you specify the seed, the random sequence being generated in windows and linux (ubuntu) is the same across several runs. '"
335462280,403,b'Setting Threshold for Predict',b'Suppose we have some binary classification task and train the model using any of binary classifier available (LogisticRegressionBinaryClassifier or FastTreeBinaryClassifier or anything else).\r\n\r\nThen we evaluate our model on a testing set  using BinaryClassificationEvaluator. During this evaluation we can set a threshold using `Threshold` property of the evaluator. \r\n\r\nThe question is: how can we set the threshold for prediction? '
335282189,401,"b""Entry point 'Transforms.TextFeaturizer' not found when using F# Interactive""","b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  Version:            2.1.201\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nSimilar to https://github.com/dotnet/machinelearning/issues/92 I\'m trying to run the example in F#. It works fine when I run it with \r\n\r\n    fsi --exec imdb_sentiment.fsx\r\n\r\n(similar to the code here: https://github.com/isaacabraham/ml-test-experiment/blob/master/mlnet.fsx ). However when I send the source code interactively to the REPL I get an exception when I call the `Train<..>` method:\r\n\r\n```\r\nSystem.InvalidOperationException: Entry point \'Transforms.TextFeaturizer\' not found\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode..ctor(IHostEnvironment env, ModuleCatalog moduleCatalog, RunContext context, String id, String entryPointName, JObject inputs, JObject outputs, Boolean checkpoint, String stageId, Single cost)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.ValidateNodes(IHostEnvironment env, RunContext context, JArray nodes, ModuleCatalog moduleCatalog)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph..ctor(IHostEnvironment env, ModuleCatalog moduleCatalog, JArray nodes)\r\n   at Microsoft.ML.Runtime.Experiment.Compile()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n```\r\n\r\nWhen I run\r\n\r\n```\r\nlet env = new TlcEnvironment(new Nullable<int>(), false, MessageSensitivity.Unknown, 0, null, null)\r\nModuleCatalog.CreateInstance(env).AllEntryPoints()\r\n```\r\n\r\nin the REPL I get:\r\n\r\n```\r\nval it : Collections.Generic.IEnumerable<ModuleCatalog.EntryPointInfo> =\r\n  [|Models.BinaryCrossValidator: Cross validation for binary classification\r\n      {Description = ""Cross validation for binary classification"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+Arguments;\r\n       Method = MacroOutput`1 CrossValidateBinary(Microsoft.ML.Runtime.IHostEnvironment, Arguments, Microsoft.ML.Runtime.EntryPoints.EntryPointNode);\r\n       Name = ""Models.BinaryCrossValidator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+MacroOutput`1[Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+Output];\r\n       ShortName = null;};\r\n    Data.PredictorModelArrayConverter: Create an array variable of IPredictorModel\r\n      {Description = ""Create an array variable of IPredictorModel"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayIPredictorModelInput;\r\n       Method = ArrayIPredictorModelOutput MakeArray(Microsoft.ML.Runtime.IHostEnvironment, ArrayIPredictorModelInput);\r\n       Name = ""Data.PredictorModelArrayConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayIPredictorModelOutput;\r\n       ShortName = null;};\r\n    Data.TransformModelArrayConverter: Create an array variable of ITransformModel\r\n      {Description = ""Create an array variable of ITransformModel"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayITransformModelInput;\r\n       Method = ArrayITransformModelOutput MakeArray(Microsoft.ML.Runtime.IHostEnvironment, ArrayITransformModelInput);\r\n       Name = ""Data.TransformModelArrayConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayITransformModelOutput;\r\n       ShortName = null;};\r\n    Data.IDataViewArrayConverter: Create an array variable of IDataView\r\n      {Description = ""Create an array variable of IDataView"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayIDataViewInput;\r\n       Method = ArrayIDataViewOutput MakeArray(Microsoft.ML.Runtime.IHostEnvironment, ArrayIDataViewInput);\r\n       Name = ""Data.IDataViewArrayConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationBinaryMacro+ArrayIDataViewOutput;\r\n       ShortName = null;};\r\n    Models.CrossValidator: Cross validation for general learning\r\n      {Description = ""Cross validation for general learning"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationMacro+Arguments;\r\n       Method = MacroOutput`1 CrossValidate(Microsoft.ML.Runtime.IHostEnvironment, Arguments, Microsoft.ML.Runtime.EntryPoints.EntryPointNode);\r\n       Name = ""Models.CrossValidator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+MacroOutput`1[Microsoft.ML.Runtime.EntryPoints.CrossValidationMacro+Output];\r\n       ShortName = null;};\r\n    Models.CrossValidationResultsCombiner: Combine the metric data views returned from cross validation.\r\n      {Description = ""Combine the metric data views returned from cross validation."";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationMacro+CombineMetricsInput;\r\n       Method = CombinedOutput CombineMetrics(Microsoft.ML.Runtime.IHostEnvironment, CombineMetricsInput);\r\n       Name = ""Models.CrossValidationResultsCombiner"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CrossValidationMacro+CombinedOutput;\r\n       ShortName = null;};\r\n    Models.CrossValidatorDatasetSplitter: Split the dataset into the specified number of cross-validation folds (train and test sets)\r\n      {Description = ""Split the dataset into the specified number of cross-validation folds (train and test sets)"";\r\n       FriendlyName = ""Dataset CV Split"";\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.CVSplit+Input;\r\n       Method = Output Split(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Models.CrossValidatorDatasetSplitter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CVSplit+Output;\r\n       ShortName = null;};\r\n    Data.DataViewReference: Pass dataview from memory to experiment\r\n      {Description = ""Pass dataview from memory to experiment"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.DataViewReference+Input;\r\n       Method = Output ImportData(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Data.DataViewReference"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.DataViewReference+Output;\r\n       ShortName = null;};\r\n    Transforms.FeatureCombiner: Combines all the features into one feature column.\r\n      {Description = ""Combines all the features into one feature column."";\r\n       FriendlyName = ""Feature Combiner"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.FeatureCombiner+FeatureCombinerInput;\r\n       Method = TransformOutput PrepareFeatures(Microsoft.ML.Runtime.IHostEnvironment, FeatureCombinerInput);\r\n       Name = ""Transforms.FeatureCombiner"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""fc"";};\r\n    Transforms.LabelColumnKeyBooleanConverter: Transforms the label to either key or bool (if needed) to make it suitable for classification.\r\n      {Description = ""Transforms the label to either key or bool (if needed) to make it suitable for classification."";\r\n       FriendlyName = ""Prepare Classification Label"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.FeatureCombiner+ClassificationLabelInput;\r\n       Method = TransformOutput PrepareClassificationLabel(Microsoft.ML.Runtime.IHostEnvironment, ClassificationLabelInput);\r\n       Name = ""Transforms.LabelColumnKeyBooleanConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Transforms.PredictedLabelColumnOriginalValueConverter: Transforms a predicted label column to its original values, unless it is of type bool.\r\n      {Description = ""Transforms a predicted label column to its original values, unless it is of type bool."";\r\n       FriendlyName = ""Convert Predicted Label"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.FeatureCombiner+PredictedLabelInput;\r\n       Method = TransformOutput ConvertPredictedLabel(Microsoft.ML.Runtime.IHostEnvironment, PredictedLabelInput);\r\n       Name = ""Transforms.PredictedLabelColumnOriginalValueConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Transforms.LabelToFloatConverter: Transforms the label to float to make it suitable for regression.\r\n      {Description = ""Transforms the label to float to make it suitable for regression."";\r\n       FriendlyName = ""Prepare Regression Label"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.FeatureCombiner+RegressionLabelInput;\r\n       Method = TransformOutput PrepareRegressionLabel(Microsoft.ML.Runtime.IHostEnvironment, RegressionLabelInput);\r\n       Name = ""Transforms.LabelToFloatConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Data.CustomTextLoader: Import a dataset from a text file\r\n      {Description = ""Import a dataset from a text file"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ImportTextData+Input;\r\n       Method = Output ImportText(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Data.CustomTextLoader"";\r\n       ObsoleteAttribute = System.ObsoleteAttribute;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ImportTextData+Output;\r\n       ShortName = null;};\r\n    Data.TextLoader: Import a dataset from a text file\r\n      {Description = ""Import a dataset from a text file"";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.ILearningPipelineLoader|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ImportTextData+LoaderInput;\r\n       Method = Output TextLoader(Microsoft.ML.Runtime.IHostEnvironment, LoaderInput);\r\n       Name = ""Data.TextLoader"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ImportTextData+Output;\r\n       ShortName = null;};\r\n    Transforms.ModelCombiner: Combines a sequence of TransformModels into a single model\r\n      {Description = ""Combines a sequence of TransformModels into a single model"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+CombineTransformModelsInput;\r\n       Method = CombineTransformModelsOutput CombineTransformModels(Microsoft.ML.Runtime.IHostEnvironment, CombineTransformModelsInput);\r\n       Name = ""Transforms.ModelCombiner"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+CombineTransformModelsOutput;\r\n       ShortName = null;};\r\n    Transforms.ManyHeterogeneousModelCombiner: Combines a sequence of TransformModels and a PredictorModel into a single PredictorModel.\r\n      {Description = ""Combines a sequence of TransformModels and a PredictorModel into a single PredictorModel."";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+PredictorModelInput;\r\n       Method = PredictorModelOutput CombineModels(Microsoft.ML.Runtime.IHostEnvironment, PredictorModelInput);\r\n       Name = ""Transforms.ManyHeterogeneousModelCombiner"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+PredictorModelOutput;\r\n       ShortName = null;};\r\n    Transforms.TwoHeterogeneousModelCombiner: Combines a TransformModel and a PredictorModel into a single PredictorModel.\r\n      {Description = ""Combines a TransformModel and a PredictorModel into a single PredictorModel."";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+SimplePredictorModelInput;\r\n       Method = PredictorModelOutput CombineTwoModels(Microsoft.ML.Runtime.IHostEnvironment, SimplePredictorModelInput);\r\n       Name = ""Transforms.TwoHeterogeneousModelCombiner"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+PredictorModelOutput;\r\n       ShortName = null;};\r\n    Models.DatasetTransformer: Applies a TransformModel to a dataset.\r\n      {Description = ""Applies a TransformModel to a dataset."";\r\n       FriendlyName = ""Apply Transform Model Output"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+ApplyTransformModelInput;\r\n       Method = ApplyTransformModelOutput Apply(Microsoft.ML.Runtime.IHostEnvironment, ApplyTransformModelInput);\r\n       Name = ""Models.DatasetTransformer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ModelOperations+ApplyTransformModelOutput;\r\n       ShortName = null;};\r\n    Models.OneVersusAll: One-vs-All macro (OVA)\r\n      {Description = ""One-vs-All macro (OVA)"";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITrainerInputWithWeight;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITrainerInputWithLabel;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITrainerInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.OneVersusAllMacro+Arguments;\r\n       Method = MacroOutput`1 OVA(Microsoft.ML.Runtime.IHostEnvironment, Arguments, Microsoft.ML.Runtime.EntryPoints.EntryPointNode);\r\n       Name = ""Models.OneVersusAll"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+MacroOutput`1[Microsoft.ML.Runtime.EntryPoints.OneVersusAllMacro+Output];\r\n       ShortName = null;};\r\n    Models.TrainTestBinaryEvaluator: Train test for binary classification\r\n      {Description = ""Train test for binary classification"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.TrainTestBinaryMacro+Arguments;\r\n       Method = MacroOutput`1 TrainTestBinary(Microsoft.ML.Runtime.IHostEnvironment, Arguments, Microsoft.ML.Runtime.EntryPoints.EntryPointNode);\r\n       Name = ""Models.TrainTestBinaryEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+MacroOutput`1[Microsoft.ML.Runtime.EntryPoints.TrainTestBinaryMacro+Output];\r\n       ShortName = null;};\r\n    Models.TrainTestEvaluator: General train test for any supported evaluator\r\n      {Description = ""General train test for any supported evaluator"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.TrainTestMacro+Arguments;\r\n       Method = MacroOutput`1 TrainTest(Microsoft.ML.Runtime.IHostEnvironment, Arguments, Microsoft.ML.Runtime.EntryPoints.EntryPointNode);\r\n       Name = ""Models.TrainTestEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+MacroOutput`1[Microsoft.ML.Runtime.EntryPoints.TrainTestMacro+Output];\r\n       ShortName = null;};\r\n    Transforms.TrainTestDatasetSplitter: Split the dataset into train and test sets\r\n      {Description = ""Split the dataset into train and test sets"";\r\n       FriendlyName = ""Dataset Train-Test Split"";\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.TrainTestSplit+Input;\r\n       Method = Output Split(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Transforms.TrainTestDatasetSplitter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.TrainTestSplit+Output;\r\n       ShortName = null;};\r\n    Transforms.DataCache: Caches using the specified cache option.\r\n      {Description = ""Caches using the specified cache option."";\r\n       FriendlyName = ""Cache Data"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.Cache+CacheInput;\r\n       Method = CacheOutput CacheData(Microsoft.ML.Runtime.IHostEnvironment, CacheInput);\r\n       Name = ""Transforms.DataCache"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.Cache+CacheOutput;\r\n       ShortName = null;};\r\n    Transforms.ColumnConcatenator: Concatenates two columns of the same item type.\r\n      {Description = ""Concatenates two columns of the same item type."";\r\n       FriendlyName = ""Concat Transform"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.ConcatTransform+Arguments;\r\n       Method = TransformOutput ConcatColumns(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.ColumnConcatenator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Concat"";};\r\n    Transforms.ColumnSelector: Selects a set of columns, dropping all others\r\n      {Description = ""Selects a set of columns, dropping all others"";\r\n       FriendlyName = ""Select Columns"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.DropColumnsTransform+KeepArguments;\r\n       Method = TransformOutput SelectColumns(Microsoft.ML.Runtime.IHostEnvironment, KeepArguments);\r\n       Name = ""Transforms.ColumnSelector"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Transforms.ColumnCopier: Duplicates columns from the dataset\r\n      {Description = ""Duplicates columns from the dataset"";\r\n       FriendlyName = ""Copy Columns Transform"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.CopyColumnsTransform+Arguments;\r\n       Method = TransformOutput CopyColumns(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.ColumnCopier"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Copy"";};\r\n    Transforms.ColumnDropper: Drops columns from the dataset\r\n      {Description = ""Drops columns from the dataset"";\r\n       FriendlyName = ""Drop Columns Transform"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.DropColumnsTransform+Arguments;\r\n       Method = TransformOutput DropColumns(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.ColumnDropper"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Drop"";};\r\n    Transforms.ScoreColumnSelector: Selects only the last score columns and the extra columns specified in the arguments.\r\n      {Description = ""Selects only the last score columns and the extra columns specified in the arguments."";\r\n       FriendlyName = ""Choose Columns By Index"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+ScoreColumnSelectorInput;\r\n       Method = TransformOutput SelectColumns(Microsoft.ML.Runtime.IHostEnvironment, ScoreColumnSelectorInput);\r\n       Name = ""Transforms.ScoreColumnSelector"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Transforms.BinaryPredictionScoreColumnsRenamer: For binary prediction, it renames the PredictedLabel and Score columns to include the name of the positive class.\r\n      {Description = ""For binary prediction, it renames the PredictedLabel and Score columns to include the name of the positive class."";\r\n       FriendlyName = ""Rename Binary Prediction Score Columns"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+RenameBinaryPredictionScoreColumnsInput;\r\n       Method = TransformOutput RenameBinaryPredictionScoreColumns(Microsoft.ML.Runtime.IHostEnvironment, RenameBinaryPredictionScoreColumnsInput);\r\n       Name = ""Transforms.BinaryPredictionScoreColumnsRenamer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = null;};\r\n    Transforms.DatasetScorer: Score a dataset with a predictor model\r\n      {Description = ""Score a dataset with a predictor model"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+Input;\r\n       Method = Output Score(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Transforms.DatasetScorer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+Output;\r\n       ShortName = null;};\r\n    Transforms.DatasetTransformScorer: Score a dataset with a transform model\r\n      {Description = ""Score a dataset with a transform model"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+InputTransformScorer;\r\n       Method = Output ScoreUsingTransform(Microsoft.ML.Runtime.IHostEnvironment, InputTransformScorer);\r\n       Name = ""Transforms.DatasetTransformScorer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+Output;\r\n       ShortName = null;};\r\n    Transforms.Scorer: Turn the predictor model into a transform model\r\n      {Description = ""Turn the predictor model into a transform model"";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+ModelInput;\r\n       Method = Output MakeScoringTransform(Microsoft.ML.Runtime.IHostEnvironment, ModelInput);\r\n       Name = ""Transforms.Scorer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.ScoreModel+Output;\r\n       ShortName = null;};\r\n    Transforms.RowRangeFilter: Filters a dataview on a column of type Single, Double or Key (contiguous). Keeps the values that are in the specified min/max range. NaNs are always filtered out. If the input is a Key type, the min/max are considered percentages of the number of values.\r\n      {Description = ""Filters a dataview on a column of type Single, Double or Key (contiguous). Keeps the values that are in the specified min/max range. NaNs are always filtered out. If the input is a Key type, the min/max are considered percentages of the number of values."";\r\n       FriendlyName = ""Range Filter"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.RangeFilter+Arguments;\r\n       Method = TransformOutput FilterByRange(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.RowRangeFilter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""RangeFilter"";};\r\n    Transforms.RowSkipFilter: Allows limiting input to a subset of rows by skipping a number of rows.\r\n      {Description = ""Allows limiting input to a subset of rows by skipping a number of rows."";\r\n       FriendlyName = ""Skip Filter"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.SkipTakeFilter+SkipArguments;\r\n       Method = TransformOutput SkipFilter(Microsoft.ML.Runtime.IHostEnvironment, SkipArguments);\r\n       Name = ""Transforms.RowSkipFilter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Skip"";};\r\n    Transforms.RowTakeFilter: Allows limiting input to a subset of rows by taking N first rows.\r\n      {Description = ""Allows limiting input to a subset of rows by taking N first rows."";\r\n       FriendlyName = ""Take Filter"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.SkipTakeFilter+TakeArguments;\r\n       Method = TransformOutput TakeFilter(Microsoft.ML.Runtime.IHostEnvironment, TakeArguments);\r\n       Name = ""Transforms.RowTakeFilter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Take"";};\r\n    Transforms.RowSkipAndTakeFilter: Allows limiting input to a subset of rows at an optional offset.  Can be used to implement data paging.\r\n      {Description = ""Allows limiting input to a subset of rows at an optional offset.  Can be used to implement data paging."";\r\n       FriendlyName = ""Skip and Take Filter"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.SkipTakeFilter+Arguments;\r\n       Method = TransformOutput SkipAndTakeFilter(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.RowSkipAndTakeFilter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""SkipTake"";};\r\n    Models.Summarizer: Summarize a linear regression predictor.\r\n      {Description = ""Summarize a linear regression predictor."";\r\n       FriendlyName = null;\r\n       InputKinds = null;\r\n       InputType = Microsoft.ML.Runtime.EntryPoints.SummarizePredictor+Input;\r\n       Method = SummaryOutput Summarize(Microsoft.ML.Runtime.IHostEnvironment, Input);\r\n       Name = ""Models.Summarizer"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = null;\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+SummaryOutput;\r\n       ShortName = null;};\r\n    Models.AnomalyDetectionEvaluator: Evaluates an anomaly detection scored dataset.\r\n      {Description = ""Evaluates an anomaly detection scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.AnomalyDetectionMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput AnomalyDetection(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.AnomalyDetectionEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.BinaryClassificationEvaluator: Evaluates a binary classification scored dataset.\r\n      {Description = ""Evaluates a binary classification scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.BinaryClassifierMamlEvaluator+Arguments;\r\n       Method = ClassificationEvaluateOutput Binary(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.BinaryClassificationEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IClassificationEvaluatorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ClassificationEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.ClusterEvaluator: Evaluates a clustering scored dataset.\r\n      {Description = ""Evaluates a clustering scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.ClusteringMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput Clustering(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.ClusterEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.ClassificationEvaluator: Evaluates a multi class classification scored dataset.\r\n      {Description = ""Evaluates a multi class classification scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.MultiClassMamlEvaluator+Arguments;\r\n       Method = ClassificationEvaluateOutput MultiClass(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.ClassificationEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IClassificationEvaluatorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ClassificationEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.MultiOutputRegressionEvaluator: Evaluates a multi output regression scored dataset.\r\n      {Description = ""Evaluates a multi output regression scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.MultiOutputRegressionMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput MultiOutputRegression(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.MultiOutputRegressionEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.QuantileRegressionEvaluator: Evaluates a quantile regression scored dataset.\r\n      {Description = ""Evaluates a quantile regression scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.QuantileRegressionMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput QuantileRegression(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.QuantileRegressionEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.RankerEvaluator: Evaluates a ranking scored dataset.\r\n      {Description = ""Evaluates a ranking scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.RankerMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput Ranking(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.RankerEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.RegressionEvaluator: Evaluates a regression scored dataset.\r\n      {Description = ""Evaluates a regression scored dataset."";\r\n       FriendlyName = null;\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+IEvaluatorInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.RegressionMamlEvaluator+Arguments;\r\n       Method = CommonEvaluateOutput Regression(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Models.RegressionEvaluator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+IEvaluatorOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CommonEvaluateOutput;\r\n       ShortName = null;};\r\n    Models.PlattCalibrator: Apply a Platt calibrator to an input model\r\n      {Description = ""Apply a Platt calibrator to an input model"";\r\n       FriendlyName = ""Sigmoid Calibration"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ICalibratorInput;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Internal.Calibration.Calibrate+NoArgumentsInput;\r\n       Method = CalibratorOutput Platt(Microsoft.ML.Runtime.IHostEnvironment, NoArgumentsInput);\r\n       Name = ""Models.PlattCalibrator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ICalibratorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITrainerOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CalibratorOutput;\r\n       ShortName = null;};\r\n    Models.NaiveCalibrator: Apply a Naive calibrator to an input model\r\n      {Description = ""Apply a Naive calibrator to an input model"";\r\n       FriendlyName = ""Naive Calibrator"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ICalibratorInput;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Internal.Calibration.Calibrate+NoArgumentsInput;\r\n       Method = CalibratorOutput Naive(Microsoft.ML.Runtime.IHostEnvironment, NoArgumentsInput);\r\n       Name = ""Models.NaiveCalibrator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ICalibratorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITrainerOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CalibratorOutput;\r\n       ShortName = null;};\r\n    Models.PAVCalibrator: Apply a PAV calibrator to an input model\r\n      {Description = ""Apply a PAV calibrator to an input model"";\r\n       FriendlyName = ""PAV Calibration"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ICalibratorInput;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Internal.Calibration.Calibrate+NoArgumentsInput;\r\n       Method = CalibratorOutput Pav(Microsoft.ML.Runtime.IHostEnvironment, NoArgumentsInput);\r\n       Name = ""Models.PAVCalibrator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ICalibratorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITrainerOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CalibratorOutput;\r\n       ShortName = null;};\r\n    Models.FixedPlattCalibrator: Apply a Platt calibrator with a fixed slope and offset to an input model\r\n      {Description = ""Apply a Platt calibrator with a fixed slope and offset to an input model"";\r\n       FriendlyName = ""Fixed Sigmoid Calibration"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ICalibratorInput;\r\n                      Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Internal.Calibration.Calibrate+FixedPlattInput;\r\n       Method = CalibratorOutput FixedPlatt(Microsoft.ML.Runtime.IHostEnvironment, FixedPlattInput);\r\n       Name = ""Models.FixedPlattCalibrator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ICalibratorOutput;\r\n                       Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITrainerOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+CalibratorOutput;\r\n       ShortName = null;};\r\n    Transforms.ColumnTypeConverter: Converts a column to a different type, using standard conversions.\r\n      {Description = ""Converts a column to a different type, using standard conversions."";\r\n       FriendlyName = ""Convert Transform"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.ConvertTransform+Arguments;\r\n       Method = TransformOutput Convert(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.ColumnTypeConverter"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Convert"";};\r\n    Transforms.RandomNumberGenerator: Adds a column with a generated number sequence.\r\n      {Description = ""Adds a column with a generated number sequence."";\r\n       FriendlyName = ""Generate Number Transform"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.GenerateNumberTransform+Arguments;\r\n       Method = TransformOutput Generate(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.RandomNumberGenerator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Generate"";};\r\n    Transforms.LabelIndicator: Label remapper used by OVA\r\n      {Description = ""Label remapper used by OVA"";\r\n       FriendlyName = ""LabelIndicator"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.LabelIndicatorTransform+Arguments;\r\n       Method = TransformOutput LabelIndicator(Microsoft.ML.Runtime.IHostEnvironment, Arguments);\r\n       Name = ""Transforms.LabelIndicator"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""LabelIndictator"";};\r\n    Transforms.NoOperation: Does nothing.\r\n      {Description = ""Does nothing."";\r\n       FriendlyName = ""No Op"";\r\n       InputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonInputs+ITransformInput|];\r\n       InputType = Microsoft.ML.Runtime.Data.NopTransform+NopInput;\r\n       Method = TransformOutput Nop(Microsoft.ML.Runtime.IHostEnvironment, NopInput);\r\n       Name = ""Transforms.NoOperation"";\r\n       ObsoleteAttribute = null;\r\n       OutputKinds = [|Microsoft.ML.Runtime.EntryPoints.CommonOutputs+ITransformOutput|];\r\n       OutputType = Microsoft.ML.Runtime.EntryPoints.CommonOutputs+TransformOutput;\r\n       ShortName = ""Nop"";}|]\r\n```\r\n\r\nAre there any workaround I can use to get this module into the module list? Ping @isaacabraham\r\n\r\n'"
335177426,400,b'Iris data set (iris.txt) is not correct',"b""[/test/data folder](https://github.com/dotnet/machinelearning/tree/master/test/data) contains two files related to the iris data set:\r\n- [*iris.data*](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.data) which source looks to be [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/)\r\n- [*iris.txt*](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.txt) that is tab-separated and contains the header with the column titles\r\n\r\nProblem: *iris.txt* does not match *iris.data*. \r\n\r\nLet's forget about the **Label** column and consider only the feature columns. While those columns in *iris.txt* are named in the same order as they are in the *iris.data*, the data values were somehow mixed.\r\n\r\nFirst lines of the *iris.data*:\r\n```\r\n5.1,3.5,1.4,0.2,Iris-setosa\r\n4.9,3.0,1.4,0.2,Iris-setosa\r\n4.7,3.2,1.3,0.2,Iris-setosa\r\n```\r\n\r\nFirst lines of the *iris.txt*:\r\n```\r\n#Label\tSepal length\tSepal width\tPetal length\tPetal width\r\n0\t3.5\t1.4\t0.2\t5.1\r\n0\t3.0\t1.4\t0.2\t4.9\r\n0\t3.2\t1.3\t0.2\t4.7\r\n```\r\n\r\nThe last column in the *iris.txt* must be second shifting other feature columns by one to the right. Petals of length 0.2 cm and width 5.1 cm are not natural :).\r\n\r\n//cc @OliaG as the iris data sets in the [dotnet/machinelearning-samples](https://github.com/dotnet/machinelearning-samples/tree/master/datasets) look to be produced from the *iris.txt* file."""
335070811,399,"b'Passing CollectionDataSource w/ SQL dependency throws ""System.ArgumentOutOfRangeException: Source column not found""'","b'### Issue\r\nPassing a `CollectionDataSource.Create<T>(data: var)` to `pipeline.Add(var)` returns null values when referencing SQL Db via EF Core as the data source. Note that the latest version of ML.Net (0.20) is currently indicated as a dependency in the .csproj.\r\n\r\nInspecting the object indicates a valid state of data returned from the table but loaded as null into the pipeline however, I am not clear if the bug is attributable to the dataloader or its use. Any guidelines or help on the corrected implementation of parsing data from SQL Server is much appreciated.\r\n\r\n\r\n### Implementation\r\n\r\n**genericClass.cs**\r\n```\r\npublic partial class GenericClass {\r\n    public int CustomerId { get; set; }\r\n    public float PurchaseAmt { get; set; }\r\n    public string OrderType { get; set; }\r\n}\r\n\r\npublic partial class GenericPredictionClass {\r\n    [ColumnName(""Score"")]\r\n    public float PredictedAmt;\r\n}\r\n```\r\n\r\n**sampleController.cs**\r\n```\r\npublic async Task<IActionResult> ShowOutput() {\r\n    PredictionModel<GenericClass, GenericPredictionClass> model = await TrainAsync();\r\n    \r\n    return View();\r\n}\r\n\r\nprivate Task<List<GenericClass> LoadDataFromSql() {\r\n    var sqlTblOutput = _context.Table1\r\n        .Take(1000);\r\n\r\n    return Task.Run(function: () => sqlTblOutput.ToList());\r\n}\r\n\r\nprivate async Task<PredictionModel<GenericClass, GenericPredictionClass>> TrainAsync() {\r\n    var pipeline = new LearningPipeline();\r\n    List<GenericClass> parseData = await LoadDataFromSql();\r\n    var dataReference = CollectionDataSource.Create<GenericClass>(data: parseData);\r\n\r\n    pipeline.Add(dataReference);\r\n    pipeline.Add(new CategoricalOneHotVectorizer(""OrderType""));\r\n   \r\n    ...\r\n\r\n    return model;\r\n}\r\n```\r\n\r\n\r\n\r\n### Locals\r\n\r\n```\r\npipeline: {Microsoft.ML.LearningPipeline}\r\n    Rows [PipelineItemDebugRow[]]: {Microsoft.ML.PipelineItemDebugRow[10]}\r\n        [0] [PipelineItemDebugRow]: """"\r\n            Values [string]: """"\r\n\r\n\r\nparseData [List]: Count = 1000\r\n    [0]: {Namespace.Models.GenericClass}\r\n        CustomerId: 1234\r\n        PurchaseAmt: 40.99\r\n        OrderType [string]: ""Test Order""\r\n\r\n\r\ndataReference [ILearningPipelineLoader]: {Microsoft.ML.Data.CollectionDataSource.ListDataSource<Namespace.Models.GenericClass>}\r\n    Non-Public members\r\n        _dataView [IDataView]: null\r\n        _dataViewEntryPoint [DataViewReference]: null\r\n        _listCollection [IList]: Count = 1000\r\n            [0]: {Namespace.Models.GenericClass}\r\n                CustomerId: 1234\r\n                PurchaseAmt: 40.99\r\n                OrderType [string]: ""Test Order""\r\n```\r\n\r\n\r\n### Log\r\n\r\n`\r\n""System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.ArgumentOutOfRangeException: Source column OrderType not found\\nParameter name: Source\\n   at Microsoft.ML.Runtime.Data.OneToOneTransformBase.Bindings.Create(OneToOneTransformBase parent, OneToOneColumn[] column, ISchema input, ITransposeSchema transInput, Func2 testType)\\n   at Microsoft.ML.Runtime.Data.OneToOneTransformBase..ctor(IHostEnvironment env, String name, OneToOneColumn[] column, IDataView input, Func2 testType)\\n   at Microsoft.ML.Runtime.Data.TermTransform..ctor(ArgumentsBase args, ColumnBase[] column, IHostEnvironment env, IDataView input)\\n   at Microsoft.ML.Runtime.Data.CategoricalTransform.Create(IHostEnvironment env, Arguments args, IDataView input)\\n   at Microsoft.ML.Runtime.Data.Categorical.CatTransformDict(IHostEnvironment env, Arguments input)\\n   --- End of inner exception stack trace ---\\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\\n   at Microsoft.ML.LearningPipeline.Execute(IHostEnvironment environment)\\n   at Microsoft.ML.LearningPipelineDebugProxy.ExecutePipeline()""\r\n`\r\n\r\n### System information\r\n\r\n- **Distro**: Fedora 28 (latest)\r\n- **.NET Version**:  2.1.301\r\n- **ML.NET Package version**: 0.2.0'"
335020532,398,b'Expose Microsoft.ML.Core NuGet for component authors.',"b'Currently there is a single NuGet package ""Microsoft.ML""  that contains both algorithms and the common framework.\r\n\r\nThere are two major usages for the ML.NET: \r\n1. Author end-user applications that use ML.NET for training and inference\r\n2. Author new ML.NET Components, such as trainers, loaders or transforms.\r\n\r\nThe needs of two use cases are different.  For the former, we need everything that is currently included in Microsoft.ML.  For the latter, only the base, common interfaces and utilities are needed, such as IDataView.\r\n\r\nProposal:\r\n- Define additional NuGet package Microsoft.ML.Core that only contains  core, math and related common utils.\r\n- Modify Microsoft.ML to depend on  Microsoft.ML.Core.'"
335017738,396,b'Temp path created for model loading is too long',"b'In some environments access to the file system is restricted, so when we deserialize a model file first extract the entries in the zip repository to temporary files. The path for the temporary file contains the system\'s temporary folder name, followed by ""TLC_"" and a guid. Sometimes this creates a path that is too long because Windows doesn\'t allow paths that are over 260 characters. '"
335012603,395,b'EvaluatorUtils should handle key label columns with non-text key values',"b'When CV needs to concatenate the per-instance data views, it needs to reconcile the key values from the different folds, even if the key values are not text.'"
334770266,391,b'Port LightGBM ',b'Integration for LightGBM for binary and multiclass classification problems.'
334571015,390,b'Add documentation about Entry Points',"b'Add initial documentation about what entry points, entry points manifests are, and what classes related to them. \r\n'"
334529439,389,b'Improve the documentation on the transform classes',b'Documentation on the transform classes at [docs.microsoft.com](https://docs.microsoft.com) needs to be expanded. '
334528569,388,b'Improve the documentation on the trainer classes. ',b'The documentation describing the trainers on [docs.microsoft.com ](https://docs.microsoft.com) needs to be expanded. \r\n'
334256239,387,b'Example on converting ML.NET model to ONNX.',b'Add a link to an example for Convert to ONNX API.'
334221002,384,b'The warnings data view in CV macro is always null',"b'The inputs and outputs are not being wired correctly in the macro, resulting in a null for the warnings data view.'"
334137577,382,"b""Roadmap can be read as saying we don't support text""","b'In a recent StackOverflow answer, our [Roadmap ](https://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/ROADMAP.md#featurization-improvements) was seemingly interpreted it to say that text/NLP is a purely future work item. \r\n\r\nThe roadmap currently says:\r\n> ### Featurization Improvements\r\n> * Text  (*)\r\n>   * Natural language text preprocessing such as tokenization, part-of-speech tagging, and sentence > breaking\r\n>   * Pre-trained text models that can be used for extracting of semantic or sentiment features from text\r\n> * Image  (*)\r\n>   * Image preprocessing such as loading, resizing, and normalization if images\r\n>   * Image featurization, including industry-standard pre-trained ImageNet neural models, such as ResNet and AlexNet\r\n\r\n\r\n\r\nWe should change the roadmap to indicate that further text/NLP techniques like pre-trained WordEmbedding models, _improvements_ to tokenization, etc. are on the roadmap, whereas text handling, in the form of n-grams, already exists.'"
334122701,381,b'Add Factorization Machines to ML.NET',b'Add the train a field-aware factorization machine algorithm to ML.NET as described in the following papers:\r\n[1] http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf\r\n[2] http://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf\r\n[3] https://github.com/wschin/fast-ffm\r\n'
333882804,380,b'Create convenience constructor for the Transforms (workitem related to #371)',"b'This work item is related to the new API proposal #371 \r\n\r\nFollowing is the initial list of transforms that will be implemented to gather feedback.\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n\r\nThere are different ways to create a public facing API for these transforms based on their class definition.\r\n\r\n### Add `Convenience` constructor directly to the transform class.\r\n\r\n It is only possible for following type of transforms. \r\n\r\n   - BootstrapSampleTransform\r\n   - ConcatTransform\r\n   - NAFilter\r\n\r\n### Add `Create` method (a helper method) for transforms that have `Create` method already implemented. \r\n\r\nThis is possible for following transforms.\r\n\r\n   - CategoricalHashTransform\r\n   - CategoricalTransform\r\n   - CopyColumnsTransform\r\n   - CountFeatureSelection\r\n\r\n### Add `CreateX` method (a helper method) for all possible use case of a transform where `X` is the name of the operation.\r\n\r\nThis is because one transform can instantiated for multiple purpose based on the argument e.g. \r\n   - DropColumnTransform (can be instantiated for dropping or keeping columns)\r\n   - LpNormNormalizerTransform (can be instantiated for LpNorm or GCNorm)\r\n   - NormalizerTransform (can be instantiated for MinMax, Mean-Var, LogMean etc.)\r\n'"
333870365,378,b'Would be nice to bring ensembles into ML.Net',"b'An Ensemble is a set of models, each trained on a sample of the training set. In some cases, training an ensemble instead of a single model is used to boost the accuracy of a given algorithm. Parallel Ensemble is an umbrella word to denote all types of ensembles where the models are independent and can run in parallel.'"
333849904,376,b'Question about predictor output: Score and PredictedLabel columns',"b""Current two tutorials in the docs use different columns to get a predicted value out of the pipeline into an instance of the user-defined prediction type:\r\n- Regression [taxi fare tutorial](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/taxi-fare#create-classes-and-define-paths) uses the **Score** column\r\n- Binary classification [sentiment analysis tutorial](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/sentiment-analysis#create-classes-and-define-paths) uses the **PredictedLabel** column\r\n\r\nHow does one know which column to use to populate instances of the prediction type? Especially given that, in case of the (binary) classification solution, the **Score** column is also available (I guess, then it contains the probabilities of being in a certain class).\r\n\r\nAs for the trainer inputs, rules are more or less clear: \r\n- Use the **Label** column for labels (or specify another column name through the `LabelColumn` property)\r\n- Use the **Features** column for features (or specify another column name through the `FeatureColumn` property)\r\n\r\nCan the setup of the predictor output be done in similar way:\r\n- Use the column with the same name across all the predictors for the predictor output. I guess that might require to extend regression `IDataView` with the **PredictedLabel** column that would be a copy of the **Score** column.\r\n- Be able to setup the name of the output column. (That seems the [PredictedLabelColumnOriginalValueConverter](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.predictedlabelcolumnoriginalvalueconverter?view=ml-dotnet) can be used for that; or I'm wrong and that class is intended for use in tandem with the [Dictionarizer](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.dictionarizer?view=ml-dotnet)?)\r\n\r\nBy the way, the mere explanation of the **Score** and **PredictedLabel** columns here would be appreciated as well. Then, at least, I'll update the docs to make story clearer."""
333768666,375,"b'""The following inputs are missing..."" error message'","b'### Issue\r\n\r\n\r\n\r\nI changed my testing application from loading training data from file (using TextLoader) to loading them from the data objects in memory using CollectionDataSource.    \r\nAt the very first attempt I forgot to include my training collection to the pipeline (`pipline.Add(collection)` were missed) and got a very strange error message:\r\n```\r\nSystem.InvalidOperationException: \'The following inputs are missing: Var_b9ec7864fc3943e9b9ab9d9b38020e3c\'\r\n```\r\n\r\nI guess the error message must be more understandable. Like ""No training collection"" or something similar.'"
333670293,374,b'StochasticDualCoordinateAscentClassifier',"b'anyone know how is ""StochasticDualCoordinateAscentClassifier()"" working? is there any explanation for that? I cant understand how it\'s working in the background.\r\nIs it a neural net model or some other model?'"
333468693,373,b'Add LightLDA transform',"b'**LightLDA: Big Topic Models on Modest Compute Clusters**\r\n- Current implementations of LDA ( Latent Dirichlet Allocation ) such as SparseLDA or AliasLDA allow to achieve massive data and model scales, for example models with tens of billions of parameters to be inferred from billions of documents. However this requires using cluster up to thousands of machines with all ensuing costs to setup and maintain. \r\n- LightLDA solves this problem in a more cost-effective manner by providing an implementation that is ef\xef\xac\x81cient enough for modest clusters with at most tens of machines...\r\n\r\nFor more details please see LightLDA paper:\r\n  http://arxiv.org/abs/1412.1576 \r\n  http://www.www2015.it/documents/proceedings/proceedings/p1351.pdf\r\nand open source implementation:\r\n  https://github.com/Microsoft/LightLDA '"
333390478,371,b'Proposal for Major Change in API',"b'In this issue we describe a proposal to change the API. The core of the\r\nproposal is, instead of working via the entry-point runtime abstraction lying\r\non top of the implementing code, we encourage people to use the implementing\r\ncode directly.\r\n\r\n# Current State\r\n\r\nWithin ML.NET, for a component to be exposed in the ""public"" API, a component\r\nauthor follows the following steps (from an extremely high level):\r\n\r\n1. The author writes a component, implementing some sort of central interface.\r\n   Often this is something like `IDataLoader`, `IDataTransform`, `ITrainer,`\r\n   or some other such type of object.\r\n2. An ""entry-point"" wrapping object is created for that component. This is a\r\n   purely functional view of components as having inputs (as fields in some\r\n   sort of input class) and outputs (as fields in some sort of output class).\r\n   This is decorated with attributes, to allow the dependency injection\r\n   framework to do its work.\r\n3. A JSON ""manifest"" describing all such components is created, through some\r\n   process involving a scan of all `.dll`s and the aforementioned attributes.\r\n4. Some other code reads this JSON ""manifest"" and out of it generates a number\r\n   of C# classes. (This process being the code in `CSharpApiGenerator.cs`, the\r\n   artifact of which is described in `CSharpApi.cs`.)\r\n\r\nA user then works with this component in the following fashion.\r\n\r\n1. The user constructs a `LearningPipeline` object.\r\n2. They adds implementations of `ILearningPipelineItem`, which are sort of\r\n   configuration objects. (These are some of the objects that were code\r\n   generated.)\r\n3. Through some process that is probably too complex to describe here, these\r\n   `ILearningPipelineItem` are transmuted into a sort of abstract ""graph""\r\n   structure comprised of inputs and outputs. (This is an ""entry-point""\r\n   experiment graph.)\r\n4. This graph structure is then serialized to JSON, de-serialized back out of\r\n   JSON, then the actual underlying code that implements the operations is\r\n   loaded using dependency injection.\r\n5. Once loaded, the associated ""settings"" objects (which are actual types\r\n   explicitly written in ML.NET) have their fields populated from values in\r\n   this JSON.\r\n6. There is some higher level runtime coordinating this process of graph nodes\r\n   (the entry-point graph runner). This is a sort of runtime for the nodes,\r\n   and handles job scheduling, variable setting, and whatnot.\r\n\r\nThe way this process works is via something called entry-points. Entry-points\r\nwere conceived as a mechanism to enable a ""regular"" way to invoke ML.NET\r\ncomponents from native code, that was more expressive and powerful than the\r\ncommand line. Essentially: they are a command-line on steroids, that instead\r\nof inventing a new DSL utilizes JSON. This is effective at alleviating the\r\nburden of writing ""bridges"" from R and Python into ML.NET. It also has\r\nadvantages in situations where you need to send a sequence of commands ""over\r\nthe wire"" in some complex fashion. While a few types would need to be handled\r\n(e.g., standard numeric types, `IDataView`, `IFileHandle`, and some others),\r\nso long as the entry-points used *only* those supported types, composing an\r\nexperiment in those non-.NET environments would be possible.\r\n\r\n# Possible Alternate State\r\n\r\nInstead of working indirectly with ML.NET components through the entry-point\r\nabstraction, you could just instantiate and use the existing classes directly.\r\nThat is, the aforementioned `IDataLoader`, `IDataTransform`, `ITrainer,` and\r\nso forth would be instantiated and operated on directly.\r\n\r\nWhile entry-points would still be necessary for any components we wished to\r\nexpose through R or Python, we would constrain our usage to those applications\r\nwhere the added level of abstraction served some purpose.\r\n\r\nThis alternate pattern of usage is already well tested, as it actually\r\nreflects how ML.NET itself is written.\r\n\r\n# Changes for ML.NET\r\n\r\nIn order to move towards this state, a few high level adjustments will be\r\nnecessary.\r\n\r\n* Low level API is based direct instantiations of `IDataViews`/`ITrainer` and\r\n  other fundamental types and utilities already used within ML.NET code.\r\n* We will work to actively identify and improve that low level API from the\r\n  point of view of usage. See the sequel for more in depth discussion of this\r\n  point.\r\n* Writing higher level abstractions to make things easier should be\r\n  encouraged, however always with the aim of making them non-opaque. That is,\r\n  in edge cases when the abstraction fails, integrating what *can* be done\r\n  with the abstraction with the lower level explicit API should be possible.\r\n  Generally: Easy things should be easy and hard things should be possible.\r\n* To clarify: We are not getting rid of entry-points, because it remains the\r\n  mechanism by which interop from non-.NET programming environments into TLC\r\n  will continue to happen, and is therefore important. The shift is: the lower\r\n  level C# API will not use entry-points. For the purpose of servicing\r\n  GUI/Python/non-.NET bindings, we will continue in our own code to provide\r\n  entry points, while allowing user code to work by implementing the core\r\n  interfaces directly.\r\n\r\n# Examples of Potential Improvements in ""Direct Access"" API\r\n\r\nWe give the following concrete examples of areas that probably need\r\nimprovement. The examples are meant to be illustrative only. That is: the list\r\nis not exhaustive, nor are specific ""solutions"" to problems meant to convey\r\nthat something *must* be done in a particular way.\r\n\r\n* Instantiation of late binding components was previously always done via\r\n  dependency injection. Therefore, all components have constructors or static\r\n  create methods that have had *identical* signatures (e.g., for transforms,\r\n  `IHostEnvironment env, Arguments args, IDataView input`). Direct\r\n  instantiation by the user *could* use that, but would doubtless be better\r\n  served by a more contextually appropriate constructor that reflects common\r\n  use-cases. For example, this:\r\n\r\n  ```csharp\r\n  IDataTransform trans = new ConcatTransform(env, new ConcatTransform.Arguments()\r\n  {\r\n      Column = new[] {\r\n      new ConcatTransform.Column()\r\n      {\r\n          Name = ""NumericalFeatures"",\r\n          Source = new[] { ""SqftLiving"", ""SqftLot"", ""SqftAbove"",   ""SqftBasement"",\r\n              ""Lat"", ""Long"", ""SqftLiving15"", ""SqftLot15"" }\r\n      }}\r\n  }, loader);\r\n  ```\r\n\r\n  may become this:\r\n\r\n  ```csharp\r\n  IDataTransform trans = new ConcatTransform(env, loader, ""NumericalFeatures"",\r\n      ""SqftLiving"", ""SqftLot"", ""SqftAbove"", ""SqftBasement"", ""Lat"", ""Long"",\r\n      ""SqftLiving15"", ""SqftLot15"");\r\n  ```\r\n\r\n  This can work both ways: if these objects are directly instantiated, the\r\n  objects could provide richer information than merely being an\r\n  `IDataTransform`, or what have you. Due to working via the command line,\r\n  entry-points, or a GUI, it is considered almost useless for a component to\r\n  have any purely programmatic access. So for example: we could have had the\r\n  `AffineNormalizer` expose its slope and intercept, but we instead expose it\r\n  by metadata instead. A direct accessor in ML.NET may be appropriate if we\r\n  directly use these components.\r\n\r\n* Creating a transform and loader feels similar. However, creating a trainer,\r\n  using it to provide a predictor, and then ultimately parameterizing a scorer\r\n  transform with that predictor. Where possible we can try to harmonize the\r\n  interfaces to make them seem more consistent. (Obviously not always possible\r\n  since the underlying abstraction may in fact be genuinely different.)\r\n\r\n* Some parts of the current library introduce needless complexity: `Train`\r\n  method on trainer is `void`, always followed by `CreatePredictor`. Other\r\n  incidents of needless complexity may be less easy to resolve.\r\n\r\n* Some parts of the current library introduce *needful* complexity, but could\r\n  probably be improved somehow. `RoleMappedData` creation and usage, while\r\n  providing an essential service (""use this column for this purpose""), is\r\n  incredibly difficult to use. When it was just an ""internal"" structure we\r\n  just sort of dealt with it, but we would like to improve it. (In some cases\r\n  we can hide its creation into auxillary helper methods, for example.)\r\n\r\n* Simple things like improving naming of things may just help a lot. For\r\n  example: `ScoreUtils.GetScorer` returns a transform with the predictor\'s\r\n  scores applied to data. `ScoreUtils.GetScoredData` or something may be a\r\n  better name.\r\n\r\n* Our so-called ""internal"" methods do not always direct people towards pits of\r\n  success. For example: some pipeline components should probably apply only\r\n  during training (e.g., filtering, sampling, caching). Some distinction or\r\n  other engineering nicety (e.g., have the utilities for saving models throw\r\n  by default) may help warn people off this common misuse case.\r\n\r\n* Components of the existing API that deal with\r\n  late-binding/dependency-injection stuff could potentially use delegates or\r\n  something like entry-point style factory interfaces instead. This means\r\n  among other things lifting out things like `SubComponent` from most code.\r\n  Whether these delegates happen to be composed from the command line parser\r\n  calling `SubComponent.CreateInstance`, or some entry-point ""subgraph""\r\n  generating a delegate out of its own graph, is the business of the command\r\n  line parser and entry-point engine, not the component code itself. (Maybe\r\n  the delegate just calls Run graph or something then binds the values.)\r\n\r\n  So for example what is currently this:\r\n\r\n  ```csharp\r\n  new Ova(env, new Ova.Argumnets() { Trainer = new SubComponent(""sdcaR"") );\r\n  ```\r\n\r\n  might become this:\r\n\r\n  ```csharp\r\n  new Ova(env, host => new SdcaRegression(host));\r\n  ```\r\n\r\n* When we think about transform chains and pipelines, both the existing and suggested systems have a need for an intermediate object capable of representing a pipeline *before* it is instantiated. That intermediate form must be something you can reason over, both to pre-verify pipelines, as well as for certain applications like suggested transforms/auto-ML. One example is issue #267.\r\n\r\n  Entry-points were *an* intermediate object, but being logically only `JObject`s you could not get rich information about what or how they would operate. (Given a pipeline in entry-points you could tell that something might be outputting *a* `IDataView`, for example, but have no information about what columns were actually in that output.)\r\n\r\n  This suggests that the API will want something *like* `LearningPipeline`, though I am quite confident `LearningPipeline` is an incorrect level of abstraction. (See the previous point about opaque abstractions, among other points.)\r\n\r\nNote that many of these enhancements will serve not only users, but component\r\nauthors (including us), and so improve the whole platform.\r\n\r\n# Miscellaneous Details\r\n\r\nNote that C# code generation from entry-point graphs will still be possible:\r\nall entry-point invocations come down to (1) defining input objects, (2)\r\ncalling a static method and (3) doing something with the output object.\r\nHowever it will probably not be possible to make it seem ""natural"" any more\r\nthan an attempt to do code-generation from a `mml` command line would seem\r\n""natural.""\r\n\r\nWhen we decided to make the public facing API entry-points based, this\r\nnecessarily required shifting related infrastructure (e.g., `GraphRunner`,\r\n`JsonManifestUtils`) into more central assemblies. Once that ""idiom"" is\r\ndeconstructed, this infrastructure should resume its prior state of being in\r\nan isolated assembly.\r\n\r\nAlong similar lines of isolation, once we shift the components to not use\r\n`SubComponent` directly, we can ""uplift"" what is currently the command line\r\nparsing code out into a separate assembly.'"
333103042,367,b'Temporary file created by HybridMemoryStream in Transposer not deleted',"b'The `HybridMemoryStream` created in the `Transposer` https://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Data/DataView/Transposer.cs#L173\r\nis closed, but never disposed.  This is because the `Dispose` implementation of the `BinaryLoader` here\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Data/DataLoadSave/Binary/BinaryLoader.cs#L1184\r\nonly calls `Dispose` on the `System.IO.BinaryReader` it contains, which in turn only calls `Close` on `HybridMemoryStream`, but **not** `Dispose` (see https://referencesource.microsoft.com/#mscorlib/system/io/binaryreader.cs,91).  Therefore, the deletion of the temporary file here\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Core/Utilities/HybridMemoryStream.cs#L127\r\nis never reached.\r\n\r\nThis is causing the temporary directory on my PC to fill up all the available space on the disk.\r\n'"
333102248,366,"b"".NET Framework 4.6.1 - ML.NET package does't show up in references, thus can't use its assembly references. ""","b'### System information\r\n\r\n- Windows 7/ 64 bit OS\r\n- .NET Framework 4.6.1 \r\n\r\n### Issue\r\n\r\n- I created a console App to use Microsoft.ML. I tried to install ML.NET package -  the package manager successfully installed it but it never shows up in references. \r\n- I am not able to use ML.NET libraries, as even after successfully installing it the using statements gives me red lines to show missing assembly reference error.\r\n![capture](https://user-images.githubusercontent.com/39928473/41513174-d9a50140-724c-11e8-9ec4-8a297304b014.PNG)\r\n![image](https://user-images.githubusercontent.com/39928473/41513187-084c47e2-724d-11e8-8b42-1d248c98ad7b.png)\r\n![image](https://user-images.githubusercontent.com/39928473/41513204-3986b1ee-724d-11e8-9435-c1bb66003d72.png)\r\n\r\n\r\n\r\n'"
332411141,360,b'Problem with ColumnCopier',"b""I wrapped ML.NET as Excel functions using ExcelDNA.\r\nEverything works except ColumnCopier (for some strange reason).\r\nMay be ColumnCopier tries to emit code which might now work in that context?\r\nIt'll take me too long to create a replication example... but hopefully this general comment is enough to find the problem."""
332239075,357,b'Using ML.Net in Classic Windows Console or WPF App',"b""@Dirkster99 commented on [Wed Jun 13 2018](https://github.com/dotnet/docs/issues/5937)\n\nI am currently evaluating the ML.Net library and get it to run with .Net Core:\r\nhttps://github.com/Dirkster99/ML\r\n\r\nbut I would like to also run it within a classic Windows console or WPF app (eg .Net 4.5.2).\r\n\r\nIs it possible to do this with the current Nuget?\r\nMy problem is that when I try to install the ML.Net Nuget package - the package manager says its installed (see output below). But the ML.Net package never shows up in the references section and I find it, thus, hard to use it in this context.\r\n\r\nIs this a current limitation of VS or an issue with the ML.Net nuget package? Is there a workaround solution?\r\n\r\n\r\nPackage Manager output log:\r\nAttempting to gather dependency information for package 'Microsoft.ML.0.2.0' with respect to project 'Classifier', targeting '.NETFramework,Version=v4.5.2'\r\nGathering dependency information took 70.64 ms\r\nAttempting to resolve dependencies for package 'Microsoft.ML.0.2.0' with DependencyBehavior 'Lowest'\r\nResolving dependency information took 0 ms\r\nResolving actions to install package 'Microsoft.ML.0.2.0'\r\nResolved actions to install package 'Microsoft.ML.0.2.0'\r\nRetrieving package 'Microsoft.ML 0.2.0' from 'nuget.org'.\r\nAdding package 'Microsoft.ML.0.2.0' to folder 'C:\\Users\\NOP\\Desktop\\Classifier\\packages'\r\nAdded package 'Microsoft.ML.0.2.0' to folder 'C:\\Users\\NOP\\Desktop\\Classifier\\packages'\r\nAdded package 'Microsoft.ML.0.2.0' to 'packages.config'\r\nSuccessfully installed 'Microsoft.ML 0.2.0' to Classifier\r\nExecuting nuget actions took 1.05 sec\r\nTime Elapsed: 00:00:01.3016144\r\n========== Finished ==========\r\n![screenshot](https://user-images.githubusercontent.com/2129700/41371517-e0e3db16-6f4a-11e8-975e-ca96a9390ee4.png)\r\n\n\n"""
332074884,354,b'TextLoader CreateFrom useHeader usage is confusing',"b'Example:\r\n\r\n`pipeline.Add(new TextLoader(_datapath).CreateFrom<SampleModel>(useHeader: true, separator: \',\'));`\r\n\r\nThe usage of the useHeader argument is not intuitive, based on the name.  The name ""useHeader"" implies that a value of **true** will cause the header line to be included when loading the model.  In reality, setting useHeader to **true** causes the header line to be skipped.  Perhaps something like ""excludeHeader"", or ""ignoreHeader"", instead?  Or, if you\'d prefer something that simply indicates the presence of a header line, versus an action to be taken, maybe ""containsHeader""?\r\n\r\nUsing ML version 0.2.0 in a .NET Core 2 console app.'"
332030298,353,b'Need better support for using JSON files as a training dataset',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: Version 2.1.200 \r\n\r\n### Issue\r\n\r\n- **What did you do?** I want to use a JSON file as my training data. \r\n- **What happened?** Throws error `System.ArgumentOutOfRangeException: \'Could not determine an IDataView type for member Patterns\'`\r\n- **What did you expect?** To be able to use my json file to train a ML model. \r\n\r\n### Source code / logs\r\n\r\nJSON File (Abbreviated here for brevity, but its all the same):\r\n```\r\n[\r\n    {\r\n      ""Label"": ""greeting"",\r\n      ""Patterns"": [ ""Hi"", ""How are you"", ""Is anyone there?"", ""Hello"", ""Good day"" ]\r\n    },\r\n    {\r\n      ""Label"": ""goodbye"",\r\n      ""Patterns"": [ ""Bye"", ""See you later"", ""Goodbye"" ]\r\n    }\r\n]\r\n\r\n```\r\n\r\nClass I am deserializing into: \r\n\r\n```\r\n  public class Intent\r\n    {\r\n        [Column(""0"")]\r\n        [ColumnName(""Label"")]\r\n        public string Label;\r\n        [Column(""1"")]\r\n        public List<string> Patterns = new List<string>();\r\n    }\r\n```\r\n\r\nLoading in the data using:\r\n```\r\n    public static class IntentLoader\r\n    {\r\n\r\n        public static List<Intent> LoadIntentData()\r\n        {\r\n            var fileContents = System.IO.File.ReadAllText(""intents.json"");\r\n\r\n            try\r\n            {\r\n               var intents = JsonConvert.DeserializeObject<List<Intent>>(fileContents);\r\n                return intents;\r\n            }\r\n            catch (Exception e)\r\n            {\r\n\r\n                throw e;\r\n            }\r\n            \r\n        }\r\n    }\r\n```\r\npipeline:\r\n```\r\n public LearningPipeline GetPipeline()\r\n        {\r\n            var intents = IntentLoader.LoadIntentData();\r\n            var collection = CollectionDataSource.Create(intents);\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(collection);\r\n            pipeline.Add(new ColumnConcatenator(outputColumn: ""Features"", ""Patterns""));\r\n            pipeline.Add(new Dictionarizer(""Label""));\r\n            pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n            pipeline.Add(new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = ""PredictedLabel"" });\r\n\r\n            return pipeline;\r\n        }\r\n```\r\nModel training (exception happens here):\r\n```\r\n public PredictionModel<Intent, IntentPrediction> Train()\r\n        {\r\n            var pipeline = GetPipeline();\r\n            var model = pipeline.Train<Intent, IntentPrediction>(); //exception thrown here\r\n            return model;\r\n        }\r\n```\r\n\r\n'"
332027543,352,"b""Can't use getter/setters in objects ""","b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 2.1.200\r\n\r\n### Issue\r\n\r\n- **What did you do?** Trying to use a JSON object that has been deserialized into C# classes\r\n- **What happened?** Using getter/setters causes errors with trying to decorate the columns. \r\nOkay:\r\n[Column(""0"")]\r\npublic string Label;\r\nNot okay:\r\n[Column(""0"")]\r\npublic string Label { get; set; }\r\n\r\n- **What did you expect?** To be able to use getter/setters. Without them, it makes everything a PITA\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nClass I am using to deserialize: \r\n\r\n```\r\n    public class Intent\r\n    {\r\n        [Column(""0"")]\r\n        [ColumnName(""Label"")]\r\n        public string Label;\r\n        [Column(""1"")]\r\n        public List<string> Patterns = new List<string>();\r\n    }\r\n\r\n```\r\n\r\nLoading in intent data with this:\r\n\r\n```\r\n public static class IntentLoader\r\n    {\r\n\r\n        public static List<Intent> LoadIntentData()\r\n        {\r\n            var fileContents = System.IO.File.ReadAllText(""intents.json"");\r\n\r\n            try\r\n            {\r\n               var intents = JsonConvert.DeserializeObject<List<Intent>>(fileContents);\r\n                return intents;\r\n            }\r\n            catch (Exception e)\r\n            {\r\n\r\n                throw e;\r\n            }\r\n            \r\n        }\r\n    }\r\n```\r\n'"
331752523,350,b'We no longer need dependency on System.ValueTuple',b'No point to drag additional dependency for package which we no longer consume.'
331705127,349,b'Enable fault tolerance in FastTree for distributed learning',"b'As we plan to add distributed training to ML.NET, we have to consider Fault Tolerance of the individual worker nodes. In the case of FastTree, fault tolerance for individual workers has two requirements:\r\n- Failed FastTree workers must be restarted in the current state of the calculation\r\n- Non-failing workers must respond to failures in the IParallelTraining components*\r\n\r\n*This response depends on the implementation of fault tolerance.\r\n'"
331369471,347,b'Use schema from trained model instead of inferring it again from type when creating prediction engine.',"b'### System information\r\n\r\n- **Windows/Linux/MacOS**:\r\n- **.NET Version: 2.1.200**: \r\n\r\n### Issue\r\n\r\n- **Defining custom schema using TextLoaderArguments in TextLoader?**\r\n- **Training failed when creating prediction engine?**\r\n- **Expect that `CreateBatchPredictionEngine` should use schema from trained model instead of inferring schema again from input type?**\r\n\r\n### Source code / logs\r\n\r\n``` C#\r\npublic class IrisData\r\n{\r\n    public float Label;\r\n\r\n    public float[] Features;\r\n}\r\n\r\npublic class IrisPrediction\r\n{\r\n    [ColumnName(""Score"")]\r\n    public float[] PredictedLabels;\r\n}\r\n        \r\npublic void SampleTest()\r\n{\r\n    string dataPath = GetDataPath(""iris.txt"");\r\n\r\n    var pipeline = new LearningPipeline(seed: 1, conc: 1);\r\n\r\n    pipeline.Add(new TextLoader(dataPath)\r\n    {\r\n        Arguments = new TextLoaderArguments\r\n        {\r\n            Separator = new[] { \'\\t\' },\r\n            HasHeader = true,\r\n            Column = new[]\r\n            {\r\n                new TextLoaderColumn()\r\n                {\r\n                    Name = ""Label"",\r\n                    Source = new [] { new TextLoaderRange(0) },\r\n                    Type = Runtime.Data.DataKind.Num\r\n                },\r\n\r\n                new TextLoaderColumn()\r\n                {\r\n                    Name = ""Features"",\r\n                    Source = new [] { new TextLoaderRange(1,4) },\r\n                    Type = Runtime.Data.DataKind.Num\r\n                }\r\n            }\r\n        }\r\n    });\r\n\r\n    pipeline.Add(new StochasticDualCoordinateAscentClassifier()\r\n    {\r\n        NormalizeFeatures = NormalizeOption.No\r\n    });\r\n\r\n    PredictionModel<IrisData, IrisPrediction> model = pipeline.Train<IrisData, IrisPrediction>();\r\n\r\n    IrisPrediction prediction = model.Predict(new IrisData()\r\n    {\r\n        Features = new[] { 3.3f, 1.6f, 0.2f, 5.1f }\r\n    });\r\n\r\n    Assert.Equal(1, prediction.PredictedLabels[0], 2);\r\n    Assert.Equal(0, prediction.PredictedLabels[1], 2);\r\n    Assert.Equal(0, prediction.PredictedLabels[2], 2);\r\n}\r\n```\r\n'"
331310502,346,b'ParallelTraining API',"b""Can anyone explain what `ParallelTraining` is and how to use it? And what's the difference between `ParallelTraining` and `SingleParallelTraining`?\r\n"""
331285976,345,b'CSharpApiGenerator.cs does not generate compile-able code...',b'CSharpApiGenerator.cs does not generate compile-able code. Some types have been moved around in different namespaces which are causing error during compilation.\r\n\r\nThis happened after the PR #61 was merged. \r\n\r\n'
330990596,343,b'Predict hangs indefinetly',"b'### System information\r\n\r\n- **OS version/distro**: Mac OS X 10.13\r\n- **.NET Version (eg., dotnet --info)**:  2.0.5\r\n\r\n### Issue\r\n\r\n- I have a `.csv` file with data that I use for individual predictions. I use a `FastTreeRegressor` model loaded from disk. I make individual predictions and not batch predictions because I need the absolute error histogram. At first, predicting works fine, but then, after what appears to be a random number of executions, the `Predict` method hangs without anything else happening.\r\n- I expect either `Predict` failing with some Exception, or better, fail for the same example or, even better, `Predict` to work for all my examples, which it should.\r\n\r\nBy _random_ I mean that I have a few million examples I have to go through, but predicting stops anywhere between after a few hundreds predictions or at best after a few thousands.\r\n\r\n### Source code / logs\r\n\r\nThe stripped down source code for `Program.cs`. Note that I have also tried with version `0.2`\r\n\r\n```\r\nusing System;\r\nusing System.IO;\r\nusing System.Threading.Tasks;\r\nusing Microsoft.ML;\r\nusing PredictionModelling;\r\n\r\nnamespace PredictionMetrics\r\n{\r\n    class Program\r\n    {\r\n\r\n        static async Task Main(string[] args)\r\n        {\r\n            foreach (string culture in cultures)\r\n            {\r\n                var model = await PredictionModel.ReadAsync<Data, DataPrediction>(""model.zip"");\r\n                StreamReader file = new StreamReader(""test.csv"");\r\n\r\n                file.ReadLine(); // This is for the header\r\n\r\n                string line;\r\n\r\n                using (StreamWriter outputFile = new StreamWriter(""test-predictions.csv""))\r\n                {\r\n                    var i = 0;\r\n                    outputFile.WriteLine($""actual-value,predicted-value"");\r\n                    while ((line = file.ReadLine()) != null)\r\n                    {\r\n                        var data = line.Split(new[] { \',\' });\r\n                        var data = new Data()\r\n                        {\r\n                            Feature0 = float.Parse(data[0]),\r\n                            Feature1 = float.Parse(data[1])\r\n                        };\r\n                        var csvLine = $""{data[2]},{model.Predict(data).Value}"";\r\n                        outputFile.WriteLine(csvLine);\r\n                        i++;\r\n                        if (i % 100 == 0)\r\n                        {\r\n                            outputFile.Flush();\r\n                        }\r\n                    }\r\n                }\r\n                file.Close();\r\n            }\r\n        }\r\n    }\r\n}\r\n```'"
330952887,342,b'Add API for shuffling to MLContext',"b'the class ""TrainTestSplit"" only support ""Fraction"" in TrainTestSplit.Input current, ""Shuffle"" is other important attribute. \r\nCould ML.NET support ""Shuffle & Split"" next version?'"
330843823,341,b'Should entry-points respect `HideEnumValueAttribute` information?',"b'The `HideEnumValueAttribute` is currently only respected by the command line help tool. Here is an example of it:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Transforms/NAHandleTransform.cs#L45-L52\r\n\r\nYet in the entry-point manifest I see is polluted with these shorter forms. I feel like these *probably* ought to be suppressed here during manifest generation as well.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/20099c31a9ca2d9c50eff299b8ce6f7be5d72346/test/BaselineOutput/Common/EntryPoints/core_manifest.json#L15620-L15632\r\n\r\nAlso the entry-point based API is affected by the same issue, of course.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/20099c31a9ca2d9c50eff299b8ce6f7be5d72346/src/Microsoft.ML/CSharpApi.cs#L11162-L11169'"
330842719,340,b'Will this work with PCL Projects? ',"b'### System information\r\n\r\n- **OS version/distro**: iOS/Android\r\n\r\n### Issue\r\n- **What did you do?**\r\nI was experimenting running this on a Xamarin Mobile app (Xam.Forms). I was able to install the nuget package into my project, which targets PCL. However, no luck in getting it to work.\r\n\r\n- **What happened?**\r\nEntry point \'Trainers.StochasticDualCoordinateAscentClassifier\' not found\r\n\r\n- **What did you expect?**\r\nI expected the program to run.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```\r\nvar pipeline = new LearningPipeline();\r\nvar data = new List<TranscriptionData>() {\r\n    new TranscriptionData { Transcription=""This is a Happy presnetation!!"" , clicked=1},\r\n    new TranscriptionData { Transcription=""Very sad now"" , clicked=0},\r\n    new TranscriptionData { Transcription=""This is sad also"" , clicked=0}\r\n };\r\n\r\n     var collection = CollectionDataSource.Create(data);\r\n     pipeline.Add(collection);\r\n     pipeline.Add(new ColumnConcatenator(""Features"", ""Transcription""));\r\n     pipeline.Add(new StochasticDualCoordinateAscentClassifier()); //ERROR: any classifier here fails with entry point\r\n     PredictionModel<TranscriptionData, TranscriptionPrediction> model = pipeline.Train<TranscriptionData,TranscriptionPrediction>();\r\n\r\n```'"
330788591,337,"b""OVA macro can't handle trainers that create SchemaBindableCalibratedPredictor""","b'The solution is to create the CalibratedPredictor (which implements IValueMapperDist, the interfaced used by OVA) whenever possible.'"
330785950,336,b'Load data into LearningPipeline without TextLoader',"b""**Question:**\r\n\r\nSo I'm actually capturing my data directly from an array of sensors, and these are currently in memory. I don't have millions of datapoints, just a few hundred. I do not want to write them to file. Is TextLoader is the only way as of now to ingest data to `LearningPipeline`? \r\n\r\nI wondering if I could point to an array of objects instead of a text file to load them up, is there any alternate way I could ingest data?"""
330733393,334,b'solution file contain link to  non existent project',"b'Where is no src\\Microsoft.ML.Commands project in our codebase\r\nProject(""{2150E333-8FDC-42A3-9474-1A3956D46DE8}"") = ""src"", ""src"", ""{09EADF06-BE25-4228-AB53-95AE3E15B530}""\r\n\tProjectSection(SolutionItems) = preProject\r\n\t\tsrc\\Microsoft.ML.Commands\\Microsoft.ML.Commands.csproj = src\\Microsoft.ML.Commands\\Microsoft.ML.Commands.csproj\r\n\tEndProjectSection\r\nEndProject\r\n\r\n'"
330630799,333,"b""System.DllNotFoundException: Unable to load DLL 'CpuMathNative'""","b""### System information\r\n\r\n- **OS version/distro**: Windows Server 2016 Standard\r\n- **.NET Version (eg., dotnet --info)**: Core 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nWhen trying to load model from a file `var model = PredictionModel.ReadAsync<IrisData, IrisPrediction>(modelPath).Result;` gives DllNotFoundException while running in windows container.\r\n- **What happened?**\r\nInternal Server Error\r\n- **What did you expect?**\r\nModel should be loaded in model variable.\r\n### Source code / logs\r\n```\r\nSystem.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.DotU(Single* pa, Single* pb, Int32 c)\r\n   at Microsoft.ML.Runtime.Internal\r\n1000\r\n.CpuMath.SseUtils.DotProductDense(Single[] a, Single[] b, Int32 count)\r\n   at Microsoft.ML.Runtime.Learners.MulticlassLogisticRegressionPredictor.PredictCore(VBuffer`1& src, Single[]& dst)\r\n   at Microsoft.ML.Runtime.Learners.MulticlassLogisticRegressionPredictor.<GetMapper>b__30_0[TSrc,TDst](VBuffer`1& src, VBuffer`1& dst)\r\n   at Microsoft.ML.Runtime.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, IRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Runtime.Data.MultiClassClassifierScorer.<>c__DisplayClass14_0.<GetPredictedLabelGetter>b__0(UInt32& dst)\r\n   at Microsoft.ML.Runtime.Data.KeyToValueTransform.KeyToValueMap`2.<>c__DisplayClass7_0.<GetMappingGetter>b__0(TValue& dst)\r\n   at Microsoft.ML.Runtime.Data.DataViewUtils.Splitter.Consolidator.<>c__DisplayClass4_1.<ConsolidateCore>b__2()\r\n\r\n```Please paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
330596962,332,b'TextLoader is different in 0.1.0 and 0.2.0',"b'### System information\r\n\r\n- **OS version/distro**: 2016\r\n- **.NET Version (eg., dotnet --info)**: 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to use `new TextLoader<IrisData>(dataPath, separator: "","")` in 0.2.0\r\n- **What happened?**\r\nShows error\r\n- **What did you expect?**\r\nPlease give a documentation for new changes in 0.2.0\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
330535975,331,b'Async Main is not taken as entrypoint in c# 7.0',"b""### System information\r\n\r\n- **OS version/distro**: Windows Server 2016 \r\n- **.NET Version (eg., dotnet --info)**: Core 2.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried to use static async Main\r\n- **What happened?**\r\nCouldn't build\r\n- **What did you expect?**\r\nBuild without error\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
330448071,329,b'Unhandled Exception when using OrdinaryLeastSquaresRegressor',"b""### System information\r\n\r\n- **OS version/distro Windows 10**:\r\n- **.NET Version 2.1.300-rc1-008673**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI replace `FastTreeRegressor` with `OrdinaryLeastSquaresRegressor` in sample Regression_TaxiFarePrediction https://github.com/dotnet/machinelearning-samples/blob/master/samples/getting-started/Regression_TaxiFarePrediction/Program.cs#L65\r\n- **What happened?**\r\nerror msg:\r\n```\r\n=============== Training model ===============\r\nAutomatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.\r\n  Bad value at line 1 in column PassengerCount\r\n  Bad value at line 1 in column TripDistance\r\nProcessed 100001 rows with 2 bad values and 0 format errors\r\n  Bad value at line 1 in column PassengerCount\r\n  Bad value at line 1 in column TripDistance\r\n  Bad value at line 1 in column FareAmount\r\nProcessed 100001 rows with 3 bad values and 0 format errors\r\nTrainer solving for 19 parameters across 100000 examples\r\n\r\nUnhandled Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.NotSupportedException: The MKL library (Microsoft.ML.MklImports.dll) or one of its dependencies is missing.\r\n   at Microsoft.ML.Runtime.Learners.OlsLinearRegressionTrainer.TrainCore(IChannel ch, Factory cursorFactory, Int32 featureCount)\r\n   at Microsoft.ML.Runtime.Learners.OlsLinearRegressionTrainer.Train(RoleMappedData examples)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, String name, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inpPredictor)\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\n   at Microsoft.ML.Runtime.Learners.OlsLinearRegressionTrainer.TrainRegression(IHostEnvironment env, Arguments input)\r\n\r\n```\r\n- **What did you expect?**\r\nI was wondering how to use `OrdinaryLeastSquaresRegressor`?\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n"""
330441759,328,b'v 0.2.0 does not support BinaryLogisticRegressor and LogisticRegressor',"b'### System information\r\n\r\n- **OS version/distro Windows 10**:\r\n- **.NET Version 2.1.300-rc1-008673**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nsrc:\r\n```\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Models;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\nusing System;\r\nusing System.Diagnostics;\r\nusing System.Threading.Tasks;\r\n\r\nnamespace mlnettest\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            test1();\r\n            test2();\r\n        }\r\n\r\n        static void test1()\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new BinaryLogisticRegressor());\r\n        }\r\n\r\n        static void test2()\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new LogisticRegressor());\r\n        }\r\n    }\r\n}\r\n```\r\ncsproj\r\n```\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n\r\n  <PropertyGroup>\r\n    <OutputType>Exe</OutputType>\r\n    <TargetFramework>netcoreapp2.1</TargetFramework>\r\n  </PropertyGroup>\r\n  \r\n  <ItemGroup>\r\n    <PackageReference Include=""Microsoft.ML"" Version=""0.2.0"" />\r\n  </ItemGroup>\r\n</Project>\r\n```\r\n- **What happened?**\r\nerror msg when I run `dotnet run`:\r\n```\r\nProgram.cs(23,30): error CS0246: The type or namespace name \'BinaryLogisticRegressor\' could not be found (are you missing a using directive or an assembly reference?) [C:\\Users\\guo\\Desktop\\mlnettest\\mlnettest.csproj]\r\nProgram.cs(29,30): error CS0246: The type or namespace name \'LogisticRegressor\' could not be found (are you missing a using directive or an assembly reference?) [C:\\Users\\guo\\Desktop\\mlnettest\\mlnettest.csproj]\r\n```\r\n- **What did you expect?**\r\nIf I use v0.1.0 `<PackageReference Include=""Microsoft.ML"" Version=""0.1.0"" />`, the code can run without any issue. I was wondering why v0.2.0 does not support these two learners?\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
330146549,326,b'Is it possible to visualize a generated decision tree?',"b'Like the title says, is it possible to visualize a generated decision tree based on the model?\r\nLike I heard it possible in Azure ML\r\n\r\nCurrently working on a project and would love to visualize the decision tree it generates so I can look for differences and test certain things.'"
330091005,325,b'Does ML.NET supports Chinese?',"b'For example, A Chinese `\xe9\x95\xbf\xe6\x98\xa5\xe5\xb8\x82\xe9\x95\xbf\xe6\x98\xa5\xe8\x8d\xaf\xe5\xba\x97`  that have many ways to extract text.\r\n\r\nBigram algorithm, its simple and fast.\r\n```\r\n\xe9\x95\xbf\xe6\x98\xa5\r\n\xe6\x98\xa5\xe5\xb8\x82\r\n\xe5\xb8\x82\xe9\x95\xbf\r\n\xe9\x95\xbf\xe6\x98\xa5\r\n\xe6\x98\xa5\xe8\x8d\xaf\r\n\xe8\x8d\xaf\xe5\xba\x97\r\n```\r\n\r\nStandard algorithm.\r\n```\r\n\xe9\x95\xbf\xe6\x98\xa5\xe5\xb8\x82\r\n\xe9\x95\xbf\xe6\x98\xa5\r\n\xe8\x8d\xaf\xe5\xba\x97\r\n```\r\n\r\nI noticed the ML.NET was include a `NGramNgramExtractor` class that supported N-Gram algorithm, does it  support Chinese? The `Transforms.TextTransformLanguage` includes `English,French,German,Dutch,Italian,Spanish,Japanese`.\r\n\r\nIf not, how to implement custom text segmentation for other language? Hope in the future version can support custom extract text feature.\r\n\r\nThanks.\r\n'"
330074648,323,b'Return Centroids for KMeansPlusPlusClusterer After Training',"b'### Issue\r\n\r\nOnce training is complete on a KMeansPlusPlusClusterer algorithm in the `LearningPipeline`, provide a method of accessing the centroids. \r\n'"
330060335,322,"b'Release notes for 0.2 are not linked from the .sln, but those for 0.1 are'","b'When browsing the `docs` folder via Visual Studio, there are release notes for ML.NET 0.1 listed. However, the release notes for 0.2 are missing. They are, in fact, in the file system.\r\n\r\nWe should have a consistent scheme here: Either the files are always added to the solution file, or never.'"
330035085,321,b'Add weight quantization',"b'Weight quantization enables low-power edge devices to perform machine learning by trading a couple of percentage points of prediction accuracy for a very dramatic reduction in computation times. \r\n\r\nMobile devices will motivate dramatic optimizations and code changes to enable cross platform SIMD across very different devices. An alternative is to create an implementation that is fast(simple) enough and correct enough that most users never need to care about numerical performance. \r\n\r\nThe approach was initially made popular by XNOR-NET for real time edge vision classification. \r\nhttps://arxiv.org/pdf/1603.05279.pdf\r\nBut this is a generalized approach and there have been deeper analyses of the best way to negotiate the bitwidth-vs-model-accuracy scale. The training side can compress until the accuracy drops too low as part of the automatic hyperparameter tuning. This means a slight increase in training time in order to achieve low-power, high-speed streaming inference on edge processors. '"
330014023,319,b'Include all categorical split points in feature gain map and clean up regression tree predictor for categorical splits.',b'FastTree feature gain map needs to contain feature gain per categorical split point in the case of multiple categorical values chosen as split points on a node when categorical split optimization is turned on.'
329999025,318,b'TextLoader().CreateFrom() Unhandled Exception for version 0.2.0',"b'### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Version 2.1.300-rc1-008673**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI move my code from ML.NET version 0.1.0 to ML.NET version 0.2.0. I have a data structure `FlightData` looks like following. Then I use `pipeline.Add(new TextLoader(trainingDataSet).CreateFrom<FlightData>(useHeader: true, separator: \',\', allowQuotedStrings:true));` to load the data. \r\n```\r\n    public class FlightData\r\n    {\r\n        [Column(ordinal: ""0"")]\r\n        public float QUARTER;\r\n        [Column(ordinal: ""1"")]\r\n        public float MONTH;\r\n        [Column(ordinal: ""2"")]\r\n        public float DAY_OF_MONTH;\r\n        [Column(ordinal: ""3"")]\r\n        ....\r\n    }\r\n```\r\n- **What happened?**\r\n\r\nError message: \r\n```\r\nUnhandled Exception: System.InvalidOperationException: DAY_OF_MONTH is not alphanumeric.\r\n   at Microsoft.ML.Data.TextLoader.CreateFrom[TInput](Boolean useHeader, Char separator, Boolean allowQuotedStrings, Boolean supportSparse, Boolean trimWhitespace)\r\n```\r\n\r\nAfter looking at the error msg and ML.NET source code https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML/Data/TextLoader.cs#L87, I change `DAY_OF_MONTH` to `DAYOFMONTH`. Then the error disappears. But it\'s common to use `_` in the variable names. \r\n- **What did you expect?**\r\n\r\nI can use `_` in variable names, which are part of Input fed to TextLoader.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n'"
329979741,317,b'Question: How to get accuracy in predicted label',"b'Is it possible to get the accuracy/precision of a predicted label? Is there an attribute I can use the extract it? Basically some thing like:\r\n\r\n```cs\r\npublic class EmployeePrediction\r\n{\r\n    [ColumnName(""PredictedLabel"")]\r\n    public bool Outcome;\r\n\r\n    [SomeAttribute]\r\n    public float Accuracy;\r\n}\r\n```'"
329648904,315,b'ExecuteGraphCommand.GetOutputToPath should not throw if the outputs are null ',"b'### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: 0.3.0-preview-26604-1\r\n\r\n### Issue\r\n\r\nConstruct an entry-points graph invoking the CV macro, and specifying the Warnings output of the CV macro, as the overall graph output. \r\n\r\nNotice that if the run produced no warnings, (warnings idv is null) ExecuteGraphCommand.GetOutputToPath throws. I think it should just warn and proceed to saving the rest of the output. \r\n\r\n\r\n### Source code / logs\r\n\r\nGraph used:\r\n```json\r\n{\r\n\t""Inputs"": {\r\n\t\t""TrainFile"": ""..\\\\Sent140_Train.tsv""\r\n\t},\r\n\t""Outputs"": {\r\n\t\t""PredictorModel0"": ""PredictorModel0.zip"",\r\n\t\t""Warnings0"": ""Warnings0.csv"",\r\n\t\t""OverallMetrics0"": ""OverallMetrics0.csv"",\r\n\t\t""PerInstanceMetrics0"": ""PerInstanceMetrics0.csv"",\r\n\t\t""ConfusionMatrix0"": ""ConfusionMatrix0.csv""\r\n\t},\r\n\t""Nodes"": [\r\n\t\t{\r\n\t\t\t""Name"": ""Data.CustomTextLoader"",\r\n\t\t\t""Inputs"": {\r\n\t\t\t\t""InputFile"": ""$TrainFile"",\r\n\t\t\t\t""CustomSchema"": "" sep=tab header+ col=SentimentText:TX:3  col=Sentiment:R4:1 ""\r\n\t\t\t},\r\n\t\t\t""Outputs"": {\r\n\t\t\t\t""Data"": ""$TrainDataView""\r\n\t\t\t}\r\n\t\t},\r\n\t\t{\r\n\t\t\t""Name"": ""Models.CrossValidator"",\r\n\t\t\t""Inputs"": {\r\n\t\t\t\t""Kind"": ""SignatureBinaryClassifierTrainer"",\r\n\t\t\t\t""NumFolds"": 2,\r\n\t\t\t\t""Data"": ""$TrainDataView"",\r\n\t\t\t\t""Nodes"": [\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\t""Name"": ""Transforms.ColumnCopier"",\r\n\t\t\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t\t\t""Column"": [\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\t""Name"": ""Label"",\r\n\t\t\t\t\t\t\t\t\t""Source"": ""Sentiment""\r\n\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t""Data"": ""$data0""\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t\t\t""OutputData"": ""$Copy_DataView_Output_1528237424459_579"",\r\n\t\t\t\t\t\t\t""Model"": ""$Copy_TransformModel_Output_1528237424459_493""\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\t""Name"": ""Transforms.TextFeaturizer"",\r\n\t\t\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t\t\t""Column"": {\r\n\t\t\t\t\t\t\t\t""Name"": ""FeaturesText"",\r\n\t\t\t\t\t\t\t\t""Source"": [\r\n\t\t\t\t\t\t\t\t\t""SentimentText""\r\n\t\t\t\t\t\t\t\t]\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t""Data"": ""$Copy_DataView_Output_1528237424459_579"",\r\n\t\t\t\t\t\t\t""WordFeatureExtractor"": {\r\n\t\t\t\t\t\t\t\t""Name"": ""NGram"",\r\n\t\t\t\t\t\t\t\t""Settings"": {\r\n\t\t\t\t\t\t\t\t\t""NgramLength"": 2,\r\n\t\t\t\t\t\t\t\t\t""SkipLength"": 0,\r\n\t\t\t\t\t\t\t\t\t""AllLengths"": true,\r\n\t\t\t\t\t\t\t\t\t""MaxNumTerms"": [\r\n\t\t\t\t\t\t\t\t\t\t10000000\r\n\t\t\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t\t\t""Weighting"": ""Tf""\r\n\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t""CharFeatureExtractor"": {\r\n\t\t\t\t\t\t\t\t""Name"": ""NGram"",\r\n\t\t\t\t\t\t\t\t""Settings"": {\r\n\t\t\t\t\t\t\t\t\t""NgramLength"": 3,\r\n\t\t\t\t\t\t\t\t\t""SkipLength"": 0,\r\n\t\t\t\t\t\t\t\t\t""AllLengths"": true,\r\n\t\t\t\t\t\t\t\t\t""MaxNumTerms"": [\r\n\t\t\t\t\t\t\t\t\t\t10000000\r\n\t\t\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t\t\t""Weighting"": ""Tf""\r\n\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t\t\t""OutputData"": ""$Text_DataView_Output_1528237424462_956"",\r\n\t\t\t\t\t\t\t""Model"": ""$Text_TransformModel_Output_1528237424462_164""\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\t""Name"": ""Transforms.ColumnConcatenator"",\r\n\t\t\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t\t\t""Column"": [\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\t""Name"": ""Features"",\r\n\t\t\t\t\t\t\t\t\t""Source"": [\r\n\t\t\t\t\t\t\t\t\t\t""FeaturesText""\r\n\t\t\t\t\t\t\t\t\t]\r\n\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t""Data"": ""$Text_DataView_Output_1528237424462_956""\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t\t\t""OutputData"": ""$Concat_DataView_Output_1528237424464_228"",\r\n\t\t\t\t\t\t\t""Model"": ""$Concat_TransformModel_Output_1528237424464_5""\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\t""Name"": ""Trainers.AveragedPerceptronBinaryClassifier"",\r\n\t\t\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t\t\t""TrainingData"": ""$Concat_DataView_Output_1528237424464_228"",\r\n\t\t\t\t\t\t\t""LossFunction"": {\r\n\t\t\t\t\t\t\t\t""Name"": ""HingeLoss"",\r\n\t\t\t\t\t\t\t\t""Settings"": {\r\n\t\t\t\t\t\t\t\t\t""Margin"": 1\r\n\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t""NumIterations"": 10,\r\n\t\t\t\t\t\t\t""Calibrator"": {\r\n\t\t\t\t\t\t\t\t""Name"": ""PlattCalibrator""\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t\t\t""PredictorModel"": ""$ap_PredictorModel_Output_1528237424465_314""\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\t""Name"": ""Transforms.ManyHeterogeneousModelCombiner"",\r\n\t\t\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t\t\t""TransformModels"": [\r\n\t\t\t\t\t\t\t\t""$Copy_TransformModel_Output_1528237424459_493"",\r\n\t\t\t\t\t\t\t\t""$Text_TransformModel_Output_1528237424462_164"",\r\n\t\t\t\t\t\t\t\t""$Concat_TransformModel_Output_1528237424464_5""\r\n\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t""PredictorModel"": ""$ap_PredictorModel_Output_1528237424465_314""\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t\t\t""PredictorModel"": ""$PredictorModel0""\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t],\r\n\t\t\t\t""Inputs"": {\r\n\t\t\t\t\t""Data"": ""$data0""\r\n\t\t\t\t},\r\n\t\t\t\t""Outputs"": {\r\n\t\t\t\t\t""PredictorModel"": ""$PredictorModel0""\r\n\t\t\t\t}\r\n\t\t\t},\r\n\t\t\t""Outputs"": {\r\n\t\t\t\t""PredictorModel"": ""$PredictorModel0"",\r\n\t\t\t\t""Warnings"": ""$Warnings0"",\r\n\t\t\t\t""OverallMetrics"": ""$OverallMetrics0"",\r\n\t\t\t\t""PerInstanceMetrics"": ""$PerInstanceMetrics0"",\r\n\t\t\t\t""ConfusionMatrix"": ""$ConfusionMatrix0""\r\n\t\t\t}\r\n\t\t}\r\n\t]\r\n}\r\n```'"
329640135,314,"b""The transforms entry points don't contain function information ""","b'### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: 0.3.0-preview-26604-1\r\n\r\n### Issue\r\n\r\nThe transforms entry point should contain information about the way in which they manipulate the data: schema manipulation, featurizer, pre-processing etc. \r\n\r\nSystems interfacing with ML.NET through entry points might need to classify the transforms based on the function their perform over the dataset, and present them to their users in that fashion. '"
329638918,313,"b""The trainer entry points don't contain sufficient information about the algorithm type (linear, tree etc)""","b""### System information\r\n\r\n- **.NET Version (eg., dotnet --info)**: 0.3.0-preview-26604-1\r\n\r\n### Issue\r\nThe trainer entry points don't contain any information about their algorithm type ( tree, linear)\r\nSystems interfacing with ML.NET in this fashion might need to present to their users the information classified based on this criteria. \r\n"""
329628280,312,b'Add API for Cluster Evaluator ',b'We need a public API for Cluster Evaluator\r\n'
329623049,311,b'Simplification of experiment methods',"b""Few things so far:\r\nA) We have this pattern in our code:\r\n```\r\nvar importInput = new ML.Data.TextLoader(dataPath);\r\n...\r\nexperiment.SetInput(importInput.InputFile, new SimpleFileHandle(env, dataPath, false, false));\r\n```\r\nAnd I'm not sure why I have to specify same file twice.\r\nB) We have this pattern everywhere in our code:\r\n```\r\nexperiment.Compile();\r\nexperiment.SetInput(importInput.InputFile, new SimpleFileHandle(env, dataPath, false, false));\r\nexperiment.Run();\r\n```\r\nCan we simplify this into one method instead of  3 different calls?"""
329607195,309,b'TextLoader is not identified',"b'### System information\r\n.NET Command Line Tools (2.1.200)\r\n\r\nProduct Information:\r\n Version:            2.1.200\r\n Commit SHA-1 hash:  2edba8d7f1\r\n\r\nRuntime Environment:\r\n OS Name:     deepin\r\n OS Version:  15.5\r\n OS Platform: Linux\r\n RID:         linux-x64\r\n Base Path:   /home/amine-smahi/dotnet/sdk/2.1.200/\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.7\r\n  Build    : 2d61d0b043915bc948ebf98836fefe9ba942be11\r\n\r\n\r\n### Issue\r\n\r\nWhen following all Getting started with ML.NET guides or using the samples , i get a missing reference message saying that TextLoader is missing are you missing assemblies\r\n\r\n### Source code / logs\r\nfor example \r\n`  var testData = new TextLoader<SentimentData>(_testDataPath, useHeader: true, separator: ""tab""); `\r\n'"
329597486,308,b'CollectionDataSource fail with CrossValidator and TrainTestEvaluator',"b'System information\r\n.NET Version (eg., dotnet --info): 0.3.0-preview-26604-1\r\n```\r\nvar pipeline = new LearningPipeline();\r\nvar data = new List<IrisData>() {\r\n    new IrisData { SepalLength = 1f, SepalWidth = 1f ,PetalLength=0.3f, PetalWidth=5.1f, Label=1},\r\n    new IrisData { SepalLength = 1f, SepalWidth = 1f ,PetalLength=0.3f, PetalWidth=5.1f, Label=1},\r\n    new IrisData { SepalLength = 1.2f, SepalWidth = 0.5f ,PetalLength=0.3f, PetalWidth=5.1f, Label=0}\r\n};\r\nvar collection = CollectionDataSource.Create(data);\r\n\r\npipeline.Add(collection);\r\npipeline.Add(new ColumnConcatenator(outputColumn: ""Features"",\r\n    ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth""));\r\npipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\nvar testCollection = CollectionDataSource.Create(data);\r\nvar tt = new TrainTestEvaluator().TrainTestEvaluate<IrisData, IrisPrediction>(pipeline, testCollection);\r\nvar cv = new CrossValidator() {  Kind = MacroUtilsTrainerKinds.SignatureMultiClassClassifierTrainer}.CrossValidate<IrisData, IrisPrediction>(pipeline);\r\n```\r\nMessage: System.ArgumentOutOfRangeException : Score column is missing\r\nParameter name: ScoreColumn\r\nLooks like test collection in both cases are empty during evaluation\r\n\r\n'"
329596456,307,"b""TrainTestEvaluator can't accept same collection for train and testing.""","b'System information\r\n.NET Version (eg., dotnet --info): 0.3.0-preview-26604-1\r\n```\r\nvar pipeline = new LearningPipeline();\r\nvar data = new List<IrisData>() {\r\n    new IrisData { SepalLength = 1f, SepalWidth = 1f ,PetalLength=0.3f, PetalWidth=5.1f, Label=1},\r\n    new IrisData { SepalLength = 1f, SepalWidth = 1f ,PetalLength=0.3f, PetalWidth=5.1f, Label=1},\r\n    new IrisData { SepalLength = 1.2f, SepalWidth = 0.5f ,PetalLength=0.3f, PetalWidth=5.1f, Label=0}\r\n};\r\nvar collection = CollectionDataSource.Create(data);\r\npipeline.Add(collection);\r\npipeline.Add(new ColumnConcatenator(outputColumn: ""Features"",\r\n    ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth""));\r\npipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\nvar tt = new TrainTestEvaluator().TrainTestEvaluate<IrisData, IrisPrediction>(pipeline, collection);\r\n```\r\n\r\nMessage: System.InvalidOperationException : Port \'Var_c3b11d6c322a4a65ab0b8a5c7054c94c\' is already set\r\n'"
329594842,306,"b""CrossValidation and TrainTest doesn't autoinfer type of task.""","b'System information\r\n.NET Version (eg., dotnet --info): 0.3.0-preview-26604-1\r\n\r\n```string dataPath = GetDataPath(""iris.txt"");\r\nvar pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader(dataPath).CreateFrom<IrisData>(useHeader: false));\r\npipeline.Add(new ColumnConcatenator(outputColumn: ""Features"",\r\n    ""SepalLength"", ""SepalWidth"", ""PetalLength"", ""PetalWidth""));\r\npipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\nvar cv = new CrossValidator() .CrossValidate<IrisData, IrisPrediction>(pipeline);\r\n```\r\nthis will fail with Score column is missing and I have to manually add kind to CrossValidator.\r\n```\r\nvar cv = new CrossValidator() { Kind = MacroUtilsTrainerKinds.SignatureMultiClassClassifierTrainer }.CrossValidate<IrisData, IrisPrediction>(pipeline);\r\n```\r\n\r\nsame for TrainTest\r\n```\r\nvar tt = new TrainTestEvaluator().TrainTestEvaluate<IrisData, IrisPrediction>(pipeline, testCollection);\r\n```'"
329551913,305,"b""CSharpApiGenerator doesn't assign default values to Optional<> type.""","b'The code generated for an argument that is defined as\r\nstring LabelColumn = ""Label"";\r\n\r\nis:\r\n            /// <summary>\r\n            /// Column to use for labels\r\n            /// </summary>\r\n            public string LabelColumn { get; set; } = ""Label"";\r\n\r\nbut the code generate for an argument that is defined as\r\npublic Optional<string> GroupColumn = Optional<string>.Implicit(""GroupId"");\r\n\r\nis:\r\n\r\n            /// <summary>\r\n            /// Column to use for grouping\r\n            /// </summary>\r\n            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupColumn { get; set; }\r\n\r\n'"
329351355,302,b'Shall we unify the file encodings of C# source files?',"b'C# source files have different file encodings. E.g. some have UTF-8 with BOM file encoding, while some have ASCII encoding.\r\n\r\n![image](https://user-images.githubusercontent.com/9329359/40964166-fa80640a-68dc-11e8-8ae7-00633e22bd56.png)\r\n'"
329261557,300,"b""Result of OVA macro doesn't respect auto normalization.""","b'```\r\nvar dataPath = GetDataPath(@""iris.txt"");\r\nusing (var env = new TlcEnvironment(42))\r\n{\r\n    var subGraph = env.CreateExperiment();\r\n    var learnerInput = new ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier\r\n    {\r\n        NumThreads = 1\r\n    };\r\n    var learnerOutput = subGraph.Add(learnerInput);\r\n\r\n    var experiment = env.CreateExperiment();\r\n    var importInput = new ML.Data.TextLoader(dataPath);\r\n    importInput.Arguments.Column = new ML.Data.TextLoaderColumn[]\r\n    {\r\n        new ML.Data.TextLoaderColumn { Name = ""Label"", Source = new[] { new ML.Data.TextLoaderRange(0) } },\r\n        new ML.Data.TextLoaderColumn { Name = ""Features"", Source = new[] { new ML.Data.TextLoaderRange(1,4) } }\r\n    };\r\n\r\n    var importOutput = experiment.Add(importInput);\r\n\r\n    var oneVersusAll = new ML.Models.OneVersusAll\r\n    {\r\n        TrainingData = importOutput.Data,\r\n        Nodes = subGraph,\r\n        UseProbabilities = true,\r\n    };\r\n    var ovaOutput = experiment.Add(oneVersusAll);\r\n    var scoreInput = new ML.Transforms.DatasetScorer\r\n    {\r\n        Data = importOutput.Data,\r\n        PredictorModel = ovaOutput.PredictorModel\r\n    };\r\n    var scoreOutput = experiment.Add(scoreInput);\r\n\r\n    var evalInput = new ML.Models.ClassificationEvaluator\r\n    {\r\n        Data = scoreOutput.ScoredData\r\n    };\r\n    var evalOutput = experiment.Add(evalInput);\r\n    experiment.Compile();\r\n    experiment.SetInput(importInput.InputFile, new SimpleFileHandle(env, dataPath, false, false));\r\n    experiment.Run();\r\n}\r\n```\r\n\r\nPredictor got trained on normalized features, but during prediction time it got non-normalized features. '"
329251277,299,b'Macro outputs should not be required',"b""### System information\r\n\r\n- windows\r\n- version 0.3.0-preview-26604-1 \r\n\r\n### Issue\r\nThe CV macro outputs (and any graph outputs) should not be mandatory. \r\nCurrently the CV macro is not checking for presence of the metrics, before  adding the metrics node to the outputs, and throwing if they are missing. \r\n\r\nI don't think any output should be required, and especially some metrics like 'Confusion Matrix' don't make sense for every kinds of task. \r\n\r\nTo reproduce, compose an entry points graph with the CV  macro present, and don't specify outputs for it. Run this graph. \r\n### Source code / logs\r\n\r\n{System.InvalidOperationException: Invalid parameter 'ConfusionMatrix': parameter does not exist.\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.GetOutputVariableName(String paramName)\r\n   at Microsoft.ML.Runtime.EntryPoints.CrossValidationMacro.CrossValidate(IHostEnvironment env, Arguments input, EntryPointNode node)}\r\n"""
329237995,298,b'It would be helpful to have a ML.NET symbol package ',"b' For debugging, it would be great to publish symbol package. '"
329127300,292,"b""Cross validation macro doesn't work with non-default label column name""","b'If the label column is not called ""Label"" there is no way to pass the correct column name to the CV macro for it to pass to the evaluator.'"
328753546,290,b'Installing ML.NET on target framework .NET Framework=4.7.2 (Latest) Fails via Nuget',"b'### System information\r\n\r\n- **OS Windows 7**:\r\n- **.NET 4.7.2 (Latest)**: \r\n- **Visual Studio 2015 (x64)**: \r\n\r\n### Issue\r\n\r\n- **What did you do:**\r\n\r\n Attempting to install Microsoft.ML package via Nuget on project that has .NET targetframework = 4.7.2 (latest)\r\n\r\n- **What happened?: \'**\r\n\r\npackage install failed with the following message \r\n\r\nCould not install package \'Microsoft.ML 0.1.0\'. You are trying to install this package into a project that targets \'.NETFramework,Version=v4.7.2\', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\r\n\r\n\r\n- **What did you expect?:**\r\nThe documentation indicates this can be installed on netcore **or .NET Framework.** Am I doing something wrong? To Verify I manually downloaded the Microsoft.ML package from nuget and in ""Microsoft.ML.nuspec"" under target frameworks only netcore 2.0 is listed for v0.1.0 of ML.NET\r\n\r\n'"
328677227,288,b'Splitting datasets to train and test sets?',"b""Is there a way to do this with the current release? \r\n\r\nI noticed there's a [`TrainTestSplitter`](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.traintestdatasetsplitter?view=ml-dotnet), but there doesn't seem to be any documentation on how to use it and have been unsuccessful when I was messing with it. \r\n\r\nThanks!"""
328606575,285,b'LearningPipeline.Execute must have a Data step as the last step',"b'### System information\r\n\r\n- **OS version/distro**: windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.Net 7.1\r\n\r\n### Issue\r\n\r\nI am getting this error: LearningPipeline.Execute must have a Data step as the last step\r\nWhen trying to create my pipeline following along the ""Tutorial: Use ML.NET to predict New York Taxi Fares (Regression)"" tutorial.\r\n\r\n### Source code / logs\r\nHere is my class and main program code:\r\n\r\nTermDate.cs\r\n    public class TerminationDate\r\n    {\r\n        [Column(ordinal: ""0"")]\r\n        public float age;\r\n        [Column(ordinal: ""1"")]\r\n        public float gender;\r\n        [Column(ordinal: ""2"")]\r\n        public float married;\r\n        [Column(ordinal: ""3"")]\r\n        public float salary;\r\n        [Column(ordinal: ""4"")]\r\n        public float TermYear;\r\n    }\r\n\r\n    public class TermDatePrediction\r\n    {\r\n        [Column(""Score"")]\r\n        public float TermYear;\r\n    }\r\n\r\npart of Program.cs\r\nclass Program\r\n    {\r\n        const string _datapath = @""......\\Data\\Book1.csv"";\r\n        const string _testdatapath = @""......\\Data\\Book2.csv"";\r\n        const string _modelpath = @""......\\Models\\Model.zip"";\r\n        static async Task Main(string[] args)\r\n        {\r\n            PredictionModel<TerminationDate, TermDatePrediction> modelTerm = await Train();\r\n            Evaluate(modelTerm);\r\n            var predictionTerm = modelTerm.Predict(TestTerminations.Term1);\r\n            Console.WriteLine(""Predicted Year: {0}"", predictionTerm.TermYear);\r\n            Console.ReadLine();\r\n        }\r\n\r\n        public static async Task<PredictionModel<TerminationDate, TermDatePrediction>> Train()\r\n        {\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                new TextLoader<TerminationDate>(_datapath, useHeader: true, separator: "",""),\r\n                new ColumnCopier((""TermYear"",""Label"")),\r\n                new ColumnConcatenator(""Features"", ""age"", ""gender"", ""married"", ""salary""),\r\n                new FastTreeRegressor()\r\n            };\r\n            PredictionModel<TerminationDate, TermDatePrediction> modelTerm = pipeline.Train<TerminationDate, TermDatePrediction>();\r\n            await modelTerm.WriteAsync(_modelpath);\r\n            return modelTerm;\r\n        }\r\n\r\n        private static void Evaluate(PredictionModel<TerminationDate, TermDatePrediction> model)\r\n        {\r\n            var testData = new TextLoader<TerminationDate>(_testdatapath, useHeader: true, separator: "","");\r\n            var evaluator = new RegressionEvaluator();\r\n            RegressionMetrics metrics = evaluator.Evaluate(model, testData);\r\n            Console.WriteLine(""RMS="" + metrics.Rms);\r\n            Console.WriteLine(""R^2="" + metrics.RSquared);\r\n        }\r\n    }'"
328439084,283,b'When will 0.2.0 be released?',"b""I'm champing at the bit to open packaging."""
328396418,282,b'Concatenate 2 columns as a label',"b'I\'ve been wondering if it was possible to concatenate 2 columns of the datatype string into the label column.\r\n\r\nWhat I tried was:\r\n`\r\npipeline.Add(new ColumnConcatenator(""Label"", ""string1"", ""string2""));`\r\n\r\nBut that just spits out a V2(text, 2). And a Label must be of type R4-R8.\r\n\r\nThe reason I need this is because I only have 2 input variables (day and time) and I want to use regression to determine which is the best. I also stumbled upon [LabelToFloat](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.labeltofloatconverter?view=ml-dotnet) which I thought would convert this to a suitable type, but it didnt.\r\n\r\nAnyone know how to solve this? Thanks!'"
328387291,281,b'Trainer Entrypoints should allow validation set/preinitialization of model states for learners that support them',"b'The underlying trainer implementations can implement `IIncrementalTrainer` (for preinitializing models, or online training) or `IValidatingTrainer` (for models that have validation sets). As far as I see, however, no trainer actually puts optional inputs for a validation set or an incremental training in their entry-point inputs.\r\n\r\nFor example: we have this learner here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fb06f38d23e5b1b40407c97f7a487efa28c8f869/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs#L1451-L1453\r\n\r\nYet, the input uses the same general type of input used by practically all the typical trainers, without any sort of initial predictor.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fb06f38d23e5b1b40407c97f7a487efa28c8f869/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs#L1756-L1757\r\n\r\nThis results in the unfortunate situation that while the underlying runtime code does implement code to enable some form of online learning, the new public API has does not actually expose that to users. See e.g., #257 for a request for this.'"
328333904,279,b'SupportedMetric.ByName() method no longer functions',"b'PipelineInference/AutoInference.cs/SupportedMetric.ByName() method no longer works as expected, since names of fields in SupportedMetric no longer match their values. Need to change method to work with latest commits fixing the names of the metric values, comparing the values and not the field names themselves.'"
328107640,274,b'ColumnCopier API is confusing',"b'`ColumnCopier` has a constructor that takes a sequence of strings and another constructor that takes a sequence of pairs of strings.\r\n\r\nThis means that both of the following lines <s>are valid, with different meanings</s> compile:\r\n\r\n```c#\r\nnew ColumnCopier(""foo"", ""bar"")\r\nnew ColumnCopier((""foo"", ""bar""))\r\n```\r\n\r\nIt seems this API is confusing to people who are learning about ML.NET, as evidenced by these two issues on the docs repo: https://github.com/dotnet/docs/issues/5628, https://github.com/dotnet/docs/issues/5671. There is also https://github.com/dotnet/machinelearning/issues/189 about the same issue.\r\n\r\nCould the API be changed somehow to make it clearer?\r\n\r\nOne option would be to remove both constructors and make `AddColumn` fluent. E.g. the two examples above would change to:\r\n\r\n```c#\r\nnew ColumnCopier().AddColumn(""foo"").AddColumn(""bar"")\r\nnew ColumnCopier().AddColumn(""foo"", ""bar"")\r\n```\r\n\r\nThis makes the API more verbose, but maybe it would be worth it to make it clearer?\r\n\r\nI\'m also assuming that API breaking changes are acceptable at this point. If they\'re not, then there\'s probably nothing that can be done.'"
327939555,272,b'Some metric names in PipelineSweeperSupportedMetrics incorrect',"b'PipelineSweeperSupportedMetrics in InputBuilder.cs contains some metric names, such as ""L1"" and ""L2"", which are incorrect, and should be named as ""L1(avg)"" and ""L2(avg)"", etc. This will require changing these names in InputBuilder.cs to the correct names (which show up in the schema of the output from the train test macro). There are several of them, which should map back to what is used in the evaluators.'"
327833810,267,b'Do a column validation during pipeline construction',"b'In code below supply a wrong column (bolded below)\r\nCurrently wrong column discovered during Train command\r\nIdeally pipeline.Add() should return an error saying that column doesn\'t exist.\r\n\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader<HousePriceData>(dataPath, header: true, sep: "",""));\r\n            pipeline.Add(new ColumnConcatenator(outputColumn: ""NumericalFeatures"",\r\n                ""**SqftLiving1**"", ""SqftLot"", ""SqftAbove"", ""SqftBasement"", ""Lat"", ""Long"", ""SqftLiving15"", ""SqftLot15""));'"
327632522,265,b'Remove PMF and Lotus references',b''
327460635,262,b'PipelineInference\\RocketEngine bug fix for taking top k items.',"b'There is a bug in the RocketEngine GetTopLearners() method which potentially allows for duplicated pipelines to show up in the results. Bug found and diagnosed by @yaeldekel. Fix should be easy.\r\n\r\nMore detail: The logic in GetTopLearners() looped through two arrays, and compared the items in the second array to the items in the first, replacing them if some criterion was met (had higher weights). The way it was written could allow for a learner to replace more than one item in the first list, leading to two or more copies of the learner in our Top K array (which is a bug).'"
327457235,261,b'No Arguments in Entry Points',"b'The entry points for certain components are incorrectly designed. Normally components for entry-points are instantiated and their parameters are set on the object directly. For some reason, a handful of components slipped through, by having a separate ""arguments"" object be set, rather than have the arguments on the object directly.\r\n\r\nThe most conspicuous example of this flaw is the text loader.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/9f3076df0d7a7f3ebccc53e0602fa30b90a897fc/src/Microsoft.ML/CSharpApi.cs#L1481\r\n\r\nAs we see in its usage here, we have the peculiar setup that we instantiate this, only to turn around and set a completely *different* object for its settings, which is completely wrong. Those parameters ought to be on the object itself.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/11d5ba79d8e83a79f7e8f9cfd2515cabd63878dc/test/Microsoft.ML.TestFramework/ModelHelper.cs#L61-L65\r\n\r\nThis extends beyond text loader. As near as I can tell, all classes in `CSharpApi.cs` with the suffix ""argument"" in its name is an example of this anti-pattern.'"
327240369,259,b'CountVectorizer Alternative?',"b""### System information\r\n\r\nProduct Information:\r\n Version:            2.1.200\r\n Commit SHA-1 hash:  2edba8d7f1\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.13\r\n OS Platform: Darwin\r\n RID:         osx.10.13-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/2.1.200/\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.7\r\n  Build    : 2d61d0b043915bc948ebf98836fefe9ba942be11\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to create a model that based on tags (such as sunny, windy, outdoor, ...) predicts the number of comments. This format looks like:\r\n\r\n```csv\r\nlikes;tags;\r\n123;tag1,tag2,tag3;\r\n12;tag1;\r\n654;tag2;tag4\r\n```\r\nI know scikit has this through the `CountVectorizerModel` but I'm looking for a ML.NET alternative. Is anyone aware of this?\r\n\r\n- **What happened?**\r\nI couldn't find an alternative\r\n\r\n- **What did you expect?**\r\nBeing able to use a `CountVectorizerModel`\r\n\r\n### Source code / logs\r\n\r\nSee above for more information \r\n"""
327212274,258,b'Make sure error messages refer to https://aka.ms/MLNetIssue',"b'Solution: look for tlcsupp in the code, replace by https://aka.ms/MLNetIssue.\r\n'"
327156400,257,b'Is it possible update model without retraining?',"b""Hello.\r\n\r\n1, I want to update stored model after read it. I don't want to retrain whole data. How can I do this?\r\n2. Can I load data from c# collection or just string for generate model, not file or stream?"""
327129022,256,b'Training multiple random forests on common data set',"b'I am attempting to train random forests on a fixed 6GB data set of features, with `N` different labels, using `M` different random forest parameter settings.  Overwhelmingly, the time taken to do this appears to be the disk transpose operation, which occurs `N * M` times, when ideally it should only be done once (as the feature set is common to all models).\r\n\r\nTo rectify this, is there any way to either:\r\n- train multiple random forests in the same pipeline, or,\r\n- share the transposed data object between multiple training pipelines?'"
327087730,254,b'Support ColumnAttribute on properties and not just fields',"b""It looks like it's been considered:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ea07be87a5300e0e4d50563cfb14e963f3dee286/src/Microsoft.ML.Api/SchemaDefinition.cs#L318-L319\r\n\r\nI just wanted to get the issue started as it's probably the best solution to #180."""
327052208,251,b'Enable TrainTest for learning pipeline.',b''
327037213,250,b'Get prediction list',"b'I am testing about document classification.\r\nIt return only single label.\r\n\r\nI want to list of prediction with weight.\r\nIt would look like below,\r\n```\r\npublic class DocumentPrediction \r\n{\r\n  [ColumnName(""PredictedLabel"")]\r\n  public string Label {get;set;}\r\n  public float Weight {get;set;}\r\n}\r\n,\r\nPredictionModel<DocumentData , List<DocumentPrediction>>\r\n```\r\n\r\nIs that possible with StochasticDualCoordinateAscentClassifier? How can I do that? \r\nThere is no ref about this.\r\n'"
326909758,249,b'Microsoft.ML.Scenarios.ScenariosTests.PredictClusters fails intermittently.',b'https://ci2.dot.net/job/dotnet_machinelearning/job/master/job/windows_nt_debug_prtest/277/testReport/junit/(root)/(empty)/Microsoft_ML_Scenarios_ScenariosTests_PredictClusters/\r\n\r\nIn addition I have seen it failing sporadically on my local machine. '
326792307,246,"b'Question about ""Unknown"" classification'","b'Hello,\r\n\r\nWhen using a multiclass classifier, eg ``StochasticDualCoordinateAscentClassifier``, the scores are all relative to 1.\r\n\r\nWhat is the best way to detect when there are no suitable matches, rather than the classifier leaning towards one of them?\r\n\r\nthanks'"
326774721,245,b'Issue with training data',"b'https://github.com/dotnet/machinelearning/blob/master/test/data/wikipedia-detox-250-line-data.tsv\r\n\r\n""We can make this file beautiful and searchable if this error is corrected: Unclosed quoted field on line 83.""\r\n\r\nNeeds a quote on line 83.'"
326763842,244,b'Question about import strategy',"b'Hello, \r\n\r\nin many posts, chats and issues I can read that there will be many importer / data loader come. \r\nMy question now are the following : \r\n\r\n- will every loader / importer implement the same interface?\r\n- will there be a small documentation explain this interface so we other have a chance to bring more importer to ML.NET?\r\n- can the importer / data loader be used outside the pipe objects? so maybe in ACCORD.NET or other libraries? \r\n\r\nI really hope to get a better understanding for the import process. \r\nIf they all implement the same interface - I will close issue https://github.com/dotnet/machinelearning/issues/138. At this time I did not see the interfaces like IDataView, ISaveData, ILoadData (I forgot the true names but I saw interfaces which gave me the thinking - okay thats a general interface I was looking for). \r\n\r\nthanks for your time. And I hope ML.NET will become giant and popular framework - it was the biggest suprise  to me this year after Blazor. :D '"
326728106,243,b'Some micro optimizations for performance are possible.',"b""### Some micro optimizations for performance are possible.\r\n\r\nFor.ex. in the PerLabelL1 property ( [see link](https://github.com/dotnet/machinelearning/blob/33c8364032570003bbdc0bee3c4546df35661c49/src/Microsoft.ML.Data/Evaluators/MultiOutputRegressionEvaluator.cs#L194)) we divide all array's elements onto the single _sumWeight value, in the loop. If we compute 1/_sumWeight division before a loop, we can multiply all element on computed value, that speeds up an execution time 4 times (see example below and in the attach).\r\n\r\n### Source code / logs\r\n\r\n```\r\n        private static int _sumWeights = 14;        \r\n\r\n        public static double[] OriginDivideArray(this double[] _l1Loss)\r\n        {\r\n            var res = new double[_l1Loss.Length];\r\n            if (_sumWeights == 0)\r\n                return res;\r\n            for (int i = 0; i < _l1Loss.Length; i++)\r\n                res[i] = _l1Loss[i] / _sumWeights;\r\n            return res;\r\n        }\r\n\r\n        public static double[] OptimizedDivideArray(this double[] _l1Loss)\r\n        {\r\n            var res = new double[_l1Loss.Length];\r\n            if (_sumWeights == 0)\r\n                return res;\r\n\r\n            var revSumWeights = 1 / _sumWeights; // Cache division result here\r\n\r\n            for (int i = 0; i < _l1Loss.Length; i++)\r\n                res[i] = _l1Loss[i] * revSumWeights; // Update division to mult here\r\n            return res;\r\n        }\r\n```\r\n\r\nThe question is: do we need these optimizations? On a 1000 elements array it saves us just some microseconds.\r\n\r\n![image](https://user-images.githubusercontent.com/6274989/40575161-2fa1a52e-60e8-11e8-97b0-f96e2e28f2bb.png)\r\n[PointsToImprove.txt](https://github.com/dotnet/machinelearning/files/2041529/PointsToImprove.txt)\r\n[Program.zip](https://github.com/dotnet/machinelearning/files/2041531/Program.zip)\r\n\r\n"""
326524490,242,b'FastTree: FastTreeRanking per-iteration loss metrics are empty',"b""### System information\r\n\r\n- **OS version/distro**: Various Windows 10 machines, Windows Server 2012 or 2016.\r\n- **.NET Version (eg., dotnet --info)**: 4.7, 4.6.x\r\n\r\nAlthough, not a system-related bug.\r\n\r\n### Issue\r\n\r\n- **What did you do?** Train on a dataset using `FastTreeRanking` with the `testFrequency` parameter set to something like 1. Optionally, add a validation set. FastTree will now report training metrics on the train (and validation) sets every N iterations. Do the same for `FastTreeRegression` and `FastTreeClassification`.\r\n- **What happened?** For `Regression` and `Classification`, the expected output is printed. For `Ranking`, The header for the per-iteration test and validation metrics prints, but there are no metrics.\r\n- **What did you expect?** I expected metrics to be printed for the `Ranking` case.\r\n\r\n### Source code / logs\r\n\r\nSample output:\r\n```[6] 'FastTree training' started.\r\ntrainNDCG:\r\nvalidNDCG:\r\ntrainNDCG:\r\nvalidNDCG:\r\ntrainNDCG:\r\nvalidNDCG:\r\ntrainNDCG:\r\nvalidNDCG:\r\n```\r\n"""
326442303,241,b'Dependency Error when using Ordinary Least Squares Regressor',"b'### System information\r\n\r\n```\r\nProduct Information:\r\n Version:            2.1.201\r\n Commit SHA-1 hash:  7932dc6179\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.201\\\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.7\r\n  Build    : 2d61d0b043915bc948ebf98836fefe9ba942be11\r\n```\r\n\r\n### Issue\r\n- **What did you do?**\r\nCreated a simple ML.NET Console project with the following code:\r\n    ```\r\n    var pipeline = new LearningPipeline();\r\n\r\n    var splitter = new TrainTestDatasetSplitter() { Fraction = 0.7f };\r\n\r\n    pipeline.Add(new TextLoader<SalaryData>(""SalaryData.csv"", useHeader: true, separator: "",""));\r\n    pipeline.Add(new ColumnConcatenator(""Features"", ""YearsExperience""));\r\n    pipeline.Add(new OrdinaryLeastSquaresRegressor());\r\n\r\n    pipeline.Train<SalaryData, SalaryPrediction>();\r\n    ```\r\n\r\n- **What happened?**\r\nWhen calling `Train`, I\'m getting the error `The MKL library (Microsoft.ML.MklImports.dll) or one of its dependencies is missing.` After some searching, I couldn\'t find where I can get a reference to it to include in the project.\r\n\r\n- **What did you expect?**\r\nExpected no errors, or a way to include the missing dependency.\r\n\r\nIf anything else is needed, just let me know. Thanks!\r\n'"
326238001,237,b'Natural language generation from structured data',"b'does ML.NET have a capability to extract text out of structured data ? Say for example , we have a stock data of a company over some years. I want to generate text based on a template for YoY Analysis.'"
326212865,235,b'Multi class predicted label shifted by one.',"b'```\r\npublic class Digit\r\n{\r\n    [Column(""0"")] public float Up;\r\n\r\n    [Column(""1"")] public float Middle;\r\n\r\n    [Column(""2"")] public float Bottom;\r\n\r\n    [Column(""3"")] public float UpLeft;\r\n    [Column(""4"")] public float BottomLeft;\r\n    [Column(""5"")] public float TopRight;\r\n    [Column(""6"")] public float BottomRight;\r\n\r\n    [Column(""7"")] [ColumnName(""Label"")] public float Label;\r\n}\r\n\r\npublic class DigitPrediction\r\n{\r\n    [ColumnName(""PredictedLabel"")]\r\n    public uint ExpectedDigit;\r\n\r\n    [ColumnName(""Score"")]\r\n    public float[] Score;\r\n}\r\n\r\n\r\nvar pipeline = new LearningPipeline();\r\nvar data = new Digit[]\r\n{\r\n    new Digit { Up = 1, Middle = 0, Bottom = 1, UpLeft = 1, BottomLeft = 1, TopRight = 1, BottomRight = 1, Label = 0 },\r\n    new Digit { Up = 0, Middle = 0, Bottom = 0, UpLeft = 0, BottomLeft = 0, TopRight = 1, BottomRight = 1, Label = 1 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 0, BottomLeft = 1, TopRight = 1, BottomRight = 0, Label = 2 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 0, BottomLeft = 0, TopRight = 1, BottomRight = 1, Label = 3 },\r\n    new Digit { Up = 0, Middle = 1, Bottom = 0, UpLeft = 1, BottomLeft = 1, TopRight = 1, BottomRight = 1, Label = 4 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 1, BottomLeft = 1, TopRight = 0, BottomRight = 1, Label = 5 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 1, BottomLeft = 1, TopRight = 0, BottomRight = 1, Label = 6 },\r\n    new Digit { Up = 1, Middle = 0, Bottom = 0, UpLeft = 0, BottomLeft = 0, TopRight = 1, BottomRight = 1, Label = 7 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 1, BottomLeft = 1, TopRight = 1, BottomRight = 1, Label = 8 },\r\n    new Digit { Up = 1, Middle = 1, Bottom = 1, UpLeft = 1, BottomLeft = 0, TopRight = 1, BottomRight = 1, Label = 9 }\r\n\r\n};\r\npipeline.Add(CollectionDataSource.Create(data));\r\npipeline.Add(new ColumnConcatenator(""Features"", ""Up"", ""Middle"", ""Bottom"", ""UpLeft"", ""BottomLeft"", ""TopRight"", ""BottomRight""));\r\npipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\nvar model = pipeline.Train<Digit, DigitPrediction>();\r\nvar prediction = model.Predict(new Digit\r\n{\r\n    Up = 1,\r\n    Middle = 1,\r\n    Bottom = 1,\r\n    UpLeft = 1,\r\n    BottomLeft = 1,\r\n    TopRight = 1,\r\n    BottomRight = 1});\r\n   ```\r\n\r\nI have this wonderful test, but for ExpectedDigit is shifted by 1. I.e if it predict digit 9, it put 10 into expectedDigit'"
326183367,234,b'Trying to add and run OrdinaryLeastSquaresRegressor throwing not supported error and missing Mkl libary.',b'### System information\r\n\r\n- Windows 10 Pro\r\n- dotnet core 2.0\r\n\r\n### Issue\r\n\r\n- Tried to run taxi fare prediction example using ordinary least squares instead of fast tree\r\n- Library error missing Mkl libary.\r\n- Model created.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n![image](https://user-images.githubusercontent.com/17802262/40496707-0944c482-5f40-11e8-935a-e1f45a40474a.png)\r\n\r\n![image](https://user-images.githubusercontent.com/17802262/40496735-18ebc282-5f40-11e8-853d-6ffa89ea0a26.png)\r\n\r\n\r\n'
325998689,226,b'How to predict integer values (seven segments display output) using ML.NET?',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version**: .NET 4.7.1\r\n\r\n### Question\r\n\r\nI\'m looking at a the cs file here: https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows and everything works well.\r\n\r\nNow I\'d like to improve the example: I\'d like to predict a number-only data set and not a number-string dataset, for example predict the ouput of a seven segments display.\r\n\r\nHere is my super easy dataset, the last column is the int number that I want to predict:\r\n\r\n    1,0,1,1,1,1,1,0\r\n    0,0,0,0,0,1,1,1\r\n    1,1,1,0,1,1,0,2\r\n    1,1,1,0,0,1,1,3\r\n    0,1,0,1,0,1,1,4\r\n    1,1,1,1,0,0,1,5\r\n    1,1,1,1,1,0,1,6\r\n    1,0,0,0,0,1,1,7\r\n    1,1,1,1,1,1,1,8\r\n    1,1,1,1,0,1,1,9\r\n\r\nAnd here is my test code:\r\n\r\n    public class Digit\r\n    {\r\n        [Column(""0"")] public float Up;\r\n    \r\n        [Column(""1"")] public float Middle;\r\n    \r\n        [Column(""2"")] public float Bottom;\r\n    \r\n        [Column(""3"")] public float UpLeft;\r\n        [Column(""4"")] public float BottomLeft;\r\n        [Column(""5"")] public float TopRight;\r\n        [Column(""6"")] public float BottomRight;\r\n    \r\n        [Column(""7"")] [ColumnName(""Label"")] public float Label;\r\n    }\r\n\r\n    public class DigitPrediction\r\n    {\r\n        [[ColumnName(""Score"")] public float[] Score;\r\n    }\r\n\r\n    public PredictDigit()\r\n    {\r\n        var pipeline = new LearningPipeline();\r\n        var dataPath = Path.Combine(""Segmenti"", ""segments.txt"");\r\n        pipeline.Add(new TextLoader<Digit>(dataPath, false, "",""));\r\n        pipeline.Add(new ColumnConcatenator(""Label"", ""DigitValue""));\r\n        pipeline.Add(new ColumnConcatenator(""Features"", ""Up"", ""Middle"", ""Bottom"", ""UpLeft"", ""BottomLeft"", ""TopRight"", ""BottomRight""));\r\n        pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n        var model = pipeline.Train<Digit, DigitPrediction>();\r\n        var prediction = model.Predict(new Digit\r\n        {\r\n            Up = 1,\r\n            Middle = 1,\r\n            Bottom = 1,\r\n            UpLeft = 1,\r\n            BottomLeft = 1,\r\n            TopRight = 1,\r\n            BottomRight = 1,\r\n        });\r\n    \r\n        Console.WriteLine($""Predicted digit is: {prediction.Score}"");\r\n        Console.ReadLine();\r\n    }\r\n\r\nNow the system ""works"" and I got as `prediction.Score` a `Single[]` value where the index associated with the higher value is the predicted value. How to obtain exactly the value?\r\nIs it the right approach?\r\n\r\n\r\n'"
325979906,225,b'K-means entry-point definition omitted weight column',"b'The k-means arg attributes, from which the entry-points are derived, do not define a weight column argument, not in \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ae1ecefce576baed2419bd61f5782489d94d1821/src/Microsoft.ML.KMeansClustering/KMeansPlusPlusTrainer.cs#L47\r\n\r\nThis despite the trainer itself supporting weighted training:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ae1ecefce576baed2419bd61f5782489d94d1821/src/Microsoft.ML.KMeansClustering/KMeansPlusPlusTrainer.cs#L325\r\n\r\nSo we can use weighted training from the command line, but not via entry-points, and so not via the ML.NET API, which is an unfortunate and I believe unintended functionality gap.\r\n\r\nOne possible remediation is to merely duplicate what @yaeldekel did in #221 , except for this class. Another possibly better solution is to introduce another convenience abstract class for weighted but unsupervised algorithms, to avoid that duplication, then change both to use that.'"
325920628,223,b'Need more details',"b'@abidur commented on [Wed May 23 2018](https://github.com/dotnet/docs/issues/5574)\n\nIt would be nice to have more details on this beyond, ""Number of weak hypotheses in the ensemble""\n\n---\n#### Document Details\n\n\xe2\x9a\xa0 *Do not edit this section. It is required for docs.microsoft.com \xe2\x9e\x9f GitHub issue linking.*\n\n* ID: 12f802b4-7e85-f280-316a-8c0f026f7276\n* Version Independent ID: a6ae94b0-5d3e-0d89-1c2b-802b55f79a1b\n* Content: [FastTreeBinaryClassifier.NumTrees Property (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.fasttreebinaryclassifier.numtrees?view=ml-dotnet#Microsoft_ML_Trainers_FastTreeBinaryClassifier_NumTrees)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/FastTreeBinaryClassifier.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/FastTreeBinaryClassifier.xml)\n* Service: **unspecified**\n* Product: **unspecified**\n* GitHub Login: @dotnet-bot\n\n'"
325878723,220,b'PCA anomaly detection entry point requires a label column',"b'It is an unsupervised learner, so label column should not be required.'"
325873195,218,"b""Baseline comparisons with tolerance should not exit when values don't match""","b'Instead of calling Assert.InRange(), in MatchNumberWithTolerance(), we should call Fail() with a detailed error message saying which file and which line the error occurred in, and continue comparing the rest of the files in the unit test.'"
325856850,217,"b""Inconsistency for Num threads calculation if they don't specified""","b""We have few places in code with code like:\r\n```\r\n_threads = Math.Max(1, args.Threads ?? (Environment.ProcessorCount / 2));\r\n```\r\nin some places it's ```Math.Max(2, Environment.ProcessorCount - 1)```\r\n\r\nin others it's`Args.NumThreads ?? Environment.ProcessorCount;`\r\n\r\nwhich is a bit strange. It's either half of cores, all cores, or we left one core to be free.\r\nKMeans, SdcaRegression, LinearClassifier , and BinaryLoader use half of available cores which leads to 50% CPU utilization. \r\n@TomFinley, @GalOshri , @glebuk  """
325836389,216,b'Trained model does not contain information about Loader...',"b'This issue is a blocker for issue #5 \r\n\r\nWhen model is trained in ML.Net using TextLoader (or any other loader in general), the loader information is not saved in the model. This is a blocker to issue #5 where evaluator needs to know how to load test file based on the loader information in the training pipeline.\r\n\r\nPlease look at https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/EntryPoints/TransformModel.cs'"
325812158,215,"b'The ProposeSweeps method, in sweepers should return uniqie entries'","b""public virtual ParameterSet[] ProposeSweeps(int maxSweeps, IEnumerable<IRunResult> previousRuns) in ISweeper implementations should not return duplicate ParameterSet entries in the array it returns. \r\n\r\nDuplicate entries are ParameterSet elements that have the same IparameterValue Name and ValueText field values. \r\n\r\nSince the ParameterSet class also calculates the hash, for each entry in the ParameterSet[], it wouldn't be hard to disambiguate. \r\n\r\nI can't think of a case where consuming the output of this method would not follow up by cleaning up duplicates. It should be built in the system. \r\n"""
325802319,214,"b'There are two transforms with the Friendly Name ""Term Transform"" '","b'In the list of entry points there are two identical transforms, one with the name field: ""Transforms.TextToKeyConverter"" and the other with the name field: ""Transforms.Dictionarizer"". \r\nTheir Friendly Name filed is the same: ""Term Transform"". \r\n\r\nThis will be confusing for systems interfacing with ml.net through the entry points; ml.net should not present the same entry point choice more than once. '"
325561667,211,b'Error executing the quick start tutorial in documentation website on Windows',"b'### System information\r\n\r\n- **OS version/distro**:\r\n\r\nWindows Server 2012 R2 DataCenter Build 9600\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n.NET Commandline Utility (2.1.4)\r\n\r\nProduct Information:\r\n Version:            2.1.4\r\n Commit SHA-1 hash:  5e8add2190\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  6.3.9600\r\n OS Platform: Windows\r\n RID:         win81-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.4\\\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.5\r\n  Build    : 17373eb129b3b05aa18ece963f8795d65ef8ea54\r\n\r\n\r\n**csproj content**\r\n```xml\r\n<Project Sdk=""Microsoft.NET.Sdk"">\r\n\r\n  <PropertyGroup>\r\n    <OutputType>Exe</OutputType>\r\n    <TargetFramework>netcoreapp2.0</TargetFramework>\r\n    <RuntimeIdentifier>win-x64</RuntimeIdentifier>\r\n  </PropertyGroup>\r\n\r\n  <ItemGroup>\r\n    <PackageReference Include=""Microsoft.ML"" Version=""0.1.0"" />\r\n  </ItemGroup>\r\n  <ItemGroup>\r\n      <None Include=""iris-data.txt"">\r\n        <CopyToOutputDirectory>Always</CopyToOutputDirectory>\r\n      </None>\r\n    </ItemGroup>\r\n</Project>\r\n```\r\n\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI followed instructions on [this page](https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows) on the doc website trying to run the tutorial. \r\n\r\n- **What happened?**\r\nAn exception was thrown when I executed `dotnet run` after all code and materials were prepared.\r\nI also tried the tutorial on macOS, it worked well.\r\n\r\n- **What did you expect?**\r\nNormal console output should be printed and program runs correctly.\r\n\r\n### Exception stack trace\r\nWhen an exception was thrown, the program tried to get a resource string with a key, and failed. I extracted the resource key using windbg, and it was `BlockingCollection_CantTakeWhenDone`.\r\n\r\nHere are raw stack trace:\r\n```\r\nAssert Failure\r\nExpression: [Recursive resource lookup bug]\r\nDescription: Infinite recursion during resource lookup within System.Private.CoreLib.  This may be a bug in System.Private.CoreLib, or potentially in certain extensibility points such as assembly resolve events or CultureInfo names.  Resource name: ArgumentNull_Generic\r\nStack Trace:\r\n   at System.SR.InternalGetResourceString(String key)\r\n   at System.SR.GetResourceString(String resourceKey, String defaultString)\r\n   at System.ArgumentNullException..ctor(String paramName)\r\n   at System.Runtime.Loader.AssemblyLoadContext.GetLoadContext(Assembly assembly)\r\n   at System.Reflection.Assembly.LoadFromResolveHandler(Object sender, ResolveEventArgs args)\r\n   at System.AppDomain.OnAssemblyResolveEvent(RuntimeAssembly assembly, String assemblyFullName)\r\n   at System.Reflection.RuntimeAssembly._nLoad(AssemblyName fileName, String codeBase, Evidence assemblySecurity, RuntimeAssembly locationHint, StackCrawlMark& stackMark, IntPtr pPrivHostBinder, Boolean throwOnFileNotFound, Boolean forIntrospection, Boolean suppressSecurityChecks, IntPtr ptrLoadContextBinder)\r\n   at System.Reflection.RuntimeAssembly.InternalGetSatelliteAssembly(String name, CultureInfo culture, Version version, Boolean throwOnFileNotFound, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GetSatelliteAssembly(CultureInfo lookForCulture, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GrovelForResourceSet(CultureInfo culture, Dictionary`2 localResourceSets, Boolean tryParents, Boolean createIfNotExists, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo requestedCulture, Boolean createIfNotExists, Boolean tryParents, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo culture, Boolean createIfNotExists, Boolean tryParents)\r\n   at System.Resources.ResourceManager.GetString(String name, CultureInfo culture)\r\n   at System.SR.InternalGetResourceString(String key)\r\n   at System.SR.GetResourceString(String resourceKey, String defaultString)\r\n   at System.ArgumentNullException..ctor(String paramName)\r\n   at System.Runtime.Loader.AssemblyLoadContext.GetLoadContext(Assembly assembly)\r\n   at System.Reflection.Assembly.LoadFromResolveHandler(Object sender, ResolveEventArgs args)\r\n   at System.AppDomain.OnAssemblyResolveEvent(RuntimeAssembly assembly, String assemblyFullName)\r\n   at System.Reflection.RuntimeAssembly._nLoad(AssemblyName fileName, String codeBase, Evidence assemblySecurity, RuntimeAssembly locationHint, StackCrawlMark& stackMark, IntPtr pPrivHostBinder, Boolean throwOnFileNotFound, Boolean forIntrospection, Boolean suppressSecurityChecks, IntPtr ptrLoadContextBinder)\r\n   at System.Reflection.RuntimeAssembly.InternalGetSatelliteAssembly(String name, CultureInfo culture, Version version, Boolean throwOnFileNotFound, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GetSatelliteAssembly(CultureInfo lookForCulture, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GrovelForResourceSet(CultureInfo culture, Dictionary`2 localResourceSets, Boolean tryParents, Boolean createIfNotExists, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo requestedCulture, Boolean createIfNotExists, Boolean tryParents, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo culture, Boolean createIfNotExists, Boolean tryParents)\r\n   at System.Resources.ResourceManager.GetString(String name, CultureInfo culture)\r\n   at System.SR.InternalGetResourceString(String key)\r\n   at System.SR.GetResourceString(String resourceKey, String defaultString)\r\n   at System.Runtime.Loader.AssemblyLoadContext.ResolveUsingEvent(AssemblyName assemblyName)\r\n   at System.Runtime.Loader.AssemblyLoadContext.ResolveUsingResolvingEvent(IntPtr gchManagedAssemblyLoadContext, AssemblyName assemblyName)\r\n   at System.Reflection.RuntimeAssembly._nLoad(AssemblyName fileName, String codeBase, Evidence assemblySecurity, RuntimeAssembly locationHint, StackCrawlMark& stackMark, IntPtr pPrivHostBinder, Boolean throwOnFileNotFound, Boolean forIntrospection, Boolean suppressSecurityChecks, IntPtr ptrLoadContextBinder)\r\n   at System.Reflection.RuntimeAssembly.InternalGetSatelliteAssembly(String name, CultureInfo culture, Version version, Boolean throwOnFileNotFound, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GetSatelliteAssembly(CultureInfo lookForCulture, StackCrawlMark& stackMark)\r\n   at System.Resources.ManifestBasedResourceGroveler.GrovelForResourceSet(CultureInfo culture, Dictionary`2 localResourceSets, Boolean tryParents, Boolean createIfNotExists, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo requestedCulture, Boolean createIfNotExists, Boolean tryParents, StackCrawlMark& stackMark)\r\n   at System.Resources.ResourceManager.InternalGetResourceSet(CultureInfo culture, Boolean createIfNotExists, Boolean tryParents)\r\n   at System.Resources.ResourceManager.GetString(String name, CultureInfo culture)\r\n   at System.SR.GetResourceString(String resourceKey, String defaultString)\r\n   at System.Collections.Concurrent.BlockingCollection`1.Take()\r\n   at Microsoft.ML.Runtime.Data.TextLoader.Cursor.LineReader.GetBatch()\r\n   at Microsoft.ML.Runtime.Data.TextLoader.Cursor.ParallelState.Parse(Int32 tid)\r\n   at Microsoft.ML.Runtime.Data.TextLoader.Cursor.ParallelState.ThreadProc(Object obj)\r\n   at System.Threading.Thread.ThreadMain_ParameterizedThreadStart(Object parameter)\r\n   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n```'"
325537913,210,b'Feature importance for random forests',"b'When training a random forest, the scikit-learn package returns the feature importances (see http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), where the feature importance metric is the mean decrease impurity (as described here http://blog.datadive.net/selecting-good-features-part-iii-random-forests/).  Can `ML.Net` also provide this information?'"
325530889,209,b'Cross validation macro should return evaluation metrics as one data view',b'As opposed to an array of data views which it currently returns.'
325514938,208,b'ComponentCatalog design issues',"b'https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs\r\n\r\n-\tEnumerates all types in all loaded assemblies. This pattern is known to have poor performance characteristics that lead to long startup time.\r\n-\tEnumerates assemblies in application directory. This is not compatible with .NET Core app model. The app assemblies are not guaranteed to be in the application directory in .NET Core (e.g. they can be in one of the shared frameworks or in the assembly cache), or they may not exist at all (single file .exes planned for .NET Core, or .NET Native used for UWP apps).\r\n-\tA long list of hardcoded names to skip while enumerating: https://github.com/dotnet/machinelearning/blob/c023727b76970ab913ec1ce38276508835c17bcf/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L306 \r\n\r\nDoes ML.NET really need its own dependency injection framework? Would it be worth looking at decoupling the dependency injection from the ML.Core, and ideally using one of the existing dependency injection frameworks instead of inventing yet another one?'"
325432031,206,b'Taxi fare dataset is almost 50MB',b'These two files is almost 50mb altogether\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/data/taxi-fare-test.csv\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/data/taxi-fare-train.csv\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/170 allows to download files from external sources. Can we move these files to separate repository and clean history? '
325417980,205,b'K-means clustering cannot currently be used in experiments',"b'[K-means clustering](https://github.com/dotnet/machinelearning/tree/86f5ee663611f6c97ddb87be1150601018d74b4b/src/Microsoft.ML.KMeansClustering) is already available as a learner in ML.NET, but it is not exposed in the APIs and cannot be used in `LearningPipeline`. \r\n\r\nThe entry point needs to be added to the C# APIs (along with other necessary components like the clustering evaluator).'"
325401605,204,b'CSharpApi.cs is autogenerated file which I have no idea how to generate',"b""We used to have instruction inside https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML/CSharpApi.cs how to regenerate it in case of changes and new entrypoints. Now it's unclear, at least for me."""
325390597,203,b'ML.NET repo does not have a place to showcase community examples',b'- I expect the repo to have a .md file such as GALLERY.md to showcase the examples that the community does with ML.NET\r\n\r\n- Currently we are missing this.\r\n'
325385330,202,b'CSharpApi Generator is not properly handling nested namespaces',"b'PR https://github.com/dotnet/machinelearning/pull/61 has hard coded ""Microsoft.ML."" as the root namespace for GetSymbolFromType. This is necessary because the current CSharpApiGenerator does not properly handle nested namespaces. The code should be refactored to properly handle the root namespace.'"
325362243,201,"b'how could i add some extra fields to the ""IrisDataWithStringLabel"" as features?'","b'e.g.   class IrisDataWithStringLabel in \xe2\x80\x9c/Scenarios/IrisPlantClassificationWithStringLabelTests.cs\xe2\x80\x9d\r\nIf i want to add some other fields to the ""IrisDataWithStringLabel \xe2\x80\x9c as extra features as below after ""TextLoad"" step ,  but these extra fields won\' t be loaded from data file(maybe calculate in runtime), how could i define step and set value of that in pipline?\r\n\r\n```csharp\r\npublic class IrisData\r\n {\r\n            [Column(""0"")]\r\n            public float SepalLength;\r\n\r\n            public float SepalLength;\r\n\r\n            [Column(""1"")]\r\n            public float SepalWidth;\r\n\r\n            [Column(""2"")]\r\n            public float PetalLength;\r\n\r\n            [Column(""3"")]\r\n            public float PetalWidth;\r\n\r\n            [Column(""4"")]\r\n            [ColumnName(""Label"")]\r\n            public string Labe;\r\n\r\n            public float Color;  // -> here is my issue\r\n}\r\n```\r\n\r\nAny help please? '"
325165551,200,b'Muti-Class Classification - Follow on from Sentiment Analysis example',"b'### System information\r\n\r\n- **Windows 10**:\r\n- **.NET Version 4.6.1**: \r\n\r\n### Issue\r\n\r\nIs muti-class classification possible at this point? I noticed with the sentiment analysis example, you have a string and float column, then a prediction class that is of type bool, if you change this to type float for example, the program blows up with the following exception:\r\n\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Can\'t bind the IDataView column \'PredictedLabel\' of type \'Bool\' to field \'JobQueue\' of type \'System.Single\'.\r\n  Source=DotNetML\r\n  StackTrace:\r\n   at ML.NET.Program.Main(String[] args) in C:\\Developer\\DotNetML\\DotNetML\\Program.cs:line 57\r\n\r\n### Source code / logs\r\n\r\nMy two input classes look like this:\r\n\r\npublic class SCSMData\r\n    {\r\n        [Column(ordinal: ""0"")]\r\n        public string JobDescription;\r\n        [Column(ordinal: ""1"", name: ""Label"")]\r\n        public float JobQueue;\r\n    }\r\n\r\n    public class SCSMPrediction\r\n    {\r\n        [ColumnName(""PredictedLabel"")]\r\n        public float JobQueue;\r\n    }'"
325156549,199,b'Plans for lazy Loading?',"b'Hello ML.NET experts :D,\r\n\r\nthere is just one other point which was in my mind. In a time of cloud and big data there is always one important question : **how to access data with a good performance and low memory**?\r\n\r\nI had a lot of trouble in past in simulations because the tools of our customers loaded (mostly) all measurement data at once. It took about 5-10 Minutes for loading and 20-30 GB of memory. Just let you know - this was in car simulation area and to be honest - this was low data - todays time such cars have TB of data in just 1 hour driving. So we reinvented their tools and included lazy loading. \r\n\r\n**We archived this lazy loading by included some tricks into import level**. Every data source got one general class called ""dataSrc"" and was injected with an Dataprovider. When user called the property ""DataSets"" (property in C# meaning) the Getter invoke provider and the provider looked for all dataSet IDs (column names or general spoken - the ID of an measurement array) in the source. The DataSets property returned an Array of dataset objects. Each Set had an Array property (which was still not invoken) and a dictionary with Attributes (key - value). So we could search for meta informations (by the Dictionary) without loading the array (our true measurement data). Just when the User really was sure - okay I want the data from DataSet XYZ - then the Provider was invoken to look for my data. \r\n\r\nWith this strategy we was able to reduce the time and memory a lot. The users could search for attributes and take datasets they need - moreover - It was even possible to use Linq in the same way for every possible datasource. \r\n\r\nOne thing more to consider : \r\n- If the arrays get too big maybe we could think about loading parts of the total measurement array (like Span<T>? . \r\n \r\n'"
325026377,195,b'List Loader',"b'I was looking through the ml.net api for a generalized data loader, and I could not find one. So here is my proposal:\r\n\r\nTake the following example for the TextLoader:\r\n```\r\nvar dataPath = ""intents.txt"";\r\npipeline.Add(new TextLoader<IntentData>(dataPath, separator: ""tab""));\r\n```\r\n\r\nI would like to have something like this:\r\n```\r\nvar intents = new List<IntentData();\r\nintents.Add(new IntentData());\r\npipeline.Add(new ListLoader<IntentData>(intents));\r\n```\r\nWith a generalized loader like this I would have a wider range of sources for my data.'"
324999687,194,b'Generate `DebuggerDisplayAttribute` for API',"b'`DebuggerDisplayAttribute` is a nice little thing to add to classes -- properly written, they make the debugger a bit less obnoxious to use by putting some important information about an instance front and center. At the same time, it would be nice if we could possibly avoid having to write all those ourselves, piecemeal.\r\n\r\n`CSharpApi.cs` is geneated from the code in `CSharpApiGenerator.cs`. It may be a simple matter to enhance that code to attach a `DebuggerDisplay` attribute to the generated classes. The configuration objects have their properties and documentation derived from the `ArgumentAttribute`. We needn\'t display everything: In other contexts, we have distinguished important vs. more unimportant ""advanced"" parameters by `ArgumentAttribute`\'s `SortOrder` property. We could exploit that for this purpose as well, and only include in the display formatted string those parameters with that property set and of course only those types that would display well there anyway.'"
324613452,192,b'Adding Multiple Training Files to the Pipeline?',"b'System information\r\n    OS version/distro: Windows 7 Home\r\n    .NET Version (eg., dotnet --info): ML .net V0.1.0\r\n\r\nIssue:\r\nWhat is the correct way to add multiple training files to a Learning Pipeline?\r\n\r\nIn the Taxi Fare example, just adding another textloader and/or ColumnCopier, etc seems to not be correct.\r\n\r\nExample:\r\npipeline.Add(new TextLoader<TaxiTrip>(DataPath, useHeader: true, separator: "",""));\r\npipeline.Add(new TextLoader<TaxiTrip>(DataPath2, useHeader: true, separator: "",""));\r\n'"
324590515,191,b'Project will not build because of space in build path',"b'### System information\r\n\r\n- **OS version/distro**: Windows 10 Home\r\n- **.NET Version (eg., dotnet --info)**: 2.1.200, concerning ML .net V0.1.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Try to build from source\r\n- **What happened?** When trying to build, I have a space in my user profile, for example let\'s say ""John Smith"".  So when I cloned to C:/users/John Smith/source/repo/machinelearning/ and tried to build using a command prompt (in the before directory) using command `start build.cmd -Release -TargetArchitecture:x64` \r\n\r\nAnother window opened (expected) and it said `\'C:\\Users\\John\' is not recognized as an internal or external command, operable program or batch file`\r\n\r\nMoving the folder up to C:/ it builds just fine. \r\n- **What did you expect?** To build\r\n\r\n### Source code / logs\r\n\r\nIts probably caused by %~dp0 in the build.cmd file. \r\n'"
324561785,189,"b'Confusion parameter options in Dictionarizer, ColumnCopier etc.'","b'The following transform can operate on multiple columns either by using tuple [(input, output), (input2,output2), ... , (input_n,output_n)] or string array [col1,col2....coln]\r\n\r\nThere is no error for the following option. Both work fine. However, no.1 is actually not correct. Can we simplify it? or at least flag error because ""Label"" column is not yet there in the pipeline.\r\n\r\n1. pipeline.Add(new Dictionarizer(""Area"", ""Label""));\r\n2. pipeline.Add(new Dictionarizer( (""Area"", ""Label"") ));\r\n'"
324561491,188,b'We currently have no easy way to create IDataView.',b'In few places in our API we expect IDataView.  CollectionDataSource produce ILearningPipelineLoader.'
324492772,186,b'CpuMathNative and FastTreeNative cannot be loaded on Windows 10 and French locale',"b'### System information\r\n\r\n- **Windows 10: 10.0.17134**:\r\n- **.NET Version (2.1.2)**: \r\n\r\n### Issue\r\n\r\n- **Try to train a FastTree for a binary classification.**\r\n- **It fails in Sse.cs line 1187, unable to find CpuMathNative.dll**\r\n\r\n### Source code / logs\r\n\r\nIt works if I compile the two libraries with charset=unicode (instead of multibyte right now = default for cmake).'"
324211026,184,"b'Feature type, input, and output validation should happen much earlier'","b'Validation of feature vector types, inputs, and outputs seems to happen randomly throughout the learning pipeline - sometimes after a few minutes, sometimes after an hour.  It would really be great if this happened up front so that errors could be corrected faster.  It would also be great if some of these were documented.\r\n\r\nFor example:\r\n```cs\r\npublic class InputData\r\n{\r\n    [Column(""0"")]\r\n    public double input0;\r\n\r\n    [Column(""1"")]\r\n    public double input1;\r\n\r\n    [Column(""2"", name: ""Label"")]\r\n    public double output0;\r\n}\r\n\r\npublic class OutputData\r\n{\r\n    [ColumnName(""Score"")]\r\n    public double output0;\r\n}\r\n\r\npublic class Program\r\n{\r\n    static void Main(string[] args)\r\n    {\r\n        var pipeline = new LearningPipeline();\r\n        pipeline.Add(new TextLoader<InputData>(""mydata.txt"", separator: ""comma""));\r\n        pipeline.Add(new ColumnConcatenator(""Features"", ""input0"", ""input1"");\r\n        pipeline.Add(new FastTreeRegressor());\r\n        var model = pipeline.Train<InputData, OutputData>();\r\n    }\r\n}\r\n```\r\n\r\nRunning this with a very large ""mydata.txt"" gives output of:\r\n```\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nWarning: We seem to be processing a lot of data. Consider using the FastTree diskTranspose+ (or dt+) option, for slower but more memory efficient transposition.\r\nProcessed 1112251 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 10301148 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n```\r\n\r\nAnd then about 15 minutes later, an exception occurs:\r\n```\r\nIncompatible features column type item type: \'R8\' vs \'R4\'\r\n\r\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapperBase.Bind(IHostEnvironment env, RoleMappedSchema schema)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.Bindings.Create(IHostEnvironment env, ISchemaBindableMapper bindable, ISchema input, IEnumerable`1 roles, String suffix, Boolean user)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer..ctor(IHost host, ModelLoadContext ctx, IDataView input)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.<>c__DisplayClass15_0.<Create>b__0(IChannel ch)\r\n   at Microsoft.ML.Runtime.HostExtensions.Apply[T](IHost host, String channelName, Func`2 func)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n```\r\n\r\nAfter lots of digging through code, it turns out only float types are supported - not doubles. Why didn\'t the docs say this and why wasn\'t I told almost immediately when I called Train()?'"
324135262,182,"b""CrossValidationMacro doesn't work with stratification column""","b'The CrossValidatorDatasetSplitter entry point applies a HashJoinTransform with the default number of bits (31) to the stratification column, and the RangeFilter that tries to split the data expects a key with a well known count.'"
324064633,181,b'Reinforcement learning',"b""I've looked into the available documentation and examples, but haven't been able to figure out if it is possible to use the ML.NET in its current state for (non-deep) reinforcement learning. If it is possible, I'd be thankful for any hints on how to implement a simple case. In case reinforcement learning is not possible atm, what exactly is missing and are there any plans on implementing the missing pieces?\r\n\r\nThanks!  """
323931277,180,b'F# Records not compatible with ML .NET',"b'Perhaps related to #92. Apparently ML .NET doesn\'t work with F# records! Is this perhaps to do with the fact that F# Records use a different naming convention to Classes for backing fields, and the ML .NET Library. If you use records, the library simply can\'t find the columns and complains of missing columns. If you port from records to classes with mutable properties, it doesn\'t fail with that error any longer.\r\n\r\nHowever, mutable classes are pretty much non-idiomatic in F# - no one uses them for the sorts of data-bound workloads that you\'ll see with ML.\r\n\r\nInstead of this:\r\n\r\n```fsharp\r\ntype SentimentData =\r\n    { [<Column(ordinal = ""0"")>] SentimentText : string\r\n      [<Column(ordinal = ""1"", name = ""Label"")>] Sentiment : float }\r\n\r\n[<CLIMutable>]\r\ntype SentimentPrediction =\r\n    { [<ColumnName ""PredictedLabel"">] Sentiment : bool }\r\n```\r\n\r\nYou\'ll have to use something like this monstrosity.\r\n\r\n```fsharp\r\ntype SentimentData() =\r\n    [<Column(ordinal = ""0""); DefaultValue>]\r\n    val mutable SentimentText : string\r\n    [<Column(ordinal = ""1"", name = ""Label""); DefaultValue>]\r\n    val mutable Sentiment : float32\r\n\r\ntype SentimentPrediction() =\r\n    [<ColumnName ""PredictedLabel""; DefaultValue>]\r\n    val mutable Sentiment : bool\r\n```\r\n\r\nYou can\'t even use the `member val` shorthand syntax that F# provides for mutable get / set properties since the `ColumnName` attribute doesn\'t work with them. Plus, you lose all the standard features that Records bring such as lightweight syntax, easy creation, copy-and-update, immutability and structural equality.\r\n\r\nI strongly recommend adding support for them by ensuring that whatever internal hydration logic that is currently coupled to classes supports records as well.'"
323864804,179,b'Speed of Random Forest predictions',"b""I trained a `FastForestBinaryClassifier` on a toy model with two features and zero input transformations, and found that calling the `Predict` method on the resulting model takes about 5ms for a single input on a high spec machine.  This seems quite slow, shouldn't it take less than 1ms?\r\n\r\nI notice that the `FastTreePredictionWrapper` type is able to write itself out as code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ae1ecefce576baed2419bd61f5782489d94d1821/src/Microsoft.ML.FastTree/FastTree.cs#L2942\r\n\r\nWould it be possible to write out the calibrated model as C# code, which should presumably be faster to run?  This would have the additional benefit of being able to be included as a static model which can be deployed without any `ML.Net` dependencies...\r\n"""
323781692,175,b'TreeLeafFeaturizer cannot be used with the Pipeline API.',"b'The TreeLeafFeaturizer needs to have a PredictorModel as well as an IDataView as input, but since the Pipeline automatically adds a scorer after the predictor, The TreeLeafFeaturizer step cannot access the model.\r\n'"
323765117,174,b'Language improvements',"b'I\'m sorry to say but on every line i see PipeLine.Add\r\nIt sounds actually to me like the language isnt ready.\r\nLike Basic code having line numbers, telling it to write a line number first.\r\nas in :\r\n30 Gosub 150\r\n\r\nJust imagine psudo code from here below \r\n```\r\nusing ( ML.Net  ) new net.dataSource FlightData= \r\n{ \r\n .DataSource.File.LoadCSV(@""C:\\Data\\flights.csv"", tabs);\r\n .DataColumnsNormalize(""1,2,3,4,8,9"");\r\n .DataColum[4].type = .DataType.TimeDayLightSaving.12Hours\r\n .DataColum[8].type = .DataType.TimeSpan.Between.Minutes\r\n .DataSource.MySQL.Add(dburl, tabel, user =""test,password =""trythis"", prompt = prompt.OnLoginFail);\r\n .DataSource.MySQL.removeNullEntries;\r\n .DataSource.MySQL[tabel].DataColumnsNormalize(""7,8"")\r\n .DataSource.MySQL.removeNonComplete;\r\n .DataSource.Http(http://airportlivedata/arrivals)\r\n .DataSource.HttpFilter (""Flight number"",""time"",....etc);\r\n  // .DataSource.StoreAll.File.Compressed(....\r\n\r\n //Or \r\n  Add.Using (ML.Datasources.SQL(dburl,tabel,user,pass) \r\n   { \r\n      .removeNullEntries\r\n   }\r\n } \r\n\r\nML.Network PredictFlights using FlightData\r\n{\r\n.predict =[1,4,7,8]\r\n.Regression\r\n.Layer[6].FeedBackLoop => Layer[1]\r\n.AnalyzeLayer[4].Debug.DisplayHeatMap.RGB24 =>DumpToFileAsWell\r\n}\r\n\r\nFlightData.Train\r\nFlightData.Request(input columns[]as new ML.userInput(columns[1,3,5,69,12])\r\n```\r\n\r\n[formatting added by @danmosemsft]'"
323743274,171,b'No transform pipeline fail execution',"b'`\r\npublic class Data\r\n        {\r\n            [ColumnName(""Features"")]\r\n            [VectorType(2)]\r\n            public float[] Features;\r\n\r\n            [ColumnName(""Label"")]\r\n            public float Label;\r\n        }\r\n\r\n        public class Prediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public bool PredictedLabel;\r\n        }\r\n\r\n        static void Train(IEnumerable<Data> data)\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(CollectionDataSource.Create(data));\r\n            pipeline.Add(new FastForestBinaryClassifier());\r\n            var model = pipeline.Train<Data, Prediction>();\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var data = new Data[1];\r\n            data[0] = new Data();\r\n            data[0].Features = new float[] { 0.0f, 1.0f };\r\n            data[0].Label = false;\r\n\r\n            Train(data);\r\n        }\r\n\r\nwill fail in model combainer.'"
323634766,169,b'SysRandom.NextSigned()',"b'https://github.com/dotnet/machinelearning/blob/436700aadf615e7f05a22925476cc441c63a919d/src/Microsoft.ML.Core/Utilities/Random.cs#L154\r\n\r\nShould be `return _rnd.Next(int.MinValue, int.MaxValue);`'"
323599846,168,b'Should Random.Utilities be thread safe and more random?',"b""Coming from https://github.com/dotnet/machinelearning/issues/166.\r\n\r\n1. The various random number generators are not thread safe. It might make sense to make them such. Are there cases against not making them such?\r\n2. Should the generators be seeded with cryptographic random seed to make sure they're random when no seed is given?\r\n3. The MachineLearning.Net has tendency to put many classes in one file (and have them uncommented). Would there be opposition to put the classes into separate files?\r\n4. The library has also a tendency to put functions not strictly needed for the functionality in the domain classes. Such as saving, like at https://github.com/dotnet/machinelearning/blob/436700aadf615e7f05a22925476cc441c63a919d/src/Microsoft.ML.Core/Utilities/Random.cs#L186. Would there be opposition to provide these as extension methods or in some other fashion? Since it might be one might want to serialize things differently and organizing differently would avoid baking in dependencies. A related idea: https://github.com/dotnet/machinelearning/issues/126#issuecomment-388485566.\r\n\r\nAt a glance point, there can be other issues too. Would there be opposition to refactor points 1 through 3? Possibly 4?\r\n\r\nThe source: https://github.com/dotnet/machinelearning/blob/436700aadf615e7f05a22925476cc441c63a919d/src/Microsoft.ML.Core/Utilities/Random.cs"""
323475646,167,b'Implement ICanGetSummaryAsIDataView for several learners',"b""Several learners don't have ICanGetSummaryAsIDataView  implemented.\r\nList of learners:\r\n            NaiveBayesClassifier,\r\n            KMeansPlusPlus\r\n            PcaAnomalyDetector\r\n            OrdinaryLeastSquaresRegressor\r\n"""
323459531,166,b'RandomUtils.NextFloat(this Random) can return exactly 1',b'https://github.com/dotnet/machinelearning/blob/436700aadf615e7f05a22925476cc441c63a919d/src/Microsoft.ML.Core/Utilities/Random.cs#L52\r\n\r\nIt seems `RandomUtils.NextFloat(this Random)` has a possibility of returning exactly 1.'
323408653,164,b'VectorType attribute with dynamic dimension',"b'The `VectorType` attribute can be added to an array-valued field when the length of the array is known at compile time, e.g.,\r\n```\r\n        public class Data\r\n        {\r\n            [ColumnName(""Features"")]\r\n            [VectorType(2)]\r\n            public float[] Features;\r\n\r\n            [ColumnName(""Label"")]\r\n            public bool Label;\r\n        }\r\n```\r\n\r\nHowever, what if the length of the array is only known at run time?\r\n\r\nFor example, given `IEnumerable<Data> data` where the length of the `Features` array is given by `int numFeatures`, I need to be able to pass `numFeatures` to `CollectionDataSource.Create(data)` somehow, and remove the static `2` argument to the `VectorType` attribute on the `Features` field.'"
323365650,163,b'Support time series anomaly algorithms',"b""### Issue\r\n\r\nWould love to have/add support for time series forecasting/anomaly detection. There's some pretty common scenarios such as\r\n\r\n- different types of forecasting such as HW (TES and DES)\r\n- online aspect of these algorithms (performant; so no retraining/evaluation is necessary to be integrated in a streaming fashion)\r\n- PScore/ZScore/threadhold evaluation for anomalies\r\n\r\n\r\n"""
323361042,162,b'Remove Google.Protobuf dependency from Microsoft.ML',"b""### System information\r\n\r\n- **OS version/distro**: all\r\n- **.NET Version (eg., dotnet --info)**:  all\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nInstall the base `Microsoft.ML` nuget package\r\n\r\n- **What happened?**\r\nIt also adds a reference to `Google.Protobuf`\r\n\r\n- **What did you expect?**\r\nI expected that the base `Microsoft.ML` nuget package would have minimal dependencies.  From my understanding, Google.Protobuf is only used in ML.NET for the ONNX support, which isn't needed all of the time.  We should move the ONNX support into a separate NuGet package that developers can opt into.  That way developers who aren't using this functionality won't need to pay for this dependency.\r\n\r\n### Source code / logs\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/436700aadf615e7f05a22925476cc441c63a919d/src/Microsoft.ML.UniversalModelFormat/Microsoft.ML.UniversalModelFormat.csproj#L9 is the only place that uses this dependency.  This project should be factored out of the base package, similar to what we've done with the `Microsoft.ML.Parquet` package.\r\n\r\n/cc @glebuk @TomFinley \r\n"""
323345240,161,b'Using ML.net for NLP/NLU',"b'@atotalnoob commented on [Tue May 15 2018](https://github.com/dotnet/docs/issues/5388)\n\nHey all, \r\n\r\nWhat would need to be done to make ML.net do NLP/NLU? We use a python back-end for our current chatbot platform, looking to explore ML.net, because we use .net front-end.\r\n\r\nMy understanding of what needs to be done is:\r\n\r\nLoad in a dataset with 2 columns using TextLoader. \r\n\r\nSentenceToBeScored | Intent\r\n\r\nThen use a TextFeaturizer to change intents into numeric vectors\r\n\r\nThen train and predict. \r\n\r\nIs it that simple? Or am I missing something? \r\n\r\n\r\n\n\n'"
323335902,160,b'Migration of Code Documentation',"b'There have been many questions both in issues and PRs that could have been addressed with some existing as-yet unmigrated documentation. (Not all questions, but a significant number.) People are curious, that\'s great.\r\n\r\nNote that this is not MSDN-style API documentation, but more ad hoc documents. I believe there is a shared understanding that documents like this, not MSDN-style docs but the more ad hoc docs, should be checked in next to the code. Let me know if not.\r\n\r\nThis will not be a straight copy job though and should be done with due care, for the following reasons:\r\n\r\n1. some docs refer to the prior internal name for ML.NET (though to be fair I\'ve noticed the code does too in places \xf0\x9f\x98\x9b) so that ought to be changed,\r\n2. it appeals to historical perspectives or prior states of code that are invisible to people, which is awkward. This is hard, you can\'t just *delete* that stuff, because the point of the code docs is to explain exactly why something is engineered in a certain way, and that discussion is helped enormously if you explain why a deceptively ""easier"" way of doing task X, Y, or Z was deemed unacceptable.\r\n3. it sometimes contextualizes the presence of this or that aspect of the code as being something that exists to solve an existing use-case, and not all those use-cases are open sourced.\r\n4. While much of it is already in `.md`, some older docs are in other formats and will require some attention to migrate them.\r\n\r\nWould appreciate discussion from @asthana86 , @eerhardt , @GalOshri , @glebuk , and @shauheen specifically on this topic. (To clarify all are welcome, just mentioning to make sure it gets flagged for them. \xf0\x9f\x98\x84)'"
323333624,159,b'TensorFlow Integration',"b'I thought it might be beneficial to add an issue just for the integration of TensorFlow into ML.Net to allow for discussions specific to this topic. I would also like to point out that there is an existing C# wrapper called TensorFlowSharp that might be good to look at as a point of reference for using TensorFlow in ML.Net. TensforFlowSharp repo: https://github.com/migueldeicaza/TensorFlowSharp The project is a wrapper around the TensorFlow C library, and works with C# and F#.'"
323304919,158,b'Label and Score',"b""Not sure if it's the best place for this question but how to get the labels back when getting the score? I remember from the build 2018 video that during the demo they used `PredictedLabelColumnOriginalValueConverter` to get the label back instead of the index for the `PredictedLabel` but is there a way to apply this converter to all the values in the `Score`? If yes, how so?\r\n\r\nI also remember they were using the `ClassificationMetrics.ConfusionMatrix.ClassNames` to get the labels back from the score but this isn't really doable if you load the output in an app and don't need/want to test your data.\r\n\r\nI found the file `Terms.txt` in the output zip archive and I can definitely parse it to find the labels but I'm sure there's a better way to do it."""
323124799,157,b'Training Model fails in Xamarin Workbooks',"b'### System information\r\n\r\n- **OS version/distro**: macOS High Sierra (10.13.4)\r\n- **.NET Version (eg., dotnet --info)**: 2.1.4\r\n\r\n### Issue\r\n\r\n- Tried training a model based on *FastTreeLearner*.\r\n- The pipeline all the way to the model training succeeded, but the training part failed because of a .dll which was not found.\r\n- Training with similar code in Visual Studio works just fine. I expect the Xamarin Workbooks to be compatible with this ML library.\r\n\r\n### Source code / logs\r\n\r\n#### The Xamarin Workbook\r\n\r\n```\r\n---\r\nuti: com.xamarin.workbook\r\nid: dfsdfsd-sdfsdfsd-sdfsdf-sdfsdfsdf\r\ntitle: Sample\r\nplatforms:\r\n- DotNetCore\r\npackages:\r\n- id: Microsoft.ML\r\n  version: 0.1.0\r\n---\r\n```\r\n\r\n```csharp\r\n#r ""Microsoft.ML.Api""\r\n#r ""Microsoft.ML.Core""\r\n#r ""Microsoft.ML.CpuMath""\r\n#r ""Microsoft.ML.Data""\r\n#r ""Microsoft.ML""\r\n#r ""Microsoft.ML.FastTree""\r\n#r ""Microsoft.ML.InternalStreams""\r\n#r ""Microsoft.ML.KMeansClustering""\r\n#r ""Microsoft.ML.Maml""\r\n#r ""Microsoft.ML.PCA""\r\n#r ""Microsoft.ML.PipelineInference""\r\n#r ""Microsoft.ML.ResultProcessor""\r\n#r ""Microsoft.ML.StandardLearners""\r\n#r ""Microsoft.ML.Sweeper""\r\n#r ""Microsoft.ML.Transforms""\r\n#r ""Microsoft.ML.UniversalModelFormat""\r\n```\r\n\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Models;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\nusing Microsoft.ML;\r\nusing System;\r\n```\r\n\r\n```csharp\r\nconst string DataPath = @""data.csv"";\r\nconst string ModelPath = @""model.zip"";\r\n```\r\n\r\n```csharp\r\n#pragma warning disable 0649\r\npublic class InputData\r\n{\r\n    [Column(""0"")]\r\n    public float Feature1;\r\n\r\n    [Column(""1"")]\r\n    public float Feature2;\r\n\r\n    [Column(""2"")]\r\n    public float DependentVariable;\r\n}\r\n```\r\n\r\n```csharp\r\n#pragma warning disable 0649\r\npublic class OutputPrediction\r\n{\r\n    [ColumnName(""Score"")]\r\n    public float DependentVariable;\r\n}\r\n```\r\n\r\n```csharp\r\nvar pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader<InputData>(DataPath, useHeader: true, separator: "",""));\r\npipeline.Add(new ColumnCopier((""DependentVariable"", ""Label"")));\r\npipeline.Add(new ColumnConcatenator(""Features"", ""Feature1"", ""Feature2""));\r\npipeline.Add(new FastTreeRegressor() { DiskTranspose = true });\r\n```\r\n\r\n```csharp\r\n try\r\n{\r\n    pipeline.Train<InputData, OutputPrediction>();\r\n}\r\ncatch (Exception ex)\r\n{\r\n    Console.Write(ex.ToString());\r\n}\r\n```\r\n\r\n### Error at the last step\r\n\r\n```\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise on disk\r\nProcessed 1000 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 2340 bytes\r\nStarting to train ...\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.AggregateException: One or more errors occurred. (Unable to load DLL \'FastTreeNative\': The specified module or one of its dependencies could not be found.\r\n(Exception from HRESULT: 0x8007007E)) (Unable to load DLL \'FastTreeNative\': The specified module or one of its dependencies could not be found.\r\n(Exception from HRESULT: 0x8007007E)) ---> System.DllNotFoundException: Unable to load DLL \'FastTreeNative\': The specified module or one of its dependencies could not be found.\r\n(Exception from HRESULT: 0x8007007E)\r\nat Microsoft.ML.Runtime.FastTree.Internal.DenseIntArray.C_Sumup_double(Int32 numBits, Byte* pData, Int32* pIndices, Double* pSampleOutputs, Double* pSampleOutputWeights, Double* pSumTargetsByBin, Double* pSumTargets2ByBin, Int32* pCountByBin, Int32 totalCount, Double totalSampleOutputs, Double totalSampleOutputWeights)\r\nat Microsoft.ML.Runtime.FastTree.Internal.DenseIntArray.SumupCPlusPlusDense(SumupInputData input, FeatureHistogram histogram, Byte* data, Int32 numBits)\r\nat Microsoft.ML.Runtime.FastTree.Internal.Dense4BitIntArray.Sumup(SumupInputData input, FeatureHistogram histogram)\r\nat Microsoft.ML.Runtime.FastTree.Internal.FeatureHistogram.SumupWeighted(Int32 numDocsInLeaf, Double sumTargets, Double sumWeights, Double[] outputs, Double[] weights, Int32[] docIndices)\r\nat Microsoft.ML.Runtime.FastTree.Internal.LeastSquaresRegressionTreeLearner.Sumup(SufficientStatsBase stats, Int32 featureMin, LeafSplitCandidates candidates)\r\nat Microsoft.ML.Runtime.FastTree.Internal.LeastSquaresRegressionTreeLearner.FindBestThresholdForFlockThreadWorker(Int32 flock)\r\nat System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)\r\nat System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\r\n--- End of inner exception stack trace ---\r\nat System.ThrowHelper.ThrowAggregateException(List`1 exceptions)\r\nat System.Threading.Tasks.Task.WaitAll(Task[] tasks, Int32 millisecondsTimeout, CancellationToken cancellationToken)\r\nat System.Threading.Tasks.Task.WaitAll(Task[] tasks, Int32 millisecondsTimeout)\r\nat System.Threading.Tasks.Task.WaitAll(Task[] tasks)\r\nat System.Threading.Tasks.Parallel.Invoke(ParallelOptions parallelOptions, Action[] actions)\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nat System.Threading.Tasks.Parallel.ThrowSingleCancellationExceptionOrOtherException(ICollection exceptions, CancellationToken cancelToken, Exception otherException)\r\nat System.Threading.Tasks.Parallel.Invoke(ParallelOptions parallelOptions, Action[] actions)\r\nat Microsoft.ML.Runtime.FastTree.Internal.ThreadTaskManager.ThreadTask.RunTask()\r\nat Microsoft.ML.Runtime.FastTree.Internal.LeastSquaresRegressionTreeLearner.FindBestSplitOfRoot(Double[] targets)\r\nat Microsoft.ML.Runtime.FastTree.Internal.LeastSquaresRegressionTreeLearner.FitTargets(IChannel ch, Boolean[] activeFeatures, Double[] targets)\r\nat Microsoft.ML.Runtime.FastTree.Internal.GradientDescent.TrainingIteration(IChannel ch, Boolean[] activeFeatures)\r\nat Microsoft.ML.Runtime.FastTree.FastTreeTrainerBase`2.Train(IChannel ch)\r\nat Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer.Train(IChannel ch)\r\nat Microsoft.ML.Runtime.FastTree.FastTreeTrainerBase`2.TrainCore(IChannel ch)\r\nat Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer.Train(RoleMappedData trainData)\r\n--- End of inner exception stack trace ---\r\nat System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\nat System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\nat Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, String name, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inpPredictor)\r\nat Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\nat Microsoft.ML.Runtime.FastTree.FastTree.TrainRegression(IHostEnvironment env, Arguments input)\r\n--- End of inner exception stack trace ---\r\nat System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\nat System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\nat Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\nat Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\nat Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\nat Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\nat Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n```'"
323105910,156,b'Exception using CollectionDataSource',"b'### System information\r\n\r\n- Windows 10 Pro 64 Bit\r\n- .NET framework 4.7\r\n- libraries built from master branch\r\n\r\n### Issue\r\n\r\nThe code below (a self-contained repro) throws a null reference exception on line https://github.com/dotnet/machinelearning/blob/83f9bac40939d3fe3485059710f5bd4456bcf02e/src/Microsoft.ML.Api/DataViewConstructionUtils.cs#L233 since `peek` is null when attempting to get the value of the `Label` column.\r\n\r\n```\r\n        public class Data\r\n        {\r\n            [ColumnName(""Features"")]\r\n            [VectorType(2)]\r\n            public float[] Features;\r\n\r\n            [ColumnName(""Label"")]\r\n            public bool Label;\r\n        }\r\n\r\n        public class Prediction\r\n        {\r\n            [ColumnName(""PredictedLabel"")]\r\n            public bool PredictedLabel;\r\n        }\r\n\r\n        static void Train(IEnumerable<Data> data)\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(CollectionDataSource.Create(data));\r\n            pipeline.Add(new FastForestBinaryClassifier());\r\n            var model = pipeline.Train<Data, Prediction>();\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var data = new Data[1];\r\n            data[0] = new Data();\r\n            data[0].Features = new float[] { 0.0f, 1.0f };\r\n            data[0].Label = false;\r\n\r\n            Train(data);\r\n        }\r\n```'"
323020280,153,b'Learning pipeline adds a null model to the pipeline',b''
322953124,151,b'Expose internal graph variable names as part of outputs for pipeline sweeping',b'Need to add support for passing along the internal graph variable names from the pipeline graphs output by the PipelineSweeperMacro. That way a user can make use of the resulting pipeline graph without having to regex the JSON to find the variable names (which is error prone).'
322952376,150,b'Add training metrics to PipelineSweeper framework',b'### Issue\r\n\r\nThe PipelineSweeperMacro and related framework need to have access to Training dataset metrics from completed sweeps. This will be needed as the framework expands to include other methods.\r\n'
322938521,149,b'Support for LSTM / RNN (Time Series)',b'Great project and i really love the classifiers so far! Are there any short term plans to support LSTM / RNN for time series type of predictions? Or may be i just overlooked it.'
322876143,144,"b""Microsoft.ML.Parquet doesn't have a symbols package""","b'### System information\r\n\r\n- **OS version/distro**: all\r\n- **.NET Version (eg., dotnet --info)**:  N/A\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTry to load symbols for the Microsoft.ML.Parquet package\r\n- **What happened?**\r\nThere are no symbols uploaded to the symbols server\r\n- **What did you expect?**\r\nI expected the symbols to be on the symbols server, just like Microsoft.ML.\r\n\r\n### Source code / logs\r\n\r\nWe don\'t have a ""symbols.nupkgproj"" here:  https://github.com/dotnet/machinelearning/tree/master/pkg/Microsoft.ML.Parquet\r\nBut we do for https://github.com/dotnet/machinelearning/tree/master/pkg/Microsoft.ML.'"
322814664,143,"b""Rename 'Documentation' folder to 'Docs' for consistency""","b'There is a mix of lowercase and capitalization e.g. (Documentation vs. src, pkg, test) and usage of short vs. long names (e.g. Documentation vs. src, pkg, test). \r\n\r\nWould propose renaming to the following:\r\nDocumentation -> docs\r\n\r\nThoughts?'"
322681444,141,b'Support DataTable/DataView',"b'Currently, we have to create a model that maps to the data. It is difficult to use it in a scripting language like F# interactive or Powershell. We will be able use scripting language if there is a general data container such as DataFrame in numpy. DataTable/DataView is the closest thing in .net.\r\n\r\nMachine learning requires a lot of experiments. Scripting language will make it much easier. Otherwise we have to keep recompiling and rerun the steps.'"
322625026,140,b'Add Examples/Samples for ML.NET ',"b'**Why Examples?**\r\nTo simplify getting-started for ml.net add examples for different ML tasks like regression, binary and multi-class classification. In the future examples should also demonstrate how to use different transforms, transforms with hyper-parameters, learners and more. This will allow ML.NET users to have a great getting started experience OOTB and also help build models specific to their problem sets. \r\n\r\n**What should we do?**\r\nThere are a few kind of examples/samples required. 1. and 2. should be available as a part of the dotnet/machinelearning/samples location. For 3. we should find a place to host them separate to this repository. \r\n\r\n**1. First Touch with ML.NET:** \r\n    - Simple, getting started, Quick-Starts, F5-able in Visual Studio/VS Code and dot-net CLI \r\n       e.g. Taxi Fare, Sentiment Analysis, Iris etc. \r\n\r\n**2. ML.NET usage:** \r\n    - How to use different features in ML.NET: CV vs. train-test, using different transforms, learners etc. \r\n\r\n**3. End-End samples**\r\n    - Real world apps like ASP.NET apps(eshop), Cloud Native apps demonstrating how a productized,   \r\n       real world sample app will look like with ML.NET\r\n\r\nThoughts?\r\n'"
322604709,138,b'Generalized framework / method to Access data?',"b'Hello guys, \r\n\r\nthis is just a question came up to my mind. In Simulation (and other Areas) developers are always confronted with different departments (in a Company) having different data sources (SQL, XML, Excel, CSV, HDF5, MAT, MDF (Format in automotive), ....). All we developer want are the Arrays / datasets with their meta data. So honestly I was thinking ""ok - it is the same Situation like table based SQL data - so many different sources from Oracle, IBM, Microsoft, etc. but one Framework to Access and represent all different sources : EF Core"". \r\n\r\nSo now my question : you think it would be beneficial for ML.NET to have a EF Core like Framework but with Focus on Access Arrays? Every data source Format could implement an Interface / Provider. Maybe it would bring most benefit for heterogeneous Environments. I know for SQL etc. we have EF Core and EF Core could be also used maybe for this - but I think EF is focused on ORM and not searching for Arrays in HDF5, MDF, CSV etc. \r\n\r\nTo be honest : I did not find such a Framework in Python, Java etc. Thats why I ask how others think about this. If every source have a specific Provider and this Provider can search for Arrays and meta data : you even could think about a Query Language. Sth like ""Select Arrays where Unit == ""\xc2\xb0C"""" or sth in this way.    '"
322575831,137,b'.NET 4.7 CpuMathNative.dll not found',"b""- Windows 10 Pro x64\r\n- .NET Framework 4.7 Console App in Visual Studio 2017 15.7.1 \r\n\r\nI followed the steps on the 'Get Started' page (https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows). But I created a .NET 4.7 console app.\r\n\r\nWhen I run the application the following exception is thrown on line 70 of Program.cs\r\n\r\nI have located the missing DLL in the packages folder. If I manually copy the file into the output folder of my project the application runs as expected.\r\n\r\n============== Exception Information ==============\r\nSystem.Reflection.TargetInvocationException\r\n  HResult=0x80131604\r\n  Message=Exception has been thrown by the target of an invocation.\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n   at myApp.Program.Main(String[] args) in C:\\Users\\Dave\\Documents\\Visual Studio 2017\\Projects\\MLTests\\Iris\\Program.cs:line 70\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 2:\r\nDllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)"""
322415587,135,b'We need to find way to control random seed and amount of threads at least for tests.',"b""Currently out pipeline.Train function creates\r\n`using (var environment = new TlcEnvironment())`\r\nwhich is nice, but it doesn't specify seed which become random and concurrency which force algorithms to use all threads available on machine. Which can result in different metrics, predictions and any other stuff we assert in tests.\r\n """
322389948,132,"b""Why is ColumnAttribute's ordinal parameter a string?""","b'Why is the ctor:\r\n\r\npublic ColumnAttribute(string ordinal, string name = null);\r\n\r\nAs opposed to:\r\n\r\npublic ColumnAttribute(int ordinal, string name = null);'"
322348956,130,"b""TreeEnsembleFeaturizer entry point doesn't instantiate the scorer correctly""","b'It should instantiate the scorer on top of the transformed data, but instead it uses the input data.'"
322303982,128,"b""'Type not implemented or supported' exception message from TextLoader is not descriptive""","b""### Issue\r\n\r\n- I added ml package for the first time and tried to customize a tutorial a bit\r\n- I got 'Type not implemented or supported' exception. I did not understand what type is not supported and wasted a lot of time and ended up on github, looking for answers\r\n- I would like to know, what type is actually not supported yet. It would simplify a learning curve and save me some nerves.\r\n"""
322283512,127,b'Suggestion related to Working with Columns',"b'Right now we use Column attribute to decorate how to read columns. Additionally we mark column with text ""Label"" to indicate that it is a label.\r\n\r\nIf label column is missing ore not correctly named we get: ""InvalidOperationException: Column \'Label\' not found""\r\n\r\nSuggestion:\r\nIt might be better to use dedicated attributes like FeatureColumn and LabelColumn instead of freely written text. It is a statically typed and more .NET (C#) agnostic.\r\n'"
322234822,126,b'IFormatProvider in TextLoader',"b'Want to know how TextLoader deals with files in different cultures.\r\nFor example, if you are running on OS with culture like ""de-de"" such files might be loaded incorrectly:\r\n\r\n\r\nCMT,1,1,1267,**6.9**,CRD,23\r\nCMT,1,1,1267,**6.8**,CRD,24\r\n\r\nWith such cultures (none-invariant) would require files formatted in following way (separator = \';\')\r\n\r\nCMT;1;1;1267;**6,9**,CRD;23\r\nCMT;1;1;1267;**6,8**,CRD;23\r\n'"
322149208,125,b'Which format does exported model use?',b'can I get a onnx model by using ML.NET?'
322134438,124,b'Native build failed with CLI',"b'Trying to build on Windows using CLI first, ran build.cmd in root folder\r\nbuild started and was looking fine, until it started building native components.\r\n\r\n### Error Message\r\n\r\nmachinelearning-master\\src\\Native\\build.proj(47,5): error MSB3073\r\nmachinelearning-master\\src\\Native\\build.cmd Debug x64"" exited with code 255.\r\n\r\nBuild FAILED.\r\n\r\nTime Elapsed 00:00:02.03\r\nCommand execution failed with exit code 1.\r\n\r\nany ideas?'"
322132988,123,b'FastTree: Instantiate feature map for disk transpose and make Generalized Additive Models predictor resilient when feature map is not available.',"b""We drop features from FastTree gradient boosting decision tree during training that offer little to no value such as features that have zero instance count during training or features that don't have enough instance count for unique feature values. Due to this the feature count in training set can be less than or equal to the feature count in the input features vector from the user, hence we use a featuremap internally to map dataset training features to the input features. \r\n\r\nIssue# 1:\r\nIf no features are dropped or filtered during training then feature map is not created. FastTree handles a null featuremap but Generalized Additive Model(GAM) predictor does not.\r\n\r\nIssue# 1.1:\r\nBefore training starts in FastTree we go through a data preparation step where we transpose the dataset and eliminate examples that have missing feature values. The transpose can be done in memory or on disk(recommended for larger dataset). In disk transpose the code was not filtering features that were not supposed to be included in training and it was also not creating a feature map when one was supposed to be created. Hence a null feature map was passed to GAM predictor which was not resilient to it."""
322098654,119,"b'Entry-points and API for ""Loaders"" Need Models'","b'We have an entry-point for text loader. The public API type for this corresponds to an interface, `ILearningPipelineLoader`. This interface and the entry-point wrapped by the implementation of this interface for the text loader has two major problems:\r\n\r\nFirst, and most seriously, the output type does not contain the loader\'s model. We note that in the code, both `IDataTransform` and `IDataLoader` implement the `ICanSaveModel`. This is critical for, in the case of transforms, applying the same transforms to novel `IDataView`s, and for loaders, applying the same loader to new input files.\r\n\r\nCurrently, what we seem to do is to *respecify* the loader from scratch. The problems with this are not yet obvious in the current ML.NET codebase, I suppose, because the only loader that is introduced so-far is the `TextLoader`, and the trainable behavior of that loader is limited. As we introduce more loaders, (E.g., a loader to read data in SVM-light format, and close variants of that format), the problems of this approach will be more obvious.\r\n\r\nSecond, it accepts as its input type an `IFileHandle`, as opposed to what data-loaders *actually* accept in much of the runtime, an `IMultiStreamSource`. (This has come up also in issue #60, which complained among other things about lack of multi-file support, implications for Parquet loaders, etc.) Not only are multiple file scenarios impacted, but also scenarios where you want to load *no files at all* during loader specification are impacted as well. (To give an example of when this is important, since it\'s not obvious: distributed applications will first specify a shared model, made naturally out of untrained loaders and transforms, save the model, then distribute them to worker nodes so we are sure all workers have the same models.)\r\n\r\nBoth of these architectural problems are on display in [PR 106](https://github.com/dotnet/machinelearning/pull/106), when we are introducing something that absolutely is **not a loader at all**, that is, it loads no data and exports no model, but somehow still manages to conform to that interface seemingly with no problems, and we are naming a ""loader"" despite the fact that it reads nothing.\r\n\r\nFor this I\'d suggest the following rather simple fixes:\r\n\r\n1. We ""standardize"" runtime entrypoints for loaders by having them more closely resemble our existing practices for transforms, that is, they output both data, and model. The most natural thing to do is introduce a common output type akin to what we already have for tranform entrypoints (`CommonOutputs.ITransformOutput`), except `ILoaderOutput`, presumably.\r\n\r\n2. This output type would include a `Model`, presumably of type `ILoaderModel`, that resembles `ITransformModel`. This interface would also have `Apply`, but instead of over `IDataView` would be `IMultiStreamSource`.\r\n\r\n3. While we are at it, change the input type for existing entry points for the text loader to use `IMultiStreamSource` instead of `IFileHandle`, thus partially addressing the other part of the issue of =#60. Also *probably* introducing something into `CommonInputs`, similar to what happens for transforms.'"
322098232,118,b'ParquetLoader Exceptions Due to Block Size',"b'- ParquetLoader will fail on OutOfMemoryException when trying to create an enumeration sequence array that is too big.\r\n- If the {numbers of rows in a block} or {number of blocks} is greater than int.MaxValue, Overflow exception will be thrown. Ideally, we would use longs to keep track instead, but this is restricted due to point 1.\r\n\r\nThese exceptions should be caught with suggestions to alter block size as a fix.'"
322088467,117,"b""InvalidOperationException: Source column 'Label' is required but not found.""","b'### System information\r\n\r\n.NET Command Line Tools (2.1.4)\r\n\r\nProduct Information:\r\n Version:            2.1.4\r\n Commit SHA-1 hash:  5e8add2190\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.16299\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.4\\\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.5\r\n  Build    : 17373eb129b3b05aa18ece963f8795d65ef8ea54\r\n\r\n### Issue\r\n\r\nWhen decorating input type field with ""Label"" attribute as shown in the following\r\n\r\n```\r\nclass CoreFxIssue\r\n{\r\n    [Column(""0"")]\r\n    public string ID;\r\n\r\n    [Column(""1"", name: ""Label"")]\r\n    public string Area;\r\n\r\n    [Column(""2"")]\r\n    public string Title;\r\n\r\n    [Column(""3"")]\r\n    public string Description;\r\n}\r\n\r\npublic class CoreFxIssuePrediction\r\n{\r\n    [ColumnName(""PredictedLabel"")]\r\n    public string Area;\r\n}\r\n```\r\nThe training breaks with exception shown below when using ""Label"" in a transform in the pipeline.\r\n![image](https://user-images.githubusercontent.com/38438266/39894790-dd5e37f6-545c-11e8-9e44-df23af4fb2f2.png)\r\n\r\nThe problem is when defining input/output schema from input/output type, the column names are not properly loaded. Input type uses ColumnAttribute class while Output type uses ColumnNameAttribute while loading custom attributes ( c.f. https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Api/SchemaDefinition.cs).\r\n\r\n### Solution\r\nThe solution is to check for both type of custom attributes (ColumnAttribute, ColumnNameAttribute)  and load names properly and add a few tests to cover this issue.\r\n\r\n### Side Effects\r\nThis is the side effect of using custom attribute ""Label"" on any field in input type.\r\n\r\nWhen decorating ""Area"" field with ""Label"" attribute in CoreFxIssue\r\ntype above, the ""Area"" field is no longer available in the pipeline. ""Area"" is replaced with ""Label"" i.e. use ""Label"" for ""Area"" in the pipeline. Need to highlight it in the documentation properly.\r\n'"
322081124,116,b'Find a robust way to figure out which trainer entry points perform which task',"b'We should add this information to the EntryPoint attribute, and find a way to pass this to the generated C# API (perhaps through a common interface for each task).'"
322036310,114,b'Entry point name for logistic regression is misleading',"b'The entry point names for logistic regression should be ""Trainers.LogisticRegressionBinaryClassifier"" and ""Trainers.LogisticRegressionClassifier"" instead of ""Trainers.BinaryLogisticRegressor"" and ""Trainers.LogisticRegressor"".'"
322033553,112,b'MacroUtils does not handle the new entry point names properly',"b'The MacroUtils class has a static dictionary containing mapping from trainer kinds (classifier, regressor, etc.) to an object of type ""TaskInformationBundle"" which contains information about the trainer kind. Part of this information is the suffix of the entry point names of trainers of this kind. This needs to be updated because it does not currently match the existing entry point names.'"
321940076,110,b'Review and Remove calls to DateTime.Now.',"b'The codebase should probably be using DateTime.UtcNow, instead of DateTime.Now, to be locale agnostic.\r\n\r\nfrom: [comment](https://github.com/dotnet/machinelearning/issues/51#issuecomment-388054776)\r\n'"
321817966,108,b'Command-line tool to script ML.NET training and inference',"b'## Why Command Line?\r\nWhile C# is a great language to build services and apps, it is not a scripting language.  As a result, it is difficult sometimes to quickly experiment, play and test different ML approaches.  \r\nIn many situations, it is highly useful to script, parametrize and automate ML program execution.  This also might help end users operationalize model creation, maintenance, and deployment.\r\n\r\n## What should it do?\r\nWe need a command line tool that runs with ML.NET libraries and exposes a command line interface to the framework.  Such an EXE would:\r\n* Run training, inference, and evaluation against data files\r\n* Show list of available components and their arguments\r\n* Allow ability to run specific scripts files to run specific pipelines that can be used in benchmarking\r\n* Inspect models and binary data sources\r\n* Import and export models from ONNX\r\n* Autogenerate CS inference classes from trained models\r\n* Sweep hyper parameters\r\n* Moreover, we can define an interface for all of the actions so that it would be extended with developers to create additional commands\r\n\r\nWhat do you think?\r\n'"
321802414,107,b'Support for loading data from SQL server',"b'Somewhat related to #96 but more specific, it would be nice to have a loader to stream data out of a SQL Server table or view and into this framework for training.'"
321746115,104,b'Update BuildTools to .NET Core 2.1.200',b'.NET Core 2.1 RC was released at //build with version `2.1.200`. We should probably shift to that.'
321724743,103,"b""SourceLink doesn't work with the Microsoft.ML NuGet package""","b'### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: net471\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDebug an application that uses Microsoft.ML.\r\nLoad the symbols from the public Microsoft symbols server.\r\nTry to F11 into `new LearningPipeline();`.\r\n\r\n- **What happened?**\r\nVisual Studio prompted me to find the LearningPipeline.cs file myself.\r\n\r\n- **What did you expect?**\r\nI expected Visual Studio to automatically download the file from GitHub for me and step into it.\r\n'"
321663717,101,b'C# code generator should handle generic types.',"b""Line 505 in CSharpApiGenerator throws an exception in case the type is generic, since fullTypeName contains multiple dots after the last index of '+':\r\n\r\nname += fullTypeName.Substring(0, fullTypeName.LastIndexOf('+')).Substring(fullTypeName.LastIndexOf('.') + 1);\r\n"""
321657911,100,b'Add a README.md to `test/BaselineOutput`',b'We should have a `README.md` to the `test/BaselineOutput` folder to explain its purpose.\r\n\r\n(Updated on 2018-07-02 to reflect the new location of the folder)'
321648204,98,b'Support for HDF5?',"b'### Question about importer\r\n\r\nHello ML.NET Team, \r\n\r\nIt\'s so amazing to see that we .NET People really got a spark or scikit like Framework! From what I saw we can be proud of. \xf0\x9f\x91\x8d \r\n\r\nNow the question \r\n\r\n**Did you consider to write HDF5 importer?** \r\n\r\nMaybe I should explain. HDF5 is a very flexible and great data Format which is often used in Simulation area - the MATLAB file Format *.mat bases on HDF5. There exist many Python and Java Projects for HDF5 if you look at Github and on their web page https://portal.hdfgroup.org/display/support. But I really missing us .NET developers in this area. We have C#, F# and Powershell (also have VB.NET) and I find it would be good for .NET and the HDF5 if we work together. ;) \r\n\r\nMaybe a 2nd hint to Microsoft and ML.NET Team - there exist also the Project HDFql for SQL like query for my data - Image like ""give me all Arrays with have a tag ""Temperatur"" or ""give me all data with unit ""\xc2\xb0C"". ^^\r\n'"
321644936,97,b'Support Windows x86 builds',"b""### System information\r\n\r\n- **OS version/distro**:  Windows\r\n- **.NET Version (eg., dotnet --info)**:   All - desktop, .net core\r\n\r\n### Issue\r\n\r\n- **What did you do?**  Try to use ML.NET in an x86 process\r\n- **What happened?**  It doesn't work because CpuMathNative can't be loaded into an x86 process\r\n- **What did you expect?**  I expected it to work in a Windows x86 process.\r\n\r\n### Notes\r\n\r\nThere are cases where developers are forced to use x86 processes.  For example, if their hosting environment only supports x86 processes.  Or if they are using other native libraries that are only available for x86, and they don't want to (or can't) spin up multiple processes (x64 for ML.NET and x86 for other native libraries).\r\n"""
321622224,96,b'Working with streaming and larger than memory data sets',"b""Where does ml.net stand with regard to streaming support and large data sets? Is it design to only work with static data sets that can fit into main memory all at once? \r\n\r\nAre capabilities similar to https://github.com/BlueMountainCapital/Deedle.BigDemo/blob/master/README.md planned?\r\n\r\nWhen evaluating an approach on how to incorporate ML into application architecture, it is important for decision makers to understand what is going to be possible and what are the limits with regard to working with large and or unbounded data sets. It would be good to have a clear message about that in the readme and roadmap.\r\n\r\nI'm not sure if a successful ml library is possible without a very efficient and flexible (streaming, big data) data frame implementation like the one discussed in https://github.com/dotnet/corefx/issues/26845\r\nIt would be very interesting to understand ml.net team's take on that."""
321491282,93,"b""Microsoft.ML NuGet package doesn't work with packages.config""","b""### Original Title\r\nImpossible to run Iris classification test\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: \r\n Product Information:\r\n Version:            2.1.200\r\n Commit SHA-1 hash:  2edba8d7f1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTry Iris tutorial\r\n\r\n- **What happened?**\r\nRuntime error:\r\n\r\nSystem.Reflection.TargetInvocationException\r\n  HResult=0x80131604\r\n  Message=Eccezione generata dalla destinazione di una chiamata.\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.LearningPipeline.Train[TInput,TOutput]()\r\n   at IrsiExample.Program.Main(String[] args) in C:\\Users\\gvolpi\\source\\repos\\MLNetTest1\\IrsiExample\\Program.cs:line 69\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Eccezione generata dalla destinazione di una chiamata.\r\n\r\nInner Exception 2:\r\nDllNotFoundException: Impossibile caricare la DLL 'CpuMathNative': Impossibile trovare il modulo specificato. (Eccezione da HRESULT: 0x8007007E).\r\n\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nCode copy/pasted from github \r\n"""
321475326,92,"b'Sample fails with ""The size of input lines is not consistent""'","b'I\'m trying out the sample shown [here](https://docs.microsoft.com/en-gb/dotnet/machine-learning/tutorials/sentiment-analysis). However, whenever I try to train the model I get an error: ""The size of input lines is not consistent"". This is using the exact files that are specified in the tutorial so I\'m not sure where I\'m going wrong - any ideas?\r\n\r\n```fsharp\r\n#r ""netstandard""\r\n#load @""C:\\Users\\Isaac\\Source\\Repos\\scratchpad\\.paket\\load\\netstandard2.0\\ML\\ml.group.fsx""\r\n\r\nopen Microsoft.ML\r\nopen Microsoft.ML.Runtime.Api\r\nopen Microsoft.ML.Transforms\r\nopen Microsoft.ML.Trainers\r\n\r\nlet dataPath = @""data\\imdb_labelled.txt""\r\nlet testDataPath = @""data\\yelp_labelled.txt""\r\n\r\ntype SentimentData =\r\n    { [<Column(ordinal = ""0"")>] SentimentText : string\r\n      [<Column(ordinal = ""1"", name = ""Label"")>] Sentiment : float }\r\n\r\n[<CLIMutable>]\r\ntype SentimentPrediction =\r\n    { [<ColumnName ""PredictedLabel"">] Sentiment : bool }\r\n\r\nlet pipeline = LearningPipeline()\r\npipeline.Add(TextLoader<SentimentData>(dataPath, useHeader = false, separator = ""tab""))\r\npipeline.Add(TextFeaturizer(""Features"", ""SentimentText""))\r\npipeline.Add(FastTreeBinaryClassifier(NumLeaves = 5, NumTrees = 5, MinDocumentsInLeafs = 2))\r\n\r\n/// Pop!\r\nlet model = pipeline.Train<SentimentData, SentimentPrediction>()\r\n```'"
321466046,91,b'How do you load data from an in-memory data set?',b'The only sample I can see uses the `TextLoader` to import data from a CSV file. How do you load in arbitrary data from e.g. a record or array and specify labels etc. on there?\r\n\r\nThanks!'
321461407,89,b'Update documentation front page',"b""On https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet, please update the text:\r\n\r\n> Use your **.NET and C#** skills to easily integrate custom machine learning into your applications without any prior expertise in developing or tuning machine learning models.\r\n\r\nto\r\n\r\n> Use your **C# or F# on .NET** skills to easily integrate custom machine learning into your applications without any prior expertise in developing or tuning machine learning models.\r\n\r\nIf you can point me to the repo that contains this documentation I'm happy to submit the PR myself"""
321456937,88,b'F# Samples',b'There should be a sample project (or even just a set of scripts) that illustrate using the library from F#.'
321413974,86,b'GPU',"b'hi, is there (or will there be) any support for training and doing stuff on gpu using ML.net too or no???'"
321371067,85,"b""Need to bump master's version number to 0.2""","b""We've shipped v0.1.0.  We should bump the daily build version numbers to 0.2.0-preview.  That way the new daily builds aren't lower versioned than the already-released `0.1.0` version.\r\n"""
321266551,83,b'CpuMath: any plan to use AVX-512 in the native code used when not on .NET Core 3.0?',b'It seems [CpuMathNative](https://github.com/dotnet/machinelearning/tree/master/src/Native/CpuMathNative) has both Sse version and Avx version. Is there any plan to implement the AVX-512 version?\r\n'
321262478,82,b'Improvements on the Gitter channel setup',"b'A few improvement suggestion to the Gitter channel:\r\n\r\nIt would be really nice if clicking the channel name would open the Github page of this project, an image for that what I mean:\r\n![Channel name](https://user-images.githubusercontent.com/5158694/39770471-c78b0fc8-52f7-11e8-80ef-955ce4659036.png)\r\n\r\nIt would also be nice to see repository events in the side-panel, commits, issues and so forth, again an image to clarify:\r\n\r\n![Repository events](https://user-images.githubusercontent.com/5158694/39770520-ec883c4c-52f7-11e8-83d2-5aa63b6c1502.png)\r\n\r\n\r\n'"
321255579,81,b'CpuMath: Avx version has less APIs than Sse version',"b'It seems [Avx version](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.CpuMath/Avx.cs) has less APIs available than [Sse version](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.CpuMath/Sse.cs).  For example, Sse version has both `DotProductDense `and `DotProductSparse` while Avx version has only `DotProductSparse`.\r\n\r\nIs there any particular reason that Avx version has less APIs? Any plan to make them equal?\r\n'"
321252471,80,"b'CpuMath: Sse code is executed when Avx is available, except on .NET Core 3.0'","b'### System information\r\n\r\n- **Windows 10 Enterprise**:\r\n- **dotnet Version: 2.1.105**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI followed the tutorial https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows to install SDK and create the sample app. I ran this example in release mode `dotnet run -c Release` and profiled it.\r\n- **What happened?**\r\nThe profiling shows Sse code is executed as shown below.\r\n![capture](https://user-images.githubusercontent.com/18431130/39768870-5cc25096-529f-11e8-942a-366943de137f.PNG)\r\n\r\n- **What did you expect?**\r\nSince my machine is Avx capable and `AddScale ` has Avx version https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.CpuMath/Avx.cs#L721, I would expect the Avx version is used.\r\n\r\n'"
321159983,77,b'Where is SentimentData defined?',"b'### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  2.1.200\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI\'m try the [examples](https://github.com/dotnet/machinelearning#examples) in the readme.\r\n\r\n- **What happened?**\r\n\r\nI installed Microsoft.ML package to a newly created .Net core console app.\r\n\r\nAnd in the `Program.cs` file,\r\n\r\n```\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Trainers;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace MLTry\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader<SentimentData>(dataPath, separator: "",""));\r\n//...\r\n```\r\n\r\nIt doesn\'t compile because `SentimentData` is not defined. And I searched for `SentimentData` in the repo but found nothing related.\r\n\r\n- **What did you expect?**\r\nFound the type `SentimentData`.\r\n'"
321114922,74,b'Some tests (eight) fail in Microsoft.ML.Predictor.Tests',"b""### System information\r\n\r\n.NET Command Line Tools (2.1.200)\r\n\r\nProduct Information:\r\n Version:            2.1.200\r\n Commit SHA-1 hash:  2edba8d7f1\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.200\\\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.7\r\n  Build    : 2d61d0b043915bc948ebf98836fefe9ba942be11\r\n\r\n### Issue\r\n\r\n1. I checkout the project,\r\n2. Ran `.\\build.cmd` on PowerShell prompt\r\n3. Opened the project in VS 2017 15.7\r\n4. Ran all tests, some of which failed (see attached image).\r\n\r\nI did expect all tests to pass.\r\n\r\n![fail line](https://user-images.githubusercontent.com/5158694/39749916-90e9f5fa-52bc-11e8-8ad3-ac332fb1aea6.png)\r\nThe assert here fails. I didn't  go further to check if the cause is a programming error or something else as this was more of curiosity, but noted here. :)\r\n\r\nThese are all of the eight tests that fail due to the assert in the previous image:\r\n![failed tests](https://user-images.githubusercontent.com/5158694/39749953-a6f4e3fa-52bc-11e8-8ee9-8192acb5ad1d.png)\r\n"""
321082702,73,b'Build failed under OSX',"b'### System information\r\n\r\n- **OS version/distro**: OSX 10.12.6\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\n.NET Command Line Tools (2.1.4)\r\n\r\nProduct Information:\r\n Version:            2.1.4\r\n Commit SHA-1 hash:  5e8add2190\r\n\r\nRuntime Environment:\r\n OS Name:     Mac OS X\r\n OS Version:  10.12\r\n OS Platform: Darwin\r\n RID:         osx.10.12-x64\r\n Base Path:   /usr/local/share/dotnet/sdk/2.1.4/\r\n\r\nMicrosoft .NET Core Shared Framework Host\r\n\r\n  Version  : 2.0.5\r\n  Build    : 17373eb129b3b05aa18ece963f8795d65ef8ea54\r\n```\r\n### Issue\r\n\r\n- **What did you do?** \r\n```bash\r\n> git clone git@github.com:dotnet/machinelearning.git\r\n> cd machinelearning\r\n> ./build.sh\r\n```\r\n\r\n- **What happened?**\r\nBuild failed\r\n\r\n- **What did you expect?**\r\nML goodness\r\n\r\n### Source code / logs\r\n```\r\n... truncated for brevity ...\r\n\r\n  + cmake /Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native -G \'Unix Makefiles\' -DCMAKE_BUILD_TYPE=Debug -DVERSION_FILE_PATH:STRING=/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/../../bin/obj/version.c\r\n  -- The C compiler identification is Clang 3.5.1\r\n  -- The CXX compiler identification is Clang 3.5.1\r\n  -- Check for working C compiler: /usr/local/bin/clang-3.5\r\n  -- Check for working C compiler: /usr/local/bin/clang-3.5 -- works\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Detecting C compile features\r\n  -- Detecting C compile features - done\r\n  -- Check for working CXX compiler: /usr/local/bin/clang++-3.5\r\n  -- Check for working CXX compiler: /usr/local/bin/clang++-3.5 -- works\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Detecting CXX compile features\r\n  -- Detecting CXX compile features - done\r\n  -- Configuring done\r\n  -- Generating done\r\nEXEC : CMake warning (dev):  [/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj]\r\n    Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run ""cmake\r\n    --help-policy CMP0042"" for policy details.  Use the cmake_policy command to\r\n    set the policy and suppress this warning.\r\n  \r\n    MACOSX_RPATH is not specified for the following targets:\r\n  \r\n     CpuMathNative\r\n     FastTreeNative\r\n  \r\n  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n  \r\n  -- Build files have been written to: /Users/justinormont/Documents/Microsoft/src/machinelearning/bin/obj/x64.Debug/Native\r\n  + set +x\r\n  Scanning dependencies of target CpuMathNative\r\n  [  8%] Building CXX object CpuMathNative/CMakeFiles/CpuMathNative.dir/Sse.cpp.o\r\nEXEC : error : unknown warning option \'-Wno-unused-local-typedef\' [-Werror,-Wunknown-warning-option] [/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj]\r\n  make[2]: *** [CpuMathNative/CMakeFiles/CpuMathNative.dir/Sse.cpp.o] Error 1\r\n  make[1]: *** [CpuMathNative/CMakeFiles/CpuMathNative.dir/all] Error 2\r\n  make: *** [all] Error 2\r\n/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj(33,5): error MSB3073: The command ""/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.sh --configuration Debug --arch x64 "" exited with code 2.\r\n\r\nBuild FAILED.\r\n\r\nEXEC : CMake warning (dev):  [/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj]\r\nEXEC : error : unknown warning option \'-Wno-unused-local-typedef\' [-Werror,-Wunknown-warning-option] [/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj]\r\n/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.proj(33,5): error MSB3073: The command ""/Users/justinormont/Documents/Microsoft/src/machinelearning/src/Native/build.sh --configuration Debug --arch x64 "" exited with code 2.\r\n    1 Warning(s)\r\n    2 Error(s)\r\n\r\nTime Elapsed 00:01:28.38\r\nCommand execution failed with exit code 1.\r\n```\r\n\r\n### Attempts\r\nI first suspected an older version of clang or cmake:\r\n```bash\r\n> clang++ --version\r\nApple LLVM version 7.0.2 (clang-700.1.81)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\n\r\n> cmake --version\r\ncmake version 3.10.1\r\n```\r\n\r\nAfter updating:\r\n```bash\r\n> clang++ --version\r\nApple LLVM version 9.0.0 (clang-900.0.39.2)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n> cmake --version\r\ncmake version 3.11.1\r\n```\r\nStill no luck after updating clang++ & cmake.\r\n'"
321073457,72,b'URL to sample is incorrect in readme.md',"b""The correct URL should be https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/Scenarios/SentimentPredictionTests.cs\r\n \r\nit changed with the latest pull request but the readme.md hasn't been updated.\r\n"""
321064893,70,b'ML.Net and Azure ML Relationship',"b'It would be beneficial for potential users to understand the relationship between ml.net and azure ML. \r\n\r\nIs ml.net the lib behind azure ml? Is ml.net going to be a block inside azure ml? How do those things.work together, is it going to be possible to seamlessly move models, flows, etc between the two?'"
321063861,69,b'R and Python integration / interoperability',"b'Will this library offer R and Python integration? Where is it on the roadmap? What kind of data transfer library/format will it use, Apache arrow? Something else?\r\n\r\nIt is important for solution architects to understand how ml.net is going to fit into the big data picture, it is necessary these days given that java, R and Python are dominant in this space.'"
321062556,68,b'Samples for trainers',b'Looking for samples for supported trainers:\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers?view=ml-dotnet\r\n\r\nThanks\r\n'
321033167,67,b'Bring CNTK model evaluation to this library',"b'I had a great conversation with some of the team at Build today.  I hope this is the right place - would love to see ML.Net bring evaluation of CNTK models.  The team suggested I place a note here to hopefully help vote this up. \r\nWe use custom CNTK models for behind the scenes processing in our app to do various things.  We do the evaluation in Azure Function, and would love to see a pure-.net deploy instead of the current deploy where we have to bin deploy lots of C++ libraries and manually work around getting those into a path location so they are callable via c#/managed code.\r\n\r\nSo, +1 for our team - we would love to see this feature add.'"
321031935,66,b'Nice work!',"b""I haven't worked with C# in a while because I've been working on some machine learning projects in Python with Scikit-Learn. It's so awesome to see .NET is getting its own built-in, high performance machine learning package! \xf0\x9f\x8e\x89 \r\n\r\nI have a question about the goals of this project-- how exactly does it relate to existing high-quality frameworks like [Accord.NET](https://github.com/accord-net/framework) or [all of the projects listed here](https://github.com/quozd/awesome-dotnet#machine-learning-and-data-science)? Thanks."""
321025542,64,b'Binary Training Data',b'As shown during the .NET Overview Session today at BUILD and as discussed with the ML Team there is only a text based reader for training data. Having a binary reader for training data would be highly beneficial to my use case.'
320999518,63,b'ML.NET Github tagging example from MS Build',b'I just attended to the session on BUILD 2018 with Scott Hanselman who showed an example of ML.NET for tagging Github pull requests. Is this example available somewhere?'
320988464,60,"b""Doesn't support partitioned directories.""",b'Storage formats such as Parquet allow partitioning their data through multiple files and structured directories. This library has no such way to load these partitioned files into one IDataView.'
320968683,57,b'Verifying steps to build machinelearning repo on Linux and Mac',b'Need to verify the instructions in the Documentation folder for building this repo on different distos have no missing steps.\r\n\r\n[Windows](https://github.com/dotnet/machinelearning/blob/master/Documentation/building/windows-instructions.md) \r\n* Has been verified already.\r\n\r\n[Unix](https://github.com/dotnet/machinelearning/blob/master/Documentation/building/unix-instructions.md):\r\n\r\n* Linux: clang version 3.9+ is the minimum pre-requisite not 3.5+\r\n* macOS: to be verified.\r\n\r\ncc: @danmosemsft @eerhardt '
320964760,56,b'Use .NET Core Hardware Intrinsics to optimize the code?',"b""It's great to see a C# machine learning framework!\r\n\r\nIt seems some linear algebra algorithms are implemented by calling into native cpp code. I assume this is due to the rich SIMD instructions in cpp. Since .NET Core 2.1 has the preview feature of Hardware Intrinsics, using hardware intrinsics is another option to use SIMD instructions.\r\n\r\n"""
320936110,53,b'Simple example using House Pricing Scenario',"b'This is the first time I\'ve looked into machine learning but I have a use case I\'d like to test with it.\r\n\r\nTo get started I\'ve created a simple example from the house pricing scenario which somewhat closely matches my use case but the results I\'m getting are not at all close to what I expected. The data I\'m providing is simply linear in terms of just the `SqftLiving` input parameter to the `Price` where `Price = SqftLiving * 100`. The `SqftLot` is held constant for training and prediction so it should be a non-factor.\r\n\r\nI\'m just trying to predict the Price when the `SqftLiving` is 1500 which with the linear model created by the provided data should make it about $150,000.\r\n\r\nHowever, the results I get vary wildly from the negative to the postive 10\'s of millions every time I run the program which is unexpected. Could someone look into this simple example and let me know what if anything I\'m doing is causing these poor results?\r\n\r\n```c#\r\nclass Program\r\n{\r\n    static void Main(string[] args)\r\n    {\r\n        var filePath = ""C://Temp/kc_house_data.csv"";\r\n\r\n        File.WriteAllText(filePath, @""100000,1000,8000\r\n200000,2000,8000\r\n400000,4000,8000"");\r\n\r\n        var pipeline = new LearningPipeline\r\n        {\r\n            new TextLoader<HousePriceData>(filePath, separator: "",""),\r\n            new ColumnConcatenator(""Features"", ""SqftLiving"", ""SqftLot""),\r\n            new StochasticDualCoordinateAscentRegressor()\r\n        };\r\n\r\n        var model = pipeline.Train<HousePriceData, HousePricePrediction>();\r\n\r\n        var prediction = model.Predict(new HousePriceData { SqftLiving = 1500, SqftLot = 8000 });\r\n\r\n        Console.WriteLine(prediction.Price);\r\n        Console.ReadLine();\r\n    }\r\n}\r\n\r\npublic class HousePriceData\r\n{\r\n    [Column(ordinal: ""0"", name: ""Label"")]\r\n    public float Price;\r\n\r\n    [Column(ordinal: ""1"")]\r\n    public float SqftLiving;\r\n\r\n    [Column(ordinal: ""2"")]\r\n    public float SqftLot;\r\n}\r\n\r\npublic class HousePricePrediction\r\n{\r\n    [ColumnName(""Score"")]\r\n    public float Price;\r\n}\r\n```'"
320922849,51,b'A few questions',"b""Hey,\r\n\r\nThat's a great initiative to see a machine learning FW for .NET \xf0\x9f\x91\x8d \r\n\r\nI have a couple of questions about the rationale behind the project:\r\n\r\n- Apart the difference between a pure .NET implementation and a mixed C++&.NET Bindings, what are the advantages/differences with [CNTK](https://github.com/Microsoft/CNTK)?\r\n- What are the training algorithms supported? (e.g CNN, RNN?)\r\n- What is the plan about multi-machine, multi-CPU, GPU (and multi-GPU) support?\r\n- Is it aimed at providing an abstract API (and a default implementation) that could plug to any implementation behind (e.g CNTK?)?\r\n\r\nThanks!\r\n"""
320919992,49,b'EntryPointChainedCrossValMacros test fails in CI occasionally',"b""### System information\r\n\r\n- **OS version/distro**:  Linux Debug\r\n- **.NET Version (eg., dotnet --info)**:   .NET Core\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nSubmitted a PR that only changed a markdown file:  https://github.com/dotnet/machinelearning/pull/48\r\n- **What happened?**\r\nThe Linux Debug leg failed.  See https://ci2.dot.net/job/dotnet_machinelearning/job/master/job/linux_debug_prtest/1/\r\n\r\n- **What did you expect?**\r\nI expected all the tests to pass on all legs since I didn't change any code.\r\n\r\n### Source code / logs\r\n\r\n```\r\nMESSAGE:\r\n                                        Assert failed: longIdx=328, invariants.Length=328\r\nExpected: True\r\nActual:   False\r\n                                        +++++++++++++++++++\r\n                                        STACK TRACE:\r\n                                           at Microsoft.ML.Runtime.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/test/Microsoft.ML.TestFramework/GlobalBase.cs:line 47\r\n   at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 751\r\n   at Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 764\r\n   at Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.Core/Utilities/Contracts.cs:line 822\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`1.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs:line 520\r\n   at Microsoft.ML.Runtime.Learners.LinearTrainerBase`1.TrainEx(RoleMappedData data, LinearPredictor predictor) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs:line 76\r\n   at Microsoft.ML.Runtime.Learners.LinearTrainerBase`1.Train(RoleMappedData examples) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.StandardLearners/Standard/LinearClassificationTrainer.cs:line 84\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore[TDataSet,TPredictor](IChannel ch, ITrainer trainer, Action`1 train, TDataSet data, TDataSet validData, TPredictor predictor) in /mnt/resource/j/w/dotnet_machinelearning/master/linux_debug_prtest/src/Microsoft.ML.Data/Commands/TrainCommand.cs:line 324\r\n```\r\n"""
320890431,47,b'Adding dataset and license for NYC Taxi Fare',b'Per conversation with CELA adding license and datasets.'
320858473,43,b'Fill out nupkg metadata completely',"b'### System information\r\n\r\n- **OS version/distro**:  All\r\n- **.NET Version (eg., dotnet --info)**:  All\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nInspect the NuGet metadata for Microsoft.ML\r\n\r\n- **What happened?**\r\n\r\nOnly some of the info is filled out.  For example, for ""description"" it says ""Package Description"".  It also doesn\'t have a link to release notes or license/project URL.\r\n\r\n- **What did you expect?**\r\n\r\nI expected all the info to be filled out.'"
320857497,41,b'The Gitter link in Readme.md points to the wrong chate',b'Line 47 of our README.md says:\r\n\r\n```\r\nPlease join our community on Gitter [![Join the chat at https://gitter.im/dotnet/corefx](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/dotnet/?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\r\n```\r\n\r\nWhile it really should be:\r\n\r\n```\r\nPlease join our community on Gitter [![Join the chat at https://gitter.im/dotnet/mlnet](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/dotnet/mlnet)\r\n```'
320670569,39,b'Microsoft.ML.Scenarios.Top5Scenarios.TrainAndPredictIrisModelTest fails intermittently ',b''
320616939,36,b'Add release notes for ML.NET 0.1',b'Need to add release notes for ML.NET 0.1 with installation steps and available components.'
320539048,34,b'Enable using OneVersusAll (OVA) in LearningPipeline',b'OneVersusAll would enable using more learners in multiclass classification problems (e.g. FastTree). OVA is currently available but not as part of `LearningPipeline`. '
320465434,33,b'Exception message missing parameter name',"b'This message probably meant to have the parameter name in the string.\r\n```\r\n""System.ArgumentOutOfRangeException:  is missing ColumnAttribute\r\nParameter name: Name\r\n   at Microsoft.ML.TextLoader`1.SetCustomStringFromType(Boolean useHeader, String separator, Boolean allowQuotedStrings, Boolean supportSparse, Boolean trimWhitespace)\r\n   at Microsoft.ML.TextLoader`1..ctor(String inputFilePath, Boolean useHeader, String separator, Boolean allowQuotedStrings, Boolean supportSparse, Boolean trimWhitespace)\r\n   at Microsoft.ML.NYCTaxiFare.Program.Train() in C:\\Users\\danmose\\source\\repos\\ConsoleApp81\\ConsoleApp81\\Program.cs:line 25\r\n   at Microsoft.ML.NYCTaxiFare.Program.Main(String[] args) in C:\\Users\\danmose\\source\\repos\\ConsoleApp81\\ConsoleApp81\\Program.cs:line 17""\r\n```\r\nIt\'s because it\'s thrown like \r\n`                    throw Contracts.ExceptParam(nameof(field.Name), "" is missing ColumnAttribute"");`\r\nand the ExceptParam does not prefix it for free:\r\n```\r\n  306:         public static Exception ExceptParam(string paramName, string msg)\r\n  307              => Process(new ArgumentOutOfRangeException(paramName, msg));\r\n```'"
320463154,32,b'Refactor Scenario tests...',"b'Issue: In Scenarios, there is a class named ""Top5Scenarios""\r\nDepending on how you count, there are either 2 or 4 scenarios.\r\nIt is recommended renaming the class.\r\n\r\n----\r\nLet\'s also review the names of the files and make sure they are descriptive.'"
320462546,31,b'Intellisense is not helpful with filling in pipeline components.',"b'When adding transforms/trainers into the ""LearningPipeline"" object. There is no info/docs/help available through the intellisense. It would be nice to add docs to explain what to add.'"
320460550,28,b'Building in Visual Studio ',"b""_From @terrajobst on Mar 26_\r\n\r\nOn a clean machine, opening the solution file and building in VS fails as the\xc2\xa0Tools\xc2\xa0folder doesn't exist. Just running\xc2\xa0`init-tools.cmd`\xc2\xa0doesn't fix it either as it now fails with malformed\xc2\xa0`AssemblyInfo.cs`\xc2\xa0files.\r\nI'm still trying to get build working from the command line (where I get mostly actionable error messages, like\xc2\xa0`Install CMake`) this feels like the sort of thing that discourages contributors quickly. Ideally, you should be able to clone the repo, open the solution in VS, and building immediately.\r\nThoughts?"""
320460186,27,b'Add ML.NET Roadmap',b'Add ML.NET roadmap for near and long term'
320459405,26,b'-rp.txt files are not getting generated on linux and mac ',"b""_From @Anipik on May 2, 2018, 1:49 PM PDT_\r\n\r\nhttps://ci2.dot.net/job/Private/job/dotnet_machinelearning/job/master/job/linux_debug_prtest/388/console\r\n\r\n```\r\n13:43:16    Running as: TrainTest tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-3 nt=1} data=/mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/test/data/breast-cancer.txt seed=1 test=/mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/test/data/breast-cancer.txt out={/mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/netcoreapp2.0/TestOutput/LogisticRegression/LogisticRegression-norm-TrainTest-breast-cancer-model.zip} dout={/mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/netcoreapp2.0/TestOutput/LogisticRegression/LogisticRegression-norm-TrainTest-breast-cancer.txt}\r\n13:43:16  Output matches baseline: 'LogisticRegression/LogisticRegression-norm-TrainTest-breast-cancer-out.txt'\r\n13:43:16  *** Failure: Output file not found: /mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/netcoreapp2.0/TestOutput/LogisticRegression/LogisticRegression-norm-TrainTest-breast-cancer-rp.txt\r\n13:43:16  Output matches baseline: 'LogisticRegression/LogisticRegression-norm-TrainTest-breast-cancer.txt'\r\n13:43:16  Suffix of length 34 compared against sequence of length 42\r\n13:43:16  Running 'LogisticRegression' on 'breast-cancer'\r\n13:43:16    Running as: CV tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-3 nt=1} data=/mnt/resource/j/w/Private/dotnet_machinelearning/master/linux_debug_prtest/test/data/breast-cancer.txt seed=1 dout=\r\n```\r\n\r\ncc @danmosemsft @eerhardt @codemzs """
320459322,25,b'Hyperparameters reversed in Scenario3 ',"b'_From @justinormont on May 2, 2018, 8:51 AM PDT_\r\n\r\nLine below on file `machinelearning/test/Microsoft.ML.Tests/Scenarios/Scenario3_SentimentPrediction.cs`\r\n\r\n> CharFeatureExtractor = new NGramNgramExtractor() { NgramLength = 2, AllLengths = true }, \r\n\r\n\r\nCurrently: _(trigrams & unichargrams+bichargrams)_\r\n```C#\r\n  CharFeatureExtractor = new NGramNgramExtractor() { NgramLength = 2, AllLengths = true },\r\n  WordFeatureExtractor = new NGramNgramExtractor() { NgramLength = 3, AllLengths = false }\r\n```\r\n\r\nShould be: _(unigram+bigram & trichargrams)_\r\n```C#\r\n  CharFeatureExtractor = new NGramNgramExtractor() { NgramLength = 3, AllLengths = false },\r\n  WordFeatureExtractor = new NGramNgramExtractor() { NgramLength = 2, AllLengths = true }\r\n```'"
320458814,24,b'Add support for training on a collection of objects',"b'Right now, the `LearningPipeline` can only learn from data consumed via the `TextLoader` or any other `Loader` component. For many scenarios, it would be nice to allow for the consumption of collections of objects for training.'"
320458270,23,b'Add Evaluate overload that takes IDataView',"b""_From @eerhardt on May 1, 2018, 9:52 AM PDT_\r\n\r\n\r\nSee comment _From @glebuk created May 1, 2018, 8:52 AM PDT_ for file `src/Microsoft.ML/Models/BinaryClassificationEvaluator.cs` on line below:\r\n\r\n```\r\npublic BinaryClassificationMetrics Evaluate(PredictionModel model, ILearningPipelineLoader testData)\r\n```\r\n\r\n>Evaluate [](start = 43, length = 8)\r\n\r\nWe should add another overload to evaluate against a scored IDV.  There you'd need to specify columns for actual, predicted labels and score. (ok to ship after build) #Closed\r\n"""
320456795,22,b'Add mono support',"b""_From @alexanderkyte on Apr 27, 2018, 10:58 AM PDT_\r\n\r\nIn order for our models to be useful on mobile platforms, we're going to need to get this working on mono. It'll probably simply be some infrastructure work. \r\n\r\nI can address it, as I'm a mono runtime engineer.\r\n\r\nCurrently on backlog / low-priority \r\n"""
320456662,21,b'Add ML.NET samples to https://github.com/dotnet/samples',"b'_From @KrzysztofCwalina on Apr 23, 2018, 8:38 AM PDT_\r\n\r\n_No description provided_'"
320456510,20,b'Add performance tests for scenarios we care about',"b'_From @KrzysztofCwalina on Apr 19, 2018, 2:41 PM PDT_\r\n\r\n_No description provided._'"
320456257,19,b'Remove/Rename LotusIR namespace',"b'_From @KrzysztofCwalina on Apr 16, 2018, 9:13 AM PDT_\r\n\r\nThere is a public top level LotusIR namespace in our repo. We agreed that all our namespaces will be in Microsoft.MachineLearning, and so we should rename or remove this LotusIR namespace.'"
320456083,18,b'System.MachineLearning.Runtime namespaces cleanup',"b'_From @KrzysztofCwalina on Apr 16, 2018, 9:11 AM PDT_\r\n\r\nThere are several problems with System.MachineLearning.Runtime namespaces. We should clean these problems out:\r\n\r\n- [ ] There are too many System.MachineLearning.Runtime subnamepsaces. This will overwhelm users browsing the documentation on MSDN, IDE browsers, etc. We should combine the APIs in fewer subnamespaces.\r\n- [ ] We should not use ""Api"" in namespace or project names. All public things are ""APIs"" as far as .NET developers are concerned.\r\n\r\n- [ ] We have ""EntryPoints"" namespace. We should rename it. All ""entry point"" APIs should simply be in the root namespace (or subnamesapce of the root..\r\n\r\n- [ ] We should not have ""tools"" APIs in the main assmebly. Remove/rename Microsoft.MachineLearning.Runtime.Internal.Tools'"
320455787,16,b'Provide Scenario Sample Code for All Scenarios',"b'_From @KrzysztofCwalina\xc2\xa0on Apr 16, 2018, 9:07 AM PDT_\r\n\r\nCurrently, we have only one scenario code sample (house price prediction). We should have top 5 scenario samples.\r\n'"
320455210,15,b'Need to support more types than string and float',"b'_From @eerhardt on Apr 12, 2018, 6:52 AM PDT_\r\n\r\n\r\nSee code in `machinelearning/src/Microsoft.MachineLearning.EntryPoints/TextLoader.cs`\r\n\r\n```\r\n\tprivate string TypeToName(Type type) \r\n\t{ \r\n\tif (type == typeof(string)) \r\n\treturn ""TX""; \r\n\telse if (type == typeof(float) || type == typeof(double)) \r\n\treturn ""R4""; \r\n\telse \r\n\tthrow new Exception(""Type not implemented or supported.""); //Add more types. \r\n\t} \r\n```\r\n(Refers to Lines 70 to 78 in 6e74d72)\r\n\r\nWe should fill all supported types out and add tests.\r\n'"
320454323,14,b'Figure out a long term name for CpuMathNative',"b'_From @eerhardt on March 26th_\r\n\r\nfrom\r\n` - internal const string     NativePath = @""Microsoft.MachineLearning.CpuMathNative.dll""; `\r\nto    \r\n`+ internal const     string NativePath = ""CpuMathNative"";               \xc2\xa0  `                \xc2\xa0   \r\n\r\nGlad this worked, and thanks for filing the CoreCLR issue. As far as I can tell   this should work on netcoreapp2.0 and desktop as well, but we should test   that since this codepath has undergone a few changes in 2.1. Also we may   consider adding something more specific to the name since we won\'t be able to rely on a fix for dotnet/coreclr#17150.\xc2\xa0'"
320442529,11,b'Publish daily official builds to myget',b'We should publish our daily official builds to https://dotnet.myget.org.  That way developers external to Microsoft can get access to the official daily packages.'
320419893,10,b'Enabling LearningPipeline to use IEnumerable input data',"b'ML.NET currently enables me to load in data through a file (e.g. CSV/TSV). However, I might have collected the dataset through another source and want to train on it without first saving it to a file.'"
320413876,9,b'Add/expose random seed in LearningPipeline to get deterministic results',b'It is important to be able to set a random seed for ML experiments so the results are reproducible. Add random seed to LearningPipeline (or elsewhere) to ensure a full experiment is deterministic.'
320413492,8,b'Enable/increase verbosity for LearningPipeline and its components (like TextFeaturizer)',"b'Transforms like `TextFeaturizer` do not show sufficient logs. These logs exist but are currently not exposed.\r\n\r\nIn an experiment where the TextFeaturizer is the first transform, a user might not see any logs for several minutes, which might suggest there is an issue. Increasing verbosity will clarify what is happening.\r\n'"
320413090,7,b'Simplify Pipeline Initalization with Append() that returns the pipeline',"b'Issue:\r\nCurrently we have to use the pipeline instance to append additional items to the pipeline. It looks something like this:\r\n```csharp\r\nvar pipeline = new LearningPipeline();\r\npipeline.Add(new TextLoader<SentimentData>(dataPath, separator: "",""));\r\npipeline.Add(new TextFeaturizer(""Features"", ""SentimentText""));\r\n```\r\nWe can add the ability to add a pipeline item in a fluent fashion.  The benefit would be reduction of typing and  cleaner API.  \r\nThis would require pipeline to add the following method:\r\n```csharp\r\npublic LearningPipeline Append(ILearningPipelineItem item);\r\n```\r\nThe user code will look like this:\r\n```csharp\r\nvar pipeline = new LearningPipeline()\r\n   .Append(new TextLoader<SentimentData>(dataPath, separator: "",""))\r\n   .Append(new TextFeaturizer(""Features"", ""SentimentText""));\r\n```\r\n(optional) with extension methods, this can be simplified even further to:\r\n```csharp\r\nvar pipeline = new LearningPipeline()\r\n   .AddTextLoader<SentimentData>(dataPath, separator: "","")\r\n   .AddTextFeaturizer(""Features"", ""SentimentText"");\r\n```'"
320408460,6,b'Enable cross-validation for LearningPipeline',"b'Cross-validation would make it easier to validate models if the data is not already split into train and test files (and generally helps give more precise metrics). This is already exposed as an entrypoint [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML/Runtime/EntryPoints/CrossValidationMacro.cs), but needs to be enabled for LearningPipeline.'"
320405694,5,b'Enabling different settings for the TextLoader on train and test data might lead to incorrect metrics with no error',"b'The train and test data can be read with different `TextLoader`s, which makes it easy to introduce bugs. If there is a difference in the settings, the metrics are likely to be wrong but there are no errors. \r\nExample:\r\n```cs\r\nstring trainDataPath= ""sentiment_data.tsv"";\r\npipeline.Add(new TextLoader<SentimentData>(trainDataPath, useHeader: true));\r\n\r\n// Later in the file, after completing the pipeline and training the model\r\nstring testDataPath = ""sentiment_test.tsv"";\r\nvar testData = new TextLoader<SentimentData>(testDataPath, userHeader: true, sep: \',\');\r\n\r\nvar evaluator = new BinaryClassificationEvaluator();\r\nBinaryClassificationMetrics metrics = evaluator.Evaluate(model, testData);\r\n```\r\nEvaluating on the test data will result in incorrect metrics as the test file will be parsed incorrectly. However, the experiment runs successfully with no errors, so this might be difficult to detect.\r\n\r\n\r\n'"
320393138,4,b'Move Samples/UCI and ZBaseline Folders to Test/Data Folder',b'These folders should not be in the root of the repo.'
320380854,3,b'Need to get access to external data sets ',"b""There are some data sets we can't commit into the repository.  We should download these data sets as part of the initial build, and then cache them in the `bin` directory (or similarly `gitignored` folder).  That way we can use them in our tests."""
